b'Financial Account: Investment in Reporting Country',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/OXn6X-foOq0) by [Medena Rosa](https://unsplash.com/@daisy66) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/oecd-org/financial-account-investment-in-reporting-country
b'Wine Reviews',"b'130k wine reviews with variety, location, winery, price, and description'","b""### Context\n\nAfter watching [Somm](http://www.imdb.com/title/tt2204371/) (a documentary on master sommeliers) I wondered how I could create a predictive model to identify wines through blind tasting like a master sommelier would. The first step in this journey was gathering some data to train a model. I plan to use deep learning to predict the wine variety using words in the description/review. The model still won't be able to taste the wine, but theoretically it could identify the wine based on a description that a sommelier could give. If anyone has any ideas on how to accomplish this, please post them!\n\n### Content\n\n\nThis dataset contains three files:\n\n- **winemag-data-130k-v2.csv** contains 10 columns and 130k rows of wine reviews. \n\n- **winemag-data_first150k.csv** contains 10 columns and 150k rows of wine reviews.  \n\n- **winemag-data-130k-v2.json** contains 6919 nodes of wine reviews. \n\nClick on the data tab to see individual file descriptions, column-level metadata and summary statistics.\n\n\n### Acknowledgements\n\nThe data was scraped from [WineEnthusiast](http://www.winemag.com/?s=&drink_type=wine) during the week of June 15th, 2017. The code for the scraper can be found [here](https://github.com/zackthoutt/wine-deep-learning) if you have any more specific questions about data collection that I didn't address.\n\n**UPDATE 11/24/2017**\nAfter feedback from users of the dataset I scraped the reviews again on November 22nd, 2017. This time around I collected the title of each review, which you can parse the year out of, the tasters name, and the taster's Twitter handle. This should also fix the duplicate entry issue.\n\n\n### Inspiration\n\nI think that this dataset offers some great opportunities for sentiment analysis and other text related predictive models. My overall goal is to create a model that can identify the variety, winery, and location of a wine based on a description. If anyone has any ideas, breakthroughs, or other interesting insights/models please post them.""","b""['food and drink', 'critical theory', 'medium', 'featured']""",https://www.kaggle.com/zynicide/wine-reviews
b'UFO Sightings + Air Quality',b'UFO (USA / lights) + Air Quality (USA / Pollutants levels)',"b'This dataset is the result of the fusion of two interesting datasets:\n\nUFO Sightings (https://www.kaggle.com/NUFORC/ufo-sightings)\nU.S. Pollution Data (https://www.kaggle.com/sogun3/uspollution)\nThe goal was to combine these datasets using the dates and locations (latitude and longitude) in order to get further climat informations (pollutants levels) about the ufo sightings that occured in the USA.\n\nCopied description of the pollutant metrics (from BrendaSo):\n\nEach of the five pollutants included has its own five columns of metrics. For instance, for NO2:\n\nNO2 Units : The units measured for NO2\n\nNO2 Mean : The arithmetic mean of concentration of NO2 within a given day\n\nNO2 AQI : The calculated air quality index of NO2 within a given day\n\nNO2 1st Max Value : The maximum value obtained for NO2 concentration in a given day\n\nNO2 1st Max Hour : The hour when the maximum NO2 concentration was recorded in a given day\n\nI also added a new binary variable called ET, this variable is equal to 1 if a sighting has occured and 0 otherwise. The idea is to introduce noise to the dataset by including observations that have no UFO sighting.\n\nI will later provide my own analyses and conclusions.\n\nFeel free to add suggestions!\n\nThanks.'","b""['climate', 'space', 'earth sciences', 'timelines', 'natural disasters', 'small', 'featured']""",https://www.kaggle.com/infof422henni/ufo-air-quality
b'Safebooru - Anime Image Metadata',b'1.9 million rows of tag-based anime image metadata',"b'### Context\n\n[Safebooru][1] is a tag-based image archive maintained by anime enthusiasts. It allows users to post images and add tags, annotations, translations and comments. It\'s derived from Danbooru, and differs from it in that it disallows explicit content. It\'s quite popular, and there are more than 2.5 million posts as of August 15, 2018.\n\n\n### Content\n\nThe data was scraped via Safebooru\'s online API, then converted from XML to CSV (some attributes were discarded during the conversion to make the whole csv a little smaller).\nThere are 1,934,214 rows of the metadata.\nThe data contains images uploaded to safebooru.org in the time range of 2010-01-29 through 2016-11-20.\n\n\n### Acknowledgements\n\nBanner image taken from https://safebooru.org/index.php?page=post&s=view&id=1514244\n\n\n### Inspiration\n\nWhat tags are highly correlated?\n\nCan you predict missing tags?\n\nCan you predict the score of an image based on its tags?\n\nSome tags are dependent on each other (eg. the presence of ""striped socks"" implies the existence of ""socks""). Can you build trees which visualize these dependencies?\n\n\n  [1]: http://safebooru.org'","b""['popular culture', 'visual arts', 'animation', 'drawing', 'subcultures', 'medium', 'featured']""",https://www.kaggle.com/alamson/safebooru
b'QuickDraw Sketches',b'Sketches and Strokes from the QuickDraw Game',"b'### Context\n\nThe dataset consists of the series of strokes made by users as part of the QuickDraw game from Google Creative Lab (quickdraw.withgoogle.com).  \n\n### Content\n\nThe data here are stored in ndjson format \n\n    { \n        ""key_id"":""5891796615823360"",\n        ""word"":""nose"",\n        ""countrycode"":""AE"",\n        ""timestamp"":""2017-03-01 20:41:36.70725 UTC"",\n        ""recognized"":true,\n        ""drawing"":[[[129,128,129,129,130,130,131,132,132,133,133,133,133,...]]]\n      }\n\n\nThe format of the drawing array is as following:\n\n    [ \n      [  // First stroke \n        [x0, x1, x2, x3, ...],\n        [y0, y1, y2, y3, ...],\n        [t0, t1, t2, t3, ...]\n      ],\n      [  // Second stroke\n        [x0, x1, x2, x3, ...],\n        [y0, y1, y2, y3, ...],\n        [t0, t1, t2, t3, ...]\n      ],\n      ... // Additional strokes\n    ]\n\n### Acknowledgements\n\nThe data was copied from the Google Cloud store described here: https://github.com/googlecreativelab/quickdraw-dataset on April 17, 2018 and contain just the simplified NDJSON files. The full dataset links can be found on the github page.\n\n\n### Inspiration\n\nTest ML Models'","b""['image processing', 'visual arts', 'drawing', 'large', 'featured']""",https://www.kaggle.com/google/tinyquickdraw
b'EEG Micro-experiment',b'Music vs. Reading (3-4 min per condition)',"b""### Context\n\nThis is a tiny self-experiment. The researcher collected 4-channel EEG data using \n\n - gold-tipped wet electrodes\n - [OpenBCI][1] Ganglion 4-channel development board\n - Ten20 elastic EEG cap\n - Bluetooth connection to Python and OpenBCI software\n \n\n### Content\n\nData was collected in 2 conditions for approximately 3 minutes (a bit over):\n\n 1. **Music** - the researcher streamed popular music on a custom voice-controlled IoT device\n 2. **Reading** - the researcher read scholarly articles about wave signal analysis\n\n\n### Inspiration\n\nIf there's interest in this sort of data, then I hope to make available a greatly scaled up experimental data set. This is a prototype of the process of collecting and publishing the data.\n\n  [1]: http://www.openbci.com\n  [2]: http://openbci.com""","b""['neuroscience', 'biotechnology', 'small', 'featured']""",https://www.kaggle.com/millerintllc/eeg-microexperiment
b'Brazilian E-Commerce Public Dataset by Olist',"b'100,000 Orders with product, customer and reviews info'","b""# Brazilian E-Commerce Public Dataset by Olist\n\nWelcome! This is a Brazilian ecommerce public dataset of orders made at [Olist Store](http://www.olist.com). The dataset has information of 100k orders from 2016 to 2018 made at multiple marketplaces in Brazil. Its features allows viewing an order from multiple dimensions: from order status, price, payment and freight performance to customer location, product attributes and finally reviews written by customers. We also released a geolocation dataset that relates Brazilian zip codes to lat/lng coordinates.  \n\nThis is real commercial data, it has been anonymised, and references to the companies and partners in the review text have been replaced with the names of Game of Thrones great houses.\n\n## Join it With the Marketing Funnel by Olist\nWe have also released a [Marketing Funnel Dataset](https://www.kaggle.com/olistbr/marketing-funnel-olist/home). You may join both datasets and see an order from Marketing perspective now! \n\n**Instructions on joining are available on this [Kernel](https://www.kaggle.com/andresionek/joining-marketing-funnel-with-brazilian-e-commerce).**\n\n## Context\nThis dataset was generously provided by Olist, the largest department store in Brazilian marketplaces. Olist connects small businesses from all over Brazil to channels without hassle and with a single contract. Those merchants are able to sell their products through the Olist Store and ship them directly to the customers using Olist logistics partners. See more on our website: [www.olist.com](https://www.olist.com)\n\nAfter a customer purchases the product from Olist Store a seller gets notified to fulfill that order. Once the customer receives the product, or the estimated delivery date is due, the customer gets a satisfaction survey by email where he can give a note for the purchase experience and write down some comments.\n\n### Attention\n1. An order might have multiple items.\n2. Each item might be fulfilled by a distinct seller.\n3. All text identifying stores and partners where replaced by the names of Game of Thrones great houses.\n\n### Example of a product listing on a marketplace\n![Example of a product listing on a marketplace](https://i.imgur.com/JuJMns1.png)\n\n## Data Schema\nThe data is divided in multiple datasets for better understanding and organization. Please refer to the following data schema when working with it:\n![Data Schema](https://i.imgur.com/HRhd2Y0.png)\n\n## Classified Dataset\nWe had previously released a classified dataset, but we removed it at *Version 6*. We intend to release it again as a new dataset with a new data schema. While we don't finish it, you may use the classified dataset available at the *Version 5* or previous.\n\n## Inspiration\nHere are some inspiration for possible outcomes from this dataset.\n\n**NLP:** <br>\nThis dataset offers a supreme environment to parse out the reviews text through its multiple dimensions.\n\n**Clustering:**<br> \nSome customers didn't write a review. But why are they happy or mad?\n\n**Sales Prediction:**<br> \nWith purchase date information you'll be able to predict future sales.\n\n**Delivery Performance:**<br> \nYou will also be able to work through delivery performance and find ways to optimize delivery times.\n\n**Product Quality:** <br>\nEnjoy yourself discovering the products categories that are more prone to customer insatisfaction.\n\n**Feature Engineering:** <br>\nCreate features from this rich dataset or attach some external public information to it.\n\n## Acknowledgements\nThanks to Olist for releasing this dataset.""","b""['data visualization', 'eda', 'nlp', 'multiclass classification', 'brazil', 'medium', 'featured']""",https://www.kaggle.com/olistbr/brazilian-ecommerce
b'FiveThirtyEight Forecast Methodology Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Historical FiveThirtyEight Senate Forecasts\n\nThis folder contains the data behind the story [How The FiveThirtyEight Senate Forecast Model Works](http://fivethirtyeight.com/features/how-the-fivethirtyeight-senate-forecast-model-works/).\n\nHeader | Definition\n---|---------\n`state` | Election\n`year` | Year of election\n`candidate` | Last name\n`forecast_prob` | Probability of winning election per FiveThirtyEight Election Day forecast\n`result` | `Win` or `Loss`\n\nFor archived results, see:\n\n * **2008** https://web.archive.org/web/20081106113055/http://www.fivethirtyeight.com/\n * **2010** http://elections.nytimes.com/2010/forecasts/senate\n * **2012** http://fivethirtyeight.blogs.nytimes.com/fivethirtyeights-2012-forecast/\n  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-forecast-methodology-dataset
b'Chicago Energy Usage 2010',b'From City of Chicago Open Data',"b""### Content  \n\nDisplays several units of energy consumption for households, businesses, and industries in the City of Chicago during 2010. Electric  The data was aggregated from ComEd and Peoples Natural Gas by Accenture. Electrical and gas usage data comprises 88 percent of Chicago's buildings in 2010. The electricity data comprises 68 percent of overall electrical usage in the city while gas data comprises 81 percent of all gas consumption in Chicago for 2010.\n\nCensus blocks with less than 4 accounts is displayed at the Community Area without further geographic identifiers. This dataset also contains selected variables describing selected characteristics of the Census block population, physical housing, and occupancy.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/SdSc4sWVMRU) by [Jeff Sheldon](https://unsplash.com/@ugmonk) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'energy', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-energy-usage-2010
b'FiveThirtyEight Food World Cup Dataset',b'Explore Data from FiveThirtyEight',"b'### Content  \n\n# Food World Cup\n\nThis folder contains data behind the stories:\n* [The FiveThirtyEight International Food Association\xe2\x80\x99s 2014 World Cup](https://fivethirtyeight.com/features/the-fivethirtyeight-international-food-associations-2014-world-cup/)\n* [What is Americans\xe2\x80\x99 Favorite Global Cuisine?](https://fivethirtyeight.com/features/what-is-americans-favorite-global-cuisine/)\n\nAnwser key for the responses to the ""Please rate how much you like the traditional cuisine of X:"" questions.\n\nValue | Description\n------|--------------\n5 | I love this country\'s traditional cuisine. I think it\'s one of the best in the world.\n4 | I like this country\'s traditional cuisine. I think it\'s considerably above average.\n3 | I\'m OK with this county\'s traditional cuisine. I think it\'s about average.\n2 | I dislike this country\'s traditional cuisine. I think it\'s considerably below average.\n1 | I hate this country\'s traditional cuisine. I think it\'s one of the worst in the world.\nN/A | I\'m unfamiliar with this country\'s traditional cuisine.  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub\'s [API](https://developer.github.com/v3/?) and Kaggle\'s [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.'","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-food-world-cup-dataset
b'FiveThirtyEight Flying Etiquette Survey Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Flying Etiquette Survey\n\nThis folder contains data behind the story [41 Percent of Fliers Say It\xe2\x80\x99s Rude To Recline Your Airplane Seat](http://fivethirtyeight.com/datalab/airplane-etiquette-recline-seat).\n\n`flying-etiquette.csv` contains the results of a SurveyMonkey survey commissioned by FiveThirtyEight for the story.  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-flying-etiquette-survey-dataset
b'FiveThirtyEight Hip Hop Candidate Lyrics Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Hip Hop Candidate Lyrics\n\nThis folder contains data behind the story [ Hip-Hop Is Turning On Donald Trump](http://projects.fivethirtyeight.com/clinton-trump-hip-hop-lyrics/).\n\n`genius_hip_hop_lyrics.csv` contains every mention of the 2016 primary candidates in hip-hop songs.\n\nHeader | Definition\n---|---------\n`candidate` | Candidate referenced\n`song` | Song name\n`artist` | Artist name\n`sentiment` | Positive, negative or neutral\n`theme` | Theme of lyric\n`album_release_date` | Date of album release\n`line` | Lyrics\n`url` | Genius link\n\nSource: [Genius](http://genius.com/)  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-hip-hop-candidate-lyrics-dataset
b'NYS Utility Company Customer Service Response Data',b'From New York State Open Data',"b""### Content  \n\nThe Customer Service Response Index tracks utility performance and identifies the current level of customer service and responsiveness delivered by each utility service provider under the Commission\xe2\x80\x99s jurisdiction with respect to consumer complaints filed with the Commission.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/YoelVcKWmws) by [Luca Bravo](https://unsplash.com/@lucabravo) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'utility', 'telecommunications', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-utility-company-customer-service-response-data
b'September 2018 Donald Trump-Related Tweets',b'Tweets Scrapped Using #trump',"b'#Context\n\nDonald Trump is/was the 45th president of the United States of America.\n\n#Content\n\n### September 2018 #trump Tweets\n\nThis dataset was created to conduct a sentiment analysis on tweets made about President Donald Trump on September 29, 2018 and compare those results to an analysis made on tweets posted on election night of 2016. \n\n#Acknowledgements\n\nThis database was scraped using the Twitter API.'","b""['politics', 'small', 'featured']""",https://www.kaggle.com/thomascedge/september-2018-trump-tweets
b'English Wikipedia Articles 2017-08-20 Models',b'Gensim models trained on English Wikipedia Article 2017-08-20',"b'### Context\n\nThis is a collection of pre-trained Gensim models produced for Data Science Nashville\'s November meetup, ""Introduction to Gensim."" I\'ve trained these models on the [English Wikipedia Articles 2017-08-20 SQLite][1] dataset, and will be uploading the scripts used. Check back here soon for links.\n\n### Content\n\n - Dictionary\n - TF-IDF\n - Latent Semantic Indexing/Analysis (LSI/LSA)\n     - topics = 200\n     - single pass\n - Latent Dirichlet Allocation (LDA)\n     - topics = 200\n     - single pass\n - Word2Vec\n     - size = 100\n     - 5 epochs\n - FastText\n     - size = 100\n     - 5 epochs\n\n### Acknowledgements\n\nHopefully, these pre-trained models will be useful for fledgling data scientists that are new to Gensim. I suggest creating a notebook and linking the [English Wikipedia Articles 2017-08-20 SQLite][2] to it so you have some data to play with. Note that these models are not tuned in any manner whatsoever, I simply wanted to demonstrate how to train a Gensim model and allows users to explore the API.\n\nThe banner image was provided by [Jack T][3] on [Unsplash][4].\n\n\n  [1]: https://www.kaggle.com/jkkphys/english-wikipedia-articles-20170820-sqlite\n  [2]: https://www.kaggle.com/jkkphys/english-wikipedia-articles-20170820-sqlite\n  [3]: https://unsplash.com/@blankest\n  [4]: https://unsplash.com'","b""['text mining', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/jkkphys/english-wikipedia-articles-20170820-models
b'Chest X-Ray Images (Pneumonia)',"b'5,863 images, 2 categories'","b'### Context\n\nhttp://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n\n![](https://i.imgur.com/jZqpV51.png)\n\nFigure S6. Illustrative Examples of Chest X-Rays in Patients with Pneumonia, Related to Figure 6\nThe normal chest X-ray (left panel) depicts clear lungs without any areas of abnormal opacification in the image. Bacterial pneumonia (middle) typically exhibits a focal lobar consolidation, in this case in the right upper lobe (white arrows), whereas viral pneumonia (right) manifests with a more diffuse \xe2\x80\x98\xe2\x80\x98interstitial\xe2\x80\x99\xe2\x80\x99 pattern in both lungs.\nhttp://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n\n### Content\n\nThe dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia/Normal).  There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia/Normal). \n\nChest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children\xe2\x80\x99s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients\xe2\x80\x99 routine clinical care. \n\nFor the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.\n\n### Acknowledgements\n\nData: https://data.mendeley.com/datasets/rscbjbr9sj/2\n\nLicense: [CC BY 4.0][1]\n\nCitation: http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n\n![enter image description here][2]\n\n\n### Inspiration\n\nAutomated methods to detect and classify human diseases from medical images.\n\n\n  [1]: https://creativecommons.org/licenses/by/4.0/\n  [2]: https://i.imgur.com/8AUJkin.png'","b""['image data', 'medicine', 'biology', 'large', 'featured']""",https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia
b'Christmas Recipes',b'1600 christmas cooking recipes',"b""### Context\n\nI put together this list of Christmas recipes so I could better understand common themes of Christmas cooking and practice common NLP techniques.\n\nFeel free to run your own analysis and let me know of any suggestions I could make to improve the dataset.\n\nScraping code can be found [here][1].\n\n\n### Content\n\nThis JSON lines file contains 1600 christmas cooking recipes scraped from [BBC Good Food][2]. \n\nThe file contains:\n\n - Recipe Title\n - Recipe Description\n - Recipe Author\n - Ingredients list\n - Step by step method\n\n### Acknowledgements\n\nI'd like to acknowledge the authors of each recipe and BBC Good Food website.\n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?\n\n\n  [1]: https://github.com/GJBroughton/BBC_good_food_recipes\n  [2]: https://www.bbcgoodfood.com/""","b""['nlp', 'food and drink', 'small', 'featured']""",https://www.kaggle.com/gjbroughton/christmas-recipes
b'2018 NBA Play-by-Play',b'Every play logged in 2018 Season',"b""### Context\n\nThis dataset contains play-by-play data for 2018/19 regular season games.\n\n\n### Content\n\nThis data is subscription based from BigDataBall.com. This dataset is limited to the current season (2018/19) through November 20, 2018.\n\n\n### Acknowledgements\n\nSource: https://www.bigdataball.com\n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?""","b""['basketball', 'small', 'featured']""",https://www.kaggle.com/yarnedia/2018-nba-playbyplay
b'Mall Customer Segmentation Data',b'Market Basket Analysis',"b""### Context\n\nThis data set is created only for the learning purpose of the customer segmentation concepts , also known as market basket analysis . I will demonstrate this by using unsupervised ML technique (KMeans Clustering Algorithm) in the simplest form.   \n\n\n### Content\n\nYou are owing a supermarket mall and through membership cards , you have some basic data about your customers like Customer ID, age, gender, annual income and spending score. \nSpending Score is something you assign to the customer based on your defined parameters like customer behavior and purchasing data. \n\n**Problem Statement**\nYou own the mall and want to understand the customers like who can be easily converge [Target Customers] so that the sense can be given to marketing team and plan the strategy accordingly. \n\n\n### Acknowledgements\n\nFrom Udemy's Machine Learning A-Z course.\n\nI am new to Data science field and want to share my knowledge to others\n\nhttps://github.com/SteffiPeTaffy/machineLearningAZ/blob/master/Machine%20Learning%20A-Z%20Template%20Folder/Part%204%20-%20Clustering/Section%2025%20-%20Hierarchical%20Clustering/Mall_Customers.csv\n\n### Inspiration\n\nBy the end of this case study , you would be able to answer below questions. \n1- How to achieve customer segmentation using machine learning algorithm (KMeans Clustering) in Python in simplest way.\n2- Who are your target customers with whom you can start marketing strategy [easy to converse]\n3- How the marketing strategy works in real world    ""","b""['business', 'clustering', 'preprocessing', 'object segmentation', 'market basket', 'small', 'featured']""",https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python
b'Kaggle Datasets',b'A dataset of all the datasets on Kaggle',"b'### Inspiration\nWhat did we all upload to kaggle actually? And how did the community responded? We can find it out via looking at this dataset of the datasets.\n\n### Content\nThis dataset is in a csv format, where each column is the features and attributes of a dataset on Kaggle (e.g. tags, filetype, no. of Kernels, etc.) and each row is a dataset on Kaggle\n\n### Acknowledgements\nThanks kaggle for the super easy api endpoint design!\n'","b""['tabular data', 'small', 'featured']""",https://www.kaggle.com/morriswongch/kaggle-datasets
b'Sign Language Digits Dataset',"b""Turkey Ankara Ayranc\xc4\xb1 Anadolu High School's Sign Language Digits Dataset""","b'### Context\n\nSign languages (also known as signed languages) are languages that use manual communication to convey meaning. This can include simultaneously employing hand gestures, movement, orientation of the fingers, arms or body, and facial expressions to convey a speaker\'s ideas.  Source: https://en.wikipedia.org/wiki/Sign_language\n\n### Content\n\n### Dataset Preview:\n\n\n<img src=""https://github.com/ardamavi/Sign-Language-Digits-Dataset/raw/master/Examples/example_0.JPG""> <img src=""https://github.com/ardamavi/Sign-Language-Digits-Dataset/raw/master/Examples/example_1.JPG""> <img src=""https://github.com/ardamavi/Sign-Language-Digits-Dataset/raw/master/Examples/example_2.JPG""> <img src=""https://github.com/ardamavi/Sign-Language-Digits-Dataset/raw/master/Examples/example_3.JPG""> <img src=""https://github.com/ardamavi/Sign-Language-Digits-Dataset/raw/master/Examples/example_4.JPG"">\n\n<img src=""https://github.com/ardamavi/Sign-Language-Digits-Dataset/raw/master/Examples/example_5.JPG""> <img src=""https://github.com/ardamavi/Sign-Language-Digits-Dataset/raw/master/Examples/example_6.JPG""> <img src=""https://github.com/ardamavi/Sign-Language-Digits-Dataset/raw/master/Examples/example_7.JPG""> <img src=""https://github.com/ardamavi/Sign-Language-Digits-Dataset/raw/master/Examples/example_8.JPG""> <img src=""https://github.com/ardamavi/Sign-Language-Digits-Dataset/raw/master/Examples/example_9.JPG"">\n\n### Details of datasets:\n- Image size: 64x64\n- Color space: Grayscale\n- File format: npy\n- Number of classes: 10 (Digits: 0-9)\n- Number of participant students: 218\n- Number of samples per student: 10\n\n### Details of datasets in GitHub Repo:\nRepo: [github.com/ardamavi/Sign-Language-Digits-Dataset](https://github.com/ardamavi/Sign-Language-Digits-Dataset)\n\n- Image size: 100x100\n- Color space: RGB\n\n\n### Acknowledgements\n\n# Sign Language Digits Dataset\n## Dataset GitHub Page: [github.com/ardamavi/Sign-Language-Digits-Dataset](https://github.com/ardamavi/Sign-Language-Digits-Dataset)\n### By ***[Turkey Ankara Ayranc\xc4\xb1 Anadolu High School](http://ayrancianadolu.meb.k12.tr)*** Students\n\n#### Turkey Ankara Ayranc\xc4\xb1 Anadolu High School\'s Sign Language Digits Dataset\nThis dataset prepared by our school students.\n\n## Project executives:\n## Zeynep Dikle & Arda Mavi\nTurkey Ankara Ayranc\xc4\xb1 Anadolu High School Students\n\n# For Development:\n### Processing Dataset:\nFor processing the dataset, look up Arda Mavi\'s GitHub Gist: [gist.github.com/ardamavi/get_dataset.py](https://gist.github.com/ardamavi/a7d06ff8a315308771c70006cf494d69)\n\n### Inspiration\n\nWhat is that person saying?\n'","b""['image data', 'languages', 'small', 'featured']""",https://www.kaggle.com/ardamavi/sign-language-digits-dataset
b'Oakland Crime Statistics 2011 to 2016',b'Explore open data from the city of Oakland',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of Oakland in California. The organization has an open data platform found [here](data.oaklandnet.com) and they update their information according to the amount of data that is brought in. Explore Oakland's Data using Kaggle and all of the data sources available through the city of Oakland [organization page](https://www.kaggle.com/cityofoakland)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License, NA""","b""['socrata', 'utility', 'medium', 'featured']""",https://www.kaggle.com/cityofoakland/oakland-crime-statistics-2011-to-2016
b'Ethereum Blockchain',b'Complete live historical Ethereum blockchain data (BigQuery)',"b'## Context\n\nBitcoin and other cryptocurrencies have captured the imagination of technologists, financiers, and economists. Digital currencies are only one application of the underlying blockchain technology. Like its predecessor, Bitcoin, the [Ethereum][1] blockchain can be described as an immutable distributed ledger. However, creator Vitalik Buterin also extended the set of capabilities by including a virtual machine that can execute arbitrary code stored on the blockchain as smart contracts.\n\nBoth Bitcoin and Ethereum are essentially [OLTP][2] databases, and provide little in the way of [OLAP][3] (analytics) functionality. However the Ethereum dataset is notably distinct from the Bitcoin dataset:\n\n* The Ethereum blockchain has as its primary unit of value Ether, while the Bitcoin blockchain has Bitcoin. However, the majority of value transfer on the Ethereum blockchain is composed of so-called tokens. Tokens are created and managed by smart contracts.\n\n* Ether value transfers are precise and direct, resembling accounting ledger debits and credits. This is in contrast to the Bitcoin value transfer mechanism, for which it can be difficult to determine the balance of a given wallet address.\n\n* Addresses can be not only wallets that hold balances, but can also contain smart contract bytecode that allows the programmatic creation of agreements and automatic triggering of their execution.  An aggregate of coordinated smart contracts could be used to build a [decentralized autonomous organization][4].\n\n## Content\n\nThe Ethereum blockchain data are now available for exploration with BigQuery. All historical data are in the [`ethereum_blockchain dataset`][5], which updates daily.\n\nOur hope is that by making the data on public blockchain systems more readily available it promotes technological innovation and increases societal benefits.\n\n## Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.bitcoin_blockchain.[TABLENAME]`. **[Fork this kernel to get started][6]**.\n\n## Acknowledgements\n\n[Cover photo by Thought Catalog][7] on Unsplash\n\n## Inspiration\n\n* What are the most popularly exchanged digital tokens, represented by ERC-721 and ERC-20 smart contracts? \n* Compare transaction volume and transaction networks over time\n* Compare transaction volume to historical prices by joining with other available data sources like [Bitcoin Historical Data][8]\n\n\n  [1]: https://ethereum.org/\n  [2]: https://en.wikipedia.org/wiki/Online_transaction_processing\n  [3]: https://en.wikipedia.org/wiki/Online_analytical_processing\n  [4]: https://en.wikipedia.org/wiki/Decentralized_autonomous_organization\n  [5]: https://bigquery.cloud.google.com/dataset/bigquery-public-data:ethereum_blockchain\n  [6]: https://www.kaggle.com/mrisdal/visualizing-average-ether-costs-over-time\n  [7]: https://unsplash.com/photos/bj8U389A9N8\n  [8]: https://www.kaggle.com/bigquery/bitcoin-blockchain'","b""['finance', 'internet', 'bigquery', 'time series', 'money', 'large', 'featured']""",https://www.kaggle.com/bigquery/ethereum-blockchain
b'The Office Action Research Dataset for Patents',b'Actions taken by patent examiners to patent applicants (BigQuery)',"b'### [Fork this notebook][3] to get started on accessing data in the BigQuery dataset by writing SQL queries using the BQhelper module.\n\n## Context\nThe Office Action Research Dataset for Patents contains detailed information derived from the Office actions issued by patent examiners to applicants during the patent examination process. The \xe2\x80\x9cOffice action\xe2\x80\x9d is a written notification to the applicant of the examiner\xe2\x80\x99s decision on patentability and generally discloses the grounds for a rejection, the claims affected, and the pertinent prior art. \n\n## Content\nThis initial release consists of three files derived from 4.4 million Office actions mailed during the 2008 to mid-2017 period from USPTO examiners to the applicants of 2.2 million unique patent applications.\n\n## Acknowledgements\nA working paper describing this dataset is available and can be cited as Lu, Qiang and Myers, Amanda F. and Beliveau, Scott, USPTO Patent Prosecution Research Data: Unlocking Office Action Traits (November 20, 2017). USPTO Economic Working Paper No. 2017-10. Available at SSRN: https://ssrn.com/abstract=3024621 (link is external).\n\nThis effort is made possible by the USPTO Digital Services & Big Data portfolio and collaboration with the USPTO Office of the Chief Economist (OCE). The OCE provides these data files for public use and encourages users to identify fixes and improvements. Please provide all feedback to: EconomicsData@uspto.gov.\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:uspto_oce_office_actions\n\nBanner photo by [Trent Erwin][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/UgA3Xvi3SkA\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-office-action-research-patents-data'","b""['bigquery', 'law', 'research', 'large', 'featured']""",https://www.kaggle.com/bigquery/uspto-oce-office-actions
b'OECD Current Price Gross Domestic Product',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/5KmrpfJiTSc) by [ian dooley](https://unsplash.com/@nativemello) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/oecd-org/oecd-current-price-gross-domestic-product
b'USPTO OCE Patent Litigation Docket Reports Data',"b'Detailed patent litigation data on 74,623 unique district court cases (BigQuery)'","b'### [Fork this notebook][3] to get started on accessing data in the BigQuery dataset by writing SQL queries using the BQhelper module.\n\n## Context\nOCE collected all of the data from the Public Access to Court Electronics Records (PACER) and RECAP, an independent project designed to serve as a repository for litigation data sourced from PACER. The final output datasets include information on the litigating parties involved and their attorneys; the cause of action; the court location; important dates in the litigation history; and descriptions of all documents submitted in a given case, which cover more than 5 million separate documents contained in the case docket reports.\n\n## Content\nUSPTO OCE Patent Litigation Docket Reports Data contains detailed patent litigation data on 74,623 unique district court cases filed during the period 1963-2015.\n\n## Acknowledgements\n""USPTO OCE Patent Litigation Docket Reports Data"" by the USPTO, for public use.\nMarco, A., A. Tesfayesus, A. Toole (2017). \xe2\x80\x9cPatent Litigation Data from US District Court Electronic Records (1963-2015).\xe2\x80\x9d USPTO Economic Working Paper No. 2017-06.\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:uspto_oce_litigation\n\nBanner photo by [Samuel Zeller][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/vpR0oc4X8Mk\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-uspto-patent-litigation-reports-data'","b""['bigquery', 'law', 'large', 'featured']""",https://www.kaggle.com/bigquery/uspto-oce-litigation
b'Breast Histopathology Images',"b'198,738 IDC(-) image patches; 78,786 IDC(+) image patches'","b'### Context\n\nInvasive Ductal Carcinoma (IDC) is the most common subtype of all breast cancers. To assign an aggressiveness grade to a whole mount sample, pathologists typically focus on the regions which contain the IDC. As a result, one of the common pre-processing steps for automatic aggressiveness grading is to delineate the exact regions of IDC inside of a whole mount slide.\n\n### Content\n\nThe original dataset consisted of 162 whole mount slide images of Breast Cancer (BCa) specimens scanned at 40x. From that, 277,524 patches of size 50  x 50 were extracted (198,738 IDC negative and 78,786 IDC positive).  Each patch\xe2\x80\x99s file name is of the format:  u_xX_yY_classC.png   \xe2\x80\x94 > example 10253_idx5_x1351_y1101_class0.png . Where u is the patient ID (10253_idx5), X is the x-coordinate of where this patch was cropped from, Y is the y-coordinate of where this patch was cropped from, and C indicates the class where 0 is non-IDC and 1 is IDC.\n\n\n\n### Acknowledgements\n\nThe original files are located here: http://gleason.case.edu/webdata/jpi-dl-tutorial/IDC_regular_ps50_idx5.zip\nCitation: https://www.ncbi.nlm.nih.gov/pubmed/27563488 and http://spie.org/Publications/Proceedings/Paper/10.1117/12.2043872\n\n### Inspiration\n\nBreast cancer is the most common form of cancer in women, and invasive ductal carcinoma (IDC) is the most common form of breast cancer.  Accurately identifying and categorizing breast cancer subtypes is an important clinical task, and automated methods can be used to save time and reduce error.'","b""['image data', 'binary classification', 'medicine', 'machine learning', 'large', 'featured']""",https://www.kaggle.com/paultimothymooney/breast-histopathology-images
b'RMU Dissertation - Final Data File',b'Healthcare Data Analytics',"b'### Context\n\nFinding the factors that may influence the Standardized Readmission Ratio (SRR) to help dialysis facilities improve care qulaity. \n\n### Content\n\n\nInteger,CCN\nAverageAge\nPctgAge18\nPctgAge18t64\nPctgAge64\nPctgBlack\nPctgHispanic\nPctgFemale\nNetwork\nName\nCity\nStateCode\nPctgCalciumUncorrected102\nAvgCalciumUncorrected\nAvgSerumPhosphorous\nPctgSerumPhosphorous70\nPctgFistula\nPctgCatheterOnly90\nTotalPatients\nPctgMedicare\nPctgMedicarePending\nPctgNonMedicare\nComplianceStatus\nProfitStatus\nChainOwner\nEveningShift\nDialyzerReuse\nTotalStations\nTotalStaff\nSRR\nPctgFluVaccine\nAvgHemoglobin\nPctgHemoglobin10\nPctgHemoglobin10t11\nPctgHemoglobin11t12\nPctgHemoglobin12\nPctgESAPrescribed\nAvgUFR\nPctgUFRLE13\nPctgUFRGT13\nAvgKtV\nPctgKtV12\nPctgKtV12t18\nPctgKtV18\nPctgKtVOther\nZipCode\nPctgBlackACS\nPctgHispanicACS\nUnemploymentRate\nPctgFamilyBelowFPL\nPctgPoorEnglish\nHospitalAffiliation\nState\nRegion\nDivision\nUrbanicity\nUrbanicity2\nYearsInOps\n\n### Acknowledgements\n\nThis is the final dataset produced by the data blending process described below:\n\n - https://www.kaggle.com/wcj365/activity-one-blend-dfr-dfc-qip-data\n - https://www.kaggle.com/wcj365/activity-two-blend-acs-data\n - https://www.kaggle.com/wcj365/activity-three-to-seven\n\nThanks to Kaggle for the powerful platform and wonderful community.\n\n\n### Inspiration\n\nData Analytics for Social Good.'","b""['healthcare', 'health', 'small', 'featured']""",https://www.kaggle.com/wcj365/rmudsc2
b'OECD Hourly Earnings: Manufacturing',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/RE5UGE_4iFU) by [thr3 eyes](https://unsplash.com/@thr3eyes) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/oecd-org/oecd-hourly-earnings-manufacturing
b'Google Patents Public Data',b'Worldwide bibliographic and US patent publications (BigQuery)',"b'### [Fork this notebook][4] to get started on accessing data in the BigQuery dataset by writing SQL queries using the BQhelper module.\n\n## Context\n\nGoogle Patents Public Data, provided by IFI CLAIMS Patent Services, is a worldwide bibliographic and US full-text dataset of patent publications. Patent information accessibility is critical for examining new patents, informing public policy decisions, managing corporate investment in intellectual property, and promoting future scientific innovation. The growing number of available patent data sources means researchers often spend more time downloading, parsing, loading, syncing and managing local databases than conducting analysis. With these new datasets, researchers and companies can access the data they need from multiple sources in one place, thus spending more time on analysis than data preparation.\n\n## Content\n\nThe Google Patents Public Data dataset contains a collection of publicly accessible, connected database tables for empirical analysis of the international patent system. \n\n## Acknowledgements\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:patents\n\nFor more info, see the documentation at https://developers.google.com/web/tools/chrome-user-experience-report/\n\n\xe2\x80\x9cGoogle Patents Public Data\xe2\x80\x9d by IFI CLAIMS Patent Services and Google is licensed under a [Creative Commons Attribution 4.0 International License][3].\n\nBanner photo by [Helloquence][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/5fNmWej4tAA\n  [2]: https://unsplash.com/\n  [3]: https://creativecommons.org/licenses/by/4.0/\n  [4]: https://www.kaggle.com/jessicali9530/how-to-query-google-patents-public-data\n'","b""['bigquery', 'business', 'law', 'large', 'featured']""",https://www.kaggle.com/bigquery/patents
b'FiveThirtyEight Masculinity Survey Dataset',b'Explore Data from FiveThirtyEight',"b'### Content  \n\n# Masculinity Survey\n\nThis directory contains data behind the story [What Do Men Think It Means To Be A Man?](https://fivethirtyeight.com/features/what-do-men-think-it-means-to-be-a-man).\n\n`masculinity-survey.csv` contains the results of a survey of 1,615 adult men conducted by SurveyMonkey in partnership with FiveThirtyEight and WNYC Studios from May 10-22, 2018. The modeled error estimate for this survey is plus or minus 2.5 percentage points. The percentages have been weighted for age, race, education, and geography using the Census Bureau\xe2\x80\x99s American Community Survey to reflect the demographic composition of the United States age 18 and over. Crosstabs with less than 100 respondents have been left blank because responses would not be statistically significant.\n\n`raw-responses.csv` contains all 1,615 responses to the survey including the weights for each response. Responses to open-ended questions have been omitted, including those where a respondent explained what they meant by selecting the ""other"" option in response to a question.\n\n`masculinity-survey.pdf` contains the questions corresponding to the colums in the raw responses file.  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub\'s [API](https://developer.github.com/v3/?) and Kaggle\'s [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.'","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-masculinity-survey-dataset
b'CMS Pending Initial L and Ts',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/cms-pending-initial-l-and-ts
b'OECD GDP by Expenditure in Constant Prices',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/VsJWcFfBjuY) by [eberhard grossgasteiger](https://unsplash.com/@eberhardgross) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/oecd-org/oecd-gdp-by-expenditure-in-constant-prices
b'GDP Implicit Price Deflator',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/skeSzEL27F0) by [Aleks Dahlberg](https://unsplash.com/@aleksdahlberg) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/oecd-org/gdp-implicit-price-deflator
b'Gross Fixed Capital Formation',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/zDkXbW_QGsA) by [Holly Mandarich](https://unsplash.com/@hollymandarich) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/oecd-org/gross-fixed-capital-formation
b'Disclosed Standard Essential Patents (dSEP) Data',b'Disclosed SEPs data at 13 major standard setting organizations (BigQuery)',"b'## Context\nThis database is the result of a combined effort of several European and US researchers to collect, clean and harmonise disclosed SEPs data at thirteen major standard setting organisations (including ETSI, ITU, IEEE, ISO, and more). \n\n## Content\nDisclosed Standard Essential Patents (dSEP) Data provides a full overview of disclosed intellectual property rights at setting organizations worldwide.\n\n[Fork this notebook][3] to get started on accessing data in the BigQuery dataset using the BQhelper package to write SQL queries.\n\n## Acknowledgements\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:dsep\n\n\xe2\x80\x9cDisclosed Standard Essential Patents Database\xe2\x80\x9d by Bekkers, R., Catalini, C., Martinelli, A., & Simcoe, T. (2012). Intellectual Property Disclosure in Standards Development. Proceedings from NBER conference on Standards, Patents & Innovation, Tucson (AZ), January 20 and 21, 2012.\n\nBanner photo by [Helloquence][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/OQMZwNd3ThU\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-google-patents-public-data'","b""['bigquery', 'business', 'small', 'featured']""",https://www.kaggle.com/bigquery/dsep
b'USFS Forest Inventory and Analysis (FIA) Program',b'USFS Forest Inventory and Analysis (FIA) Program Data (BigQuery Dataset)',"b""### Context\n\nUS Forest Service Forest Inventory and Analysis National Program.\n\nThe Forest Inventory and Analysis (FIA) Program of the U.S. Forest Service provides the information needed to assess America's forests. \n\nhttps://www.fia.fs.fed.us/\n\n### Content\n\nAs the Nation's continuous forest census, our program projects how forests are likely to appear 10 to 50 years from now. This enables us to evaluate whether current forest management practices are sustainable in the long run and to assess whether current policies will allow the next generation to enjoy America's forests as we do today. \n\nFIA reports on  status and trends in forest area and location; in the species, size, and health of trees; in total tree growth, mortality, and removals by harvest;  in wood production and utilization rates by various products; and in forest land ownership.\n\nThe Forest Service has significantly enhanced the FIA program by changing from a periodic survey to an annual survey, by increasing our capacity to analyze and publish data, and by expanding the scope of our data collection to include soil, under story vegetation, tree crown conditions, coarse woody debris, and lichen community composition on a subsample of our plots. The FIA program has also expanded to include the sampling of urban trees on all land use types in select cities. \n\nFor more details, see: https://www.fia.fs.fed.us/library/database-documentation/current/ver70/FIADB%20User%20Guide%20P2_7-0_ntc.final.pdf\n\nFork [this kernel][2] to get started with this dataset.\n\n### Acknowledgements\n\nhttps://www.fia.fs.fed.us/\n\nhttps://cloud.google.com/blog/big-data/2017/10/get-to-know-your-trees-us-forest-service-fia-dataset-now-available-in-bigquery\n\nFIA is managed by the Research and Development organization within the USDA Forest Service in cooperation with State and Private Forestry and National Forest Systems. FIA traces it's origin back to the McSweeney - McNary Forest Research Act of 1928 (P.L. 70-466). This law initiated the first inventories starting in 1930.\n\nBanner Photo by [@rmorton3 from Unplash][3].\n\n### Inspiration\n \nEstimating timberland and forest land acres by state.\n\n![enter image description here][1]\nhttps://cloud.google.com/blog/big-data/2017/10/images/4728824346443776/forest-data-4.png\n\n  [1]: https://cloud.google.com/blog/big-data/2017/10/images/4728824346443776/forest-data-4.png\n  [2]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-usfs-dataset\n  [3]: https://unsplash.com/photos/hjdQdd3oudQ""","b""['government', 'utility', 'environment', 'government agencies', 'forestry', 'large', 'featured']""",https://www.kaggle.com/usforestservice/usfs-fia
"b'BR Elections for Fed. Deputy, from 2006-2010'","b'Data about elections for federal deputies, in Brazil, from 2006 to 2010.'","b""### Context\n\nThe dataset was obtained in order to exercise prediction of some variables. In particular the number of votes to a specific federal deputy, during a Brazilian election.\n\n### Content\n\nThe data correspond to candidates for federal deputy elections from the period of 2006 to 2010. There's a variety of names, from various states and parties.\n\n### Acknowledgements\n\nThe data was provided by my teacher at UFCG.""","b""['politics', 'government', 'brazil', 'small', 'featured']""",https://www.kaggle.com/ddspog/br-elections-for-federal-deputy-from-20062010
b'Google Patents Research Data',b'Data analysis work used in Google Patents (BigQuery)',"b'## Context\nGoogle Patents is a search engine launched in 2006 that lets you search through millions of patents from over a dozen patent offices including United States Patent and Trademark Office (USPTO) and those of other countries.\n\n## Content\nGoogle Patents Research Data contains the output of much of the data analysis work used in Google Patents (patents.google.com), including machine translations of titles and abstracts from Google Translate, extracted top terms, similar documents, and forward references.\n\n[Fork this notebook][3] to get started on accessing data in the BigQuery dataset using the BQhelper package to write SQL queries.\n\n## Acknowledgements\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:google_patents_research\n\n\xe2\x80\x9cGoogle Patents Research Data\xe2\x80\x9d by Google, based on data provided by IFI CLAIMS Patent Services, is licensed under a Creative Commons Attribution 4.0 International License.\n\nBanner photo by [Alejandro Escamilla][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/y83Je1OC6Wc\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-google-patents-public-data'","b""['bigquery', 'business', 'research', 'large', 'featured']""",https://www.kaggle.com/bigquery/google-patents-research
b'Oakland Call Center & Public Work Service Requests',b'Explore open data from the city of Oakland',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of Oakland in California. The organization has an open data platform found [here](data.oaklandnet.com) and they update their information according to the amount of data that is brought in. Explore Oakland's Data using Kaggle and all of the data sources available through the city of Oakland [organization page](https://www.kaggle.com/cityofoakland)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: NA, Public Domain""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/cityofoakland/oakland-call-center-public-work-service-requests
b'SF Police Calls for Service and Incidents',b'From San Francisco Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License""","b""['socrata', 'crime', 'utility', 'medium', 'featured']""",https://www.kaggle.com/san-francisco/sf-police-calls-for-service-and-incidents
b'Stack Overflow Data',b'Stack Overflow Data (BigQuery Dataset)',"b'### Context\n\nStack Overflow is the largest online community for programmers to learn, share their knowledge, and advance their careers. \n\n### Content\n\nUpdated on a quarterly basis, this BigQuery dataset includes an archive of Stack Overflow content, including posts, votes, tags, and badges. This dataset is updated to mirror the Stack Overflow content on the Internet Archive, and is also available through the Stack Exchange Data Explorer.\n\nFork [this kernel][1] to get started with this dataset.\n\n### Acknowledgements\n\nDataset Source: https://archive.org/download/stackexchange\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:stackoverflow\n\nhttps://cloud.google.com/bigquery/public-data/stackoverflow\n\nBanner Photo by [Caspar Rubin from Unplash][2].\n\n\n### Inspiration\n\nWhat is the percentage of questions that have been answered over the years?\n\nWhat is the reputation and badge count of users across different tenures on StackOverflow?\n\nWhat are 10 of the \xe2\x80\x9ceasier\xe2\x80\x9d gold badges to earn?\n\nWhich day of the week has most questions answered within an hour?\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-stackoverflow-data\n  [2]: https://unsplash.com/photos/fPkvU7RDmCo\n'","b""['internet', 'programming', 'programming languages', 'large', 'featured']""",https://www.kaggle.com/stackoverflow/stackoverflow
b'FiveThirtyEight Mad Men Dataset',b'Explore Data from FiveThirtyEight',"b'### Content  \n\n# Mad Men\n\nThis directory contains the data behind the story [\xe2\x80\x98Mad Men\xe2\x80\x99 Is Ending. What\xe2\x80\x99s Next For The Cast?](http://fivethirtyeight.com/datalab/mad-men-is-ending-whats-next-for-the-cast/)\n\nThe primary file `show-data.csv` contains data of actors who appeared on at least half the episodes of television shows that were nominated for an Emmy for Outstanding Drama since the year 2000. It contains the following variables:\n\nHeader | Definition\n---|---------\n`Performer` | The name of the actor, according to IMDb. This is not a unique identifier - two performers appeared in more than one program\n`Show` | The television show where this actor appeared in more than half the episodes\n`Show Start` | The year the television show began\n`Show End` | The year the television show ended, ""PRESENT"" if the show remains on the air as of May 10. \n`Status?` | Why the actor is no longer on the program:  ""END"" if the show has concluded, ""LEFT"" if the show remains on the air.\n`CharEnd` | The year the character left the show. Equal to ""Show End"" if the performer stayed on until the final season. \n`Years Since` | 2015 minus CharEnd\n`#LEAD` | The number of leading roles in films the performer has appeared in since and including ""CharEnd"", according to OpusData\n`#SUPPORT` | The number of leading roles in films the performer has appeared in since and including ""CharEnd"", according to OpusData\n`#Shows` | The number of seasons of television of which the performer appeared in at least half the episodes since and including ""CharEnd"", according to OpusData\n`Score` | #LEAD + #Shows + 0.25*(#SUPPORT)\n`Score/Y` | ""Score"" divided by ""Years Since""\n`lead_notes` | The list of films  counted in #LEAD\n`support_notes` | The list of films  counted in #SUPPORT\n`show_notes`| The seasons of shows counted in #Shows\n\nThe supplemental file `performer-scores.csv` is the consolidated data from `show-data.csv` made into a pivot table.  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub\'s [API](https://developer.github.com/v3/?) and Kaggle\'s [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.'","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-mad-men-dataset
b'CMS PBJ Daily Nurse Staggins (2017-2018)',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: NA""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/cms/cms-pbj-daily-nurse-staggins-2017-2018
b'NOAA Global Surface Summary of the Day',b'From NOAA Updated Data',"b'* Update Frequency: Daily\n\nThis dataset is identical to Kaggle\'s [NOAA GSOD dataset](https://www.kaggle.com/noaa/gsod) using BigQuery. The data for both datasets updates on the same basis (daily) but may not be updated on the same time. Data from this dataset can be downloaded/accessed through this dataset page and Kaggle\'s [API](https://github.com/Kaggle/kaggle-api).\n\n### Context\n\nGlobal Surface Summary of the Day is derived from The Integrated Surface Hourly (ISH) dataset. The ISH dataset includes global data obtained from the USAF Climatology Center, located in the Federal Climate Complex with NCDC. The latest daily summary data are normally available 1-2 days after the date-time of the observations used in the daily summaries.\n\nGlobal summary of day data for 18 surface meteorological elements are derived from the synoptic/hourly observations contained in USAF DATSAV3 Surface data and Federal Climate Complex Integrated Surface Hourly (ISH). Historical data are generally available for 1929 to the present, with data from 1973 to the present being the most complete. For some periods, one or more countries\' data may not be available due to data restrictions or communications problems.\n\n### Content\n\nThe online data files begin with 1929 and are at the time of this writing at the Version 8 software level. Over 9000 stations\' data are typically available. The daily elements included in the dataset (as available from each station) are: Mean temperature (.1 Fahrenheit) Mean dew point (.1 Fahrenheit) Mean sea level pressure (.1 mb) Mean station pressure (.1 mb) Mean visibility (.1 miles) Mean wind speed (.1 knots) Maximum sustained wind speed (.1 knots) Maximum wind gust (.1 knots) Maximum temperature (.1 Fahrenheit) Minimum temperature (.1 Fahrenheit) Precipitation amount (.01 inches) Snow depth (.1 inches) Indicator for occurrence of: Fog, Rain or Drizzle, Snow or Ice Pellets, Hail, Thunder, Tornado/Funnel Cloud.\n\n### Acknowledgements\n\nDataset Source: NOAA.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source \xe2\x80\x94 http://www.data.gov/privacy-policy#data_policy \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\n[Cover photo](https://unsplash.com/photos/mA9abjhEG4A) by [Jeremy Bishop](https://unsplash.com/@jeremybishop) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['weather', 'climate', 'utility', 'large', 'featured']""",https://www.kaggle.com/noaa/noaa-global-surface-summary-of-the-day
b'CMS Indian Health Care Provider Programs ',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: NA, Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/cms-indian-health-care-provider-programs-
b'NHL Game Data',"b'Game, team, player and plays information including x,y coordinates'","b'### Context\n\nFor some, statistical analysis increases the enjoyment of sport. My long-term aim is to build an automated database driven advanced stats website like many that have come and gone before however that first starts with statistical analysis of the game to assess what and how much individual actions contribute to the outcome of the game. \n\nThe data represents all the official metrics measured for each game in the NHL in the past 6 years. I intend to update it semi-regularly depending on development progress of my database server.\n\n\n### Content\n\nThis is a mostly rational database, please refer to the ""table_realtionships.jpg"" for details on how the tables can be joined. This is not just the results and player stats of NHL games  but also details on individual plays such as shots, goals and stoppages including date & time and x,y coordinates. \n\nThe dataset is incomplete, there are some games where no plays information is available on NHL.com. It is rare and I do not know the reasons.\n\n\n### Acknowledgements\n\nThanks to Kevin Sidwar who began [documenting the still un-documented NHL stats API][1] which was used to gather this data.\n\n\n### Inspiration\n\nCompared to other sports, advanced statistics in Hockey are still in infancy. It has been suggested that the best models [can only predict the winner 62% of the time][2] due to variances in talent and ""puck luck"". \n\nI would like to believe feature engineering and a suitably trained model can account for some of this variance and beat this seemingly low target.\n\nOtherwise, what metrics can be developed to provide better indications than Corsi & Fenwick?\n\n\n  [1]: https://www.kevinsidwar.com/iot/2017/7/1/the-undocumented-nhl-stats-api\n  [2]: https://www.nhlnumbers.com/2013/08/01/machine-learning-and-hockey-is-there-a-theoretical-limit-on-predictions'","b""['sports', 'databases', 'ice hockey', 'medium', 'featured']""",https://www.kaggle.com/martinellis/nhl-game-data
b'FiveThirtyEight Hate Crimes Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Hate Crimes\n\nThis folder contains data behind the story [Higher Rates Of Hate Crimes Are Tied To Income Inequality](https://fivethirtyeight.com/features/higher-rates-of-hate-crimes-are-tied-to-income-inequality/).\n\nHeader | Definition\n---|---------\n`state` | State name\n`median_household_income` | Median household income, 2016\n`share_unemployed_seasonal` | Share of the population that is unemployed (seasonally adjusted), Sept. 2016\n`share_population_in_metro_areas` | Share of the population that lives in metropolitan areas, 2015\n`share_population_with_high_school_degree` | Share of adults 25 and older with a high-school degree, 2009\n`share_non_citizen` | Share of the population that are not U.S. citizens, 2015\n`share_white_poverty` | Share of white residents who are living in poverty, 2015\n`gini_index` | Gini Index, 2015\n`share_non_white` | Share of the population that is not white, 2015\n`share_voters_voted_trump` | Share of 2016 U.S. presidential voters who voted for Donald Trump\n`hate_crimes_per_100k_splc` | Hate crimes per 100,000 population, Southern Poverty Law Center, Nov. 9-18, 2016\n`avg_hatecrimes_per_100k_fbi` | Average annual hate crimes per 100,000 population, FBI, 2010-2015\n\n\nSources:\n[Kaiser Family Foundation](http://kff.org/other/state-indicator/median-annual-income/?currentTimeframe=0)\n[Kaiser Family Foundation](http://kff.org/other/state-indicator/unemployment-rate/?currentTimeframe=0)\n[Kaiser Family Foundation](http://kff.org/other/state-indicator/unemployment-rate/?currentTimeframe=0)\n[Census Bureau](https://www.census.gov/prod/2012pubs/p20-566.pdf)\n[Kaiser Family Foundation](http://kff.org/other/state-indicator/distribution-by-citizenship-status/?currentTimeframe=0)\n[Kaiser Family Foundation](http://kff.org/other/state-indicator/poverty-rate-by-raceethnicity/?currentTimeframe=0)\n[Census Bureau](https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_10_1YR_B19083&prodType=table)\n[Kaiser Family Foundation](http://kff.org/other/state-indicator/distribution-by-raceethnicity/?currentTimeframe=0)\n[United States Elections Project](http://www.electproject.org/2016g)\n[Southern Poverty Law Center](https://www.splcenter.org/20161129/ten-days-after-harassment-and-intimidation-aftermath-election)\n[FBI](https://ucr.fbi.gov/hate-crime)\n\n#### Correction\n\nPlease see the following commit:\nhttps://github.com/fivethirtyeight/data/commit/fbc884a5c8d45a0636e1d6b000021632a0861986\n  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-hate-crimes-dataset
b'Additional kiva snapshot',b'Additional 3GB uncompressed snapshot  from kiva',"b'### Context\nThis dataset contains additional data snapshot provided by kiva.org. It could be used in the [Data Science for Good: Kiva Crowdfunding][1] challenge. The snapshot provides information about 1.4M loans and 2.3M lenders.\n\nCountry level statistics and detailed economic grid data are provided as well.\n\n![Cover][2]\n\n### Inspiration\nThese additional files could be used for\n\n - NLP\n - Demography (age, marital status, family size)\n - Explore lenders statistics\n - Map poverty indices, economic data to countries/regions\n - Merge GPS coords to loans \n\n![gmaps][3]\n\n### Content\nThis dataset has seven main files.\n\n - loans.csv\n - lenders.csv\n - loans_lenders.csv\n - country_stats.csv\n - GEconV4.csv\n - locations.csv\n - loan_coords.csv\n\n### Acknowledgements\n\n - Thanks for kiva for providing these snapshots.  http://build.kiva.org/docs/data/snapshots\n - Human Development Index http://hdr.undp.org/en/composite/HDI\n -  CIA World Factbook https://www.cia.gov/library/publications/resources/the-world-factbook/fields/print_2046.html\n - Global Gridded Geographically Based Economic Data http://sedac.ciesin.columbia.edu/data/set/spatialecon-gecon-v4\n\nPhoto by [Doug Linstedt][4] on Unsplash.\n\n\n  [1]: https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding\n  [2]: https://www.kaggle.com/gaborfodor/additional-kiva-snapshot/downloads/cover_small.png/12\n  [3]: https://www.kaggle.com/gaborfodor/additional-kiva-snapshot/downloads/gmaps.png/12\n  [4]: https://unsplash.com/@douglinstedt'","b""['finance', 'nlp', 'demographics', 'crowdfunding', 'lending', 'medium', 'featured']""",https://www.kaggle.com/gaborfodor/additional-kiva-snapshot
b'USA Name Data',b'USA Name Data (BigQuery Dataset)',"b'### Context\n\n Cultural diversity in the U.S. has led to great variations in names and naming traditions and names have been used to express creativity, personality, cultural identity, and values.  Source: https://en.wikipedia.org/wiki/Naming_in_the_United_States\n\n### Content\n\nThis public dataset was created by the Social Security Administration and contains all names from Social Security card applications for births that occurred in the United States after 1879. Note that many people born before 1937 never applied for a Social Security card, so their names are not included in this data. For others who did apply, records may not show the place of birth, and again their names are not included in the data.\n\nAll data are from a 100% sample of records on Social Security card applications as of the end of February 2015.  To safeguard privacy, the Social Security Administration restricts names to those with at least 5 occurrences.\n\nFork [this kernel][1] to get started with this dataset.\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:usa_names\n\nhttps://cloud.google.com/bigquery/public-data/usa-names\n\nDataset Source: Data.gov.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source \xe2\x80\x94 http://www.data.gov/privacy-policy#data_policy \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [@dcp from Unplash][2].\n\n### Inspiration\n\nWhat are the most common names?\n\nWhat are the most common female names?\n\nAre there more female or male names?\n\nFemale names by a wide margin?\n\n\n\n\n\n\n\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-usa-names-data\n  [2]: https://unsplash.com/photos/7lmq5Gniypg\n\n\n\n'","b""['government', 'culture and humanities', 'medium', 'featured']""",https://www.kaggle.com/datagov/usa-names
b'London Police Records',"b'A snapshot of crime, outcome, and stop and search data'","b""This dataset provides a complete snapshot of crime, outcome, and stop and search data, as held by the Home Office from late 2014 through mid 2017 for London, both the greater metro and the city.\n\n### Content\n\nThe core fields are as follows:\n\nReported by:\tThe force that provided the data about the crime.\n\nFalls within:\tAt present, also the force that provided the data about the crime. This is currently being looked into and is likely to change in the near future.\n\nLongitude and Latitude:\tThe anonymised coordinates of the crime.\n\nLSOA code and LSOA name:\tReferences to the Lower Layer Super Output Area that the anonymised point falls into, according to the LSOA boundaries provided by the Office for National Statistics.\n\nCrime type:\tOne of the crime types listed in the Police.UK FAQ.\n\nLast outcome category:\tA reference to whichever of the outcomes associated with the crime occurred most recently. For example, this crime's 'Last outcome category' would be 'Offender fined'.\n\nContext:\tA field provided for forces to provide additional human-readable data about individual crimes. Currently, for newly added CSVs, this is always empty.\n\nFor additional details, including the steps taken to anonymize the data, please see https://data.police.uk/about/#provenance.\n\n### Acknowledgements\n\nThis dataset was kindly released by the British Home Office under the [Open Government License 3.0][1] at https://data.police.uk/data/. If you are looking for more data, they cover much more than London! All major cities in England and Wales are available, adding up to roughly 2gb of new data per month.\n\n\n  [1]: https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/""","b""['crime', 'government', 'large', 'featured']""",https://www.kaggle.com/sohier/london-police-records
b'Bitcoin Blockchain',b'Complete live historical Bitcoin blockchain data (BigQuery)',"b'### Context\n\nBlockchain technology, first implemented by [Satoshi Nakamoto in 2009][1] as a core component of Bitcoin, is a distributed, public ledger recording transactions. Its usage allows secure peer-to-peer communication by linking blocks containing hash pointers to a previous block, a timestamp, and transaction data. Bitcoin is a decentralized digital currency (cryptocurrency) which leverages the Blockchain to store transactions in a distributed manner in order to mitigate against flaws in the financial industry.\n\nNearly ten years after its inception, Bitcoin and other cryptocurrencies experienced an explosion in popular awareness. The value of Bitcoin, on the other hand, has experienced more volatility. Meanwhile, as use cases of Bitcoin and Blockchain grow, mature, and expand, hype and controversy have swirled. \n\n### Content\n \nIn this dataset, you will have access to information about blockchain blocks and transactions. All historical data are in the `bigquery-public-data:bitcoin_blockchain` dataset. It\xe2\x80\x99s updated it every 10 minutes. The data can be joined with historical prices in kernels. See available similar datasets here: https://www.kaggle.com/datasets?search=bitcoin. \n\n## Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.bitcoin_blockchain.[TABLENAME]`. **[Fork this kernel to get started][2]**.\n \n### Method &amp; Acknowledgements\n\nAllen Day ([Twitter][3] | [Medium][4]), Google Cloud Developer Advocate &amp; Colin Bookman, Google Cloud Customer Engineer retrieve data from the Bitcoin network using a [custom client available on GitHub][5] that they built with the [`bitcoinj`][6] Java library.  Historical data from the origin block to 2018-01-31 were loaded in bulk to two BigQuery tables, blocks_raw and transactions.  These tables contain fresh data, as they are now appended when new blocks are broadcast to the Bitcoin network.  For additional information visit the Google Cloud Big Data and Machine Learning Blog post [""Bitcoin in BigQuery: Blockchain analytics on public data""][7]. \n \nPhoto by [Andre Francois][8] on [Unsplash][9]. \n\n### Inspiration\n\n* How many bitcoins are sent each day?\n* How many addresses receive bitcoin each day?\n* Compare transaction volume to historical prices by joining with [other available data sources][10]\n\n\n  [1]: https://en.wikipedia.org/wiki/Blockchain\n  [2]: https://www.kaggle.com/mrisdal/visualizing-daily-bitcoin-recipients\n  [3]: https://twitter.com/allenday\n  [4]: https://medium.com/@allenday\n  [5]: https://github.com/cobookman/blockchainToAvro\n  [6]: https://bitcoinj.github.io/\n  [7]: https://cloud.google.com/blog/big-data/2018/02/bitcoin-in-bigquery-blockchain-analytics-on-public-data\n  [8]: https://unsplash.com/photos/JrjhtBJ-pGU?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\n  [9]: https://unsplash.com/search/photos/bitcoin?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\n  [10]: https://www.kaggle.com/datasets?search=bitcoin'","b""['finance', 'internet', 'bigquery', 'time series', 'money', 'large', 'featured']""",https://www.kaggle.com/bigquery/bitcoin-blockchain
b'USPTO Cancer Moonshot Patent Data',b'Discover patent trends and innovations in cancer research (BigQuery)',"b'### [Fork this notebook][3] to get started on accessing data in the BigQuery dataset by writing SQL queries using the BQhelper module.\n\n## Context\nThis curated dataset consists of 269,353 patent documents (published patent applications and granted patents) spanning the 1976 to 2016 period and is intended to help identify promising R&D on the horizon in diagnostics, therapeutics, data analytics, and model biological systems.\n\n## Content\nUSPTO Cancer Moonshot Patent Data was generated using USPTO examiner tools to execute a series of queries designed to identify cancer-specific patents and patent applications. This includes drugs, diagnostics, cell lines, mouse models, radiation-based devices, surgical devices, image analytics, data analytics, and genomic-based inventions.\n\n## Acknowledgements\n\xe2\x80\x9cUSPTO Cancer Moonshot Patent Data\xe2\x80\x9d by the USPTO, for public use. Frumkin, Jesse and Myers, Amanda F., Cancer Moonshot Patent Data (August, 2016).\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:uspto_oce_cancer\n\nBanner photo by [Jaron Nix][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/7wWRXewYCH4\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-uspto-cancer-moonshot-patent-data'","b""['healthcare', 'bigquery', 'medicine', 'medium', 'featured']""",https://www.kaggle.com/bigquery/uspto-oce-cancer
b'PatentsView Data',b'Analyze and explore US patent data by the USPTO (BigQuery)',"b'## Context\nThe USPTO grants US patents to inventors and assignees all over the world. For researchers in particular, PatentsView is intended to encourage the study and understanding of the intellectual property (IP) and innovation system; to serve as a fundamental function of the government in creating \xe2\x80\x9cpublic good\xe2\x80\x9d platforms in these data; and to eliminate redundant cleaning, converting and matching of these data by individual researchers, thus freeing up researcher time to do what they do best\xe2\x80\x94study IP, innovation, and technological change.\n\n## Content\nPatentsView Data is a database that longitudinally links inventors, their organizations, locations, and overall patenting activity. The dataset uses data derived from USPTO bulk data files.\n\n[Fork this notebook][3] to get started on accessing data in the BigQuery dataset using the BQhelper package to write SQL queries.\n\n## Acknowledgements\n\xe2\x80\x9cPatentsView\xe2\x80\x9d by the USPTO, US Department of Agriculture (USDA), the Center for the Science of Science and Innovation Policy, New York University, the University of California at Berkeley, Twin Arch Technologies, and Periscopic, used under CC BY 4.0.\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:patentsview\n\nBanner photo by [rawpixel][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/FFfTNa6tQT0\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-google-patents-public-data'","b""['bigquery', 'business', 'large', 'featured']""",https://www.kaggle.com/bigquery/patentsview
b'Sportradar Baseball dataset',b'Play-by-play data for every Baseball game in 2016',"b'### Context\n\nThis public data includes pitch-by-pitch data for Major League Baseball (MLB) games in 2016.  With this data you can effectively replay a game and rebuild basic statistics for players and teams.\n\n### Content\n\n**games_wide** - Every pitch, steal, or lineup event for each at bat in the 2016 regular season.\n\n**games_post_wide** - Every pitch, steal, or lineup event for each at-bat in the 2016 post season.\n\n**schedules** - The schedule for every team in the regular season.\n\n*The schemas for the games_wide and games_post_wide tables are identical.\n\n## Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.github_repos.[TABLENAME]`. **[Fork this kernel to get started][99]** to learn how to safely manage analyzing large BigQuery datasets.\n  [99]: https://www.kaggle.com/mrisdal/safely-analyzing-github-projects-popular-licenses\n\n### Acknowledgements\n\nDataset Source: Sportradar LLC\n\nUse: Copyright Sportradar LLC. Access to data is intended solely for internal research and testing purposes, and is not to be used for any business or commercial purpose. Data are not to be exploited in any manner without express approval from Sportradar. Display of data must include the phrase, \xe2\x80\x9cData provided by Sportradar LLC,\xe2\x80\x9d and be hyperlinked to www.sportradar.com.\n\n'","b""['bigquery', 'sports', 'statistical analysis', 'baseball', 'large', 'featured']""",https://www.kaggle.com/sportradar/baseball
b'News Category Dataset',b'Identify the type of news based on headlines and short descriptions',"b'# Context\nThis dataset contains around 200k news headlines from the year 2012 to 2018 obtained from [HuffPost](https://www.huffingtonpost.com/). The model trained on this dataset could be used to identify tags for untracked news articles or to identify the type of language used in different news articles.\n\n# Content\nEach news headline has a corresponding category. Categories and corresponding article counts are as follows:\n\n* ```POLITICS```: ```32739```\n\n* ```WELLNESS```: ```17827```\n\n* ```ENTERTAINMENT```: ```16058```\n\n* ```TRAVEL```: ```9887```\n\n* ```STYLE & BEAUTY```: ```9649```\n\n* ```PARENTING```: ```8677```\n\n* ```HEALTHY LIVING```: ```6694```\n\n* ```QUEER VOICES```: ```6314```\n\n* ```FOOD & DRINK```: ```6226```\n\n* ```BUSINESS```: ```5937```\n\n* ```COMEDY```: ```5175```\n\n* ```SPORTS```: ```4884```\n\n* ```BLACK VOICES```: ```4528```\n\n* ```HOME & LIVING```: ```4195```\n\n* ```PARENTS```: ```3955```\n\n* ```THE WORLDPOST```: ```3664```\n\n* ```WEDDINGS```: ```3651```\n\n* ```WOMEN```: ```3490```\n\n* ```IMPACT```: ```3459```\n\n* ```DIVORCE```: ```3426```\n\n* ```CRIME```: ```3405```\n\n* ```MEDIA```: ```2815```\n\n* ```WEIRD NEWS```: ```2670```\n\n* ```GREEN```: ```2622```\n\n* ```WORLDPOST```: ```2579```\n\n* ```RELIGION```: ```2556```\n\n* ```STYLE```: ```2254```\n\n* ```SCIENCE```: ```2178```\n\n* ```WORLD NEWS```: ```2177```\n\n* ```TASTE```: ```2096```\n\n* ```TECH```: ```2082```\n\n* ```MONEY```: ```1707```\n\n* ```ARTS```: ```1509```\n\n* ```FIFTY```: ```1401```\n\n* ```GOOD NEWS```: ```1398```\n\n* ```ARTS & CULTURE```: ```1339```\n\n* ```ENVIRONMENT```: ```1323```\n\n* ```COLLEGE```: ```1144```\n\n* ```LATINO VOICES```: ```1129```\n\n* ```CULTURE & ARTS```: ```1030```\n\n* ```EDUCATION```: ```1004```\n\n# Acknowledgements\n\nThis dataset was collected from [HuffPost](https://www.huffingtonpost.com/). If this is against the TOS, please let me know and I will take it down.\n\n\n# Inspiration\n\n* Can you categorize news articles based on their headlines and short descriptions?  \n\n* Do news articles from different categories have different writing styles?\n\n* A classifier trained on this dataset could be used on a free text to identify the type of language being used.'","b""['classification', 'nlp', 'linguistics', 'medium', 'featured']""",https://www.kaggle.com/rmisra/news-category-dataset
b'United States Census',b'United States Census (BigQuery Dataset)',"b'### Context\n\nThe United States Census is a decennial census mandated by Article I, Section 2 of the United States Constitution, which states: ""Representatives and direct Taxes shall be apportioned among the several States ... according to their respective Numbers.""  \nSource: https://en.wikipedia.org/wiki/United_States_Census\n\n### Content\n\nThe United States census count (also known as the Decennial Census of Population and Housing) is a count of every resident of the US. The census occurs every 10 years and is conducted by the United States Census Bureau. Census data is publicly available through the census website, but much of the data is available in summarized data and graphs. The raw data is often difficult to obtain, is typically divided by region, and it must be processed and combined to provide information about the nation as a whole.\n\nThe United States census dataset includes nationwide population counts from the 2000 and 2010 censuses. Data is broken out by gender, age and location using zip code tabular areas (ZCTAs) and GEOIDs. ZCTAs are generalized representations of zip codes, and often, though not always, are the same as the zip code for an area. GEOIDs are numeric codes that uniquely identify all administrative, legal, and statistical geographic areas for which the Census Bureau tabulates data. GEOIDs are useful for correlating census data with other censuses and surveys.\n\nFork [this kernel][1] to get started.\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:census_bureau_usa\n\nhttps://cloud.google.com/bigquery/public-data/us-census\n\nDataset Source: United States Census Bureau\n\nUse: This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - http://www.data.gov/privacy-policy#data_policy - and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [Steve Richey from Unsplash][2].\n\n### Inspiration\n\nWhat are the ten most populous zip codes in the US in the 2010 census?\n\nWhat are the top 10 zip codes that experienced the greatest change in population between the 2000 and 2010 censuses?\n\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-usa-census-dataset\n  [2]: https://unsplash.com/photos/wVK0ypTn61Y\n\n\n![https://cloud.google.com/bigquery/images/census-population-map.png](https://cloud.google.com/bigquery/images/census-population-map.png)\nhttps://cloud.google.com/bigquery/images/census-population-map.png'","b""['economics', 'bigquery', 'government', 'utility', 'medium', 'featured']""",https://www.kaggle.com/census/census-bureau-usa
b'Cooperative Patent Classification (CPC) Data',b'Scheme and definitions by CPC for classifying patent documents (BigQuery)',"b'### [Fork this notebook][3] to get started on accessing data in the BigQuery dataset by writing SQL queries using the BQhelper module.\n\n## Context\nThe CPC is the result of a partnership between the EPO and the USPTO in their joint effort to develop a common, internationally compatible classification system for technical documents, in particular patent publications, which will be used by both offices in the patent granting process.\n\n## Content\nCooperative Patent Classification Data contains the scheme and definitions of the Cooperative Patent Classification system for classifying patent documents.\n\n## Acknowledgments\n\xe2\x80\x9cCooperative Patent Classification\xe2\x80\x9d by the EPO and USPTO, for public use. Modifications have been made to parse the XML description sections to extract references to other classification symbols.\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:cpc\n\nBanner photo by [Helloquence][1] on [Unsplash][2]\n\n[1]: https://unsplash.com/photos/bI8df767i5o\n[2]: https://unsplash.com/\n[3]: https://www.kaggle.com/jessicali9530/how-to-query-cpc-data'","b""['bigquery', 'business', 'medium', 'featured']""",https://www.kaggle.com/bigquery/cpc
b'San Francisco Open Data',b'San Francisco Open Data (BigQuery Dataset)',"b'### Context\n\n DataSF seeks to transform the way that the City of San Francisco works -- through the use of data.  \n\nhttps://datasf.org/about/\n\n### Content\n\nThis dataset contains the following tables: \n[\'311_service_requests\',\n \'bikeshare_stations\',\n \'bikeshare_status\',\n \'bikeshare_trips\',\n \'film_locations\',\n \'sffd_service_calls\',\n \'sfpd_incidents\',\n \'street_trees\']\n\n - This data includes all San Francisco 311 service requests from July\n   2008 to the present, and is updated daily. 311 is a non-emergency\n   number that provides access to non-emergency municipal services.\n - This data includes fire unit responses to calls from April 2000 to present and is updated daily. Data contains the call number,\n   incident number, address, unit identifier, call type, and\n   disposition. Relevant time intervals are also included. Because this\n   dataset is based on responses, and most calls involved multiple fire\n   units, there are multiple records for each call number. Addresses are\n   associated with a block number, intersection or call box.\n - This data includes incidents from the San Francisco Police Department (SFPD) Crime Incident Reporting system, from January 2003\n   until the present (2 weeks ago from current date). The dataset is\n   updated daily. Please note: the SFPD has implemented a new system for\n   tracking crime. This dataset is still sourced from the old system,\n   which is in the process of being retired (a multi-year process).\n - This data includes a list of San Francisco Department of Public Works maintained street trees including: planting date, species, and\n   location. Data includes 1955 to present.\n\nThis dataset is deprecated and not being updated.\n\n\nFork [this kernel][1] to get started with this dataset.\n\n### Acknowledgements\n\nhttp://datasf.org/\n\n - https://cloud.google.com/bigquery/public-data/sfo-311\n - https://cloud.google.com/bigquery/public-data/sffd-service-calls\n - https://cloud.google.com/bigquery/public-data/sfpd-reports\n - https://cloud.google.com/bigquery/public-data/sfo-trees\n\nDataset Source: SF OpenData.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - http://sfgov.org/ - and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [@meric from Unplash][2].\n\n### Inspiration\n\nWhich neighborhoods have the highest proportion of offensive graffiti?\n\nWhich complaint is most likely to be made using Twitter and in which neighborhood?\n\nWhat are the most complained about Muni stops in San Francisco?\n\nWhat are the top 10 incident types that the San Francisco Fire Department responds to?\n\nHow many medical incidents and structure fires are there in each neighborhood?\n\nWhat\xe2\x80\x99s the average response time for each type of dispatched vehicle?\n\nWhich category of police incidents have historically been the most common in San Francisco?\n\nWhat were the most common police incidents in the category of LARCENY/THEFT in 2016?\n\nWhich non-criminal incidents saw the biggest reporting change from 2015 to 2016?\n\nWhat is the average tree diameter?\n\nWhat is the highest number of a particular species of tree planted in a single year?\n\nWhich San Francisco locations feature the largest number of trees?\n\n\n\n\n\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-sf-open-data\n  [2]: https://unsplash.com/photos/DtCEcY1k_qE\n\n\n\n\n\n'","b""['crime', 'government', 'road transport', 'public transport', 'public administration', 'large', 'featured']""",https://www.kaggle.com/datasf/san-francisco
b'Daily Global Historical Climatology Network ',b'Daily Global Historical Climatology Network (BigQuery Dataset)',"b'### Context\n\nWeather is the state of the atmosphere, describing for example the degree to which it is hot or cold, wet or dry, calm or stormy, clear or cloudy.  Source: https://en.wikipedia.org/wiki/Weather\n\n### Content\n\nNOAA\xe2\x80\x99s Global Historical Climatology Network (GHCN) is an integrated database of climate summaries from land surface stations across the globe that have been subjected to a common suite of quality assurance reviews. Two GHCN datasets are available in BigQuery, the GHCN-D (daily) and the GHCN-M (monthly). The data included in the GHCN datasets are obtained from more than 20 sources, including some data from every year since 1763.\n\nFor a complete description of data variables available in this dataset, see NOAA\xe2\x80\x99s readme.txt: https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt\n\nUpdate Frequency: daily\n\nFork [this kernel][1] to get started with this dataset.\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:ghcn_d\n\nhttps://cloud.google.com/bigquery/public-data/noaa-ghcn\n\nDataset Source: NOAA.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source \xe2\x80\x94 http://www.data.gov/privacy-policy#data_policy \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [Max LaRochelle from Unplash][2].\n\n\n### Inspiration\n\nFind weather stations close to a specific location?\n\nDaily rainfall amounts at specific station?\n\nPulling daily min/max temperature (in Celsius) and rainfall (in mm) for the past 14 days?\n\n\n\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-noaa-ghcnd-dataset\n  [2]: https://unsplash.com/photos/uu-Jw5SunYI\n\n\n'","b""['bigquery', 'weather', 'large', 'featured']""",https://www.kaggle.com/noaa/ghcn-d
b'Chicago Taxi Trips',b'Chicago Taxi Trips (BigQuery Dataset)',"b'### Context\n\nTaxicabs in Chicago, Illinois, are operated by private companies and licensed by the city. There are about seven thousand licensed cabs operating within the city limits. Licenses are obtained through the purchase or lease of a taxi medallion which is then affixed to the top right hood of the car.  Source: https://en.wikipedia.org/wiki/Taxicabs_of_the_United_States#Chicago\n\n\n### Content\n\nThis dataset includes taxi trips from 2013 to the present, reported to the City of Chicago in its role as a regulatory agency. To protect privacy but allow for aggregate analyses, the Taxi ID is consistent for any given taxi medallion number but does not show the number, Census Tracts are suppressed in some cases, and times are rounded to the nearest 15 minutes. Due to the data reporting process, not all trips are reported but the City believes that most are. See http://digital.cityofchicago.org/index.php/chicago-taxi-data-released for more information about this dataset and how it was created.\n\nFork [this kernel][1] to get started.\n\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:chicago_taxi_trips\n\nhttps://cloud.google.com/bigquery/public-data/chicago-taxi\n\nDataset Source: City of Chicago\n\nThis dataset is publicly available for anyone to use under the following terms provided by the Dataset Source \xe2\x80\x94https://data.cityofchicago.org \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [Ferdinand Stohr from Unplash][2].\n\n### Inspiration\n\nWhat are the maximum, minimum and average fares for rides lasting 10 minutes or more?\nWhich drop-off areas have the highest average tip?\nHow does trip duration affect fare rates for trips lasting less than 90 minutes?\n\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-chicago-taxi-dataset\n  [2]: https://unsplash.com/photos/EK8DxK_7IwY\n\n\n![](https://cloud.google.com/bigquery/images/chicago-taxi-fares-by-duration.png)\nhttps://cloud.google.com/bigquery/images/chicago-taxi-fares-by-duration.png\n'","b""['bigquery', 'transport', 'taxi services', 'large', 'featured']""",https://www.kaggle.com/chicago/chicago-taxi-trips-bq
b'Chicago Crime',b'Chicago Crime (BigQuery Dataset)',"b'### Context\n\nApproximately 10 people are shot on an average day in Chicago.\n\nhttp://www.chicagotribune.com/news/data/ct-shooting-victims-map-charts-htmlstory.html\nhttp://www.chicagotribune.com/news/local/breaking/ct-chicago-homicides-data-tracker-htmlstory.html\nhttp://www.chicagotribune.com/news/local/breaking/ct-homicide-victims-2017-htmlstory.html\n\n### Content\n\nThis dataset reflects reported incidents of crime (with the exception of murders where data exists for each victim) that occurred in the City of Chicago from 2001 to present, minus the most recent seven days. Data is extracted from the Chicago Police Department\'s CLEAR (Citizen Law Enforcement Analysis and Reporting) system. In order to protect the privacy of crime victims, addresses are shown at the block level only and specific locations are not identified. This data includes unverified reports supplied to the Police Department. The preliminary crime classifications may be changed at a later date based upon additional investigation and there is always the possibility of mechanical or human error. Therefore, the Chicago Police Department does not guarantee (either expressed or implied) the accuracy, completeness, timeliness, or correct sequencing of the information and the information should not be used for comparison purposes over time. \n\nUpdate Frequency: Daily\n\nFork [this kernel][1] to get started.\n\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:chicago_crime\n\nhttps://cloud.google.com/bigquery/public-data/chicago-crime-data\n\nDataset Source: City of Chicago\n\nThis dataset is publicly available for anyone to use under the following terms provided by the Dataset Source \xe2\x80\x94https://data.cityofchicago.org \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [Ferdinand Stohr from Unplash][2].\n\n### Inspiration\n\nWhat categories of crime exhibited the greatest year-over-year increase between 2015 and 2016?\n\nWhich month generally has the greatest number of motor vehicle thefts?\n\nHow does temperature affect the incident rate of violent crime (assault or battery)?\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-chicago-crime-dataset\n  [2]: https://unsplash.com/photos/EK8DxK_7IwY\n\n\n![](https://cloud.google.com/bigquery/images/chicago-scatter.png)\nhttps://cloud.google.com/bigquery/images/chicago-scatter.png'","b""['crime', 'bigquery', 'united states', 'violence', 'large', 'featured']""",https://www.kaggle.com/chicago/chicago-crime
b'World Bank: International Debt Data',b'World Bank: International Debt Data (BigQuery Dataset)',"b'### Context\n\nThe World Bank is an international financial institution that provides loans to countries of the world for capital projects. The World Bank\'s stated goal is the reduction of poverty.  Source: https://en.wikipedia.org/wiki/World_Bank\n\n### Content\n\nThis dataset contains both national and regional debt statistics captured by over 200 economic indicators. Time series data is available for those indicators from 1970 to 2015 for reporting countries.\n\nFor more information, see the [World Bank website][1].\n\nFork [this kernel][2] to get started with this dataset.\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:world_bank_intl_debt\n\nhttps://cloud.google.com/bigquery/public-data/world-bank-international-debt\n\nCitation: The World Bank: International Debt Statistics\n\nDataset Source: World Bank.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - http://www.data.gov/privacy-policy#data_policy - and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [@till_indeman from Unplash][3].\n\n### Inspiration\n \nWhat countries have the largest outstanding debt?\n\n![enter image description here][4]\nhttps://cloud.google.com/bigquery/images/outstanding-debt.png\n\n\n  [1]: http://data.worldbank.org/data-catalog/international-debt-statistics\n  [2]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-wbid-dataset\n  [3]: https://unsplash.com/photos/rKPiuXLq29A\n  [4]: https://cloud.google.com/bigquery/images/outstanding-debt.png'","b""['economics', 'healthcare', 'government', 'environment', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/theworldbank/world-bank-intl-debt
b'ChEMBL EBI Small Molecules Database',b'A large-scale bioactivity database for drug discovery (BigQuery)',"b'## Context\nChEMBL is maintained by the European Bioinformatics Institute (EBI), of the European Molecular Biology Laboratory (EMBL), based at the Wellcome Trust Genome Campus, Hinxton, UK.\n\n## Content\nChEMBL is a manually curated database of bioactive molecules with drug-like properties used in drug discovery, including information about existing patented drugs.\n\nSchema: http://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_23/chembl_23_schema.png\n\nDocumentation: http://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_23/schema_documentation.html\n\n[Fork this notebook][3] to get started on accessing data in the BigQuery dataset using the BQhelper package to write SQL queries.\n\n## Acknowledgements\n\xe2\x80\x9cChEMBL\xe2\x80\x9d by the European Bioinformatics Institute (EMBL-EBI), used under CC BY-SA 3.0. Modifications have been made to add normalized publication numbers.\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:ebi_chembl\n\nBanner photo by [rawpixel][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/JuKgTqhSS5M\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-google-patents-public-data'","b""['healthcare', 'bigquery', 'business', 'medicine', 'chemistry', 'large', 'featured']""",https://www.kaggle.com/bigquery/ebi-chembl
b'GitHub Repos',b'Code and comments from 2.8 million repos',"b""GitHub is how people build software and is home to the largest community of open source developers in the world, with over 12 million people contributing to 31 million projects on GitHub since 2008.\n\nThis 3TB+ dataset comprises the largest released source of GitHub activity to date. It contains a full snapshot of the content of more than 2.8 million open source GitHub repositories including more than 145 million unique commits, over 2 billion different file paths, and the contents of the latest revision for 163 million files, all of which are searchable with regular expressions. \n\n### Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.github_repos.[TABLENAME]`. **[Fork this kernel to get started][1]** to learn how to safely manage analyzing large BigQuery datasets.\n\n### Acknowledgements\nThis dataset was made available per [GitHub's terms of service](https://help.github.com/articles/github-terms-of-service/).\n\n### Inspiration\n- This is the perfect dataset for fighting language wars.\n- Can you identify any signals that predict which packages or languages will become popular, in advance of their mass adoption?\n\n\n  [1]: https://www.kaggle.com/mrisdal/safely-analyzing-github-projects-popular-licenses""","b""['bigquery', 'programming', 'programming languages', 'software engineering', 'large', 'featured']""",https://www.kaggle.com/github/github-repos
b'USPTO OCE Patent Assignment Dataset',b'Detailed data patent assignments since 1970 (BigQuery)',"b'### [Fork this notebook][3] to get started on accessing data in the BigQuery dataset by writing SQL queries using the BQhelper module.\n\n## Context\nThe Office of the Chief Economist (OCE) is responsible for advising the Under Secretary of Commerce for Intellectual Property and Director of the USPTO on the economic implications of policies and programs affecting the U.S. intellectual property (IP) system. The office disseminates detailed patent and trademark data, undertakes research, and conducts economic analysis on a variety of IP issues. OCE works with policy makers, collaborates with academics, and engages the public more generally through conferences it organizes, the publicly accessible research datasets it provides, and its publications.   \n\n## Content\nThe USPTO OCE Patent Assignment Dataset contains detailed data patent assignments and other transactions recorded at the USPTO since 1970.\n\n## Acknowledgements\n""USPTO OCE Patent Assignment Data"" by the USPTO, for public use.\nMarco, Alan C., Graham, Stuart J.H., Myers, Amanda F., D\'Agostino, Paul A and Apple, Kirsten, ""The USPTO Patent Assignment Dataset: Descriptions and Analysis"" (July 27, 2015).\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:uspto_oce_assignment\n\nBanner photo by [Jeff Sheldon][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/JWiMShWiF14\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-uspto-oce-patent-assignment-data'","b""['bigquery', 'law', 'large', 'featured']""",https://www.kaggle.com/bigquery/uspto-oce-assignment
b'120 years of Olympic history: athletes and results',b'basic bio data on athletes and medal results from Athens 1896 to Rio 2016',"b""### Context\n\nThis is a historical dataset on the modern Olympic Games, including all the Games from Athens 1896 to Rio 2016.  I scraped this data from www.sports-reference.com in May 2018. The R code I used to [scrape](https://github.com/rgriff23/Olympic_history/blob/master/R/olympics%20scrape.R) and [wrangle](https://github.com/rgriff23/Olympic_history/blob/master/R/olympics%20wrangle.R) the data is on GitHub. I recommend checking [my kernel](https://www.kaggle.com/heesoo37/olympic-history-data-a-thorough-analysis) before starting your own analysis. \n\nNote that the Winter and Summer Games were held in the same year up until 1992. After that, they staggered them such that Winter Games occur on a four year cycle starting with 1994, then Summer in 1996, then Winter in 1998, and so on. A common mistake people make when analyzing this data is to assume that the Summer and Winter Games have always been staggered. \n\n### Content\n\nThe file athlete_events.csv contains 271116 rows and 15 columns. Each row corresponds to an individual athlete competing in an individual Olympic event (athlete-events). The columns are:\n\n1. **ID** - Unique number for each athlete\n2. **Name** - Athlete's name\n3. **Sex** - M or F\n4. **Age** - Integer\n5. **Height** - In centimeters\n6. **Weight** - In kilograms\n7. **Team** - Team name\n8. **NOC** - National Olympic Committee 3-letter code\n9. **Games** - Year and season\n10. **Year** - Integer\n11. **Season** - Summer or Winter\n12. **City** - Host city\n13. **Sport** - Sport\n14. **Event** - Event\n15. **Medal** - Gold, Silver, Bronze, or NA\n\n\n### Acknowledgements\n\nThe Olympic data on www.sports-reference.com is the result of an incredible amount of research by a group of Olympic history enthusiasts and self-proclaimed 'statistorians'. Check out their [blog](http://olympstats.com/) for more information. All I did was consolidated their decades of work into a convenient format for data analysis. \n\n### Inspiration\n\nThis dataset provides an opportunity to ask questions about how the Olympics have evolved over time, including questions about the participation and performance of women, different nations, and different sports and events. ""","b""['sports', 'history', 'olympic games', 'small', 'featured']""",https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results
b'Hacker News',"b""All posts from Y Combinator's social news website from 2006 to late 2017""","b'### Context\n\nThis dataset contains all stories and comments from Hacker News from its launch in 2006.  Each story contains a story id, the author that made the post, when it was written, and the number of points the story received. Hacker News is a social news website focusing on computer science and entrepreneurship. It is run by Paul Graham\'s investment fund and startup incubator, Y Combinator. In general, content that can be submitted is defined as ""anything that gratifies one\'s intellectual curiosity"".\n\n### Content\n\nEach story contains a story ID, the author that made the post, when it was written, and the number of points the story received.\n\nPlease note that the text field includes profanity. All texts are the author\xe2\x80\x99s own, do not necessarily reflect the positions of Kaggle or Hacker News, and are presented without endorsement.\n\n## Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.hacker_news.[TABLENAME]`. **Fork [this kernel][1] to get started**.\n\n### Acknowledgements \n\nThis dataset was kindly made publicly available by [Hacker News][2] under [the MIT license][3].\n\n### Inspiration\n\n - Recent studies have found that many forums tend to be dominated by a\n   very small fraction of users. Is this true of Hacker News?\n\n - Hacker News has received complaints that the site is biased towards Y\n   Combinator startups. Do the data support this? \n\n - Is the amount of coverage by Hacker News predictive of a startup\xe2\x80\x99s\n   success?\n\n\n  [1]: https://www.kaggle.com/mrisdal/mentions-of-kaggle-on-hacker-news\n  [2]: https://github.com/HackerNews/API\n  [3]: https://github.com/HackerNews/API/blob/master/LICENSE'","b""['internet', 'bigquery', 'journalism', 'information technology', 'large', 'featured']""",https://www.kaggle.com/hacker-news/hacker-news
b'RxNorm Data',b'National Library of Medicine RxNorm Data (BigQuery Dataset)',"b'### Context\n\nRxNorm is a name of a US-specific terminology in medicine that contains all medications available on US market.  Source: https://en.wikipedia.org/wiki/RxNorm\n\nRxNorm provides normalized names for clinical drugs and links its names to many of the drug vocabularies commonly used in pharmacy management and drug interaction software, including those of First Databank, Micromedex, Gold Standard Drug Database, and Multum. By providing links between these vocabularies, RxNorm can mediate messages between systems not using the same software and vocabulary.  Source: https://www.nlm.nih.gov/research/umls/rxnorm/\n\n### Content\n\nRxNorm was created by the [U.S. National Library of Medicine (NLM)][1] to provide a normalized naming system for clinical drugs, defined as the combination of {ingredient + strength + dose form}. In addition to the naming system, the RxNorm dataset also provides structured information such as brand names, ingredients, drug classes, and so on, for each clinical drug. Typical uses of RxNorm include navigating between names and codes among different drug vocabularies and using information in RxNorm to assist with health information exchange/medication reconciliation, e-prescribing, drug analytics, formulary development, and other functions.\n\nThis public dataset includes multiple data files originally released in RxNorm Rich Release Format (RXNRRF) that are loaded into Bigquery tables. The data is updated and archived on a monthly basis.\n\nThe following tables are included in the RxNorm dataset:\n\n - RXNCONSO contains concept and source information\n   \n - RXNREL contains information regarding relationships between entities\n   \n - RXNSAT contains attribute information\n   \n - RXNSTY contains semantic information\n   \n - RXNSAB contains source info\n   \n - RXNCUI contains retired rxcui codes\n   \n - RXNATOMARCHIVE contains archived data\n   \n - RXNCUICHANGES contains concept changes\n\nUpdate Frequency: Monthly\n\nFork [this kernel][2] to get started with this dataset.\n\n### Acknowledgements\n\nhttps://www.nlm.nih.gov/research/umls/rxnorm/\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:nlm_rxnorm\n\nhttps://cloud.google.com/bigquery/public-data/rxnorm\n\nDataset Source: [Unified Medical Language System RxNorm][3]. The dataset is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset. This dataset uses publicly available data from the U.S. National Library of Medicine (NLM), National Institutes of Health, Department of Health and Human Services; NLM is not responsible for the dataset, does not endorse or recommend this or any other dataset.\n\nBanner Photo by [@freestocks from Unsplash][4].\n\n\n### Inspiration\n\nWhat are the RXCUI codes for the ingredients of a list of drugs?\n\nWhich ingredients have the most variety of dose forms?\n\nIn what dose forms is the drug phenylephrine found?\n\nWhat are the ingredients of the drug labeled with the generic code number 072718?\n\n\n\n  [1]: https://www.nlm.nih.gov/\n  [2]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-rxnorm-dataset\n  [3]: https://www.nlm.nih.gov/research/umls/rxnorm/\n  [4]: https://unsplash.com/photos/nss2eRzQwgw'","b""['healthcare', 'medicine', 'government', 'public health', 'large', 'featured']""",https://www.kaggle.com/nlm-nih/nlm-rxnorm
b'NPPES Plan and Provider Enumeration System',b'The CMS National Plan and Provider Enumeration System Data (BigQuery Dataset)',"b'### Context\n\nThe CMS National Plan and Provider Enumeration System ([NPPES][1])  was developed as part of the Administrative Simplification  provisions in the original HIPAA act. The primary purpose of NPPES was to develop a unique identifier for each physician that billed medicare and medicaid. This identifier is now known as the National Provider Identifier Standard ([NPI][2])  which is a required 10 digit number that is unique to an individual provider at the national level.\n\nOnce an NPI record is assigned to a healthcare provider, parts of the NPI record that have public relevance, including the provider\xe2\x80\x99s name, speciality, and practice address are published in a searchable website as well as downloadable file of zipped data containing all of the FOIA disclosable health care provider data in NPPES and a separate PDF file of code values which documents and lists the descriptions for all of the codes found in the data file.\n\n### Content\n\nThe dataset contains the latest NPI downloadable file in an easy to query BigQuery table, npi_raw. In addition, there is a second table, npi_optimized which harnesses the power of Big Query\xe2\x80\x99s next-generation columnar storage format  to provide an analytical view of the NPI data containing description fields for the codes based on the mappings in Data Dissemination Public File - Code Values  [documentation][3] as well as external lookups to the healthcare provider taxonomy [codes][4] . While this generates hundreds of columns, BigQuery makes it possible to process all this data effectively and have a convenient single lookup table for all provider information.\n\nFork [this kernel][5] to get started.\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:nppes?_ga=2.117120578.-577194880.1523455401\n\nhttps://console.cloud.google.com/marketplace/details/hhs/nppes?filter=category:science-research\n\nDataset Source: Center for Medicare and Medicaid Services.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - http://www.data.gov/privacy-policy#data_policy \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [@rawpixel from Unplash][6].\n\n### Inspiration\n\nWhat are the top ten most common types of physicians in Mountain View?\n\nWhat are the names and phone numbers of dentists in California who studied public health? \n\n\n  [1]: https://nppes.cms.hhs.gov/#/\n  [2]: https://www.cms.gov/Regulations-and-Guidance/Administrative-Simplification/NationalProvIdentStand/\n  [3]: https://drive.google.com/open?id=0ByNnBOdRY8TtMFJ1eW5kLV82WU0\n  [4]: http://www.nucc.org/index.php/code-sets-mainmenu-41/provider-taxonomy-mainmenu-40/csv-mainmenu-57\n  [5]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-nppes-dataset\n  [6]: https://unsplash.com/photos/w9YHKTK-wLo'","b""['healthcare', 'medicine', 'government', 'large', 'featured']""",https://www.kaggle.com/cms/nppes
"b'Ground State Energies of 16,242 Molecules'",b'Predict molecular properties from a database of atomic level simulations',"b'### Context\n\nThis dataset contains ground state energies of 16,242 molecules calculated by quantum mechanical simulations. \n\n### Content\n\nThe data contains 1277 columns. The first 1275 columns are entries in the Coulomb matrix that act as molecular features. The 1276th column is the [Pubchem][1] Id where the molecular structures are obtained. The 1277th column is the atomization energy calculated by simulations using the [Quantum Espresso][2] package.\n\nIn the csv file, the first column (X1) is the data index and unused. \n\n### Past Research\n\nThe data is used for a [publication][3] in Journal of Chemical Physics. A [blog post][4] was also published explaining the data and the research behind it in less technical terms. \n\nA [Github][5] repository is available that contains the source code used for generating the data, as well as some of the R scripts used for analysis. \n\n### Inspiration\n\nSimulations of molecular properties are computationally expensive. The purpose of this project is to use machine learning methods to come up with a model that can predict molecular properties from a database of simulations. If this can be done with high accuracy, properties of new molecules can be calculated using the trained model. This could open up many possibilities in computational design and discovery of molecules, compounds and new drugs. \n\nThe purpose is to use the 1275 molecular features to predict the atomization energy. This is a regression problem so mean squared error is minimized during training. \n\nI am looking for Kagglers to find the best model and reduce mean squared error as much as possible! \n\n\n  [1]: http://pubchem.ncbi.nlm.nih.gov/\n  [2]: http://www.quantum-espresso.org/\n  [3]: http://arxiv.org/abs/1609.07124\n  [4]: https://burakhimmetoglu.com/machine-learning-meets-quantum-mechanics/\n  [5]: https://github.com/bhimmetoglu/RoboBohr'","b""['physics', 'chemistry', 'medium', 'featured']""",https://www.kaggle.com/burakhmmtgl/energy-molecule
b'US Public Assistance for Women and Children',"b'Where does it come from, who spends it, who gets it.'","b""### Context\n\nThis dataset focuses on public assistance in the United States with initial coverage of the WIC Program. The program is formally known as the Special Supplemental Nutrition Program for Women, Infants, and Children (WIC). The program allocates Federal and State funds to help low-income women and children up to age five who are at nutritional risk. Funds are used to provide supplemental foods, baby formula, health care, and nutrition education.\n\n### Content\n\nFiles may include participation data and spending for state WIC programs, and poverty data for each state.  Data is for fiscal years 2013-2016, which is actually October 2012 through September 2016.\n\n### Motivation\nMy original purpose here is two-fold:\n\n - Explore various  aspects of US Public Assistance. Show trends over recent years and better understand differences across state agencies.  Although the federal government sponsors the program and provides funding, program are administered at the state level and can widely vary. Indian nations (native Americans) also administer their own programs.\n\n - Share with the Kaggle Community the joy - and pain -  of working with government data. Data is often spread across numerous agency sites and comes in a variety of formats. Often the data is provided in Excel, with the files consisting of multiple tabs. Also, files are formatted as reports and contain aggregated data (sums, averages, etc.) along with base data.\n\n### Additional Content Ideas\nThe dataset can benefit greatly from additional content. Economics, additional demographics, administrative costs and more. I'd like to eventually explore the money trail from taxes and corporate subsidies, through the government agencies, and on to program participants. All community ideas are welcome!\n""","b""['small', 'featured']""",https://www.kaggle.com/jpmiller/publicassistance
b'USPTO OCE Patent Claims Research Data',b'US patents granted claims and published applications (BigQuery)',"b'### [Fork this notebook][3] to get started on accessing data in the BigQuery dataset by writing SQL queries using the BQhelper module.\n\n## Context\nThe Patent Claims Research Dataset contain detailed information on claims from U.S. patents granted between 1976 and 2014 and U.S. patent applications published between 2001 and 2014. The dataset is derived from the Patent Application Publication Full-Text and Patent Grant Full Text files, available at https://bulkdata.uspto.gov/, to which the Office of Chief Economist (OCE) applied a Python algorithm to identify individual claims as well as the dependency relationship between claims. From the parsed claims text, OCE created six data files containing individually-parsed claims, claim-level statistics, and document-level statistics, including newly-developed measures of patent scope.\n\n## Content\nUSPTO OCE Patent Claims Research data contains detailed information on claims from U.S. patents granted between 1976 and 2014 and U.S. patent applications published between 2001 and 2014.\n\n## Acknowledgements\n""USPTO OCE Patent Claims Research Data"" by the USPTO, for public use.\nMarco, Alan C. and Sarnoff, Joshua D. and deGrazia, Charles, ""Patent Claims and Patent Scope"" (October 2016). USPTO Economic Working Paper 2016-04.\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:uspto_oce_claims\n\nBanner photo by [William Iven][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/gcsNOsPEXfs\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-uspto-oce-patent-claims-research-data'","b""['bigquery', 'law', 'research', 'large', 'featured']""",https://www.kaggle.com/bigquery/uspto-oce-claims
b'IDA Statement of Credits and Grants Data',b'From World Bank Financial Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](finances.worldbank.org) and they update their information according the amount of data that is brought in. Explore World Bank's Financial Data using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.\n\nThis dataset is distributed under a [Creative Commons Attribution 3.0 IGO](https://creativecommons.org/licenses/by/3.0/igo/) license.  \n\n[Cover photo](https://unsplash.com/photos/ap8bW3b5CVU) by [Jack B](https://unsplash.com/@nervum) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Creative Commons Attribution 3.0 IGO""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/theworldbank/ida-statement-of-credits-and-grants-data
b'New York City Current Job Postings',b'From New York City Open Data',"b""### Content  \n\nThis dataset contains current job postings available on the  City of New York\xe2\x80\x99s official jobs site (http://www.nyc.gov/html/careers/html/search/search.shtml).  Internal postings available to city employees and external postings available to the general public are included.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Qn9aYTT_CL4) by [Quino Al](https://unsplash.com/@quinoal) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'employment', 'small', 'featured']""",https://www.kaggle.com/new-york-city/new-york-city-current-job-postings
b'USPTO Patent Examination Research Data (PatEx)',b'Millions of publicly viewable patent applications filed with USPTO (BigQuery)',"b'### [Fork this notebook][3] to get started on accessing data in the BigQuery dataset by writing SQL queries using the BQhelper module.\n\n## Context\nThe original release of the Patent Examination Research Dataset (PatEx) contains detailed information on 9.2 million publicly viewable patent applications filed with the USPTO through December 2014. Currently, two updates of the dataset are available as well, the most recent posted in November 2017 (and referred to as the 2016 release). This latest release covers all activity through 2016, but also includes activity through late June of 2017.  It is called the 2016 release because 2016 is the latest year for which PatEx provides information on all activities. There are several data files, each of which coincides with a tab on USPTO\xe2\x80\x99s Public PAIR web portal. The data files include information on each application\xe2\x80\x99s characteristics, prosecution history, continuation history, claims of foreign priority, patent term adjustment history, publication history, and correspondence address information. \n\n## Content\nUSPTO Patent Examination Research Data (PatEx) contains detailed information on millions of publicly viewable patent applications filed with the USPTO. The data are sourced from the Public Patent Application Information Retrieval system (Public PAIR).\n\n## Acknowledgements\n\xe2\x80\x9cUSPTO Patent Examination Research Dataset\xe2\x80\x9d by the USPTO, for public use.\nGraham, S. Marco, A., and Miller, A. (2015). \xe2\x80\x9cThe USPTO Patent Examination Research Dataset: A Window on the Process of Patent Examination.\xe2\x80\x9d\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:uspto_oce_pair\n\nBanner photo by [Samuel Zeller][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/JuFcQxgCXwA\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-uspto-patex-data'","b""['bigquery', 'law', 'research', 'large', 'featured']""",https://www.kaggle.com/bigquery/uspto-oce-pair
b'FiveThirtyEight Drug Use By Age Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Drug Use By Age\n\nThis directory contains data behind the story [How Baby Boomers Get High](http://fivethirtyeight.com/datalab/how-baby-boomers-get-high/). It covers 13 drugs across 17 age groups.\n\nSource: [National Survey on Drug Use and Health from the Substance Abuse and Mental Health Data Archive](http://www.icpsr.umich.edu/icpsrweb/content/SAMHDA/index.html).\n\nHeader | Definition\n---|---------\n`alcohol-use` | Percentage of those in an age group who used alcohol in the past 12 months\n`alcohol-frequency` | Median number of times a user in an age group used alcohol in the past 12 months\n`marijuana-use` | Percentage of those in an age group who used marijuana in the past 12 months\n`marijuana-frequency` | Median number of times a user in an age group used marijuana in the past 12 months\n`cocaine-use` | Percentage of those in an age group who used cocaine in the past 12 months\n`cocaine-frequency` | Median number of times a user in an age group used cocaine in the past 12 months\n`crack-use` | Percentage of those in an age group who used crack in the past 12 months\n`crack-frequency` | Median number of times a user in an age group used crack in the past 12 months\n`heroin-use` | Percentage of those in an age group who used heroin in the past 12 months\n`heroin-frequency` | Median number of times a user in an age group used heroin in the past 12 months\n`hallucinogen-use` | Percentage of those in an age group who used hallucinogens in the past 12 months\n`hallucinogen-frequency` | Median number of times a user in an age group used hallucinogens in the past 12 months\n`inhalant-use` | Percentage of those in an age group who used inhalants in the past 12 months\n`inhalant-frequency` | Median number of times a user in an age group used inhalants in the past 12 months\n`pain-releiver-use` | Percentage of those in an age group who used pain relievers in the past 12 months\n`pain-releiver-frequency` | Median number of times a user in an age group used pain relievers in the past 12 months\n`oxycontin-use` | Percentage of those in an age group who used oxycontin in the past 12 months\n`oxycontin-frequency` | Median number of times a user in an age group used oxycontin in the past 12 months\n`tranquilizer-use` | Percentage of those in an age group who used tranquilizer in the past 12 months\n`tranquilizer-frequency` | Median number of times a user in an age group used tranquilizer in the past 12 months\n`stimulant-use` | Percentage of those in an age group who used stimulants in the past 12 months\n`stimulant-frequency` | Median number of times a user in an age group used stimulants in the past 12 months\n`meth-use` | Percentage of those in an age group who used meth in the past 12 months\n`meth-frequency` | Median number of times a user in an age group used meth in the past 12 months\n`sedative-use` | Percentage of those in an age group who used sedatives in the past 12 months\n`sedative-frequency` | Median number of times a user in an age group used sedatives in the past 12 months\n  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.  \n\n[Cover photo](https://unsplash.com/photos/PnvFVVkS9vU) by [Eric Muhr](https://unsplash.com/@ericmuhr) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-drug-use-by-age-dataset
b'Chrome User Experience Report (USA Only)',b'Chrome User Experience Report (BigQuery - USA Only)',"b'#Context\n\nGoogle Chrome is a popular web browser developed by Google.\n\n#Content\n\nThe Chrome User Experience Report is a public dataset of key user experience metrics for popular origins on the web, as experienced by Chrome users under real-world conditions.\n\n#Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/chrome-ux-report:all\n\nFor more info, see the documentation at https://developers.google.com/web/tools/chrome-user-experience-report/\n\nLicense: [CC BY 4.0][3]\n\nPhoto by [Edho Pratama][1] on [Unsplash][2]\n\n\n  [1]: https://unsplash.com/photos/yeB9jDmHm6M?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\n  [2]: https://unsplash.com/search/photos/website?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\n  [3]: https://creativecommons.org/licenses/by/4.0/'","b""['internet', 'human-computer interaction', 'web sites', 'large', 'featured']""",https://www.kaggle.com/bigquery/chrome-ux-report-country-us
b'NOAA Precipitation 15 Minute',b'From NOAA Updated Data',"b'* Update Frequency: Daily\n\nData from this dataset can be downloaded/accessed through this dataset page and Kaggle\'s [API](https://github.com/Kaggle/kaggle-api).\n\n### Context\n\nU.S. 15 Minute Precipitation Data is digital data set DSI-3260, archived at the National Climatic Data Center (NCDC). This is precipitation data. The primary source of data for this file is approximately 2,000 mostly U.S. weather stations operated or managed by the U.S. National Weather Service. Stations are primary, secondary, or cooperative observer sites that have the capability to measure precipitation at 15 minute intervals.\n\nNCDC has in archive data from most states as far back as 1970 or 1971, and continuing to the present day. The major parameter is precipitation amounts at 15 minute intervals, when precipitation actually occurs.\n\n### Content\n\nThis dataset contains 15-minute precipitation data (reported 4 times per hour, if precip occurs) for U.S. stations along with selected non-U.S. stations in U.S. territories and associated nations. It includes major city locations and many small town locations. Daily total precipitation is also included as part of the data record.\n\n### Acknowledgements\n\nDataset Source: NOAA.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source \xe2\x80\x94 http://www.data.gov/privacy-policy#data_policy \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\n[Cover photo](https://unsplash.com/photos/dAWj5Bdo6jo) by [Ricky Rew](https://unsplash.com/@rickyrew) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['weather', 'climate', 'utility', 'medium', 'featured']""",https://www.kaggle.com/noaa/noaa-precipitation-15-minute
b'walk or run',b'Can you infer if the image is walking or running?',"b'### Context\n\nI am a deep learning learner, and I had did some fine tuning work based on some well known datasets, such as Stanford Dogs, etc. \n\nBut can deep learning learn if a people is running or walking? So i create a tool to crawl some images from google image, by search key words - ""walk"", ""run"", ""walk outside"", ""run outside"" etc. Then i pick the images and compress them and upload to kaggle datasets.\n\n### Content\n\nThis dataset is about the people walk or run, you can fine tuning based on classic pre-trained network, such as Inception, ResNet, DenseNet.\n\n### Acknowledgements\n\nGoogle Images, ImageNet pre-trained, e.g. Resnet50, DenseNet, etc.\n\nUse https://datalet.cn to build this dataset.\n\n\n### Inspiration\n\nI am looking forward your kernels.'","b""['internet', 'medium', 'featured']""",https://www.kaggle.com/huan9huan/walk-or-run
b'Open Images',"b'9 million URLs with labels and more than 6,000 categories (BigQuery)'","b'### Context\n\nLabeled datasets are useful in machine learning research.\n\n### Content\n\nThis public dataset contains approximately 9 million URLs and metadata for images that have been annotated with labels spanning more than 6,000 categories.  \n\nTables:\n1) annotations_bbox\n2) dict\n3) images\n4) labels\n\nUpdate Frequency: Quarterly\n\n\n### Querying BigQuery Tables\n\n**[Fork this kernel to get started][3]**.\n\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:open_images\n\nhttps://cloud.google.com/bigquery/public-data/openimages\n\nAPA-style citation: Google Research (2016). The Open Images dataset [Image urls and labels]. Available from github: https://github.com/openimages/dataset.\n\nUse: The annotations are licensed by Google Inc. under CC BY 4.0 license.\n\nThe images referenced in the dataset are listed as having a CC BY 2.0 license. Note: while we tried to identify images that are licensed under a Creative Commons Attribution license, we make no representations or warranties regarding the license status of each image and you should verify the license for each image yourself.\n\nBanner Photo by [Mattias Diesel][1] from [Unsplash][2]. \n\n\n\n### Inspiration\n\nWhich labels are in the dataset?\nWhich labels have ""bus"" in their display names?\nHow many images of a trolleybus are in the dataset?\nWhat are some landing pages of images with a trolleybus?\nWhich images with cherries are in the training set?\n\n  [1]: https://unsplash.com/@mattiasdiesel\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-open-images-dataset\n\n'","b""['image data', 'bigquery', 'large', 'featured']""",https://www.kaggle.com/bigquery/open-images
b'London Crime Data',b'Reported crime in London by borough and LSOA (BigQuery Dataset)',"b'### Context\n\nLondon is the capital and most populous city of England and the United Kingdom.  Standing on the River Thames in the south east of the island of Great Britain, London has been a major settlement for two millennia.  Source: https://en.wikipedia.org/wiki/London\n\n### Content\n\nThis data counts the number of crimes at two different geographic levels of London (LSOA and borough) by year, according to crime type. Includes data from 2008 to present. Crime categories are included in the BigQuery table description.\n\nFork [this kernel][1] to get started with this dataset.\n\n### Acknowledgements\n\nhttps://data.london.gov.uk/\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:london_crime?_ga=2.189454959.-577194880.1523455401\n\nhttps://console.cloud.google.com/marketplace/details/greater-london-authority/london-crime?filter=category:public-safety\n\nThis dataset is publicly available for anyone to use under the following terms provided by the Dataset Source \xe2\x80\x94 http://www.data.gov/privacy-policy#data_policy  \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [Luca Micheli from Unplash][2].\n\n\n### Inspiration\n\nWhat is the change in the number of crime incidents from 2011 to 2016?\n\nWhat were the top 3 crimes per borough in 2016?\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-london-crime-dataset\n  [2]: https://unsplash.com/photos/oyUXVzq-7Po\n\n\n\n'","b""['crime', 'europe', 'utility', 'violence', 'large', 'featured']""",https://www.kaggle.com/LondonDataStore/london-crime
b'Libraries.io Data',b'Dependency and usage metadata from 25m open source projects (BigQuery Dataset)',"b'### Context\n\nIn this release you will find data about software distributed and/or crafted publicly on the Internet.&nbsp; You will find information about its development, its distribution and its relationship with other software included as a dependency.  You will not find any information about the individuals who create and maintain these projects.\n\n\n### Content\n\nLibraries.io gathers data on open source software from 33 package managers and 3 source code repositories.\nWe track over 2.4m unique open source projects, 25m repositories and 121m interdependencies between them.\nThis gives Libraries.io a unique understanding of open source software.\n\nhttps://libraries.io/data\n\nFork [this kernel][1] to get started with this dataset.\n\n### Acknowledgements\n\nThis dataset is publicly available for anyone to use under the following terms provided by the Dataset Source \xe2\x80\x94 https://libraries.io/data   \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nhttps://libraries.io/data\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:libraries_io?_ga=2.42277601.-577194880.1523455401\n\nhttps://console.cloud.google.com/marketplace/details/libraries-io/librariesio\n\nBanner Photo by [Caspar Rubin from Unplash][2].\n\n\n### Inspiration\n\nWhat are the repositories, avg project size, and avg # of stars? \n\nWhat are the top dependencies per platform?\n\nWhat are the top unmaintained or deprecated projects? \n\n\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-libraries-io-data\n  [2]: https://unsplash.com/photos/fPkvU7RDmCo\n\n'","b""['libraries', 'digital media', 'large', 'featured']""",https://www.kaggle.com/librariesdotio/libraries-io
b'CMS OPPS Provider Summary (2011-2015)',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain, NA""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/cms-opps-provider-summary-2011-2015
b'Fruits 360 dataset',b'A dataset with 81 fruits and 55244 images',"b'## Fruits 360 dataset: A dataset of images containing fruits\n\n## Version: 2018.09.07.0\n\n### Content\n\nThe following fruits are included: \nApples (different varieties: Golden, Golden-Red, Granny Smith, Red, Red Delicious), Apricot, Avocado, Avocado ripe, Banana (Yellow, Red), Cactus fruit, Cantaloupe (2 varieties), Carambula, Cherry (different varieties, Rainier), Cherry Wax (Yellow, Red, Black), Clementine, Cocos, Dates, Granadilla, Grape (Pink, White, White2), Grapefruit (Pink, White), Guava, Huckleberry, Kiwi, Kaki, Kumsquats, Lemon (normal, Meyer), Lime, Lychee, Mandarine, Mango, Maracuja, Melon Piel de Sapo, Mulberry, Nectarine, Orange, Papaya, Passion fruit, Peach, Pepino, Pear (different varieties, Abate, Monster, Williams), Physalis (normal, with Husk), Pineapple (normal, Mini), Pitahaya Red, Plum, Pomegranate, Quince, Rambutan, Raspberry, Salak, Strawberry (normal, Wedge), Tamarillo, Tangelo, Tomato (different varieties, Maroon, Cherry Red), Walnut.\n\n### Dataset properties ###\n\nTotal number of images: 55244.\n\nTraining set size: 41322 images (one fruit per image).\n\nTest set size: 13877 images (one fruit per image).\n\nMulti-fruits set size: 45 images (more than one fruit (or fruit class) per image)\n\nNumber of classes: 81 (fruits).\n\nImage size: 100x100 pixels.\n\nFilename format: image_index_100.jpg (e.g. 32_100.jpg) or r_image_index_100.jpg (e.g. r_32_100.jpg) or r2_image_index_100.jpg. ""r"" stands for rotated fruit. ""r2"" means that the fruit was rotated around the 3rd axis. ""100"" comes from image size (100x100 pixels).\n\nDifferent varieties of the same fruit (apple for instance) are stored as belonging to different classes.\n\n### How we made it\n\nFruits were planted in the shaft of a low speed motor (3 rpm) and a short movie of 20 seconds was recorded. \n\nA Logitech C920 camera was used for filming the fruits. This is one of the best webcams available.\n\nBehind the fruits we placed a white sheet of paper as background. \n\nHowever due to the variations in the lighting conditions, the background was not uniform and we wrote a dedicated algorithm which extract the fruit from the background. This algorithm is of flood fill type:  we start from each edge of the image and we mark all pixels there, then we mark all pixels found in the neighborhood of the already marked pixels for which the distance between colors is less than a prescribed value. We repeat the previous step until no more pixels can be marked.\n\nAll marked pixels are considered as being background (which is then filled with white) and the rest of pixels are considered as belonging to the object.\n\nThe maximum value for the distance between 2 neighbor pixels is a parameter of the algorithm and is set (by trial and error) for each movie.\n\n### Published research papers\n\nHorea Muresan, [Mihai Oltean](https://mihaioltean.github.io), [Fruit recognition from images using deep learning](https://www.researchgate.net/publication/321475443_Fruit_recognition_from_images_using_deep_learning), Acta Univ. Sapientiae, Informatica Vol. 10, Issue 1, pp. 26-42, 2018.\n\nThe paper introduces the dataset and an implementation of a Neural Network trained to recognized the fruits in the dataset.\n\n### Alternate download\n\nThis dataset is also available for download from GitHub: [Fruits-360 dataset](https://github.com/Horea94/Fruit-Images-Dataset)\n\n### History ###\n\nFruits were filmed at the dates given below (YYYY.MM.DD):\n\n2017.02.25 - Apple (golden).\n\n2017.02.28 - Apple (red-yellow, red, golden2), Kiwi, Pear, Grapefruit, Lemon, Orange, Strawberry, Banana.\n\n2017.03.05 - Apple (golden3, Braeburn, Granny Smith, red2).\n\n2017.03.07 - Apple (red3).\n\n2017.05.10 - Plum, Peach, Peach flat, Apricot, Nectarine, Pomegranate.\n\n2017.05.27 - Avocado, Papaya, Grape, Cherrie.\n\n2017.12.25 - Carambula, Cactus fruit, Granadilla, Kaki, Kumsquats, Passion fruit, Avocado ripe, Quince.\n\n2017.12.28 - Clementine, Cocos, Mango, Lime, Lychee.\n\n2017.12.31 - Apple Red Delicious, Pear Monster, Grape White.\n\n2018.01.14 - Ananas, Grapefruit Pink, Mandarine, Pineapple, Tangelo.\n\n2018.01.19 - Huckleberry, Raspberry.\n\n2018.01.26 - Dates, Maracuja, Salak, Tamarillo.\n\n2018.02.05 - Guava, Grape White 2, Lemon Meyer\n\n2018.02.07 - Banana Red, Pepino, Pitahaya Red.\n\n2018.02.08 - Pear Abate, Pear Williams.\n\n2018.05.22 - Lemon rotated, Pomegranate rotated.\n\n2018.05.24 - Cherry Rainier, Cherry 2, Strawberry Wedge.\n\n2018.05.26 - Cantaloupe (2 varieties).\n\n2018.05.31 - Melon Piel de Sapo.\n\n2018.06.05 - Pineapple Mini, Physalis, Physalis with Husk, Rambutan.\n\n2018.06.08 - Mulberry.\n\n2018.06.16 - Walnut, Tomato Cherry Red.\n\n2018.06.17 - Cherry Wax (Yellow, Red, Black).\n\n2018.08.19 - Tomato Maroon, Tomato 1-4.\n\n## License ##\n\nMIT License\n\nCopyright (c) 2017-2018 [Mihai Oltean](https://mihaioltean.github.io), Horea Muresan\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.'","b""['food and drink', 'image data', 'multiclass classification', 'medium', 'featured']""",https://www.kaggle.com/moltean/fruits
b'USPTO Patent Examiner Data System (PEDS) Data',b'Data from the examination process of USPTO patent applications (BigQuery)',"b'### [Fork this notebook][3] to get started on accessing data in the BigQuery dataset by writing SQL queries using the BQhelper module.\n\n## Context\nPatent Examination Data System gives users access to multiple records of USPTO patent application or patent filing status at no cost. PEDS is updated daily and mirrors the data available in the Patent Application Location and Monitoring system (PALM). PEDS provides access to public applications including: published patent applications and patents. PCT applications that have not been published by WIPO. Any applications that have not been released by the USPTO will not be available in PEDS.\n\n## Content\nUSPTO Patent Examiner Data System (PEDS) API Data contains data from the examination process of USPTO patent applications. PEDS contains the bibliographic, published document and patent term extension data tabs in Public PAIR from 1981 to present. There is also some data dating back to 1935.\n\n[Fork this notebook][3] to get started on accessing data in the BigQuery dataset using the BQhelper package to write SQL queries.\n\n## Acknowledgements\n""Patent Examination Data System"" by the USPTO, for public use.\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:uspto_peds\n\nBanner photo by [Thought Catalog][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/505eectW54k\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-uspto-peds-data'","b""['bigquery', 'law', 'research', 'large', 'featured']""",https://www.kaggle.com/bigquery/uspto-peds
b'Honey Bee pollen',b'High resolution images of individual bees on the ramp',"b'# PollenDataset\n\n(C) 2017 Ivan Rodriguez, R\xc3\xa9mi M\xc3\xa9gret, Edgar Acu\xc3\xb1a, Jos\xc3\xa9 Agosto, Tugrul Giray\n\nThis image dataset has been created from videos captured at the entrance of a bee colony in June 2017 at the Bee facility of the Gurabo Agricultural Experimental Station of the University of Puerto Rico.\n\n## Repository content\n\n- `images/` contains images for pollen bearing and no pollen bearing honey bees.\n    - The prefix of the images names define their class: e.g. `NP1268-15r.jpg` for non-pollen and `P7797-103r.jpg` for pollen bearing bees. The numbers correspond to frame and item number respectively, you need to be careful that they are not numbered sequentially. \n  \n- `Read-skimage.ipynb` Jupyter notebook for simple script to load the data and create the dataset using `skimage` library. \n\n## Acknowledgement\n\n_This dataset is based upon work supported by the National Science Foundation\nunder Grant No. 1707355 and 1633184._\n\nIf you publish work based on this dataset, please cite the following  publication:\n\n* Ivan Rodriguez, R\xc3\xa9mi M\xc3\xa9gret, Edgar Acu\xc3\xb1a, Jos\xc3\xa9 Agosto, Tugrul Giray. _Recognition of pollen-bearing bees from Video using Convolutional Neural Network_, IEEE Winter Conf. on Applications of Computer Vision, 2018, Lake Tahoe, NV. https://doi.org/10.1109/WACV.2018.00041\n\nThanks to UPR students Grace Rodriguez, Christian Esteves and Emmanuel Nieves for their help in the video annotations. Thanks to UPR students Stephanie Feliciano and Janpierre Aleman for their help in the development of the camera system.\n\n# License\n\nThis dataset is shared on Kaggle under licenses CC-BY 4.0 and ODC-ODbL 1.0 '","b""['classification', 'image data', 'image processing', 'animals', 'ecology', 'small', 'featured']""",https://www.kaggle.com/ivanfel/honey-bee-pollen
b'CMS Value Modifier Performance Years 2013-2015',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/-gjHizUfFlM) by [Tim Gouw](https://unsplash.com/@punttim) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: NA""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/cms-value-modifier-performance-years-2013-2015
b'Four Shapes',"b'16,000 images of four basic shapes (star, circle, square, triangle)'","b'This dataset contains 16,000 images of four shapes; square, star, circle, and triangle. Each image is 200x200 pixels.\n\nThe data was collected using a Garmin Virb 1080p action camera. The shapes were cut from poster board, and then painted green. I held each shape in view of the camera for two minutes. While the camera was recording the shape, I moved the shape around and rotated it.\n\nThe four videos were then processed using OpenCV in Python. Using colorspaces, the green shape is cropped out of the image and resized to 200x200 pixels. The data is arranged into four folders; square, circle, triangle, and star. The images are labeled 0.png, 1.png, etc...\n\n![classifying shapes][1]\n\nA fifth video was taken with all of the shapes in the frame. This fifth video is for testing purposes. The goal is to classify the shapes in the test video using a model created with the training data. [These classifications were made using a model made in Keras.][2]\n\nHow is this different than the MINST handwritten digits dataset? There are 10 classes in the MINST dataset and 4 in this shapes dataset. The images in this data set are rotated, and the digits in the MINST data set are not.\n\n\n  [1]: https://i.imgur.com/jDFXe0z.png\n  [2]: https://youtu.be/hfjqVD2hwqY'","b""['beginner', 'image data', 'multiclass classification', 'medium', 'featured']""",https://www.kaggle.com/smeschke/four-shapes
b'NYC Open Data',b'NYC Open Data (BigQuery Dataset)',"b'### Context\n\nNYC Open Data is an opportunity to engage New Yorkers in the information that is produced and used by City government. We believe that every New Yorker can benefit from Open Data, and Open Data can benefit from every New Yorker.  Source: https://opendata.cityofnewyork.us/overview/\n\n\n### Content\n\nThanks to NYC Open Data, which makes public data generated by city agencies available for public use, and Citi Bike, we\'ve incorporated over 150 GB of data in 5 open datasets into Google BigQuery Public Datasets, including:\n\n - Over 8 million 311 service requests from 2012-2016\n   \n - More than 1 million motor vehicle collisions 2012-present\n   \n - Citi Bike stations and 30 million Citi Bike trips 2013-present \n   \n - Over 1 billion Yellow and Green Taxi rides from 2009-present \n   \n - Over 500,000 sidewalk trees surveyed decennially in 1995, 2005, and\n   2015\n\nThis dataset is deprecated and not being updated.\n\nFork [this kernel][1] to get started with this dataset.\n\n### Acknowledgements\n\nhttps://opendata.cityofnewyork.us/\n\nhttps://cloud.google.com/blog/big-data/2017/01/new-york-city-public-datasets-now-available-on-google-bigquery\n\nThis dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - https://data.cityofnewyork.us/ - and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBy accessing datasets and feeds available through NYC Open Data, the user agrees to all of the Terms of Use of NYC.gov as well as the Privacy Policy for NYC.gov. The user also agrees to any additional terms of use defined by the agencies, bureaus, and offices providing data. Public data sets made available on NYC Open Data are provided for informational purposes. The City does not warranty the completeness, accuracy, content, or fitness for any particular purpose or use of any public data set made available on NYC Open Data, nor are any such warranties to be implied or inferred with respect to the public data sets furnished therein.\n\nThe City is not liable for any deficiencies in the completeness, accuracy, content, or fitness for any particular purpose or use of any public data set, or application utilizing such data set, provided by any third party.\n\nBanner Photo by [@bicadmedia from Unplash][2].\n\n\n### Inspiration\n\nOn which New York City streets are you most likely to find a loud party?\n\nCan you find the Virginia Pines in New York City?\n\nWhere was the only collision caused by an animal that injured a cyclist?\n\nWhat\xe2\x80\x99s the Citi Bike record for the Longest Distance in the Shortest Time (on a route with at least 100 rides)?\n\n![enter image description here][3]\nhttps://cloud.google.com/blog/big-data/2017/01/images/148467900588042/nyc-dataset-6.png\n\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-nyc-open-data\n  [2]: https://unsplash.com/photos/UnI8AGe1634\n  [3]: https://cloud.google.com/blog/big-data/2017/01/images/148467900588042/nyc-dataset-6.png'","b""['government', 'utility', 'road transport', 'public transport', 'public administration', 'large', 'featured']""",https://www.kaggle.com/nycopendata/new-york
b'Crowds Cure Cancer 2017',b'Using Crowd Sourcing to Find Tumors',"b""### Context\n(from the original page)\nMany Cancers routinely identified by imaging haven\xe2\x80\x99t yet benefited from recent advances in computer science. Approaches such as machine learning and deep learning can generate quantitative tumor 3D volumes, complex features and therapy-tracking temporal dynamics. However, cross-disciplinary researchers striving to develop new approaches often lack disease understanding or sufficient contacts within the medical community. Their research can greatly benefit from labeling and annotating basic information in the images such as tumor locations, which are obvious to radiologists.\n\nCrowd-sourcing the creation of publicly-accessible reference data sets could address this challenge. In 2011 the National Cancer Institute funded development of The Cancer Imaging Archive (TCIA), a free and open-access database of medical images. However, most of these collections lack the labeling and annotations needed by image processing researchers for progress in deep learning and radiomics. As a result, TCIA has partnered with the Radiological Society of North America (RSNA) and numerous academic centers to harness the vast knowledge of RSNA meeting attendees to generate these tumor markups.\n\n### Content\n\nThe csv file contains a list of all annotations on the images organized by author, disease type, location and patient\nThere are two subfolders\n\n 1. annotated_dicoms: contains all of the DICOM slices referenced in the\n    CSV file (but nothing else, no above / below and no full patient\n    context) \n 2. compressed_stacks: the nifti (.nii.gz) stacks of the entire\n    scans corresponding to around 70% (file size limit of Kaggle) of the\n    data. The nifti files are much more useful for testing models since\n    you won't know the slices to look for apriori.\n\n### Acknowledgements\nThe original dataset was downloaded from https://wiki.cancerimagingarchive.net/plugins/servlet/mobile?contentId=33948774#content/view/33948774\nThe citation for the data should be used as below:\n```\nJayashree Kalpathy-Cramer, Andrew Beers, Artem Mamonov, Erik Ziegler, Rob Lewis, Andre Botelho Almeida, Gordon Harris, Steve Pieper, Ashish Sharma, Lawrence Tarbox, Jeff Tobler, Fred Prior, Adam Flanders, Jamie Dulkowski, Brenda Fevrier-Sullivan, Carl Jaffe, John Freymann, Justin Kirby. Crowds Cure Cancer: Data collected at the RSNA 2017 annual meeting. The Cancer Imaging Archive. doi: 10.7937/K9/TCIA.2018.OW73VLO2\n```\n\n### Inspiration\n\nThe work was done by volunteer, unpaid radiologists and non-radiologists, which makes it a very unreliable dataset. Even in the example image it is clear the definition of a tumor and where its boundaries are varies from person to person.\n\nThe biggest question is how do you perform quality control? \n\nHow can you determine which annotators create the best data?\n\nAre bad annotations useful or should they be deleted?""","b""['medicine', 'crowdfunding', 'oncology and cancer', 'large', 'featured']""",https://www.kaggle.com/kmader/crowds-cure-cancer-2017
b'Chrome User Experience Report',b'Chrome User Experience Report (BigQuery)',"b'#Context\n\nGoogle Chrome is a popular web browser developed by Google.\n\n#Content\n\nThe Chrome User Experience Report is a public dataset of key user experience metrics for popular origins on the web, as experienced by Chrome users under real-world conditions.\n\n#Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/chrome-ux-report:all\n\nFor more info, see the documentation at https://developers.google.com/web/tools/chrome-user-experience-report/\n\nLicense: [CC BY 4.0][3]\n\nPhoto by [Edho Pratama][1] on [Unsplash][2]\n\n\n  [1]: https://unsplash.com/photos/yeB9jDmHm6M?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\n  [2]: https://unsplash.com/search/photos/website?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\n  [3]: https://creativecommons.org/licenses/by/4.0/'","b""['internet', 'human-computer interaction', 'web sites', 'large', 'featured']""",https://www.kaggle.com/bigquery/chrome-user-experience-report
b'The BeeImage Dataset: Annotated Honey Bee Images',"b'Apis mellifera with location, date, health, and more labels'","b""### Context\n\nEvery third bite of food relies on pollination by bees. At the same time, this past winter honeybee hive losses have exceeded 60% in some states. How can we address this issue? How can we better understand our bees? And most importantly, how can we save them before it's too late?\n\nWhile many indications of hive strength and health are visible on the inside of the hive, frequent check-ups on the hive are time-consuming and disruptive to the bees' workflow and hive in general. By investigating the bees that leave the hive, we can gain a more complete understanding of the hive itself. For example, an unhealthy hive infected with varroa mites will have bees with deformed wings or mites on their backs. These characteristics can be observed without opening the hive. To protect against robber bees, we could track the ratio of pollen-carrying bees vs those without. A large influx of bees without pollen may be an indication of robber bees. This dataset aims to provide basic visual data to train machine learning models to classify bees in these categories, paving the way for more intelligent hive monitoring or beekeeping in general.\n\n### Content\n\nThis dataset contains 5,100+ bee images annotated with location, date, time, subspecies, health condition, caste, and pollen. \n\nThe original batch of images was extracted from still time-lapse videos of bees. By averaging the frames to calculate a background image, each frame of the video was subtracted against that background to bring out the bees in the forefront. The bees were then cropped out of the frame so that each image has only one bee. Because each video is accompanied by a form with information about the bees and hive, the labeling process is semi-automated. Each video results in differing image crop quality levels. This dataset will be updated as more videos and data become available.\n\n-1 means the information is coming soon.\n\n### Acknowledgements\n\nThank you to everyone who has submitted a video:\n\nJames Temple\n\nKen McKenzie\n\nHoward Wetsman\n\nDaniel Long\n\nMichael J. Gras\n\nJohn Therriault\n\nCal Hansen\n\nJim Davis\n\nJack Goral\n\n### Inspiration\n\nHow can we improve our understanding of a hive through images of bees?\n\nHow can we expedite the hive checkup process?\n\nHow can bee image data help us recognize problems earlier?\n\nHow can bee image data help us save our bees?\n\n### Contribute\n\nIf you would like to contribute or learn more, please fill out this form to be added to the email list: https://goo.gl/forms/FzSUhw6z9QMSTpaH2, or contact jy2k16@gmail.com""","b""['image data', 'animals', 'environment', 'agriculture', 'natural resources', 'medium', 'featured']""",https://www.kaggle.com/jenny18/honey-bee-annotated-images
b'USPTO Patent Trial and Appeal Board (PTAB) Data',b'Trials conducted by PTAB for issues of patentability (BigQuery)',"b'### [Fork this notebook][3] to get started on accessing data in the BigQuery dataset by writing SQL queries using the BQhelper module.\n\n## Context\nThe Patent Trial and Appeal Board (PTAB) conducts trials, including inter partes, post-grant, and covered business method patent reviews and derivation proceedings; hears appeals from adverse examiner decisions in patent applications and reexamination proceedings; and renders decisions in interferences.\n\n## Content\nUSPTO Patent Trial and Appeal Board (PTAB) API Data contains data from the PTAB E2E (end-to-end) system making public America Invents Action (AIA) Trials information and documents available.\n\n## Acknowledgements\n\xe2\x80\x9cUSPTO PTAB API\xe2\x80\x9d by the USPTO, for public use.\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:uspto_ptab\n\nBanner photo by [Michael D Beckwith][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/5C58vkFXdYs\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-uspto-ptab-data'","b""['bigquery', 'law', 'medium', 'featured']""",https://www.kaggle.com/bigquery/uspto-ptab
b'Medicare Skilled Nursing Facility Provider Reports',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: NA, Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/medicare-skilled-nursing-facility-provider-reports
b'NOAA ICOADS',b'A global marine meteorological and surface ocean dataset',"b'## Overview\nThe International Comprehensive Ocean-Atmosphere Data Set (ICOADS) is a global ocean marine meteorological and surface ocean dataset. It is formed by merging many national and international data sources that contain measurements and visual observations from ships (merchant, navy, research), moored and drifting buoys, coastal stations, and other marine and near-surface ocean platforms. Each marine report contains individual observations of meteorological and oceanographic variables, such as sea surface and air temperatures, wind, pressure, humidity, and cloudiness. The coverage is global and sampling density varies depending on date and geographic position relative to shipping routes and ocean observing systems.\n\n## Content\n\nThe ICOADS dataset contains global marine data from ships (merchant, navy, research) and buoys, each capturing details according to the current weather or ocean conditions (wave height, sea temperature, wind speed, and so on). Each record contains the exact location of the observation which is great for visualizations. The historical depth of the data is quite comprehensive \xe2\x80\x94 There are records going back to 1662!\n\n## Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.github_repos.[TABLENAME]`. **[Fork this kernel to get started][99]** to learn how to safely manage analyzing large BigQuery datasets.\n  [99]: https://www.kaggle.com/mrisdal/safely-analyzing-github-projects-popular-licenses\n\n\n\n## Acknowledgements\n\nDataset Source: NOAA\nCategory: Meteorological, Climate, Transportation\n\nCitation: National Centers for Environmental Information/NESDIS/NOAA/U.S. Department of Commerce, Research Data Archive/Computational and Information Systems Laboratory/National Center for Atmospheric Research/University Corporation for Atmospheric Research, Earth System Research Laboratory/NOAA/U.S. Department of Commerce, Cooperative Institute for Research in Environmental Sciences/University of Colorado, National Oceanography Centre/Natural Environment Research Council/United Kingdom, Met Office/Ministry of Defence/United Kingdom, Deutscher Wetterdienst (German Meteorological Service)/Germany, Department of Atmospheric Science/University of Washington, and Center for Ocean-Atmospheric Prediction Studies/Florida State University. 2016, updated monthly. International Comprehensive Ocean-Atmosphere Data Set (ICOADS) Release 3, Individual Observations. Research Data Archive at the National Center for Atmospheric Research, Computational and Information Systems Laboratory: https://doi.org/10.5065/D6ZS2TR3. Accessed 01 04 2017.\n\n\nUse: This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - http://www.data.gov/privacy-policy#data_policy \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nPhoto by Gleb Kozenko on Unsplash'","b""['bigquery', 'weather', 'atmospheric sciences', 'oceans', 'large', 'featured']""",https://www.kaggle.com/noaa/noaa-icoads
b'Intellectual Property Investigations by the USITC',b'Section 337 investigations on intellectual property infringement (BigQuery)',"b'## Context\nSection 337, Tariff Act of 1930, Investigations of Unfair Practices in Import Trade. Under section 337, the USITC determines whether there is unfair competition in the importation of products into, or their subsequent sale in, the United States. Section 337 prohibits the importation into the US , or the sale of such articles by owners, importers or consignees, of articles which infringe a patent, copyright, trademark, or semiconductor mask work, or where unfair competition or unfair acts exist that can destroy or substantially injure a US industry or prevent one from developing, or restrain or monopolize trade in US commerce. These latter categories are very broad: unfair competition can involve counterfeit, mismarked or misbranded goods, where the sale of the goods are at unfairly low prices, where other antitrust violations take place such as price fixing, market division or the goods violate a standard applicable to such goods.\n\n## Content\nUS International Trade Commission 337Info Unfair Import Investigations Information System contains data on investigations done under Section 337. Section 337 declares the infringement of certain statutory intellectual property rights and other forms of unfair competition in import trade to be unlawful practices. Most Section 337 investigations involve allegations of patent or registered trademark infringement.\n\n[Fork this notebook][3] to get started on accessing data in the BigQuery dataset using the BQhelper package to write SQL queries.\n\n## Acknowledgements\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:usitc_investigations\n\n""US International Trade Commission 337Info Unfair Import Investigations Information System"" by the USITC, for public use.\n\nBanner photo by [Jo\xc3\xa3o Silas][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/I_LgQ8JZFGE\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-google-patents-public-data'","b""['bigquery', 'law', 'small', 'featured']""",https://www.kaggle.com/bigquery/usitc-investigations
b'MAtrixware REsearch Collection (MAREC) Data',b'Over 19 million patent applications and granted patents (BigQuery)',"b'## Context\nThe MAtrixware REsearch Collection (MAREC) is a standardised patent data corpus available for research purposes. MAREC seeks to represent patent documents of several languages in order to answer specific research questions. It is intended as raw material for research in areas such as information retrieval, natural language processing or machine translation, which require large amounts of complex documents. \n\n## Content\nMAREC Data is a static collection of over 19 million patent applications and granted patents in a unified file format normalized from EP, WO, US, and JP sources, spanning a range from 1976 to June 2008.\n\n[Fork this notebook][3] to get started on accessing data in the BigQuery dataset using the BQhelper package to write SQL queries.\n\n## Acknowledgements\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:marec\n\n\xe2\x80\x9cThe MAtrixware REsearch Collection\xe2\x80\x9d by cortical.io, used under CC BY 4.0.\n\nBanner photo by [Samuel Zeller][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/UG3INgQeZPw\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-google-patents-public-data'","b""['bigquery', 'business', 'large', 'featured']""",https://www.kaggle.com/bigquery/marec
b'Seattle Road Weather Information Stations',b'From City of Seattle Open Data',"b""### Content  \n\nThis data is derived from sensor stations placed on bridges and surface streets within city limits.  Each station has a temperature sensor that measures the temperature of the street surface and a sensor that measures the ambient air temperature at the station each second.  Those values are averaged into temperature readings that are recorded by the station every minute.  The dataset is updated every fifteen minutes with new data.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/DCOkEWJ_wY4) by [dan carlson](https://unsplash.com/@dan_carl5on) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'weather', 'medium', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-road-weather-information-stations
b'World Bank: Education Data',b'World Bank: Education Data (BigQuery Dataset)',"b'### Context\n\nThe World Bank is an international financial institution that provides loans to countries of the world for capital projects. The World Bank\'s stated goal is the reduction of poverty.  Source: https://en.wikipedia.org/wiki/World_Bank\n\n### Content\n\nThis dataset combines key education statistics from a variety of sources to provide a look at global literacy, spending, and access.\n\nFor more information, see the [World Bank website][1].\n\nFork [this kernel][2] to get started with this dataset.\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:world_bank_health_population\n\nhttp://data.worldbank.org/data-catalog/ed-stats\n\nhttps://cloud.google.com/bigquery/public-data/world-bank-education\n\nCitation: The World Bank: Education Statistics\n\nDataset Source: World Bank.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - http://www.data.gov/privacy-policy#data_policy - and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [@till_indeman from Unplash][3].\n\n### Inspiration\n \nOf total government spending, what percentage is spent on education?\n\n\n  [1]: http://data.worldbank.org/data-catalog/ed-stats\n  [2]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-wbed-dataset\n  [3]: https://unsplash.com/photos/rKPiuXLq29A\n'","b""['economics', 'healthcare', 'government', 'public health', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/theworldbank/world-bank-intl-education
b'HCPCS Level II ',b'Healthcare Common Procedure Coding System (HCPCS) Level II (BigQuery Dataset)',"b'### Context\n\nThe Healthcare Common Procedure Coding System (HCPCS, often pronounced by its acronym as ""hick picks"") is a set of health care procedure codes based on the American Medical Association\'s Current Procedural Terminology (CPT).\n\nHCPCS includes three levels of codes:\nLevel I consists of the American Medical Association\'s Current Procedural Terminology (CPT) and is numeric. Level II codes are alphanumeric and primarily include non-physician services such as ambulance services and prosthetic devices, and represent items and supplies and non-physician services, not covered by CPT-4 codes (Level I). Level III codes, also called local codes, were developed by state Medicaid agencies, Medicare contractors, and private insurers for use in specific programs and jurisdictions. The Health Insurance Portability and Accountability Act of 1996 (HIPAA) instructed CMS to adopt a standard coding systems for reporting medical transactions. The use of Level III codes was discontinued on December 31, 2003, in order to adhere to consistent coding standards.\n\n### Content\n\nClassification of procedures performed for patients is important for billing and reimbursement in healthcare. The primary classification system used in the United States is Healthcare Common Procedure Coding System (HCPCS), maintained by Centers for Medicare and Medicaid Services (CMS). This system is divided into two levels: level I and level II.\n\nLevel I HCPCS codes classify services rendered by physicians. This system is based on Common Procedure Terminology (CPT), a coding system maintained by the American Medical Association (AMA). Level II codes, which are the focus of this public dataset, are used to identify products, supplies, and services not included in level I codes. The level II codes include items such as ambulance services, durable medical goods, prosthetics, orthotics and supplies used outside a physician\xe2\x80\x99s office.\n\nGiven the ubiquity of administrative data in healthcare, HCPCS coding systems are also commonly used in areas of clinical research such as outcomes based research.\n\nUpdate Frequency: Yearly\n\nFork [this kernel][1] to get started.\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/table/bigquery-public-data:cms_codes.hcpcs\n\nhttps://cloud.google.com/bigquery/public-data/hcpcs-level2\n\nDataset Source: Center for Medicare and Medicaid Services.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - http://www.data.gov/privacy-policy#data_policy \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [@rawpixel from Unplash][2].\n\n### Inspiration\n\nWhat are the descriptions for a set of HCPCS level II codes?\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-hcpcs2-dataset\n  [2]: https://unsplash.com/photos/0-SGyQFiDRI\n'","b""['healthcare', 'bigquery', 'small', 'featured']""",https://www.kaggle.com/cms/cms-codes
b'IRS Form 990 Data',b'IRS Form 990 Data (BigQuery Dataset)',"b'### Context\n\nForm 990 (officially, the ""Return of Organization Exempt From Income Tax""[1]) is a United States Internal Revenue Service form that provides the public with financial information about a nonprofit organization. It is often the only source of such information. It is also used by government agencies to prevent organizations from abusing their tax-exempt status.  Source: https://en.wikipedia.org/wiki/Form_990\n\n### Content\n\nForm 990 is used by the United States Internal Revenue Service to gather financial information about nonprofit/exempt organizations. This BigQuery dataset can be used to perform research and analysis of organizations that have electronically filed Forms 990, 990-EZ and 990-PF.  For a complete description of data variables available in this dataset, see the IRS\xe2\x80\x99s extract documentation: https://www.irs.gov/uac/soi-tax-stats-annual-extract-of-tax-exempt-organization-financial-data.\n\nUpdate Frequency: Annual\n\nFork [this kernel][1] to get started with this dataset.\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:irs_990\n\nhttps://cloud.google.com/bigquery/public-data/irs-990\n\nDataset Source: U.S. Internal Revenue Service.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - http://www.data.gov/privacy-policy#data_policy - and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [@rawpixel from Unplash][2].\n\n\n### Inspiration\n\nWhat organizations filed tax exempt status in 2015?\n\nWhat was the revenue of the American Red Cross in 2017?\n\n\n\n\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-irs-990-dataset\n  [2]: https://unsplash.com/photos/BB7gHAsnQY8\n\n\n'","b""['finance', 'government', 'large', 'featured']""",https://www.kaggle.com/irs/irs-990
b'CMS Hospital Service Area File (2016-2017)',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain U.S. Government, NA""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/cms/cms-hospital-service-area-file-2016-2017
b'SF Restaurant Scores - LIVES Standard',b'From San Francisco Open Data',"b""### Content  \n\nThe Health Department has developed an inspection report and scoring system. After conducting an inspection of the facility, the Health Inspector calculates a score based on the violations observed. Violations can fall into:high risk category: records specific violations that directly relate to the transmission of food borne illnesses, the adulteration of food products and the contamination of food-contact surfaces.moderate risk category: records specific violations that are of a moderate risk to the public health and safety.low risk category: records violations that are low risk or have no immediate risk to the public health and safety.The score card that will be issued by the inspector is maintained at the food establishment and is available to the public in this dataset.\r\nSan Francisco's LIVES restaurant inspection data leverages the LIVES Flattened Schema (https://goo.gl/c3nNvr), which is based on LIVES version 2.0, cited on Yelp's website (http://www.yelp.com/healthscores).  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/EkwOre9Oqhc) by [Autumn Goodman](https://unsplash.com/@auttgood) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-restaurant-scores-lives-standard
b'San Francisco Building Permits',b'5 years and 200k building permits',"b""## Background\n\nA building permit is an official approval document issued by a governmental agency that allows you or your contractor to proceed with a construction or remodeling project on one's property. For more details go to https://www.thespruce.com/what-is-a-building-permit-1398344. Each city or county has its own office related to buildings, that can do multiple functions like issuing permits, inspecting buildings to enforce safety measures, modifying rules to accommodate needs of the growing population etc. For the city of San Francisco, permit issuing is taken care by www.sfdbi.org/\n\nWhy is this important: In the recent past, several posts and blogs highlighted that main discrepancy in demand and supply in real estate industry is due to delays in issuing building permits. Refer:\nhttps://www.trulia.com/blog/trends/elasticity-2016/  - Introduces concept of elasticity, and nice scatterplot of various cities. A good data story!\nhttps://biv.com/article/2014/11/city-building-permit-delays-costing-developers-tim\n\n## Content\n\nThe data was downloaded for the dates ranging from Jan 1st, 2013 to Feb 25th, 2018 using the filter in San Francisco open data portal.  This is the exact link:  https://data.sfgov.org/Housing-and-Buildings/Building-Permits/i98e-djp9/data\nThere are 43 columns and close to 200k records in the downloaded version (kept here). Description is separately uploaded as dictionary.\n\n## Thanks to\n\n1.  San Francisco Open Data portal for keeping and updating this data every Saturday.\n2. A fellow Kaggler and mentor Rajiv Shah for encouraging me to think of business problems\n3. A friend, Nandan PC, for suggesting to post it here and another friend Andrew Maguire for encouraging\n\n## Challenges\n\nMay be some of the questions that can be answered are:\n\nCan you try predicting permit issue times for various permit types? Which ones matter more?\nCan you suggest which is the best week day to visit Department of building inspections, based on this data?\nCan you conclude anything on the city's developments based on this data?\n\nWaiting to hear from all enthusiastic Kagglers! Enjoy..""","b""['business', 'tabular data', 'construction', 'medium', 'featured']""",https://www.kaggle.com/aparnashastry/building-permit-applications-data
b'San Francisco Building Permits',b'5 years and 200k building permits',"b""## Background\n\nA building permit is an official approval document issued by a governmental agency that allows you or your contractor to proceed with a construction or remodeling project on one's property. For more details go to https://www.thespruce.com/what-is-a-building-permit-1398344. Each city or county has its own office related to buildings, that can do multiple functions like issuing permits, inspecting buildings to enforce safety measures, modifying rules to accommodate needs of the growing population etc. For the city of San Francisco, permit issuing is taken care by www.sfdbi.org/\n\nWhy is this important: In the recent past, several posts and blogs highlighted that main discrepancy in demand and supply in real estate industry is due to delays in issuing building permits. Refer:\nhttps://www.trulia.com/blog/trends/elasticity-2016/  - Introduces concept of elasticity, and nice scatterplot of various cities. A good data story!\nhttps://biv.com/article/2014/11/city-building-permit-delays-costing-developers-tim\n\n## Content\n\nThe data was downloaded for the dates ranging from Jan 1st, 2013 to Feb 25th, 2018 using the filter in San Francisco open data portal.  This is the exact link:  https://data.sfgov.org/Housing-and-Buildings/Building-Permits/i98e-djp9/data\nThere are 43 columns and close to 200k records in the downloaded version (kept here). Description is separately uploaded as dictionary.\n\n## Thanks to\n\n1.  San Francisco Open Data portal for keeping and updating this data every Saturday.\n2. A fellow Kaggler and mentor Rajiv Shah for encouraging me to think of business problems\n3. A friend, Nandan PC, for suggesting to post it here and another friend Andrew Maguire for encouraging\n\n## Challenges\n\nMay be some of the questions that can be answered are:\n\nCan you try predicting permit issue times for various permit types? Which ones matter more?\nCan you suggest which is the best week day to visit Department of building inspections, based on this data?\nCan you conclude anything on the city's developments based on this data?\n\nWaiting to hear from all enthusiastic Kagglers! Enjoy..""","b""['business', 'tabular data', 'construction', 'medium', 'featured']""",https://www.kaggle.com/bls/bls
b'World Development Indicators (WDI) Data',b'World Bank collection of global development indicators (BigQuery)',"b'### [Fork this notebook][3] to get started on accessing data in the BigQuery dataset by writing SQL queries using the BQhelper module.\n\n## Context\nWorld Development Indicators (WDI) by World Bank includes data spanning up to 56 years\xe2\x80\x94from 1960 to 2016. WDI frames global trends with indicators on population, population density, urbanization, GNI, and GDP. These indicators measure the world\xe2\x80\x99s economy and progress toward improving lives, achieving sustainable development, providing support for vulnerable populations, and reducing gender disparities.\n\n## Content\nWorld Development Indicators Data is the primary World Bank collection of development indicators, compiled from officially-recognized international sources. It presents the most current and accurate global development data available, and includes national, regional and global estimates.\n\n## Acknowledgements\n\xe2\x80\x9cWorld Development Indicators\xe2\x80\x9d by the World Bank, used under CC BY 3.0 IGO.\n\nData Origin: https://bigquery.cloud.google.com/dataset/patents-public-data:worldbank_wdi\n\nBanner photo by [Joshua Rawson-Harris][1] on [Unsplash][2]\n\n  [1]: https://unsplash.com/photos/KRELIShKxTM\n  [2]: https://unsplash.com/\n  [3]: https://www.kaggle.com/jessicali9530/how-to-query-world-development-indicators-data'","b""['finance', 'economics', 'bigquery', 'world', 'large', 'featured']""",https://www.kaggle.com/bigquery/worldbank-wdi
"b'House Sales in King County, USA'",b'Predict house price using regression',"b""This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n\nIt's a great dataset for evaluating simple regression models.""","b""['finance', 'home', 'small', 'featured']""",https://www.kaggle.com/harlfoxem/housesalesprediction
b'IBRD Statement Of Loans Data',b'From World Bank Financial Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](finances.worldbank.org) and they update their information according the amount of data that is brought in. Explore World Bank's Financial Data using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.\n\nThis dataset is distributed under a [Creative Commons Attribution 3.0 IGO](https://creativecommons.org/licenses/by/3.0/igo/) license.  \n\nThis dataset is distributed under the following licenses: Creative Commons Attribution 3.0 IGO""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/theworldbank/ibrd-statement-of-loans-data
b'NOAA GOES-16',b'Next generation geostationary weather satellites data ',"b""## Overview\n\nThe Geostationary Operational Environmental Satellite-R Series (GOES-R) is the next generation of geostationary weather satellites. The GOES-R series will significantly improve the detection and observation of environmental phenomena that directly affect public safety, protection of property and our nation\xe2\x80\x99s economic health and prosperity.\n\nThe GOES-16 satellite, known as GOES-R prior to launch, is the first satellite in the series. It will provide images of weather pattern and severe storms as frequently as every 30 seconds, which will contribute to more accurate and reliable weather forecasts and severe weather outlooks.\n\n## Content\nThe raw dataset  includes a feed of the Advanced Baseline Imager (ABI) radiance data (Level 1b) and Cloud and Moisture Imager (CMI) products (Level 2) which are freely available through the NOAA Big Data Project.\n\n## Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.github_repos.[TABLENAME]`. **[Fork this kernel to get started][99]** to learn how to safely manage analyzing large BigQuery datasets.\n  [99]: https://www.kaggle.com/mrisdal/safely-analyzing-github-projects-popular-licenses\n\n\n\n## Acknowledgments\nThe NOAA Big Data Project (BDP) is an experimental collaboration between NOAA and infrastructure-as-a-service (IaaS) providers to explore methods of expand the accessibility of NOAA\xe2\x80\x99s data in order to facilitate innovation and collaboration. The goal of this approach is to help form new lines of business and economic growth while making NOAA's data more discoverable for the American public.\n![Sample images][1]\n\nKey metadata for this dataset has been extracted into convenient BigQuery tables (one each for L1b radiance, L2 CMIP, and L2 MCMIP). These tables can be used to query metadata in order to filter the data down to only a subset of raw netcdf4 files available in Google Cloud Storage.\n\n  [1]: https://storage.googleapis.com/public-dataset-images/noaa-goes-16-sample.png""","b""['bigquery', 'weather', 'earth sciences', 'atmospheric sciences', 'large', 'featured']""",https://www.kaggle.com/noaa/goes16
b'D.C. Residential Properties',b'Residential Properties in Washington D.C.',"b""### Context\nWashington, D.C. is the capital of the United States. Washington's [population is approaching 700,000 people][1], and has been growing since 2000 following a half-century of population decline. The city is [highly segregated][2] and features a [high cost of living][3]. In 2017, the average price of a single family home in the district was [$649,000][4]. This dataset provides insight on the housing stock of the district.\n\n### Content\n\nThe residential property descriptions and address point information is current as of July 2018 and is provided by D.C. Geographic Information System. \n\nThe **raw_census_tracts_in_2010.csv** provides contextual information for regions throughout D.C. and can be joined with the main **DC_Property_data.csv** dataset through the **tract** value. Census tract shapefiles are also included to serve mapping visualizations.\n\n### Acknowledgements\n\nAll data is available at [Open Data D.C.][5]. The residential and address point data is managed by the [Office of the Chief Technology Officer][6]  \n\n**Distribution Liability:** [data terms and conditions][7]\n\nThe [banner photograph][8] is provided by Caleb Wright.\n\n\n  [1]: http://www.washingtonpost.com/wp-dyn/content/article/2010/12/21/AR2010122102609.html\n  [2]: https://www.brookings.edu/blog/social-mobility-memos/2015/03/24/segregation-and-concentrated-poverty-in-the-nations-capital/\n  [3]: https://www.expatistan.com/cost-of-living/washington-d-c\n  [4]: https://www.washingtonpost.com/realestate/after-a-solid-year-in-2017-can-the-dc-areas-housing-market-remain-strong/2018/04/04/2f6f45aa-35ac-11e8-8fd2-49fe3c675a89_story.html?utm_term=.582684789614\n  [5]: http://opendata.dc.gov/\n  [6]: https://octo.dc.gov/\n  [7]: http://dc.gov/page/terms-and-conditions-use-district-data\n  [8]: https://unsplash.com/photos/5CFA3Uv74FA""","b""['united states', 'real estate', 'medium', 'featured']""",https://www.kaggle.com/christophercorrea/dc-residential-properties
b'Los Angeles Parking Citations',b'From Los Angeles Open Data',"b""### Content  \n\nParking citations with latitude / longitude (XY) in US Feet coordinates according to the NAD_1983_StatePlane_California_V_FIPS_0405_Feet projection.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/TvFQWHJbDUU) by [Scott Webb](https://unsplash.com/@scottwebb) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-parking-citations
b'OpenAQ',b'Global Air Pollution Measurements',"b'OpenAQ is an open-source project to surface live, real-time air quality data from around the world. Their \xe2\x80\x9cmission is to enable previously impossible science, impact policy and empower the public to fight air pollution.\xe2\x80\x9d The data includes air quality measurements from 5490 locations in 47 countries.\n\nScientists, researchers, developers, and citizens can use this data to understand the quality of air near them currently. The dataset only includes the most current measurement available for the location (no historical data). \n\nUpdate Frequency: Weekly\n\n### Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.openaq.[TABLENAME]`. **[Fork this kernel to get started](https://www.kaggle.com/sohier/how-to-integrate-bigquery-pandas)**.\n\n### Acknowledgements\n\nDataset Source: openaq.org\n\nUse: This dataset is publicly available for anyone to use under the following terms provided by the [Dataset Source](https://openaq.org/#/about?_k=s3aspo) and is provided ""AS IS"" without any warranty, express or implied.'","b""['bigquery', 'pollution', 'small', 'featured']""",https://www.kaggle.com/open-aq/openaq
b'World Values Survey',b'World wide survey investigating human beliefs and values ',"b""### Context\n\nThe WVS consists of nationally representative surveys conducted in almost 100 countries which contain almost 90 percent of the world\xe2\x80\x99s population, using a common questionnaire. The WVS is the largest non-commercial, cross-national, time series investigation of human beliefs and values ever executed, currently including interviews with almost 400,000 respondents. \n\n\n### Content\n\nThe World Value Survey data grouped by country and wave. Question codes are matched with the mean for the subgroup if numeric, and else the mode. Also, standard deviation of answers in subgroup are given in columns with code name plus suffix '_SD'. Attached Code File links the variables to their original questionnaire content, including the possible reactions.\n\nAll negative, and thus missing, responses have been indicated as NA.\n\n### Acknowledgements\n\nThe entire dataset has been created and is maintained by the World Values Survey organisation. Find the entire dataset at [their official website][1]. Please note the following disclaimer:\n\nThese data files are available without restrictions, provided\n\na) that they are used for non-profit purposes; and\nb) correct citations are provided and sent to the World Values Survey Association for each publication of results based in part or entirely on these data files. This citation will be made freely available; and\nc) the data files themselves are not redistributed.\n\n\n### Inspiration\n\n[Quote:][2]\n\nThe WVS seeks to help scientists and policy makers understand changes in the beliefs, values and motivations of people throughout the world. Thousands of political scientists, sociologists, social psychologists, anthropologists and economists have used these data to analyze such topics as economic development, democratization, religion, gender equality, social capital, and subjective well-being. These data have also been widely used by government officials, journalists and students, and groups at the World Bank have analyzed the linkages between cultural factors and economic development.\n\n\n  [1]: http://www.worldvaluessurvey.org/WVSDocumentationWVL.jsp\n  [2]: http://www.worldvaluessurvey.org/WVSContents.jsp""","b""['linguistics', 'demographics', 'world', 'languages', 'survey analysis', 'small', 'featured']""",https://www.kaggle.com/fernandol/world-values-survey
"b'Oakland Crime, 911 Calls, Gun Incidents'",b'Explore open data from the city of Oakland',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of Oakland in California. The organization has an open data platform found [here](data.oaklandnet.com) and they update their information according to the amount of data that is brought in. Explore Oakland's Data using Kaggle and all of the data sources available through the city of Oakland [organization page](https://www.kaggle.com/cityofoakland)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/hpjSkU2UYSU) by [Carlos Muza](https://unsplash.com/@kmuza) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License, Public Domain""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/cityofoakland/oakland-crime-911-calls-gun-incidents
b'Chrome User Experience Report (India Only)',b'Chrome User Experience Report (BigQuery - India Only)',"b'#Context\n\nGoogle Chrome is a popular web browser developed by Google.\n\n#Content\n\nThe Chrome User Experience Report is a public dataset of key user experience metrics for popular origins on the web, as experienced by Chrome users under real-world conditions.\n\n#Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/chrome-ux-report:all\n\nFor more info, see the documentation at https://developers.google.com/web/tools/chrome-user-experience-report/\n\nLicense: [CC BY 4.0][3]\n\nPhoto by [Edho Pratama][1] on [Unsplash][2]\n\n\n  [1]: https://unsplash.com/photos/yeB9jDmHm6M?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\n  [2]: https://unsplash.com/search/photos/website?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\n  [3]: https://creativecommons.org/licenses/by/4.0/'","b""['internet', 'human-computer interaction', 'web sites', 'large', 'featured']""",https://www.kaggle.com/bigquery/chrome-ux-report-country-in
b'Seattle Checkouts by Title',b'From City of Seattle Open Data',"b""### Content  \n\nThis dataset includes a monthly count of Seattle Public Library checkouts by title for physical and electronic items. The dataset begins with checkouts that occurred in April 2005.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/j2OprKAcWkQ) by [Gabriele Diwald](https://unsplash.com/@gabrielediwald) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'large', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-checkouts-by-title
b'CMS Part D Prescriber Summary Reports (2013-2016)',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/cms/cms-part-d-prescriber-summary-reports-2013-2016
b'The GDELT Project',b'A realtime database of global human society for open research',"b'### Context\n\nThe GDELT Project is the largest, most comprehensive, and highest resolution open database of human society ever created. Just the 2015 data alone records nearly three quarters of a trillion emotional snapshots and more than 1.5 billion location references, while its total archives span more than 215 years, making it one of the largest open-access spatio-temporal datasets in existance and pushing the boundaries of ""big data"" study of global human society. Its Global Knowledge Graph connects the world\'s people, organizations, locations, themes, counts, images and emotions into a single holistic network over the entire planet. How can you query, explore, model, visualize, interact, and even forecast this vast archive of human society?\n\n### Content\n\nGDELT 2.0 has a wealth of features in the event database which includes events reported in articles published in 65 live translated languages, measurements of 2,300 emotions and themes, high resolution views of the non-Western world, relevant imagery, videos, and social media embeds, quotes, names, amounts, and more. \n\nYou may find these code books helpful:<br>\n[GDELT Global Knowledge Graph Codebook V2.1] [1] (PDF)<br>\n[GDELT Event Codebook V2.0][2] (PDF)<br>\n## Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.github_repos.[TABLENAME]`. **[Fork this kernel to get started][98]** to learn how to safely manage analyzing large BigQuery datasets.\n\n### Acknowledgements\n\nYou may redistribute, rehost, republish, and mirror any of the GDELT datasets in any form. However, any use or redistribution of the data must include a citation to the GDELT Project and a link to the website (https://www.gdeltproject.org/).\n\n\n  [1]: http://data.gdeltproject.org/documentation/GDELT-Global_Knowledge_Graph_Codebook-V2.1.pdf\n  [2]: http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf'","b""['nlp', 'bigquery', 'languages', 'news agencies', 'social sciences', 'large', 'featured']""",https://www.kaggle.com/gdelt/gdelt
b'Medicare Data',b'Medicare Data (BigQuery Dataset)',"b'### Context\n\nIn the United States, Medicare is a single-payer, national social insurance program administered by the U.S. federal government since 1966.  It provides health insurance for Americans aged 65 and older who have worked and paid into the system through the payroll tax.  Source: https://en.wikipedia.org/wiki/Medicare_(United_States)\n\n### Content\n\nThis public dataset was created by the Centers for Medicare & Medicaid Services. The data summarizes the utilization and payments for procedures, services, and prescription drugs provided to Medicare beneficiaries by specific inpatient and outpatient hospitals, physicians, and other suppliers. The dataset includes the following data.\n\nCommon inpatient and outpatient services\nAll physician and other supplier procedures and services\nAll Part D prescriptions.\nProviders determine what they will charge for items, services, and procedures provided to patients and these charges are the amount that providers bill for an item, service, or procedure.\n\nFork [this kernel][1] to get started.\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:medicare\n\nhttps://cloud.google.com/bigquery/public-data/medicare\n\nDataset Source: Center for Medicare and Medicaid Services.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - http://www.data.gov/privacy-policy#data_policy \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [@rawpixel from Unplash][2].\n\n### Inspiration\n\nWhat is the total number of medications prescribed in each state?\n\nWhat is the most prescribed medication in each state?\n\nWhat is the average cost for inpatient and outpatient treatment in each city and state?\n\nWhich are the most common inpatient diagnostic conditions in the United States?\n\nWhich cities have the most number of cases for each diagnostic condition?\n\nWhat are the average payments for these conditions in these cities and how do they compare to the national average?\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-cms-medicare-dataset\n  [2]: https://unsplash.com/photos/Xt1qMeOF29E\n'","b""['healthcare', 'bigquery', 'large', 'featured']""",https://www.kaggle.com/cms/cms-medicare
b'NOAA SPC Reports',"b'Hail, tornado, and wind reports from the NOAA Storm Prediction Center'","b""## Overview\nNOAA\xe2\x80\x99s Storm Prediction Center (SPC) maintains a database of daily US storm data as reported by local National Weather Service offices from trained weather spotters. The types of storm data recorded by SPC include reports of Tornados, Wind, and Hail. This dataset has been subjected to a common suite of quality assurance reviews to avoid duplication of the reported weather events in the data set. The respective report type datasets are available in BigQuery under NOAA-SPC.\n\n\n### Content\n\nThis dataset contains three tables for hail reports, tornado reports, and wind reports.\n\n## Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.github_repos.[TABLENAME]`. **[Fork this kernel to get started][99]** to learn how to safely manage analyzing large BigQuery datasets.\n  [99]: https://www.kaggle.com/mrisdal/safely-analyzing-github-projects-popular-licenses\n\n\n### Acknowledgements\n\nThis public dataset is hosted in Google BigQuery and is included in BigQuery's 1TB/mo of free tier processing. This means that each user receives 1TB of free BigQuery processing every month, which can be used to run queries on this public dataset. Watch this short video to learn how to get started quickly using BigQuery to access public datasets. What is BigQuery.\n\nPhoto by Brian Cook on Unsplash""","b""['bigquery', 'weather', 'earth sciences', 'atmospheric sciences', 'small', 'featured']""",https://www.kaggle.com/noaa/noaa-spc
b'Seattle Library Collection Inventory',b'From City of Seattle Open Data',"b""### Content  \n\nThe Seattle Public Library's collection inventory.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/VphuLHwuyks) by [Alexandra Kirr](https://unsplash.com/@alexkirrthegirl) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'utility', 'large', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-library-collection-inventory
b'BigQuery Sample Tables',b'Sample Tables for Tutorials and Learning (BigQuery)',"b'### Context\n\nBigQuery provides a limited number of sample tables that you can run queries against.  These tables are suited for testing queries and learning BigQuery.\n\n### Content\n\t\n\n - gsod: Contains weather information collected by NOAA, such as precipitation\n   amounts and wind speeds from late 1929 to early 2010.\n\n - github_nested: Contains a timeline of actions such as pull requests and comments on\n   GitHub repositories with a nested schema. Created in September 2012.\n\n - github_timeline:\tContains a timeline of actions such as pull requests and comments on\n   GitHub repositories with a flat schema. Created in May 2012.\n\n - natality: Describes all United States births registered in the 50 States, the\n   District of Columbia, and New York City from 1969 to 2008.\n\n - shakespeare: Contains a word index of the works of Shakespeare, giving the number\n   of times each word appears in each corpus.\n\n - trigrams: Contains English language trigrams from a sample of works published\n   between 1520 and 2008.\n\n - wikipedia: Contains the complete revision history for all Wikipedia articles up\n   to April 2010.\n\nFork [this kernel][1] to get started.\n\n### Acknowledgements\n\nData Source: https://cloud.google.com/bigquery/sample-tables\n\nBanner Photo by [Mervyn Chan from Unplash][2].\n\n### Inspiration\n\nHow many babies were born in New York City on Christmas Day?\n\nHow many words are in the play Hamlet?\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-sample-tables\n  [2]: https://images.unsplash.com/photo-1495204559065-944ad38119c3?ixlib=rb-0.3.5&ixid=eyJhcHBfaWQiOjEyMDd9&s=0e0963de1b3260c0791ed638cdaea060&auto=format&fit=crop&w=1950&q=80\n\n\n\n\n\n\n\n\n\n\n'","b""['tutorial', 'literature', 'large', 'featured']""",https://www.kaggle.com/bigquery/samples
b'Global Economic Monitor',b'From World Bank Open Data',"b""### Content  \n\nProviding daily updates of global economic developments, with coverage of high income- as well as developing countries. Daily data updates are provided for exchange rates, equity markets, and emerging market bond indices. Monthly data coverage (updated daily and populated upon availability) is provided for consumer prices, high-tech market indicators, industrial production and merchandise trade.  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](https://databank.worldbank.org/) and they update their information according the amount of data that is brought in. Explore the World Bank using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using the World Bank's [APIs](data.worldbank.org/developers) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/39Iz5xge4sE) by [Patrick Hendry](https://unsplash.com/@worldsbetweenlines) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['world', 'medium', 'featured']""",https://www.kaggle.com/theworldbank/global-economic-monitor
b'DJIA 30 Stock Time Series',b'Historical stock data for DIJA 30 companies (2006-01-01 to 2018-01-01)',"b""### Context\n\nThe script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!\n\nStock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).\n\n          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',\n\n          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',\n\n          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']\n\nIn the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.\n\n\n### Content\n\nThe data is presented in a couple of formats to suit different individual's needs or computational limitations. \nI have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and\na smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.\n\nThe folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. \nThe all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. \nDepending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.\n\nAll the files have the following columns:\nDate - in format: yy-mm-dd \n\nOpen - price of the stock at market open (this is NYSE data so all in USD)\n\nHigh - Highest price reached in the day\n\nLow\tClose - Lowest price reached in the day\n\nVolume - Number of shares traded\n\nName - the stock's ticker name\n\n### Inspiration\n\nThis dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.\nFrom these data informative stock stats such as volatility and moving averages can be easily calculated.\nThe million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!\n\n### Acknowledgement \n\nThis Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.\nThis data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.\n\n  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb""","b""['finance', 'time series', 'stochastic processes', 'small', 'featured']""",https://www.kaggle.com/szrlee/stock-time-series-20050101-to-20171231
b'(MBTI) Myers-Briggs Personality Type Dataset',"b""Includes a large number of people's MBTI type and content written by them""","b'## Context ##\n\nThe Myers Briggs Type Indicator (or MBTI for short) is a personality type system that divides everyone into 16 distinct personality types across 4 axis:\n\n - Introversion (I) \xe2\x80\x93 Extroversion (E)\n - Intuition (N) \xe2\x80\x93 Sensing (S)\n - Thinking (T) \xe2\x80\x93 Feeling (F)\n - Judging (J) \xe2\x80\x93 Perceiving (P)\n\n[(More can be learned about what these mean here)][1]\n\nSo for example, someone who prefers introversion, intuition, thinking and perceiving would be labelled an INTP in the MBTI system, and there are lots of personality based components that would model or describe this person\xe2\x80\x99s preferences or behaviour based on the label.\n\nIt is one of, if not the, the most popular personality test in the world. It is used in businesses, online, for fun, for research and lots more. A simple google search reveals all of the different ways the test has been used over time. It\xe2\x80\x99s safe to say that this test is still very relevant in the world in terms of its use.\n\nFrom scientific or psychological perspective it is based on the work done on [cognitive functions][2] by Carl Jung i.e. Jungian Typology. This was a model of 8 distinct functions, thought processes or ways of thinking that were suggested to be present in the mind. Later this work was transformed into several different personality systems to make it more accessible, the most popular of which is of course the MBTI. \n\nRecently, its use/validity has come into question because of unreliability in experiments surrounding it, among other reasons. But it is still clung to as being a very useful tool in a lot of areas, and the purpose of this dataset is to help see if any patterns can be detected in specific types and their style of writing, which overall explores the validity of the test in analysing, predicting or categorising behaviour.\n\n## Content ##\n\nThis dataset contains over 8600 rows of data, on each row is a person\xe2\x80\x99s:\n\n - Type (This persons 4 letter MBTI code/type)\n - A section of each of the last 50 things they have posted (Each entry separated by ""|||"" (3 pipe characters))\n\n## Acknowledgements ##\n\nThis data was collected through the [PersonalityCafe forum][3], as it provides a large selection of people and their MBTI personality type, as well as what they have written. \n\n## Inspiration ##\n\nSome basic uses could include:\n\n - Use machine learning to evaluate the MBTIs validity and ability to predict language styles and behaviour online.\n - Production of a machine learning algorithm that can attempt to determine a person\xe2\x80\x99s personality type based on some text they have written.\n\n\n  [1]: http://www.myersbriggs.org/my-mbti-personality-type/mbti-basics/home.htm\n  [2]: http://www.cognitiveprocesses.com/Cognitive-Functions/\n  [3]: http://personalitycafe.com/forum/'","b""['internet', 'linguistics', 'demographics', 'psychology', 'personality', 'medium', 'featured']""",https://www.kaggle.com/datasnaek/mbti-type
b'FiveThirtyEight Comic Characters Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Comic Characters\n\nThis folder contains data behind the story [Comic Books Are Still Made By Men, For Men And About Men](http://fivethirtyeight.com/features/women-in-comic-books/).\n\nThe data comes from [Marvel Wikia](http://marvel.wikia.com/Main_Page) and [DC Wikia](http://dc.wikia.com/wiki/Main_Page). Characters were scraped on August 24. Appearance counts were scraped on September 2. The month and year of the first issue each character appeared in was pulled on October 6.\n\nThe data is split into two files, for DC and Marvel, respectively: `dc-wikia-data.csv` and `marvel-wikia-data.csv`. Each file has the following variables:\n\nVariable | Definition\n---|---------\n`page_id` | The unique identifier for that characters page within the wikia\n`name` | The name of the character\n`urlslug` | The unique url within the wikia that takes you to the character\n`ID` | The identity status of the character (Secret Identity, Public identity, [on marvel only: No Dual Identity])\n`ALIGN` | If the character is Good, Bad or Neutral\n`EYE` | Eye color of the character\n`HAIR` | Hair color of the character\n`SEX` | Sex of the character (e.g. Male, Female, etc.)\n`GSM` | If the character is a gender or sexual minority (e.g. Homosexual characters, bisexual characters)\n`ALIVE` | If the character is alive or deceased\n`APPEARANCES` | The number of appareances of the character in comic books (as of Sep. 2, 2014. Number will become increasingly out of date as time goes on.)\n`FIRST APPEARANCE` | The month and year of the character's first appearance in a comic book, if available\n`YEAR` | The year of the character's first appearance in a comic book, if available\n  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.  \n\n[Cover photo](https://unsplash.com/photos/pJKpk_rOLnw) by [Zbysiu Rodak](https://unsplash.com/@zbigniew) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-comic-characters-dataset
b'World Bank: GHNP Data',"b'World Bank: Global Health, Nutrition, and Population Data (BigQuery Dataset)'","b'### Context\n\nThe World Bank is an international financial institution that provides loans to countries of the world for capital projects. The World Bank\'s stated goal is the reduction of poverty.  Source: https://en.wikipedia.org/wiki/World_Bank\n\n### Content\n\nThis dataset combines key health statistics from a variety of sources to provide a look at global health and population trends. It includes information on nutrition, reproductive health, education, immunization, and diseases from over 200 countries.\n\nUpdate Frequency: Biannual\n\nFor more information, see the [World Bank website][1].\n\nFork [this kernel][2] to get started with this dataset.\n\n### Acknowledgements\n\nhttps://datacatalog.worldbank.org/dataset/health-nutrition-and-population-statistics\n\nhttps://cloud.google.com/bigquery/public-data/world-bank-hnp\n\nDataset Source: World Bank.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - http://www.data.gov/privacy-policy#data_policy - and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nCitation: The World Bank: Health Nutrition and Population Statistics\n\nBanner Photo by [@till_indeman from Unplash][3].\n\n### Inspiration\n \nWhat\xe2\x80\x99s the average age of first marriages for females around the world?\n\n\n  [1]: https://datacatalog.worldbank.org/dataset/health-nutrition-and-population-statistics\n  [2]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-ghnp-dataset\n  [3]: https://unsplash.com/photos/rKPiuXLq29A'","b""['economics', 'healthcare', 'government', 'public health', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/theworldbank/world-bank-health-population
b'US Traffic Fatality Records',b'Fatal car crashes for 2015-2016',"b""Fatality Analysis Reporting System (FARS) was created in the United States by the National Highway Traffic Safety Administration (NHTSA) to provide an overall measure of highway safety, to help suggest solutions, and to help provide an objective basis to evaluate the effectiveness of motor vehicle safety standards and highway safety programs.\n\nFARS contains data on a census of fatal traffic crashes within the 50 States, the District of Columbia, and Puerto Rico. To be included in FARS, a crash must involve a motor vehicle traveling on a trafficway customarily open to the public and result in the death of a person (occupant of a vehicle or a non-occupant) within 30 days of the crash. FARS has been operational since 1975 and has collected information on over 989,451 motor vehicle fatalities and collects information on over 100 different coded data elements that characterizes the crash, the vehicle, and the people involved.\n\nFARS is vital to the mission of NHTSA to reduce the number of motor vehicle crashes and deaths on our nation's highways, and subsequently, reduce the associated economic loss to society resulting from those motor vehicle crashes and fatalities. FARS data is critical to understanding the characteristics of the environment, trafficway, vehicles, and persons involved in the crash.\n\nNHTSA has a cooperative agreement with an agency in each state government to provide information in a standard format on fatal crashes in the state. Data is collected, coded and submitted into a micro-computer data system and transmitted to Washington, D.C. Quarterly files are produced for analytical purposes to study trends and evaluate the effectiveness highway safety programs.\n\n### Content\n\nThere are 40 separate data tables. You can find the manual, which is too large to reprint in this space, [here](https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812448).\n\n### Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.nhtsa_traffic_fatalities.[TABLENAME]`. **[Fork this kernel to get started](https://www.kaggle.com/sohier/ranking-state-fatality-rates-with-big-query)**.\n\n### Acknowledgements\n\nThis dataset was provided by the [National Highway Traffic Safety Administration](https://www.nhtsa.gov/).""","b""['bigquery', 'automobiles', 'medium', 'featured']""",https://www.kaggle.com/usdot/nhtsa-traffic-fatalities
b'United States International Census',b'United States Census Bureau International (BigQuery Dataset)',"b'### Context\n\nThe United States Census Bureau\xe2\x80\x99s International Dataset provides estimates of country populations since 1950 and projections through 2050.\n\n### Content\n\nThe U.S. Census Bureau provides estimates and projections for countries and areas that are recognized by the U.S. Department of State that have a population of at least 5,000.  Specifically, the data set includes midyear population figures broken down by age and gender assignment at birth. Additionally, they provide time-series data for attributes including fertility rates, birth rates, death rates, and migration rates.\n\nFork [this kernel][1] to get started.\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:census_bureau_international\n\nhttps://cloud.google.com/bigquery/public-data/international-census\n\nDataset Source: www.census.gov\n\nThis dataset is publicly available for anyone to use under the following terms provided by the Dataset Source -http://www.data.gov/privacy-policy#data_policy - and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [Steve Richey from Unsplash][2].\n\n### Inspiration\n\nWhat countries have the longest life expectancy?\n\nWhich countries have the largest proportion of their population under 25?\n\nWhich countries are seeing the largest net migration?\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-international-census\n  [2]: https://unsplash.com/photos/wVK0ypTn61Y'","b""['economics', 'bigquery', 'government', 'medium', 'featured']""",https://www.kaggle.com/census/census-bureau-international
b'Sokoto Coventry Fingerprint Dataset (SOCOFing)',b'Sokoto Coventry Fingerprint Dataset (SOCOFing)',"b'Sokoto Coventry Fingerprint Dataset (SOCOFing) is a biometric fingerprint database designed for academic research purposes. SOCOFing is made up of 6,000 fingerprint images from 600 African subjects and contains unique attributes such as labels for gender, hand and finger name as well as synthetically altered versions with three different levels of alteration for obliteration, central rotation, and z-cut. For a complete formal description and usage policy please refer to the following paper:  https://arxiv.org/abs/1807.10609 '","b""['classification', 'deep learning', 'image data', 'image processing', 'categorical data', 'medium', 'featured']""",https://www.kaggle.com/ruizgara/socofing
b'Medicare Skilled Nursing Facilities Aggregate Data',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/sZKLku0YnFM) by [Oliver Sj\xc3\xb6str\xc3\xb6m](https://unsplash.com/@ollivves) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: NA, Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/medicare-skilled-nursing-facilities-aggregate-data
b'CMS AHRQ Patient Safety Indicator Data',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: NA""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/cms-ahrq-patient-safety-indicator-data
b'NCAA Basketball ',b'Basketball data from as far back as 1894',"b""## Overview\n\nThis dataset contains data about NCAA Basketball games, teams, and players. Game data covers play-by-play and box scores back to 2009, as well as final scores back to 1996. Additional data about wins and losses goes back to the 1894-5 season in some teams' cases.\n\n## Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.github_repos.[TABLENAME]`. **[Fork this kernel to get started][99]** to learn how to safely manage analyzing large BigQuery datasets.\n  [99]: https://www.kaggle.com/mrisdal/safely-analyzing-github-projects-popular-licenses\n\n## Acknowledgements\nSportradar: Copyright Sportradar LLC. Access to data is intended solely for internal research and testing purposes, and is not to be used for any business or commercial purpose. Data are not to be exploited in any manner without express approval from Sportradar.\n\nNCAA\xc2\xae: Copyright National Collegiate Athletic Association. Access to data is provided solely for internal research and testing purposes, and may not be used for any business or commercial purpose. Data are not to be exploited in any manner without express approval from the National Collegiate Athletic Association.""","b""['bigquery', 'sports', 'basketball', 'large', 'featured']""",https://www.kaggle.com/ncaa/ncaa-basketball
b'Keras Pretrained models',b'This dataset helps to use pretrained keras models in Kernels.',"b""### Context\n\nKaggle has more and more computer vision challenges. Although Kernel resources were increased recently we still can not train useful CNNs without GPU. The other main problem is that Kernels can't use network connection to download pretrained keras model weights. This dataset helps you to apply your favorite pretrained model in the Kaggle Kernel environment. \n\nHappy data exploration and transfer learning!\n\n### Content\n\n Model (Top-1 Accuracy | Top -5 Accuracy)\n\n - [Xception][2] (0.790 | 0.945)\n - [VGG16][3] (0.715 | 0.901)\n - [VGG19][4] (0.727 | 0.910)\n - [ResNet50][5] (0.759 | 0.929)\n - [InceptionV3][6] (0.788 | 0.944)\n - [InceptionResNetV2][7] (0.804 | 0.953) (could not upload due to 500 MB limit)\n\nFor more information see https://keras.io/applications/\n\n### Acknowledgements\nThanks to Fran\xc3\xa7ois Chollet for collecting these models and for the awesome keras.\n\n\n  [1]: https://www.kaggle.io/svf/1567125/6050f9f4b59e20afee8b68c84f79ea6c/__results___files/__results___7_0.png\n  [2]: https://keras.io/applications/#xception\n  [3]: https://keras.io/applications/#vgg16\n  [4]: https://keras.io/applications/#vgg19\n  [5]: https://keras.io/applications/#resnet50\n  [6]: https://keras.io/applications/#inceptionv3\n  [7]: https://keras.io/applications/#inceptionresnetv2""","b""['artificial intelligence', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/gaborfodor/keras-pretrained-models
b'1000 Cannabis Genomes Project',b'1000 Cannabis Genomes Project (BigQuery)',"b'### Context\n\nCannabis is a genus of flowering plants in the family Cannabaceae.  \n\nSource: https://en.wikipedia.org/wiki/Cannabis\n\n### Content\n\nIn October 2016, Phylos Bioscience released a genomic open dataset of approximately 850 strains of Cannabis via the Open Cannabis Project. In combination with other genomics datasets made available by Courtagen Life Sciences, Michigan State University, NCBI, Sunrise Medicinal, University of Calgary, University of Toronto, and Yunnan Academy of Agricultural Sciences, the total amount of publicly available data exceeds 1,000 samples taken from nearly as many unique strains.\n\nhttps://medium.com/google-cloud/dna-sequencing-of-1000-cannabis-strains-publicly-available-in-google-bigquery-a33430d63998\n\nThese data were retrieved from the National Center for Biotechnology Information\xe2\x80\x99s Sequence Read Archive (NCBI SRA), processed using the BWA aligner and FreeBayes variant caller, indexed with the Google Genomics API, and exported to BigQuery for analysis.  Data are available directly from Google Cloud Storage at gs://gcs-public-data--genomics/cannabis, as well as via the Google Genomics API as dataset ID 918853309083001239, and an additional duplicated subset of only transcriptome data as dataset ID 94241232795910911, as well as in the BigQuery dataset bigquery-public-data:genomics_cannabis.\n\nAll tables in the Cannabis Genomes Project dataset have a suffix like _201703. The suffix is referred to as [BUILD_DATE] in the descriptions below. The dataset is updated frequently as new releases become available.\n\nThe following tables are included in the Cannabis Genomes Project dataset:\n\nSample_info contains fields extracted for each SRA sample, including the SRA sample ID and other data that give indications about the type of sample. Sample types include: strain, library prep methods, and sequencing technology. See SRP008673 for an example of upstream sample data. SRP008673 is the University of Toronto sequencing of Cannabis Sativa subspecies Purple Kush.\n\nMNPR01_reference_[BUILD_DATE] contains reference sequence names and lengths for the draft assembly of Cannabis Sativa subspecies Cannatonic produced by Phylos Bioscience. This table contains contig identifiers and their lengths.\n\n**MNPR01_[BUILD_DATE] contains variant calls for all included samples and types (genomic, transcriptomic) aligned to the MNPR01_reference_[BUILD_DATE] table. Samples can be found in the sample_info table. The MNPR01_[BUILD_DATE] table is exported using the Google Genomics BigQuery variants schema. This table is useful for general analysis of the Cannabis genome.**\n\n**MNPR01_transcriptome_[BUILD_DATE] is similar to the MNPR01_[BUILD_DATE] table, but it includes only the subset transcriptomic samples. This table is useful for transcribed gene-level analysis of the Cannabis genome.**\n\nFork [this kernel][1] to get started with this dataset.\n\n### Acknowledgements\n\nDataset Source: http://opencannabisproject.org/\nCategory: Genomics\nUse: This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source - https://www.ncbi.nlm.nih.gov/home/about/policies.shtml - and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\nUpdate frequency:  As additional data are released to GenBank\nView in BigQuery: https://bigquery.cloud.google.com/dataset/bigquery-public-data:genomics_cannabis\nView in Google Cloud Storage: gs://gcs-public-data--genomics/cannabis\n\nBanner Photo by [Rick Proctor from Unplash][2].\n\n### Inspiration\n\nWhich Cannabis samples are included in the variants table?\n\nWhich contigs in the MNPR01_reference_[BUILD_DATE] table have the highest density of variants?\n\nHow many variants does each sample have at the THC Synthase gene (THCA1) locus?\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-cannabis-genome-project\n  [2]: https://unsplash.com/photos/PGc9Vid8O24\n\n\n'","b""['bigquery', 'agriculture', 'plants', 'large', 'featured']""",https://www.kaggle.com/bigquery/genomics-cannabis
b'NBA player of the week',b'Player of the week data from 1984-5 to current season [Cur. 2018-9]',"b'### Context\n\nThe idea of making this data set is to explore regular season domination.  \nis seniority / last contract year etc. has an affect on the long run\n\n### Content\n\nNBA_player_of_the_week.csv\n\nColumns:\n\nAge\nConference\nDate [award date]\nDraft Year\nHeight [feet]\nPlayer\nPosition\nSeason  \nSeason short season               \nSeasons in league\nTeam\nWeight [pound]\nReal_value [If two awards given at the same week [East & West] the player got 0.5, else 1 point]\n\n### Acknowledgements\n\nhttps://github.com/jacobbaruch/NBA_scrapping_analysis\nData scrapped from [basketball real gm][1]\n\n\nPhoto by [Ricardo Resende on Unsplash][2]\n\n\n\n  [1]: https://basketball.realgm.com/\n  [2]: https://unsplash.com/photos/HVOwuodWbu0'","b""['sports', 'united states', 'small', 'featured']""",https://www.kaggle.com/jacobbaruch/nba-player-of-the-week
b'SF Employee Compensation',b'From San Francisco Open Data',"b""### Content  \n\nThe San Francisco Controller's Office maintains a database of the salary and benefits paid to City employees since fiscal year 2013. This data is summarized and presented on the Employee Compensation report hosted at http://openbook.sfgov.org, and is also available in this dataset in CSV format. New data is added on a bi-annual basis when available for each fiscal and calendar year.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/UnPhQSAVbdk) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/san-francisco/sf-employee-compensation
b'Open University Learning Analytics Dataset',"b'Course, Student and Assessment Data'","b'### Context\n\nI am working on a Learning Analytics Program Evaluation Framework for a doctoral program that takes into account student course interaction behaviors, performance and satisfaction. Behavior information is gathered from LMS and other ed tech tool analytics. Performance data is gathered from student scores. Satisfaction data is gathered from surveys. \n\nThis old slide deck was the earliest iteration of this research project: [https://www.slideshare.net/rockirussell/d-min-programeval][1]\n\nI was happy to find this dataset provided by Open University that will allow me to play around with anonymized data from outside of my academic context. \n\n### Content\n\nThis dataset offers two of the elements in the framework: behavior and performance. It contains information about 22 courses, 32,593 students, their assessment results, and logs of their interactions with the VLE represented by daily summaries of student clicks (10,655,280 entries).\n\nA thorough description of this data is provided here: https://analyse.kmi.open.ac.uk/open_dataset#description \n\n### Acknowledgements\n\nThis dataset is provided by: Kuzilek J., Hlosta M., Zdrahal Z. Open University Learning Analytics dataset Sci. Data 4:170171 doi: 10.1038/sdata.2017.171 (2017).\n\n### Inspiration\n\nIf you are interested in learning analytics or educational data, please spend some time exploring and manipulating this data. \n\n  [1]: https://www.slideshare.net/rockirussell/d-min-programeval'","b""['education', 'learning', 'medium', 'featured']""",https://www.kaggle.com/rocki37/open-university-learning-analytics-dataset
b'High Resolution Range based Face Database',b'Acquired by a Microsoft Kinect 2',"b'### Context\n\nFace database composed by a set of high resolution range images acquired by the latest generation of range / depth cameras: the Microsoft Kinect 2 (second generation). \n\n### Content\n\nThe database is composed by the faces of 18 people, acquired from different poses: frontal, lateral, etc. Faces have been acquired with and without glasses. The database is structured in different folders as: \n\n* /01: person with identifier 01.\n  * /01/test:  images for testing the person with identifier 01.\n    * /01/test/01_009.png, ..., 03_096.png, ...: images starting with the same identifier as the root folder (01 in this case) are the true/positive samples, while the others are the false/negative samples.\n  * /01/train: images for training the person with identifier 01.\n    * /01/train/01_034.png, ..., 05_g_168.png, ...: images starting with the same identifier as the root folder (01 in this case= are the true/positive samples, while the others are the false/negative samples.\n* /02 \n* /03 \n* /04\n* /04_g: same person as /04, but with glasses.\n* /05\n* ...\n* /18\n\nEvery root folder (01, 02, ...) contains the depth images of one person. The folder name is the identifier of the person (for example 01, 02, etc.). Inside every root folder, there are two sub-folders: test (for testing purposes) and train (for training purposes).\n\n### Citation\n\nT. Mantec\xc3\xb3n, C.R. del Blanco, F. Jaureguizar, N. Garc\xc3\xada, \xe2\x80\x9cVisual Face Recognition using Bag of Dense Derivative Depth Patterns\xe2\x80\x9c, IEEE Signal Processing Letters, vol. 23, no. 6, pp. 771-775, June 2016. (doi: 10.1109/LSP.2016.2553784)'","b""['image data', 'computer science', 'object recognition', 'human-computer interaction', 'medium', 'featured']""",https://www.kaggle.com/gti-upm/hrrfaced
b' Medical Cost Personal Datasets',b'Insurance Forecast by using Linear Regression',"b""## Context\nMachine Learning with R by Brett Lantz is a book that provides an introduction to machine learning using R. As far as I can tell, Packt Publishing does not make its datasets available online unless you buy the book and create a user account which can be a problem if you are checking the book out from the library or borrowing the book from a friend. All of these datasets are in the public domain but simply needed some cleaning up and recoding to match the format in the book.\n\n## Content\n**Columns**\n - age: age of primary beneficiary \n\n - sex: insurance contractor gender, female, male \n\n - bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n            objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9 \n\n - children: Number of    children covered by health insurance / Number of dependents\n\n - smoker: Smoking\n\n - region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n\n - charges: Individual medical costs billed by health insurance\n\n## Acknowledgements\n\nThe dataset is available on GitHub [here](https://github.com/stedy/Machine-Learning-with-R-datasets).\n\n## Inspiration\nCan you accurately predict insurance costs?""","b""['finance', 'healthcare', 'small', 'featured']""",https://www.kaggle.com/mirichoi0218/insurance
b'Austin Animal Center Shelter Outcomes',"b'30,000 shelter animals'","b""### Context\n\nThe Austin Animal Center is the largest no-kill animal shelter in the United States that provides care and shelter to over 18,000 animals each year and is involved in a range of county, city, and state-wide initiatives for the protection and care of abandoned, at-risk, and surrendered animals.\n\nAs part of the City of Austin Open Data Initiative, the Austin Animal Center makes available its collected dataset that contains statistics and outcomes of animals entering the Austin Animal Services system.\n\n### Content\n\nThe dataset contains shelter outcomes of several types of animals and breeds from 10/1/2013 to the present with a hourly time frequency. The data is updated daily. \n\nThe Austin Animal Center's original dataset includes columns for name, date of birth, outcome, animal type, sex and age at time of outcome, breed, and color. Outcomes range widely and include things like adoptions and transfers to other shelters.\n\nFrom a thread in the discussion, here are definitions of some of the outcome types and subtypes:\n\n* Adoption \n  - the animal was adopted to a home\n* Barn Adoption \n  - the animal was adopted to live in a barn\n* Offsite Missing \n  - the animal went missing for unknown reasons at a partner offsite location\n* In-Foster Missing \n  - the animal is missing after being placed in a foster home\n* In-Kennel Missing \n  - the animal is missing after being transferred to a kennel facility\n* Possible Theft \n  - Although not confirmed, the animal went missing as a result of theft from facility\n* Barn Transfer\n  - The animal was transferred to a facility for adoption into a barn environment\n* SNR\n  - SNR refers to the city of Austin's [Shelter-Neuter-Release](http://www.austintexas.gov/blog/changes-made-shelter-neuter-return-cat-program-reflect-community-stakeholder-input) program. I believe the outcome is representative of the animal being released.\n\n### Acknowledgements\n\nThe dataset is provided by the wonderful folks at the Austin Animal Center, the largest no-kill animal shelter in the United States. The AAC makes available the data on the [Austin Open Data Portal](https://data.austintexas.gov/). More information on the dataset can be found one the [Shelter Outcomes page](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Outcomes/9t4d-g238).\n\nA simple script to programmatically extract the Austin Animal Center's shelter outcome dataset through the Socrata Open Data Access (SODA) API can be found as a [Github Gist here](https://gist.github.com/aschleg/54bf7ed55c2383f3ba1f338b8116a77b). The shelter outcomes endpoint is https://data.austintexas.gov/resource/hcup-htgu.json.\n\n### Inspiration\n\nThe dataset was explored in a series of Jupyter Notebooks that end with a pipeline prediction model written in [scikit-learn](http://scikit-learn.org/stable/). The series of notebooks can be viewed here:\n\n* [Part One - Downloading, Cleaning and Feature Engineering the AAC Shelter Outcome dataset](https://aaronschlegel.me/extraction-feature-engineering-aac-data-requests-pandas.html)\n* [Part Two - Exploratory Data Analysis of Shelter Cat Outcomes with Pandas and Seaborn](https://aaronschlegel.me/extraction-feature-engineering-aac-data-requests-pandas.html)\n* [Part Three - Predicting Shelter Cat Adoptions and Transfers with Scikit-learn](https://aaronschlegel.me/predict-shelter-cat-outcomes-scikit-learn-machine-learning.html)\n\nThe inspiration for sharing this dataset and the associated notebooks is to spread awareness and provide another set of data to help support and care for the animals who need it most. By increasing the amount of data and knowledge around best practices and data analysis, those in the animal welfare community can more effectively respond and identify animals that need more support to avoid unwanted outcomes.""","b""['animals', 'small', 'featured']""",https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-outcomes-and
b'NYS Prison Admissions: Beginning 2008',b'From New York State Open Data',"b""### Content  \n\nRepresents inmate admissions to the NYS Department of Corrections and Community Supervision for a new offense or for a parole violation by month of admission.  Includes data about admission type, county, gender, age, and crime.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/qXn5L9BqRbE) by [James Sutton](https://unsplash.com/@jamessutton_photography) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'crime', 'gender', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-prison-admissions-beginning-2008
b'Data Science for Good: DonorsChoose.org',b'Help DonorsChoose.org connect donors with projects they care about',"b""Founded in 2000 by a Bronx history teacher, DonorsChoose.org has raised $685 million for America's classrooms. Teachers at three-quarters of all the public schools in the U.S. have come to DonorsChoose.org to request what their students need, making DonorsChoose.org the leading platform for supporting public education.\n\nTo date, 3 million people and partners have funded 1.1 million DonorsChoose.org projects. But teachers still spend more than a billion dollars of their own money on classroom materials. To get students what they need to learn, the team at DonorsChoose.org needs to be able to connect donors with the projects that most inspire them.\n\nIn the second Kaggle Data Science for Good challenge, DonorsChoose.org, in partnership with Google.org, is inviting the community to help them pair up donors to the classroom requests that will most motivate them to make an additional gift. To support this challenge, DonorsChoose.org has supplied anonymized data on donor giving from the past five years. The winning methods will be implemented in DonorsChoose.org email marketing campaigns. \n\n\n---\n\n##Problem Statement\nDonorsChoose.org has funded over 1.1 million classroom requests through the support of 3 million donors, the majority of whom were making their first-ever donation to a public school. If DonorsChoose.org can motivate even a fraction of those donors to make another donation, that could have a huge impact on the number of classroom requests fulfilled.\n\nA good solution will enable DonorsChoose.org to build targeted email campaigns recommending specific classroom requests to prior donors. Part of the challenge is to assess the needs of the organization, uncover insights from the data available, and build the right solution for this problem. Submissions will be evaluated on the following criteria: \n\n* Performance - How well does the solution match donors to project requests to which they would be motivated to donate? DonorsChoose.org will not be able to live test every submission, so a strong entry will clearly articulate why it will be effective at motivating repeat donations. \n\n* Adaptable - The DonorsChoose.org team wants to put the winning submissions to work, quickly. Therefore a good entry will be easy to implement in production. \n\n* Intelligible - A good entry should be easily understood by the DonorsChoose.org team should it need to be updated in the future to accommodate a changing marketplace. \n\n\n##How to Participate and Make a Submission\n\nTo be considered a participant in the DonorsChoose Data Science for Good Event, there are a few requirements: \n\n- Everyone must register and accept the rules by filling out [this form][1]. This ensures you're a participant and also means you'll receive update emails from us about key deadlines and announcements throughout the event.\n- To submit a kernel for consideration in the main prize track, make sure it's public and [submit it here][2]. [Read more details here][3].\n- To submit a kernel for consideration in the secondary prize track, all you need to do is make sure it's public and be a registered participant before the deadline.\n\n \n##Prizes and Eligibility\n\nThere is a total prize pool of $15,000 split into two tracks:\n\n- Main prize track for the primary event objective: build a recommendation system to match donors to classroom requests ($10,000; five winners total)\n- Upvoted kernels to encourage public sharing of code ($5,000; five winners total)\n\n\nMain Prize Track<br>\nDonorsChoose.org will award $10,000 in total prizes to five winning authors who submit public kernels effectively tackling the objective by the deadline. These kernels must be submitted for consideration by **June 20th, 2018**.\n\nUpvoted Kernels<br>\nThere is also a separate prize track for public sharing of code to encourage ongoing collaboration. Awards of $1,000 each will also be made to authors of the five top most upvoted kernels as of **May 30th, 2018**.\n\nFor more details about the prizes and eligibility [click here][4].\n\n\n\n\n##Timeline\nAll dates are 11:59PM UTC:\n\n - 7 May 2018: Challenge begins\n - 30 May 2018: Kernels Award Announcement (Top 5 upvoted kernels)\n - 20 June 2018: Challenge Deadline (Kernels for main prize must be submitted and made publicly available to be evaluated for a prize)\n - 27 June 2018: Winners of the primary prize track will be announced\n\n##Rules\nTo be eligible to win a prize in either of the above prize tracks, you must be:\n\n - a registered account holder at Kaggle.com;\n - the older of 18 years old or the age of majority in your jurisdiction of residence;\n - not a resident of Crimea, Cuba, Iran, Syria, North Korea, or Sudan; and\n - not a person or representative of an entity under U.S. export controls or sanctions.\n\nYour kernels will only be eligible to win if they have been made public on kaggle.com by the above deadline. All prizes are awarded at the discretion of DonorsChoose.org, and DonorsChoose.org reserves the right to cancel or modify prize criteria.\n\nUnfortunately employees, interns, contractors, officers and directors of Kaggle Inc., and their parent companies, are not eligible to win any prizes. \n\n\n\n  [1]: https://www.kaggle.com/data-science-for-good-donorschoose-signup\n  [2]: https://www.kaggle.com/data-science-for-good-donorschoose-submission\n  [3]: https://www.kaggle.com/donorschoose/io/discussion/56026#latest-323260\n  [4]: https://www.kaggle.com/donorschoose/io/discussion/56026""","b""['education', 'recommender systems', 'crowdfunding', 'marketing analytics', 'marketing', 'large', 'featured']""",https://www.kaggle.com/donorschoose/io
b'International Energy Statistics',b'Global energy trade & production 1990-2014 ',"b'Curious about the growth of wind energy? The extent to which the decline of coal is an American or international trend? Interested in using energy consumption as an alternate method of comparing national economies? This dataset has you covered.\n\nThe Energy Statistics Database contains comprehensive energy statistics on the production, trade, conversion and final consumption of primary and secondary; conventional and non-conventional; and new and renewable sources of energy. \n\n### Acknowledgements\n\nThis dataset was kindly published by the United Nations Statistics Division on the UNData site. You can find [the original dataset here](http://data.un.org/Explorer.aspx).\n\n### License\n[Per the UNData terms of use](http://data.un.org/Host.aspx?Content=UNdataUse): all data and metadata provided on UNdata\xe2\x80\x99s website are available free of charge and may be copied freely, duplicated and further distributed provided that [UNdata](http://data.un.org/Explorer.aspx) is cited as the reference. '","b""['economics', 'energy', 'small', 'featured']""",https://www.kaggle.com/unitednations/international-energy-statistics
b'Google Analytics Sample',b'Google Analytics Sample (BigQuery)',"b'### Context\n\nThe Google Merchandise Store sells Google branded merchandise. The data is typical of what you would see for an ecommerce website.\n\n### Content\n\nThe sample dataset contains Google Analytics 360 data from the Google Merchandise Store, a real ecommerce store. The Google Merchandise Store sells Google branded merchandise. The data is typical of what you would see for an ecommerce website. It includes the following kinds of information:\n\nTraffic source data: information about where website visitors originate. This includes data about organic traffic, paid search traffic, display traffic, etc.\nContent data: information about the behavior of users on the site. This includes the URLs of pages that visitors look at, how they interact with content, etc.\nTransactional data: information about the transactions that occur on the Google Merchandise Store website.\n\nFork [this kernel][1] to get started.\n\n### Acknowledgements\n\nData from: https://bigquery.cloud.google.com/table/bigquery-public-data:google_analytics_sample.ga_sessions_20170801\n\nBanner Photo by [Edho Pratama from Unsplash][2].\n\n\n### Inspiration\n\nWhat is the total number of transactions generated per device browser in July 2017?\n\nThe real bounce rate is defined as the percentage of visits with a single pageview.  What was the real bounce rate per traffic source?\n\n What was the average number of product pageviews for users who made a purchase in July 2017?\n\nWhat was the average number of product pageviews for users who did not make a purchase in July 2017?\n\nWhat was the average total transactions per user that made a purchase in July 2017?\n\nWhat is the average amount of money spent per session in July 2017?\n\n What is the sequence of pages viewed?\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-google-analytics-dataset\n  [2]: https://unsplash.com/photos/yeB9jDmHm6M'","b""['bigquery', 'marketing analytics', 'marketing', 'web sites', 'large', 'featured']""",https://www.kaggle.com/bigquery/google-analytics-sample
b'CMS Order and Referring',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/cms/cms-order-and-referring
b'Historical Air Quality',b'Air Quality Data Collected at Outdoor Monitors Across the US',"b'The AQS Data Mart is a database containing all of the information from AQS. It has every measured value the EPA has collected via the national ambient air monitoring program. It also includes the associated aggregate values calculated by EPA (8-hour, daily, annual, etc.). The AQS Data Mart is a copy of AQS made once per week and made accessible to the public through web-based applications. The intended users of the Data Mart are air quality data analysts in the regulatory, academic, and health research communities. It is intended for those who need to download large volumes of detailed technical data stored at EPA and does not provide any interactive analytical tools. It serves as the back-end database for several Agency interactive tools that could not fully function without it: AirData, AirCompare, The Remote Sensing Information Gateway, the Map Monitoring Sites KML page, etc.\n\nAQS must maintain constant readiness to accept data and meet high data integrity requirements, thus is limited in the number of users and queries to which it can respond. The Data Mart, as a read only copy, can allow wider access.\n\nThe most commonly requested aggregation levels of data (and key metrics in each) are:\n\nSample Values (2.4 billion values back as far as 1957, national consistency begins in 1980, data for 500 substances routinely collected)\nThe sample value converted to standard units of measure (generally 1-hour averages as reported to EPA, sometimes 24-hour averages)\nLocal Standard Time (LST) and GMT timestamps\nMeasurement method\nMeasurement uncertainty, where known\nAny exceptional events affecting the data\nNAAQS Averages\nNAAQS average values (8-hour averages for ozone and CO, 24-hour averages for PM2.5)\nDaily Summary Values (each monitor has the following calculated each day)\nObservation count\nObservation per cent (of expected observations)\nArithmetic mean of observations\nMax observation and time of max\nAQI (air quality index) where applicable\nNumber of observations &gt; Standard where applicable\nAnnual Summary Values (each monitor has the following calculated each year)\nObservation count and per cent\nValid days\nRequired observation count\nNull observation count\nExceptional values count\nArithmetic Mean and Standard Deviation\n1st - 4th maximum (highest) observations\nPercentiles (99, 98, 95, 90, 75, 50)\nNumber of observations &gt; Standard\nSite and Monitor Information\nFIPS State Code (the first 5 items on this list make up the AQS Monitor Identifier)\nFIPS County Code\nSite Number (unique within the county)\nParameter Code (what is measured)\nPOC (Parameter Occurrence Code) to distinguish from different samplers at the same site\nLatitude\nLongitude\nMeasurement method information\nOwner / operator / data-submitter information\nMonitoring Network to which the monitor belongs\nExemptions from regulatory requirements\nOperational dates\nCity and CBSA where the monitor is located\nQuality Assurance Information \nVarious data fields related to the 19 different QA assessments possible\n\n## Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.epa_historical_air_quality.[TABLENAME]`. **[Fork this kernel to get started][1]**.\n\n\n## Acknowledgements\nData provided by the US Environmental Protection Agency [Air Quality System Data Mart](https://www.epa.gov/airdata).\n\n\n  [1]: https://www.kaggle.com/sohier/getting-started-with-big-query'","b""['bigquery', 'pollution', 'large', 'featured']""",https://www.kaggle.com/epa/epa-historical-air-quality
b'SF Notices of Violation (Building Inspection)',b'From San Francisco Open Data',"b""### Content  \n\nThese records indicate the actual violations and comments by the inspector found during the inspection. The data should be sorted on the Complaint Number field and the Item Sequence Number field.  The user should be able to link this file with the Building Complaints dataset (https://data.sfgov.org/d/gm2e-bten) to get a more accurate picture of the violations.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/I8OhOu-wLO4) by [Tirza van Dijk](https://unsplash.com/@tirzavandijk) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/san-francisco/sf-notices-of-violation-building-inspection
b'Chicago Employee Reimbursements',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/45W2fOHWxYo) by [Jonathan Brinkhorst](https://unsplash.com/@jbrinkhorst) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'finance', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-employee-reimbursements
b'Chicago Food Inspections',b'From City of Chicago Open Data',"b""### Content  \n\nNOTE ABOUT 7/1/2018 CHANGE AFFECTING THIS DATASET: http://bit.ly/2yWd2JB --This information is derived from inspections of restaurants and other food establishments in Chicago from January 1, 2010 to the present. Inspections are performed by staff from the Chicago Department of Public Health\xe2\x80\x99s Food Protection Program using a standardized procedure. The results of the inspection are inputted into a database, then reviewed and approved by a State of Illinois Licensed Environmental Health Practitioner (LEHP). For descriptions of the data elements included in this set, go to http://bit.ly/tS9IE8  \r\nDisclaimer: Attempts have been made to minimize any and all duplicate inspection reports. However, the dataset may still contain such duplicates and the appropriate precautions should be exercised when viewing or analyzing these data. The result of the inspections (pass, pass with conditions or fail) as well as the violations noted are based on the findings identified and reported by the inspector at the time of the inspection, and may not reflect the findings noted at other times. For more information about Food Inspections, go to https://www.cityofchicago.org/city/en/depts/cdph/provdrs/healthy_restaurants/svcs/food-protection-services.html.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/E6HjQaB7UEA) by [Dan Gold](https://unsplash.com/@danielcgold) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-food-inspections
b'Powerlifting Database',"b'Over 3,000 meets and 300,000 lifts from competitions worldwide'","b'### Context\n\nThis dataset is a snapshot of the [OpenPowerlifting](http://www.openpowerlifting.org/index.html) database as of February 2018. OpenPowerlifting is an organization which tracks meets and competitor results in the sport of powerlifting, in which competitors complete to lift the most weight for their class in three separate weightlifting categories.\n\n### Content\n\nThis dataset includes two files. `meets.csv` is a record of all meets (competitions) included in the OpenPowerlifting database. `competitors.csv` is a record of all competitors who attended those meets, and the stats and lifts that they recorded at them.\n\nFor more on how this dataset was collected, see the [OpenPowerlifting FAQ](http://www.openpowerlifting.org/faq.html).\n\n### Acknowledgements\n\nThis dataset is republished as-is from the [OpenPowerlifting source](http://www.openpowerlifting.org/data.html).\n\n### Inspiration\n\n* How much influence does overall weight have on lifting capacity?\n* How big of a difference does gender make? What is demographic of lifters more generally?'","b""['weight training', 'small', 'featured']""",https://www.kaggle.com/open-powerlifting/powerlifting-database
b'Twitter data: Pakistan elections 2018',b'Twitter data of tweets related to general election in Pakistan 2018',"b""### Context\n\nGeneral elections in Pakistan are expected to be held on 25th July 2018. Twitter is a known source for analyzing people's behavior and the reason for collecting this data is to let the analysts use this data and analyze. The objective is to get some beneficial insights that can help in predicting the outcome of elections. Of course its not easy but let's try!\n\n### Content\n\nThe data is in JSON format like we get the conventional tweets. The schema is available in the docs [here][1].\n\n### Acknowledgements\n\nThanks to twitter for making their API free and highly simple.\n\n  [1]: https://developer.twitter.com/en/docs""","b""['politics', 'twitter', 'medium', 'featured']""",https://www.kaggle.com/mohdazfar/pakistan-elections-2018
b'NOAA GSOD',b'Daily global surface summary from over 9000 weather stations from 1929 to 2016',"b'## Overview \nGlobal Surface Summary of the Day is derived from The Integrated Surface Hourly (ISH) dataset. The ISH dataset includes global data obtained from the USAF Climatology Center, located in the Federal Climate Complex with NCDC. The latest daily summary data are normally available 1-2 days after the date-time of the observations used in the daily summaries. \n\n## Content\nOver 9000 stations\' data are typically available. \n\nThe daily elements included in the dataset (as available from each station) are: Mean temperature (.1 Fahrenheit) Mean dew point (.1 Fahrenheit) Mean sea level pressure (.1 mb) Mean station pressure (.1 mb) Mean visibility (.1 miles) Mean wind speed (.1 knots) Maximum sustained wind speed (.1 knots) Maximum wind gust (.1 knots) Maximum temperature (.1 Fahrenheit) Minimum temperature (.1 Fahrenheit) Precipitation amount (.01 inches) Snow depth (.1 inches)\n\nIndicator for occurrence of: Fog, Rain or Drizzle, Snow or Ice Pellets, Hail, Thunder, Tornado/Funnel \n\n## Querying BigQuery tables\n\nYou can use the BigQuery Python client library to query tables in this dataset in Kernels. Note that methods available in Kernels are limited to querying data. Tables are at `bigquery-public-data.github_repos.[TABLENAME]`. **[Fork this kernel to get started][99]** to learn how to safely manage analyzing large BigQuery datasets.\n  [99]: https://www.kaggle.com/mrisdal/safely-analyzing-github-projects-popular-licenses\n\n\n## Acknowledgements\n\nThis public dataset was created by the National Oceanic and Atmospheric Administration (NOAA) and includes global data obtained from the USAF Climatology Center.  This dataset covers GSOD data between 1929 and present, collected from over 9000 stations.\nDataset Source: NOAA\n\nUse: This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source \xe2\x80\x94 http://www.data.gov/privacy-policy#data_policy \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nPhoto by Allan Nygren on Unsplash\n'","b""['bigquery', 'weather', 'earth sciences', 'atmospheric sciences', 'large', 'featured']""",https://www.kaggle.com/noaa/gsod
b'TripAdvisor Restaurants Info for 31 Euro-Cities',b'Ratings and reviews for restaurants across 31 European cities',"b""### Context\nThis dataset has been obtained by scraping TA (the famous tourism website) for information about restaurants for a given city.\nThe scraper goes through the restaurants listing pages and fulfills a raw dataset.\nThe raw datasets for the main cities in Europe have been then curated for futher analysis purposes, and aggregated to obtain this dataset.\n\nThe scraper is a Python script, available on the GitHub repository [here][1].\n\nIt uses principally pandas and BeautifulSoup libraries.\n\nIMPORTANT: the restaurants list contains the restaurants that are registrered in the TA database only.  All the restaurants of a city may not be resgistered in this database.\n\n\n### Content\n\nThe dataset contain restaurants information for 31 cities in Europe: Amsterdam (NL),  Athens (GR) , Barcelona (ES) , Berlin (DE), Bratislava (SK), Bruxelles (BE), Budapest (HU), Copenhagen (DK), Dublin (IE), Edinburgh (UK), Geneva (CH), Helsinki (FI), Hamburg (DE), Krakow (PL), Lisbon (PT), Ljubljana (SI), London (UK), Luxembourg (LU), Madrid (ES), Lyon (FR), Milan (IT), Munich (DE), Oporto (PT), Oslo (NO), Paris (FR), Prague (CZ), Rome (IT), Stockholm (SE), Vienna (AT), Warsaw (PL), Zurich (CH).\n\nThe data is a .csv file comma-separated that contains 125 433 entries (restaurants). It is structured as follow:\n- **Name**: name of the restaurant\n\n - **City**: city location of the restaurant\n\n - **Cuisine Style**: cuisine style(s) of the restaurant, in a Python list object (94 046 non-null)\n\n - **Ranking**: rank of the restaurant among the total number of restaurants in the city as a float object (115 645 non-null)\n\n - **Rating**: rate of the restaurant on a scale from 1 to 5, as a float object (115 658 non-null)\n\n - **Price Range**: price range of the restaurant among 3 categories , as a categorical type (77 555 non-null)\n\n - **Number of Reviews**: number of reviews that customers have let to the restaurant, as a float object (108 020 non-null)\n\n - **Reviews**: 2 reviews that are displayed on the restaurants scrolling page of the city, as a list of list object where the first list contains the 2 reviews, and the second le dates when these reviews were written (115 673 non-null)\n\n - **URL_TA**: part of the URL of the detailed restaurant page that comes after 'www.tripadvisor.com' as a string object (124 995 non-null)\n\n - **ID_TA**: identification of the restaurant in the TA database constructed a one letter and a number (124 995 non-null)\n\nMissing information for restaurants (for example unrated or unreviewed restaurants) are in the dataset as NaN (numpy.nan).\n\n\n### Acknowledgements\n\nThis work has been done as a personal interest but also as a training of the skills I got from the DataCamp data science bootcamp I have followed.\n\nI hope you will find this dataset inspiring and will make great stories out of it that I will be pleased to read :)\n\n\n  [1]: https://github.com/dambeneschi/TA_scraper_and_analysis""","b""['food and drink', 'europe', 'small', 'featured']""",https://www.kaggle.com/damienbeneschi/krakow-ta-restaurans-data-raw
b'The Met Public Domain Art Works',"b""The Metropolitan Museum of Art's Public Domain Art Works (BigQuery Dataset)""","b'### Context\n\nThe Metropolitan Museum of Art, better known as the Met, provides a public domain dataset  with over 200,000 objects including metadata and images. In early 2017, the Met debuted their Open Access policy to make part of their collection freely available for unrestricted use under the Creative Commons Zero designation and their own terms and conditions.\n\n### Content\n\n This dataset provides a new view to one of the world\xe2\x80\x99s premier collections of fine art. The data includes both image in Google Cloud Storage, and associated structured data in two BigQuery two tables, objects and images (1:N). Locations to images on both The Met\xe2\x80\x99s website and in Google Cloud Storage are available in the BigQuery table.\n\nFork [this kernel][1] to get started with this dataset.\n\n![](https://cloud.google.com/blog/big-data/2017/08/images/150177792553261/met03.png)\nhttps://cloud.google.com/blog/big-data/2017/08/images/150177792553261/met03.png\n\n### Acknowledgements\n\nhttps://bigquery.cloud.google.com/dataset/bigquery-public-data:the_met\n\nhttps://console.cloud.google.com/launcher/details/the-metropolitan-museum-of-art/the-met-public-domain-art-works\n\nThis dataset is publicly available for anyone to use under the following terms provided by the Dataset Source \xe2\x80\x94 http://www.metmuseum.org/about-the-met/policies-and-documents/image-resources  \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\nBanner Photo by [@danieltong from Unplash][2].\n\n### Inspiration\n\nWhat are the types of art by department?\n\nWhat are the earliest photographs in the collection?\n\nWhat was the most prolific period for ancient Egyptian Art?\n\n\n\n\n\n\n\n\n\n\n  [1]: https://www.kaggle.com/paultimothymooney/starter-kernel-for-met-data\n  [2]: https://unsplash.com/photos/xBeid9r1paU\n\n\n\n\n\n\n\n\n\n\n\n'","b""['visual arts', 'medium', 'featured']""",https://www.kaggle.com/metmuseum/the-met
b'Beer Consumption - Sao Paulo',b'Predict beer consumption',"b'Beer is one of the most democratic and consumed drinks in the world. Not without reason, it is perfect for almost every situation, from happy hour to large wedding parties. If you just think about it, you already feel like having a beer, you\xe2\x80\x99re not alone.\nThe truth is that around the world, thousands of people consume the drink regularly and also in different situations. But have you ever stopped to think about which countries are the most consuming beer in the world? The first one that came to your head was Germany? Well, know that it is not so.\nThe answer to that question is resounding: the Czech Republic. According to research by the Japanese beverage company Kirin, the country has topped the per capita beer drinking table for 23 consecutive years.\nIn 2015, the most recent year for which statistics are available, the Czechs drank 142.4 litres per person. That\xe2\x80\x99s the equivalent of 250 pints\xe2\x80\x8a\xe2\x80\x94\xe2\x80\x8aor one every 35 hours. But, given that minors are unlikely to be contributing to that figure, it\xe2\x80\x99s safe to assume that the average beer drinker probably guzzles quite a bit more.\nSnapping at the Czech Republic\xe2\x80\x99s heels are the usual pretenders. Austria and Germany come third and fourth, Poland sixth and Ireland seventh.There are some surprises, however. In second place is the Seychelles, a lofty ranking which we\xe2\x80\x99ll put down to the hot climate and the large number of holidaymakers. \n\n**The data (sample) were collected in S\xc3\xa3o Paulo\xe2\x80\x8a\xe2\x80\x94\xe2\x80\x8aBrazil, in a university area, where there are some parties with groups of students from 18 to 28 years of age (average).\n The dataset used for this activity has 7 attributes, being a Target, with period of one year.**'","b""['beginner', 'linear regression', 'small', 'featured']""",https://www.kaggle.com/dongeorge/beer-consumption-sao-paulo
b'Crimes in Boston',"b'More than 2,60,760 crimes in Boston (2015- 2018)'","b'\n**Context-**\n\nThis is a dataset containing records from the new crime incident report system, which includes a reduced set of fields focused on capturing the type of incident as well as when and where it occurred.\n\n**Content-**\n\nThis dataset has 2,60,760 rows and 17 columns.\n\n - INCIDENT_NUMBER: \n - OFFENSE_CODE:\n - OFFENSE_CODE_GROUP:\n - OFFENSE_DESCRIPTION:\n - DISTRICT:\n - REPORTING_AREA:\n - SHOOTING:\n - OCCURRED_ON_DATE:\n - YEAR:\n - MONTH:\n - DAY_OF_WEEK:\n - HOUR:\n - UCR_PART:\n - STREET:\n - LATITUDE:\t\n - LONGITUDE:\n - LOCATION:\n\n**Acknowledgements-**\n\nI would like to thank the Boston Police Department for making this dataset available to everyone.\n\n**Inspiration**\n\n1.\tHow has crime changed over the years?\n2.\tIs it possible to predict where or when a crime will be committed?\n3.\tWhich areas of the city have evolved over this time span?\n4.\tIn which area most crimes are committed?\n'","b""['crime', 'united states', 'medium', 'featured']""",https://www.kaggle.com/ankkur13/boston-crime-data
b'CMS Estimated Uninsured People',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: NA""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/cms-estimated-uninsured-people
b'Oakland PD Calls for Service 1/2013 to 10/2015',b'Explore open data from the city of Oakland',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of Oakland in California. The organization has an open data platform found [here](data.oaklandnet.com) and they update their information according to the amount of data that is brought in. Explore Oakland's Data using Kaggle and all of the data sources available through the city of Oakland [organization page](https://www.kaggle.com/cityofoakland)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofoakland/oakland-pd-calls-for-service-1-2013-to-10-2015
b'NSE Stocks Data',b'The data is of National Stock Exchange of India for 2016 and 2017',"b""### Context\n\nThe data is of National Stock Exchange of India.\nThe data is compiled to felicitate Machine Learning, without bothering much about Stock APIs.\n\n### Content\n\nThe data is of National Stock Exchange of India's stock listings for each trading day of 2016 and 2017.\nA brief description of columns.\nSYMBOL: Symbol of the listed company. \nSERIES: Series of the equity. Values are [EQ, BE, BL, BT, GC and IL] \nOPEN: The opening market price of the equity symbol on the date. \nHIGH: The highest market price of the equity symbol on the date. \nLOW: The lowest recorded market price of the equity symbol on the date. \nCLOSE: The closing recorded price of the equity symbol on the date. \nLAST: The last traded price of the equity symbol on the date. \nPREVCLOSE: The previous day closing price of the equity symbol on the date. \nTOTTRDQTY: Total traded quantity of the equity symbol on the date. \nTOTTRDVAL: Total traded volume of the equity symbol on the date. \nTIMESTAMP: Date of record. \nTOTALTRADES: Total trades executed on the day. \nISIN: International Securities Identification Number. \n\n### Acknowledgements\n\nAll data is fetched from NSE official site. \nhttps://www.nseindia.com/\n\n\n### Inspiration\n\nThis dataset is compiled to felicitate Machine learning on Stocks.""","b""['strategy', 'medium', 'featured']""",https://www.kaggle.com/minatverma/nse-stocks-data
b'Seattle Crisis Data',b'From City of Seattle Open Data',"b""### Content  \n\nData representing crisis contacts made by officers of the Seattle Police Department. Data is denormalized to represent the one to many relationship between the record and the reported disposition of the contact. \r\n\r\n**USE CAUTION WHEN COUNTING**  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-crisis-data
b'goodbooks-10k',"b'Ten thousand books, one million ratings. Also books marked to read, and tags.'","b'**This version of the dataset is obsolete. It contains duplicate ratings (same user_id,book_id), as reported by Philipp Spachtholz in his illustrious notebook.**\n\n**The current version has duplicates removed, and more ratings (six million), sorted by time. Book and user IDs are the same.** \n\n**It is available at https://github.com/zygmuntz/goodbooks-10k.**\n\n---\n\nThere have been good datasets for movies (Netflix, Movielens) and music (Million Songs) recommendation, but not for books. That is, until now. \n\nThis dataset contains ratings for ten thousand popular books. As to the source, let\'s say that these ratings were found on the internet. Generally, there are 100 reviews for each book, although some have less - fewer - ratings. Ratings go from one to five.\n\nBoth book IDs and user IDs are contiguous. For books, they are 1-10000, for users, 1-53424. All users have made at least two ratings. Median number of ratings per user is 8.\n\nThere are also books marked to read by the users, book metadata (author, year, etc.) and tags.\n\n## Contents\n\n**ratings.csv** contains ratings and looks like that:\n\n\tbook_id,user_id,rating\n\t1,314,5\n\t1,439,3\n\t1,588,5\n\t1,1169,4\n\t1,1185,4\n\n**to_read.csv** provides IDs of the books marked ""to read"" by each user, as **user_id,book_id** pairs.\n\n**books.csv** has metadata for each book (goodreads IDs, authors, title, average rating, etc.).\n\nThe metadata have been extracted from goodreads XML files, available in the third version of this dataset as **books_xml.tar.gz**. The archive contains 10000 XML files. One of them is available as **sample_book.xml**. To make the download smaller, these files are absent from the current version. Download version 3 if you want them.\n\n**book_tags.csv** contains tags/shelves/genres assigned by users to books. Tags in this file are represented by their IDs.\n\n**tags.csv** translates tag IDs to names.\n\nSee the [notebook][1] for some basic stats of the dataset.\n\n### goodreads IDs\n\nEach book may have many editions.  **goodreads_book_id** and **best_book_id** generally point to the most popular edition of a given book, while goodreads  **work_id** refers to the book in the abstract sense.\n\nYou can use the goodreads book and work IDs to create URLs as follows:\n\nhttps://www.goodreads.com/book/show/2767052   \nhttps://www.goodreads.com/work/editions/2792775\n\n  [1]: https://github.com/zygmuntz/misc/blob/master/goodbooks-10k/basic_stats.ipynb'","b""['books', 'medium', 'featured']""",https://www.kaggle.com/zygmunt/goodbooks-10k
b'Democrat Vs. Republican Tweets',b'200 tweets of Dems and Reps',"b'### Context\n\nTwitter give the general public unfiltered direct access to the ideas and policies of politicians. This means that understanding the content and reach of these tweets can help us understand what connects with constituents. This dataset is meant to help with that exploration. By applying sentiment analysis (using an already trained system) we can apply sentiment context to these tweets. This will help us understand who responds to positive and negative content. Finally this analysis may help to indentify fake or hyperbole polarized Twitter users. \n\n\n### Content\n\nThe dataset contains two files both in .csv format.  The first is a list of the political party and the representative handles, and the second are the 200 latest tweets as of May 2018 from those twitter users.\n\n### Acknowledgements\n\nI would like to thank the following website and people who helped me get started\n\n### Inspiration\n\nI was first inspired by trying to find out if the average person would be able to distinguish between political tweets of no context was given. I made a small website that you can try this on. I will use real user data to cross check and see if ML methods are actually better than the average person. \n\nOther ace uses are the following:\nCan we use this to detect Russian troll twitter accounts?\nDo people respond to negative or positive political tweets?\n'","b""['internet', 'linguistics', 'politics', 'small', 'featured']""",https://www.kaggle.com/kapastor/democratvsrepublicantweets
b'Taxi Trajectory Data',b'Data from ECML/PKDD 15: Taxi Trip Time Prediction (II) Competition',"b'### Context\n\nTechnology has many effects on the transportation industry.\n\n### Content\n\nWe have provided an accurate dataset describing a complete year (from 01/07/2013 to 30/06/2014) of the trajectories for all the 442 taxis running in the city of Porto, in Portugal (i.e. one CSV file named ""train.csv""). These taxis operate through a taxi dispatch central, using mobile data terminals installed in the vehicles. We categorize each ride into three categories: A) taxi central based, B) stand-based or C) non-taxi central based. For the first, we provide an anonymized id, when such information is available from the telephone call. The last two categories refer to services that were demanded directly to the taxi drivers on a B) taxi stand or on a C) random street.\n\nEach data sample corresponds to one completed trip. It contains a total of\n9 (nine) features, described as follows:\n\n\n -  TRIP_ID: (String) It contains an unique identifier for each trip;\n    \n - CALL_TYPE: (char) It identifies the way used to demand this service. It may contain one of three possible values:\n        \xe2\x80\x98A\xe2\x80\x99 if this trip was dispatched from the central;\n        \xe2\x80\x98B\xe2\x80\x99 if this trip was demanded directly to a taxi driver on a specific stand;\n        \xe2\x80\x98C\xe2\x80\x99 otherwise (i.e. a trip demanded on a random street).\n   \n - ORIGIN_CALL: (integer) It contains an unique identifier for each phone number which was used to demand, at least, one service. It identifies the trip\xe2\x80\x99s customer if CALL_TYPE=\xe2\x80\x99A\xe2\x80\x99. Otherwise, it assumes a NULL value;\n  \n -  ORIGIN_STAND: (integer): It contains an unique identifier for the taxi stand. It identifies the starting point of the trip if CALL_TYPE=\xe2\x80\x99B\xe2\x80\x99. Otherwise, it assumes a NULL value;\n   \n - TAXI_ID: (integer): It contains an unique identifier for the taxi driver that performed each trip;\n   \n -  TIMESTAMP: (integer) Unix Timestamp (in seconds). It identifies the trip\xe2\x80\x99s start; \n   \n -  DAYTYPE: (char) It identifies the daytype of the trip\xe2\x80\x99s start. It assumes one of three possible values:\n        \xe2\x80\x98B\xe2\x80\x99 if this trip started on a holiday or any other special day (i.e. extending holidays, floating holidays, etc.);\n        \xe2\x80\x98C\xe2\x80\x99 if the trip started on a day before a type-B day;\n        \xe2\x80\x98A\xe2\x80\x99 otherwise (i.e. a normal day, workday or weekend).\n   \n - MISSING_DATA: (Boolean) It is FALSE when the GPS data stream is complete and TRUE whenever one (or more) locations are missing\n    \n - POLYLINE: (String): It contains a list of GPS coordinates (i.e. WGS84 format) mapped as a string. The beginning and the end of the string are identified with brackets (i.e. [ and ], respectively). Each pair of coordinates is also identified by the same brackets as [LONGITUDE, LATITUDE]. This list contains one pair of coordinates for each 15 seconds of trip. The last list item corresponds to the trip\xe2\x80\x99s destination while the first one represents its start;\n\n\nThe total travel time of the trip (the prediction target of this competition) is defined as the (number of points-1) x 15 seconds. For example, a trip with 101 data points in POLYLINE has a length of (101-1) * 15 = 1500 seconds. Some trips have missing data points in POLYLINE, indicated by MISSING_DATA column, and it is part of the challenge how you utilize this knowledge. \n\n\n### Acknowledgements\n\nData from ECML/PKDD 15: Taxi Trip Time Prediction (II) Competition\n\n\n### Inspiration\n\nAdded this dataset because competition datasets do not appear in the dataset search and this dataset could help learn basic \nmethods in the area of geo-spatial analysis and trajectory handling'","b""['data visualization', 'data cleaning', 'geospatial analysis', 'geography', 'databases', 'medium', 'featured']""",https://www.kaggle.com/crailtap/taxi-trajectory
"b""ICO's Crop Data""","b'Which country produces, consumes and exports coffee the most?'","b""### Context and Data Ownership\n\nThis is a historical dataset summarising annual reports gathered by International Coffee Organisation for 56 member state countries from 1990 to 2017. ICO is the main intergovernmental organisation for coffee market, representing almost entire coffee production market and two-thirds of coffee consumption.\n\nThe original data is available at International Coffee Organization's [website](http://www.ico.org/coffee_prices.asp). I wrangled raw data in this [notebook](https://www.kaggle.com/sbajew/ico-coffee-crop-data-data-wrangling).\n\nFor an overview of this dataset, see [my kernel](https://www.kaggle.com/sbajew/exploring-coffee-production-and-consumption).\n\n### Content\n\nThis dataset summarises four annual reports submitted by the Member states of ICO from 1990 to 2017.\nBy the end of each crop year, a member state reports on Total Production, Domestic Consumption, Exportable production \nand Gross Opening Stocks. The values represent **thousand 60 kg bags of green coffee** (not roasted), unless specified otherwise.\n\nThe columns in this dataset represent:\n\n1. COUNTRY- Member state of ICO; there are 56 countries in this dataset\n2. YEAR- Crop year for which the data was collected\n3. MONTH- Month of crop harvest\n4. TOTAL_PRODUCTION - total coffee production in a member state per year\n5. DOMESTIC_CONSUMPTION - coffee consumption in a member state per year\n6. EXPORTABLE_PRODUCTION - amount of coffee dedicated for exports per year, essentially the difference between Total Production and Domestic Consumption\n7. GROSS_OPENING_STOCKS - amount of coffee held at the end of each crop year for the next accounting year\n\n### Motivation\n\nAs a coffee lover/addict, I never explored coffee behind the scenes, before it ends up in my cup of a perfect brew. That is, until I found ICO's website! This dataset offers unique insights of coffee market from 1990 to 2017 in most of coffee producing countries around the world. I hope it will be used to explore global trends in coffee production and domestic consumption of coffee producing countries and also to make valuable predictions of those. ""","b""['food and drink', 'databases', 'government agencies', 'research', 'small', 'featured']""",https://www.kaggle.com/sbajew/icos-crop-data
"b""STC ML School 2018's Sound Classification dataset""",b'More than 3k .wav files divided into classes.',"b""### Context\n\nThis dataset was used at STC ML School 2018 qualifiers.\n\n\n### Content\nThere are 3660 .wav files that you could use to train the model.  \nAlso there is test dataset with around 400 predicted and 200 unknown files.  \n\n### Acknowledgements\n\n**Second place solution**  \nI've used VGGish + BN to solve this task with Adamax instead of Adam that resulted in **95.77 %** accuracy on marked testset.\n""","b""['classification', 'multiclass classification', 'signal processing', 'large', 'featured']""",https://www.kaggle.com/l4morak/soundclas-stcml
b'Chicago 311 Service Requests',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'vehicles', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-311-service-requests
b'Los Angeles Metro Bike Share Trip Data',b'From Los Angeles Open Data',"b""### Content  \n\nBike Share data from LA Metro, pulled from https://bikeshare.metro.net/about/data/  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/bI2j1olMXUA) by [Andrew Ruiz](https://unsplash.com/@andrewruiz) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-metro-bike-share-trip-data
b'Department of Justice 2009-2018 Press Releases',"b'Contains title, date, topics, and text of records'","b'# Context\nThis is a historical dataset containing 13,087 press releases from the Department of Justice\'s (DOJ) website https://www.justice.gov/news. The DOJ typically publishes several releases per day and this dataset spans from 2009 to July 2018. The releases contain information such as outcomes of criminal cases, notable actions taken against felons, or other updates about the current administration.  This dataset only includes releases categorized as ""Press release"" and does not contain those which have been labeled as ""Speeches"".  Some releases are tagged with topics or related agencies.\n\nThe original Python code to scrape the data can be found on GitHub at https://github.com/jbencina/dojreleases\n\n# Content\nThe contents are stored as newline delimited JSON records with the following fields:\n\n - **id**: Press release number (can be missing if included in contents)\n - **title**: Title of release\n - **contents**: Text of release\n - **date**: Posted date\n - **topics**: Array of topic tags (if any provided)\n - **components**: Array of agencies & departments (if any provided)\n\n# Acknowledgements\nAll data was sourced from https://www.justice.gov/news\n\n# Inspiration\nThe data provides an opportunity for analysis including:\n\n - How have the reported topics changed over the years / administrations?\n - What words tend occur frequently together?\n - How can documents be clustered using the content of the releases?\n - Can a predictive text model be trained off the supplied topics?\n - Use a tool like [Spacy][1] to handle named entities in the releases (names, locations, etc.)\n\n\n  [1]: https://spacy.io/usage/linguistic-features#section-named-entities'","b""['nlp', 'crime', 'politics', 'text data', 'medium', 'featured']""",https://www.kaggle.com/jbencina/department-of-justice-20092018-press-releases
b'SF Air Traffic Passenger and Landings Statistics',b'From San Francisco Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-air-traffic-passenger-and-landings-statistics
b'Sentiment Labelled Sentences Data Set ',"b'From Group to Individual Labels using Deep Features, Kotzias et. al,. KDD 2015'","b""### Context\n\nOpinion mining (sometimes known as sentiment analysis or emotion AI) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information.  Source: https://en.wikipedia.org/wiki/Sentiment_analysis\n\n### Content\n\nThis dataset was created for the Paper 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015  \n\nIt contains sentences labelled with a positive or negative sentiment. \n\n**Format:**\n\nsentence score \n\n**Details:**\n\nScore is either 1 (for positive) or 0 (for negative)\t\nThe sentences come from three different websites/fields: \n\nimdb.com \namazon.com \nyelp.com \n\nFor each website, there exist 500 positive and 500 negative sentences. Those were selected randomly for larger datasets of reviews. \nWe attempted to select sentences that have a clearly positive or negative connotaton, the goal was for no neutral sentences to be selected. \n\n\nAmazon: contains reviews and scores for products sold on amazon.com in the cell phones and accessories category,\nand is part of the dataset collected by McAuley and Leskovec. Scores are on an integer scale from 1 to 5. We considered reviews with a score of 4 and 5 to be positive, and scores of 1 and 2 to be negative. We randomly partitioned the data into two halves of 50%, one for training and one for testing, with 35,000 documents in each set.\n\nIMDb: refers to the IMDb movie review sentiment dataset originally introduced by Maas et al. as a benchmark for\nsentiment analysis. This dataset contains a total of 100,000 movie reviews posted on imdb.com. There are 50,000 unlabeled\nreviews and the remaining 50,000 are divided into a set of 25,000 reviews for training and 25,000 reviews for\ntesting. Each of the labeled reviews has a binary sentiment label, either positive or negative. In our experiments, we\ntrain only on the labelled part of the training set.\n\nYelp: refers to the dataset from the Yelp dataset challenge from which we extracted the restaurant reviews. Scores\nare on an integer scale from 1 to 5. We again considered reviews with scores 4 and 5 to be positive, and 1 and 2 to\nbe negative. We randomly generated a 50-50 training and testing split, which led to approximately 300,000 documents\nfor each set. Sentences: for each of the datasets above, we extracted and manually labeled 1000 sentences from the test set, with 50% positive sentiment and 50% negative sentiment. These sentences are only used to evaluate our instance-level classi-\nfier for each dataset3. They are not used for model training, to maintain consistency with our overall goal of learning at\na group level and predicting at the instance level.\n\nSource: http://mdenil.com/media/papers/2015-deep-multi-instance-learning.pdf\n\n### Acknowledgements\n\nDimitrios Kotzias dkotzias '@' ics.uci.edu\n\nhttp://mdenil.com/media/papers/2015-deep-multi-instance-learning.pdf\nhttps://www.researchgate.net/publication/299970579_From_Group_to_Individual_Labels_Using_Deep_Features\n\nBanner photo by [@rvignes from Unsplash][1].\n\n# Inspiration\n\nCan you predict the sentiment of a sentence?\n\n\n  [1]: https://unsplash.com/photos/ywqa9IZB-dU\n""","b""['classification', 'linguistics', 'languages', 'naive bayes', 'small', 'featured']""",https://www.kaggle.com/marklvl/sentiment-labelled-sentences-data-set
b'NY Bus Breakdown and Delays',b'From New York City Open Data',"b""### Content  \n\nThe Bus Breakdown and Delay system collects information from school bus vendors operating out in the field in real time. Bus staff that encounter delays during the route are instructed to radio the dispatcher at the bus vendor\xe2\x80\x99s central office. The bus vendor staff are then instructed to log into the Bus Breakdown and Delay system to record the event and notify OPT. OPT customer service agents use this system to inform parents who call with questions regarding bus service. The Bus Breakdown and Delay system is publicly accessible and contains real time updates. All information in the system is entered by school bus vendor staff.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/DaLstmw0r9Y) by [chuttersnap](https://unsplash.com/@chuttersnap) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-bus-breakdown-and-delays
b'NYC Trade Waste Hauler Licensees',b'From New York City Open Data',"b'### Content  \n\nThe following companies have been issued trade waste removal licenses by the Business Integrity Commission and, therefore, are authorized to collect and remove all types of trade waste covered by Local Law 42 of 1996.\r\n\r\n""This data is collected on the entities that apply with the commission to operate as Licensees. \r\n\r\nEach record represents an entity that is approved to operate in the City of New York by the Commission. \r\n\r\nThe  Application Type field denotes the class of application \'License\'  noting the type of applicant which is a Licensee. They are able to pickup all trade waste from various businesses throughout the city.\r\n\r\nThe BIC Number field is unique to every company that applies to the Commission. ""  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/oMozEtmklGU) by [Ayotunde Oguntoyinbo](https://unsplash.com/@karptein) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-trade-waste-hauler-licensees
b'Boat types recognition',"b'About 1,500 pictures of boats classified in 9 categories'","b""### Context\n\nThis dataset is used on this blog post https://clorichel.com/blog/2018/11/10/machine-learning-and-object-detection/ where you'll train an image recognition model with TensorFlow to find about anything on pictures and videos.\n\n\n### Content\n\nYou'll find about 1,500 pictures of boats, of various sizes, but classified by those different types: buoy, cruise ship, ferry boat, freight boat, gondola, inflatable boat, kayak, paper boat, sailboat.\n\n\n### Acknowledgements\n\nThanks to [Pixabay](https://pixabay.com/) and its community for the amazing royalty free stock photos.""","b""['classification', 'image data', 'multiclass classification', 'photography', 'medium', 'featured']""",https://www.kaggle.com/clorichel/boat-types-recognition
b'BRFSS: Tobacco Use Data',b'Explore Open Data from the Centers for Disease Control',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Disease Control and Prevention. The organization has an open data platform found [here](https://data.cdc.gov) and they update their information according the amount of data that is brought in. Explore CDC Data using Kaggle and all of the data sources available through the CDC [organization page](https://www.kaggle.com/cdc)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/32TrhvwKhu0) by [KAIBING FAN](https://unsplash.com/@fanklin) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: NA""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cdc/brfss-tobacco-use-data
b'Gun Violence Data',b'Comprehensive record of over 260k US gun violence incidents from 2013-2018',"b'### Context\n\nThere\'s currently a lack of large and easily-accessible amounts of detailed data on gun violence. \n\n### Content\n\nThis project aims to change that; we make a record of more than 260k gun violence incidents, with detailed information about each incident, available in CSV format. We hope that this will make it easier for data scientists and statisticians to study gun violence and make informed predictions about future trends.  \n\nThe CSV file contains data for all recorded gun violence incidents in the US between January 2013 and March 2018, inclusive.\n\n### Acknowledgements\n\n**Where did you get the data?**\n\nThe data was downloaded from [gunviolencearchive.org](http://www.gunviolencearchive.org/). From the organization\'s description:\n\n&gt; Gun Violence Archive (GVA) is a not for profit corporation formed in 2013 to provide free online public access to accurate information about gun-related violence in the United States. GVA will collect and check for accuracy, comprehensive information about gun-related violence in the U.S. and then post and disseminate it online.\n\n**How did you get the data?**\n\nBecause GVA limits the number of incidents that are returned from a single query, and because the website\'s ""Export to CSV"" functionality was missing crucial fields, it was necessary to obtain this dataset using web scraping techniques.\n\n**Stage 1:** For each date between 1/1/2013 and 3/31/2018, a Python script queried all incidents that happened at that particular date, then scraped the data and wrote it to a CSV file. Each month got its own CSV file, with the exception of 2013, since not many incidents were recorded from then.\n\n**Stage 2:** Each entry was augmented with additional data not directly viewable from the query results page, such as participant information, geolocation data, etc.\n\n**Stage 3:** The entries were sorted in order of increasing date, then merged into a single CSV file.\n\n\n### Inspiration\n\nI believe there are plenty of ways this dataset can be put to good use. If you have an interesting idea or feel like messing around with the data, then go for it.\n\nI was originally inspired to compile it in the wake of the Parkland shooting and the mass media coverage that followed. Reports like [this](https://heavy.com/news/2018/02/nikolas-cruz-florida-instagram-nicolas-nicholas-social-media/) and [this](https://www.nytimes.com/2018/02/17/us/nikolas-cruz-florida-shooting.html) showed that Nikolas Cruz had exhibited plenty of warning signs on social media before the shooting; what if we could build a machine learning system that preemptively detected such signs?'","b""['crime', 'law', 'violence', 'social sciences', 'medium', 'featured']""",https://www.kaggle.com/jameslko/gun-violence-data
b'Colorectal Histology MNIST',b'Collection of textures in colorectal cancer histology',"b'# Overview\n\nThe dataset serves as a much more interesting MNIST or CIFAR10 problem for biologists by focusing on histology tiles from patients with colorectal cancer. In particular, the data has 8 different classes of tissue (but Cancer/Not Cancer can also be an interesting problem).\n\n## Challenge\n- Classify tiles correctly into one of the eight classes\n- Which classes are most frequently confused? \n- What features can be used (like texture, see scikit-image) to improve classification?\n- How can these models be applied to the much larger 5000x5000 models? How can this be done efficiently?\n\n\n## Acknowledgements\nThe dataset has been copied from Zenodo: https://zenodo.org/record/53169#.W6HwwP4zbOQ with [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.53169.svg)](https://doi.org/10.5281/zenodo.53169)\n\n made by: Kather, Jakob Nikolas; Z\xc3\xb6llner, Frank Gerrit; Bianconi, Francesco; Melchers, Susanne M; Schad, Lothar R; Gaiser, Timo; Marx, Alexander; Weis, Cleo-Aron\n\nThe copy here is to make it more accessible to Kaggle users and allow kernels providing basic analysis of the data\n\n## Content\n\nThis data set represents a collection of textures in histological images of human colorectal cancer. It contains two files:\n\n""Kather_texture_2016_image_tiles_5000.zip"": a zipped folder containing 5000 histological images of 150 * 150 px each (74 * 74 \xc2\xb5m). Each image belongs to exactly one of eight tissue categories (specified by the folder name). \n""Kather_texture_2016_larger_images_10.zip"": a zipped folder containing 10 larger histological images of 5000 x 5000 px each. These images contain more than one tissue type. \nImage format\n\nAll images are RGB, 0.495 \xc2\xb5m per pixel, digitized with an Aperio ScanScope (Aperio/Leica biosystems), magnification 20x. Histological samples are fully anonymized images of formalin-fixed paraffin-embedded human colorectal adenocarcinomas (primary tumors) from our pathology archive (Institute of Pathology, University Medical Center Mannheim, Heidelberg University, Mannheim, Germany).\n\n## Ethics statement\n\nAll experiments were approved by the institutional ethics board (medical ethics board II, University Medical Center Mannheim, Heidelberg University, Germany; approval 2015-868R-MA). The institutional ethics board waived the need for informed consent for this retrospective analysis of anonymized samples. All experiments were carried out in accordance with the approved guidelines and with the Declaration of Helsinki.\n\n## More information / data usage\n\nFor more information, please refer to the following article. Please cite this article when using the data set.\n\nKather JN, Weis CA, Bianconi F, Melchers SM, Schad LR, Gaiser T, Marx A, Zollner F: Multi-class texture analysis in colorectal cancer histology (2016), Scientific Reports (in press)\n\n## Contact\n\nFor questions, please contact:\nDr. Jakob Nikolas Kather\nhttp://orcid.org/0000-0002-3730-5348\nResearcherID: D-4279-2015'","b""['image data', 'oncology and cancer', 'medium', 'featured']""",https://www.kaggle.com/kmader/colorectal-histology-mnist
b'NJ Transit + Amtrak (NEC) Rail Performance',b'Granular performance data from 150k+ NJ Transit and Amtrak train trips',"b'### Context\n\nNJ Transit is the second largest commuter rail network in the United States by ridership; it spans New Jersey and connects the state to New York City. On the Northeast Corridor, the busiest passenger rail line in the United States, Amtrak also operates passenger rail service; together, NJ Transit and Amtrak operate nearly 750 trains across the [NJ Transit rail network](https://www.njtransit.com/pdf/rail/Rail_System_Map.pdf). \n\nDespite serving over 300,000 riders on the average weekday, no granular, trip-level performance data is publicly available for the NJ Transit rail network or Amtrak. This datasets aims to publicly provide such data. \n\n### Content\n\nThis dataset contains monthly CSVs covering the performance of nearly every train trip on the NJ Transit rail network.\n\nAs of October 14, 2018:\n\n - Stop-level, minute resolution data on 156,000+ train trips (137,000+ NJ Transit trips, 19,000+ Amtrak trips)\n - Coverage from March 1, 2018 to Sep 30, 2018 (updated monthly)\n - Transparent reporting on train trips for which data was missing/invalid, or that were scraped or parsed incorrectly (98.6% of train trips were correctly captured)\n\nSince February of 2018, I have been running a scraper that gathers stop-level, minute resolution data for NJ Transit and Amtrak train trips operating on the NJ Transit rail network. This scraper gathers data every minute from the NJ Transit [DepartureVision](https://dv.njtransit.com/webdisplay/tid-mobile.aspx?sid=NY) Real Time Train Status service. The raw, timestamped train status pages are stored in a data lake and then parsed into tabular form; the parser is implemented as a state machine.\n\nFor more details on these processes and ancillary meta data (such as schedules and station locations) from the [NJ Transit Developer Portal](https://www.njtransit.com/mt/mt_servlet.srv?hdnPageAction=MTDevLoginTo), check out the project [GitHub repo](https://github.com/pranavbadami/njtransit).\n\n### Inspiration\n\nLots of interesting, high-impact projects could be driven by this data:\n\n- Robust prediction: This data could be used to derive a system-level prediction system for the NJ Transit network. Such a system could provide intelligent, targeted advance warnings of delays or cancellations for millions of riders.\n- Combining datasets: Weather data and [service alert data](https://twitter.com/NJTRANSIT_NEC) could be incorporated to look at the effect of weather events and analyze the impacts of specific kinds of service interruptions.\n- Data visualization: Visualizing this data could provide robust insight into the system-level mechanics of the NJ Transit rail network, as well as more engaging reporting on NJ Transit.\n\nFor some more inspiration, you can check out Medium articles written by Michael Zhang and me with this data:\n\n1. [The 5 Stages of a System Breakdown on NJ Transit](https://towardsdatascience.com/the-5-stages-of-a-system-breakdown-on-nj-transit-8258127e31e9)\n2. [What are the chances that NJ Transit will cause you to miss the Dinky?](https://medium.com/@mzhang13/what-are-the-chances-that-nj-transit-will-cause-you-to-miss-the-dinky-bfeacd11ebc6)\n3. [How data can help fix NJ Transit](https://medium.com/@mzhang13/what-are-the-chances-that-nj-transit-will-cause-you-to-miss-the-dinky-bfeacd11ebc6)\n\n### Acknowledgements\n\nA special thanks to Michael Zhang for his valuable work on using and preparing this data, as well as general support throughout the project.'","b""['tabular data', 'transport', 'public transport', 'rail transport', 'timelines', 'medium', 'featured']""",https://www.kaggle.com/pranavbadami/nj-transit-amtrak-nec-performance
b'NYS NYSERDA Low-to-Moderate-Income Census Populat',b'From New York State Open Data',"b""### Content  \n\nThe Low- to Moderate-Income (LMI) New York State (NYS) Census Population Analysis dataset is resultant from the LMI market database designed by APPRISE as part of the NYSERDA LMI Market Characterization Study (https://www.nyserda.ny.gov/lmi-tool).  All data are derived from the U.S. Census Bureau\xe2\x80\x99s American Community Survey (ACS) 1-year Public Use Microdata Sample (PUMS) files for 2013, 2014, and 2015.  \n\nEach row in the LMI dataset is an individual record for a household that responded to the survey and each column is a variable of interest for analyzing the low- to moderate-income population. \n\nThe LMI dataset includes: county/county group, households with elderly, households with children, economic development region, income groups, percent of poverty level, low- to moderate-income groups, household type, non-elderly disabled indicator, race/ethnicity, linguistic isolation, housing unit type, owner-renter status, main heating fuel type, home energy payment method, housing vintage, LMI study region, LMI population segment, mortgage indicator, time in home, head of household education level, head of household age, and household weight. \n\nThe LMI NYS Census Population Analysis dataset is intended for users who want to explore the underlying data that supports the LMI Analysis Tool.  The majority of those interested in LMI statistics and generating custom charts should use the interactive LMI Analysis Tool at https://www.nyserda.ny.gov/lmi-tool.  This underlying LMI dataset is intended for users with experience working with survey data files and producing weighted survey estimates using statistical software packages (such as SAS, SPSS, or Stata).  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/5IiH_UVYdp0) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'income', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-nyserda-low-to-moderate-income-census-populat
b'Kaggle Machine Learning & Data Science Survey 2017',b'A big picture view of the state of data science and machine learning.',"b'### Context\n\nFor the first time, Kaggle conducted an industry-wide survey to establish a comprehensive view of the state of data science and machine learning. The survey received over 16,000 responses and we learned a ton about who is working with data, what\xe2\x80\x99s happening at the cutting edge of machine learning across industries, and how new data scientists can best break into the field.\n\nTo share some of the initial insights from the survey, we\xe2\x80\x99ve worked with the folks from [The Pudding](https://pudding.cool/) to put together [this interactive report](kaggle.com/surveys/2017). They\xe2\x80\x99ve shared all of the kernels used in the report [here]().\n\n### Content\n\nThe data includes 5 files: \n\n  - `schema.csv`: a CSV file with survey schema. This schema includes the questions that correspond to each column name in both the `multipleChoiceResponses.csv` and `freeformResponses.csv`.\n  - `multipleChoiceResponses.csv`: Respondents\' answers to multiple choice and ranking questions. These are non-randomized and thus a single row does correspond to all of a single user\'s answers.\n  -`freeformResponses.csv`: Respondents\' freeform answers to Kaggle\'s survey questions. These responses are randomized within a column, so that reading across a single row does not give a single user\'s answers.\n  - `conversionRates.csv`: Currency conversion rates (to USD) as accessed from the R package ""quantmod"" on September 14, 2017\n  - `RespondentTypeREADME.txt`: This is a schema for decoding the responses in the ""Asked"" column of the `schema.csv` file.\n\n### Kernel Awards in November\nIn the month of November, we\xe2\x80\x99re awarding $1000 a week for code and analyses shared on this dataset via [Kaggle Kernels](https://www.kaggle.com/kaggle/kaggle-survey-2017/kernels). Read more about this month\xe2\x80\x99s [Kaggle Kernels Awards](https://www.kaggle.com/about/datasets-awards/kernels) and help us advance the state of machine learning and data science by exploring this one of a kind dataset.\n\n### Methodology\n  - This survey received 16,716 usable respondents from 171 countries and territories. If a country or territory received less than 50 respondents, we grouped them into a group named \xe2\x80\x9cOther\xe2\x80\x9d for anonymity.\n  - We excluded respondents who were flagged by our survey system as \xe2\x80\x9cSpam\xe2\x80\x9d or who did not answer the question regarding their employment status (this question was the first required question, so not answering it indicates that the respondent did not proceed past the 5th question in our survey).\n  - Most of our respondents were found primarily through Kaggle channels, like our email list, discussion forums and social media channels.\n  - The survey was live from August 7th to August 25th. The median response time for those who participated in the survey was 16.4 minutes. We allowed respondents to complete the survey at any time during that window.\n  - We received salary data by first asking respondents for their day-to-day currency, and then asking them to write in either their total compensation.\n     - We\xe2\x80\x99ve provided a csv with an exchange rate to USD for you to calculate the salary in US dollars on your own.\n     - The question was optional\n  - Not every question was shown to every respondent. In an attempt to ask relevant questions to each respondent, we generally asked work related questions to employed data scientists and learning related questions to students. There is a column in the `schema.csv` file called ""Asked"" that describes who saw each question. You can learn more about the different segments we used in the `schema.csv` file and `RespondentTypeREADME.txt` in the data tab.\n  - To protect the respondents\xe2\x80\x99 identity, the answers to multiple choice questions have been separated into a separate data file from the open-ended responses. We do not provide a key to match up the multiple choice and free form responses. Further, the free form responses have been randomized column-wise such that the responses that appear on the same row did not necessarily come from the same survey-taker. \n'","b""['artificial intelligence', 'employment', 'sociology', 'medium', 'featured']""",https://www.kaggle.com/kaggle/kaggle-survey-2017
b'Eclipse Megamovie',b'Citizen science covering the 2017 eclipse',"b'This first-of-its-kind citizen science project is a collection of photos submitted by a group of dedicated volunteers from locations across the United States during the August 21, 2017 total solar eclipse. \n\nThe bigquery tables include metadata for the photos, links to the photos, and astronomical measurements extracted from the photos.\n\n### Acknowledgements\nThis dataset was kindly prepared by Google, UC Berkeley, and thousands of volunteers. Please see https://eclipsemega.movie/ for more information.\n\n### Inspiration\n- Can you map out the locations of the contributors to the project? How many of them were outside the path of totality?'","b""['bigquery', 'astronomy', 'medium', 'featured']""",https://www.kaggle.com/eclipse-megamovie/eclipse-megamovie
"b'5,000 #JustDoIt! Tweets Dataset'","b""People reacting to Nike's endorsement of Colin Kaepernick""","b'### Context\nNike just announced its partnership with Colin Kaepernick to be the face of the 30th anniversary of its **JustDoIt** campaign.   \nThey used the slogan ""Believe in something, even if it means sacrificing everything.""  \nKaepernick had made a controversial decision not to stand up during the national anthem, as a protest to police brutality, a while back.  \nThis has stirred a heated debate, and became a big national issue especially when [Donald Trump commented on it](https://www.youtube.com/watch?v=oY3hpZVZ7pk).\n\n\n### Content\n\nThis dataset contains 5,000 tweets that contain the hashtag #JustDoIt.   \nAll tweets happened on September 7, 2018, which is days after Nike made its announcement to endorse Kaepernick.\n\n#### Some of the top entities of those tweets: \n### #JustDoIt #Nike #ColinKaepernick #TakeaKnee\n### \xf0\x9f\x98\x82 \xf0\x9f\xa4\xa3 \xe2\x9c\x94 \xf0\x9f\x94\xa5 \xe2\x9d\xa4 \xf0\x9f\x8f\x88 \xf0\x9f\x92\xaf \xf0\x9f\x92\x99 \xf0\x9f\x87\xba\xf0\x9f\x87\xb8\n### @Nike @Kaepernick7 @realDonaldTrump\n\n\n\n### Acknowledgements\nPython, Twitter, twython, pandas, matplotlib do the heavy lifting in generating the data and exploring it.\n \n### Inspiration\nI\'m an online marketing person. Love words, love numbers. Can\'t help it!  \nI think it\'s very interesting to see how these issues unfold, and how people respond to them. Maybe you can uncover some hidden insights or patterns.   \nI\'m also trying to show how you can [use the `extract_` functions from my `advertools` package](https://www.kaggle.com/eliasdabbas/extract-entities-from-social-media-posts). \n'","b""['text data', 'text mining', 'twitter', 'marketing', 'small', 'featured']""",https://www.kaggle.com/eliasdabbas/5000-justdoit-tweets-dataset
b'Gene expression dataset (Golub et al.)',b'Molecular Classification of Cancer by Gene Expression Monitoring',"b'### Context\n\nThis dataset comes from a proof-of-concept study published in 1999 by Golub et al. It showed how new cases of cancer could be classified by gene expression monitoring (via DNA microarray) and thereby provided a general approach for identifying new cancer classes and assigning tumors to known classes. These data were used to classify patients with acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL).\n\n### Content\n\nGolub et al ""Molecular Classification of Cancer: Class Discovery and Class\nPrediction by Gene Expression Monitoring""\n\nThere are two datasets containing the initial (training, 38 samples) and independent (test, 34 samples) datasets used in the paper.  These datasets contain measurements corresponding to ALL and AML samples from Bone Marrow and Peripheral Blood. Intensity values have been re-scaled such that overall intensities for each chip are equivalent. \n\n### Acknowledgements\n\n**Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression**\n\nScience 286:531-537. (1999). Published: 1999.10.14 \n\nT.R. Golub, D.K. Slonim, P. Tamayo, C. Huard, M. Gaasenbeek, J.P. Mesirov, H. Coller, M. Loh, J.R. Downing, M.A. Caligiuri, C.D. Bloomfield, and E.S. Lander\n\n**These datasets have been converted to a comma separated value files (CSV).**\n\n### Inspiration\n\nThese datasets are great for classification problems. The original authors used the data to classify the type of cancer in each patient by their gene expressions.'","b""['biology', 'health sciences', 'human genetics', 'biotechnology', 'small', 'featured']""",https://www.kaggle.com/crawford/gene-expression
b'Trending YouTube Video Statistics',b'Daily statistics for trending YouTube videos',"b'UPDATE: Source code used for collecting this data [released here](https://github.com/DataSnaek/Trending-YouTube-Scraper)\n\n### Context\n\nYouTube (the world-famous video sharing website) maintains a list of the [top trending videos](https://www.youtube.com/feed/trending) on the platform. [According to Variety magazine](http://variety.com/2017/digital/news/youtube-2017-top-trending-videos-music-videos-1202631416/), \xe2\x80\x9cTo determine the year\xe2\x80\x99s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they\xe2\x80\x99re not the most-viewed videos overall for the calendar year\xe2\x80\x9d. Top performers on the YouTube trending list are music videos (such as the famously virile \xe2\x80\x9cGangam Style\xe2\x80\x9d), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.\n\nThis dataset is a daily record of the top trending YouTube videos.\n\nNote that this dataset is a structurally improved version of [this dataset](https://www.kaggle.com/datasnaek/youtube).\n\n### Content\n\nThis dataset includes several months (and counting) of data on daily trending YouTube videos. Data is included for the US, GB, DE, CA, and FR regions (USA, Great Britain, Germany, Canada, and France, respectively), with up to 200 listed trending videos per day.\n\nEDIT: Now includes data from RU, MX, KR, JP and IN regions (Russia, Mexico, South Korea, Japan and India respectively) over the same time period.  \n\nEach region\xe2\x80\x99s data is in a separate file. Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count.\n\nThe data also includes a `category_id` field, which varies between regions. To retrieve the categories for a specific video, find it in the associated `JSON`. One such file is included for each of the five regions in the dataset.\n\nFor more information on specific columns in the dataset refer to the [column metadata](https://www.kaggle.com/datasnaek/youtube-new/data).\n\n### Acknowledgements\n\nThis dataset was collected using the YouTube API.\n\n### Inspiration\n\nPossible uses for this dataset could include:\n\n* Sentiment analysis in a variety of forms\n* Categorising YouTube videos based on their comments and statistics.\n* Training ML algorithms like RNNs to generate their own YouTube comments.\n* Analysing what factors affect how popular a YouTube video will be.\n* Statistical analysis over time\x0c.\n\nFor further inspiration, see the kernels on this dataset!'","b""['internet', 'linguistics', 'languages', 'statistics', 'popular culture', 'medium', 'featured']""",https://www.kaggle.com/datasnaek/youtube-new
b'Electronic Products and Pricing Data',"b'A list of over 15,000 electronic products with 10 fields of pricing information.'","b""# About This Data\n\nThis is a list of over 15,000 electronic products with pricing information across 10 unique fields provided by [Datafiniti's Product Database][1]. The dataset also includes the brand, category, merchant, name, source, and more. \n\n*Note that this is a sample of a large data set. The full data set is available through Datafiniti.*\n\n# What You Can Do With This Data\n\nYou can use this data to [identify retail industry trends in pricing strategies][2]. E.g.:\n\n- How does the prices.condition affect the pricing strategy of a product? \n- Is there a correlation between the prices.dateSeen of a product and its dynamic pricing across merchants?\n- What is the competitive pricing strategy for the same product from different merchants?\n- What role does a product\xe2\x80\x99s category play in its listing price? \n\n# Data Schema\nA full schema for the data is available in our [support documentation][3].\n\n# About Datafiniti\nDatafiniti provides instant access to web data. We compile data from thousands of websites to create standardized databases of business, product, and property information. [Learn more][4].\n\n# Want More?\nYou can get more data like this by [joining Datafiniti][5] or [requesting a demo][6].\n\n  [1]: https://datafiniti.co/products/product-data/\n  [2]: https://datafiniti.co/use-case/trov/\n  [3]: https://datafiniti-api.readme.io/docs/product-data-schema\n  [4]: https://datafiniti.co/\n  [5]: https://portal.datafiniti.co/login\n  [6]: https://datafiniti.co/request-a-demo/""","b""['internet', 'databases', 'product', 'electronics', 'small', 'featured']""",https://www.kaggle.com/datafiniti/electronic-products-prices
b'NY Work Order Management Module',b'From New York City Open Data',"b""### Content  \n\nWork orders associated with a CSR complaints  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/y_WDEY9e6mA) by [Daniel Bradley](https://unsplash.com/@_danbrad) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-work-order-management-module
b'NYS Motor Vehicle Crashes and Insurance Reduction',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'safety', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-motor-vehicle-crashes-and-insurance-reduction
b'FIFA Soccer Rankings',"b""International Men's Ranking (August 1993 - June 2018)""","b""### Context\nThe world football governing body FIFA has been ranking international teams since 1992. This dataset contains all available FIFA men's international soccer rankings from August 1993 to April 2018. The rankings and points have been scraped from the official FIFA website. \n\nA more detailed explanation and history of the rankings is available here: https://en.wikipedia.org/wiki/FIFA_World_Rankings\n\nAn explanation of the ranking procedure is available here: https://www.fifa.com/fifa-world-ranking/procedure/men.html\n\nIncludes all ~200 teams and available data from 1993-2018.\n\n----------\n\n### Content\n\nAll features available on the FIFA ranking page (https://www.fifa.com/fifa-world-ranking/ranking-table/men/index.html).\n\n* Rank\n* Country\n* Country Abbreviation\n* Total Points \n* Previous Points\n* Rank Change\n* Average Previous Years Points\n* Average Previous Years Points Weighted (50%)\n* Average 2 Years Ago Points \n* Average 2 Years Ago Points Weighted (30%)\n* Average 3 Years Ago Points \n* Average 3 Years Ago Points Weighted (20%)\n* Confederation\n\n----------\n\n### Acknowledgements\n\nThe data was scraped from the official fifa.com site (https://www.fifa.com/fifa-world-ranking/ranking-table/men/index.html)\n\nGithub Project:  https://github.com/tadhgfitzgerald/fifa_ranking\n\n----------\n\n### Inspiration\n\nWith the world cup coming up in just a  few months what better time to start exploring soccer datasets! \n\n* Look at how a teams ranking has evolved over the years. \n* Build a world cup predictor.\n* Correlate player performance and team ranking.\n* Who are the most consistent teams? Who are the least consistent?\n* Which confederation is the strongest? Which is the fastest improving?\n* Which team has been most dominant? Which has fallen off the most?""","b""['sports', 'association football', 'ranking', 'small', 'featured']""",https://www.kaggle.com/tadhgfitzgerald/fifa-international-soccer-mens-ranking-1993now
b'Super Heroes Dataset',"b""How's your average superhero?""","b'## Super Heroes Dataset\n\n### Context\nSuper Heroes have been in popular culture for a long time and now more than ever. Since its creation, super heroes have not been very diverse, but that is changing rapidly. This dataset aims to provide an overview about heroes and their physical as well as power characteristics, helping researchers and curious minds identify trends and patterns.\n\n### Content\nThis data was collected in June/2017 from superherodb and not updated since, so it may not be up to date. There are two datasets here. The first one lists the characteristics of every super hero found on my source, the second contains information about every superpower and lists if they are present in any given hero.\n\n### Acknowledgements\n\nThis data was scraped from [SuperHeroDb][1]. \n\n# Inspiration\n\nWhat are the characteristics of your favorite super heroes?\n\n  [1]: https://www.superherodb.com/'","b""['popular culture', 'entertainment', 'web sites', 'comics', 'small', 'featured']""",https://www.kaggle.com/claudiodavi/superhero-set
"b'Earthquakes in 1910-2017, Turkey @alpkoc'",b'Corrected Earthquake Data of Turkey in 1910-2017 @alpkoc',"b'*I fork the data from @alpkoc and i have fixed several areas in cvs like wrong country names and wrong number formats,\nSo here is the explanation of original data owner:*\n\n**Context**\nOver the years the earthquakes have been recorded by different organisations in Turkey. Bogazici University, as the most successful university in Turkey, has a earthquake research center and they collected up all the data during the years. They have the most technological devices to uncover the specifications about the earthquakes. The data was collected from the database with particular filters.\n\n**Content**\nThe data covers up all the recorded earthquakes in the latitudes between 25 - 50; longitudes 15 - 60. As the metering stations are placed in Turkey most of the recorded earthquakes are in latitudes between 35 - 45; longitudes 25 - 45. The database search time filter was set to dates 27/09/1910 to 27/09/2017. As there are too many earthquakes which have intensities smaller than 4.0, the filter of intensity was set to 3.5 to 9.0 (there was no earthquakes recorded larger than 9.0 intensity).\nNot being an earthquake specilist or geologist, I have no idea about the different kind of intensity measurements in the dataset (the columns between xM and Ms). \n\n**Acknowledgements**\nAll the data here is owned by ""Bo\xc4\x9fazi\xc3\xa7i \xc3\x9cniversitesi Rekt\xc3\xb6rl\xc3\xbc\xc4\x9f\xc3\xbc"" and it can only be used for uncommercial issues with regards to ""Bo\xc4\x9fazi\xc3\xa7i \xc3\x9cniversitesi Kandilli Rasathanesi ve Deprem Ara\xc5\x9ft\xc4\xb1rma Enstit\xc3\xbcs\xc3\xbc B\xc3\xb6lgesel Deprem-Tsunami \xc4\xb0zleme ve De\xc4\x9ferlendirme Merkezi"". \n\nInspiration\nI hope all kind of data scientists would be interested in this data in order to: - Visualize the current data on any kind of GIS. - Reveal some truths and correleations behind and across the data. - Analyze seasonality across months, years and decades. - Improve any kind of data model which can be useful to represent the eathquakes in Turkey. - Develop algorithms to predict the earthquake with an intensity, an interval and a coordinate corridor. '","b""['world', 'geography', 'earth sciences', 'small', 'featured']""",https://www.kaggle.com/caganseval/earthquake
b'ECG Heartbeat Categorization Dataset',b'Segmented and Preprocessed ECG Signals for Heartbeat Classification',"b'# Context\n\n# ECG Heartbeat Categorization Dataset\n\n## Abstract\n\nThis dataset is composed of two collections of heartbeat signals derived from two famous datasets in heartbeat classification, [the MIT-BIH Arrhythmia Dataset](https://www.physionet.org/physiobank/database/mitdb/) and [The PTB Diagnostic ECG Database](https://www.physionet.org/physiobank/database/ptbdb/). The number of samples in both collections is large enough for training a deep neural network. \n\nThis dataset has been used in exploring heartbeat classification using deep neural network architectures, and observing some of the capabilities of transfer learning on it. The signals correspond to electrocardiogram (ECG) shapes of heartbeats for the normal case and the cases affected by different arrhythmias and myocardial infarction. These signals are preprocessed and segmented, with each segment corresponding to a heartbeat.\n\n## Content\n\n### Arrhythmia Dataset\n<ul>\n    <li> Number of Samples: 109446</li>\n    <li> Number of Categories: 5</li>\n    <li> Sampling Frequency: 125Hz</li>\n    <li> Data Source: Physionet\'s MIT-BIH Arrhythmia Dataset</li>\n    <li> Classes: [\'N\': 0, \'S\': 1, \'V\': 2, \'F\': 3, \'Q\': 4]</li>\n</ul>\n\n### The PTB Diagnostic ECG Database\n<ul>\n    <li> Number of Samples: 14552</li>\n    <li> Number of Categories: 2</li>\n    <li> Sampling Frequency: 125Hz</li>\n    <li> Data Source: Physionet\'s PTB Diagnostic Database</li>\n</ul>\n\n\n**Remark**: *All the samples are cropped, downsampled and padded with zeroes if necessary to the fixed dimension of 188*.\n\n## Data Files\n\nThis dataset consists of a series of CSV files. Each of these CSV files contain a matrix, with each row representing an example in that portion of the dataset. The final element of each row denotes the class to which that example belongs.\n\n## Acknowledgements\n\nKachuee, Mohammad, Shayan Fazeli, and Majid Sarrafzadeh. ""ECG Heartbeat Classification: A Deep Transferable Representation."" [*arXiv preprint arXiv:1805.00794 (2018)*](https://arxiv.org/abs/1805.00794).\n\n# Inspiration\n\nCan you identify myocardial infarction?'","b""['classification', 'deep learning', 'healthcare', 'health', 'signal data', 'medium', 'featured']""",https://www.kaggle.com/shayanfazeli/heartbeat
"b'Brooklyn Home Sales, 2003 to 2017'",b'Brooklyn New York housing and GIS data',"b'### Context\n\nI\'m trying to make a Choropleth map over time of home sale prices by block in Brooklyn for the last 15 years to visualize gentrification. I have the entire dataset for all 5 boroughs of New York, but am starting with Brooklyn.\n\n### Content and Acknowledgements\nPrimary dataset is the NYC Housing Sales Data Found in this Link:\nhttp://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page\n\nThe data in all the separate excel spreadsheets for 2003-2017 was merged via VBA scripting in Excel and further cleaned & de-duped in R\n\nAdditionally, in my hunt for shapefiles I discovered these wonderful shapefiles from NYCPluto:\nhttps://www1.nyc.gov/site/planning/data-maps/open-data/dwn-pluto-mappluto.page\n\nI left joined it by ""Block"" & ""Lot"" onto the primary data frame, but 25% of the block/lot combo\'s ended up not having a corresponding entry in the Pluto shapefile and are NAs.\n\nNote that as in other uploaded datasets of NYC housing on Kaggle, many of these transactions have a sale_price of $0 or only a nominal amount far less than market value. These are likely property transfers to relatives and should be excluded from any analysis of market prices.\n\n### Inspiration\n\nCan you model Brooklyn home prices accurately?'","b""['housing', 'medium', 'featured']""",https://www.kaggle.com/tianhwu/brooklynhomes2003to2017
b'NYS Traffic Tickets Issued: Four Year Window',b'From New York State Open Data',"b""### Content  \n\nData extracted from records of tickets on file with NYS DMV. The tickets were issued to motorists for violations of:  NYS Vehicle & Traffic Law (VTL), Thruway Rules and Regulations, Tax Law, Transportation Law, Parks and Recreation Regulations, Local New York City Traffic Ordinances, and NYS Penal Law pertaining to the involvement of a motor vehicle in acts of assault, homicide, manslaughter and criminal negligence resulting in injury or death.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/crGG3QXuyPc) by [Jordan Andrews](https://unsplash.com/@exit) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'law', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-traffic-tickets-issued-four-year-window
b'deepScapulaSSM',b'A draft database containing 1000 scapula meshes with features and SSM parameters',"b'### Context\n\nIn the scope of my Research Internship at the Faculty of Health Sciences of UCT, I had to find correlations between Scapulae features such as glene version or tilt and the parameters of my statistical shape model.\nI developped a Scala app based on Scalismo, to build a database as big as one could desire using the generative properties of SSM.\nThe SSM was built with 76 scapulae, so it reduces the potential bias.\n\n### Content\n\nEach row represents a mesh (a 3D model of a Scapulae) with its features (Critical Shoulder Angle, Tilt, Version, Width, Length) and the parameters of the SSM projected on the first 10 principal components.\n\n\n### Acknowledgements\n\nThis dataset was built with the help of my colleagues at the Human Biology department of UCT and also thanks to the GRAVIS department of the University of Basel who developped the Scalismo library that allows everyone to start playing with statistical shape models.\n\n\n'","b""['statistics', 'medicine', 'medium', 'featured']""",https://www.kaggle.com/iham97/deepscapulassm
"b'AMEX, NYSE, NASDAQ stock histories'","b'Daily historical data of over 8,000 stocks trading on AMEX, NYSE, and NASDAQ'","b""# AMEX, NYSE, and NASDAQ stocks histories\n#### Update every **Satur... Sun... I mean Friday... &gt;_&lt; sometime during the weekend**\n###Full history of stock symbols on NASDAQ and NYSE:\n- Unzip **fh_&lt; version_date &gt;.zip**\n- Each stock symbol has a .csv file under **full_history/**\n    - i.e. AMD.csv\n- Columns in .csv\n    - **date** - year-month-day, 2018-08-08\n    - **volume** - int, volume of the day\n    - **open** - float, opening price of the day\n    - **close** - float, closing price of the day\n    - **high** - float, highest price of the day\n    - **low** - float, lowest price of the day\n    - **adjclose** - float, adjusted closing price of the day\n\n###Other files:\n- all_symbols.txt - All the stock symbols with history\n- excluded_symbols.txt - All the ones that I couldn't retrieve data for\n- NASDAQ.txt - NASDAQ listing\n- NYSE.txt - NYSE listing\n- AMEX.txt - AMEX listing\n\n###Disclaimer\nThis dataset contains **almost** all the stocks listed on these exchanges as of the date shown in the file name. Some of the symbols cannot be found on Yahoo Finance, which I plan on using CNN Money to scrape. There are also a few cases that got excluded due to a poor internet connection. There are other symbols that have different classes that require some modification before I can make them queryable... I have yet to decide on the best course of action. If you want to know what these excluded symbols are, see excluded_symbols.txt.\n\n###Github - for you to DIY:\n**https://github.com/qks1lver/redtide**\n\n###Data source\n**Listing files (i.e. NYSE.txt) are from http://eoddata.com/symbols.aspx**\n\n**Daily historical data compiled from Yahoo Finance**\n\n###Need someone to talk to?\nIf you have questions, e-mail me: jiunyyen@gmail.com\n\nHappy mining!\n""","b""['finance', 'economics', 'business', 'marketing', 'medium', 'featured']""",https://www.kaggle.com/qks1lver/amex-nyse-nasdaq-stock-histories
b'Global Map Japan Data',"b'Environmental, Land, Transportation, Population Spatial Data'","b""### Context\n\nGlobal Map is a set of basic geospatial information at the scale of 1:1 million, which was developed and verified by National Geospatial Information Authorities (NGIAs) in the world so that it is considered as \xe2\x80\x9cauthoritative data.\xe2\x80\x9d\nGlobal Mapping Project is a collaborative international project of developing Global Map for sustainable development, environmental protection and disaster mitigation.  \n\nThe International Steering Committee for Global Mapping (ISCGM) was established to implement the Project. The Geospatial Information Authority of Japan (GSI) served as the Secretariat of ISCGM for the whole duration of the Committee from February 1996 to March 2017, and supported the Project activities.  \n\nRecognizing that the objective of Global Mapping Project was mostly achieved by the collective efforts of ISCGM and the participating NGIAs, the 23rd ISCGM meeting held in August, 2016 adopted the resolution of dissolving ISCGM and transferring the Global Map data to the Geospatial Information Section of the United Nations. Thus, Global Mapping Project came to end.  \n\n### Content\n\nThis dataset contains geospatial vector and raster data across the map of Japan. Each zip file contains a portion (or all) of the data layers for the specific map version.\n\nFilename breakdown:  \n'gm-jpn-ve_u_1_0.zip'  \n'GlobalMap - Japan - Layer _ Version _ Version_Num .zip'\n\n### Acknowledgements\n\nThis data is pulled directly from the Geospatial Information Authority of Japan website (http://www.gsi.go.jp/kankyochiri/gm_japan_e.html). To see more information on licensing, please visit the website's [Terms of Use](http://www.gsi.go.jp/ENGLISH/page_e30286.html).  \n\nFrom Terms of Use:  \n```Information made available on this website (hereinafter referred to as \xe2\x80\x9cContent\xe2\x80\x9d) may be freely used, copied, publicly transmitted, translated or otherwise modified on condition that the user complies with provisions 1) to 7) below. Commercial use of Content is also permitted.```\n\n[Cover photo](https://unsplash.com/photos/N4DbvTUDikw) by [David Edelstein](https://unsplash.com/@jlhopes) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['geospatial analysis', 'geography', 'asia', 'japan', 'medium', 'featured']""",https://www.kaggle.com/gsi-japan/global-map-japan-data
b'Hourly Weather Surface - Brazil (Southeast region)',b'Climata data from 122 weathes stations between 2000 and 2016 - 17 features',"b""### Context\n\nIt's covers hourly weather data from **122 weathers stations of southeast region (Brazil)**. The southeast include the states of Rio de Janeiro, S\xc3\xa3o Paulo, Minas Gerais e Espirito Santo.\n\n**Dataset Source:** INMET (National Meteorological Institute -  Brazil).\n\n**Equipament:** [Vaisala Automatic Weather Station AWS310 ][1]\n\n**Category:** Weather\n\n### Content\n\nData: \n\n- Instant Air Temperature (celsius degrees) \n- Maximum Air Temperature (celsius degrees) \n- Minimum Air Temperature (celsius degrees) \n- Relative Humidity of Air (%)\n- Maximum Relative Air Humidity  (%)\n- Minimum Relative Air Humidity  (%)\n- Instant Dew Point  (celsius degrees) \n- Maximum Dew Point (celsius degrees) \n- Minimum Dew Point Temperature (celsius degrees) \n- Instant Air Atmospheric Pressure (millibars)\n- Maximum Air Atmospheric Pressure (millibars)\n- Minimum Air Atmospheric Pressure (millibars)\n- Instant Wind Speed (metres per second)\n- Wind Direction (radius degrees)\n- Wind Gust Intensity (metres per second)\n- Solar radiation \n- Precipitation (milimetres) \n\n### Inspiration\n\nCan you predict the amount of rain? temperature? \n\n**NOTE:** Not all weather stations started operating since 2000\n\n\n  [1]: https://www.vaisala.com/sites/default/files/documents/WEA-MET-AWS310-Brochure-B211290EN.pdf""","b""['data cleaning', 'weather', 'climate', 'medium', 'featured']""",https://www.kaggle.com/PROPPG-PPG/hourly-weather-surface-brazil-southeast-region
b'fastText English Word Vectors',"b'Word vectors trained on Wikipedia 2017, UMBC webbase corpus, and statmt.org '","b'### English Word Vectors\n\n---\n\n###  About fastText<br>\n\nfastText is a library for efficient learning of word representations and sentence classification. One of the key features of fastText word representation is its ability to produce vectors for any words, even made-up ones. Indeed, fastText word vectors are built from vectors of substrings of characters contained in it. This allows you to build vectors even for misspelled words or concatenation of words.\n\n\n### About the vectors<br>\nThese pre-trained vectors contain 1 million word vectors that were learned using Wikipedia 2017, the UMBC webbase corpus and the statmt.org news dataset. In total, it contains 16B tokens.\n\nThe first line of the file contains the number of words in the vocabulary and the size of the vectors. Each line contains a word followed by its vectors, like in the default fastText text format. Each value is space separated. Words are ordered by descending frequency.\n\n### Acknowledgements<br>\nThese word vectors are distributed under the Creative Commons Attribution-Share-Alike License 3.0.\n\nP. Bojanowski*, E. Grave*, A. Joulin, T. Mikolov, Enriching Word Vectors with Subword Information<br>\nA. Joulin, E. Grave, P. Bojanowski, T. Mikolov, Bag of Tricks for Efficient Text Classification<br>\nA. Joulin, E. Grave, P. Bojanowski, M. Douze, H. J\xc3\xa9gou, T. Mikolov, FastText.zip: Compressing text classification models<br><br>\n\n(* These authors contributed equally.)'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/facebook/fasttext-wikinews
b'Disneyland Paris Reviews ',b'300k avis sur Disneyland Paris ',"b""## Le contexte\n\nDans le cadre d'un travail pour Disneyland Paris, j'ai particip\xc3\xa9 \xc3\xa0 une \xc3\xa9tude visant \xc3\xa0 analyser les points de vues et les avis sur les r\xc3\xa9seaux sociaux.\n\n## Le contenu\n\nIl y aura plusieurs jeux de donn\xc3\xa9es dans ce dataset. Ils proviennent de diff\xc3\xa9rentes sources: \n\n+ Facebook\n+ TripAdvisor \n+ Google\n+ Instagram\n\n### Data Wrangling\n\nLorsque les jeux de donn\xc3\xa9es sont scrap\xc3\xa9s, et selon la source, ils demandent plus ou moins de traitement.\n\nLes jeux de donn\xc3\xa9es propos\xc3\xa9s ici sont format\xc3\xa9s et nettoy\xc3\xa9s en utilisant dplyr, gsub et stringr. \n\n\n### Facebook\n\nLe jeu de donn\xc3\xa9es ci dessous comporte \n\n**facebook_reviews_disneylandParis_format.csv** \n\n299 635 avis et 12 colonnes.\n\nCe jeu de donn\xc3\xa9es vient de la page publique Facebook de Disneyland Paris [DisneylandParis](https://www.facebook.com/Disneyland). \nIl comprend les avis des utilisateurs sur la page depuis 2012 jusqu'au 29 septembre 2017. \n\n## Informations\n\nN'h\xc3\xa9sitez pas si vous avez des questions :)\n\n## Inspiration\n\nCes donn\xc3\xa9es peuvent \xc3\xaatres int\xc3\xa9ressantes pour comprendre les points positifs et n\xc3\xa9gatifs soulev\xc3\xa9s par les clients de Disneyland Paris. On peut distinguer plusieurs applications possible:\n\n+ Sentiment analysis\n\n+ Topic modeling ""","b""['nlp', 'text data', 'text mining', 'languages', 'medium', 'featured']""",https://www.kaggle.com/romain9292/disneyland-paris-facebook-reviews
b'NYS Salary Information for the Public Sector',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-salary-information-for-the-public-sector
b'1.6 million UK traffic accidents',b'Visualise and analyse traffic demographics',"b'### Context\nThe UK government amassed traffic data from 2000 and 2016, recording over 1.6 million accidents in the process and making this one of the most comprehensive traffic data sets out there. It\'s a huge picture of a country undergoing change.\n\nNote that all the contained accident data comes from police reports, so this data does not include minor incidents.\n\n### Content\n`ukTrafficAADF.csv` tracks how much traffic there was on all major roads in the given time period (2000 through 2016). AADT, the core statistic included in this file, stands for ""Average Annual Daily Flow"", and is a measure of how activity a road segment based on how many vehicle trips traverse it. The [AADT page on Wikipedia](https://en.wikipedia.org/wiki/Annual_average_daily_traffic) is a good reference on the subject.\n\nAccidents data is split across three CSV files: `accidents_2005_to_2007.csv`, `accidents_2009_to_2011.csv`, and `accidents_2012_to_2014.csv`. These three files together constitute 1.6 million traffic accidents. The total time period is 2005 through 2014, but 2008 is missing.\n\nA data dictionary for the raw dataset at large is available from the UK Department of Transport website [here](http://data.dft.gov.uk/gb-traffic-matrix/all-traffic-data-metadata.pdf). For descriptions of individual columns, see the [column metadata](https://www.kaggle.com/daveianhickey/2000-16-traffic-flow-england-scotland-wales/data).\n\n### Acknowledgements\n\nThe license for this dataset is the Open Givernment Licence used by all data on data.gov.uk ([here](http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/)). The raw datasets are available from the UK Department of Transport website [here](https://www.dft.gov.uk/traffic-counts/download.php).\n\n### Inspiration\n\n* How has changing traffic flow impacted accidents?\n* Can we predict accident rates over time? What might improve accident rates?\n* Plot interactive maps of changing trends, e.g. How has London has changed for cyclists? Busiest roads in the nation?\n* Which areas never change and why? Identify infrastructure needs, failings and successes.\n* How have Rural and Urban areas differed (see `RoadCategory`)? How about the differences between England, Scotland, and Wales?\n* The UK government also like to look at miles driven. You can do this by multiplying the AADF by the corresponding length of road (link length) and by the number of days in the years. What does this tell you about UK roads?'","b""['climate', 'road transport', 'automobiles', 'taxi services', 'medium', 'featured']""",https://www.kaggle.com/daveianhickey/2000-16-traffic-flow-england-scotland-wales
b'PBS Newshour Transcripts',"b'Transcripts from more than 17,000 news stories'","b'### Context\n\nPBS Newshour is an American daily news program founded in 1975.  The program spans one hour on the weekdays and 30 minutes on the weekends and it covers domestic and international news.\n\nPBS Newshour is different from other news sources because it is a non-profit supported through limited advertisements and viewer support.\n\n### Data\n\nI scraped this data myself from PBS Newshour\'s website.  They have an archive of videos that go back to the 1970s and most videos are accompanied by a transcript.  All my code for this project can be found on [Github](https://github.com/pstetz/PBS-Newshour)\n\nI hope to update this dataset quarterly depending on interest.\n\n### Content\n\nIf you\'re unsure of the dataset feature names, I\'d recommend looking at an [example clip](https://www.pbs.org/newshour/show/trump-steps-up-attacks-on-canada-key-ally-and-largest-u-s-export-market) on PBS Newshour\'s website.\n\nProbably the most confusing feature is `Story`, although this is just the summary of the clip that appears before every transcript.\n\n### MacNeil/Lehrer journalism (PBS Newshour guidelines)\n\nThese guidelines were vocalized by PBS Newshour\'s founders.  I believe PBS Newshour follows them to a T to this day!\n\n-    ""Do nothing I cannot defend.""  \n-    ""Cover, write, and present every story with the care I would want if the story were about me.""  \n-    ""Assume there is at least one other side or version to every story.""  \n-    ""Assume the viewer is as smart and as caring and as good a person as I am.""  \n-    ""Assume the same about all people on whom I report.""  \n-    ""Assume personal lives are a private matter until a legitimate turn in the story absolutely mandates otherwise.""  \n-    ""Carefully separate opinion and analysis from straight news stories, and clearly label everything.""  \n-    ""Do not use anonymous sources or blind quotes except on rare and monumental occasions.""  \n-    ""No one should ever be allowed to attack another anonymously.""  \n-    ""And finally, I am not in the entertainment business.""  \n\n### Acknowledgements\n\nThank you to PBS Newshour, my favorite news source!'","b""['politics', 'news agencies', 'journalism', 'medium', 'featured']""",https://www.kaggle.com/pstetz/pbs-newshour-transcripts
b'FIFA 18 - Fifa Ultimate Team',b'21k+ FIFA Ultimate Team players - Final version',"b'**Context**\n-----------\n\nFIFA 19 will be released at the end of September 2018, so it is the right moment to provide the final version of the dataset that includes all the players available in the Ultimate Team mode of FIFA 18 (*https://www.easports.com/fifa/ultimate-team/features*).\n\n**Content**\n-----------\n\nEach row represents a football player that can be used in Ultimate Team, but, since a single player might have multiple versions of himself (upgrades, transfers or special versions), it is better to refer to each row as an Ultimate Team card; each column contains player\xe2\x80\x99s attributes described on the column Metadata.\n\nThe file contains 21,561 players with 83 different attributes gathered and it includes also the card prices (on the PS4, Xbox, and PC platforms) available on *https://futbin.com*.\n\n\n**The data set includes information about:**\n\n - Quality of the player card, whether it is Gold, Silver, or Bronze (rare or normal)\n - Reason why that card was included (if it is a standard card the value is ""N/A"", otherwise it can be due to Transfers, Updates, or other reasons) - Column is called origin\n - Date in which the card was added to the game \xe2\x80\x93 Column is called added_date\n - All the player skills (GK skills included)\n - Player overall value for each position in the pitch\n\n**Acknowledgements**\n--------------------\n\nData has been scraped from the publicly available website *https://futbin.com*.\n\n**Inspiration**\n---------------\n\nTo provide the final version of all the players available on FIFA 18 Ultimate Team before the release of FIFA 19.'","b""['video games', 'sports', 'popular culture', 'association football', 'medium', 'featured']""",https://www.kaggle.com/stefanoleone992/fifa-18-fifa-ultimate-team
b'NY Street Hail Livery (SHL)',b'From New York City Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/RW7TrDwdqpk) by [Erickson Javier](https://unsplash.com/@javiererickson) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-street-hail-livery-shl
b'Seattle Building Permits',b'From City of Seattle Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.""","b""['socrata', 'construction', 'medium', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-building-permits
b'Multi-Modal Dataset for Hand Gesture Recognition',b'Acquired by Leap Motion',"b'### Context\n\nHand  gesture recognition dataset is presented, composed by a set of near infrared images and skeletal information acquired by the Leap Motion sensor.\n\n\n### Content\n\nThe dataset is composed by 15 different hand-gestures that are performed by 15 different subjects (5 women and 10 men).\n\nThe dataset is structured as follows:\n \n\nnear-infrared (Near infrared images)\n\n - /00  (subject with identifier 00)\n   - /test_gesture (hand gesture testing imageries for subject 00)\n     - /02_l (testing samples of hand gesture with identifier 02_l)\n         - /00 (images for sample 00 of hand gesture 02_l)\n         - /00/frame_4312_l.png,...,frame_4459_r.png,...  (images that corresponds to one repetition of the L hand gesture performed by the subject with identifier 00)\n         - /02\n         - ...\n         - /05\n     - /04_fist_moved\n     - ...\n     - /22_up\n   - /test_pose (hand poses testing imageries for subject 00)\n     - /02_l\n     - ...\n     - /22_up\n   - /train_pose  (hand poses trainin imageries for subject 00)\n     - /02_l\n     - ...\n     - /22_up\n - /01\n - /02 \n - ...\n - /14  (last subject with identifier 14)\n\n  \n\nskeletal (Skeletal information stored in xml files)\n\n - /00  (subject with identifier 00)\n     - /test_gesture (hand gesture testing skeletal information for subject 00)\n       - /02_l (testing samples of hand gesture with identifier 02_l)\n         - /00 (skeletal information for sample 00 of hand gesture 02_l)\n         - /00/frame_4312.xml,...,frame_4459.xml,...  (xml files with skeletal information that corresponds to one repetition of the L hand gesture performed by the subject with identifier 00)\n         - /02\n         - ...\n         - /05\n       - /04_fist_moved\n       - ...\n       - /22_up\n     - /test_pose (hand poses testing imageries for subject 00)\n       - /02_l\n       - ...\n       - /22_up\n     - /train_pose  (hand poses trainin imageries for subject 00)\n       - /02_l\n       - ...\n       - /22_up\n - /01\n - /02\n - ...\n - /14  (last subject with identifier 14)\n\nThe xml with the skeletal information is structured as follows:\nFrame (Name for the Leap Motion structure that encloses the skeletal information)\n\n - Images (Distinguish between the information obtained by the two infrared cameras of the Leap Motion)\n   - RightImage (Information of the right camera)\n     - Hands (Information of the hands detected by the Leap Motion)\n     - Right (Information of the right hand, left hand is not included as the proposed dataset just uses right hand gestures)\n     - Center  (Position of the palm center)\n     - Normal  (Normal vector of the palm center)\n     - Direction  (Direction to which the palm center is pointing)\n     - Velocity  (Velocity of the hand)\n     - SphereCenter (Position of the hand center, considering also the fingers)\n     - Confidence (Indicates if the hand is well detected or not)\n     - PinchStrength (Hand pinch strength)\n     - GrabStrength (Hand grab strength)\n     - SphereRadius (Radius of the sphere defined by the hand with center in SphereCenter)\n     - Fingers (Information of the fingers)\n         - Thumb (Thumb finger information)\n             - Type  (Finger type, in this case Thumb)\n             - TipPosition  (The instantaneous position in mm from the Leap Motion origin)\n             - TipDirection  (The current pointing direction vector)\n             - TipVelocity  (The instantaneous velocity)\n             - TippLength  (The apparent length of the finger)\n             - dipPosition  (dip position)\n             - pipPosition  (pip position)\n             - mcpPosition  (mcp position)\n         - Index (Index finger information)\n         - Middle (Middle finger information)\n         - Ring (Ring finger information)\n         - Pinky (Pinky finger information)\n   - LeftImage (Information of the left camera)'","b""['image data', 'computer science', 'object recognition', 'human-computer interaction', 'large', 'featured']""",https://www.kaggle.com/gti-upm/multimodhandgestrec
b'Image Colorization',b'Image Colorizing dataset consisting of 25k 224x224 grayscale and normal images.',"b'###  LAB COLOR SPACE\n\n### Context\n\nWe are working on the project of automatic [Image colorization][1] for the Texas Innovation Challenge([TIC][2]). Hence for the training of the model I had to create this dataset, wherein gray scale images are taken as input and a and b components of LAB color space are taken as output. This is the first dataset I ever created , so please do share your reviews on it :):) \n\n\n### Content\n\nThe dataset consists of two compressed zip files:\n(1) ab.zip : This contains 25 .npy files consisting of a and b dimensions of LAB color space images, of the [MIRFLICKR25k][3] randomly sized colored image dataset. The LAB color space generally takes up large disk spaces, hence is a lot slower to load. That is the reason, I divided this into 25 files, so that it can be loaded at the time of requirement.\n\n(2) l.zip : This consists of a gray_scale.npy file which is the grayscale version of the [MIRFLICKR25k][4] dataset.\n\nThe image dataset which I used was taken from the [MIRFLICKR25k][5] . \n\n\n  [1]: https://sites.google.com/view/coloi/\n  [2]: https://innovate.mygov.in/india-innovation-challenge-design-contest-2018/\n  [3]: http://press.liacs.nl/mirflickr/mirdownload.html\n  [4]: http://press.liacs.nl/mirflickr/mirdownload.html\n  [5]: http://press.liacs.nl/mirflickr/mirdownload.html'","b""['deep learning', 'image data', 'image processing', 'gan', 'large', 'featured']""",https://www.kaggle.com/shravankumar9892/image-colorization
b'Weather archive Jena',"b'Air temperature, atmospheric pressure, humidity, etc recorded over seven years'","b'### Context\n\nThe Dataset is used by ""A temperature-forecasting problem"" from the ""Deep Learning with Python"" book\n\n\n### Content\n\nThe data was downloaded from:\n[https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip][1]\n\nIt represents time period between 2009 and 2016\n\n\n### Acknowledgements\n\nThe dataset recorded at the Weather Station at the Max Planck Institute\nfor Biogeochemistry in Jena, Germany.\n[https://www.bgc-jena.mpg.de/wetter/][2]\n\nIt was reassembled by Fran\xc3\xa7ois Chollet, the author of the ""Deep Learning with Python"" book\n\n### Inspiration\n\nThe main purpose of this dataset is to perform RNN exercise (6.3.1 A temperature-forecasting problem) from the ""Deep Learning with Python"" book.\n\n\n  [1]: https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n  [2]: https://www.bgc-jena.mpg.de/wetter/'","b""['weather', 'climate', 'utility', 'medium', 'featured']""",https://www.kaggle.com/pankrzysiu/weather-archive-jena
b'Medicare Physician & Other Supplier NPI Aggregates',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain, NA""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/cms/medicare-physician-other-supplier-npi-aggregates
b'Stanford Car Dataset by classes folder',b'The Stanford car  dataset for using with Keras ImageGenerator',"b'### Context\n\nThis is the [Stanford car dataset][1]. The difference is the .zip file contains all the images with this structure:\n  -&gt; train -&gt; 2012 Tesla Model S\n                -&gt; 2012 BMW M3 coupe\n                ...\n  -&gt; test  -&gt; 2012 Tesla Model S\n               -&gt; 2012 BMW M3 coupe\n               ...\n\n### Content\n\nThe Cars dataset contains 16,185 images of 196 classes of cars. The data is split into 8,144 training images and 8,041 testing images, where each class has been split roughly in a 50-50 split. Classes are typically at the level of Make, Model, Year, e.g. 2012 Tesla Model S or 2012 BMW M3 coupe.\n\n\n### Acknowledgements\n\nsee this [paper][2]\n\n#Inspiration\n\nWhat car was that?\n\n  [1]: https://ai.stanford.edu/~jkrause/cars/car_dataset.html\n  [2]: https://ai.stanford.edu/~jkrause/papers/3drr13.pdf'","b""['multiclass classification', 'object detection', 'large', 'featured']""",https://www.kaggle.com/jutrera/stanford-car-dataset-by-classes-folder
b'Oakland City 5-Year Financial Forecast 2016-20',b'Explore open data from the city of Oakland',"b""  \n\n### Context  \n\nThis is a dataset hosted by the city of Oakland in California. The organization has an open data platform found [here](data.oaklandnet.com) and they update their information according to the amount of data that is brought in. Explore Oakland's Data using Kaggle and all of the data sources available through the city of Oakland [organization page](https://www.kaggle.com/cityofoakland)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/tPps5S-_BJM) by [Jerry Kiesewetter](https://unsplash.com/@jerryinocmd) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under NA""","b""['socrata', 'finance', 'small', 'featured']""",https://www.kaggle.com/cityofoakland/oakland-city-5-year-financial-forecast-2016-20
b'UK Road Safety: Traffic Accidents and Vehicles',b'Detailed dataset of road accidents and involved vehicles in the UK (2005-2016)',"b'### Context\n\nThe UK government collects and publishes (usually on an annual basis) detailed information about traffic accidents across the country. This information includes, but is not limited to, geographical locations, weather conditions, type of vehicles, number of casualties and vehicle manoeuvres, making this a very interesting and comprehensive dataset for analysis and research.\n\nThe creation of this dataset was inspired by the one previously published by [Dave Fisher-Hickey][1]. However, this current dataset features the following significant improvements over its predecessor:\n\n* It covers a wider date range of events.\n* Most of the coded data variables have been transformed to textual strings using relevant lookup tables, enabling more efficient and ""human-readable"" analysis.\n* It features detailed information about the vehicles involved in the accidents.\n\n### Content\n\nThe data come from the [Open Data][2] website of the UK government, where they have been published by the Department of Transport.\n\nThe dataset comprises of two csv files:\n\n* **Accident_Information.csv:** every line in the file represents a unique traffic accident (identified by the Accident_Index column), featuring various properties related to the accident as columns. Date range: 2005-2016\n* **Vehicle_Information.csv:** every line in the file represents the involvement of a unique vehicle in a unique traffic accident, featuring various vehicle and passenger properties as columns. Date range: 2004-2016\n\nThe two above-mentioned files/datasets can be linked through the unique traffic accident identifier (Accident_Index column).\n\nThe dataset will keep being updated as more data become available by the Department of Transport. \n\n### Acknowledgements\n\nThanks to Dave Fisher-Hickey for previously publishing, what I consider to be, the first solid and structured version of this dataset on Kaggle.\n\nAlso thanks to data.gov.uk for making this information publicly available.\n\nLast but not least, thanks to [The Data Lab][3] for allocating me some much needed time to assemble this dataset.\n\n### Inspiration\n\nGo crazy using the dataset. Don\'t go crazy while driving.\n\n\n  [1]: https://www.kaggle.com/daveianhickey/2000-16-traffic-flow-england-scotland-wales\n  [2]: https://data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-safety-data\n  [3]: https://www.thedatalab.com/'","b""['demographics', 'road transport', 'automobiles', 'vehicles', 'safety', 'medium', 'featured']""",https://www.kaggle.com/tsiaras/uk-road-safety-accidents-and-vehicles
b'Huge Stock Market Dataset',b'Historical daily prices and volumes of all U.S. stocks and ETFs',"b""### Context\n\nHigh-quality financial data is expensive to acquire and is therefore rarely shared for free.  Here I provide the full historical daily price and volume data for all US-based stocks and ETFs trading on the NYSE, NASDAQ, and NYSE MKT. It's one of the best datasets of its kind you can obtain. \n\n### Content\n\nThe data (last updated 11/10/2017) is presented in CSV format as follows: Date, Open, High, Low, Close, Volume, OpenInt. Note that prices have been adjusted for dividends and splits. \n\n### Acknowledgements\n\nThis dataset belongs to me. I\xe2\x80\x99m sharing it here for free. You may do with it as you wish. \n\n### Inspiration\n\nMany have tried, but most have failed, to predict the stock market's ups and downs. Can you do any better? ""","b""['finance', 'economics', 'business', 'artificial intelligence', 'medium', 'featured']""",https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs
b'Points of Interest POI Database',b'A large number of points of interests including longitude/latitudes',"b'### Context\n\nThis dataset contains roughly 400,000 unique points of interest, including latitude and longitude, as well as links and categories. The picture for this dataset is actually a graph of all of the points in this dataset plotted on a rectangle.\n\n### Content\n\nThe dataset was derived by parsing wikipedia for articles containing latitude/longitude pairs in the infobox, and then storing the coordinates, as well as other metadata.\n\n### Acknowledgements\n\nA big thanks to wikipedia.'","b""['world', 'united states', 'geography', 'cartography', 'medium', 'featured']""",https://www.kaggle.com/ehallmar/points-of-interest-poi-database
b'NYS Patient Characteristics Survey (PCS): 2015',b'From New York State Open Data',"b""### Content  \n\nThe number of persons described by survey year (2015)\nreported in OMH Region\xe2\x80\x90specific totals (Region of Provider)\nand three demographic characteristics of the client served\nduring the week of the survey: sex (Male, Female, and Unknown), Transgender (No, Not Transgender; Yes, Transgender and Unknown), age (below 17 (Child), 18 and above(Adult) and unknown age) and race (White only, Black Only, Multi\xe2\x80\x90racial, Other and Unknown race) and ethnicity (Non\xe2\x80\x90Hispanic, Hispanic, Client Did Not Answer and Unknown). Persons with Hispanic ethnicity are grouped as \xe2\x80\x9cHispanic,\xe2\x80\x9d regardless of race or races reported.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/2wWmWvg3zF8) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'mental health', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-patient-characteristics-survey-pcs-2015
b'New York City CATS Permits',b'From New York City Open Data',"b""### Content  \n\nContains information on current boiler and industrial operation permits in New York City registered with  DEP.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/InMS8UZ5Ki8) by [Colin Avery](https://unsplash.com/@shofukan) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/new-york-city-cats-permits
"b'Chicago Beach Swim, Weather, Lab Data'",b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: ODbL-1.0, ODbL-1.0, ODbL-1.0, ODbL-1.0, ODbL-1.0""","b""['socrata', 'weather', 'utility', 'small', 'featured']""","https://www.kaggle.com/chicago/chicago-beach-swim,-weather,-lab-data"
b'LA Restaurant & Market Health Data',b'From Los Angeles Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/MQwQk93YISE) by [Eerik Sandstrom](https://unsplash.com/@mountainmofo) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain U.S. Government""","b""['socrata', 'food and drink', 'health', 'small', 'featured']""",https://www.kaggle.com/cityofLA/la-restaurant-market-health-data
b'Kickstarter Projects',"b'More than 300,000 kickstarter projects'","b""### Context\n\nI'm a crowdfunding enthusiast and i'm watching kickstarter since its early days. Right now I just collect data and the only app i've made is this twitter bot which tweet any project reaching some milestone: @bloomwatcher . I have a lot of other ideas, but sadly not enough time to develop them... But I hope you can!\n\n### Content\n\nYou'll find most useful data for project analysis. Columns are self explanatory except:\n\n- usd_pledged: conversion in US dollars of the pledged column  (conversion done by kickstarter).\n\n- usd pledge real: conversion in US dollars of the pledged column (conversion from [Fixer.io API][1]).\n\n- usd goal real: conversion in US dollars of the goal column (conversion from [Fixer.io API][1]).\n\n### Acknowledgements\n\nData are collected from [Kickstarter Platform][2]\n\nusd conversion (usd_pledged_real and usd_goal_real columns) were generated from [convert ks pledges to usd][3] script done by [tonyplaysguitar][4] \n\n### Inspiration\n\nI hope to see great projects, and why not a model to predict if a project will be successful before it is released? :)\n\n\n  [1]: http://Fixer.io\n  [2]: https://www.kickstarter.com/\n  [3]: https://www.kaggle.com/tonyplaysguitar/convert-ks-pledges-to-usd/\n  [4]: https://www.kaggle.com/tonyplaysguitar""","b""['finance', 'crowdfunding', 'medium', 'featured']""",https://www.kaggle.com/kemical/kickstarter-projects
b'New York City Film Permits',b'From New York City Open Data',"b""### Content  \n\nPermits are generally required when asserting the exclusive use of city property, like a sidewalk, a street, or a park. See http://www1.nyc.gov/site/mome/permits/when-permit-required.page  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/G-jJdZhE0mw) by [Corinne Lanthemann](https://unsplash.com/@cxre96) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'film', 'small', 'featured']""",https://www.kaggle.com/new-york-city/new-york-city-film-permits
"b'Wayfinding, Path Planning, and Navigation Dataset'","b'Indoor trajectories dataset for wayfinding, path planning and navigation'","b""### Context\n\nGANs have been used widely for vision-based tasks to generate new samples from the available data, while the generated images cannot be easily distinguished from the real images. Inspired by the success of this technique, we intend to use GANs for IoT settings in wayfinding and path planning applications. This dataset was created to perform a proof-of-concept based on this idea. \n\n### Content\n\nThis dataset contains samples of the trajectories in an indoor building (Waldo Library at Western Michigan University) for navigation and wayfinding applications. We have 6 different classes that define the source and target of a path (in pathClasses.csv). The dataset is labeled such that the names of sample files contains the Id of the path between the source and destination points.\n\nEach class has about 52 samples with a total of 313 samples that are stored as CSV files. Each file resembles a frame containing the path in the indoor environment. A path frame is a matrix of the size of 19*13 in which the item at indexes (i, j) indicates that the corresponding position of (i, j) constitute the path or not. The CSV files are named with their class, followed by a '_' and then an index.\n\nAll the paths are created based on a baseline layout (public_accesss_area_layout.csv) that specifies the public access areas in the building.\n![Public access area](https://www.kaggle.com/mehdimka/path-planning/downloads/public_access_area.png)\n\nSample paths from (0,0) to (14,7)\n\n![Sample path1](https://www.kaggle.com/mehdimka/path-planning/downloads/00_016.png)\n![Sample path2](https://www.kaggle.com/mehdimka/path-planning/downloads/00_031.png)\n\nSample paths from (0,0) to (16,12)\n\n![Sample path3](https://www.kaggle.com/mehdimka/path-planning/downloads/01_035.png)\n![Sample path4](https://www.kaggle.com/mehdimka/path-planning/downloads/01_047.png)\n\n### Acknowledgements\n\nProvider: Mehdi Mohammadi, Sepideh Mohammadi, and Ala Al-Fuqaha, {mehdi.mohammadi, sepideh.mohammadi, ala.al-fuqaha}@wmich.edu, Department of Computer Science, Western Michigan University.\n\nCitation request:\n\nMohammadi, M., Al-Fuqaha, A. and Oh, J.S., 2018. Path Planning in Support of Smart Mobility Applications using Generative Adversarial Networks. [arXiv preprint arXiv:1804.08396][1].\n\n### Inspiration\nHow can the quality of generated paths be measured automatically? How to learn the generated paths are novel (i.e., they are not reproduced from existing samples)?\n\n\n  [1]: https://arxiv.org/pdf/1804.08396.pdf""","b""['classification', 'internet', 'road transport', 'universities and colleges', 'navigation', 'small', 'featured']""",https://www.kaggle.com/mehdimka/path-planning
"b'freeCodeCamp Gitter Chat, 2015-2017'",b'Three years and 5 million posts in freeCodeCamp chat',"b'### Context\n\nPosts extracted from a Gitter\'s public chatroom used for an online course to learn to program.\n\nThe files contains the posts from students, bots, moderators and contributors in the main (""/freeCodeCamp"") Gitter chatroom between 31-Dec-2014 until the first days of Dec-2017. There are around 5 million posts from near 400,000 users (all estimates). Data was extracted using Python code over the [Gitter API](https://developer.gitter.im/docs/rest-api). Records are not anonymised or modified and are presented ""as they are"".\n\nThe datasets are a contribution from [freeCodeCamp](https://www.freecodecamp.org/) as part of the [freeCodeCamp\'s Open Data Initiative](https://github.com/freeCodeCamp/open-data). More information about the rationale of this initiative can be found in this [announcement of us releasing the chat history dataset](https://medium.freecodecamp.org/we-just-released-3-years-of-freecodecamp-chat-history-as-open-data-all-5-million-messages-of-it-a03901f4d6fb). \n\n\n### Content\n\n1. `freecodecamp_casual_chatroom_(01/02/03).json` datasets, json files of the posts of users in the Gitter main chatroom. Details about the structure of each post can be found at Gitter Rest-API documentation. Example (one single record):\n\n        [ {\n        ""Id"":""5330521e20d939a3be000018"",    //id of the message\n        ""text"":""Happy Hacking!"",\n        ""html"":""Happy Hacking!"",\n        ""sent"":""2014-03-24T15:41:18.991Z"", //timezone of the post\'s reader\n        ""editedAt"":null,\n        ""fromUser"":\n        {\n        ""Id"":""5315ef029517002db7dde53b"", //id of the poster \n        ""username"":""malditogeek"",\n        ""displayName"":""Mauro Pompilio"",\n        ""url"":""/malditogeek"",\n        ""avatarUrlSmall"":""https://avatars.githubusercontent.com/u/14751?"",\n        ""avatarUrlMedium"":""https://avatars.githubusercontent.com/u/14751?"",\n        ""v"":2\n        },\n        ""unread"":false,\n        ""readBy"":0,\n        ""Urls"":[],                         //urls found in the text message\n        ""Mentions"":[],                     //other users mentioned in the text message\n        ""issues"":[],\n        ""meta"":{},\n        ""v"":1\n        } ]\n\n\nThe three files make a continuous dataset containing all posts sent during the aforementioned period. The three files might present overlapping between some days.\n\n**IMPORTANT**: time reported per record fits Western European timezone. Be aware of possible effect on time mismatches due to summer time changes! Dates of extraction are:\n\n* `freecodecamp_casual_chatroom_01.json` : 01-06-2016\n\n* `freecodecamp_casual_chatroom_02.json` : 09-03-2017\n\n* `freecodecamp_casual_chatroom_03.json` : 12-12-2017\n\n\n### Acknowledgements\n\nAll the files were prepared by Evaristo Caraballo (GitHub: @evaristoc).\n\nThanks to freeCodeCamp team, specially to Quincy Larson for supporting the initiative. Thanks to all freeCodeCamp students who kindly allowed to share their personal progress and to Gitter for making these data available.\n\n### Publications\n\nSome preliminary analyses using this dataset can be found at the Github repository for the [freeCodeCamp\'s Open Data Initiative](https://github.com/freeCodeCamp/open-data).\n\n### Contact\n\nIf you have questions about this dataset, please contact quincy@freecodecamp.com or get in touch with us through https://gitter.im/FreeCodeCamp/DataScience (Gitter registration might be required).'","b""['internet', 'education', 'social groups', 'medium', 'featured']""",https://www.kaggle.com/freecodecamp/all-posts-public-main-chatroom
b'FiveThirtyEight Bad Drivers Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Bad Drivers\n\nThis folder contains data behind the story [Dear Mona, Which State Has The Worst Drivers?](http://fivethirtyeight.com/datalab/which-state-has-the-worst-drivers/)\n\nVariable | Source\n---|---------\n`State` | N/A\n`Number of drivers involved in fatal collisions per billion miles` | National Highway Traffic Safety Administration, 2012\n`Percentage Of Drivers Involved In Fatal Collisions Who Were Speeding` | National Highway Traffic Safety Administration, 2009\n`Percentage Of Drivers Involved In Fatal Collisions Who Were Alcohol-Impaired` | National Highway Traffic Safety Administration, 2012\n`Percentage Of Drivers Involved In Fatal Collisions Who Were Not Distracted`\t | National Highway Traffic Safety Administration, 2012\n`Percentage Of Drivers Involved In Fatal Collisions Who Had Not Been Involved In Any Previous Accidents` | National Highway Traffic Safety Administration, 2012\n`Car Insurance Premiums ($)` | National Association of Insurance Commissioners, 2011\n`Losses incurred by insurance companies for collisions per insured driver ($)` | National Association of Insurance Commissioners, 2010\n  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-bad-drivers-dataset
b'African Fabric Images',b'Image Dataset of African Fabric Patterns and Textiles',"b""### Context\nI needed to work on using GANs to generate African fabrics but they weren't any available dataset for it. So I had to source for image dataset of African fabrics and wax patterns. Open data was definitely the next step.  \n\n\n### Content\nThe current dataset is of about 1056 images with size: 64x64.\nThe dataset is not yet partitioned into test and training set. \nIt is a zipped file of about 7mb.\n\n\n### Acknowledgements\nA bulk of these images were gotten from google image searches.\n\n\n### Inspiration\nAfrica has so much untapped data that when fused with machine intelligence could trigger diverse exploration.""","b""['cnn', 'africa', 'gan', 'small', 'featured']""",https://www.kaggle.com/mikuns/african-fabric
b'Geological Texture Database',"b'Location, description, and texture of samples.'","b'### Context\n\nThis sediment database contains location, description, and texture of samples taken by numerous marine sampling programs. Most of the samples are from the Atlantic Continental Margin of the United States, but some are from as diverse locations as Lake Baikal, Russia, the Hawaiian Islands region, Puerto Rico, the Gulf of Mexico, and Lake Michigan. The database presently contains data for over 27,000 samples, which includes texture data for approximately 3800 samples taken or analyzed by the Atlantic Continental Margin Program (ACMP), a joint U.S. Geological Survey/Woods Hole Oceanographic Institution project conducted from 1962 to 1970. As part of the ACMP, some historical data from samples collected between 1955 and 1962 were also incorporated into the dataset.\n\n\n### Content\n\nSome rows \n\nAREA                      27784 non-null object  \nLATITUDE             27784 non-null float64  \nLONGITUDE         27784 non-null float64  \nDEPTH_M              27784 non-null float64  \nT_DEPTH               27784 non-null float64  \nB_DEPTH               27784 non-null float64  \nDEVICE                  27784 non-null object  \nMONTH_COLL      27784 non-null int64  \nDAY_COLL              27784 non-null object  \nYEAR_COLL           27784 non-null int64  \n\n\n### Acknowledgements\n\nCsv file found here :\nhttps://catalog.data.gov/dataset/ecstdb2014-shp-u-s-geological-survey-east-coast-sediment-texture-database-201446d0d'","b""['data visualization', 'text data', 'databases', 'water technology', 'small', 'featured']""",https://www.kaggle.com/eivindstroemsvaag/daddad
"b""NSE Listed 1000+ Companies' Historical Data""",b'Indian stock data from the NSE',"b""### Context\nThe Dataset here is the CSV (Comma Separated Value) formatted data of 1000+ Indian companies' historical stock data which are listed on NSE web scrapped using python. This data helps the community to dive into algorithmic trading using the ML techniques and can be used for any task. Hope this will be of great use for everyone. \n \n\n### Content\n\nThis dataset(.zip) is a collection of numerous CSV formatted files that are in format of ['Date','Open','high','low','close','adj close','volume']. I've acquired this data using the yahoo finance v7 server using the python requests and a bit of pre-processing.\n\n - Maruti_data.csv is the sample data of Maruti stock data from 2003-07 to till data (updated on 18-Feb-2018) .\n- Companies_dict.d is the python pickle dictionary variable to get company name from the SYMBOL or name if the csv file. You can load this using the pickle library and get the actual company SYMBOL to Legal Name. \n###### `e.g.Python Code`\n###### ` Symbol2Name =  pickle.load(open('company_symbol_name_dict.d','rb'))`\n###### `print(Symbol2Name['MARUTI']) #Will give you Maruti_Suzuki_India_Ltd`\n\n\n### Acknowledgements\n\nI would like to thank this [githubrepo](https://github.com/sjev/trading-with-python.git) for making the python file this script of mine is based on.\n\n\n### Inspiration\n\nI would love to see many people like me to get their hands dirty with this data and use it effectively to correlate the inter relationships among the companies.""","b""['deep learning', 'finance', 'business', 'artificial intelligence', 'money', 'medium', 'featured']""",https://www.kaggle.com/abhishekyana/nse-listed-1384-companies-data
b'FIFA World Cup 2018 Tweets',b'A collection of tweets during the 2018 FIFA World Cup',"b'**Context:**\n------------\nThe FIFA World Cup (often simply called the World Cup\xe2\x80\x8a), \xe2\x80\x8abeing the most prestigious association football tournament, as well as the most widely viewed and followed sporting event in the world, was one of the Top Trending topics frequently on Twitter while ongoing.&nbsp;<br> <br>\nThis dataset contains a random collection of 530k tweets starting from the Round of 16 till the World Cup Final that took place on 15 July, 2018 & was won by France<br>\nA preliminary analysis from the data (till the Round of 16) is available at: <br>\n[https://medium.com/@ritu_rg/nlp-text-visualization-twitter-sentiment-analysis-in-r-5ac22c778448][1]\n\n\n**Content:**\n------------\n**Data Collection:**  <br>\nThe dataset was created using the Tweepy API, by streaming tweets from world-wide football fans before, during or after the matches.  <br> \nTweepy is a Python API for accessing the Twitter API, that provides an easy-to-use interface for streaming real-time data from Twitter. More information related to this API can be found at: http://tweepy.readthedocs.io/en/v3.5.0/ <br> <br>\n\n**Data Pre-processing:**  <br>\nThe dataset includes English language tweets containing any references to FIFA or the World Cup. The collected tweets have been pre-processed to facilitate analysis\xe2\x80\x8a, while trying to ensure that any information from the original tweets is not lost.&nbsp; <br>\n- The original tweet has been stored in the column ""Orig_tweet"".&nbsp; <br>\n- As part of pre-processing, using the ""BeautifulSoup"" & ""regex"" libraries in Python, the tweets have been cleaned off any nuances as required for natural language processing, such as website names, hashtags, user mentions, special characters, RTs, tabs, heading/trailing/multiple spaces, among others. <br>\n- Words containing extensions such as n\'t \'ll \'re \'ve have been replaced with their proper English language counterparts. Duplicate tweets have been removed from the dataset. <br>\n- The original Hashtags & User Mentions extracted during the above step have also been stored in separate columns. <br> <br>\n\n**Data Storage:**  <br>\nThe collected tweets have been consolidated into a single dataset & shared as a Comma Separated Values file ""FIFA.csv"". <br>\nEach tweet is uniquely identifiable by its ID, & characterized by the following attributes, per availability: <br>\n- ""Lang""\xe2\x80\x8a-\xe2\x80\x8aLanguage of the tweet <br>\n- ""Date""\xe2\x80\x8a-\xe2\x80\x8aWhen it was tweeted <br>\n- ""Source""\xe2\x80\x8a-\xe2\x80\x8aThe device/medium where it was tweeted from <br>\n- ""len""\xe2\x80\x8a-\xe2\x80\x8aThe length of the tweet <br>\n- ""Orig_Tweet""\xe2\x80\x8a-\xe2\x80\x8aThe tweet in its original form <br>\n- ""Tweet""\xe2\x80\x8a-\xe2\x80\x8aThe updated tweet after pre-processing <br>\n- ""Likes""\xe2\x80\x8a-\xe2\x80\x8aThe number of likes received by the tweet (till the time the extraction was done) <br>\n- ""RTs""\xe2\x80\x8a-\xe2\x80\x8aThe number of times the tweet was shared <br>\n- ""Hashtags""\xe2\x80\x8a-\xe2\x80\x8aThe Hashtags found in the original tweet <br>\n- ""UserMentionNames"" & ""UserMentionID""\xe2\x80\x8a-\xe2\x80\x8a Extracted from the original tweet <br> <br>\n\nIt also includes the following attributes about the person that the tweet is from: <br>\n- ""Name"" & ""Place"" of the user <br>\n- ""Followers""\xe2\x80\x8a-\xe2\x80\x8aThe number of followers that the user account has <br>\n- ""Friends""\xe2\x80\x8a-\xe2\x80\x8aThe number of friends the user account has <br>\n\n\n**Acknowledgements:** <br>\n-----------------\nThe following resources have helped me through using the Tweepy API: <br>\n[http://tweepy.readthedocs.io/en/v3.5.0/auth_tutorial.html][2] <br>\n[https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets][3] <br>\n[https://www.safaribooksonline.com/library/view/mining-the-social/9781449368180/ch01.html][4] <br>\n\n\n\n**Inspiration:** <br>\n------------\nThis project gave me a fascinating look into the conversations & sentiments of people from all over the world, who were following this prestigious football tournament, while also giving me the opportunity to explore some of the streaming, natural language processing & visualizations techniques in both R & Python <br> <br>\n\n\n  [1]: https://medium.com/@ritu_rg/nlp-text-visualization-twitter-sentiment-analysis-in-r-5ac22c778448\n  [2]: http://tweepy.readthedocs.io/en/v3.5.0/auth_tutorial.html\n  [3]: https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets\n  [4]: https://www.safaribooksonline.com/library/view/mining-the-social/9781449368180/ch01.html'","b""['twitter', 'medium', 'featured']""",https://www.kaggle.com/rgupta09/world-cup-2018-tweets
b'ASL Alphabet Test',b'ASL Alphabet Images with a variety of backgrounds for validating a model',"b""This data set consists of a set of 870 images. Each image contains a hand making the shape of an ASL letter (with some variation). The purpose of this data set is to act as a sort of validation set to see how good the preprocessing and the model are, based on the following ASL Alphabet data set also available on Kaggle: https://www.kaggle.com/grassknoted/asl-alphabet.\n\n\n### Content\n\nThere are 30 images for each symbol, A-Z, delete, space, and nothing, making 870 images in total. The images are 200x200 8-bit photos to match the [asl-alphabet](https://www.kaggle.com/grassknoted/asl-alphabet) data set, and are organized in a folder structure to make it easy to use `flow_from_directory` in Keras.\n\n### Acknowledgements\n\nThe idea for this data set came about because of the [ASL Alphabet](https://www.kaggle.com/grassknoted/asl-alphabet) data set.\n\nBanner and thumbnail photo by [Sebasti\xc3\xa1n Le\xc3\xb3n Prado on Unsplash](https://unsplash.com/photos/gbfRAzWR03E).\n\n### Inspiration\n\nThis data set is being used as part of a project for the W207 Applied Machine Learning class in UC Berkeley's master of information and data science program (MIDS).""","b""['image data', 'linguistics', 'image processing', 'medium', 'featured']""",https://www.kaggle.com/danrasband/asl-alphabet-test
b'Caltech 256 Image Dataset',"b'Over 30,000 images in 256 object categories'","b'### Context\nThe Caltech 256 is considered an improvement to its predecessor, the Caltech 101 dataset, with new features such as larger category sizes, new and larger clutter categories, and overall increased difficulty. This is a great dataset to train models for visual recognition: How can we recognize frogs, cell phones, sail boats and many other categories in cluttered pictures? How can we learn these categories in the first place? Can we endow machines with the same ability? \n\n### Content\nThere are 30,607 images in this dataset spanning 257 object categories. Object categories are extremely diverse, ranging from grasshopper to tuning fork. The distribution of images per category are:\n\n- Min: 80\n- Med: 100\n- Mean: 119\n- Max: 827\n\n### Acknowledgements\n\nOriginal data source and banner image: http://www.vision.caltech.edu/Image_Datasets/Caltech256/\n\nWhen using this dataset, please remember to cite:\n\n*Griffin, G. Holub, AD. Perona, P.* \n**The Caltech 256.** \nCaltech Technical Report.\n\n### Inspiration\n- Can you build a model that IDs certain images?\n- What is the object? Is it a backpack, chopsticks, fried egg, or one of the other 253 object categories?'","b""['classification', 'image data', 'object recognition', 'object identification', 'large', 'featured']""",https://www.kaggle.com/jessicali9530/caltech256
b'SF Street Tree List',b'From San Francisco Open Data',"b""### Content  \n\nList of dpw maintained street trees including: Planting date, species, and location  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/y0kAUjL_RhQ) by [Victor Lugassy](https://unsplash.com/@maitrerenard) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/san-francisco/sf-street-tree-list
b'Predict FIFA 2018 Man of the Match',b'Match statistics with which team player has won Man of the match',"b""### Context\n\nI thought of consolidating and sharing this public data to see how the data science world uses it discover interesting patterns. The data has been collected from 2018 FIFA World Cup Russia Official App.\n\n### Content\nThe data will be updated after each match daily.\n\nNote: On the column '1st Goal', any goal that was scored in the extra time will be denoted as 45 or 90 based on 1st or 2nd half of the game (ex. if 1st goal was scored in 45+2 mins then it will be mentioned as 45 instead of 47, likewise for the 2nd half)\n\n### Acknowledgements\n\nThanks to the FIFA 2018 World Cup App.\n\n\n### Inspiration\nI thought of consolidating and sharing this public data to see how the data science world uses it discover interesting patterns. Can we predict the Man of the match award using this statistics before the official announcement that will be made right after the match?""","b""['sports', 'world', 'small', 'featured']""",https://www.kaggle.com/mathan/fifa-2018-match-statistics
b'Labelled Faces in the Wild (LFW) Dataset',"b'Over 13,000 images of faces collected from the web'","b'### Context\n\nLabeled Faces in the Wild (LFW) is a database of face photographs designed for studying the problem of unconstrained face recognition. This database was created and maintained by researchers at the University of Massachusetts, Amherst (specific references are in Acknowledgments section). 13,233 images of 5,749 people were detected and centered by the Viola Jones face detector and collected from the web. 1,680 of the people pictured have two or more distinct photos in the dataset. The original database contains four different sets of LFW images and also three different types of ""aligned"" images. According to the researchers, deep-funneled images produced superior results for most face verification algorithms compared to the other image types. Hence, the dataset uploaded here is the deep-funneled version. \n\n### Content\nThere are 11 files in this dataset. **lfw-deepfunneled.zip** is the file containing the images. **All other 10 files are relevant metadata** that may help you in forming your training and testing sets for your model. There are two sections below to help you navigate the files better. The first section provides information specifically pertaining to the images. The second section explains the content of each metadata file.\n\n**Image information:**\n\n- ***Image file format***: Each image is available as ""lfw/name/name_xxxx.jpg"" where ""xxxx"" is the image number padded to four characters with leading zeroes. For example, the 10th George_W_Bush image can be found as ""lfw/George_W_Bush/George_W_Bush_0010.jpg""\n- ***Image dimensions***: Each image is a 250x250 jpg, detected and centered using the openCV implementation of Viola-Jones face detector.  The cropping region returned by the detector was then automatically enlarged by a factor of 2.2 in each dimension to capture more of the head and then scaled to a uniform size.\n\n**Metadata information:**\n\n- ***lfwallnames.csv***: Contains all names of each face in the dataset along with number of images each face has.\n- ***lfwreadme.csv***: Comprehensive readme file found on the original database. If there is any information you are missing here or are looking for additional resources you will probably find it in this file. It explains how each .csv file comes into play when forming training and testing models, as well as column metadata information for figuring out what the .csv is talking about. The original website also gives recommendations on training/testing splits and comparison benchmarks. \n\nThere are **two recommended configurations** for developing training and testing sets (pairs vs people). Depending on which route you choose, you will use the following .csv files: \n\n- ***pairs.csv***: Contains randomly generated splits for 10-fold cross validation specifically for pairs. Use this for the image restricted configuration when forming training sets (refer to readme). There are 10 total sets; 5 sets contain 300 matched pairs, the other 5 sets contain 300 mismatched pairs. \n- ***people.csv***: Contains randomly generated splits for 10-fold cross validation specifically for individual faces. Use this for the unrestricted configuration when forming training sets (refer to readme). There are 10 total sets, each with a different amount of people; Set 1: 601. Set 2: 555. Set 3: 552. Set 4: 560. Set 5: 567. Set 6: 527. Set 7: 597. Set 8: 601. Set 9: 580. Set 10: 609.\n- ***matchpairsDevTest.csv***: Use this testing set if you decide to go with the pairs configuration. Contains 500 matched pairs of faces for testing set.\n- ***matchpairsDevTrain.csv***: Use this training set if you decide to go with the pairs configuration. Contains 1100 matched pairs of faces for training set.\n- ***mismatchpairsDevTest.csv***: Use this testing set if you decide to go with the pairs configuration. Contains 500 mismatched pairs of faces for testing set.\n- ***mismatchpairsDevTrain.csv***: Use this training set f you decide to go with the pairs configuration. Contains 1100 mismatched pairs of faces for training set.\n- ***peopleDevTest.csv***: Use this testing test if you decide to go with the people configuration. Contains 1711 people and 3708 images.\n- ***peopleDevTrain.csv***: Use this training set if you decide to go with the people configuration. Contains 4038 people and 9525 images.\n\n### Acknowledgements\nAll data and metadata were originally found on http://vis-www.cs.umass.edu/lfw/. Please visit the site for other data versions including original, non-aligned data as well as more information on errata and training/testing model resources.\n\nA big thank you and kudos to the creators of this dataset and relevant research:\n\n*Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\nLabeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments.\nUniversity of Massachusetts, Amherst, Technical Report 07-49, October, 2007.*\n\nSpecifically for the deep-funneled version of the image data: \n\n*Gary B. Huang, Marwan Mattar, Honglak Lee, and Erik Learned-Miller.\nLearning to Align from Scratch.\nAdvances in Neural Information Processing Systems (NIPS), 2012.*\n\nBanner photo by John Bakator on Unsplash\n\n### Inspiration\n\n- Can you form a model that correctly identifies images that are of the same person?\n- What about recognising gender, male or female?\n- What pictures are of Al Gore? Are there any faces that look similar to his? '","b""['classification', 'image data', 'image processing', 'object detection', 'medium', 'featured']""",https://www.kaggle.com/jessicali9530/lfw-dataset
b'Accredited Universities in the USA',b'Accreditation info from the Department of Education',"b""**Context**\n\nThis is a dataset provided by the Department of Education. Here's a link: https://ope.ed.gov/accreditation/GetDownLoadFile.aspx\n\n\n**Content**\n\n**Institution_ID**\nDatabase Specific Identification Number for Institution\n\n**Institution_Name**\t\n\n**Institution_Address**\t\n\n**Institution_City**\t\n\n**Institution_State**\t\n\n**Institution_Zip**\t\n\n**Institution_Phone**\t\n\n**Institution_OPEID**\nIdentification number used by the U.S. Department of Education's Office of Postsecondary Education (OPE) to identify schools that have Program Participation Agreements (PPA).\n\n**Institution_IPEDS_UnitID**\nA unique identification number for institutions that participate in the Integrated Postsecondary Education Data System Survey.\n\n**Institution_Web_Address**\t\n\n**Campus_ID**\t\nDatabase Specific Identification Number for Campus\n\n**Campus_Name**\t\n\n**Campus_Address**\n\t\n**Campus_City**\t\n\n**Campus_State**\t\n\n**Campus_Zip**\t\n\n**Campus_IPEDS_UnitID**\nA unique identification number for institutions that participate in the Integrated Postsecondary Education Data System Survey. \n\n**Accreditation_Type**\t\n\xe2\x80\xa2\tInstitutional \xe2\x80\x93 an accreditation type which normally applies to an entire institution, including freestanding single\xe2\x80\x93purpose institutions. Typically can be used to establish eligibility to participate in Title IV programs.\n\n\xe2\x80\xa2\tSpecialized \xe2\x80\x93 an accreditation type which normally applies to the evaluation of programs, departments, or schools which usually are parts of a total collegiate or other postsecondary institution.\n\n\xe2\x80\xa2\tInternship/Residency \xe2\x80\x93 an accreditation type which is granted to locations which provide practical training and/or specialized clinical training to advanced students or recent graduates in areas such as medicine, psychology, and dietetics.\n\n**Agency_Name**\t\n\n**Agency Status**\nIndicates whether an agency has lost or resigned recognition. \n\n**Program_Name**\t\nName of Accredited Program\n\n**Accreditation_Status**\t\n\xe2\x80\xa2\tPre\xe2\x80\x93Accredited \xe2\x80\x93 Public recognition that an accrediting agency grants an institution or program for a limited period which signifies the agency has determined that the institution or program is progressing towards accreditation and is likely to gain accreditation.\n\n\xe2\x80\xa2\tAccredited \xe2\x80\x93 Public recognition that an institution or program maintains standards requisite for its graduates to gain admission to other reputable institutions of higher learning or to achieve credentials for professional practice\n\n**Accreditation_Date_Type**\nIndicator for actual or estimated initial date of accreditation/pre\xe2\x80\x93accreditation\n\n**Periods**\nPeriod of accreditation in form (initial date \xe2\x80\x93 end date)\n\n**Last Action**\nThe most recent accreditation action for this accreditation record. \nPlease see the glossary on the site (https://ope.ed.gov/accreditation/Glossary.aspx) for individual definitions. \nAction Date\nDate of the most recent accreditation action.\n\n**Justification**\nProvides the reasoning behind the most recent accreditation action.\n\n**Other_Justification**\nProvides for justifications not found in the system or allows an agency to report multiple justifications for the most recent accreditation action. \n\n**Justification_Url**\nProvides a link to an accrediting agency hosted page which provides additional information about the most recent action and the justification for that action.\n\n""","b""['united states', 'universities and colleges', 'north america', 'small', 'featured']""",https://www.kaggle.com/ghalebdweikat/accredited-universities-in-the-usa
b'Accidents in France from 2005 to 2016',b'Help prevent accidents.',"b'### Context\n\nEvery year, road accidents cause thousands of deaths. \nI strongly Believe that Data Science can be used for good, That\'s why I decided to make this contribution.\n\nHere Is the description of the tables :\n\n\n### Content\n\n----------------------------------------------------------------------- \n\n**CARACTERISTICS** :\n\n**Num_Acc** : Accident ID\n\n**jour** : Day of the accident\n\n**mois** : Month of the accident\n\n**an** : Year of the accident\n\n**hrmn** : Time of the accident in hour and minutes (hhmm)\n\n**lum** : Lighting : lighting conditions in which the accident occurred\n\n- 1 - Full day\n\n- 2 - Twilight or dawn\n\n- 3 - Night without public lighting\n\n- 4 - Night with public lighting not lit\n\n- 5 - Night with public lighting on\n\n\n**dep** :  Departmeent : INSEE Code (National Institute of Statistics and Economic Studies) of the departmeent followed\nby a 0 (201 Corse-du-Sud - 202 Haute-Corse)\n\n\n**com** : Municipality: The commune number is a code given by INSEE. The code has 3 numbers set to the right.\n\n\n**Localisation** :\n\n- 1 - Out of agglomeration\n\n- 2 - In built-up areas\n\n**int** : Type of Intersection :\n\n- 1 - Out of intersection\n\n- 2 - Intersection in X\n\n- 3 - Intersection in T\n\n- 4 - Intersection in Y\n\n- 5 - Intersection with more than 4 branches\n\n- 6 - Giratory\n\n- 7 - Place\n\n- 8 - Level crossing\n\n- 9 - Other intersection\n\n**atm** : Atmospheric conditions:\n\n- 1 - Normal\n\n- 2 - Light rain\n\n- 3 - Heavy rain\n\n- 4 - Snow - hail\n\n- 5 - Fog - smoke\n\n- 6 - Strong wind - storm\n\n- 7 - Dazzling weather\n\n- 8 - Cloudy weather\n\n- 9 - Other\n\n\n**col** : Type of collision:\n\n- 1 - Two vehicles - frontal\n\n- 2 - Two vehicles - from the rear\n\n- 3 - Two vehicles - by the side\n\n- 4 - Three vehicles and more - in chain\n\n- 5 - Three or more vehicles - multiple collisions\n\n- 6 - Other collision\n\n- 7 - Without collision\n\n**adr** : Postal address: variable filled in for accidents occurring in built-up areas\n\n**gps** : GPS coding: 1 originator character:\n\n- M = M\xc3\xa9tropole\n\n- A = Antilles (Martinique or Guadeloupe)\n\n- G = Guyane\n\n- R = R\xc3\xa9union\n\n- Y = Mayotte\n\nGeographic coordinates in decimal degrees:\n\n- lat : Latitude\n\n- long : Longitude\n\n-----------------------------------------------------------------------\n**Places**:\n\n**Num_Acc** : Accident ID\n\n**catr** : Category of road:\n\n- 1 - Highway\n\n- 2 - National Road\n\n- 3 - Departmental Road\n\n- 4 - Communal Way\n\n- 5 - Off public network\n\n- 6 - Parking lot open to public traffic\n\n- 9 - other\n\n**voie** : Road Number\n\n**V1**: Numeric index of the route number (example: 2 bis, 3 ter etc.)\n\n**V2**: Letter alphanumeric index of the road\n\n**circ**: Traffic regime:\n\n- 1 - One way\n\n- 2 - Bidirectional\n\n- 3 - Separated carriageways\n\n- 4 - With variable assignment channels\n\n**nbv**: Total number of traffic lanes\n\n**vosp**: Indicates the existence of a reserved lane, regardless of whether or not the accident occurs on that lane.\n\n- 1 - Bike path\n\n- 2 - Cycle Bank\n\n- 3 - Reserved channel\n\n**Prof**: Longitudinal profile describes the gradient of the road at the accident site\n\n- 1 - Dish\n\n- 2 - Slope\n\n- 3 - Hilltop\n\n- 4- Hill bottom\n\n**pr**: Home PR number (upstream terminal number)\n\n**pr1**: Distance in meters to the PR (relative to the upstream terminal)\n\n**plan**: Drawing in plan:\n\n- 1 - Straight part\n\n- 2 - Curved on the left\n\n- 3 - Curved right\n\n- 4 - In ""S""\n\n**lartpc**: Central solid land width (TPC) if there is\n\n**larrout**: Width of the roadway assigned to vehicle traffic are not included the emergency stop strips,\nCPRs and parking spaces\n\n**surf**: surface condition\n\n- 1 - normal\n\n- 2 - wet\n\n- 3 - puddles\n\n- 4 - flooded\n\n- 5 - snow\n\n- 6 - mud\n\n\n- 7 - icy\n\n- 8 - fat - oil\n\n- 9 - other\n\n**infra**: Development - Infrastructure:\n\n- 1 - Underground - tunnel\n\n- 2 - Bridge - autopont\n\n- 3 - Exchanger or connection brace\n\n- 4 - Railway\n\n- 5 - Carrefour arranged\n\n- 6 - Pedestrian area\n\n- 7 - Toll zone\n\n**situ**: Situation of the accident:\n\n- 1 - On the road\n\n- 2 - On emergency stop band\n\n- 3 - On the verge\n\n- 4 - On the sidewalk\n\n- 5 - On bike path\n\n**env1**: school point: near a school\n\n-----------------------------------------------------------------------\n**USERS**:\n\n**Acc_number**: Accident identifier.\n\n**Num_Veh**: Identification of the vehicle taken back for each user occupying this vehicle (including pedestrians who are\nattached to the vehicles that hit them)\n\n**place**: Allows to locate the place occupied in the vehicle by the user at the time of the accident\n\n**catu**: User category:\n\n- 1 - Driver\n\n- 2 - Passenger\n\n- 3 - Pedestrian\n\n- 4 - Pedestrian in rollerblade or scooter\n\n**grav**: Severity of the accident: The injured users are classified into three categories of victims plus the uninjured\n\n- 1 - Unscathed\n\n- 2 - Killed\n\n- 3 - Hospitalized wounded\n\n- 4 - Light injury\n\n**sex**: Sex of the user\n\n- 1 - Male\n\n- 2 - Female\n\n**Year_on**: Year of birth of the user\n\n**trip**: Reason for traveling at the time of the accident:\n\n- 1 - Home - work\n\n- 2 - Home - school\n\n- 3 - Shopping - Shopping\n\n- 4 - Professional use\n\n- 5 - Promenade - leisure\n\n- 9 - Other\n\n**secu**: on 2 characters:\nthe first concerns the existence of a safety equipment\n\n- 1 - Belt\n\n- 2 - Helmet\n\n- 3 - Children\'s device\n\n- 4 - Reflective equipment\n\n- 9 - Other\n\nthe second is the use of Safety Equipment\n\n- 1 - Yes\n\n- 2 - No\n\n- 3 - Not determinable\n\n**locp**: Location of the pedestrian:\n\nOn pavement:\n\n- 1 - A + 50 m from the pedestrian crossing\n\n- 2 - A - 50 m from the pedestrian crossing\n\nOn pedestrian crossing:\n\n- 3 - Without light signaling\n\n- 4 - With light signaling\n\nVarious:\n\n- 5 - On the sidewalk\n\n- 6 - On the verge\n\n- 7 - On refuge or BAU\n\n- 8 - On against aisle\n\n**actp**: Action of the pedestrian:\n\nMoving\n\n- 0 - not specified or not applicable\n\n- 1 - Meaning bumping vehicle\n\n- 2 - Opposite direction of the vehicle\nVarious\n\n- 3 - Crossing\n\n- 4 - Masked\n\n- 5 - Playing - running\n\n- 6 - With animal\n\n- 9 - Other\n\n**etatp**: This variable is used to specify whether the injured pedestrian was alone or not\n\n- 1 - Only\n\n- 2 - Accompanied\n\n- 3 - In a group\n\n-----------------------------------------------------------------------\n**VEHICLES**:\n\n**Num_Acc**\nAccident ID\n\n**Num_Veh**\nIdentification of the vehicle taken back for each user occupying this vehicle (including pedestrians who are\nattached to vehicles that hit them) - alphanumeric code\n\n**GP**\nFlow direction :\n\n- 1 - PK or PR or increasing postal address number\n\n- 2 - PK or PR or descending postal address number\n\n**CATV**\nCategory of vehicle:\n\n- 01 - Bicycle\n\n- 02 - Moped &lt;50cm3\n\n- 03 - Cart (Quadricycle with bodied motor) (formerly ""cart or motor tricycle"")\n\n- 04 - Not used since 2006 (registered scooter)\n\n- 05 - Not used since 2006 (motorcycle)\n\n- 06 - Not used since 2006 (side-car)\n\n- 07 - VL only\n\n- 08 - Not used category (VL + caravan)\n\n- 09 - Not used category (VL + trailer)\n\n- 10 - VU only 1,5T &lt;= GVW &lt;= 3,5T with or without trailer (formerly VU only 1,5T &lt;= GVW &lt;= 3,5T)\n\n- 11 - Most used since 2006 (VU (10) + caravan)\n\n- 12 - Most used since 2006 (VU (10) + trailer)\n\n- 13 - PL only 3,5T '","b""['data visualization', 'demographics', 'time series', 'vehicles', 'mortality', 'medium', 'featured']""",https://www.kaggle.com/ahmedlahlou/accidents-in-france-from-2005-to-2016
"b""Women's E-Commerce Clothing Reviews""","b'23,000 Customer Reviews and Ratings '","b'### Context\n\nWelcome. This is a Women\xe2\x80\x99s Clothing E-Commerce dataset revolving around the reviews written by customers. Its nine supportive features offer a great environment to parse out the text through its multiple dimensions. Because this is real commercial data, it has been anonymized, and references to the company in the review text and body have been replaced with \xe2\x80\x9cretailer\xe2\x80\x9d.\n\n### Content\n\nThis dataset includes 23486 rows and 10 feature variables. Each row corresponds to a customer review, and includes the variables:\n\n - **Clothing ID:** Integer Categorical variable that refers to the specific piece being reviewed. \n - **Age:** Positive Integer variable of the reviewers age.\n - **Title:** String variable for the title of the review.\n - **Review Text:** String variable for the review body. \n - **Rating:** Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best. \n - **Recommended IND:** Binary variable stating where the customer recommends the    product where 1 is recommended, 0 is not recommended.    \n - **Positive Feedback Count:** Positive Integer documenting the number of other customers who found this review positive.\n - **Division Name:** Categorical name of the product high level division.\n - **Department Name:** Categorical name of the product department name.\n - **Class Name:** Categorical name of the product class name.\n\n### Acknowledgements\n\nAnonymous but real source\n\n### Inspiration\n\nI look forward to come quality NLP! There is also some great opportunities for feature engineering, and multivariate analysis.\n\n### Publications\n[Statistical Analysis on E-Commerce Reviews, with Sentiment Classification using Bidirectional Recurrent Neural Network](https://www.researchgate.net/publication/323545316_Statistical_Analysis_on_E-Commerce_Reviews_with_Sentiment_Classification_using_Bidirectional_Recurrent_Neural_Network) <br>\nby [Abien Fred Agarap](https://www.kaggle.com/afagarap) - [Github](https://github.com/AFAgarap/ecommerce-reviews-analysis)\n'","b""['internet', 'nlp', 'business', 'text mining', 'small', 'featured']""",https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews
b'NYS Spill Incidents',b'From New York State Open Data',"b""### Content  \n\nThis dataset contains records of spills of petroleum and other hazardous materials. Under State law and regulations, spills that could pollute the lands or waters of the state must be reported by the spiller (and, in some cases, by anyone who has knowledge of the spill). Examples of what may be included in a spill record includes: Administrative information (DEC region and unique seven-digit spill number). Program facility name. Spill date/time. Location. Spill source and cause. Material(s) and material type spilled. Quantity spilled and recovered. Units measured. Surface water bodies affected. Close date (cleanup activity finished and all paperwork completed).  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/3pz8hBJrnNA) by [Forest Simon](https://unsplash.com/@forest_s) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-spill-incidents
b'German Single speaker Speech Dataset',b'CSS10 German: Single speaker Speech Dataset',"b'### Context\n\nCSS10 is a collection of single speaker speech datasets for 10 languages. Each of them consists of audio files recorded by a sinlge volunteer and their aligned text sourced from LibriVox.\n\n### Content\nEach line in `transcript.txt` is delimited by `|` into four fields, i.e., audio file location, original script, normalized script, and audio duration.\n\nVisit [here](https://github.com/kyubyong/css10) to check out our project using this dataset.\n\n### Acknowledgements\n\nWe thank LibriVox and the volunteers.\n \n### Contact\nYou can contact me at kbpark.linguist@gmail.com.\n\nJune, 2018.\n\nKyubyong Park & Tommy Mulc\n'","b""['linguistics', 'large', 'featured']""",https://www.kaggle.com/bryanpark/german-single-speaker-speech-dataset
b'Traffic Violations in Maryland County',b'Complete set of traffic violation events from 2012 - 2018',"b'### Context\n\n**A short description on Traffic Violations**\n\nA traffic violation is any violation of vehicle laws that is committed by the driver of a vehicle, which constitutes a ""minor violation"" or infraction varies, examples include moving and non-moving violations, defective or improper vehicle equipment, seat belt and child-restraint safety violations, and insufficient proof of license, exceeding speed limit, insurance or registration. In contrast, for more ""serious"" violations, traffic violators may be held criminally liable, accused of a misdemeanor or even a felony. Serious violations tend to involve multiple prior offenses, willful disregard of public safety, death or serious bodily injury, or damage to property.\n\n**Moving Violations vs. Non-Moving Violations**\n\nA moving violation occurs whenever a traffic law is violated by a vehicle in motion. Some examples of moving violations are speeding, running a stop sign or red light, and drunk driving. A non-moving violation, by contrast, is usually related to parking or faulty equipment. Examples include parking in front of a fire hydrant, parking in a no-parking zone, parking in front of an expired meter, and excessive muffler noise.\n\n\n### Content\n\nThis data set contains all events of traffic violations from 2012 to 2018.  It has about 1.04 million records. \n\n**The data include items, such as:**\n\nAccident\t:\tIf traffic violation involved an accident.\n\nAgency\t:\tAgency issuing the traffic violation. (Example: MCP is Montgomery County Police)\n\nAlcohol\t:\tIf the traffic violation included an alcohol related\n\nArrest Type\t:\tType of Arrest (A = Marked, B = Unmarked, etc.)\n\nArticle\t:\tArticle of State Law. (TA = Transportation Article, MR = Maryland Rules)\n\nBelts\t:\tIf traffic violation involved a seat belt violation.\n\nCharge\t:\tNumeric code for the specific charge.\n\nColor\t:\tColor of the vehicle.\n\nCommercial License\t:\tIf driver holds a Commercial Drivers License.\n\nCommercial Vehicle\t:\tIf the vehicle committing the traffic violation is a commercial vehicle.\n\nContributed To Accident\t:\tIf the traffic violation was a contributing factor in an accident.\n\nDate Of Stop\t:\tDate of the traffic violation.\n\nDescription\t:\tText description of the specific charge.\n\nDL State\t:\tState issuing the Driver\xe2\x80\x99s License.\n\nDriver City\t:\tCity of the driver\xe2\x80\x99s home address.\n\nDriver State\t:\tState of the driver\xe2\x80\x99s home address.\n\nFatal\t:\tIf traffic violation involved a fatality.\n\nGender\t:\tGender of the driver (F = Female, M = Male)\n\nGeolocation\t:\tGeo-coded location information.\n\nHAZMAT\t:\tIf the traffic violation involved hazardous materials.\n\nLatitude\t:\tLatitude location of the traffic violation.\n\nLocation\t:\tLocation of the violation, usually an address or intersection.\n\nLongitude\t:\tLongitude location of the traffic violation.\n\nMake\t:\tManufacturer of the vehicle (Examples: Ford, Chevy, Honda, Toyota, etc.)\n\nModel\t:\tModel of the vehicle.\n\nPersonal Injury\t:\tIf traffic violation involved Personal Injury.\n\nProperty Damage\t:\tIf traffic violation involved Property Damage.\n\nRace\t:\tRace of the driver. (Example: Asian, Black, White, Other, etc.)\n\nState\t:\tState issuing the vehicle registration.\n\nSubAgency\t:\tCourt code representing the district of assignment of the officer. R15 = 1st district, Rockville B15 = 2nd \ndistrict, Bethesda SS15 = 3rd district, Silver Spring WG15 = 4th district, Wheaton G15 = 5th district, Germantown M15 = 6th district, Gaithersburg / Montgomery Village HQ15 = Headquarters and Special Operations\n\nTime Of Stop\t:\tTime of the traffic violation.\n\nVehicleType\t:\tType of vehicle (Examples: Automobile, Station Wagon, Heavy Duty Truck, etc.)\n\nViolation Type\t:\tViolation type. (Examples: Warning, Citation, SERO)\n\nWork Zone\t:\tIf the traffic violation was in a work zone.\n\nYear\t:\tYear vehicle was made.\n\n***The time period of this data ranges from 2012-2018***\n\n\n### Acknowledgements\n\n**This dataset was collected from [https://www.data.gov/][1]**\n\n[Click here for dataset][2]\n\n\n### Inspiration\n\n* Is there a strong  link between reckless drivers( under influence of alcohol,mobile phones  ) and road accidents.\n\n* Predict the likelihood of a driver causing road accident\n\n* Based on the description column details can we identify whether its a moving or a non moving traffic violation?\n\n* Finding daily trends and patterns for moving and non moving traffic violations\n\n\n  [1]: https://www.data.gov/\n  [2]: https://catalog.data.gov/dataset/traffic-violations-56dda'","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/rounak041993/traffic-violations-in-maryland-county
b'Articles sharing and reading from CI&T DeskDrop',b'Logs of users interactions on shared articles for content Recommender Systems',"b""### Context\n\n[**Deskdrop**](https://deskdrop.co/) is an internal communications platform developed by [CI&T](http://www.ciandt.com/), focused in companies using Google G Suite. Among other features, this platform allows companies employees to share relevant articles with their peers, and collaborate around them.  \n\n### Content\n\nThis rich and rare dataset contains a real sample of **12 months logs** (Mar. 2016 - Feb. 2017) from CI&T's Internal Communication platform (DeskDrop).    \nI contains about **73k logged users interactions** on more than **3k public articles shared** in the platform.   \n\nThis dataset features some distinctive characteristics:\n\n - **Item attributes**: Articles' original URL, title, and content plain text are available in two languages (English and Portuguese).   \n - **Contextual information**: Context of the users visits, like date/time, client (mobile native app / browser) and geolocation.  \n - **Logged users**: All users are required to login in the platform, providing a long-term tracking of users preferences (not depending on cookies in devices).  \n - **Rich implicit feedback**: Different interaction types were logged, making it possible to infer the user's level of interest in the articles (eg. comments > likes > views).\n - **Multi-platform**: Users interactions were tracked in different platforms (web browsers and mobile native apps)\n\n**If you like it, please upvote!**\n\nTake a look in these featured Python kernels:  \n - [**Deskdrop datasets EDA**](https://www.kaggle.com/gspmoreira/deskdrop-datasets-eda): Exploratory analysis of the articles and interactions in the dataset   \n - [**DeskDrop Articles Topic Modeling**](https://www.kaggle.com/gspmoreira/deskdrop-articles-topic-modeling): A statistical analysis of the main articles topics using [LDA](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)   \n - [**Recommender Systems in Python 101**](https://www.kaggle.com/gspmoreira/recommender-systems-in-python-101): A practical introduction of the main Recommender Systems approaches: Popularity model, Collaborative Filtering, Content-Based Filtering and Hybrid Filtering.   \n\n### Acknowledgements\n\nWe thank [CI&T](http://www.ciandt.com/) for the support and permission to share a sample of real usage data from its internal communication platform: [**Deskdrop**](https://deskdrop.co/).\n\n### Inspiration\nThe two main approaches for [Recommender Systems](https://en.wikipedia.org/wiki/Recommender_system) are Collaborative Filtering and Content-Based Filtering.  \n\nIn the RecSys community, there are some popular datasets available with users ratings on items (explicit feedback), like [MovieLens](http://www.recsyswiki.com/wiki/MovieLens) and [Netflix Prize](http://www.recsyswiki.com/wiki/Netflix_Prize), which are useful for Collaborative Filtering techniques.   \n\nTherefore, it is very difficult to find [open datasets](http://www.recsyswiki.com/wiki/Category:Dataset) with additional item attributes, which would allow the application of Content-Based filtering techniques or Hybrid approaches, specially in the domain of ephemeral textual items (eg. articles and news).  \n\nNews datasets are also reported in academic literature as very sparse, in the sense that, as users are usually not required to log in in news portals, IDs are based on device cookies, making it hard to track the users page visits in different portals, browsing sessions and devices.  \n\nThis difficult scenario for research and experiments on Content Recommender Systems was the main motivation for the sharing of this dataset.""","b""['internet', 'human-computer interaction', 'web sites', 'medium', 'featured']""",https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop
b'Tweets during Nintendo E3 2018 Conference',b'#NintendoE3 #NintendoDirect',"b""### Context\n\nData set containing Tweets captured during the **Nintendo E3 2018 Conference**. \n\n### Content\n\n All Twitter APIs that return Tweets provide that data encoded using JavaScript Object Notation (JSON). **JSON** is based on key-value pairs, with named attributes and associated values. The JSON file include the following objects and attributes: \n\n* **[Tweet](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object)** - Tweets are the basic atomic building block of all things Twitter. The Tweet object has a long list of \xe2\x80\x98root-level\xe2\x80\x99 attributes, including fundamental attributes such as `id`, `created_at`, and `text`. Tweet child objects include `user`, `entities`, and `extended_entities.` Tweets that are geo-tagged will have a `place` child object.\n\n    + **[User](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/user-object)** - Contains public Twitter account metadata and describes the author of the Tweet with attributes as `name`, `description`, `followers_count`, `friends_count`, etc.\n\n    + **[Entities](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/entities-object)** - Provide metadata and additional contextual information about content posted on Twitter. The `entities` section provides arrays of common things included in Tweets: hashtags, user mentions, links, stock tickers   (symbols), Twitter polls, and attached media.\n\n    + **[Extended Entities](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/extended-entities-object)** - All Tweets with attached photos, videos and animated GIFs will include an `extended_entities` JSON object.\n\n    + **[Places](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/geo-objects)** - Tweets can be associated with a location, generating a Tweet that has been \xe2\x80\x98geo-tagged.\xe2\x80\x99 \n\nMore information [here](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json). \n\n###Acknowledgements\n\nI used the `filterStream()` function to open a connection to Twitter's Streaming API, using the keywords **#NintendoE3** and **#NintendoDirect**. The capture started on **Tuesday, June 12th 04:00 am UCT** and finished on **Tuesday, June 12th 05:00 am UCT**.\n\n### Inspiration\n\n- Time analysis\n- Try text mining!\n-  Cross-language differences in Twitter\n- Use this data to produce a sentiment analysis\n- Twitter geolocation\n- Network analysis: graph theory, metrics and properties of the network, community detection, network visualization, etc. ""","b""['data visualization', 'video games', 'text mining', 'network analysis', 'medium', 'featured']""",https://www.kaggle.com/xvivancos/tweets-during-nintendo-e3-2018-conference
b'Stars from Gaia DR2 and RAVE DR5',"b'250K stars from Gaia DR2 and RAVE DR5, with parallax (distance), photometry.'","b'### Context\n\nThe RAVE dataset along with Gaia DR1 was used by Zackrisson et al. (2018), a paper on Dysonian SETI.\n\nGaia is a mission of the European Space Agency (ESA) that aims to accurately measure the position, distance and magnitude of over a billion stars. RAVE is a radial velocity dataset. RAVE also provides spectrophotometric parallax data, as well as cross-identification of stars with a number of other datasets, including Gaia DR2.\n\n### Content\n\nThis dataset is a combination of RAVE DR5 and Gaia DR2 sources. The data is obtained using the query tool of the [RAVE project.][1] The SQL query follows:\n\n    SELECT G.source_id,G.parallax,G.parallax_error,G.ra,G.dec,G.phot_g_mean_mag,G.phot_bp_mean_mag,G.phot_rp_mean_mag,G.l,G.b,G.pmra,G.pmdec, R.HRV AS r_hrv,R.Met_K AS r_metallicity,R.Algo_Conv_K AS r_quality,R.Mg AS r_mg,R.Si AS r_si,R.Ti AS r_ti,R.Fe AS r_fe,R.Ni AS r_ni,R.distance r_distance,R.parallax r_parallax,R.Jmag_2MASS r_jmag_2mass,R.Hmag_2MASS r_hmag_2mass,R.Kmag_2MASS r_kmag_2mass, R.RAdeg r_ra,R.DEdeg r_de, W1mag_ALLWISE r_w1mag_allwise, W2mag_ALLWISE r_w2mag_allwise, W3mag_ALLWISE r_w3mag_allwise, W4mag_ALLWISE r_w4mag_allwise, BTmag_TYCHO2 r_btmag_tycho2, VTmag_TYCHO2 r_vtmag_tycho2, Bmag_APASSDR9 r_bmag_apassdr9, Vmag_APASSDR9 r_vmag_apassdr9, rpmag_APASSDR9 r_rpmag_apassdr9, ipmag_APASSDR9 r_ipmag_apassdr9, Imag_DENIS r_imag_denis, Jmag_DENIS r_jmag_denis, Kmag_DENIS r_kmag_denis, B1mag_USNOB1 r_b1mag_usnob1, R1mag_USNOB1 r_r1mag_usnob1, B2mag_USNOB1 r_b2mag_usnob1, R2mag_USNOB1 r_r2mag_usnob1, Imag_USNOB1 r_imag_usnob1 FROM `RAVEPUB_DR5`.`RAVE_DR2gaia_source` G INNER JOIN `RAVEPUB_DR5`.`RAVE_DR5` R ON R.RAVE_OBS_ID=G.RAVE_OBS_ID WHERE G.parallax IS NOT NULL\n\nThe following processing was done:\n\n 1. Removed rows with missing values in any of the following columns: \t\t\t\n""ra"",\n\t\t\t""dec"",\n\t\t\t""pmra"",\n\t\t\t""pmdec"",\n\t\t\t""l"",\n\t\t\t""b"",\n\t\t\t""parallax"",\n\t\t\t""parallax_error"",\n\t\t\t""phot_g_mean_mag"",\n\t\t\t""phot_bp_mean_mag"",\n\t\t\t""phot_rp_mean_mag"",\n\t\t\t""r_hrv"",\n\t\t\t""r_metallicity"",\n\t\t\t""r_distance"",\n\t\t\t""r_parallax"",\n\t\t\t""r_jmag_2mass"",\n\t\t\t""r_hmag_2mass"",\n\t\t\t""r_kmag_2mass"",\n\t\t\t""r_mg"",\n\t\t\t""r_si"",\n\t\t\t""r_fe"",\t\t\t\n\t\t\t""r_quality"",\n\t\t\t""r_ra"",\n\t\t\t""r_de"",\n\t\t\t""r_w1mag_allwise"",\n\t\t\t""r_w2mag_allwise"",\n\t\t\t""r_w3mag_allwise"",\n\t\t\t""r_w4mag_allwise"",\n\t\t\t""r_bmag_apassdr9"",\n\t\t\t""r_vmag_apassdr9"",\n\t\t\t""r_rpmag_apassdr9"",\n\t\t\t""r_ipmag_apassdr9"",\n\t\t\t""r_imag_denis"",\n\t\t\t""r_jmag_denis"",\n\t\t\t""r_kmag_denis""\n 2. Averaged those values for rows that have the same Gaia ""source_id"".\n\n### Note\n\nAn alternative dataset is recommended: *[257k Gaia DR2 stars](https://www.kaggle.com/solorzano/257k-gaia-dr2-stars)*. It contains sources from the Northern and Southern Hemispheres. \n\n### Acknowledgements\n\nThis work has made use of data from the European Space Agency (ESA) mission Gaia (https://www.cosmos.esa.int/gaia), processed by the Gaia Data Processing and Analysis Consortium (DPAC, https://www.cosmos.esa.int/web/gaia/dpac/consortium). Funding for the DPAC has been provided by national institutions, in particular the institutions participating in the Gaia Multilateral Agreement.\n\n### References\n\nKunder et al. (2016). *The Radial Velocity Experiment (RAVE): Fifth Data Release*. arXiv:1609.03210\n\nZackrisson et al. (2018). *SETI with Gaia: The observational signatures of nearly complete Dyson spheres*. arXiv:1804.08351\n\n  [1]: https://www.rave-survey.org/project/\n'","b""['astronomy', 'medium', 'featured']""",https://www.kaggle.com/solorzano/rave-dr5-gaia-dr2-consolidated
b'NYS Environmental Remediation Sites',b'From New York State Open Data',"b'### Content  \n\nEnvironmental Remediation Sites are areas being remediated under one of DEC\'s remedial programs, including State Superfund and Brownfield Cleanup.  This database contains records of the sites which have been remediated or are being managed under by the agency. All sites listed on the ""Registry of Inactive Hazardous Waste Disposal Sites in New York State"" are included in this database. The Database also includes the ""Registry of Institutional and Engineering Controls in New York State"".\r\n\r\nEach site record includes: Administrative information, including site name, classification, unique site code, site   location, and site owner(s).    Institutional and Engineering Controls implemented at the site. Wastes known or thought to be disposed at the site.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/P36KI_ws3vs) by [Vlad Shapochnikov](https://unsplash.com/@vladshap) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'pollution', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-environmental-remediation-sites
b'FiveThirtyEight Police Killings Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Police Killings\n\nThis directory contains the data behind the story [Where Police Have Killed Americans In 2015](http://fivethirtyeight.com/features/where-police-have-killed-americans-in-2015).\n\nWe linked entries from the [Guardian's database on police killings](http://www.theguardian.com/us-news/ng-interactive/2015/jun/01/the-counted-map-us-police-killings) to census data from the American Community Survey. The Guardian data was downloaded on June 2, 2015. More information about its database is available [here](http://www.theguardian.com/us-news/ng-interactive/2015/jun/01/about-the-counted).\n\nCensus data was calculated at the tract level from the 2015 5-year American Community Survey using the tables `S0601 (demographics)`, `S1901 (tract-level income and poverty)`, `S1701 (employment and education)` and `DP03 (county-level income)`. Census tracts were determined by geocoding addresses to latitude/longitude using the Bing Maps and Google Maps APIs and then overlaying points onto 2014 census tracts. GEOIDs are census-standard and should be easily joinable to other ACS tables -- let us know if you find anything interesting.\n\nField descriptions:\n\nHeader | Description | Source\n---|-----------|----\n`name` | Name of deceased | Guardian\n`age` | Age of deceased | Guardian\n`gender` | Gender of deceased | Guardian\n`raceethnicity` | Race/ethnicity of deceased | Guardian\n`month` | Month of killing | Guardian\n`day` | Day of incident | Guardian\n`year` | Year of incident | Guardian\n`streetaddress` | Address/intersection where incident occurred | Guardian\n`city` | City where incident occurred | Guardian\n`state` | State where incident occurred | Guardian\n`latitude` | Latitude, geocoded from address | \n`longitude` | Longitude, geocoded from address | \n`state_fp` | State FIPS code | Census\n`county_fp` | County FIPS code | Census\n`tract_ce` | Tract ID code | Census\n`geo_id` | Combined tract ID code | \n`county_id` | Combined county ID code | \n`namelsad` | Tract description | Census\n`lawenforcementagency` | Agency involved in incident | Guardian\n`cause` | Cause of death | Guardian\n`armed` | How/whether deceased was armed | Guardian\n`pop` | Tract population | Census\n`share_white` | Share of pop that is non-Hispanic white | Census\n`share_bloack` | Share of pop that is black (alone, not in combination) | Census\n`share_hispanic` | Share of pop that is Hispanic/Latino (any race) | Census\n`p_income` | Tract-level median personal income | Census\n`h_income` | Tract-level median household income | Census\n`county_income` | County-level median household income | Census\n`comp_income` | `h_income` / `county_income` | Calculated from Census \n`county_bucket` | Household income, quintile within county | Calculated from Census\n`nat_bucket` | Household income, quintile nationally | Calculated from Census\n`pov` | Tract-level poverty rate (official) | Census\n`urate` | Tract-level unemployment rate | Calculated from Census\n`college` | Share of 25+ pop with BA or higher | Calculated from Census\n\n<b>Note regarding income calculations:</b>\n\nAll income fields are in inflation-adjusted 2013 dollars.\n\n`comp_income` is simply tract-level median household income as a share of county-level median household income.\n\n`county_bucket` provides where the tract's median household income falls in the distribution (by quintile) of all tracts in the county. (1 indicates a tract falls in the poorest 20% of tracts within the county.) Distribution is not weighted by population.\n\n`nat_bucket` is the same but for all U.S. counties.\n  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-police-killings-dataset
"b'18,393 Pitchfork Reviews'","b'Pitchfork reviews from Jan 5, 1999 to Jan 8, 2017'","b""# Context \n\n[Pitchfork](https://pitchfork.com/) is a music-centric online magazine. It was started in 1995 and grew out of independent music reviewing into a general publication format, but is still famed for its variety music reviews. I scraped over 18,000 [Pitchfork][1] reviews (going back to January 1999). Initially, this was done to satisfy a few of [my own curiosities][2], but I bet Kagglers can come up with some really interesting analyses! \n\n# Content\n\nThis dataset is provided as a `sqlite` database with the following tables: `artists`, `content`, `genres`, `labels`, `reviews`, `years`. For column-level information on specific tables, refer to the [Metadata tab](https://www.kaggle.com/nolanbconaway/pitchfork-data/data).\n\n# Inspiration\n\n* Do review scores for individual artists generally improve over time, or go down?\n* How has Pitchfork's review genre selection changed over time?\n* Who are the most highly rated artists? The least highly rated artists?\n\n# Acknowledgements\n\nGotta love [Beautiful Soup][4]!\n\n  [1]: http://pitchfork.com/\n  [2]: https://github.com/nolanbconaway/pitchfork-data\n  [3]: https://github.com/nolanbconaway/pitchfork-data/tree/master/scrape\n  [4]: https://www.crummy.com/software/BeautifulSoup/""","b""['music', 'critical theory', 'medium', 'featured']""",https://www.kaggle.com/nolanbconaway/pitchfork-data
b'Flowers Recognition',b'This dataset contains labeled 4242 images of flowers. ',"b'### Context\nThis dataset contains 4242 images of flowers. \nThe data collection is based on the data flicr, google images, yandex images.\nYou can use this datastet to recognize plants from the photo.\n\n\n### Content\nThe pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion. \nFor each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. Photos are not reduced to a single size, they have different proportions!\n\n#Acknowledgements\nThe data collection is based on scraped data from flickr, google images, and yandex images.\n\n#Inspiration\nWhat kind of flower is that?'","b""['image data', 'multiclass classification', 'machine learning', 'plants', 'photography', 'medium', 'featured']""",https://www.kaggle.com/alxmamaev/flowers-recognition
b'Fifa 18 More Complete Player Dataset',b'FIFA 18 Player Data++. ',"b""### Context\n\nThis dataset is an extension of that found [here](https://www.kaggle.com/thec03u5/fifa-18-demo-player-dataset). It contains several extra fields and is pre-cleaned to a much greater extent. After talking with the creator of the original dataset, he and I agreed that merging our work would require making breaking changes to the original, and that this should be published as a new dataset.\n\n### Content\n\n- 185 fields for every player in FIFA 18.\n- Player info such as age, club, league, nationality, salary and physical attributes\n- All playing attributes, such as finishing and dribbling\n- Special attributes like skill moves and international reputation\n- Traits and specialities\n- Overall, potential, and ratings for each position\n\n### Differences\n\nHere are the columns in this dataset that aren't in the original:\n\n- birth_date\n- eur_release_clause\n- height_cm\n- weight_kg\n- body_type\n- real_face\n- league\n- Headline attributes: pac, sho, pas, dri, def, and phy. These are what appear on Ultimate Team cards\n- international_reputation\n- skill_moves\n- weak_foot\n- work_rate_att\n- work_rate_def\n- preferred_foot\n- all traits and specialities as dummy variables\n- all position preferences as dummy variables\n\n\n### Acknowledgements\n\nCredit goes to [Aman Shrivastava](https://www.kaggle.com/thec03u5) for building the original dataset. And thanks of course to  https://sofifa.com for not banning my IP when I scraped over 18000 pages to get this data.\n\n\n### Inspiration\n\nWhat insights can this data give us, not only into FIFA 18 but into real-world football? The [kernels](https://www.kaggle.com/artimous/complete-fifa-2017-player-dataset-global/kernels) on last year's dataset are a good place to find ideas.\n\n### Contributing\n\nContributions to the [GitHub project](https://github.com/kevinheavey/fifa18-even-more-player-data) are more than welcome. Do let me know if you think of ways to improve either the code or the dataset!""","b""['video games', 'sports', 'popular culture', 'association football', 'small', 'featured']""",https://www.kaggle.com/kevinmh/fifa-18-more-complete-player-dataset
b'Historical Hourly Weather Data 2012-2017',b'Hourly weather data for 30 US & Canadian Cities + 6 Israeli Cities ',"b""# Historical Hourly Weather Data\n\nWho amongst us doesn't small talk about the weather every once in a while?  \nThe goal of this dataset is to [elevate this small talk to medium talk][1].  \n\nJust kidding, I actually originally decided to collect this dataset in order to demonstrate basic signal processing concepts, such as filtering, Fourier transform, auto-correlation, cross-correlation, etc..., (for a data analysis course I'm currently preparing).   \nI wanted to demonstrate these concepts on signals that we all have intimate familiarity with and hope that this way these concepts will be better understood than with just made up signals.  \n\nThe weather is excellent for demonstrating these kinds of concepts as it contains periodic temporal structure with two very different periods (daily and yearly).\n\n![a nice 4 seasons image][2]\n\n### Content\n\nThe dataset contains ~5 years of **high temporal resolution** (hourly measurements) data of various weather attributes, such as temperature, humidity, air pressure, etc.  \nThis data is available for 30 US and Canadian Cities, as well as 6 Israeli cities.  \nI've organized the data according to a common time axis for easy use.   \nEach attribute has it's own file and is organized such that the rows are the time axis (it's the same time axis for all files), and the columns are the different cities (it's the same city ordering for all files as well).  \nAdditionally, for each city we also have the country, latitude and longitude information in a separate file.\n\n### Acknowledgements\n\nThe dataset was aquired using [Weather API][3] on the [OpenWeatherMap website][4], and is available under the [ODbL License][5].  \n\n### Inspiration\n\nWeather data is both intrinsically interesting, and also potentially useful when correlated with other types of data.  \nFor example, [Wildfire][6] spread is potentially related to weather conditions, demand for cabs is famously known to be correlated with weather conditions ([here][7], [here][8] and [here][9] you can find NYC cab ride data), and use of city bikes is probably also correlated with weather in interesting ways (check out [this Austin dataset][10], [this SF dataset][11], [this Montreal dataset][12], and [this NYC dataset][13]).  \n[Traffic][14] is also probably related to weather.   \nAnother potentially interesting source of correlation is between weather and crime. Here are a few crime datasets on kaggle of cities present in this weather dataset: [Chicago][15], [Philadelphia][16], [Los Angeles][17], [Vancouver][18], [Austin][19], [NYC][20]  \n\nThere are many other potentially interesting connections between everyday life and the weather that we can explore together with the help of this dataset. Have fun!\n\n\n  [1]: https://www.youtube.com/watch?v=qeFlDoepDR0\n  [2]: http://www.sciencehub4kids.com/wp-content/uploads/2015/08/The-four-seasons.jpg\n  [3]: https://openweathermap.org/api\n  [4]: https://openweathermap.org/\n  [5]: https://opendatacommons.org/licenses/odbl/\n  [6]: https://www.kaggle.com/rtatman/188-million-us-wildfires\n  [7]: https://www.kaggle.com/dhimananubhav/2015-nyc-taxi-trips-subset-12-million-rows\n  [8]: https://www.kaggle.com/kentonnlp/2014-new-york-city-taxi-trips\n  [9]: https://www.kaggle.com/c/nyc-taxi-trip-duration\n  [10]: https://www.kaggle.com/jboysen/austin-bike\n  [11]: https://www.kaggle.com/benhamner/sf-bay-area-bike-share\n  [12]: https://www.kaggle.com/pablomonleon/montreal-bike-lanes\n  [13]: https://www.kaggle.com/new-york-city/nyc-east-river-bicycle-crossings\n  [14]: https://www.kaggle.com/jboysen/us-traffic-2015\n  [15]: https://www.kaggle.com/currie32/crimes-in-chicago\n  [16]: https://www.kaggle.com/mchirico/philadelphiacrimedata\n  [17]: https://www.kaggle.com/cityofLA/crime-in-los-angeles\n  [18]: https://www.kaggle.com/wosaku/crime-in-vancouver\n  [19]: https://www.kaggle.com/jboysen/austin-crime\n  [20]: https://www.kaggle.com/adamschroeder/crimes-new-york-city""","b""['time series', 'weather', 'united states', 'history', 'geography', 'medium', 'featured']""",https://www.kaggle.com/selfishgene/historical-hourly-weather-data
b'Chicago Building Permits',b'From City of Chicago Open Data',"b'### Content  \n\nPermits issued by the Department of Buildings in the City of Chicago from 2006 to the present. The dataset for each year contains more than 65,000 records/rows of data and cannot be viewed in full in Microsoft Excel. Therefore, when downloading the file, select CSV from the Export menu. Open the file in an ASCII text editor, such as Wordpad, to view and search. Data fields requiring description are detailed below. \r\nPERMIT TYPE: ""New Construction and Renovation"" includes new projects or rehabilitations of existing buildings; ""Other Construction"" includes items that require plans such as cell towers and cranes; ""Easy Permit"" includes minor repairs that require no plans; ""Wrecking/Demolition"" includes private demolition of buildings and other structures; ""Electrical Wiring"" includes major and minor electrical work both permanent and temporary; ""Sign Permit"" includes signs, canopies and awnings both on private property and over the public way; ""Porch Permit"" includes new porch construction and renovation (defunct permit type porches are now issued under ""New Construction and Renovation"" directly); ""Reinstate Permit"" includes original permit reinstatements; ""Extension Permits"" includes extension of original permit when construction has not started within six months of original permit issuance. WORK DESCRIPTION: The description of work being done on the issued permit, which is printed on the permit. PIN1 \xe2\x80\x93 PIN10: A maximum of ten assessor parcel index numbers belonging to the permitted property. PINs are provided by the customer seeking the permit since mid-2008 where required by the Cook County Assessor\xe2\x80\x99s Office. CONTRACTOR INFORMATION: The contractor type, name, and contact information. Data includes up to 15 different contractors per permit if applicable.\r\n\r\nData Owner: Buildings.\r\n\r\nTime Period: January 1, 2006 to present.\r\n\r\nFrequency: Data is updated daily.\r\n\r\nRelated Applications: Building Data Warehouse (https://webapps.cityofchicago.org/buildingviolations/violations/searchaddresspage.html).  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/tXICOsK8Duc) by [Verne Ho](https://unsplash.com/@verneho) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-building-permits
b'Premier League',b'Results of each match and stats of each team from season 2006/2007 to 2017/2018',"b""### Context\n\nOfficial football data organised and formatted in csv files ready for download is quite hard to come by. Stats providers are hesitant to release their data to anyone and everyone, even if it's for academic purposes. That was my exact dilemma which prompted me to scrape and extract it myself. Now that it's at your disposal, have fun with it.\n\n### Content\n\nThe data was acquired from the Premier League website and is representative of seasons 2006/2007 to 2017/2018. Visit both sets to get a detailed description of what each entails.\n\n### Inspiration\n\nUse it to the best of your ability to predict match outcomes or for a thorough data analysis to uncover some intriguing insights. Be safe and only use this dataset for personal projects. If you'd like to use this type of data for a commercial project, contact Opta to access it through their API instead.""","b""['sports', 'small', 'featured']""",https://www.kaggle.com/zaeemnalla/premier-league
b'Multidigit MNIST(M2NIST)',b'MNIST of semantic segmentation.',"b""### Context\n\nI created this dataset to teach the basics of fully convolution networks for semantic segmentation of images. Most real-world semantic image segmentation tasks require building huge networks that are slow to train and experiment with. The dataset was generated by selecting up to 3 random 28px x 28px  grayscale images from the [MNIST dataset](https://www.kaggle.com/c/digit-recognizer/data) and copying them in to a single 64px(height) x 84px(width) image. The digits were pasted so that they did not overlap and no transformations were applied to the original images, so digits in M2NIST maintain the same orientation as the have in MNIST. \n\n### Content\nThe dataset has 5000 multi-digit images in `combined.npy` and 11 segmentation masks for every image in `segmented.npy`. The files can be read in using `numpy.load()`, for example, as `combined=np.load('combined.npy')` and `segmented = np.load('segmented.npy')`. The data in `combined.npy` has shape `(5000, 64, 84)` while the data in `segmented.npy` has shape `(5000, 64, 84, 11)`. Every element in `combined.npy` is a grayscale image with up to 3 digits. The corresponding element in `segmented.npy` is a tensor with 64 rows, 84 columns and 11 layers or channels. Each layer or channel is a binary mask. The k-th layer (0&lt;=k&lt;9) has 1s wherever the digit k is present in the combined image and 0s everywhere else. The last layer k=10 represents background and has 1s wherever there is no digit in the combined image and 0's wherever at pixels where some digit is present in the original image.\n\n\n### Acknowledgements\nThis dataset is ultimately derived from the data published by YanLeCun and his group http://yann.lecun.com/exdb/mnist/index.html and is licensed under the [Creative Commons Attribution-Share Alike 4.0 license](https://creativecommons.org/licenses/by-sa/4.0/). The code used to generate this dataset is available on [github](https://github.com/farhanhubble/udacity-connect/blob/master/segmented-generator.ipynb) as an Ipython Notebook.\n\n### Inspiration\nThe M2NIST dataset is released in the hope that it enables users to understand semantic segmentation and perhaps give us more insights about what neural networks learn and in turn leads us to smaller and more robust networks.""","b""['internet', 'medium', 'featured']""",https://www.kaggle.com/farhanhubble/multimnistm2nist
b'pix2pix dataset',"b'pix2pix dataset (facades, cityscapes, maps and edges to shoes)'","b""**Introduction**\n\nThis is the dataset for pix2pix model which aims to work as a general-purpose solution for image-to-image translation problems.\n\nDue to Kaggle's size limitations, only 4 datasets are available here.\n\n- Facades\n- Cityscapes\n- Maps\n- Edges to shoes\n\n1 more dataset (Edges to handbags) and can be downloaded from the link provided in the sources section.\n\n----------\n\n**Common tasks**\n\n- Loading the data: https://www.kaggle.com/vikramtiwari/loading-pix-2-pix-dataset\n- Pix-2-Pix model implementation: https://www.kaggle.com/vikramtiwari/pix-2-pix-model-using-tensorflow-and-keras\n\n\nMore description of the actual model, some implementations, and all the community contributions can be found on the author's GitHub project page here: https://phillipi.github.io/pix2pix/\n\n\n----------\n\n**Sources**\n\n- Paper for pix2pix model: https://arxiv.org/abs/1611.07004\n- Dataset source location: https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets\n""","b""['deep learning', 'image data', 'large', 'featured']""",https://www.kaggle.com/vikramtiwari/pix2pix-dataset
b'Oakland Street Cleaning Citations 2013-15 ',b'Explore open data from the city of Oakland',"b""### Content  \n\nPRR 9545  \n\n### Context  \n\nThis is a dataset hosted by the city of Oakland in California. The organization has an open data platform found [here](data.oaklandnet.com) and they update their information according to the amount of data that is brought in. Explore Oakland's Data using Kaggle and all of the data sources available through the city of Oakland [organization page](https://www.kaggle.com/cityofoakland)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ZGjbiukp_-A) by [Samson Duborg-Rankin](https://unsplash.com/@samsonyyc) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under NA""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofoakland/oakland-street-cleaning-citations-2013-15-
b'US Census Demographic Data',b'Demographic and Economic Data for Tracts and Counties',"b'### Context\n\nThis dataset expands on my earlier [New York City Census Data][1] dataset. It includes data from the entire country instead of just New York City. The expanded data will allow for much more interesting analyses and will also be much more useful at supporting other data sets.\n\n### Content\n\nThe data here are taken from the DP03 and DP05 tables of the 2015 American Community Survey 5-year estimates. The full datasets and much more can be found at the American Factfinder [website][2]. Currently, I include two data files:\n\n 1. acs2015_census_tract_data.csv: Data for each census tract in the US, including DC and Puerto Rico.\n 2. acs2015_county_data.csv: Data for each county or county equivalent in the US, including DC and Puerto Rico.\n\nThe two files have the same structure, with just a small difference in the name of the id column. Counties are political subdivisions, and the boundaries of some have been set for centuries. Census tracts, however, are defined by the census bureau and will have a much more consistent size. A typical census tract has around 5000 or so residents.\n\nThe Census Bureau updates the estimates approximately every year. At least some of the 2016 data is already available, so I will likely update this in the near future.\n\n### Acknowledgements\n\nThe data here were collected by the US Census Bureau. As a product of the US federal government, this is not subject to copyright within the US.\n\n### Inspiration\n\nThere are many questions that we could try to answer with the data here. Can we predict things such as the state (classification) or household income (regression)? What kinds of clusters can we find in the data? What other datasets can be improved by the addition of census data? \n\n  [1]: https://www.kaggle.com/muonneutrino/new-york-city-census-data\n  [2]: https://factfinder.census.gov/faces/nav/jsf/pages/index.xhtml'","b""['demographics', 'united states', 'small', 'featured']""",https://www.kaggle.com/muonneutrino/us-census-demographic-data
b'Financial Tweets',"b'Tweets from verified users concerning stocks traded on the NYSE, NASDAQ, & SNP'","b""### Context\nI have been interested in using public sentiment and journalism to gather sentiment profiles on publicly traded companies. I first developed a Python package (https://github.com/dwallach1/Stocker) that scrapes the web for articles written about companies, and then noticed the abundance of overlap with Twitter. I then developed a NodeJS project that I have been running on my RaspberryPi to monitor Twitter for all tweets coming from those mentioned in the *content* section. If one of them tweeted about a company in the stocks_cleaned.csv file, then it would write the tweet to the database. Currently, the file is only from earlier today, but after about a month or two, I plan to update the tweets.csv file (hopefully closer to 50,000 entries. \n\nI am not quite sure how this dataset will be relevant, but I hope to use these tweets and try to generate some sense of public sentiment score.  \n\n\n### Content\n\nThis dataset has all the publicly traded companies (tickers and company names) that were used as input to fill the tweets.csv. The influencers whose tweets were monitored were: \n['MarketWatch', 'business', 'YahooFinance', 'TechCrunch', 'WSJ', 'Forbes', 'FT', 'TheEconomist', 'nytimes', 'Reuters', 'GerberKawasaki', 'jimcramer', 'TheStreet', 'TheStalwart', 'TruthGundlach', 'Carl_C_Icahn', 'ReformedBroker', 'benbernanke', 'bespokeinvest', 'BespokeCrypto', 'stlouisfed', 'federalreserve', 'GoldmanSachs', 'ianbremmer', 'MorganStanley', 'AswathDamodaran', 'mcuban', 'muddywatersre', 'StockTwits', 'SeanaNSmith'\n\n\n\n### Acknowledgements\n\nThe data used here is gathered from a project I developed : https://github.com/dwallach1/StockerBot\n\n### Inspiration\n\nI hope to develop a financial sentiment text classifier that would be able to track Twitter's (and the entire public's) feelings about any publicly traded company (and cryptocurrency).""","b""['finance', 'twitter', 'small', 'featured']""",https://www.kaggle.com/davidwallach/financial-tweets
b'CAPTCHA Images',b'Version 2 CAPTCHA Images',"b'### Context\n\nThis dataset contains CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) images. Built in 1997 as way for users to identify and block bots (in order to prevent spam, DDOS etc.). They have since then been replace by reCAPTCHA because they are breakable using Artificial Intelligence (as I encourage you to do).\n\n### Content\n\nThe images are 5 letter words that can contain numbers. The images have had noise applied to them (blur and a line). They are 200 x 50 PNGs.\n\n### Acknowledgements\n\nThe dataset comes from [Wilhelmy, Rodrigo & Rosas, Horacio. (2013). captcha dataset.][1] \n[1]: https://www.researchgate.net/publication/248380891_captcha_dataset\n\nThumbnail image from [Accessibility of CAPTCHAs]\n[2]: http://www.bespecular.com/blog/accessibility-of-captchas/\n### Inspiration\n\nThis dataset is a perfect opportunity to attempt to make Optical Character Recognition algorithms.'","b""['image data', 'image processing', 'computer security', 'small', 'featured']""",https://www.kaggle.com/fournierp/captcha-version-2-images
b'Global Commodity Trade Statistics',b'Three decades of global trade flows',"b""Are you curious about fertilizer use in developing economies? The growth of Chinese steel exports? American chocolate consumption? Which parts of the world still use typewriters? You'll find all of that and more here. This dataset covers import and export volumes for 5,000 commodities across most countries on Earth over the last 30 years.\n\n### Acknowledgements\n\nThis dataset was kindly published by the United Nations Statistics Division on the UNData site. You can find [the original dataset here](http://data.un.org/Explorer.aspx).\n\n### Inspiration\n- Some of these numbers are more trustworthy than others. I'd expect that British tea imports are fairly accurate, but doubt that Afghanistan exported exactly 51 sheep in 2016. Can you identify which nations appear to have the most trustworthy data? Which industries?\n\n### License\n[Per the UNData terms of use](http://data.un.org/Host.aspx?Content=UNdataUse): all data and metadata provided on UNdata\xe2\x80\x99s website are available free of charge and may be copied freely, duplicated and further distributed provided that [UNdata](http://data.un.org/Explorer.aspx) is cited as the reference. ""","b""['economics', 'shipping', 'supply chain', 'medium', 'featured']""",https://www.kaggle.com/unitednations/global-commodity-trade-statistics
b'NYS Solar Electric Programs Reported by NYSERDA',b'From New York State Open Data',"b""### Content  \n\nSolar Electric Programs Reported by NYSERDA; Beginning 2000 dataset includes the following data points for projects completed and in the pipeline (not yet installed) in the Incentive Program beginning December 2000: Project number, city, county, state, zip code, sector, program type, solicitation, electric utility, purchase type, date application received, date completed, project status, contractor, primary inverter manufacturer, total inverter quantity, primary inverter model number, primary PV module manufacturer, total PV module quantity, primary PV module model number, project cost, incentive amount, total nameplate capacity, expected annual kilowatt-hour production, remote net metering, affordable solar, community distributed generation project and Green Jobs-Green New York participant. Blank cells represent data that were not required or are not currently available.  Contractor data is provided for completed projects only, except for Community Distributed Generation projects. Pipeline projects are subject to change. The interactive map at https://www.nyserda.ny.gov/All-Programs/Programs/NY-Sun/Data-and-Trends provides information on solar photovoltaic (PV) installations supported by NYSERDA throughout New York State since 2000 by county, region, or statewide. Updated monthly, the graphs show the number of projects, expected production, total capacity, and annual trends.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/XGAZzyLzn18) by [American Public Power Association](https://unsplash.com/@publicpowerorg) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-solar-electric-programs-reported-by-nyserda
b'Heart Disease and Stroke Prevention',b'Provides a comprehensive image for cardiovascular diseases & related prevention',"b""### Context\nThis is one of the dataset provided by the National Cardiovascular Disease Surveillance System. \n\nThe system is designed to integrate multiple indicators from many data sources to provide a comprehensive picture of the public health burden of CVDs and associated risk factors in the United States. \n\n\n### Content\n\nThe data are organized by location (national, regional, state, and selected sites) and indicator, and they include CVDs (e.g., heart failure) and risk factors (e.g., hypertension). The data can be plotted as trends and stratified by age group, sex, and race/ethnicity.\n\n2011 to present. BRFSS is a continuous, state-based surveillance system that collects information about modifiable risk factors for chronic diseases and other leading causes of death. \n\n\n### Acknowledgements\n\nIndicators from this data source have been computed by personnel in CDC's Division for Heart Disease and Stroke Prevention (DHDSP). ""","b""['healthcare', 'cardiology', 'small', 'featured']""",https://www.kaggle.com/mazharkarimi/heart-disease-and-stroke-prevention
b'The Movies Dataset',"b'Metadata on over 45,000 movies. 26 million ratings from over 270,000 users.'","b""### Context\n\nThese files contain metadata for all 45,000 movies listed in the Full MovieLens Dataset. The dataset consists of movies released on or before July 2017. Data points include cast, crew, plot keywords, budget, revenue, posters, release dates, languages, production companies, countries, TMDB vote counts and vote averages.\n\nThis dataset also has files containing 26 million ratings from 270,000 users for all 45,000 movies. Ratings are on a scale of 1-5 and have been obtained from the official GroupLens website.\n\n\n### Content\n\nThis dataset consists of the following files:\n\n**movies_metadata.csv:** The main Movies Metadata file. Contains information on 45,000 movies featured in the Full MovieLens dataset. Features include posters, backdrops, budget, revenue, release dates, languages, production countries and companies.\n\n**keywords.csv:** Contains the movie plot keywords for our MovieLens movies. Available in the form of a stringified JSON Object.\n\n**credits.csv:** Consists of Cast and Crew Information for all our movies. Available in the form of a stringified JSON Object.\n\n**links.csv:** The file that contains the TMDB and IMDB IDs of all the movies featured in the Full MovieLens dataset.\n\n**links_small.csv:** Contains the TMDB and IMDB IDs of a small subset of 9,000 movies of the Full Dataset.\n\n**ratings_small.csv:** The subset of 100,000 ratings from 700 users on 9,000 movies.\n\nThe Full MovieLens Dataset consisting of 26 million ratings and 750,000 tag applications from 270,000 users on all the 45,000 movies in this dataset can be accessed [here](https://grouplens.org/datasets/movielens/latest/) \n\n### Acknowledgements\n\nThis dataset is an ensemble of data collected from TMDB and GroupLens.\nThe Movie Details, Credits and Keywords have been collected from the TMDB Open API. This product uses the TMDb API but is not endorsed or certified by TMDb. Their API also provides access to data on many additional movies, actors and actresses, crew members, and TV shows. You can try it for yourself [here](https://www.themoviedb.org/documentation/api).\n\nThe Movie Links and Ratings have been obtained from the Official GroupLens website. The files are a part of the dataset available [here](https://grouplens.org/datasets/movielens/latest/)\n\n![](https://www.themoviedb.org/assets/static_cache/9b3f9c24d9fd5f297ae433eb33d93514/images/v4/logos/408x161-powered-by-rectangle-green.png)\n\n\n### Inspiration\n\nThis dataset was assembled as part of my second Capstone Project for Springboard's [Data Science Career Track](https://www.springboard.com/workshops/data-science-career-track). I wanted to perform an extensive EDA on Movie Data to narrate the history and the story of Cinema and use this metadata in combination with MovieLens ratings to build various types of Recommender Systems.\n\nBoth my notebooks are available as kernels with this dataset: [The Story of Film](https://www.kaggle.com/rounakbanik/the-story-of-film) and  [Movie Recommender Systems](https://www.kaggle.com/rounakbanik/movie-recommender-systems)\n\nSome of the things you can do with this dataset:\nPredicting movie revenue and/or movie success based on a certain metric. What movies tend to get higher vote counts and vote averages on TMDB? Building Content Based and Collaborative Filtering Based Recommendation Engines.\n""","b""['popular culture', 'film', 'medium', 'featured']""",https://www.kaggle.com/rounakbanik/the-movies-dataset
"b""NYS Assembled Workers' Compensation Claims""",b'From New York State Open Data',"b""### Content  \n\nThe Workers\xe2\x80\x99 Compensation Board (WCB) administers and regulates workers\xe2\x80\x99 compensation benefits, disability benefits, volunteer firefighters\xe2\x80\x99 benefits, volunteer ambulance workers\xe2\x80\x99 benefits, and volunteer civil defense workers\xe2\x80\x99 benefits. The WCB processes and adjudicates claims for benefits; ensures employer compliance with the requirement to maintain appropriate insurance coverage; and regulates the various system stakeholders, including self-insured employers, medical providers, third party administrators, insurance carriers and legal representatives.  Claim assembly occurs when the WCB learns of a workplace injury and assigns the claim a WCB claim number. The WCB \xe2\x80\x9cassembles\xe2\x80\x9d a claim in which an injured worker has lost more than one week of work, has a serious injury that may result in a permanent disability, is disputed by the carrier or employer, or receives a claim form from the injured worker (Form C-3).  A reopened claim is one that has been reactivated to resolve new issues following a finding that no further action was necessary  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/QXgPXa6ydzg) by [John Salvino](https://unsplash.com/@jsalvino) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-assembled-workers'-compensation-claims
b'MotionSense Dataset : Smartphone Sensor Data',"b""Time-series data generated by smartphone's sensors: accelerometer and gyroscope""","b""# Context\nThis dataset includes time-series data generated by accelerometer and gyroscope sensors (attitude, gravity, userAcceleration, and rotationRate). It is collected with an iPhone 6s kept in the participant's front pocket using [SensingKit](https://www.sensingkit.org/) which collects information from [Core Motion](https://developer.apple.com/documentation/coremotion/cmdevicemotion) framework on iOS devices. A total of 24 participants in a range of gender, age, weight, and height performed 6 activities in 15 trials in the same environment and conditions: downstairs, upstairs, walking, jogging, sitting, and standing. With this dataset, we aim to look for  *personal attributes fingerprints* in time-series of sensor data, i.e. attribute-specific patterns that can be used to infer gender or personality of the data subjects in addition to their activities. \n\n[A simple code for importing dataset and to get your hands in][1]\n\n# Content\n\nFor each participant, the study had been commenced by collecting their demographic (age and gender) and physically-related (height and weight) information. Then, we provided them with a dedicated smartphone (iPhone 6) and asked them to store it in their trousers' front pocket during the experiment. All the participant were asked to wear flat shoes. We then asked them to perform 6 different activities (walk downstairs, walk upstairs, sit, stand and jogging) around the Queen Mary University of London's Mile End campus. For each trial, the researcher set up the phone and gave it to the current participants, then the researcher stood in a corner. Then, the participant pressed the start button of [Crowdsense app](https://itunes.apple.com/us/app/crowdsense/id930853606?mt=8) and put it in their trousers' front pocket and performed the specified activity. We asked them to do it as natural as possible, like their everyday life. At the end of each trial, they took the phone out of their pocket and pressed the stop button. The exact places and routes for running all the activities are shown in the illustrative map in the following Figure.  \n\nAs we can see, there are 15 trials:\n\n1. Long trials: those with number 1 to 9 with around 2 to 3 minutes duration.\n2. Short trials: those with number 11 to 16 that are around 30 seconds to 1 minutes duration.\n\nThere are 24 data subjects. The `A_DeviceMotion_data` folder contains time-series collected by both Accelerometer and Gyroscope for all 15 trials. For every trial we have a multivariate time-series. Thus, we have time-series with 12 features: attitude.roll, attitude.pitch, attitude.yaw, gravity.x, gravity.y, gravity.z, rotationRate.x, rotationRate.y, rotationRate.z, userAcceleration.x, userAcceleration.y, userAcceleration.z.\n\nThe accelerometer measures the sum of two acceleration vectors: gravity and user acceleration. User acceleration is the acceleration that the user imparts to the device. Because Core Motion is able to track a device\xe2\x80\x99s attitude using both the gyroscope and the accelerometer, it can differentiate between gravity and user acceleration. A CMDeviceMotion object provides both measurements in the gravity and userAcceleration properties. ([More info][3])\n\nThere are 6 different labels: \n\n1. **dws**: downstairs\n\n2. **ups**: upstairs\n\n3. **sit**: sitting\n\n4. **std**: standing\n\n5. **wlk**: walking\n\n6. **jog**: jogging\n\n\n## Acknowledgements\nIf you use this dataset, please cite the following paper:\n\nMohammad Malekzadeh, Richard G. Clegg, Andrea Cavallaro, and Hamed Haddadi. 2018. [Protecting Sensory Data against Sensitive Inferences](https://arxiv.org/abs/1802.07802). In W-P2DS\xe2\x80\x9918: 1st Workshop on Privacy by Design in Distributed Systems , April 23\xe2\x80\x9326, 2018, Porto, Portugal. ACM, New York, NY, USA, 6 pages. https: //doi.org/10.1145/3195258.3195260\n\n\n  [1]: https://github.com/mmalekzadeh/motion-sense\n  [3]: https://developer.apple.com/documentation/coremotion/cmdevicemotion""","b""['classification', 'time series', 'regression', 'time series analysis', 'learning', 'medium', 'featured']""",https://www.kaggle.com/malekzadeh/motionsense-dataset
b'STL-10 Image Recognition Dataset',b'Train models to recognize different animals and vehicles',"b'### Context\n\nSTL-10 is an image recognition dataset inspired by CIFAR-10 dataset with some improvements.  With a corpus of 100,000 unlabeled images and 500 training images, this dataset is best for developing unsupervised feature learning, deep learning, self-taught learning algorithms. Unlike CIFAR-10, the dataset has a higher resolution which makes it a challenging benchmark for developing more scalable unsupervised learning methods. \n\n### Content\n\nData overview: \n\n- There are three files: train_image.zips, test_images.zip and unlabeled_images.zip\n- 10 classes: airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck\n- Images are 96x96 pixels, color\n- 500 training images (10 pre-defined folds), 800 test images per class\n- 100,000 unlabeled images for unsupervised learning. These examples are extracted from a similar but broader distribution of images. For instance, it contains other types of animals (bears, rabbits, etc.) and vehicles (trains, buses, etc.) in addition to the ones in the labeled set\n- Images were acquired from labeled examples on ImageNet\n\nThe original data source recommends the following standardized testing protocol for reporting results:\n\n1. Perform unsupervised training on the unlabeled data\n2. Perform supervised training on the labeled data using 10 (pre-defined) folds of 100 examples from the training data. The indices of the examples to be used for each fold are provided\n3. Report average accuracy on the full test set\n\n### Acknowledgements\n\nOriginal data source and banner image: https://cs.stanford.edu/~acoates/stl10/\n\nPlease cite the following reference when using this dataset:\n\nAdam Coates, Honglak Lee, Andrew Y. Ng An Analysis of Single Layer Networks in Unsupervised Feature Learning AISTATS, 2011. \n\n### Inspiration\n- Can you train a model to accurately identify what animal or transportation object is in each image?'","b""['image data', 'object recognition', 'object identification', 'large', 'featured']""",https://www.kaggle.com/jessicali9530/stl10
b'Chicago Payments',b'From City of Chicago Open Data',"b'### Content  \n\nAll vendor payments made by the City of Chicago from 1996 to present. Payments from 1996 through 2002 have been rolled-up and appear as ""2002."" Total payment information is summarized for each vendor and contract number for data older than two years. These data are extracted from the City\xe2\x80\x99s Vendor, Contract, and Payment Search.\r\n\r\nTime Period: 1996 to present.\r\n\r\nFrequency: Data is updated daily.\r\n\r\nRelated Applications: City of Chicago Vendor, Contract, and Payments Search (http://webapps.cityofchicago.org/VCSearchWeb/org/cityofchicago/vcsearch/controller/payments/begin.do?agencyId=city).  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/iJBU8Ra8h3c) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-payments
b'NYS Annual Average Daily Traffic (AADT)',b'From New York State Open Data',"b""### Content  \n\nAnnual Average Daily Traffic (AADT) is an estimate of the average daily traffic along a defined segment of roadway. This value is calculated from short term counts taken along the same section which are then factored to produce the estimate of AADT. Because of this process, the most recent AADT for any given roadway will always be for the previous year. Data is available for all New York State Routes and roads that are part of the Federal Aid System.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/7nrsVjvALnA) by [Denys Nevozhai](https://unsplash.com/@dnevozhai) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-annual-average-daily-traffic-aadt
b'Images of Lego Bricks',"b'Approximately 12,700 images of 16 different Lego bricks '",b'### Context\n\nI was looking for a good dataset for learning and research purposes. I always kept in mind a collection which could be used for a sorting robot machine in later stage. Lego bricks are good candidates. At first thought I did some experimentation to photograph bricks from different angles but this was time consuming. That is why I turned to computer rendering of the bricks using Blender.\n\n\n### Content\nIn this dataset you will find 16 different lego bricks. Each brick is selected in Mecabricks.com and next imported in collada (.dae) format in Blender. I used an animator object to render the imported brick from 400 different angles.   \n\n\n### Acknowledgements\nBlender is free and Open 3D Creation Software. Mecabricks.com is a free online Lego modeling tool.    \n\n\n### Inspiration\n\nI hope you can take advantage of this simple set in your learning or research. Let me know if there is need to expand the dataset to more bricks. Enjoy! ',"b""['classification', 'deep learning', 'image data', 'multiclass classification', 'games and toys', 'medium', 'featured']""",https://www.kaggle.com/joosthazelzet/lego-brick-images
b'Complete Cryptocurrency Market History',b'Daily historical prices for all cryptocurrencies listed on CoinMarketCap',"b'### Cryptocurrencies\n\nCryptocurrencies are fast becoming rivals to traditional currency across the world. The digital currencies are available to purchase in many different places, making it accessible to everyone, and with retailers accepting various cryptocurrencies it could be a sign that money as we know it is about to go through a major change.\n\nIn addition, the blockchain technology on which many cryptocurrencies are based, with its revolutionary distributed digital backbone, has many other promising applications. Implementations of secure, decentralized systems can aid us in conquering organizational issues of trust and security that have plagued our society throughout the ages. In effect, we can fundamentally disrupt industries core to economies, businesses and social structures, eliminating inefficiency and human error.\n\n### Content\n\nThe dataset contains all historical daily prices (open, high, low, close) for all cryptocurrencies listed on [CoinMarketCap].\n\n### Acknowledgements\n\n- [Every Cryptocurrency Daily Market Price] - I initially developed kernels for this dataset before making my own scraper and dataset so that I could keep it regularly updated.\n- [CoinMarketCap]  - For the data\n\n  [Every Cryptocurrency Daily Market Price]: https://www.kaggle.com/jessevent/all-crypto-currencies ""Every Cryptocurrency Daily Market Price""\n  [CoinMarketCap]: https://coinmarketcap.com/ ""CoinMarketCap""'","b""['finance', 'internet', 'economics', 'business', 'money', 'medium', 'featured']""",https://www.kaggle.com/taniaj/cryptocurrency-market-history-coinmarketcap
b'Retinal OCT Images (optical coherence tomography)',"b'84,495 images, 4 categories'","b'### Context\n\nhttp://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n\nRetinal optical coherence tomography (OCT) is an imaging technique used to capture high-resolution cross sections of the retinas of living patients.  Approximately 30 million OCT scans are performed each year, and the analysis and interpretation of these images takes up a significant amount of time (Swanson and Fujimoto, 2017). \n\n![](https://i.imgur.com/fSTeZMd.png)\n\nFigure 2. Representative Optical Coherence Tomography Images and the Workflow Diagram [Kermany et. al. 2018] http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n\n(A) (Far left) choroidal neovascularization (CNV) with neovascular membrane (white arrowheads) and associated subretinal fluid (arrows). (Middle left) Diabetic macular edema (DME) with retinal-thickening-associated intraretinal fluid (arrows). (Middle right) Multiple drusen (arrowheads) present in early AMD. (Far right) Normal retina with preserved foveal contour and absence of any retinal fluid/edema.\n\n### Content\n\nThe dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (NORMAL,CNV,DME,DRUSEN). There are 84,495 X-Ray images (JPEG) and 4 categories (NORMAL,CNV,DME,DRUSEN).\n\nImages are labeled as (disease)-(randomized patient ID)-(image number by this patient) and split into 4 directories: CNV, DME, DRUSEN, and NORMAL.\n\nOptical coherence tomography (OCT) images (Spectralis OCT, Heidelberg Engineering, Germany) were selected from retrospective cohorts of adult patients from the Shiley Eye Institute of the University of California San Diego, the California Retinal Research Foundation, Medical Center Ophthalmology Associates, the Shanghai First People\xe2\x80\x99s Hospital, and Beijing Tongren Eye Center between July 1, 2013 and March 1, 2017.  \n\nBefore training, each image went through a tiered grading system consisting of multiple layers of trained graders of increasing exper- tise for verification and correction of image labels. Each image imported into the database started with a label matching the most recent diagnosis of the patient. The first tier of graders consisted of undergraduate and medical students who had taken and passed an OCT interpretation course review. This first tier of graders conducted initial quality control and excluded OCT images containing severe artifacts or significant image resolution reductions. The second tier of graders consisted of four ophthalmologists who independently graded each image that had passed the first tier. The presence or absence of choroidal neovascularization (active or in the form of subretinal fibrosis), macular edema, drusen, and other pathologies visible on the OCT scan were recorded. Finally, a third tier of two senior independent retinal specialists, each with over 20 years of clinical retina experience, verified the true labels for each image. The dataset selection and stratification process is displayed in a CONSORT-style diagram in Figure 2B. To account for human error in grading, a validation subset of 993 scans was graded separately by two ophthalmologist graders, with disagreement in clinical labels arbitrated by a senior retinal specialist.\n\nFor additional information: see http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n\n### Acknowledgements\n\nData: https://data.mendeley.com/datasets/rscbjbr9sj/2\n\nCitation: http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n\n![enter image description here][1]\n\n\n### Inspiration\n\nAutomated methods to detect and classify human diseases from medical images.\n\n\n  [1]: https://i.imgur.com/8AUJkin.png'","b""['image data', 'medicine', 'biology', 'large', 'featured']""",https://www.kaggle.com/paultimothymooney/kermany2018
b'Indian Liver Patient Records',"b'Patient records collected from North East of Andhra Pradesh, India'","b'### Context\n\nPatients with Liver disease have been continuously increasing because of excessive consumption of alcohol, inhale of harmful gases, intake of contaminated food, pickles and drugs. This dataset was used to evaluate prediction algorithms in an effort to  reduce burden on doctors. \n\n### Content\n\nThis data set contains 416 liver patient records and 167 non liver patient records collected from North East of Andhra Pradesh, India.  The ""Dataset"" column is a class label used to divide groups into liver patient (liver disease) or not (no disease). This data set contains 441 male patient records and 142 female patient records. \n\nAny patient whose age exceeded 89 is listed as being of age ""90"".\n\nColumns:\n\n- Age of the patient \n- Gender of the patient \n- Total Bilirubin \n- Direct Bilirubin \n- Alkaline Phosphotase \n- Alamine Aminotransferase \n- Aspartate Aminotransferase \n- Total Protiens \n- Albumin \n- Albumin and Globulin Ratio \n- Dataset: field used to split the data into two sets (patient with liver disease, or no disease)\n\n\n### Acknowledgements\n\nThis dataset was downloaded from the UCI ML Repository:\n\nLichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n\n### Inspiration\n\nUse these patient records to determine which patients have liver disease and which ones do not. '","b""['healthcare', 'health', 'medicine', 'health sciences', 'small', 'featured']""",https://www.kaggle.com/uciml/indian-liver-patient-records
b'LA County Restaurant Inspections and Violations',b'Environmental health inspections and violations in LA County restaurants',"b'## Context\n\nRestaurants and markets in Los Angeles county are regularly inspected for health code violations. The county makes these data publicly available and accessible, enabling a transparent look into this public health information.\n\n## Content\n\nThe data  covers health code inspections (`inspections.csv`) and health code violations (`violation.csv`). More details about the two files is provided in the sections below.\n\n**Violations**\n\nThis dataset contains Environmental Health Violations for Restaurants and Markets in Los Angeles County. Los Angeles County Environmental Health is responsible for checking food violations for all unincorporated areas and 85 of the 88 cities in the County. This dataset does not include Pasadena, Long Beach or Vernon (each has its own city health department). Each row represents one health code violation. \n\nAll rows with the same Activity Date, Record ID, and Serial Number are part of the same violation.\n\nThe Serial Number is the primary key to review the inspection grade (Inspection Result dataset).\n\n**Inspections**\n\nThis dataset contains Environmental Health Inspection Results for Restaurants and Markets in Los Angeles County. Los Angeles County Environmental Health is responsible for inspections and enforcement activities for all unincorporated areas and 85 of the 88 cities in the County. This dataset does not include Pasadena, Long Beach or Vernon (each has its own city health department).\nEach row represents one inspection result.\n\nThe Activity Date, Record ID, and Serial Number are the primary keys to review the violations (Violations Dataset)\n\n## Inspiration\n\n* What are the most common health code violations?\n* What is the trend of health code violations over time?\n* Is there a geographic pattern to health code violations?\n\n---\n\nBanner photo by [Webvilla][1] on Unsplash\n\n\n  [1]: https://unsplash.com/photos/hv1MrBzGGNY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText'","b""['food and drink', 'public health', 'medium', 'featured']""",https://www.kaggle.com/meganrisdal/la-county-restaurant-inspections-and-violations
b'NYS Quarterly Census of Employment and Wages',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'employment', 'industry', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-quarterly-census-of-employment-and-wages
b'News Headlines Dataset For Sarcasm Detection',b'High quality dataset for the task of Sarcasm Detection',"b'#Context\n\nPast studies in Sarcasm Detection mostly make use of Twitter datasets collected using hashtag based supervision but such datasets are noisy in terms of labels and language. Furthermore, many tweets are replies to other tweets and detecting sarcasm in these requires the availability of contextual tweets.\n\nTo overcome the limitations related to noise in Twitter datasets, this **News Headlines dataset for Sarcasm Detection** is collected from two news website. [*TheOnion*](https://www.theonion.com/) aims at producing sarcastic versions of current events and we collected all the headlines from News in Brief and News in Photos categories (which are sarcastic). We collect real (and non-sarcastic) news headlines from [*HuffPost*](https://www.huffingtonpost.com/).\n\nThis new dataset has following advantages over the existing Twitter datasets:\n\n* Since news headlines are written by professionals in a formal manner, there are no spelling mistakes and informal usage. This reduces the sparsity and also increases the chance of finding pre-trained embeddings.\n\n* Furthermore, since the sole purpose of *TheOnion* is to publish sarcastic news, we get high-quality labels with much less noise as compared to Twitter datasets.\n\n* Unlike tweets which are replies to other tweets, the news headlines we obtained are self-contained. This would help us in teasing apart the real sarcastic elements.\n\n# Content\nEach record consists of three attributes:\n\n* ```is_sarcastic```: 1 if the record is sarcastic otherwise 0\n\n* ```headline```: the headline of the news article\n\n* ```article_link```: link to the original news article. Useful in collecting supplementary data\n\n# Further Details\nGeneral statistics of data, instructions on how to read the data in python, and basic exploratory analysis could be found at [this GitHub repo](https://github.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection). A hybrid NN architecture trained on this dataset can be found at [this GitHub repo](https://github.com/rishabhmisra/Sarcasm-Detection-using-NN).\n\n# Acknowledgements\n\nThis dataset was collected from [TheOnion](https://theonion.com) and [HuffPost](https://www.huffingtonpost.com/). If this is against the TOS, please let me know and I will take it down.\n\n# Inspiration\n\nCan you identify sarcastic sentences? Can you distinguish between fake news and legitimate news sources?'","b""['classification', 'deep learning', 'nlp', 'linguistics', 'small', 'featured']""",https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection
b'VSRR Provisional Drug Overdose Death Counts',b'Explore Open Data from the Centers for Disease Control',"b""### Content  \n\nThis data contains provisional counts for drug overdose deaths based on a current flow of mortality data in the National Vital Statistics System. Counts for the most recent final annual data are provided for comparison. National provisional counts include deaths occurring within the 50 states and the District of Columbia as of the date specified and may not include all deaths that occurred during a given time period. Provisional counts are often incomplete and causes of death may be pending investigation (see Technical notes) resulting in an underestimate relative to final counts. To address this, methods were developed to adjust provisional counts for reporting delays by generating a set of predicted provisional counts (see Technical notes). Starting in June 2018, this monthly data release will include both reported and predicted provisional counts.\n\nThe provisional data include: (a) the reported and predicted provisional counts of deaths due to drug overdose occurring nationally and in each jurisdiction; (b) the percentage changes in provisional drug overdose deaths for the current 12 month-ending period compared with the 12-month period ending in the same month of the previous year, by jurisdiction; and (c) the reported and predicted provisional counts of drug overdose deaths involving specific drugs or drug classes occurring nationally and in selected jurisdictions. The reported and predicted provisional counts represent the numbers of deaths due to drug overdose occurring in the 12-month periods ending in the month indicated. These counts include all seasons of the year and are insensitive to variations by seasonality. Deaths are reported by the jurisdiction in which the death occurred.\n\nSeveral data quality metrics, including the percent completeness in overall death reporting, percentage of deaths with cause of death pending further investigation, and the percentage of drug overdose deaths with specific drugs or drug classes reported are included to aid in interpretation of provisional data as these measures are related to the accuracy of provisional counts (see Technical notes). Reporting of the specific drugs and drug classes involved in drug overdose deaths varies by jurisdiction, and comparisons of death rates involving specific drugs across selected jurisdictions should not be made (see Technical notes). Provisional data will be updated on a monthly basis as additional records are received.\n\nTechnical notes\n\nNature and sources of data\n\nProvisional drug overdose death counts are based on death records received and processed by the National Center for Health Statistics (NCHS) as of a specified cutoff date. The cutoff date is generally the first Sunday of each month. National provisional estimates include deaths occurring within the 50 states and the District of Columbia. NCHS receives the death records from state vital registration offices through the Vital Statistics Cooperative Program (VSCP).\n\nThe timeliness of provisional mortality surveillance data in the National Vital Statistics System (NVSS) database varies by cause of death. The lag time (i.e., the time between when the death occurred and when the data are available for analysis) is longer for drug overdose deaths compared with other causes of death (1). Thus, provisional estimates of drug overdose deaths are reported 6 months after the date of death.\n\nProvisional death counts presented in this data visualization are for \xe2\x80\x9c12-month ending periods,\xe2\x80\x9d defined as the number of deaths occurring in the 12-month period ending in the month indicated. For example, the 12-month ending period in June 2017 would include deaths occurring from July 1, 2016, through June 30, 2017. The 12-month ending period counts include all seasons of the year and are insensitive to reporting variations by seasonality. Counts for the 12-month period ending in the same month of the previous year are shown for comparison. These provisional counts of drug overdose deaths and related data quality metrics are provided for public health surveillance and monitoring of emerging trends. Provisional drug overdose death data are often incomplete, and the degree of completeness varies by jurisdiction and 12-month ending period. Consequently, the numbers of drug overdose deaths are underestimated based on provisional data relative to final data and are subject to random variation. Methods to adjust provisional counts have been developed to provide predicted provisional counts of drug overdose deaths, accounting for delayed reporting (see Percentage of records pending investigation and Adjustments for delayed reporting).\n\nProvisional data are based on available records that meet certain data quality criteria at the time of analysis and may not include all deaths that occurred during a given time period. Therefore, they should not be considered comparable with final data and are subject to change.\n\nCause-of-death classification and definition of drug deaths\nMortality statistics are compiled in accordance with World Health Organization (WHO) regulations specifying that WHO member nations classify and code causes of death with the current revision of the International Statistical Classification of Diseases and Related Health Problems (ICD). ICD provides the basic guidance used in virtually all countries to code and classify causes of death. It provides not only disease, injury, and poisoning categories but also the rules used to select the single underlying cause of death for tabulation from the several diagnoses that may be reported on a single death certificate, as well as definitions, tabulation lists, the format of the death certificate, and regulations on use of the classification. Causes of death for data presented in this report were coded according to ICD guidelines described in annual issues of Part 2a of the NCHS Instruction Manual (2).\n\nDrug overdose deaths are identified using underlying cause-of-death codes from the Tenth Revision of ICD (ICD\xe2\x80\x9310): X40\xe2\x80\x93X44 (unintentional), X60\xe2\x80\x93X64 (suicide), X85 (homicide), and Y10\xe2\x80\x93Y14 (undetermined). Drug overdose deaths involving selected drug categories are identified by specific multiple cause-of-death codes. Drug categories presented include: heroin (T40.1); natural opioid analgesics, including morphine and codeine, and semisynthetic opioids, including drugs such as oxycodone, hydrocodone, hydromorphone, and oxymorphone (T40.2); methadone, a synthetic opioid (T40.3); synthetic opioid analgesics other than methadone, including drugs such as fentanyl and tramadol (T40.4); cocaine (T40.5); and psychostimulants with abuse potential, which includes methamphetamine (T43.6). Opioid overdose deaths are identified by the presence of any of the following MCOD codes: opium (T40.0); heroin (T40.1); natural opioid analgesics (T40.2); methadone (T40.3); synthetic opioid analgesics other than methadone (T40.4); or other and unspecified narcotics (T40.6). This latter category includes drug overdose deaths where \xe2\x80\x98opioid\xe2\x80\x99 is reported without more specific information to assign a more specific ICD\xe2\x80\x9310 code (T40.0\xe2\x80\x93T40.4) (3,4). Among deaths with an underlying cause of drug overdose, the percentage with at least one drug or drug class specified is defined as that with at least one ICD\xe2\x80\x9310 multiple cause-of-death code in the range T36\xe2\x80\x93T50.8.\n\nDrug overdose deaths may involve multiple drugs; therefore, a single death might be included in more than one category when describing the number of drug overdose deaths involving specific drugs. For example, a death that involved both heroin and fentanyl would be included in both the number of drug overdose deaths involving heroin and the number of drug overdose deaths involving synthetic opioids other than methadone.\n\nSelection of specific states and other jurisdictions to report\nProvisional counts are presented by the jurisdiction in which the death occurred (i.e., the reporting jurisdiction). Data quality and timeliness for drug overdose deaths vary by reporting jurisdiction. Provisional counts are presented for reporting jurisdictions based on measures of data quality: the percentage of records where the manner of death is listed as \xe2\x80\x9cpending investigation,\xe2\x80\x9d the overall completeness of the data, and the percentage of drug overdose death records with specific drugs or drug classes recorded. These criteria are defined below.\n\nPercentage of records pending investigation\n\nDrug overdose deaths often require lengthy investigations, and death certificates may be initially filed with a manner of death \xe2\x80\x9cpending investigation\xe2\x80\x9d and/or with a preliminary or unknown cause of death. When the percentage of records reported as \xe2\x80\x9cpending investigation\xe2\x80\x9d is high for a given jurisdiction, the number of drug overdose deaths is likely to be underestimated. For jurisdictions reporting fewer than 1% of records as \xe2\x80\x9cpending investigation\xe2\x80\x9d, the provisional number of drug overdose deaths occurring in the fourth quarter of 2015 was approximately 5% lower than the final count of drug overdose deaths occurring in that same time period. For jurisdictions reporting greater than 1% of records as \xe2\x80\x9cpending investigation\xe2\x80\x9d the provisional counts of drug overdose deaths may underestimate the final count of drug overdose deaths by as much as 30%. Thus, jurisdictions are included in Table 2 if 1% or fewer of their records in NVSS are reported as \xe2\x80\x9cpending investigation,\xe2\x80\x9d following a 6-month lag for the 12-month ending periods included in the dashboard. Values for records pending investigation are updated with each monthly release and reflect the most current data available.\n\nPercent completeness\n\nNCHS receives monthly counts of the estimated number of deaths from each jurisdictional vital registration offices (referred to as \xe2\x80\x9ccontrol counts\xe2\x80\x9d). This number represents the best estimate of how many deaths occurred in a given jurisdiction in each month. Death records in the NVSS database must have both demographic and coded cause-of-death information. The percent completeness is obtained by dividing the number of death records in the NVSS database for each jurisdiction for each 12-month period by the control counts and multiplying by 100. For more information on completeness, see Technical Notes of the Vital Statistics Rapid Release Program. Jurisdictions are included in Table 2 if the percent completeness was consistently 90% or higher following a 6-month lag for the 12-month ending periods included in the dashboard.\n\nDrug specificity\n\nThe percentage of death records in which a specific drug or drug class is identified as involved in a drug overdose death varies by jurisdiction (5). Selected jurisdictions consistently had 90% or more of drug overdose death certificates mentioning at least one specific drug for all of the 12-month ending periods included in the dashboard. Provisional counts of drug overdose deaths where a specific drug or drug class is reported on the death certificate are presented for the United States and for jurisdictions meeting this threshold. Additionally, as a data quality metric, the percentage of drug overdose death records where at least one drug or drug class is recorded is presented.\n\nAs the timeliness and data quality of the drug overdose mortality data improve, the list of included jurisdictions will be re-examined to determine whether additional jurisdictions should be included or excluded based on the criteria described above. Due to reporting variations by jurisdiction, comparisons across selected jurisdictions should not be made. Data quality measures are shown for all jurisdictions in the below table. Values are updated with each monthly release and reflect the most current data available.\n\nAdjustments for delayed reporting\n\nProvisional counts of drug overdose deaths are underestimated relative to final counts. The degree of underestimation is determined primarily by the percentage of records with the manner of death reported as \xe2\x80\x9cpending investigation\xe2\x80\x9d and tends to vary by reporting jurisdiction, year, and month of death. Specifically, the number of drug overdose deaths will be underestimated to a larger extent in jurisdictions with higher percentages of records reported as \xe2\x80\x9cpending investigation,\xe2\x80\x9d and this percentage tends to be higher in more recent months.\n\nMethods were developed to adjust provisional counts for reporting delays related to temporal factors (i.e., 12 month-ending period) and the percentage of records that are reported with manner of death \xe2\x80\x9cpending investigation.\xe2\x80\x9d Briefly, these methods involve developing \xe2\x80\x98multiplication factors\xe2\x80\x99 based on the degree of underreporting in provisional data compared with final data. For example, if provisional counts of drug overdose deaths were historically 90% complete relative to final data, then the multiplication factor in this instance would be 1.1.  The reported provisional counts can be multiplied by this factor to generate a set of predicted provisional counts that adjust for reporting delays.\n\nThe 12 month-ending period and the percentage of records with manner of death reported as \xe2\x80\x9cpending investigation\xe2\x80\x9d were used to predict the degree of underreporting in provisional data relative to final.  Results from these models were used to generate a set of multiplication factors that could be applied to the reported provisional counts of drug overdose deaths to estimate predicted provisional counts.  These predicted provisional counts may represent a more accurate picture of recent trends by accounting for reporting delays related to the percentage of records in provisional data with manner of death \xe2\x80\x9cpending investigation.\xe2\x80\x9d It is important to note that flat or declining numbers of drug overdose deaths (either reported or predicted) could be due to incomplete data, true decreases in the number of deaths, or a combination of the two. True declines or plateaus in the numbers of drug overdose deaths across the U.S. cannot be ascertained until final data become available.\n\nSource: NCHS, National Vital Statistics System. Estimates for 2017 are based on provisional data. Estimates for 2015 and 2016 are based on final data (available from: https://www.cdc.gov/nchs/nvss/mortality_public_use_data.htm).\n\nReferences\n\n1. Spencer MR, Ahmad F. Timeliness of death certificate data for mortality surveillance and provisional estimates. National Center for Health Statistics. 2016.\n2. National Vital Statistics System. Instructions for classifying the underlying cause of death. In: NCHS instruction manual; Part 2a. Published annually.\n3. Slavova S, O\xe2\x80\x99Brien DB, Creppage K, et al. Drug Overdose Deaths: Let\xe2\x80\x99s Get Specific. Public Health Reports. 2015;130(4):339-342.\n4. Rudd RA, Seth P, David F, Scholl L. Increases in Drug and Opioid-Involved Overdose Deaths\xe2\x80\x94United States, 2010\xe2\x80\x932015. MMWR Morb Mortal Wkly Rep 65(5051):1445\xe2\x80\x9352. 2016.\n5. Warner M, Paulozzi LJ, Nolte KB, Davis GG, Nelson LS. State variation in certifying manner of death and drugs involved in drug intoxication deaths. Acad Forensic Pathol 3(2)231\xe2\x80\x937. 2013.\n\nSuggested citation\n\nAhmad FB, Rossen LM, Spencer MR, Warner M, Sutton P. Provisional drug overdose death counts. National Center for Health Statistics. 2018.\n\nDesigned by LM Rossen, A Lipphardt, FB Ahmad, JM Keralis, and Y Chong: National Center for Health Statistics.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Disease Control and Prevention. The organization has an open data platform found [here](https://data.cdc.gov) and they update their information according the amount of data that is brought in. Explore CDC Data using Kaggle and all of the data sources available through the CDC [organization page](https://www.kaggle.com/cdc)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ScEKf8u7y-c) by [Len  dela Cruz](https://unsplash.com/@mommist) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'united states', 'mortality', 'small', 'featured']""",https://www.kaggle.com/cdc/vsrr-provisional-drug-overdose-death-counts
b'IrishTimes - The Waxy-Wany News',b'Tracing 2.2 Decades of European events',"b'### Context\n\nThis news dataset is a compilation of 1.4 million news headlines published by The Irish Times based in Ireland.\n\nCreated over 159 Years ago the agency provides a long term birds eye view of the happenings of Europe.\n\nAgency Website: https://www.irishtimes.com\n\nThe historical reels can be explored thoroughly via the archives portal.\n\n### Content\n\nFormat: CSV ; Single File\n \n - 1 publish_date: Date of the article being published online in yyyyMMdd format\n - 2 headline_category: Category of the headline, Ascii, dot delimited, lowercase values\n - 3 headline_text: Text of the Headline assumed to be English\n\nStart Date: 1996-01-01 End Date: 2017-12-31\n\nTotal Events: **1,422,228**\n\nFeed Code: w3-event-irishtimes; Si.gh.rank: JAD\n\n### Acknowledgements\n\nSpecial Thanks to the journalists who participated in the creation of this News Dataset. \n\nMinimal cleanup and post-processing done due to generally optimal categories, site layout, formatting and timestamping.\n\nDedicated to Aurobindo Ghose a\xc5\xad Mirra Alfassa\n\nCitation for usage:\n\n**Rohit Kulkarni** (2018), Irish-Times News Archive, 1996-2XXX [CSV data file], doi:10.7910/DVN/0U9Z9F, Retrieved from: [this url]\n\nThis is an ongoing project by KonivaC. An update may be provided sidereally with the latest events.\n\n### Inspiration\n\nCelebrating the Summer Solistice of 2018 in Pondicherry.'","b""['news agencies', 'journalism', 'historiography', 'medium', 'featured']""",https://www.kaggle.com/therohk/ireland-historical-news
b'IAM Handwriting Top50',"b""Offline IAM Handwriting Dataset's subset, w.r.t. the 50 most common writers.""","b""### Context\n\nIAM Handwriting Dataset is a collection of handwritten passages by several writers. Generally, they use that data to classify writers according to their writing styles. A traditional way of solving such problem is extracting features like spacing between letters, curvatures, etc. and feeding them into Support Vector Machines. But, I wanted to solve this problem by Deep learning using Keras and Tensorflow. For the purpose, we don't need the full IAM Handwriting Dataset, but some authentic subset which can be used for training such as a subset of images by top 50 persons who contributed the most towards the dataset.\n\n### Content\n\nThis dataset contains images of each handwritten sentence with the dash-separated filename format. The first field represents the test code, second the writer id, third passage id, and fourth the sentence id.\n\n### Acknowledgements\n\nThis dataset won't be here without the help of FKI Computer Vision and Artificial Intelligence. As I came across the [IAM Handwriting dataset](http://www.fki.inf.unibe.ch/databases/iam-handwriting-database) from their website. \n\n### Inspiration\n\nI would like to see people use this data for more insights, exploratory notebooks, and many more because Handwriting recognition is not an easy task to be done individually. I need you Kagglers to have a look at it. ""","b""['image data', 'pattern recognition', 'medium', 'featured']""",https://www.kaggle.com/tejasreddy/iam-handwriting-top50
b'NYC Revised Notice of Property Value (RNOPV)',b'From New York City Open Data',"b""### Content  \n\nEvery January, Finance mails New York City property owners a Notice of Property Value (NOPV). This important notice has information about your property\xe2\x80\x99s market and assessed values. Finance determines your property\xe2\x80\x99s value every year, according to State law. The City\xca\xbcs property tax rates are applied to the assessed value to calculate your property taxes for the next tax year. You get your first tax bill for the year in June. If you believe the values or property descriptions on the NOPV are not correct.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/h5QNclJUiA8) by [Gus Ruballo](https://unsplash.com/@gusruballo) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'finance', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-revised-notice-of-property-value-rnopv
b'Mobile App Store ( 7200 apps)',b'Analytics for Mobile Apps',"b'**Mobile App Statistics (Apple iOS app store)**\n======================================\nThe ever-changing mobile landscape is a challenging space to navigate.  . The percentage of mobile over desktop is only increasing.  Android holds about 53.2% of the smartphone market, while iOS is 43%.  To get more people to download your app, you need to make sure they can easily find your app.  Mobile app analytics is a great way to understand the existing strategy to drive growth and retention of future user.\n\nWith million of apps around nowadays,  the following data set  has become very key to getting top trending apps in iOS app store.  This data set contains more than 7000 Apple iOS mobile application details. The data was extracted from the [iTunes Search API](http://www.transtats.bhttps://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/iTuneSearchAPI/SearchExamples.html#//apple_ref/doc/uid/TP40017632-CH6-SW1ts.gov/DatabaseInfo.asp?DB_ID=120&Link=0) at the Apple Inc website.  R and  linux web scraping tools were used for this study. \n\n**Data collection date (from API);**\nJuly 2017\n\n**Dimension of the data set;**\n7197 rows and 16 columns\n\n**Content:**\n------------\n\nappleStore.csv\n--------------\n\n1. ""id"" : App ID\n\n2. ""track_name"": App Name\n\n3. ""size_bytes"": Size (in Bytes)\n\n4. ""currency"": Currency Type\n\n5. ""price"": Price amount\n\n6. ""rating_count_tot"": User Rating counts (for all version)\n\n7. ""rating_count_ver"": User Rating counts (for current version)\n\n8. ""user_rating"" : Average User Rating value (for all version)\n\n9. ""user_rating_ver"": Average User Rating value (for current version)\n\n10. ""ver"" : Latest version code\n\n11. ""cont_rating"": Content Rating\n\n12. ""prime_genre"": Primary Genre \n\n13. ""sup_devices.num"": Number of supporting devices \n\n14. ""ipadSc_urls.num"": Number of screenshots showed for display\n\n15. ""lang.num"": Number of supported languages\n\n16. ""vpp_lic"": Vpp Device Based Licensing Enabled\n\nappleStore_description.csv\n--------------------------\n\n1.   id : App ID\n2.   track_name: Application name\n3.  size_bytes: Memory size (in Bytes)\n4.   app_desc: Application description\n\n# Acknowledgements\nThe data was extracted from the [iTunes Search API](http://www.transtats.bhttps://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/iTuneSearchAPI/SearchExamples.html#//apple_ref/doc/uid/TP40017632-CH6-SW1ts.gov/DatabaseInfo.asp?DB_ID=120&Link=0) at the Apple Inc website.  R and  linux web scraping tools were used for this study. \n\n## Inspiration\n1. *How does the App details contribute the user ratings?*\n2. *Try to compare app statistics for different groups?*\n\n**Reference: R package**\nFrom github, with \n`devtools::install_github(""ramamet/applestoreR"")`\n\n## Licence\nCopyright (c) 2018 Ramanathan Perumal\n\n'","b""['internet', 'business', 'mobile web', 'small', 'featured']""",https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps
b'FiveThirtyEight Nutrition Studies Dataset',b'Explore Data from FiveThirtyEight',"b'### Content  \n\n# Nutrition Studies\n\nThis directory contains data and code behind the story [You Can\xe2\x80\x99t Trust What You Read About Nutrition](http://fivethirtyeight.com/features/you-cant-trust-what-you-read-about-nutrition).\n\nMany studies of diet and nutrition include multiple variables with vast amounts of data, making it easy to p-hack your way to sexy (and false) results. We learned this firsthand when we invited readers to take a survey about their eating habits known as the food frequency questionnaire and answer a few other questions about themselves. We ended up with 54 complete responses and looked for associations much as researchers look for links between foods and dreaded diseases. It was easy to find them. \n\n*Warning*: This is evil (statistical) work. Do not go to the dark side. Do not try this at home.\n\nThis directory contains three files:\n\nFile | Description\n--- | -----\n`raw_anonymized_data.csv` | The FFQ and survey data from 54 respondents\n`p_hacking.R` | An R script that performs 27,716 regressions\n`p_values_analysis.csv` | The output data file listing the p-values\n\n**Note:** This is an intentionally shady regression analysis, both because of the ""p-hacking"" or ""data mining"" behind running more than 27,000 regressions and because the statistics reported were the p-values of the characteristics (the independent variables).\n\n**IN OTHER WORDS: THIS IS NOT AN EXAMPLE OF SOUND DATA ANALYSIS.**  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub\'s [API](https://developer.github.com/v3/?) and Kaggle\'s [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.'","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-nutrition-studies-dataset
b'CMS HPSA & Low-Income ZIP Code Database',b'Explore open data from the CMS',"b""### Content  \n\nDatabase of HPSA and Low-Income ZIP Codes for Issuers Subject to the Alternate ECP Standard for the purposes of QHP Certification  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/bWLfUGOgqhM) by [Markus Spiske](https://unsplash.com/@markusspiske) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under NA""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/cms-hpsa-low-income-zip-code-database
b'Chicago Transit Authority (CTA) Data',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-transit-authority-cta-data
b'fatstText Common Crawl',b' 2 million word vectors trained on Common Crawl',"b'### English Word Vectors from Common Crawl\n\n\n---\n\n### About fastText<br>\n\nfastText is a library for efficient learning of word representations and sentence classification. One of the key features of fastText word representation is its ability to produce vectors for any words, even made-up ones. Indeed, fastText word vectors are built from vectors of substrings of characters contained in it. This allows you to build vectors even for misspelled words or concatenation of words.\n\n\n### About the vectors<br>\nThese pre-trained vectors contain 2 million word vectors trained on Common Crawl (600B tokens).\n\nThe first line of the file contains the number of words in the vocabulary and the size of the vectors. Each line contains a word followed by its vectors, like in the default fastText text format. Each value is space separated. Words are ordered by descending frequency.\n\n\n\n### Acknowledgements<br>\nThese word vectors are distributed under the Creative Commons Attribution-Share-Alike License 3.0.\n\nP. Bojanowski*, E. Grave*, A. Joulin, T. Mikolov, Enriching Word Vectors with Subword Information<br>\nA. Joulin, E. Grave, P. Bojanowski, T. Mikolov, Bag of Tricks for Efficient Text Classification<br>\nA. Joulin, E. Grave, P. Bojanowski, M. Douze, H. J\xc3\xa9gou, T. Mikolov, FastText.zip: Compressing text classification models<br><br>\n\n(* These authors contributed equally.)'","b""['nlp', 'pre-trained model', 'large', 'featured']""",https://www.kaggle.com/facebook/fatsttext-common-crawl
b'Austin Animal Center Shelter Intakes and Outcomes',"b'80,000 Shelter Animal Intakes and Resulting Outcomes'","b""### Context\n\nThe [Austin Animal Center](http://www.austintexas.gov/department/aac) is the largest no-kill animal shelter in the United States that provides care and shelter to over 18,000 animals each year. As part of the AAC's efforts to help and care for animals in need, the organization makes available its accumulated data and statistics as part of the city of [Austin's Open Data Initiative](https://data.austintexas.gov/).\n\n### Content\n\nThe data contains intakes and outcomes of animals entering the Austin Animal Center from the beginning of October 2013 to the present day. The datasets are also freely available on the [Socrata Open Data Access API](https://dev.socrata.com/) and are updated daily. \n\nThe following are links to the datasets hosted on Socrata's Open Data:\n\n* [Austin Animal Center Intakes](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Intakes/wter-evkm)\n* [Austin Animal Center Outcomes](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Outcomes/9t4d-g238)\n\nThe data contained in this dataset is the outcomes and intakes data as noted above, as well as a combined dataset. The merging of the outcomes and intakes data was done on a unique key that is a combination of the given Animal ID and the intake number. Several of the animals in the dataset have been taken into the shelter multiple times, which creates duplicate Animal IDs that causes problems when merging the two datasets.\n\nCopied from the description of the Shelter Outcomes dataset, here are some definitions of the outcome types:\n\n* Adoption \n  - the animal was adopted to a home\n* Barn Adoption \n  - the animal was adopted to live in a barn\n* Offsite Missing \n  - the animal went missing for unknown reasons at an offsite partner location\n* In-Foster Missing \n  - the animal is missing after being placed in a foster home\n* In-Kennel Missing \n  - the animal is missing after being transferred to a kennel facility\n* Possible Theft \n  - Although not confirmed, the animal went missing as a result of theft from the facility\n* Barn Transfer\n  - The animal was transferred to a facility for adoption into a barn environment\n* SNR\n  - SNR refers to the city of Austin's [Shelter-Neuter-Release](http://www.austintexas.gov/blog/changes-made-shelter-neuter-return-cat-program-reflect-community-stakeholder-input) program. I believe the outcome is representative of the animal being released.\n\n### Acknowledgements\n\nThe data presented here is only possible through the hard work and dedication of the Austin Animal Center in saving and caring for animal lives. \n\n### Inspiration\n\nFollowing from the first dataset I posted to Kaggle, [Austin Animal Shelter Outcomes](https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-outcomes-and), which was initially filtered for just cats as part of an analysis I was performing, I wanted to post the complete outcome and complementing intake datasets. My hope is the great users of Kaggle will find this data interesting and want to explore shelter animal statistics further and perhaps get more involved in the animal welfare community. The analysis of this data and other shelter animal provided datasets helps uncover useful insights that have the potential to save lives directly.""","b""['animals', 'small', 'featured']""",https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes
"b""What's Happening LA Calendar Dataset""",b'From Los Angeles Open Data',"b""### Content  \n\nAll-City event calendar - ARCHIVED\r\n\r\nFor the new LA City Events dataset (refreshed daily), see https://data.lacity.org/A-Prosperous-City/LA-City-Events/rx9t-fp7k  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ZMMXSRMSoI8) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/what's-happening-la-calendar-dataset
b'Seattle Trade Permits',b'From City of Seattle Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/g8GfTWqCdFY) by [Tim Arterbury](https://unsplash.com/@tim_arterbury) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-trade-permits
b'Flats for Rent at Budapest',b'Scraped flat offers with images from a Hungarian site',"b'### Context\n\nI am looking for a flat to rent and on the ""biggest"" Hungarian site there is no filter for animals. Because of this I wrote a script witch can notify me if there is a apartment with the correct conditions and also allows dogs. I realized I could collect the data and share with you, so this is what I did.\n\n### Content\n\n- **csv file:** Inside the `csv` file you can find self descriptive column names, but the values are all in Hungarian. The first column is the index of the rows which was the URL of the original offer on the site. The rows can and will contain `NaN` values because almost every property is optional for those who creates the offer\n- **images**: For every flat that had images there is a folder with name of a uuid. Inside that folder you can find the images for the flat\n  - `orientation` :  Portrait and Landscape\n  - `size`: the longer side of the original image is `360px` and the sorter side is resized according to the original aspect ratio\n\n\n### Acknowledgements\n\nMy miniature dachshund puppy ,`Joey` is the reason I collected the data. With him, it\'s much harder to find a flat. :D\n<img src=""https://i.imgur.com/lnLju8i.png"">\n\n### Inspiration\n\nIt would be interesting to see how the images correlates with the price of the flats. There must be some kind of *visual score*.\n\n\n  [1]: https://i.imgur.com/lnLju8i.png\n\n### Other\n\nThe data is not my property, I only followed hyperlinks and scraped the visible data. (which is visible for those who visit the site).'","b""['image data', 'real estate', 'home', 'medium', 'featured']""",https://www.kaggle.com/gaborvecsei/flats-to-rent-at-budapest
b'SETI Data',b'Simulated Signal Data for Machine Learning',"b""### Aim\n\nI hope that by uploading some of the data previously shared by [SETI][1] onto Kaggle, more people will become aware of SETI\xe2\x80\x99s work and become engaged in the application of machine learning to the data (amongst other things). Note, I am in no way affiliated with SETI, I just think this is interesting data and amazing science.\n\n### Finding ET\n\nIf you\xe2\x80\x99re reading this, then I\xe2\x80\x99m guessing you have an interest in data science. And if you have an interest in data science, you\xe2\x80\x99ve probably got an interest in science in general. \n\nOut of every scientific endeavour undertaken by humanity, from mapping the human genome to landing a man on the moon, it seems to me that the **Search for Extra-terrestrial Intelligence** (SETI) has the greatest chance to fundamentally change how we think about our place in the Universe.\n\nJust imagine if a signal was detected. Not natural. Not human. On the one hand it would be a Copernican-like demotion of mankind\xe2\x80\x99s central place in the Cosmos, and on the other an awe-inspiring revelation that somewhere out there, at least once, extra-terrestrial intelligence emerged.\n\n### SETI\n\nOver the past few years, SETI have launched a few initiatives to engage the public and \xe2\x80\x98citizen scientists\xe2\x80\x99 to help with their search. Below is a summary of their work to date (from what I can tell).\n\nIn January 2016, the Berkeley SETI Research Center at the University of Berkley started a program called **Breakthrough Listen**, described as \xe2\x80\x9c*the most comprehensive search for alien communications to date*\xe2\x80\x9d. Radio data is being currently been collected by the Green Bank Observatory in West Virginia and the Parkes Observatory in New South Wales, with optical data being collected by the Automated Planet finder in California. Note that (for now at least), the rest of this description focusses on the radio data.\n\nThe basic technique for finding a signal is this; point the telescope at a candidate object and listen for 5 minutes. If any sort of signal is detected, point slightly away and listen again. If the signal drops away, then it\xe2\x80\x99s probably not terrestrial. Go back to the candidate and listen again. Is the signal still there? Now point to a second, slightly different position. How about now? The most interesting finding is, as you might expect, SIGNAL - NO SIGNAL \xe2\x80\x93 SIGNAL - NO SIGNAL \xe2\x80\x93 SIGNAL.\n\nThe Breakthrough Listen project has just about everything covered. The hardware and software to collect signals, the time, the money, and the experts to run the project. The only sticking point is the data. Even after compromising on the raw data\xe2\x80\x99s time or frequency resolution, Breakthrough Listen is archiving 500GB and data every hour (!).\n\nThe resulting data are stored in something called a **filterbank** file, which are created at three different frequency resolutions. These are,\n\n - High frequency resolution (~3 Hz frequency resolution, ~18 second sample time)\n - High time resolution (~366 kHz frequency resolution, ~349 microsecond sample time)\n - Medium resolution (~3 kHz frequency resolution, ~1 second sample time)\n\nTo engage the public, Breakthrough listen\xe2\x80\x99s primary method is something called **SETI@Home**, where a program can be downloaded and installed, and your PC used when idle to download packets of data and run various analysis routines on them.\n\nBeyond this, they have shared a number of starter scripts and some data. To find out more, a general landing page can be found [here][2]. The scripts can be found on GitHub [here][3] (very useful), and a data archive can be found [here][4] (although most of this is in the **baseband** format, which is a rawer format compared to the filterbank format). Note that the optical data from the Automated Planet Finder is also in a different format called a **FITS** file.\n\n### Entering the Cloud\n\nThe second initiative by SETI to engage the public was the **SETI@IBMCloud** project launched in September 2016. This provided the public with access to an enormous amount of data via the IBM Cloud platform. This initiative, too, came with an excellent collection of starter scripts which can still be found on GitHub [here][5]. Unfortunately, at the time of writing, this project is on hold and the data cannot be accessed.\n\n### SETI & Machine Learning\n\nThere are a few other sources of data online from SETI, one of which is the basis for this dataset.\n\nIn the summer of 2017, SETI hosted a machine learning challenge where simulated datasets of various sizes were provided to participants along with a blinded test set. The winning team achieved a classification accuracy of 94.67% using a **convolution neural network**. The aim of this challenge was to attempt a novel approach to signal detection, namely to go beyond traditional signal analysis approaches and to turn the problem into an image classification task, after converting the signals into **spectrograms**.\n\nThe primary training data has been removed, but a 'basic', 'small' and 'medium' version of the data is still on the GitHub page [here][6]. I\xe2\x80\x99m using the \xe2\x80\x98small\xe2\x80\x99 version for this Kaggle dataset. This consists of 7 different classes of SETI signal (1000 files per class). Details of the nature of these signals along with a more detailed description of the challenge can be found [here][7].\n \nNote that many of the scripts written by SETI as hosted on Github, and my starter scripts on Kaggle, use a non-standard Python package called **ibmseti**.\n\n### Media Interest\n\nSETI\xe2\x80\x99s work in machine learning has recently hit the headlines when a deep learning algorithm was applied to a gargantuan chunk of data from the Green Bank telescope relating to a radio source called **FRB 121102**. Thought to originate from a dwarf galaxy 3 billion light years away, a number of mysterious signals were discovered, sending the media into an alien-fuelled frenzy. That said, it turns out that the signals are also highly polarised, suggesting they\xe2\x80\x99ve passed through an extremely powerful magnetic field, leading to the speculation that they originate from a neutron star, perhaps near a massive black hole.\n\nAll of the data from this work and a link to the corresponding paper can be found [here][8].\n\n### This dataset and possible challenges\n\nI aim to keep this dataset regularly updated with new data and kernels, contacting SETI along the way to get advice and feedback. In terms of the data, my main aim is to upload some real-world data and run it through a signal detection algorithm. \n\nFor now, consider the following challenges,\n\n - Create an improved algorithm for signal classification of the small primary dataset\n - Take a step back and investigate signal processing techniques\n - Try simulating some new data, perhaps with different signal types, or multiple signal types per image\n - Can a deep learning algorithm not only classify signals but also infer some properties, too?\n\nGood luck and happy hunting!\n\n\n  [1]: https://www.seti.org/\n  [2]: https://seti.berkeley.edu/listen/\n  [3]: https://github.com/UCBerkeleySETI/breakthrough\n  [4]: http://breakthroughinitiatives.org/opendatasearch\n  [5]: https://github.com/ibm-watson-data-lab/seti_at_ibm\n  [6]: https://github.com/setiQuest/ML4SETI\n  [7]: https://medium.com/ibm-watson-data-lab/using-artificial-intelligence-to-search-for-extraterrestrial-intelligence-ec19169e01af\n  [8]: http://seti.berkeley.edu/frb-machine/""","b""['deep learning', 'cnn', 'astronomy', 'large', 'featured']""",https://www.kaggle.com/tentotheminus9/seti-data
b'Los Angeles Registered Foreclosure Properties',b'From Los Angeles Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/UylqA1MFQLo) by [Andre Benz](https://unsplash.com/@trapnation) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Creative Commons 1.0 Universal (Public Domain Dedication), NA""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-registered-foreclosure-properties
b' Hotels on Makemytrip',"b'Details of 20,000 hotels on MakeMyTrip.com'","b""###Context\n\nThis is a pre-crawled dataset, taken as subset of a bigger dataset (more than 615,000 hotels) that was created by extracting data from MakeMyTrip.com, a travel portal in India. The complete dataset is available on [DataStock][1], a web data repository with historical records from several industries. \n\n### Content\n\nThis dataset has following fields:\n\n- area\n- city\n- country\n- crawl_date\n- highlight_value\n- hotel_overview\n- hotel_star_rating\n- image_urls\n- in_your_room\n- is_value_plus\n- latitude\n- longitude\n- mmt_holidayiq_review_count\n- mmt_location_rating\n- mmt_review_count\n- mmt_review_rating\n- mmt_review_score\n- mmt_traveller_type_review_count\n- mmt_tripadvisor_count\n- pageurl\n- property_address\n- property_id\n- property_name\n- property_type\n- qts\n- query_time_stamp\n- room_types\n- site_review_count\n- site_review_rating\n- sitename\n- state\n- traveller_rating\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud's in-house web-crawling service.\n\n### Inspiration\nAnalyses of the reviews, ratings and property description can be performed.\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=mm-kaggle&utm_medium=referral""","b""['internet', 'hotels', 'medium', 'featured']""",https://www.kaggle.com/PromptCloudHQ/hotels-on-makemytrip
b'Data Scientist Job Market in the U.S.',b'An outlook at data science job market in the U.S. in 2018 August. ',"b""### Context\n\nFor those who are actively looking for data scientist jobs in the U.S., the best news this month is the LinkedIn Workforce Report August 2018.  According to the report,  there is a shortage of 151,717 people with data science skills, with particularly acute shortages in New York City, San Francisco Bay Area and Los Angeles.\n\nTo help job hunters (including me) to better understand the job market, I scraped Indeed website and collected information of 7,000 data scientist jobs around the U.S. on August 3rd. The information that I collected are: Company Name, Position Name, Location, Job Description, and Number of Reviews of the Company. \n\n\n### Content\n\n - alldata.csv If you want to explore the job market around the U.S., download this one because it aggregates all information and cleans the job description by removing the tags. \n - all other files. If you want to explore specific city or region, you can download any of them. \n\n### Acknowledgements\n\nSpecial thanks to Indeed for not blocking me : )\n\n\n### Inspiration\n\n - If you have no clue of where to start, check my [blog][1] for inspiration. \n - Link to my PowerPoint Slides for [Presentation.][2] \n - Link to my [GitHub Code][3].\n - Reach me at sl6149@nyu.edu\n \n\nPossible Questions: \n\n 1. Who gets hired? What kind of talent do employers want when they are hiring a data scientist?\n 2. Which location has the most opportunities? \n 3. What skills, tools, degrees or majors do employers want the most for data scientists?\n 4. What's the difference between data scientist, data engineer and data analyst? \n 5. Can you develop an efficient classification algorithm to differentiate the three job types above? \n\n\n  [1]: https://nycdatascience.com/blog/student-works/who-gets-hired-an-outlook-of-the-u-s-data-scientist-job-market-in-2018/\n  [2]: https://github.com/Silvialss/projects/blob/master/IndeedWebScraping/2018DataScienceMarketResearch.pdf\n  [3]: https://github.com/Silvialss/projects/tree/master/IndeedWebScraping""","b""['data visualization', 'classification', 'data cleaning', 'categorical data', 'medium', 'featured']""",https://www.kaggle.com/sl6149/data-scientist-job-market-in-the-us
b'FiveThirtyEight Police Deaths Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Police Deaths\n\nThis directory contains the data and code behind the story [The Dallas Shooting Was Among The Deadliest For Police In U.S. History](https://fivethirtyeight.com/features/the-dallas-shooting-was-among-the-deadliest-for-police-in-u-s-history/). The primary source of data is the [Officer Down Memorial Page](https://www.odmp.org/) (ODMP), started in 1996 by a college student who is now a police officer and who continues to maintain the database.\n\nFile descriptions:\n\nFile | Description\n---|-----------\n`scrape.R` | Scrapes data on the death of every officer tracked on ODMP\n`all_data.csv` | Output of `scrape.R`\n`clean.R` | Takes the data in `all_data.csv`, cleans it and formats the dates correctly, and tags every entry as human or canine.\n`clean_data.csv` | Output of `clean.R`\n`plot.R` | Summarizes police deaths by category and generates a plot similar to the one below\n\n![](https://i1.wp.com/espnfivethirtyeight.files.wordpress.com/2016/07/bialik-flowers-king-police-deaths-1.png)  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-police-deaths-dataset
b'Cat Dataset',"b'Over 9,000 images of cats with annotated facial features'","b'### Context\n\nThe CAT dataset includes over 9,000 cat images. For each image, there are annotations of the head of cat with nine points, two for eyes, one for mouth, and six for ears.  \n\n\n### Content\n\nThe annotation data are stored in a file with the name of the corresponding image plus .""cat"" at the end. There is one annotation file for each cat image.  For each annotation file, the annotation data are stored in the following sequence:\n\n- Number of points (default is 9)\n- Left Eye\n- Right Eye\n- Mouth\n- Left Ear-1\n- Left Ear-2\n- Left Ear-3\n- Right Ear-1\n- Right Ear-2\n-Right Ear-3\n\n\n### Acknowledgements<br>\nWeiwei Zhang, Jian Sun, and Xiaoou Tang,  Cat Head Detection - How to Effectively Exploit Shape and Texture Features, Proc. of European Conf. Computer Vision, vol. 4, pp.802-816, 2008.<br>\nDataset originally found on the Internet Archive at https://archive.org/details/CAT_DATASET<br><br>\n\n'","b""['image data', 'image processing', 'animals', 'object labeling', 'large', 'featured']""",https://www.kaggle.com/crawford/cat-dataset
b'Chicago Business Licenses and Owners',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/qGb4-eCYhY8) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'business', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-business-licenses-and-owners
b'Fast Food Restaurants Across America',"b'A list of 10,000 restaurants and their locations. '","b""# Content\n\nThis is a list of over 10,000 fast food restaurants provided by [Datafiniti's Business Database][1]. The dataset includes the restaurant's address, city, latitude and longitude coordinates, name, and more.  \n\n*Note that this is a sample of a large data set. The full data set is available through Datafiniti.*\n\n# What You Can Do with This Data\n\nYou can use this data to [rank cities with the most and least fast food restaurants across the U.S.][2]. E.g.:\n\n - Cities with the most and least McDonald's per capita \n - Fast food restaurants per capita for all states\n - Fast food restaurants with the most locations nationally \n - Major cities with the most and least fast food restaurants per capita \n - Small cities with the most fast food restaurants per capita\n - States with the most and least fast food restaurants per capita \n - The number of fast food restaurants per capita\n\n# Data Schema\nA full schema for the data is available in our [support documentation][3].\n\n# About Datafiniti\nDatafiniti provides instant access to web data. We compile data from thousands of websites to create standardized databases of business, product, and property information. [Learn more][4].\n\n# Want More?\nYou can get more data like this by [joining Datafiniti][5] or [requesting a demo][6].\n\n  [1]: https://datafiniti.co/products/business-data/\n  [2]: https://datafiniti.co/fast-food-restaurants-america/\n  [3]: https://developer.datafiniti.co/docs/business-data-schema\n  [4]: https://datafiniti.co/\n  [5]: https://portal.datafiniti.co/login\n  [6]: https://datafiniti.co/request-a-demo/""","b""['food and drink', 'business', 'databases', 'small', 'featured']""",https://www.kaggle.com/datafiniti/fast-food-restaurants
b'NYS Department Application Review and Tracking-Web',b'From New York State Open Data',"b""### Content  \n\nTabular Data for Permits administered by the Agency in which the general public can use a web interface to look up specific facilities and applications.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/npxXWgQ33ZQ) by [Glenn Carstens-Peters](https://unsplash.com/@glenncarstenspeters) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-department-application-review-and-tracking-web
b'311 Service Requests Pitt',b'Great data to begin analysis',b'### Context\n\n311 service request data\n\n### Content\n\nThousands of rows and many variables for every call made on 311.\n\n### Acknowledgements\n\nThis data set is taken from an online open source. \n\n### Inspiration\n\nCompleting service requests is critical for happy and satisfied citizens. This data will give insight into the efficiency of all the departments working to serve the people.',"b""['data cleaning', 'time series analysis', 'small', 'featured']""",https://www.kaggle.com/yoghurtpatil/311-service-requests-pitt
b'H1B Disclosure Dataset ',b'H1B Disclosure Dataset - Predicting the Case Status',"b'__Project Description:__\n\n__1) Data Background__\n\nIn the Data Mining class, we had the opportunity to analyze data by performing data mining algorithms to a dataset. Our dataset is from Office of Foreign Labor Certification (OFLC). OFLC is a division of the U.S. Department of Labor. The main duty of OFLC is to assist the Secretary of Labor to enforce part of the Immigration and Nationality Act (INA), which requires certain labor conditions exist before employers can hire foreign workers. \nH-1B is a visa category in the United States of America under the INA, section 101(a)(15)(H) which allows U.S. employers to employ foreign workers. The first step employer must take to hire a foreign worker is to file the Labor Condition Application. In this project, we will analyze the data from the Labor Condition Application. \n\n__1.1) Introduction to H1B Dataset__  \n \nThe H-1B Dataset selected for this project contains data from employer\xe2\x80\x99s Labor Condition Application and the case certification determinations processed by the Office of Foreign Labor Certification (OFLC) where the date of the determination was issues on or after October 1, 2016 and on or before June 30, 2017.\n\nThe Labor Condition Application (LCA) is a document that a perspective H-1B employer files with U.S. Department of Labor Employment and Training Administration (DOLETA) when it seeks to employ non-immigrant workers at a specific job occupation in an area of intended employment for not more than three years. \t\n\n__1.2) Goal of the Project__  \n\nOur goal for this project is to predict the case status of an application submitted by the employer to hire non-immigrant workers under the H-1B visa program. Employer can hire non-immigrant workers only after their LCA petition is approved. The approved LCA petition is then submitted as part of the Petition for a Non-immigrant Worker application for work authorizations for H-1B visa status.   \n\nWe want to uncover insights that can help employers understand the process of getting their LCA approved. We will use WEKA software to run data mining algorithms to understand the relationship between attributes and the target variable.\n\n\n__2)Dataset Information:__\n\na) Source: Office of Foreign Labor Certification, U.S. Department of Labor Employment and Training Administration   \nb) List Link: https://www.foreignlaborcert.doleta.gov/performancedata.cfm   \nc) Dataset Type: Record \xe2\x80\x93 Transaction Data   \nd) Number of Attributes: 40   \ne) Number of Instances: 528,147   \nf) Date Created: July 2017  \n\n__3) Attribute List:__\n\nThe detailed description of each attribute below is given in the Record Layout file available in the zip folder H1B Disclosure Dataset Files. \n\nThe H-1B dataset from OFLC contained 40 attributes and 528,147 instances. The attributes are in the table below. The attributes highlighted __bold__ were removed during the data cleaning process.\n\n__1) CASE_NUMBER__      \n2)CASE_SUBMITTED  \n3)DECISION_DATE  \n4)VISA_CLASS  \n__5)EMPLOYMENT_START_DATE__        \n__6)EMPLOYMENT_END_DATE__       \n7)EMPLOYER_NAME  \n__8)EMPLOYER_ADDRESS__        \n__9)EMPLOYER_CITY__       \n10)EMPLOYER_STATE  \n__11)EMPLOYER_POSTAL_CODE__        \n12)EMPLOYER_COUNTRY  \n__13)EMPLOYER_PROVINCE__      \n__14)EMPLOYER_PHONE__     \n__15)EMPLOYER_PHONE_EXT__   \n__16)AGENT_ATTORNEY_NAME__   \n__17)AGENT_ATTORNEY_CITY__    \n__18)AGENT_ATTORNEY_STATE__   \n__19)JOB_TITLE__   \n__20)SOC_CODE__   \n21)SOC_NAME  \n22)NAICS_CODE  \n23)TOTAL_WORKERS   \n24)FULL_TIME_POSITION   \n25)PREVAILING_WAGE   \n26)PW_UNIT_OF_PAY   \n27)PW_SOURCE   \n28)PW_SOURCE_YEAR   \n29)PW_SOURCE_OTHER   \n30)WAGE_RATE_OF_PAY_FROM   \n31)WAGE_RATE_OF_PAY_TO   \n32)WAGE_UNIT_OF_PAY   \n33)H-1B_DEPENDENT   \n__34) WILLFUL_VIOLATOR__      \n__35) WORKSITE_CITY__     \n__36)WORKSITE_COUNTY__       \n37)WORKSITE_STATE  \n38)WORKSITE_POSTAL_CODE   \n__39)ORIGINAL_CERT_DATE__       \n40)CASE_STATUS* - __Class Attribute - To be predicted   \n\n\n__3.1) Class Attribute__\n\nFor the H-1B Dataset our class attribute is \xe2\x80\x98CASE_STATUS\xe2\x80\x99. There are 4 categories of Case Status. The values of Case_Status attributes are:\n\n1) Certified  \n2) Certified_Withdrawn  \n3) Withdrawn  \n4) Denied  \n\nCertified means the LCA of an employer was approved. Certified Withdrawn means the case was withdrawn after it was certified by OFLC. Withdrawn means the case was withdrawn by the employer. Denied means the case was denied OFLC. \n'","b""['united states', 'artificial intelligence', 'machine learning', 'mining', 'medium', 'featured']""",https://www.kaggle.com/trivedicharmi/h1b-disclosure-dataset
b'Practice makes master: Movie Collection Analysis',b'Dataset to train Analysis- and Machine Learning Skills',"b'### Context\n\nThe data set represents movies which were released in the years of xxx up to 2017. It is kept quite general and does not have any real problem / challenge as a background. The whole data set is meant to practice different types of techniques for a data analyst / data scientist.  \n\nI\xc2\xb4d like also to mention that the Dataset is not fully cleaned. Reasoning is that it shall demonstrate you the real life of being an Analyst / Scientist. \nGet Data - Prep Data - Analyse Data - Visualize Data ;-)\n\n### Content\n\nI love watching movies and therefore tried to combine this hobby with my current self studies of becoming a data scientist.\nTherefore I needed a way to obtain a data set which included information of movies so that I could play around and use my learnings.  On the first glance I could see that the data set can be used for Regressions, Classifications or potentially even Deep Learning (such as Image Recognition - Post URLs are given)\n\nI did aquire this dataset by using different steps. First I did check the internet for a specific API which I may use to receive movie information. After a short time I got to know omdbapi.com. With the help of this API I was able to fetch information based on the title of the movies. \n\nNow I had another problem. I was missing movie titles. The next search had begun. I couldn\xc2\xb4t find an API for that but I did see that wikipedia was quite well structured in regards to movie titles. So I did build a scraper to fetch all movie titles from 1990 to 2017. \n\nAfter receiving all the data I could finally start to obtain all movie information of a movie by having the title + year (there might be movies which have the same name). Unfortunately some movie titles have been written differently and so I had a failure rate of 10% for obtaining the movie data.  Based on the 10% failed movie titles - I did an Text Analysis and found around 400 000 new Movies / Series. The latest Version should include nearly 200 000 different movies based on the imdbID. \n\nAdditionally I did clean some of the information such as Genre, Actors and Writer for better analysing. Each of the CSV File can be joined by the **imdbID**. Be aware that some information are missing and declared as *_NOT_GIVEN*. \n\n\n\n### Acknowledgements\n\n - Thanks to omdbapi.com for providing such a good API and well structured data. \n\n### Inspiration\n\nThe inspiration of this data set came from getting into the practical flow of developing an image recognition application. **Recognize the genre of a movie by the given poster.**\nBy request I could also provide the images of the movies. But for the given Dataset I do have the following questions in my mind:\n\n 1. Does the Genre correlate with the given Scoring?\n 2. Can we see a hype of specific genre over the past years?\n 3. Do the actors or writer prefer a genre? \n 4. Do the actors or writer have an impact on the imdb scoring?\n 5. Do the directors have prefered actors for their movies?\n 6. Do the directors have prefered writers for their movies?\n 7. How many movies have been produced by the directors?\n 8. Is there any relation between the director and the imdb rating?\n 9. .... many more questions :-)'","b""['data visualization', 'classification', 'regression analysis', 'time series analysis', 'medium', 'featured']""",https://www.kaggle.com/beyjin/movies-1990-to-2017
b'NOAA Global Historical Climatology Network Daily',b'From NOAA Updated Data',"b'* Update Frequency: Daily\n\nThis dataset is identical to Kaggle\'s [NOAA GHCN-D dataset](https://www.kaggle.com/noaa/ghcn-d) using BigQuery. The data for both datasets updates on the same basis (daily) but may not be updated on the same time. Data from this dataset can be downloaded/accessed through this dataset page and Kaggle\'s [API](https://github.com/Kaggle/kaggle-api).\n\n### Context\n\nGHCN (Global Historical Climatology Network)-Daily is an integrated database of daily climate summaries from land surface stations across the globe. Like its monthly counterpart (GHCN-Monthly) , GHCN-Daily is comprised of daily climate records from numerous sources that have been integrated and subjected to a common suite of quality assurance reviews.\n\nEvery day there are updates to GHCN-Daily station data from a variety of data streams, which also undergo a suite of quality checks. In addition the dataset is reconstructed each weekend from its 25-plus data source components to ensure that GHCN-Daily is generally in sync with its growing list of constituent sources. During this process, the system applies quality assurance checks to the full dataset.\n\n### Content\n\nGHCN-Daily contains records from over 100,000 stations in 180 countries and territories. NCEI provides numerous daily variables, including maximum and minimum temperature, total daily precipitation, snowfall, and snow depth; however, about one half of the stations report precipitation only. Both the record length and period of record vary by station and cover intervals ranging from less than a year to more than 175 years.\n\n\n### Acknowledgements\n\nDataset Source: NOAA.  This dataset is publicly available for anyone to use under the following terms provided by the Dataset Source \xe2\x80\x94 http://www.data.gov/privacy-policy#data_policy \xe2\x80\x94 and is provided ""AS IS"" without any warranty, express or implied, from Google. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset.\n\n[Cover photo](https://unsplash.com/photos/zAWs-hKChYA) by [Nicole Wilcox](https://unsplash.com/@nicolerwilcox) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['weather', 'climate', 'utility', 'large', 'featured']""",https://www.kaggle.com/noaa/noaa-global-historical-climatology-network-daily
b'BLE RSSI Dataset for Indoor localization',b'Bluetooth Low Energy iBeacon RSSI Dataset for Indoor localization and Navigation',"b'### Content\n\nThe dataset was created using the RSSI readings of an array of 13 ibeacons in the first floor of Waldo Library, Western Michigan University. Data was collected using iPhone 6S. The dataset contains two sub-datasets: a labeled dataset (1420 instances) and an unlabeled dataset (5191 instances). The recording was performed during the operational hours of the library. For the labeled dataset, the input data contains the location (label column), a timestamp, followed by RSSI readings of 13 iBeacons. RSSI measurements are negative values. Bigger RSSI values indicate closer proximity to a given iBeacon (e.g., RSSI of -65 represent a closer distance to a given iBeacon compared to RSSI of -85). For out-of-range iBeacons, the RSSI is indicated by -200. The locations related to RSSI readings are combined in one column consisting a letter for the column and a number for the row of the position. The following figure depicts the layout of the iBeacons as well as the arrange of locations. \n\n![iBeacons Layout](https://www.kaggle.com/mehdimka/ble-rssi-dataset/downloads/iBeacon_Layout.jpg)\n\n### Attribute Information\n\n - location: The location of receiving RSSIs from ibeacons b3001 to b3013; symbolic values showing the column and row of the location on the map (e.g., A01 stands for column A, row 1). \n - date: Datetime in the format of \xe2\x80\x98d-m-yyyy hh:mm:ss\xe2\x80\x99\n - b3001 - b3013: RSSI readings corresponding to the iBeacons; numeric, integers only.\n\n### Acknowledgements\nProvider:\nMehdi Mohammadi and Ala Al-Fuqaha, {mehdi.mohammadi, ala-alfuqaha}@wmich.edu,\nDepartment of Computer Science,\nWestern Michigan University\n\nCitation Request:\n\nM. Mohammadi, A. Al-Fuqaha, M. Guizani, J. Oh, \xe2\x80\x9cSemi-supervised Deep Reinforcement Learning in Support of IoT and Smart City Services,\xe2\x80\x9d IEEE Internet of Things Journal, Vol. PP, No. 99, 2017.\n\n### Inspiration\n\n#### How unlabeled data can help for an improved learning system. How a GAN model can synthesizes viable paths based on the little labeled data and larger set of unlabeled data.  '","b""['multiclass classification', 'universities and colleges', 'networks', 'navigation', 'small', 'featured']""",https://www.kaggle.com/mehdimka/ble-rssi-dataset
"b'NYS Retail Food Store Inspections, Current Ratings'",b'From New York State Open Data',"b""### Content  \n\nDataset includes most recent inspections of retail food stores.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/nHRXNv2qeDE) by [Bernard Hermant](https://unsplash.com/@bernardhermant) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""","https://www.kaggle.com/new-york-state/nys-retail-food-store-inspections,-current-ratings"
b'Predicting a Pulsar Star',b' Pulsar candidates collected during the High Time Resolution Universe Survey',"b""# PREDICTING A PULSAR STAR\n\n\nHTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey . \n\nPulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter . \n\nAs pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsars \nrotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes. \n\nEach pulsar produces a slightly different emission pattern, which varies slightly with each rotation . Thus a potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find. \n\nMachine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted, \nwhich treat the candidate data sets as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class.\n\nThe data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators. \n\nEach row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive). \n\n# Attribute Information:\nEach candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency . The remaining four variables are similarly obtained from the DM-SNR curve . These are summarised below: \n\n1. Mean of the integrated profile. \n2. Standard deviation of the integrated profile. \n3. Excess kurtosis of the integrated profile. \n4. Skewness of the integrated profile. \n5. Mean of the DM-SNR curve. \n6. Standard deviation of the DM-SNR curve. \n7. Excess kurtosis of the DM-SNR curve. \n8. Skewness of the DM-SNR curve. \n9. Class \n\nHTRU 2 Summary \n17,898 total examples. \n1,639 positive examples. \n16,259 negative examples.\n\n""","b""['data visualization', 'classification', 'model comparison', 'astronomy', 'small', 'featured']""",https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star
b'NYS 511 NY Events',b'From New York State Open Data',"b""### Content  \n\nThe 511NY dataset contain historical traffic and transit event information provided by the New York State Department of Transportation (NYSDOT), the New York City Department of Transportation, the New York State Thruway Authority and the Niagara International Transportation Technology Coalition (Buffalo-Niagara Region). The file includes all incidents/accidents, construction projects and special events in New York State that were available on the 511NY traffic and transit map for the time period noted.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/a4LLbMYUjE4) by [Borna Bevanda](https://unsplash.com/@bbevanda) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'construction', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-511-ny-events
b'Amazon sales rank data for print and kindle books',"b'61,000 unique ASINs and 200,000,000 salesrank data points (JSON / CSV)'","b""### License\n**CC-BY-NC-SA** Credit to [NovelRank.com][1] for compiling the data and Amazon.com as the data source.\n\n### Context\n\nI've been collecting salesrank for authors publishing through Amazon worldwide for almost a decade via the site NovelRank.com. The data is collected as frequently as hourly and as infrequently as once every 24 hours. Over a single year this represents GBs of data. I think this would be a great time to let the Kaggle community play with it.\n\n\n### Content\n\nThe earliest data is from Jan 1, 2017. The latest data is from June 29, 2018. \nWithin the 61,000+ unique books, there is roughly a 50/50 split between **Kindle Editions** and **Print Editions**. This is critically important because **Amazon sales rankings are grouped under the *Books* umbrella into those two categories**. Thus you can have two books in the data set have the same sales rank at the same time if one is in the *kindle* group and the other is in the *book* group.\n\nWithin the data set there is a small subset of books that have more consistent sales rank collection, specifically they have **hourly salesrank collection**. *(Future Goal: offer a .zip file of only these ASINs). These titles are tracked by NovelRank Pro users which has the benefit of no throttling to their tracking. Books that don't sell for a while will have tracking throttled to as low as once every 24 hours until a drop in sales rank is detected, thus the variability in most of the data collection timestamps.\n\nFinally, **when salesrank has not changed, NovelRank does not record it**. In other words, taking the books that have hourly checks mentioned above, if salesrank has not changed, then there would be a gap, possibly 2 hours between the data points or more due to this housekeeping detail. *This is true for books that maintain a very good ranking (where it is harder for the book to manage but more likely to occur) as well as for books with a very low ranking.* \n\n**Sales rank is updated on an hourly basis (at best) by Amazon.**\n\n### Inspiration\n\nFor years I've used salesrank changes to estimate # of sales for authors, which due to inherent flaws in ranking data as a primary source has been better for low volume sellers than high volume sellers. This is aggravated by unreliable data collection to match actual sales to sales rank changes to improve things. \n\nSome of the flaws:\n\n- Purchasing multiple copies of a title in a single order will count as 1 sale in terms of sales rank improvement.\n- Sales rank changes due to sales can lag between 3 and 12 hours from the actual sale.\n- Sales rankings are unique to the total number of items in the group on that domain and since this is constantly in flux, no singular formula represents a good estimation. Kindle Edition books on Amazon.com will have a much wider range and much greater level of changes than Print Edition books on Amazon.it (Italy) due to group size.\n\n\n  [1]: https://www.novelrank.com/""","b""['internet', 'time series', 'time series analysis', 'ranking', 'large', 'featured']""",https://www.kaggle.com/ucffool/amazon-sales-rank-data-for-print-and-kindle-books
b'Edible wild plants',b'Learn your trail food',"b""### Context\n\nThe dataset contains pictures of edible wild plants, The purpose of this dataset is to support supervised learning models.\n\n\n### Content\n\nThe dataset contains images of 62 wild edible plants, gathered off the internet.  The photos are under the size of 300K\n\n\n### Acknowledgements\n\nThe dataset is collected from the internet. Pictures of 3 of the plants are taken from Alexander Mamaev's dataset:\nhttps://www.kaggle.com/alxmamaev/flowers-recognition/home\n\n### Inspiration\n\nMany a time on my long trail runs I have run\xe2\x80\x8b short on food and struggled to finish the distance, low on energy. Also, I have always appreciated my mother for knowing so well all the wild plants and fruit, but I never managed to learn them myself \xe2\x80\x93 they all look the same to me!\nSo when I ran into an internet article depicting some wild edible plants, I know I found my project \xe2\x80\x93 image recognition \xe2\x80\x93 later making also a mobile app for it, that would recognize which of the plants I encounter on my runs are good to eat, and also offer information on which parts of the plant are edible, and which are not, or maybe even dangerous if ingested.""","b""['classification', 'multiclass classification', 'plants', 'medium', 'featured']""",https://www.kaggle.com/gverzea/edible-wild-plants
b'NY 2015 Street Tree Census - Tree Data',b'From New York City Open Data',"b""### Content  \n\nStreet tree data from the TreesCount! 2015 Street Tree Census, conducted by volunteers and staff organized by NYC Parks & Recreation and partner organizations. Tree data collected includes tree species, diameter and perception of health. Accompanying blockface data is available indicating status of data collection and data release citywide.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ygi0RcsuR6U) by [Stephen Arnold](https://unsplash.com/@iamarnold) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/ny-2015-street-tree-census-tree-data
b'Oakland Street Trees',b'Explore open data from the city of Oakland',"b""  \n\n### Context  \n\nThis is a dataset hosted by the city of Oakland in California. The organization has an open data platform found [here](data.oaklandnet.com) and they update their information according to the amount of data that is brought in. Explore Oakland's Data using Kaggle and all of the data sources available through the city of Oakland [organization page](https://www.kaggle.com/cityofoakland)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/dhvtr5fwbHI) by [Chris Barbalis](https://unsplash.com/@cbarbalis) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofoakland/oakland-street-trees
b'Chicago Red Light and Speed Camera Data',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-red-light-and-speed-camera-data
b'50000 job board records from Reed UK',b'Jobs posted in the last 15 days on Reed UK job board',"b'### Context\n\nReed is one of the top employment agency based in the United Kingdom. This data set contains 50000 records of latest job postings on Reed UK.\n\n### Content\n\nThis data was extracted on 13th March and contains job postings from last 15 days. Data fields in the dataset include category, city, state, company name, job title, job description, job requirement, job type, salary offered, and posting date.\n\n### Acknowledgements\n\nThis data was extracted using [JobsPikr][1].\n\n### Inspiration\n\nThe uses of this dataset are endless. Some of the inspirations could be:\n\n - Top paying companies\n - Highest number of job posting by a particular company\n - State/City with highest job openings\n - Salary distribution by state\n - Ratio of different job types\n\n  [1]: https://jobspikr.com/?utm_source=rb-kaggle&utm_medium=referral&utm_campaign=job-board-dataset'","b""['internet', 'medium', 'featured']""",https://www.kaggle.com/jobspikr/50000-job-board-record-from-reed-uk
b'Jobs on Naukri.com',"b'22,000 job listings on Naukri.com'","b""###Context\n\nThis is a pre-crawled dataset, taken as subset of a bigger [dataset (more than 9.4 million job listings)][1] that was created by extracting data from Naukri.com, a leading job board.\n\n### Content\n\nThis dataset has following fields:\n\n- company\n- education\n- experience\n- industry\n- job description\n- jobid\n- joblocation_address\n- job title\n- number of positions\n- pay rate\n- postdate\n- site_name\n- skills\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud's in-house web-crawling service.\n\n### Inspiration\nAnalyses of the pay rate, job title, industry and experience can be performed to name a few starting points.\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=na-kaggle&utm_medium=referral""","b""['medium', 'featured']""",https://www.kaggle.com/PromptCloudHQ/jobs-on-naukricom
b'U.S. Educational Finances',"b'Revenues and expenditures for U.S. grade schools, by year and state'","b'### Context\n\nThe United States Census Bureau conducts annual surveys to assess the finances of elementary and high schools. This data has been programmatically organized here in two files; one for school districts (districts.csv) and one for states (states.csv). \n\nAlso included is a summary of data from the NAEP (National Assessment of Educational Progress), contained in naep.csv. \n\n### Content\n\n**districts.csv** A comma-separated spreadsheet containing revenues and expenditures for all U.S. school districts, 1992-2016. \n\n<pre>STATE,ENROLL,NAME,YRDATA,TOTALREV,TFEDREV,TSTREV,TLOCREV,TOTALEXP,TCURINST,TCURSSVC,TCURONON,TCAPOUT\nAlabama,9609,AUTAUGA COUNTY SCHOOL DISTRICT,2016,80867,7447,53842,19578,76672,43843,23941,6401,1506\nAlabama,30931,BALDWIN COUNTY SCHOOL DISTRICT,2016,338236,23710,145180,169346,299880,164977,97231,19439,9749\nAlabama,912,BARBOUR COUNTY SCHOOL DISTRICT,2016,10116,2342,5434,2340,10070,4907,3896,975,110\n</pre>\n\n**states.csv** A comma-separated spreadsheet containing state summaries of revenues and expenditures, organized by year.\n\n<pre>STATE,YEAR,ENROLL,TOTAL_REVENUE,FEDERAL_REVENUE,STATE_REVENUE,LOCAL_REVENUE,TOTAL_EXPENDITURE,INSTRUCTION_EXPENDITURE,SUPPORT_SERVICES_EXPENDITURE,OTHER_EXPENDITURE,CAPITAL_OUTLAY_EXPENDITURE\nAlabama,1992,,2678885,304177,1659028,715680,2653798,1481703,735036,,174053\nAlaska,1992,,1049591,106780,720711,222100,972488,498362,350902,,37451\nArizona,1992,,3258079,297888,1369815,1590376,3401580,1435908,1007732,,609114\n</pre>\n\n**naep.csv** A comma-seperated spreadsheet containing state performance on mathematics and reading tests, for 4th and 8th grade on a selection of years.\n\n<pre>YEAR,STATE,AVG_SCORE,TEST_SUBJECT,TEST_YEAR\n2017,Alabama,232.170687741509,Mathematics,4\n2017,Alaska,230.456277558902,Mathematics,4\n2017,Arizona,234.435788152091,Mathematics,4\n</pre>\n\n**Be warned, some data will be NaN\'s** (most notably, the 1992 records contain no data for enrollment). \n\nData was created from the spreadsheets in elsec.zip (taken from the U.S. Census Bureau site) using chew_data.py and state_summary.py. Column names are documented in school15doc.pdf.\n\n### Sources\n\n    https://www.census.gov/programs-surveys/school-finances/data/tables.html\n\n    https://www.nationsreportcard.gov/ndecore/landing\n\n### Changelog\n\n[v 0.2] Added data from 1993-2001. Data is now harvested from the main spreadsheets instead of the summary spreadsheets. Data by school district is now available.\n\n[v 0.3] Added 1992 data. Added enrollment data for all years except 1992 (unavailable).\n\n[v 0.4] Straightening a few things out as I play with the data in my own kernel. Changed ""program_other_expenditure"" to ""other_expenditure"" and fixed chew_data.py to properly pull that information. Removed ""non-elsec"" funding and ""program_current_expenditure"" columns.\n\n[v 0.5] Added 2016 data. My limited testing says that it worked, but I should probably keep an eye out for possible issues.\n\n[v 0.6] Major code refactoring. Changed filenames to be a little more intuitive. Added a main function. Added NAEP data.'","b""['finance', 'education', 'united states', 'medium', 'featured']""",https://www.kaggle.com/noriuk/us-educational-finances
b'Skin Cancer MNIST: HAM10000',b'a large collection of multi-source dermatoscopic images of pigmented lesions',"b'# Overview\nAnother more interesting than digit classification dataset to use to get biology and medicine students more excited about machine learning and image processing. \n\n\n## Original Data  Source\n\n- https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T\n- Tschandl, P., Rosendahl, C. & Kittler, H. The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Sci. Data 5, 180161 (2018). doi: 10.1038/sdata.2018.161\n\n## From Authors\n\nTraining of neural networks for automated diagnosis of pigmented skin lesions is hampered by the small size and lack of diversity of available dataset of dermatoscopic images. We tackle this problem by releasing the HAM10000 (""Human Against Machine with 10000 training images"") dataset. We collected dermatoscopic images from different populations, acquired and stored by different modalities. The final dataset consists of 10015 dermatoscopic images which can serve as a training set for academic machine learning purposes. Cases include a representative collection of all important diagnostic categories in the realm of pigmented lesions: Actinic keratoses and intraepithelial carcinoma / Bowen\'s disease (akiec), basal cell carcinoma (bcc), benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, bkl), dermatofibroma (df), melanoma (mel), melanocytic nevi (nv) and vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc).\n\nMore than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file.'","b""['image data', 'multiclass classification', 'oncology and cancer', 'skin care', 'large', 'featured']""",https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000
b'Air quality data from extensive network of sensors',"b'PM1, PM2.5, PM10, temp, pres and hum data for 2017 year from Krakow, Poland'","b""**Context**\n\nIn the past, the ancient city of Krakow was known as the capital of Poland. In 2000, it became known as the official European Capital of Culture. Now, it is known for having some of the most polluted air in Europe... In a World Health Organiation (WHO) study Krakow has been rated amongst the most polluted in the world. In the report, city was ranked 8th among 575 cities for levels of PM2.5 and 145th among 1100 cities for levels of PM10. Hazardous air quality is a common problem particularly during the colder months when many residents use solid fuels (mostly coal) for household heating. Air pollution in Krakow poses a significant danger to human health and life. Krakow's poisoned air includes amongst other things: particulate matter, benzo(a)pyrene and nitrogen dioxide.\nThe state-run network of monitoring stations consists of 8 monitoring stations in Krakow. We decided to go step further - to build network of low-cost air quality sensors that can be deployed across entire city. The first step in the fight against smog is to identify areas of problem and to raise awareness among residents and the authorities. It is very important to create a network of sensors \xe2\x80\x93 only then you can check the actual conditions in various areas of the city. The technology enables real-time monitoring of air quality via [map.airly.eu][1], so the information about the air in a specific location is easily accessible and always up to date.\n\n\n**Content**\n\nThis dataset consists air quality data (the concentrations of particulate matter PM1, PM2.5 and PM10, temperature, air pressure and humidity) from 2017 generated by network of 56 low-cost sensors located in Krakow, Poland.\nEach had its own location (6 of them where replaced during this time period and have almost the same latitude and longitude).\nMeasurements are grouped in 12 files, one for each month. Resolution of data is 1 hour.\n\nKnown issues:\n- PM1 is not calibrated and therefore can be bigger than PM2.5\n- PM2.5 can be bigger than PM10 within the limits of measurement error\n- for the first two months humidity and temperature were not calibrated and therefore can show inaccurate values\n\n\n**Acknowledgements**\n\nThe data was generated by Airly network - the project is still in its beginning stage, but over 1000 sensors have already been implemented in Poland. Airly is a startup definitely worth watching, especially for citizens of the most polluted cities. After all, it\xe2\x80\x99s clean air we all want to breathe.\n\n\n**Inspiration**\n\nI think that this dataset offers some great opportunities for predictive models and data visualization. Airly's goal is to develop an effective forecast and monitoring of air quality, employ Artificial Intelligence and utilise data from extensive sensor network. If anyone has any ideas, breakthroughs or other interesting models please post them.\n\nSome questions worth exploring:\n- What are the best prediction models based on extensive sensor network - statistical or numerical forecast?\n- How weather affects air quality?\n- How much pollution comes from cars, factories and coal-fired power plants?\n\n\n  [1]: http://map.airly.eu""","b""['health', 'environment', 'pollution', 'atmospheric sciences', 'small', 'featured']""",https://www.kaggle.com/datascienceairly/air-quality-data-from-extensive-network-of-sensors
b'Tennis Match Charting Project',"b""Point-level tennis match data from Jeff Sackman's Match Charting Project""","b'These data are from the Match Charting Project by Jeff Sackman, available on [Github][1]. This is by far the most detailed publicly available tennis dataset, containing point-level match information. The data can be used to predict not just match outcomes, but also point-level outcomes. Each point-level observations includes information on the type of serve, and the following rally (see `MatchChart 0.2.0.xlsx` to decipher)\n\nThere are many interesting possibilities to explore. For example, can we predict how best to win each point? Can the type of serve be predicted based on the outcomes of the previous serves? What does this tell us about tennis strategy? Perhaps it can even tell us something about human nature, such as people\'s tendency to be overconfident, clutch, or loss averse.\n\nThe main point level files are the `charting-m-points.csv` (men\'s matches) and `charting-w-points.csv`(women\'s matches) files. All the others, such as the match level files, can be merged onto the point-level files. For detailed data information, see the file `MatchChart 0.2.0.xlsx`. The only change I made to the original data was to convert the `.xlsx` file from `.xlsm`\n\nBelow is the README explanation provided by Jeff Sackman on Github.\n\n# The Match Charting Project\n\nThe goal of the Match Charting Project (MCP) is to amass detailed records of professional matches. Organizations such as the ATP, WTA, ITF, and Grand Slam tournaments record some data, but not in a consistent way, and rarely make any of it available to the public.\n\nMCP match records contain shot-by-shot data for every point of a match, including the type of shot, direction of shot, depth of returns, types of errors, and more. There is no publicly-available data like this anywhere else. To get an idea of the possibilities, aggregate match-level data is available for every submitted match at my website[1].\n\nI started this project in late 2013[2], and since then, dozens of contributors[3] have recorded over 1,400 matches. This repo contains both the raw point-by-point data from these matches and extensive match-level aggregate totals.\n\nFiles are separated into men\'s (\'-m-\') and women\'s (\'-w-\') matches. The \'-matches\' files contain metadata for each match, including the player names, tournament, date, surface, and more. The \'-points\' files contain extensive data on each point.\n\nThe user-submitted data is found only in the \'1st\', \'2nd\', and \'Notes\' columns of the points files. All of the other columns are automatically generated by the excel doc[4] used by project contributors. While some of the columns are a bit redundant, many of the others make it easier to analyze the data.\n\n**If you have any interest in working with the raw, shot-by-shot data, I strongly encourage you to contribute to the project by charting a match (or twenty) yourself. Not only is it a nice way to give back to the project and help it grow, it is also the best way to learn exactly what you can find in the data.**\n\nHere\'s a guide to help you get started charting your first match:\nhttp://www.tennisabstract.com/blog/2015/09/23/the-match-charting-project-quick-start-guide/ \n\nWhether you intend to start by charting matches or by jumping straight into the raw data, you\'ll want to take a look at the \'Instructions\' tab of the MatchChart excel doc, which goes into detail regarding the charting notation.\n\nI\'ve now also added several \'-stats-\' files for both men and women. These contain the aggregate stat lines displayed in each match report. Again, many of the row names will be easier to understand if you\'ve charted a match or two. The rows and columns track very closely to what are shown in the match reports (e.g. http://tennisabstract.com/charting/20150321-M-Irving_CH-SF-Gilles_Muller-Tim_Smyczek.html ). The only difference is that almost all of the data in the \'-stats-\' files are integer totals, while the match reports display most as percentages.\n\nNew matches are submitted several times per week. As the project continues to grow, I will update these files periodically, approximately once per 100 additional matches. Follow me on Twitter[5] for updates on new matches and other improvements to the database.\n\n# License\n\n<a href=""http://creativecommons.org/licenses/by-nc-sa/4.0/""><img alt=""Creative Commons License"" style=""border-width: 0"" src=""https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png""></a><br> by <a href=""http://www.tennisabstract.com/charting/meta.html"">The Tennis Abstract Match Charting Project</a> is licensed under a <a href=""http://creativecommons.org/licenses/by-nc-sa/4.0/"">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.<br>Based on a work at <a href=""https://github.com/JeffSackmann/tennis_MatchChartingProject"">https://github.com/JeffSackmann/tennis_MatchChartingProject</a>\n\nIn other words: Attribution is required. Non-commercial use only.\n\n\n  [1]: https://raw.githubusercontent.com/JeffSackmann/tennis_MatchChartingProject/'","b""['sports', 'tennis', 'medium', 'featured']""",https://www.kaggle.com/ryanthomasallen/tennis-match-charting-project
b'Financial Intermediary Funds Funding Decisions',b'From World Bank Financial Open Data',"b""### Content  \n\nFinancial Intermediary Funds (FIFs) are multilateral financing arrangements for which the World Bank provides Trustee services that include committing and transferring funds to project implementers (generally international organizations such as multilateral development banks or UN agencies). In all cases the World Bank as Trustee is required to act in accordance with instructions of independent governing bodies.\r\n\r\nIn fulfilling its responsibilities, the World Bank as Trustee complies with all sanctions applicable to World Bank transactions.\r\n\r\nFunding Decisions represent amounts approved by the FIFs governing bodies for projects fees and administrative budgets. Funding to projects can be done through various financial products, including grants and concessional loans.\r\n\r\nNo further updates are planned for this particular dataset.  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](finances.worldbank.org) and they update their information according the amount of data that is brought in. Explore World Bank's Financial Data using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.\n\nThis dataset is distributed under a [Creative Commons Attribution 3.0 IGO](https://creativecommons.org/licenses/by/3.0/igo/) license.  \n\n[Cover photo](https://unsplash.com/photos/JQGmVcIiHys) by [Zachary Young](https://unsplash.com/@mrtwisty) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under Creative Commons Attribution 3.0 IGO""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/theworldbank/financial-intermediary-funds-funding-decisions
b'NYC Department of Consumer Affairs Issued Charges',b'From New York City Open Data',"b""### Content  \n\nThis data set features DCA-issued charges during the last and current calendar years to ensure compliance with local consumer protection and licensing laws, and State and federal regulations.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Se7E4BUeVrs) by [Sabri Tuzcu](https://unsplash.com/@sabrituzcu) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'business', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-department-of-consumer-affairs-issued-charges
b'International Financial Statistics',b'Global indicators from 1960-2010',"b'International Financial Statistics (IFS) is a standard source of international statistics on all aspects of international and domestic finance. It reports, for most countries of the world, current data needed in the analysis of problems of international payments and of inflation and deflation, i.e., data on exchange rates, international liquidity, international banking, money and banking, interest rates, prices, production, international transactions, government accounts, and national accounts.\nLast update in UNdata: 14 May 2010\nIf you need more current data, the IMF has made their current database available for [bulk download for personal use](http://data.imf.org/?sk=388DFA60-1D26-4ADE-B505-A05A558D9A42).\n\n### Acknowledgements\n\nThis dataset was kindly published by the United Nations on the UNData site. You can find [the original dataset here](http://data.un.org/Explorer.aspx).\n\n### License\n[Per the UNData terms of use](http://data.un.org/Host.aspx?Content=UNdataUse): all data and metadata provided on UNdata\xe2\x80\x99s website are available free of charge and may be copied freely, duplicated and further distributed provided that [UNdata](http://data.un.org/Explorer.aspx) is cited as the reference. '","b""['economics', 'small', 'featured']""",https://www.kaggle.com/unitednations/international-financial-statistics
b'ResNet-50',b'ResNet-50 Pre-trained Model for Keras',"b'# ResNet-50\n\n---\n\n## Deep Residual Learning for Image Recognition\nDeeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. \n\nAn ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. \n\nThe depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.<br>\n\n**Authors: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun**<br>\n**https://arxiv.org/abs/1512.03385**\n\n---\n\n\nArchitecture visualization: http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006\n\n![Resnet][1]\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/nyYh5xH.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/keras/resnet50
b'New York Times Best Sellers',b'Hardcover Fiction Best Sellers from 2008 to 2018',"b'### Source\n\nGathered from the New York Times API for Hardcover Fiction best sellers from June 7, 2008 to July 22, 2018\n\nThe API can be found here: [https://developer.nytimes.com/][1]\n\nCollected data includes the book title, author, the date of the best seller list, the published date of the list, the book description, the rank (this week and last week), the publisher, number of weeks on the list, and the price.\n\n  [1]: https://developer.nytimes.com/'","b""['books', 'small', 'featured']""",https://www.kaggle.com/cmenca/new-york-times-hardcover-fiction-best-sellers
b'NY Rodent Inspection',b'From New York City Open Data',"b""### Content  \n\nDataset contains information on rat inspections.\r\n\r\nRat Information Portal Data Release Notes        April 20, 2015\r\n\r\nThe Rat Information Portal (RIP) is a web-based mapping application where users can view rat inspection data. \r\n\r\nData sources: NYC Department of Health and Mental Hygiene (DOHMH), Division of Environmental Health Pest Control Database\r\n\r\nNotes on data limitations: Please note that if a property/taxlot does not appear in the file, that does not indicate an absence of rats - rather just that it has not been inspected. Similarly, neighborhoods with higher rates of active rat signs may not actually have higher rat populations but simply have more inspections. \r\n\r\nSee our Data Disclaimer:\r\nhttp://www.nyc.gov/html/doh/html/environmental/disclaimer.shtml  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/VEfYYt52aq0) by [Gene Bakner](https://unsplash.com/@huntinghunter) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'health', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/ny-rodent-inspection
b'NY Philharmonic Performance History',"b'All Performances, 1842-Present'","b""### Context: \nThe New York Philharmonic played its first concert on December 7, 1842. Since then, it has merged with the New York Symphony, the New/National Symphony, and had a long-running summer season at New York's Lewisohn Stadium. The [Performance History database](http://archives.nyphil.org/performancehistory) documents all known concerts of all of these organizations, amounting to more than 20,000 performances.\n\n### Content: \nDataset is a single csv with over 800k rows. Data contains information on season, orchestra, venue, date, time, conductor, work title, composer, movement, and soloists.\n\n### Acknowledgements: \nThis dataset was compiled by the [New York Philharmonic](http://archives.nyphil.org/performancehistory/#program). Original json files hosted [here](https://github.com/nyphilarchive). Original json files were flattened and joined on guid to form a single csv file. Image courtesy of [Larisa Birta](https://unsplash.com/@larisabirta).\n\n### Inspiration: \nNearly 175 years of performance history, covering over 11k unique works--which composers are most popular? Have there been any trends in popularity by conductor or by season?""","b""['music', 'musicians', 'composers', 'medium', 'featured']""",https://www.kaggle.com/nyphil/perf-history
b'Korean Single Speaker Speech Dataset',b'KSS Dataset: Korean Single Speaker Speech Dataset',"b""# KSS Dataset: Korean Single speaker Speech Dataset\n\nKSS Dataset is designed for the Korean text-to-speech task. It consists of audio files recorded by a professional female voice actoress and their aligned text extracted from my books. As a copyright holder, by courtesy of the publishers, I release this dataset to the public. To my best knowledge,  this is the first publicly available speech dataset for Korean.\n\n## File Format\nEach line in `transcript.v.1.1.txt` is delimited by | into five fields.\n\n|No.|Field|Example|\n\n* |1|Audio File Location|1/1_0000.wav|\n* |2|Original Script|\xea\xb7\xb8\xeb\x8a\x94 \xea\xb4\x9c\xec\xb0\xae\xec\x9d\x80 \xec\xb2\x99\xed\x95\x98\xeb\xa0\xa4\xea\xb3\xa0 \xec\x95\xa0\xec\x93\xb0\xeb\x8a\x94 \xea\xb2\x83 \xea\xb0\x99\xec\x95\x98\xeb\x8b\xa4.|\n* |3|Expanded Script|\xea\xb7\xb8\xeb\x8a\x94 \xea\xb4\x9c\xec\xb0\xae\xec\x9d\x80 \xec\xb2\x99\xed\x95\x98\xeb\xa0\xa4\xea\xb3\xa0 \xec\x95\xa0\xec\x93\xb0\xeb\x8a\x94 \xea\xb2\x83 \xea\xb0\x99\xec\x95\x98\xeb\x8b\xa4.|\n* |4|Decomposed Script|\xe1\x84\x80\xe1\x85\xb3\xe1\x84\x82\xe1\x85\xb3\xe1\x86\xab \xe1\x84\x80\xe1\x85\xab\xe1\x86\xab\xe1\x84\x8e\xe1\x85\xa1\xe1\x86\xad\xe1\x84\x8b\xe1\x85\xb3\xe1\x86\xab \xe1\x84\x8e\xe1\x85\xa5\xe1\x86\xa8\xe1\x84\x92\xe1\x85\xa1\xe1\x84\x85\xe1\x85\xa7\xe1\x84\x80\xe1\x85\xa9 \xe1\x84\x8b\xe1\x85\xa2\xe1\x84\x8a\xe1\x85\xb3\xe1\x84\x82\xe1\x85\xb3\xe1\x86\xab \xe1\x84\x80\xe1\x85\xa5\xe1\x86\xba \xe1\x84\x80\xe1\x85\xa1\xe1\x87\x80\xe1\x84\x8b\xe1\x85\xa1\xe1\x86\xbb\xe1\x84\x83\xe1\x85\xa1.|\n* |5|Duration|3.5|\n\n## Specification\n* Audio File Type: wav\n* Total Running Time: 12+ hours\n* Sample Rate: 44,100 KHZ\n* Number of Audio Files: 12,853\n* Sources\n  * |1|  [Kyubyong Park, 500 Basic Korean Verbs, Tuttle Publishing, 2015.](https://www.amazon.com/500-Basic-Korean-Verbs-Comprehensive/dp/0804846057/ref=sr_1_1?s=books&ie=UTF8&qid=1522911616&sr=1-1&keywords=kyubyong+park)|\n  * |2|\t[Kyubyong Park, 500 Basic Korean Adjectives 2nd Ed., Youkrak, 2015.](http://www.hanbooks.com/500bakoad.html)|\n  * |3|\t[Kyubyong Park, Essential Korean Vocabulary, Tuttle Publishing, 2015.](https://www.amazon.com/Essential-Korean-Vocabulary-Phrases-Fluently/dp/0804843252/ref=sr_1_3?s=books&ie=UTF8&qid=1522911806&sr=1-3&keywords=kyubyong+park)|\n  * |4|\t[Kyubyong Park, Tuttle Learner's Korean-English Dictionary, Tuttle Publishing, 2012.](https://www.amazon.com/Tuttle-Learners-Korean-English-Dictionary-Essential/dp/0804841500/ref=sr_1_8?s=books&ie=UTF8&qid=1522911806&sr=1-8&keywords=kyubyong+park)|\n\n## License\nNC-SA 4.0. You CANNOT use this dataset for ANY COMMERCIAL purpose. Otherwise, you can freely use this.\n\n## Citation\n\nIf you want to cite KSS Dataset, please refer to this:\n\nKyubyong Park, KSS Dataset: Korean Single speaker Speech Dataset, https://kaggle.com/bryanpark/korean-single-speaker-speech-dataset, 2018\n\n## Reference\n\nCheck out [this](https://github.com/Kyubyong/kss) for a project using this KSS Dataset.\n\n## Contact\n\nYou can contact me at kbpark.linguist@gmail.com.\n\nApril, 2018.\n\nKyubyong Park""","b""['languages', 'large', 'featured']""",https://www.kaggle.com/bryanpark/korean-single-speaker-speech-dataset
b'Oakland Shotspotter Data 1/13 to 10/15',b'Explore open data from the city of Oakland',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of Oakland in California. The organization has an open data platform found [here](data.oaklandnet.com) and they update their information according to the amount of data that is brought in. Explore Oakland's Data using Kaggle and all of the data sources available through the city of Oakland [organization page](https://www.kaggle.com/cityofoakland)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License""","b""['socrata', 'utility', 'small', 'featured']""",https://www.kaggle.com/cityofoakland/oakland-shotspotter-data-1-13-to-10-15
"b""Brewer's Friend Beer Recipes""","b'Data on over 75,000 homemade beers'","b'## Context\n\nThis is a dataset of  75,000 homebrewed beers with over 176 different styles. Beer records are user-reported and are classified according to one of the 176 different styles.  These recipes go into as much or as little detail as the user provided, but there\'s are least 5 useful columns where data was entered for each: Original Gravity, Final Gravity, ABV, IBU, and Color\n\n## Content\n\n**recipes.csv** - Basic data for overuser-submitted beer recipes scraped from Brewer\'s Friend. All columns standardized except ""Priming Method"" and ""Priming Amount"", which seems like it just let the users write whatever they wanted\n\n## Acknowledgements\n\nThe site [Brewer\'s Friend][1] allows users to share their recipes for homebrew beer. This dataset contains a selection of the recipes uploaded thus far.\n\n## Inspiration\nWhat goes into homemade beer?<br>\nIt would be interesting to see if the data provided is enough to define each class or if there are undiscovered patterns. In the future it might be possible to go through and scrape more detailed information for each recipe, such as the yeast and specific hops used.\n  [1]: https://www.brewersfriend.com/search/'","b""['food and drink', 'alcohol', 'chemistry', 'small', 'featured']""",https://www.kaggle.com/jtrofe/beer-recipes
b'Japan Hostel Dataset',b'Data for 300+ Hostels in Japan by HostelWorld',"b""### Context\n\nThis data contains information of over 300 hostels in Japan. Whole scraping scripts are on [my Github page.][1]\n\n### Content\n\nWhat's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.\n\n\n### Acknowledgements\n\nThis data was scraped from [HostelWorld.com][2].\n\nTheir srvice is for young and independent travellers seeking a social travel experience. The gourp focuses on hostels, maintains a leding hostel database with over 16,000 hostels and approximately 20,000 other forms of budget accommodation available globally unlike the other travel agents.\nSince 2005, it has also been managing customer-generated review database consisting of more than 10 million post-stay reviews. \n\n# Stakeholder\n\nUpcoming foreign visitors. It is expected that the number of foreign tourists coming to Japan will be increasing till 2020 when Olympic will be held in Tokyo. So, considering another method of staying in Japan apart from Hotels would benefit to all the tourists who are planning to visit Japan in near future.\n\n\n### Inspiration\n\nAnalyze dataset about hostels in Japan. \n\n\n  [1]: https://github.com/koki25ando/Hostel-Data-Scraping/blob/master/hostel.R\n  [2]: https://www.hostelworld.com/""","b""['hotels', 'asia', 'small', 'featured']""",https://www.kaggle.com/koki25ando/hostel-world-dataset
b'Brazil Companies Corporate Framework',b'Receita Federal - CNPJ - Quadros Societ\xc3\xa1rios e de Administradores',"b""### Context\n\nDataSum, a Brazilian startup focused on Open Data usage, collects and makes available data sets that need transformation and standardization, in order to facilitate its analysis by society and organizations. \n\n### Content\n\nThis data set contains the list of all Brazil's companies headquarters and their corporate framework. \n\nData Preparation:\n\n - Changed the organization of the data set from hierarchical to tabular;\n - Originally separated by State it's now in one (big) file;\n - Included a new field to inform the State;\n - Included new fields for the description of codes and indicators; \n\n### Source:\n\n[Dados Abertos do CNPJ][1] - Last update: 2017-12-15\n\n### Acknowledgements\n\nBrazil Government / \nMinist\xc3\xa9rio da Fazenda / \nReceita Federal\n\n----------\n\n### Contexto \n\nA DataSum, startup brasileira focada no uso de dados abertos (Open Data), coleta e disponibiliza conjuntos de dados que necessitam de tratamento e padroniza\xc3\xa7\xc3\xa3o, com o objetivo de facilitar sua an\xc3\xa1lise pela sociedade e organiza\xc3\xa7\xc3\xb5es.\n\n### Conte\xc3\xbado\n\nEste conjunto de dados cont\xc3\xa9m a lista de todas as sedes de empresas Brasileiras e seu quadro societ\xc3\xa1rio.\n\nPrepara\xc3\xa7\xc3\xa3o dos dados:\n\n - Altera\xc3\xa7\xc3\xa3o da organiza\xc3\xa7\xc3\xa3o do conjunto de dados de hier\xc3\xa1rquico para tabular;\n - Originalmente separado por Estado, agora em um \xc3\xbanico (grande) arquivo;\n - Inclu\xc3\xaddo um novo campo para informar o Estado;\n - Inclu\xc3\xaddos novos campos para descrever c\xc3\xb3digos e indicadores; \n\n### Fonte dos Dados:\n\n[Dados Abertos do CNPJ][1] - Atualizado em: 2017-12-15\n\n### Agradecimentos\n\nGoverno do Brasil / \nMinist\xc3\xa9rio da Fazenda / \nReceita Federal\n\n  [1]: http://idg.receita.fazenda.gov.br/orientacao/tributaria/cadastros/cadastro-nacional-de-pessoas-juridicas-cnpj/dados-abertos-do-cnpj""","b""['government', 'brazil', 'companies', 'medium', 'featured']""",https://www.kaggle.com/datasum-analytics/cnpj-qsa
b'Chicago COPA Cases',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/WEcl8_kqwpg) by [Felix Koutchinski](https://unsplash.com/@koutchinski) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-copa-cases
b'Seattle Land Use Permits',b'From City of Seattle Open Data',"b'### Content  \n\nThis data is read only as of April 26, 2018 as we transfer to a new database system. View the current <a href=""https://data.seattle.gov/Permitting/Land-Use-Permits/ht3q-kdvx"">Land Use Permit</a> dataset.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/WBu97LnmG2o) by [Dane Deaner](https://unsplash.com/@danedeaner) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-land-use-permits
b'257K Gaia DR2 Stars',"b'NH + SH w/ photometry from GSC 2.3, Tycho2, PPMXL, 2MASS and AllWISE'","b""### Context\n\nGaia is a mission of the European Space Agency (ESA) that aims to accurately measure the position, distance and magnitude of over a billion stars.\n\n### Content\n\nThe following ADQL query was used to obtain the data from the [Gaia Archive][1], as is:\n\n    SELECT G.source_id,TY.id AS tycho2_id,\n        G.parallax,G.parallax_error,\n        G.phot_g_mean_mag,G.phot_rp_mean_mag,G.phot_bp_mean_mag,\n        G.phot_g_mean_flux_error,\n        G.ra,G.dec,G.ra_error,G.dec_error,\n        G.l,G.b,\n        G.pmra,G.pmdec,\n        AWBN.angular_distance AS allwise_ang_dist,\n        GSBN.angular_distance AS gsc23_ang_dist,\n        PPBN.angular_distance AS ppmxl_ang_dist,\n        TMBN.angular_distance AS tmass_ang_dist,\n        TYBN.angular_distance AS tycho2_ang_dist,\n        AW.w1mpro AS allwise_w1, AW.w2mpro AS allwise_w2, AW.w3mpro AS allwise_w3, AW.w4mpro AS allwise_w4,\n        GS.v_mag AS gsc23_v_mag,GS.b_mag AS gsc23_b_mag,\n        PP.b1mag AS ppmxl_b1mag,\n        PP.b2mag AS ppmxl_b2mag,\n        PP.r1mag AS ppmxl_r1mag,\n        PP.imag AS ppmxl_imag,\n        TM.j_m AS tmass_j_m,\n        TM.h_m AS tmass_h_m,\n        TM.ks_m AS tmass_ks_m,\n        TY.bt_mag AS tycho2_bt_mag,\n        TY.vt_mag AS tycho2_vt_mag\n    FROM gaiadr2.gaia_source G \n    INNER JOIN gaiadr2.allwise_best_neighbour AWBN ON AWBN.source_id=G.source_id \n    INNER JOIN gaiadr2.gsc23_best_neighbour GSBN ON GSBN.source_id=G.source_id\n    INNER JOIN gaiadr2.ppmxl_best_neighbour PPBN ON PPBN.source_id=G.source_id\n    INNER JOIN gaiadr2.tmass_best_neighbour TMBN ON TMBN.source_id=G.source_id\n    INNER JOIN gaiadr2.tycho2_best_neighbour TYBN ON TYBN.source_id=G.source_id\n    INNER JOIN gaiadr1.allwise_original_valid AW ON AW.designation=AWBN.original_ext_source_id\n    INNER JOIN gaiadr1.gsc23_original_valid GS ON GS.gsc23_identifier=GSBN.original_ext_source_id\n    INNER JOIN gaiadr1.ppmxl_original_valid PP ON PP.ppmxl_oid=PPBN.ppmxl_oid\n    INNER JOIN gaiadr1.tmass_original_valid TM ON TM.designation=TMBN.original_ext_source_id\n    INNER JOIN public.tycho2 TY ON TY.id=TYBN.original_ext_source_id\n    WHERE G.parallax &gt;= 2.0 AND G.parallax_error &lt;= 0.035\n    AND G.phot_g_mean_mag &lt;= 13.5\n    AND G.parallax_error IS NOT NULL\n    AND G.phot_rp_mean_mag IS NOT NULL\n    AND G.phot_bp_mean_mag IS NOT NULL\n    AND G.phot_g_mean_flux_error IS NOT NULL\n    AND AW.w1mpro IS NOT NULL\n    AND AW.w2mpro IS NOT NULL\n    AND AW.w3mpro IS NOT NULL\n    AND AW.w4mpro IS NOT NULL\n    AND GS.v_mag IS NOT NULL\n    AND GS.b_mag IS NOT NULL\n    AND PP.b1mag IS NOT NULL\n    AND PP.b2mag IS NOT NULL\n    AND PP.r1mag IS NOT NULL\n    AND PP.imag IS NOT NULL\n    AND TM.j_m IS NOT NULL\n    AND TM.h_m IS NOT NULL\n    AND TM.ks_m IS NOT NULL\n    AND TY.bt_mag IS NOT NULL\n    AND TY.vt_mag IS NOT NULL\n    AND AWBN.angular_distance &lt;= 0.15\n    AND GSBN.angular_distance &lt;= 0.25\n    AND PPBN.angular_distance &lt;= 0.15\n    AND TMBN.angular_distance &lt;= 0.15\n    AND TYBN.angular_distance &lt;= 0.25\n    AND AWBN.best_neighbour_multiplicity=1\n    AND GSBN.best_neighbour_multiplicity=1\n    AND PPBN.best_neighbour_multiplicity=1\n    AND TMBN.best_neighbour_multiplicity=1\n    AND TYBN.number_of_neighbours=1\n\n### Notes\n\n- There are a number of duplicate source_id's in the data. \n- Magnitudes have a positional bias across databases.\n\n### Acknowledgements\n\nThis work has made use of data from the European Space Agency (ESA) mission Gaia (https://www.cosmos.esa.int/gaia), processed by the Gaia Data Processing and Analysis Consortium (DPAC, https://www.cosmos.esa.int/web/gaia/dpac/consortium). Funding for the DPAC has been provided by national institutions, in particular the institutions participating in the Gaia Multilateral Agreement.\n\n\n  [1]: https://gea.esac.esa.int/archive/\n""","b""['astronomy', 'medium', 'featured']""",https://www.kaggle.com/solorzano/257k-gaia-dr2-stars
b'Monthly Salary of Public Worker in Brazil',b'Salary of Public Worker in Brazil',"b'### Context\n\nThe monthly salary of the public workers of the State of S\xc3\xa3o Paulo in Brazil is a Public data available in the transparency portal of the state government at: [http://www.transparencia.sp.gov.br/buscaRemunera.html][1]\n\n\n### Content\n\nThe data is about the salary for all worker in the State for the month of October 2017.  There are just over one million records. The names of the employee are anonymous represented by the variable id.\n\n\n### Inspiration\n\nThis database may reveal:\n\n - Higher salaries\n - The contribution of extra remuneration to higher salaries\n\nBy the rules of the government no employee could receive more than the state governor salary: R$ 21,631.05\n\n\n\n  [1]: http://www.transparencia.sp.gov.br/buscaRemunera.html'","b""['finance', 'government', 'brazil', 'government agencies', 'public administration', 'medium', 'featured']""",https://www.kaggle.com/gustavomodelli/monthly-salary-of-public-worker-in-brazil
b'Genetic Variant Classifications',b'Predict whether a variant will have conflicting clinical classifications.',"b""### Context\n\n[ClinVar](https://www.ncbi.nlm.nih.gov/clinvar/) is a public resource containing annotations about human genetic variants. These variants are (usually manually) classified by clinical laboratories on a categorical spectrum ranging from benign, likely benign, uncertain significance, likely pathogenic, and pathogenic. Variants that have conflicting classifications (from laboratory to laboratory) can cause confusion when clinicians or researchers try to interpret whether the variant has an impact on the disease of a given patient.  \n\n### Content\n\nThe objective is to predict whether a ClinVar variant will have **conflicting classifications**. This is presented here as a binary classification problem, where each record in the dataset is a genetic **variant**.\n\n![conflicting variants figure][1]\n\nConflicting classifications are when two of any of the following three categories are present for one variant, two submissions of one category are not considered conflicting.\n\n1. Likely Benign or Benign\n2. VUS\n3. Likely Pathogenic or Pathogenic\n\nConflicting classification has been assigned to the `CLASS` column. It is a binary representation of whether or not a variant has conflicting classifications, where `0` represents consistent classifications and `1` represents conflicting classifications.\n\nSince this problem only relates to variants with multiple classifications, I removed all variants from the original ClinVar `.vcf` which only had one submission.\n\nThe raw variant call format (vcf) file was downloaded here on Saturday, April 7th, 2018:\n[ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh37/clinvar.vcf.gz][2]\n\nScripts used to generate this file in [this repo](https://github.com/arvkevi/clinvar-kaggle)\n\n### Acknowledgements\n\nLandrum MJ, Lee JM, Benson M, Brown GR, Chao C, Chitipiralla S, Gu B, Hart J, Hoffman D, Jang W, Karapetyan K, Katz K, Liu C, Maddipatla Z, Malheiro A, McDaniel K, Ovetsky M, Riley G, Zhou G, Holmes JB, Kattman BL, Maglott DR. ClinVar: improving access to variant interpretations and supporting evidence. Nucleic Acids Res. 2018 Jan 4. PubMed PMID: 29165669.\n\n### Inspiration\n\nI'm exploring ideas for applying machine learning to genomics. I'm hoping this dataset will encourage others to think about the additional feature engineering that's necessary to confidently assess the objective. There could be a benefit to identifying *single submission* variants that may yet to have assigned a **conflicting classification**.\n\n\n  [1]: https://raw.githubusercontent.com/arvkevi/clinvar-kaggle/master/clinvar-class-fig.png\n  [2]: ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh37/""","b""['classification', 'healthcare', 'medicine', 'biology', 'human genetics', 'small', 'featured']""",https://www.kaggle.com/kevinarvai/clinvar-conflicting
b'Chicago Divvy Bicycle Sharing Data',b'A combination of Chicago Divvy bicycle sharing and weather data ',"b'### Context\n\nSharing bicycles represent a healthier and environment-friendly lifestyle. There could be some interesting mechanism behind the sharing bicycles. \n\n\n### Content\n\nIn this project, the data comes from Chicago Divvy bicycle sharing system as well as the weather information in Chicago.\n\n* **Divvy Data**: https://www.divvybikes.com/system-data\n\n* **Weather Data**: https://www.wunderground.com/\n\nI download the bicycle data from Divvy website from 2013 to 2017. In addition, I also queried the weather information for Chicago from https://www.wunderground.com/.\n\n* **data_raw.csv**: contains all the bicycle data from 2013 to 2017, it also contains all the weather information. There are a lot of values missing\n\n* **data.csv**: contains the data that has been cleaned. I deleted some useless weather information and keep the trips that are within 1 hour. Also, I delete some data with missing values.\n\nFor the details about how I query the data and how I processed the data, you can visit my GitHub: https://github.com/JifuZhao/Chicago_Divvy or go to my blog: https://jifuzhao.github.io/2018/03/01/divvy.html\n\n\n### Acknowledgements\n\nThanks to Divvy for sharing the data and thanks to wunderground.com for letting me query the weather information.\n\n\n### Inspiration\n\nWhere do Divvy Bikeshare riders go? When do they ride? How far do they go? Which stations are most popular? What days of the week are most rides taken on?'","b""['weather', 'society', 'medium', 'featured']""",https://www.kaggle.com/yingwurenjian/chicago-divvy-bicycle-sharing-data
b'NYS PSYCKES Antipsychotic Polypharmacy Quality',b'From New York State Open Data',"b""### Content  \n\nThe PSYCKES antipsychotic polypharmacy measure data set provides a count of how many New York State Medicaid enrollees are eligible to be included in the measure (individuals prescribed any antipsychotic medication), the count of how many enrollees meet criteria for the flag (individuals prescribed two or more [2AP] or three or more [3AP] antipsychotic medications concurrently for more than 90 days), and the percentage of enrollees flagged.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/AVqs0ItdMQM) by [JOSHUA COLEMAN](https://unsplash.com/@jerryinocmd) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'mental health', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-psyckes-antipsychotic-polypharmacy-quality
b'Cityscapes Image Pairs',b'Semantic Segmentation for Improving Automated Driving',"b'### Context\n\nCityscapes data ([dataset home page][1]) contains labeled videos taken from vehicles driven in Germany.   This version is a processed subsample created as part of the [Pix2Pix paper][2].  The dataset has still images from the original videos, and the semantic segmentation labels are shown in images alongside the original image. This is one of the best datasets around for semantic segmentation tasks.\n\n\n### Content\n\nThis dataset has 2975 training images files and 500 validation image files.  Each image file is 256x512 pixels, and each file is a composite with the original photo on the left half of the image, alongside the labeled image (output of semantic segmentation) on the right half.\n\n### Acknowledgements\n\nThis dataset is the same as what is available [here][3] from the Berkeley AI Research group.\n\n### License\n\n  The Cityscapes data available from cityscapes-dataset.com has the following license:\n\nThis dataset is made freely available to academic and non-academic entities for non-commercial purposes such as academic research, teaching, scientific publications, or personal experimentation. Permission is granted to use the data given that you agree:\n\n- That the dataset comes ""AS IS"", without express or implied warranty. Although every effort has been made to ensure accuracy, we (Daimler AG, MPI Informatics, TU Darmstadt) do not accept any responsibility for errors or omissions.\n- That you include a reference to the Cityscapes Dataset in any work that makes use of the dataset. For research papers, cite our preferred publication as listed on our website; for other media cite our preferred publication as listed on our website or link to the Cityscapes website.\n- That you do not distribute this dataset or modified versions. It is permissible to distribute derivative works in as far as they are abstract representations of this dataset (such as models trained on it or additional annotations that do not directly include any of our data) and do not allow to recover the dataset or something similar in character.\n- That you may not use the dataset or any derivative work for commercial purposes as, for example, licensing or selling the data, or using the data with a purpose to procure a commercial gain.\n- That all rights not expressly granted to you are reserved by (Daimler AG, MPI Informatics, TU Darmstadt).\n\n\n### Inspiration\n\nCan you identify you identify what objects are where in these images from a vehicle.\n\n\n  [1]: https://www.cityscapes-dataset.com/\n  [2]: https://phillipi.github.io/pix2pix/\n  [3]: https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/'","b""['image data', 'image processing', 'medium', 'featured']""",https://www.kaggle.com/dansbecker/cityscapes-image-pairs
b'1.88 Million US Wildfires',b'24 years of geo-referenced wildfire records',"b'### Context: \n\nThis data publication contains a spatial database of wildfires that occurred in the United States from 1992 to 2015. It is the third update of a publication originally generated to support the national Fire Program Analysis (FPA) system. The wildfire records were acquired from the reporting systems of federal, state, and local fire organizations. The following core data elements were required for records to be included in this data publication: discovery date, final fire size, and a point location at least as precise as Public Land Survey System (PLSS) section (1-square mile grid). The data were transformed to conform, when possible, to the data standards of the National Wildfire Coordinating Group (NWCG). Basic error-checking was performed and redundant records were identified and removed, to the degree possible. The resulting product, referred to as the Fire Program Analysis fire-occurrence database (FPA FOD), includes 1.88 million geo-referenced wildfire records, representing a total of 140 million acres burned during the 24-year period.\n\n### Content: \n\nThis dataset is an SQLite database that contains the following information:\n\n* Fires: Table including wildfire data for the period of 1992-2015 compiled from US federal, state, and local reporting systems.\n* FOD_ID = Global unique identifier.\n* FPA_ID = Unique identifier that contains information necessary to track back to the original record in the source dataset.\n* SOURCE_SYSTEM_TYPE = Type of source database or system that the record was drawn from (federal, nonfederal, or interagency).\n* SOURCE_SYSTEM = Name of or other identifier for source database or system that the record was drawn from. See Table 1 in Short (2014), or \\Supplements\\FPA_FOD_source_list.pdf, for a list of sources and their identifier.\n* NWCG_REPORTING_AGENCY = Active National Wildlife Coordinating Group (NWCG) Unit Identifier for the agency preparing the fire report (BIA = Bureau of Indian Affairs, BLM = Bureau of Land Management, BOR = Bureau of Reclamation, DOD = Department of Defense, DOE = Department of Energy, FS = Forest Service, FWS = Fish and Wildlife Service, IA = Interagency Organization, NPS = National Park Service, ST/C&L = State, County, or Local Organization, and TRIBE = Tribal Organization).\n* NWCG_REPORTING_UNIT_ID = Active NWCG Unit Identifier for the unit preparing the fire report.\n* NWCG_REPORTING_UNIT_NAME = Active NWCG Unit Name for the unit preparing the fire report.\n* SOURCE_REPORTING_UNIT = Code for the agency unit preparing the fire report, based on code/name in the source dataset.\n* SOURCE_REPORTING_UNIT_NAME = Name of reporting agency unit preparing the fire report, based on code/name in the source dataset.\n* LOCAL_FIRE_REPORT_ID = Number or code that uniquely identifies an incident report for a particular reporting unit and a particular calendar year.\n* LOCAL_INCIDENT_ID = Number or code that uniquely identifies an incident for a particular local fire management organization within a particular calendar year.\n* FIRE_CODE = Code used within the interagency wildland fire community to track and compile cost information for emergency fire suppression (https://www.firecode.gov/).\n* FIRE_NAME = Name of the incident, from the fire report (primary) or ICS-209 report (secondary).\n* ICS_209_INCIDENT_NUMBER = Incident (event) identifier, from the ICS-209 report.\n* ICS_209_NAME = Name of the incident, from the ICS-209 report.\n* MTBS_ID = Incident identifier, from the MTBS perimeter dataset.\n* MTBS_FIRE_NAME = Name of the incident, from the MTBS perimeter dataset.\n* COMPLEX_NAME = Name of the complex under which the fire was ultimately managed, when discernible.\n* FIRE_YEAR = Calendar year in which the fire was discovered or confirmed to exist.\n* DISCOVERY_DATE = Date on which the fire was discovered or confirmed to exist.\n* DISCOVERY_DOY = Day of year on which the fire was discovered or confirmed to exist.\n* DISCOVERY_TIME = Time of day that the fire was discovered or confirmed to exist.\n* STAT_CAUSE_CODE = Code for the (statistical) cause of the fire.\n* STAT_CAUSE_DESCR = Description of the (statistical) cause of the fire.\n* CONT_DATE = Date on which the fire was declared contained or otherwise controlled (mm/dd/yyyy where mm=month, dd=day, and yyyy=year).\n* CONT_DOY = Day of year on which the fire was declared contained or otherwise controlled.\n* CONT_TIME = Time of day that the fire was declared contained or otherwise controlled (hhmm where hh=hour, mm=minutes).\n* FIRE_SIZE = Estimate of acres within the final perimeter of the fire.\n* FIRE_SIZE_CLASS = Code for fire size based on the number of acres within the final fire perimeter expenditures (A=greater than 0 but less than or equal to 0.25 acres, B=0.26-9.9 acres, C=10.0-99.9 acres, D=100-299 acres, E=300 to 999 acres, F=1000 to 4999 acres, and G=5000+ acres).\n* LATITUDE = Latitude (NAD83) for point location of the fire (decimal degrees).\n* LONGITUDE = Longitude (NAD83) for point location of the fire (decimal degrees).\n* OWNER_CODE = Code for primary owner or entity responsible for managing the land at the point of origin of the fire at the time of the incident.\n* OWNER_DESCR = Name of primary owner or entity responsible for managing the land at the point of origin of the fire at the time of the incident.\n* STATE = Two-letter alphabetic code for the state in which the fire burned (or originated), based on the nominal designation in the fire report.\n* COUNTY = County, or equivalent, in which the fire burned (or originated), based on nominal designation in the fire report.\n* FIPS_CODE = Three-digit code from the Federal Information Process Standards (FIPS) publication 6-4 for representation of counties and equivalent entities.\n* FIPS_NAME = County name from the FIPS publication 6-4 for representation of counties and equivalent entities.\n* NWCG_UnitIDActive_20170109: Look-up table containing all NWCG identifiers for agency units that were active (i.e., valid) as of 9 January 2017, when the list was downloaded from https://www.nifc.blm.gov/unit_id/Publish.html and used as the source of values available to populate the following fields in the Fires table: NWCG_REPORTING_AGENCY, NWCG_REPORTING_UNIT_ID, and NWCG_REPORTING_UNIT_NAME.\n* UnitId = NWCG Unit ID.\n* GeographicArea = Two-letter code for the geographic area in which the unit is located (NA=National, IN=International, AK=Alaska, CA=California, EA=Eastern Area, GB=Great Basin, NR=Northern Rockies, NW=Northwest, RM=Rocky Mountain, SA=Southern Area, and SW=Southwest).\n* Gacc = Seven or eight-letter code for the Geographic Area Coordination Center in which the unit is located or primarily affiliated with (CAMBCIFC=Canadian Interagency Forest Fire Centre, USAKCC=Alaska Interagency Coordination Center, USCAONCC=Northern California Area Coordination Center, USCAOSCC=Southern California Coordination Center, USCORMCC=Rocky Mountain Area Coordination Center, USGASAC=Southern Area Coordination Center, USIDNIC=National Interagency Coordination Center, USMTNRC=Northern Rockies Coordination Center, USNMSWC=Southwest Area Coordination Center, USORNWC=Northwest Area Coordination Center, USUTGBC=Western Great Basin Coordination Center, USWIEACC=Eastern Area Coordination Center).\n* WildlandRole = Role of the unit within the wildland fire community.\n* UnitType = Type of unit (e.g., federal, state, local).\n* Department = Department (or state/territory) to which the unit belongs (AK=Alaska, AL=Alabama, AR=Arkansas, AZ=Arizona, CA=California, CO=Colorado, CT=Connecticut, DE=Delaware, DHS=Department of Homeland Security, DOC= Department of Commerce, DOD=Department of Defense, DOE=Department of Energy, DOI= Department of Interior, DOL=Department of Labor, FL=Florida, GA=Georgia, IA=Iowa, IA/GC=Non-Departmental Agencies, ID=Idaho, IL=Illinois, IN=Indiana, KS=Kansas, KY=Kentucky, LA=Louisiana, MA=Massachusetts, MD=Maryland, ME=Maine, MI=Michigan, MN=Minnesota, MO=Missouri, MS=Mississippi, MT=Montana, NC=North Carolina, NE=Nebraska, NG=Non-Government, NH=New Hampshire, NJ=New Jersey, NM=New Mexico, NV=Nevada, NY=New York, OH=Ohio, OK=Oklahoma, OR=Oregon, PA=Pennsylvania, PR=Puerto Rico, RI=Rhode Island, SC=South Carolina, SD=South Dakota, ST/L=State or Local Government, TN=Tennessee, Tribe=Tribe, TX=Texas, USDA=Department of Agriculture, UT=Utah, VA=Virginia, VI=U. S. Virgin Islands, VT=Vermont, WA=Washington, WI=Wisconsin, WV=West Virginia, WY=Wyoming).\n* Agency = Agency or bureau to which the unit belongs (AG=Air Guard, ANC=Alaska Native Corporation, BIA=Bureau of Indian Affairs, BLM=Bureau of Land Management, BOEM=Bureau of Ocean Energy Management, BOR=Bureau of Reclamation, BSEE=Bureau of Safety and Environmental Enforcement, C&L=County & Local, CDF=California Department of Forestry & Fire Protection, DC=Department of Corrections, DFE=Division of Forest Environment, DFF=Division of Forestry Fire & State Lands, DFL=Division of Forests and Land, DFR=Division of Forest Resources, DL=Department of Lands, DNR=Department of Natural Resources, DNRC=Department of Natural Resources and Conservation, DNRF=Department of Natural Resources Forest Service, DOA=Department of Agriculture, DOC=Department of Conservation, DOE=Department of Energy, DOF=Department of Forestry, DVF=Division of Forestry, DWF=Division of Wildland Fire, EPA=Environmental Protection Agency, FC=Forestry Commission, FEMA=Federal Emergency Management Agency, FFC=Bureau of Forest Fire Control, FFP=Forest Fire Protection, FFS=Forest Fire Service, FR=Forest Rangers, FS=Forest Service, FWS=Fish & Wildlife Service, HQ=Headquarters, JC=Job Corps, NBC=National Business Center, NG=National Guard, NNSA=National Nuclear Security Administration, NPS=National Park Service, NWS=National Weather Service, OES=Office of Emergency Services, PRI=Private, SF=State Forestry, SFS=State Forest Service, SP=State Parks, TNC=The Nature Conservancy, USA=United States Army, USACE=United States Army Corps of Engineers, USAF=United States Air Force, USGS=United States Geological Survey, USN=United States Navy).\n* Parent = Agency subgroup to which the unit belongs (A concatenation of State and Unit from this report - https://www.nifc.blm.gov/unit_id/publish/UnitIdReport.rtf).\n* Country = Country in which the unit is located (e.g. US = United States).\n* State = Two-letter code for the state in which the unit is located (or primarily affiliated).\n* Code = Unit code (follows state code to create UnitId).\n* Name = Unit name.\n\n### Acknowledgements: \n\nThese data were collected using funding from the U.S. Government and can be used without additional permissions or fees. If you use these data in a publication, presentation, or other research product please use the following citation:\n\nShort, Karen C. 2017. Spatial wildfire occurrence data for the United States, 1992-2015 [FPA_FOD_20170508]. 4th Edition. Fort Collins, CO: Forest Service Research Data Archive. https://doi.org/10.2737/RDS-2013-0009.4\n\n### Inspiration: \n\n* Have wildfires become more or less frequent over time?\n* What counties are the most and least fire-prone?\n* Given the size, location and date, can you predict the cause of a fire wildfire?\n'","b""['climate', 'firefighting', 'medium', 'featured']""",https://www.kaggle.com/rtatman/188-million-us-wildfires
b'Medium Articles',"b'A collection of articles on ML, AI and data science'","b'### Context\n\nMedium is one of the most famous tools for spreading knowledge about almost any field. It is widely used to published articles on ML, AI, and data science. This dataset is the collection of about 350 articles in such fields. \n\n### Content\n\nThe dataset contains articles, their title, number of claps it has received, their links and their reading time.\n\n### Acknowledgements\n\n\nThis dataset was scraped from [Medium](https://medium.com/).  I created a Python script to scrap all the required articles using just their tags from Medium. Check out the script [here](https://github.com/Hsankesara/medium-scrapper)\n\n### Inspiration\n\nHow to write a good article? How to inform the reader in an interesting way? What sort of title attracts more crowd? How long an article should be?'","b""['beginner', 'data visualization', 'nlp', 'text data', 'text mining', 'small', 'featured']""",https://www.kaggle.com/hsankesara/medium-articles
b'World Bank Data (1960 to 2016)',"b'Countries population, fertility rate and life expectancy'","b""### Context\n\nIn 2006, Hans Rosling gave a TED talk titled [The best stats you've ever seen](https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen). In the beginning of the talk, he shows an animation he made to debunk some misconceptions about today's world.  \n I really enjoyed seeing this visualization and have been thinking to try to reproduce it with the tools I know (i.e python and matplotlib).   \n\n\n### Content\n\nThe data was downloaded from [data.worldbank.org](https://data.worldbank.org/) on June 28th, 2018. \n\n- [life expentancy at birth](https://data.worldbank.org/indicator/SP.DYN.LE00.IN): number of years a newborn would live if the patterns of mortality at the time of birth remain the same throughout his life.\n- [Fertility rate](https://data.worldbank.org/indicator/SP.DYN.TFRT.IN): number of children a woman would give birth to during her childbearing years.  \n- [Country population](https://data.worldbank.org/indicator/SP.POP.TOTL): total number of residents regardless of legal status or citizenship (midyear estimates)\n\n\nPhoto by Ishan @seefromthesky on Unsplash""","b""['demographics', 'world', 'small', 'featured']""",https://www.kaggle.com/gemartin/world-bank-data-1960-to-2016
b'Zomato Restaurants Data',b'Analyzing the best restaurants of the major cities',"b""### Context\n\nI really get fascinated by good quality food being served in the restaurants and would like to help community find the best cuisines around their area\n\n### Content\n\nZomato API Analysis is one of the most useful analysis for foodies who want to taste the best cuisines of every part of the world which lies in their budget. This analysis is also for those who want to find the value for money restaurants in various parts of the country for the cuisines. Additionally, this analysis caters the needs of people who are striving to get the best cuisine of the country and which locality of that country serves that cuisines with maximum number of restaurants.\xe2\x99\xa8\xef\xb8\x8f\n\nFor more information on Zomato API and Zomato API key\n\xe2\x80\xa2\tVisit : https://developers.zomato.com/api#headline1\n\xe2\x80\xa2\tData Collection: https://developers.zomato.com/documentation\n\nData\nFetching the data:\n\xe2\x80\xa2\tData has been collected from the Zomato API in the form of .json files(raw data) using the url=https://developers.zomato.com/api/v2.1/search?entity_id=1&entity_type=city&start=1&count=20\n\xe2\x80\xa2\tRaw data can be seen here\n\nData Collection:\nData collected can be seen as a raw .json file here\n\nData Storage:\nThe collected data has been stored in the Comma Separated Value file Zomato.csv. Each restaurant in the dataset is uniquely identified by its Restaurant Id. Every Restaurant contains the following variables:\n\n\xe2\x80\xa2\tRestaurant Id: Unique id of every restaurant across various cities of the world\n\xe2\x80\xa2\tRestaurant Name: Name of the restaurant\n\xe2\x80\xa2\tCountry Code: Country in which restaurant is located\n\xe2\x80\xa2\tCity: City in which restaurant is located\n\xe2\x80\xa2\tAddress: Address of the restaurant\n\xe2\x80\xa2\tLocality: Location in the city\n\xe2\x80\xa2\tLocality Verbose: Detailed description of the locality\n\xe2\x80\xa2\tLongitude: Longitude coordinate of the restaurant's location\n\xe2\x80\xa2\tLatitude: Latitude coordinate of the restaurant's location\n\xe2\x80\xa2\tCuisines: Cuisines offered by the restaurant\n\xe2\x80\xa2\tAverage Cost for two: Cost for two people in different currencies \xf0\x9f\x91\xab \n\xe2\x80\xa2\tCurrency: Currency of the country\n\xe2\x80\xa2\tHas Table booking: yes/no\n\xe2\x80\xa2\tHas Online delivery: yes/ no\n\xe2\x80\xa2\tIs delivering: yes/ no\n\xe2\x80\xa2\tSwitch to order menu: yes/no\n\xe2\x80\xa2\tPrice range: range of price of food\n\xe2\x80\xa2\tAggregate Rating: Average rating out of 5\n\xe2\x80\xa2\tRating color: depending upon the average rating color\n\xe2\x80\xa2\tRating text: text on the basis of rating of rating\n\xe2\x80\xa2\tVotes: Number of ratings casted by people\n\n\n\n\n### Acknowledgements\n\nI would like to thank Zomato API for helping me collecting data\n\n\n### Inspiration\nData Processing has been done on the following categories: \nCurrency\nCity\nLocation\nRating Text""","b""['food and drink', 'small', 'featured']""",https://www.kaggle.com/shrutimehta/zomato-restaurants-data
b'NYS Retail Food Stores',b'From New York State Open Data',"b""### Content  \n\nA listing of all retail food stores which are licensed by the Department of Agriculture and Markets.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/rKikGpkSi_g) by [Jakob Owens](https://unsplash.com/@jakobowens1) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-retail-food-stores
b'Seattle CSR Public Requests',b'From City of Seattle Open Data',"b""### Content  \n\nThis dataset shows the customer service requests, by Request Type, Department received, Neighborhood, received in the Customer Service Request (CSR) system since 1/1/2017.\nData is refreshed at the beginning of each quarter. The CSR system is not a citywide CRM system.  City departments receive and respond to customer service requests in many different ways.  This data is a small subset of the requests received through CSR.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/IBWJsMObnnU) by [Arnaud Jaegers](https://unsplash.com/@ajaegers) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-csr-public-requests
b'Hand Gesture Recognition Database',b'Acquired by Leap Motion',"b'### Context\n\nHand gesture recognition database is presented, composed by a set of near infrared images acquired by the Leap Motion sensor.\n\n\n### Content\n\nThe database is composed by 10 different hand-gestures  (showed above) that were performed by 10 different subjects (5 men and 5 women).\n\nThe database is structured in different folders as:\n\n - /00    (subject with identifier 00)\n    * /01_palm    (images for palm gesture of subject 00 )\n      + /01_palm/frame_197957_r.png,...,frame_198136_l.png, ...   (images that corresponds to different samples obtained for the palm gesture performed by the subject with identifier 00)\n   - /02_l    (images for l gesture of subject 00 )\n   - /10_down\n - /01\n - /02\n - /09    (last subject with identifier 09)\n\nEvery root folder (00, 01,...) contains the infrared images of one subject. The folder name is the identifier of each different subject.\n\n\n### Citation\n\nT. Mantec\xc3\xb3n, C.R. del Blanco, F. Jaureguizar, N. Garc\xc3\xada, \xe2\x80\x9cHand Gesture Recognition using Infrared Imagery Provided by Leap Motion Controller\xe2\x80\x9d, Int. Conf. on Advanced Concepts for Intelligent Vision Systems, ACIVS 2016, Lecce, Italy, pp. 47-57, 24-27 Oct. 2016. (doi: 10.1007/978-3-319-48680-2_5)  '","b""['image data', 'computer science', 'object recognition', 'human-computer interaction', 'large', 'featured']""",https://www.kaggle.com/gti-upm/leapgestrecog
"b""Innerwear Data from Victoria's Secret and Others""","b'600,000+ innerwear product data extracted from popular retail sites'","b""### Context\n\nThese datasets provides an opportunity to perform analyses on the fashion trend of innerwear and swimwear products.\n\n### Content\n\nThey were created by extracting data from from the popular retail sites via [PromptCloud][1]'s data extraction solutions. \n\nSites covered:\n\n - Amazon\n - Victoria's Secret\n - Btemptd\n - Calvin Klein\n - Hanky Panky\n - American Eagle\n - Macy's\n - Nordstrom\n - Topshop USA\n\nTime period: June, 2017 to July, 2017\n\n### Inspiration\n\nSome of the most common questions that can be answered are:\n\n- How does the pricing differ depending on the brand?\n- Topic modelling on the product description\n- What are the most common color used by different brands?\n- Analyses on the product ratings (wherever applicable)\n- Common style attributes (wherever applicable)\n\n  [1]: https://www.promptcloud.com/?utm_source=kaggle&utm_content=fashion""","b""['internet', 'business', 'medium', 'featured']""",https://www.kaggle.com/PromptCloudHQ/innerwear-data-from-victorias-secret-and-others
b'Insurance Claim Info for vehicles being serviced',b'Insurance Claims information for vehicles being serviced at specific branches',b'### Context\n\nThe dataset is a subset of recorded insurance claims for vehicles that have been serviced at specific branches. The dataset contains information regarding these vehicles (make and model) as well as the different stages each claim goes through for a specific vehicle before the claim is invoiced. \n\n### Content\n\nThe data is a subset of data currently stored in a data warehouse of recorded insurance claims for vehicles that have been serviced at specific branches with its respective status each claim goes through. The data also contains Turnaround times for each status a claim goes through. The data range for the data is from 02 Jan 2018 to 05 Jan 2018.\n\nThe data also reflects the current status of each claim as well as sub statuses the claim has been through in its life cycle.\n\n### Acknowledgements\n\nA big thank you to the data warehouse  team for being able to capture and store this rich information and for the cover photo by takahiro taguchi on Unsplash\n\n\n### Inspiration\n\nThe purpose of uploading this dataset is to find useful insight out of this that cannot be spotted by the naked eye as well as to find patterns that could be potentially useful.',"b""['demographics', 'business', 'automobiles', 'vehicles', 'small', 'featured']""",https://www.kaggle.com/lukamauto/insurance-claim-info-for-vehicles-being-serviced
b'NYC Registration Contacts',b'From New York City Open Data',"b""### Content  \n\nContains information about organizations or individuals listed on a Multiple Dwelling Registration form.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/kSlL887znkE) by [Jason Wong](https://unsplash.com/@jasonhk1920) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/nyc-registration-contacts
b'New York Times Comments',b'Comments on articles published in the New York Times',"b""### Context\n\nNew York Times has a wide audience and plays a prominent role in shaping people's opinion and outlook on current affairs and also in setting the tone of the public discourse, especially in the USA. The comment section in the articles is very active and it gives a glimpse of readers' take on the matters concerning the articles. \n\n### Content\n\nThe data contains information about the comments made on the articles published in New York Times in Jan-May 2017 and Jan-April 2018. The month-wise data is given in two `csv` files - one each for the articles on which comments were made and for the comments themselves. The `csv` files for comments contain over  ***2 million comments*** in total with ***34 features*** and those for articles contain ***16 features*** about more than ***9,000 articles***.  \n\n### Inspiration\n\nThe data set is rich in information containing comments' texts, that are largely very well written, along with contextual information such as section/topic of the article, as well as features indicating how well the comment was received by the readers such as `editorsSelection` and `recommendations`. This data can serve the purpose of understanding and analyzing the public mood.  \nThe [exploratory kernel here](https://www.kaggle.com/aashita/nyt-comments-eda) can be used for a review of the features of the dataset and the [NB-Logistic model kernel](https://www.kaggle.com/aashita/starter-kernel-for-predicting-nyt-s-pick/log) for predicting NYT's pick can be used as a starter for building models on a range of ideas, some of which are:\n\n1. Predicting the number of upvotes a comment will receive using the feature `recommendations` as the target variable. With enough training set for the model, we can make a guess of how a hypothetical comment on a certain topic will be received by the community of NYT readers' and this can be considered a tool to gauge public opinion. The design of this model will be very similar to the ones used in ranking the reviews based on guessing how many upvotes the reviews will receive.\n2. Predicting whether a comment will be editor's pick using feature `editorsSelection` as the target variable. It gives a clue to what NYT considers worth promoting.\n3. Based on a comment, guessing the topic (using `sectionName` and/or `newDesk` as the target variable) of the article.\n4. Predicting how likely it is for a comment to get replies (using `replyCount` feature as the target variable).\n5. Predicting how likely it is for an article to initiate discussion and get comments and upvotes as well as sentiment analysis of the comments' text.\n6. Predicting the same as above for topics (indicated by the features `sectionName` and/or `newDesk`).\n7. Analyzing behaviors of the top commenters such as which topics they most likely comment and the sentiment analysis of the comments.\n\n### Data collection\n\nThe [python package here](https://github.com/AashitaK/nyt-comments) written to supplant this dataset can be used to retrieve comments from a customized search of the NYT articles concerning a specific topic, for example - Iraq war or ObamaCare - in a given timeline. The [tutorial here](https://github.com/AashitaK/nyt-comments/blob/master/Tutorial.ipynb) gives detailed information about the use of the package with the help of examples.\n\n### Acknowledgements\n\n* The data was collected with the help of New York Times API to retrieve URL of the articles.\n* The URL used to retrieve comments from a given article in the code in the [package](https://github.com/AashitaK/nyt-comments) written to retrieve the data is taken from the [blog by Neal Caren](http://nealcaren.web.unc.edu/scraping-comments-from-the-new-york-times/).\n\n""","b""['nlp', 'politics', 'journalism', 'sociology', 'digital media', 'medium', 'featured']""",https://www.kaggle.com/aashita/nyt-comments
b'Gender Info 2007',b'Global gender statistics',"b'Gender Info 2007 is a global database of gender statistics and indicators on a wide range of policy areas, including: population, families, health, education, work, and political participation. It can be used by governments, international organizations, advocacy groups, researchers and others in need of statistics for planning, analysis, advocacy and awareness-raising. Users will find in Gender Info an easy-to-use tool to shed light on gender issues through customizable tables, graphs and maps. It is an initiative of the United Nations Statistics Division, produced in collaboration with the United Nations Children\xe2\x80\x99s Fund (UNICEF) and the United Nations Population Fund (UNFPA). \n\nThis dataset was last updated in 2008. If you need a more current version of the data please visit http://unstats.un.org/unsd/gender/data.html for other Gender Statistics.\n\n\n### Acknowledgements\n\nThis dataset was kindly published by the United Nations on the UNData site. You can find [the original dataset here](http://data.un.org/Explorer.aspx).\n\n### License\n[Per the UNData terms of use](http://data.un.org/Host.aspx?Content=UNdataUse): all data and metadata provided on UNdata\xe2\x80\x99s website are available free of charge and may be copied freely, duplicated and further distributed provided that [UNdata](http://data.un.org/Explorer.aspx) is cited as the reference. '","b""['gender', 'small', 'featured']""",https://www.kaggle.com/unitednations/gender-info-2007
b'Traditional Flute Dataset for Score Alignment',b'30 manually-labeled audio fragments and scores from real solo flute pieces',"b'\n### Context\n\nThe flute is a widely used instrument in compositional practices. Furthermore, it has a long tradition in [Electroacoustic Music][1] where instruments are combined with electrical sound production, generated for example with computers. On the other hand, audio to score alignment is the task of synchronizing an audio recording with the corresponding symbolic score, from where fields as [Computer Music][2] leverage in variety of applications. With the intention to contribute in the task of audio to score alignment with solo flute musical pieces this dataset was created out.\n\n### Content\n\nThis set of data is composed of 30 manually-labeled audio fragments and the corresponding scores with symbolic notation. Construction was made out from real solo flute pieces, through various recordings of 4 important musical pieces of flute repertoire. Selected musical pieces are based on the traditional execution techniques of the flute, where music can be described as notes (pitch and duration), leaving out the contemporary repertoire based on extended techniques. The musical pieces are:\n\n- **Allemande (first movement of BWV 1013):** composed by J.S. Bach\n- **Syrinx:** composed by C. Debussy\n- **Density 21.5:** composed by E. Varese\n- **Sequenza I:** composed by L. Berio\n\nFrom the total of fragments, 10 correspond to Allemande, 10 to Syrinx, 6 to Density 21.5 and 4 to Sequenza I. In addition all the flute register is covered (from C4 to D7) resulting in a total of 2245 musical events.  Three kind of files compose the dataset:\n\n- **Audio files:** coded as 16bits @44100Hz with file extension \'.wav\'.\n- **Score files:** in two formats. On one hand, csv files with extension \'.notes\' generated through [Lilypond][3], and on the other hand midi files with \'.midi\' extension.\n- **Ground truth:** files generated by myself through manual annotations using [Sonic Visualizer][4], exported as csv files and saved with \'.gt\' extension.\n- **load.py:** python module with some functions for the dataset usage. \n\nLast but not least, in the synth folder you can find a synthetic version of the scores and the ground truth made with [Wind Synthesis Toolbox][5].\n\n### Referencing\nIf you use this dataset in a publication, I would be grateful if you reference this page as follows:\n\nJuan P. Braga Brum (2018). ""Traditional Flute Dataset for Score Alignment"", web resource. https://www.kaggle.com/jbraga/traditional-flute-dataset\n\n\n### Acknowledgements\n\nThis dataset was compiled within my master\'s in science thesis named in its original language: ""Alineaci\xc3\xb3n entre audio y partitura para obras del repertorio de la flauta traversa"" (i.e. Audio-Score Alignment for Works of the Solo Flute Repertoire).  \n\n- **Supervisor:** [DSc. L. W. P. Biscainho][6] from Universidad Federal de Rio de Janeiro, Brasil. \n- **Musicological Supervisor:** [DMus. O. Bud\xc3\xb3n][7] from Universidad de la Rep\xc3\xbablica, Uruguay.\n\n\n### Usage\n\nFor further details in dataset usage please see [Alignment Kernel][8]. Also feel free to contact me if something comes up at: juanbragabrum@gmail.com\n\n\n  [1]: http://en.wikipedia.org/wiki/Electroacoustic_music\n  [2]: http://en.wikipedia.org/wiki/Computer_music\n  [3]: http://lilypond.org/\n  [4]: https://www.sonicvisualiser.org/\n  [5]: https://iie.fing.edu.uy/~rocamora/wind_synthesis/doc/\n  [6]: http://www02.smt.ufrj.br/~wagner/en/\n  [7]: http://www.osvaldobudon.org\n  [8]: https://www.kaggle.com/jbraga/alignment'","b""['feature engineering', 'music', 'signal processing', 'medium', 'featured']""",https://www.kaggle.com/jbraga/traditional-flute-dataset
b'FiveThirtyEight Alcohol Consumption Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Alcohol Consumption\n\nThis folder contains the data behind the story [Dear Mona Followup: Where Do People Drink The Most Beer, Wine And Spirits?](http://fivethirtyeight.com/datalab/dear-mona-followup-where-do-people-drink-the-most-beer-wine-and-spirits/)\n\nUnits: Average serving sizes per person\nSource: World Health Organisation, Global Information System on Alcohol and Health (GISAH), 2010\n  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.  \n\n[Cover photo](https://unsplash.com/photos/VEjN2jMxf0A) by [Tomasz Rynkiewicz](https://unsplash.com/@thmsr) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-alcohol-consumption-dataset
b'Resume Entities for NER',b'A document annotation dataset to perform NER on resumes.',"b""### Context\n\n**This dataset is a document annotation dataset to be used to perform NER on resumes from indeed.com**\n\nVisualize and browse the dataset below:\n\nhttps://dataturks.com/projects/abhishek.narayanan/Entity%20Recognition%20in%20Resumes\n\n![enter image description here][1]\n\n\n### Content\n\nThe dataset has 220 items of which 220 items have been manually labeled.\n\nThe labels are divided into following 10 categories:\n\nName\nCollege Name\nDegree\nGraduation Year\nYears of Experience\nCompanies worked at\nDesignation\nSkills\nLocation\nEmail Address\n\n![enter image description here][2]\n\n**Key Features**\n\n220 items\n10 categories\nHuman labeled dataset\n\n![enter image description here][3]\n\n**Examples:**\n\n![enter image description here][4]\n\n![enter image description here][5]\n\n### Acknowledgements\n\nWe wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.\n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?\n\n\n  [1]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/resume_dataset_3.png\n  [2]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/resume_dataset_1.png\n  [3]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/resume_dataset_5.png\n  [4]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/resume_dataset_2.png\n  [5]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/resume_dataset_4.png""","b""['nlp', 'linguistics', 'business', 'text data', 'small', 'featured']""",https://www.kaggle.com/dataturks/resume-entities-for-ner
b'Chicago Contracts',b'From City of Chicago Open Data',"b'### Content  \n\nContracts and modifications awarded by the City of Chicago since 1993. This data is currently maintained in the City\xe2\x80\x99s Financial Management and Purchasing System (FMPS), which is used throughout the City for contract management and payment. \r\nLegacy System Records: Purchase Order/Contract Numbers that begin with alpha characters identify records imported from legacy systems. Records with a null value in the Contract Type field were imported from legacy systems. \r\n""Comptroller-Other"" Contract Type: Some records where the Contract Type is ""COMPTROLLER-OTHER"" are ordinance-based agreements and may have start dates earlier than 1993. \r\nDepends Upon Requirements Contracts: If the contract Award Amount is $0, the contract is not cancelled, and the contract is a blanket contract, then the contract award total Depends Upon Requirements. A Depends Upon Requirements contract is an indefinite quantities contract in which the City places orders as needed and the vendor is not guaranteed any particular contract award amount. \r\n\r\nBlanket vs. Standard Contracts: Only blanket contracts (contracts for repeated purchases) have FMPS end dates. Standard contracts (for example, construction contracts) terminate upon completion and acceptance of all deliverables. These dates are tracked outside of FMPS. \r\n\r\nNegative Modifications: Some contracts are modified to delete scope and money from a contract. These reductions are indicated by negative numbers in the Award Amount field of this dataset. \r\n\r\nData Owner: Procurement Services. \r\nTime Period: 1993 to present. \r\nFrequency: Data is updated daily.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/YqwOX6Ks9k8) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-contracts
b'Chicago Smart Green Infrastructure Monitoring Data',b'From City of Chicago Open Data',"b'### Content  \n\nThis dataset is historical-only. -- Results from a 2017-2018 project of City-installed sensors measuring water runoff from streets and sidewalks. These data can be used to measure the impact of sustainable green infrastructure on flooding. These sensors also captured weather data.\n\nEach row corresponds to a sensor measurement at a specific time and location. Each row is a different sensor, which can be determined from the ""Measurement Title"" column. The value for each measurement is always numeric and available in the ""Measurement Value"" column. The corresponding unit of measurement is in the ""Units"" column. Data may be missing at times due to sensors not being available.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/xcd6DseGyZo) by [Casey Horner](https://unsplash.com/@mischievous_penguins) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'weather', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-smart-green-infrastructure-monitoring-data
b'Video Object Tracking',b'Tracking objects through complex video scenes',"b""### Content\nThe dataset is about tracking objects in 2D in movies with fixed and moving cameras. Most of the objects are pedestrians but there are a few other examples\n\nI just downloaded the zip and am now looking at what is actually inside. A kernel will hopefully clarify how the ground truth can be read.\n\n### Acknowledgements\n\nThe dataset was originally download from the TV77 website http://cmp.felk.cvut.cz/~vojirtom/dataset/tv77/\n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?""","b""['image data', 'object detection', 'large', 'featured']""",https://www.kaggle.com/kmader/videoobjecttracking
b'Science Clips',b'Explore Open Data from the Centers for Disease Control',"b""### Content  \n\nCDC Science Clips is an online bibliographic digest featuring scientific articles and publications that are shared with the public health community each week, to enhance awareness of emerging scientific knowledge.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Disease Control and Prevention. The organization has an open data platform found [here](https://data.cdc.gov) and they update their information according the amount of data that is brought in. Explore CDC Data using Kaggle and all of the data sources available through the CDC [organization page](https://www.kaggle.com/cdc)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under NA""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/cdc/science-clips
b'213K Stars From Gaia DR2',"b'213K Gaia DR2 sources, w/ photometry from 5 additional databases.'","b'### Context\n\nGaia is a mission of the European Space Agency (ESA) that aims to accurately measure the position, distance and magnitude of over a billion stars.\n\n### Content\n\nThe following ADQL query was used to obtain the data, as is:\n\n    SELECT G.source_id,GSBN.original_ext_source_id AS gsc23_source_id,\n        G.parallax,G.parallax_error,\n        G.phot_g_mean_mag,G.phot_rp_mean_mag,G.phot_bp_mean_mag,\n        G.phot_g_mean_flux_error,\n        G.ra,G.dec,G.ra_error,G.dec_error,\n        G.l,G.b,\n        G.pmra,G.pmdec,\n        AWBN.angular_distance AS allwise_ang_dist,\n        GSBN.angular_distance AS gsc23_ang_dist,\n        PPBN.angular_distance AS ppmxl_ang_dist,\n        TMBN.angular_distance AS tmass_ang_dist,\n        URBN.angular_distance AS urat1_ang_dist,\n        AW.w1mpro AS allwise_w1, AW.w2mpro AS allwise_w2, AW.w3mpro AS allwise_w3, AW.w4mpro AS allwise_w4,\n        GS.v_mag AS gsc23_v_mag,GS.b_mag AS gsc23_b_mag,\n        PP.b1mag AS ppmxl_b1mag,\n        PP.b2mag AS ppmxl_b2mag,\n        PP.r1mag AS ppmxl_r1mag,\n        PP.imag AS ppmxl_imag,\n        TM.j_m AS tmass_j_m,\n        TM.h_m AS tmass_h_m,\n        TM.ks_m AS tmass_ks_m,\n        UR.f_mag AS urat1_f_mag,\n        UR.b_mag AS urat1_b_mag,\n        UR.v_mag AS urat1_v_mag,\n        UR.g_mag AS urat1_g_mag,\n        UR.r_mag AS urat1_r_mag,\n        UR.i_mag AS urat1_i_mag\n    FROM gaiadr2.gaia_source G \n    INNER JOIN gaiadr2.allwise_best_neighbour AWBN ON AWBN.source_id=G.source_id \n    INNER JOIN gaiadr2.gsc23_best_neighbour GSBN ON GSBN.source_id=G.source_id\n    INNER JOIN gaiadr2.ppmxl_best_neighbour PPBN ON PPBN.source_id=G.source_id\n    INNER JOIN gaiadr2.tmass_best_neighbour TMBN ON TMBN.source_id=G.source_id\n    INNER JOIN gaiadr2.urat1_best_neighbour URBN ON URBN.source_id=G.source_id\n    INNER JOIN gaiadr1.allwise_original_valid AW ON AW.designation=AWBN.original_ext_source_id\n    INNER JOIN gaiadr1.gsc23_original_valid GS ON GS.gsc23_identifier=GSBN.original_ext_source_id\n    INNER JOIN gaiadr1.ppmxl_original_valid PP ON PP.ppmxl_oid=PPBN.ppmxl_oid\n    INNER JOIN gaiadr1.tmass_original_valid TM ON TM.designation=TMBN.original_ext_source_id\n    INNER JOIN gaiadr1.urat1_original_valid UR ON UR.urat1_identifier=URBN.original_ext_source_id\n    WHERE G.parallax &gt;= 1.7 AND G.parallax_error &lt;= 0.04\n    AND G.phot_g_mean_mag &lt;= 13.0\n    AND G.parallax_error IS NOT NULL\n    AND G.phot_rp_mean_mag IS NOT NULL\n    AND G.phot_bp_mean_mag IS NOT NULL\n    AND G.phot_g_mean_flux_error IS NOT NULL\n    AND AW.w1mpro IS NOT NULL\n    AND AW.w2mpro IS NOT NULL\n    AND AW.w3mpro IS NOT NULL\n    AND AW.w4mpro IS NOT NULL\n    AND GS.v_mag IS NOT NULL\n    AND GS.b_mag IS NOT NULL\n    AND PP.b1mag IS NOT NULL\n    AND PP.b2mag IS NOT NULL\n    AND PP.r1mag IS NOT NULL\n    AND PP.imag IS NOT NULL\n    AND TM.j_m IS NOT NULL\n    AND TM.h_m IS NOT NULL\n    AND TM.ks_m IS NOT NULL\n    AND UR.f_mag IS NOT NULL\n    AND UR.b_mag IS NOT NULL\n    AND UR.v_mag IS NOT NULL\n    AND UR.g_mag IS NOT NULL\n    AND UR.r_mag IS NOT NULL\n    AND UR.i_mag IS NOT NULL\n    AND AWBN.angular_distance &lt;= 0.4\n    AND GSBN.angular_distance &lt;= 0.4\n    AND PPBN.angular_distance &lt;= 0.4\n    AND TMBN.angular_distance &lt;= 0.4\n    AND URBN.angular_distance &lt;= 0.4\n    AND AWBN.best_neighbour_multiplicity=1\n    AND GSBN.best_neighbour_multiplicity=1\n    AND PPBN.best_neighbour_multiplicity=1\n    AND TMBN.best_neighbour_multiplicity=1\n    AND URBN.best_neighbour_multiplicity=1\n\n### Notes\n\nThis dataset does not include too many stars from the Southern Hemisphere. See *[257K Gaia DR2 Stars][1]* for an alternative.\n\n### Acknowledgements\n\nThis work has made use of data from the European Space Agency (ESA) mission Gaia (https://www.cosmos.esa.int/gaia), processed by the Gaia Data Processing and Analysis Consortium (DPAC, https://www.cosmos.esa.int/web/gaia/dpac/consortium). Funding for the DPAC has been provided by national institutions, in particular the institutions participating in the Gaia Multilateral Agreement.\n\n\n  [1]: https://www.kaggle.com/solorzano/257k-gaia-dr2-stars'","b""['astronomy', 'medium', 'featured']""",https://www.kaggle.com/solorzano/213k-stars-from-gaia-dr2
b'Simplified Human Activity Recognition w/Smartphone',b'Recordings of subjects performing activities while carrying inertial sensors.',"b'#Context\n\nThis is a simplified version of the ""Human Activity Recognition Using Smartphones Data Set "" that can be found in: (https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)\n\nThe sole purpose of this simplification is to use it as a teaching tool at the introductory Machine Learning Course of Universidad de Palermo  (Buenos Aires, Argentina). \nURL of the competition: https://www.kaggle.com/t/5c27656d61ec4808bcbddd67ac1fdc5a\n\nThere are no claimed rights of any kind, please refer to original dataset (link above) in order to get the full dataset.\n\n#Content\n\nAbstract: Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.\n\nData Set Characteristics:  Multivariate, Time-Series\n\nData Set Information:\n\nThe experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. \n\nThe sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.\n\nCheck the README.txt file for further details about this dataset. \n\n\nAn updated version of this dataset can be found at (https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones) It includes labels of postural transitions between activities and also the full raw inertial signals instead of the ones pre-processed into windows.\n\n#Acknowledgements\n\nSource:\n\nJorge L. Reyes-Ortiz(1,2), Davide Anguita(1), Alessandro Ghio(1), Luca Oneto(1) and Xavier Parra(2)\n1 - Smartlab - Non-Linear Complex Systems Laboratory\nDITEN - Universit\xc3\xa0 degli Studi di Genova, Genoa (I-16145), Italy. \n2 - CETpD - Technical Research Centre for Dependency Care and Autonomous Living\nUniversitat Polit\xc3\xa8cnica de Catalunya (BarcelonaTech). Vilanova i la Geltr\xc3\xba (08800), Spain\nactivityrecognition \'@\' smartlab.ws\n\n#Inspiration\n\nCan you identify behavior patterns via smart phone sensor data?'","b""['small', 'featured']""",https://www.kaggle.com/mboaglio/simplifiedhuarus
b'Structural Protein Sequences',b'Sequence and meta data for various protein structures',"b'### Context\n\nThis is a protein data set retrieved from Research Collaboratory for Structural Bioinformatics (RCSB)  Protein Data Bank (PDB). \n\nThe PDB archive is a repository of atomic coordinates and other information describing proteins and other important biological macromolecules. Structural biologists use methods such as X-ray crystallography, NMR spectroscopy, and cryo-electron microscopy to determine the location of each atom relative to each other in the molecule. They then deposit this information, which is then annotated and publicly released into the archive by the wwPDB.\n\nThe constantly-growing PDB is a reflection of the research that is happening in laboratories across the world. This can make it both exciting and challenging to use the database in research and education. Structures are available for many of the proteins and nucleic acids involved in the central processes of life, so you can go to the PDB archive to find structures for ribosomes, oncogenes, drug targets, and even whole viruses. However, it can be a challenge to find the information that you need, since the PDB archives so many different structures. You will often find multiple structures for a given molecule, or partial structures, or structures that have been modified or inactivated from their native form.\n\n\n\n\n### Content\n\nThere are two data files. Both are arranged on ""structureId"" of the protein:\n\n- **pdb_data_no_dups.csv** contains protein meta data which includes details on protein classification, extraction methods, etc. \n\n- **data_seq.csv** contains &gt;400,000 protein structure sequences.\n\n\xe2\x80\x8b\n\n\n### Acknowledgements\n\nOriginal data set down loaded from http://www.rcsb.org/pdb/\n\n### Inspiration\n\nProtein data base helped the life science community to study about different diseases and come with new drugs and solution that help the human survival.'","b""['healthcare', 'multiclass classification', 'biology', 'medium', 'featured']""",https://www.kaggle.com/shahir/protein-data-set
b'OSMI Mental Health in Tech Survey 2017',b'Data on prevalence and attitudes towards mental health among tech workers',"b'OSMI Mental Health in Tech Survey 2017\n\nThe 2017 survey aims to measure attitudes towards mental health in the tech workplace, and examine the frequency of mental health disorders among tech workers.\nHow Will This Data Be Used?\n\nWe are interested in gauging how mental health is viewed within the tech/IT workplace, and the prevalence of certain mental health disorders within the tech industry. The Open Sourcing Mental Illness team of volunteers will use this data to drive our work in raising awareness and improving conditions for those with mental health disorders in the IT workplace.'","b""['internet', 'employment', 'mental health', 'small', 'featured']""",https://www.kaggle.com/osmihelp/osmi-mental-health-in-tech-survey-2017
b'Candidatos Deputado Federal e Estadual 2014',"b'Dados pessoais, bens declarados e doa\xc3\xa7\xc3\xb5es recebidas'","b'### Context\n\nDataset criado para realizar o [projeto][1] de conclus\xc3\xa3o do curso de Engenheiro de Machine Learning pela Udacity.\n\n\n### Content\n\nDados de candidatos a deputados estadual e federal elei\xc3\xa7\xc3\xb5es 2014. Caracter\xc3\xadsticas dos candidatos (sexo, idade, ra\xc3\xa7a/cor), valores dos bens declarados e doa\xc3\xa7\xc3\xb5es recebidas. \n\n\n### Acknowledgements\n\nAgrade\xc3\xa7o a Felipe Antunes por disponibilizar o dataset de [doa\xc3\xa7\xc3\xb5es aos candidatos][2].\nTamb\xc3\xa9m agrade\xc3\xa7o Heitor Gomes, revisor de meu projeto pelas \xc3\xb3timas sugest\xc3\xb5es de melhorias.\n\n\n### Inspiration\n\nComo os dados dos candidatos podem ser utilizados para realizar uma previs\xc3\xa3o se o candidato ser\xc3\xa1 ou n\xc3\xa3o eleito melhorando o resultado obtido [neste projeto][3]?\n\n\n  [1]: https://github.com/eliezerfb/elections-prediction-capstone-ndml\n  [2]: https://www.kaggle.com/felipeleiteantunes/electoral-donations-brazil2014/downloads/receitas_candidatos_2014_brasil.txt\n  [3]: https://github.com/eliezerfb/elections-prediction-capstone-ndml/blob/master/Capstone%20Report%20-%20Machine%20Learning%20Engineer%20Nanodegree.pdf'","b""['politics', 'government', 'brazil', 'small', 'featured']""",https://www.kaggle.com/eliezerfb/candidatos-deputado-federal-e-estadual-2014
b'One-Shot-Pokemon Images',"b'Colorful and fun dataset for one shot learning problem, gotta recognize them all'","b'## Pokemon images for one shot learning\nOne-shot-learning is a very interesting task.  \nThis blog has a good [explanation for one-shot-learning](https://sorenbouma.github.io/blog/oneshot/).  \n\n## Dataset description\nThere are three directories,   \n""pokemon-a"" and ""pokemon-b"" are standard pokemon images with no background. One can use them for training.  \n""pokemon-tcg-images"" are pokemon images cropped from pokemon tcg card. They are for testing.  \nFilenames in all directories start with pokemon-id, aka class label.  \n\n## Challenge\nA classic deep convolution network with softmax can only achieve accuracy below 30%.  \nIf you have any good ideas to get better result on this dataset, you are welcome to share with us.  \nHave fun!\n\n## Where those images from\nAll images are collected from internet, and **original authors owns the copyright** (Nintendo, I guess).  \nCheck links below for more information:  \n\n- [kaggle-pokemon-images](https://www.kaggle.com/kvpratama/pokemon-images-dataset)  \n- [veekun](https://veekun.com/dex/downloads)\n- [pokemon-tcg](https://github.com/PokemonTCG)\n\n\n'","b""['classification', 'deep learning', 'image data', 'large', 'featured']""",https://www.kaggle.com/aaronyin/oneshotpokemon
b'Chicago Ordinance Violations',b'From City of Chicago Open Data',"b'### Content  \n\nList of ordinance violations filed with the Department of Administrative Hearings. This data set reflects violations brought before the Chicago Department of Administrative Hearings.  It does not reflect violations brought before the Circuit Court of Cook County. Each row of data represents a unique violation. Multiple violations may be associated with a single case. The most recent status of the case is shown in the dataset and is updated daily. Hearing date corresponds to the date of the most recent hearing. Each case often consists of multiple hearings and may encounter continuances due to various circumstances before a final disposition is rendered. The case disposition, date of the disposition, and any applicable fines and administrative costs are listed when the case is fully completed. The latest hearing status or disposition reflects the condition of the property at that time and may not reflect the current condition of the property. When multiple respondents are cited, each respondent is separated by a pipe (""|"") character. Respondents sometimes are added to cases for technical legal reasons so are not necessarily the parties believed to have committed the violations. This dataset currently lists violations issued by the Department of Buildings. Additional ordinance violations will be added over time.  Therefore, it is advisable to use the department-specific filtered view listed under the More Views button for purposes that require only one department\'s violations.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/uZnoD1xuL9A) by [Brittney Butler](https://unsplash.com/@britjanae) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-ordinance-violations
"b'Air Quality Data - Earlwood, NSW'","b'Jan 2017 - Jan 2018, various pollutants and environmental variables'","b""### Context\n\nI'm looking at air quality in my area and also using this as an exercise to investigate possible sources of pollutants, account for variations in pollutant concentration and finally, as an exercise to combine modelling physical systems with data analysis.\n\n### Content\n#### Concentrations (different period averages):\n* NO2\n* CO\n* NO\n* O3\n* PM10\n* PM2.5\n\n#### Environmental Variables\n* Wind Direction\n* Wind Speed\n* Temperature\n* Humidity\n\n#### Stations\n* Lat and Long\n\n### Acknowledgements\n\nSource: NSW OEH - http://www.environment.nsw.gov.au/aqms/search.htm\n\nBanner photo by [@veeterzy from Unsplash][1].\n\n\n### Inspiration\n\nUnderstanding pollution , finding causes for high events and mitigating its production and effects\n\n\n  [1]: https://unsplash.com/photos/UwBrS-qRMHo""","b""['pollution', 'small', 'featured']""",https://www.kaggle.com/prakaa/air-quality-data-earlwood-nsw-australia
b'NYS Facilities Licensed by the DMV',b'From New York State Open Data',"b""### Content  \n\nData set containing information on the facilities licensed by DMV in accordance with Vehicle and Traffic Law.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/JoqGIJMqENs) by [bady qb](https://unsplash.com/@bady) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-facilities-licensed-by-the-dmv
b'Tweets during Cavaliers vs Warriors ',b'3rd game of the 2018 NBA Finals #NBAFinals',"b""### Context\n\nData set containing Tweets captured during the **3rd game of the 2018 NBA Finals** between **Cleveland Cavaliers** and **Golden State Warriors**.\n\n### Content\n\n All Twitter APIs that return Tweets provide that data encoded using JavaScript Object Notation (JSON). **JSON** is based on key-value pairs, with named attributes and associated values. The JSON file include the following objects and attributes: \n\n* **[Tweet](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object)** - Tweets are the basic atomic building block of all things Twitter. The Tweet object has a long list of \xe2\x80\x98root-level\xe2\x80\x99 attributes, including fundamental attributes such as `id`, `created_at`, and `text`. Tweet child objects include `user`, `entities`, and `extended_entities.` Tweets that are geo-tagged will have a `place` child object.\n\n    + **[User](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/user-object)** - Contains public Twitter account metadata and describes the author of the Tweet with attributes as `name`, `description`, `followers_count`, `friends_count`, etc.\n\n    + **[Entities](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/entities-object)** - Provide metadata and additional contextual information about content posted on Twitter. The `entities` section provides arrays of common things included in Tweets: hashtags, user mentions, links, stock tickers   (symbols), Twitter polls, and attached media.\n\n    + **[Extended Entities](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/extended-entities-object)** - All Tweets with attached photos, videos and animated GIFs will include an `extended_entities` JSON object.\n\n    + **[Places](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/geo-objects)** - Tweets can be associated with a location, generating a Tweet that has been \xe2\x80\x98geo-tagged.\xe2\x80\x99 \n\nMore information [here](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json). \n\nI also included the captured Tweets in a CSV file. In order to convert JSON data into a CSV file, I have used the function `parseTweets()`.\n\n### Acknowledgements\n\nI used the `filterStream()` function to open a connection to Twitter's Streaming API, using the keyword **#NBAFinals**. The capture started on **Thursday, June 7th 01:13 am UCT** and finished on **Thursday, June 7th 01:58 am UCT**.\n\n### Inspiration\n\n- Time analysis\n- Try text mining!\n-  Cross-language differences in Twitter\n- Use this data to produce a sentiment analysis\n- Twitter geolocation\n- Network analysis: graph theory, metrics and properties of the network, community detection, network visualization, etc. ""","b""['sports', 'text mining', 'twitter', 'basketball', 'network analysis', 'medium', 'featured']""",https://www.kaggle.com/xvivancos/tweets-during-cavaliers-vs-warriors
b'NYC OEM Emergency Notifications',b'From New York City Open Data',"b""### Content  \n\nMessages sent with information about emergency events and important City services  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/loeqHoa1uWY) by [Daniel Tausis](https://unsplash.com/@greatmalinco) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-oem-emergency-notifications
b'Brazillian Stock Quotes',b'Daily historical data',"b""### Context\n\nMy objective sharing this data is to make studies about stock quotes using real data from the Brazilian stock market.\n\n\n### Content\n\nThis is the daily stock quotes from B3 for the 2017 year. [B3 is the unique stock exchange in Brazil](https://en.wikipedia.org/wiki/B3_(stock_exchange)), here we don't have competition in this sector as in USA.\n\n\n### Acknowledgements\n\nThis data is directly extracted from B3 [site][1], without changes. \n\n\n  [1]: http://www.bmfbovespa.com.br/pt_br/servicos/market-data/historico/mercado-a-vista/cotacoes-historicas/""","b""['brazil', 'medium', 'featured']""",https://www.kaggle.com/gbonesso/b3-stock-quotes
b'CMS National Summary of Outpatient Charge Data',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: NA, Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/cms-national-summary-of-outpatient-charge-data
b'NYS Public Assistance (PA) Cases and Information',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-public-assistance-pa-cases-and-information
b'Greek Single Speaker Speech Dataset',b'CSS10 Greek: Single Speaker Speech Dataset',"b'### Context\n\nCSS10 is a collection of single speaker speech datasets for 10 languages. Each of them consists of audio files recorded by a sinlge volunteer and their aligned text sourced from LibriVox.\n\n### Content\nEach line in `transcript.txt` is delimited by `|` into four fields, i.e., audio file location, original script, normalized script, and audio duration.\n\nVisit [here](https://github.com/kyubyong/css10) to check out our project using this dataset.\n\n### Acknowledgements\n\nWe thank LibriVox and the volunteers.\n \n### Contact\nYou can contact me at kbpark.linguist@gmail.com.\n\nJune, 2018.\n\nKyubyong Park & Tommy Mulc\n'","b""['linguistics', 'medium', 'featured']""",https://www.kaggle.com/bryanpark/greek-single-speaker-speech-dataset
"b'300 images of squares, circles, and triangles'",b'Made for beginners learning Neural Networks',"b'#Context\n\nThere are a lot of different types of shapes and it is important to be able to differentiate between them.\n\n#Content\n\nI drew 100 triangles, 100 squares and 100 circles in processing. each png image is 28x28 px\nthe images are in 3 folders labeled squares, circles and triangles\npretty straight forward\n\n#Acknowledgements\n\nBanner image by [@rawpixel from Unsplash][1].\n\n#Inspiration\n\nIs that image a triangle or a square or a circle?\n\n\n  [1]: https://unsplash.com/photos/JbDomeNrdOs'","b""['image data', 'image processing', 'small', 'featured']""",https://www.kaggle.com/cactus3/basicshapes
b'Billboard 1964-2015 Songs + Lyrics',b'50 years of pop music lyrics',"b'Original Dataset Author : https://github.com/walkerkq\n\nFrom https://github.com/walkerkq/musiclyrics :\n\n# 50 Years of Pop Music Lyrics \n \nBillboard has published a Year-End Hot 100 every December since 1958. The chart measures the performance of singles in the U.S. throughout the year. Using R, I\xe2\x80\x99ve combined the lyrics from 50 years of Billboard Year-End Hot 100 (1965-2015) into one dataset for analysis. You can download that dataset [here](https://github.com/walkerkq/musiclyrics/blob/master/billboard_lyrics_1964-2015.csv).\n  \nThe songs used for analysis were scraped from Wikipedia\xe2\x80\x99s entry for each Billboard Year-End Hot 100 Songs (e.g., 2014). This is the year-end chart, not weekly rankings. Many artists have made the weekly chart but not the final year end chart. The final chart is calculated using an inverse point system based on the weekly Billboard charts (100 points for a week at number one, 1 point for a week at number 100, etc).\n  \nI used the xml and RCurl packages to scrape song and artist names from each Wikipedia entry. I then used that list to scrape lyrics from sites that had predictable URL strings (for example, metrolyrics.com uses metrolyrics.com/SONG-NAME-lyrics-ARTIST-NAME.html). If the first site scrape failed, I moved onto the second, and so on. About 78.9% of the lyrics were scraped from metrolyics.com, 15.7% from songlyrics.com, 1.8% from lyricsmode.com. About 3.6% (187/5100) were unavailable.\n  \nThe dataset features 5100 observations with the features rank (1-100), song, artist, year, lyrics, and source. The artist feature is fairly standardized thanks to Wikipedia, but there is still quite a bit of noise when it comes to artist collaborations (Justin Timberlake featuring Timbaland, for example). If there were any errors in the lyrics that were scraped, such as spelling errors or derivatives like ""nite"" instead of ""night,"" they haven\'t been corrected.  \n\nFull analysis can be found [here](http://kaylinwalker.com/50-years-of-pop-music/).\n\n- [walkerkq](https://github.com/walkerkq)\n\n# Acknowledgements\n\nDataset is a mirror of : https://github.com/walkerkq/musiclyrics\nAll credits to gathering it goes to https://github.com/walkerkq\n\n\n# Inspiration\n\nWhat makes a song\'s lyrics popular ?'","b""['linguistics', 'music', 'small', 'featured']""",https://www.kaggle.com/rakannimer/billboard-lyrics
b'Countries of the World',"b'Country names linked to region, population, area size, GDP, mortality and more'","b'### Context\n\nWorld fact sheet, fun to link with other datasets.\n\n\n### Content\n\nInformation on population, region, area size, infant mortality and more.\n\n\n### Acknowledgements\n\n[Source:][1] All these data sets are made up of data from the US government. Generally they are free to use if you use the data in the US. If you are outside of the US, you may need to contact the US Govt to ask.\nData from the World Factbook is public domain. The website says ""The World Factbook is in the public domain and may be used freely by anyone at anytime without seeking permission.""    \nhttps://www.cia.gov/library/publications/the-world-factbook/docs/faqs.html   \n\n### Inspiration\n\nWhen making visualisations related to countries, sometimes it is interesting to group them by attributes such as region, or weigh their importance by population, GDP or other variables.\n\n\n  [1]: http://gsociology.icaap.org/dataupload.html'","b""['world', 'categorical data', 'countries', 'information', 'small', 'featured']""",https://www.kaggle.com/fernandol/countries-of-the-world
b'CITES Wildlife Trade Database',b'A year in the international wildlife trade',"b'### Context\n\nThe **Convention on International Trade in Endangered Species of Wild Fauna and Flora**, or **CITES** for short, is an international treaty organization tasked with monitoring, reporting, and providing recommendations on the international species trade. CITES is a division of the IUCN, which is one of the principal international organization focused on wildlife conversation at large. It is not a part of the UN (though its reports are read closely by the UN).\n\nCITES is one of the oldest conservation organizations in existence. Participation in CITES is voluntary, but almost every member nation in the UN (and, therefore, almost every country worldwide) participates. Countries participating in CITES are obligated to report on roughly 5000 animal species and 29000 plant species brought into or exported out of their countries, and to honor limitations placed on the international trade of these species.\n\nProtected species are organized into three appendixes. Appendix I species are those whose trade threatens them with extinction. Two particularly famous examples of Class I species are the black rhinoceros and the African elephant, whose extremely valuable tusks are an alluring target for poachers exporting ivory abroad. There are 1200 such species. Appendix II species are those not threatened with extinction, but whose trade is nevertheless detrimental. Most species in cites, around 21000 of them, are in Appendix II. Finally, Appendix III animals are those submitted to CITES by member states as a control mechanism. There are about 170 such species, and their export or import requires permits from the submitting member state(s).\n\nThis dataset records all <i>legal</i> species imports and exports carried out in 2016 (and a few records from 2017) and reported to CITES. Species not on the CITES lists are not included; nor is the significant, and highly illegal, ongoing black market trading activity.\n\n### Content\n\nThis dataset contains records on every international import or export conducted with species from the CITES lists in 2016. It contains columns identifying the species, the import and export countries, and the amount and characteristics of the goods being traded (which range from live animals to skins and cadavers).\n\nFor further details on individual rows and columns refer to the metadata on the `/data` tab. A much more detailed description of each of the fields is available in the [original CITES documentation](https://trade.cites.org/cites_trade_guidelines/en-CITES_Trade_Database_Guide.pdf).\n\n### Acknowledgements\n\nThis dataset was originally aggregated by CITES and made available online through [this downloader tool](https://trade.cites.org/en/cites_trade/#). The CITES downloader goes back to 1975, however it is only possible to download fully international data two years at a time (or so) due to limitations in the number of rows allowed by the data exporter. If you would like data going further back, check out the downloader. Be warned, though, this data takes a long time to generate!\n\nThis data is prepared for CITES by UNEP, a division of the UN, and hence likely covered by the [UN Data License](http://data.un.org/Host.aspx?Content=UNdataUse).\n\n### Inspiration\n\n* What is the geospatial distribution of the international plant/animal trade?\n* How much export/import activity is there for well-known species, like rhinos, elephants, etcetera?\n* What percent of the trade is live, as opposed to animal products (ivory, skins, cadavers, etcetera)?'","b""['animals', 'environment', 'international relations', 'plants', 'small', 'featured']""",https://www.kaggle.com/cites/cites-wildlife-trade-database
b'Tweets during Real Madrid vs Liverpool ',b'2018 UEFA Champions League Final #UCLFinal',"b""### Context\n\nData set containing Tweets captured during the **2018 UEFA Champions League Final** between **Real Madrid** and **Liverpool**. \n\n### Content\n\n All Twitter APIs that return Tweets provide that data encoded using JavaScript Object Notation (JSON). **JSON** is based on key-value pairs, with named attributes and associated values. The JSON file include the following objects and attributes: \n\n* **[Tweet](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object)** - Tweets are the basic atomic building block of all things Twitter. The Tweet object has a long list of \xe2\x80\x98root-level\xe2\x80\x99 attributes, including fundamental attributes such as `id`, `created_at`, and `text`. Tweet child objects include `user`, `entities`, and `extended_entities.` Tweets that are geo-tagged will have a `place` child object.\n\n    + **[User](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/user-object)** - Contains public Twitter account metadata and describes the author of the Tweet with attributes as `name`, `description`, `followers_count`, `friends_count`, etc.\n\n    + **[Entities](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/entities-object)** - Provide metadata and additional contextual information about content posted on Twitter. The `entities` section provides arrays of common things included in Tweets: hashtags, user mentions, links, stock tickers   (symbols), Twitter polls, and attached media.\n\n    + **[Extended Entities](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/extended-entities-object)** - All Tweets with attached photos, videos and animated GIFs will include an `extended_entities` JSON object.\n\n    + **[Places](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/geo-objects)** - Tweets can be associated with a location, generating a Tweet that has been \xe2\x80\x98geo-tagged.\xe2\x80\x99 \n\nMore information [here](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json). \n\n### Acknowledgements\n\nI used the `filterStream()` function to open a connection to Twitter's Streaming API, using the keyword **#UCLFinal**.\nThe capture started on **Saturday, May 27th 6:45 pm UCT** (beginning of the match) and finished on **Saturday, May 27th 8:45 pm UCT**.\n\n### Inspiration\n\n- Time analysis\n- Try text mining!\n- Cross-language differences in Twitter\n- Use this data to produce a sentiment analysis\n- Twitter geolocation\n- Network analysis: graph theory, metrics and properties of the network, community detection, network visualization, etc.""","b""['data visualization', 'sports', 'text mining', 'twitter', 'network analysis', 'medium', 'featured']""",https://www.kaggle.com/xvivancos/tweets-during-r-madrid-vs-liverpool-ucl-2018
b'Every Cryptocurrency Daily Market Price',"b'Daily crypto markets open, close, low, high data for every token ever'","b""# Cryptocurrency Market Data\n## Historical Cryptocurrency Prices For ALL Tokens!\n\n### **Summary**\n\t&gt; Observations: 758,534\n\t&gt; Variables: 13  \n\t&gt; Crypto Tokens: 1,584\n\t&gt; Start Date: 28/04/2017  \n\t&gt; End Date: 21/05/2018  \n  \n### **Description**\n   All historic open, high, low, close, trading volume and market cap info for all cryptocurrencies.  \n\n   I've had to go over the code with a fine tooth comb to get it compatible with CRAN so there have been significant enhancements to how some of the field conversions have been undertaken and the data being cleaned. This should eliminate a few issues around number formatting or unexpected handling of scientific notations.  \n  \n### **Data Structure**\n    Observations: 649,051    \n    Variables: 13    \n    $ slug        ""","b""['finance', 'internet', 'business', 'medium', 'featured']""",https://www.kaggle.com/jessevent/all-crypto-currencies
b'Dutch Single Speaker Speech Dataset',b'CSS10 Dutch: Single Speaker Speech Dataset',"b'### Context\n\nCSS10 is a collection of single speaker speech datasets for 10 languages. Each of them consists of audio files recorded by a single volunteer and their aligned text sourced from LibriVox.\n\n### Content\nEach line in `transcript.txt` is delimited by `|` into four fields, i.e., audio file location, original script, normalized script, and audio duration.\n\nVisit [here](https://github.com/kyubyong/css10) to check out our project using this dataset.\n\n### Acknowledgements\n\nWe thank LibriVox and the volunteers.\n \n### Contact\nYou can contact me at kbpark.linguist@gmail.com.\n\nJune, 2018.\n\nKyubyong Park & Tommy Mulc\n'","b""['linguistics', 'large', 'featured']""",https://www.kaggle.com/bryanpark/dutch-single-speaker-speech-dataset
b'New York City Complaint Problems',b'From New York City Open Data',"b""### Content  \n\nContains information about problems associated with complaints.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/iUOVU02fbSA) by [Wolfgang Lutz](https://unsplash.com/@wolfi) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/new-york-city-complaint-problems
b'Chicago Micro-Market Recovery Program Data',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/FtutC3NqiMI) by [Stuart Guest-Smith](https://unsplash.com/@sguestsmith) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-micro-market-recovery-program-data
b'HackerRank Developer Survey 2018',"b'Survey of 25,000 professionals and students on the state of developer skills'","b'### Context\n\nWe at HackerRank (https://www.hackerrank.com) are passionate about ensuring that developers and companies can find each other and that the best matches are made.  Our platforms, for the community and recruiting, are built to create the best experience for all involved.\n\nWe have over the years built a very strong global community of developers. In order to provide more transparency for ourselves and the world on the state of developers, we conducted a survey of our developers late in 2016. We got an astounding 25K responses! The survey asked developers many questions around their skills, educational background, current role, and more. We provided a high-level report of our findings from this survey earlier this year (see acknowledgements below).\n\nWe have since focused more on understanding trends about women pursuing careers as developers. On March 1 we released our high-level report on our findings. This report is based on survey responses from professional developers (14K developers, which includes hiring managers), and it is available here: [Women In Tech 2018][1]\n\nThe data set we are releasing here is the full dataset of 25K responses from our developer survey, which includes both students and professionals. The  [Women In Tech 2018][1] report uses only the 14K responses from professionals.\n\n### Content\n\nThe data consists of five files:\n\n 1. `HackerRank-Developer-Survey-2018-Codebook.csv`: a CSV file with survey schema. This schema includes the questions that correspond to each column name in `HackerRank-Developer-Survey-2018-Numeric.csv` and `HackerRank-Developer-Survey-2018-Values.csv`.   It also provides extra notes on questions if they were conditionally shown, or what the correct answer was to a coding question.\n 2. `HackerRank-Developer-Survey-2018-Numeric-Mapping.csv`: This file provides the mapping from the numeric values in `HackerRank-Developer-Survey-2018-Numeric.csv` and what their textual representation in the survey was.  Each row represents one of the possible answers to a specific question, with a mapping of the numeric answer in the data file to the textual label in the survey.\n 3. `Country-Code-Mapping.csv`: a CSV file that provides the mapping of the numeric country code in our raw data in `HackerRank-Developer-Survey-2018-Numeric.csv` to the associated country.\n 4. `HackerRank-Developer-Survey-2018-Numeric.csv`: a CSV file with the raw survey responses. Each row is one respondent, including an anonymous respondent id, the timestamp of when the survey was started and ended, and the numeric responses to each question. This is the data file that we used for our analysis.\n 5. `HackerRank-Developer-Survey-2018-Values.csv`: a CSV file with the text version of the survey responses. Each row is one respondent, including an anonymous respondent id, the timestamp of when the survey was started and ended, and the textual response to each question. This file was derived from `HackerRank-Developer-Survey-2018-Numeric.csv` using the mapping files that are included in this data set. We provide it for ease of use for those who prefer to work directly with the text values.\n\n\n### Methodology\n\n - A total of 25,090 professional and student developers completed our 10-minute online survey. \n - The survey was live from October 16 through November 1, 2017.\n - The survey was hosted by SurveyMonkey and we recruited respondents via email from our community of over 3.4 million members and through social media sites.\n - We removed responses that were incomplete as well as obvious spam submissions.\n - Not every question was shown to every respondent, as some questions were specifically for those involved in hiring. The codebook (`HackerRank-Developer-Survey-2018-Codebook.csv`) highlights under what conditions some questions were shown.\n - The [Women In Tech 2018][1] report is based only on the 14K responses from professionals\n    - Respondents who identified as students (`q8Student=1`; N=10351) were excluded from this report.\n    - Respondents who identify as \xe2\x80\x9cnon-binary\xe2\x80\x9d (`q3Gender=3`; N=76) were excluded from the male-female comparisons.\n\n### Acknowledgements\n\nThe data set we are releasing is based on the [Developer Skills][2] survey and report we released earlier this year. We did not release the data set then, so here it is!\n\n### Inspiration for March 2018\n\nThe goal of releasing this data set is the focus on supporting women in tech.  The engagement and response that we got in the Developer Skills Report was phenomenal.  We next wanted to focus on the nearly 2,000 women who responded to the survey to get a pulse on the state of being a woman in technology today. What languages are they learning, how they learn, and what\xe2\x80\x99s their career growth like. We thought doing this analysis might help expose some important trends to the world.\n\nWe encourage data scientists to look at our [Women In Tech 2018][1] report to see some of our high level findings.  We did not look at any of the text-based answers (when selecting ""other"" to any of our questions), focusing specifically on the answers that fell within the choices we provided.\n\nTo build on the analysis started in our Women in Tech report, consider exploring any of the following questions:\n\n - How are responses from students different from professionals?  Is there anything we can learn from their different priorities or preferences?\n - Are there interesting deeper analysis of the \'other\' roles that were input beyond the ones we categorized in the survey?\n - What trends we can see by looking at the different cohorts (beyond what we already outlined)?\n - Is there more to discover in trends of educational backgrounds, languages/frameworks known that we have not explored?\n - Are there important findings that are actionable in the community at large to continue to support women?\n\n  [1]: https://research.hackerrank.com/women-in-tech/2018/\n  [2]: https://research.hackerrank.com/developer-skills/2018/'","b""['data visualization', 'demographics', 'survey analysis', 'programming', 'women', 'small', 'featured']""",https://www.kaggle.com/hackerrank/developer-survey-2018
b'Annotated Named Entity Recognition Dataset',b'Named Entity Recognition Dataset to predict chemical entities',"b'### Context\n\nThis corpus is extracted from [CHEMDNER corpus][1]. Getting started with CHEMDNER corpus to extract chemical named entities in IOB annotations is tricky and tedious task. This is to avoid data pre-processing and provide tokens extracted using Chemical Tokenizer ([ChemTok: A New Rule based Tokenizer for Chemical Named Entity Recognition][2]).\n\n### Content\n\nThis corpus is divided into training, validation and evaluation. All of them contains tokens extracted using ChemTok applied on CHEMDNER corpora in IOB annotation. File contains the following content.\n\n- PMID_Type: PMID is Public Medical Identifier and Type is the Type of Medical Text i.e., Title (T) or Abstract(A).\n- Sentence_Index: It is the sentence index of each sentence in Medical text.\n- Token: It is the token extracted using ChemTok from each given sentence.\n- Tag: It is an IOB annotation given to the token.\n\n\nNOTE: Please refer README guide from the original corpora or links provided for in-depth information on this subject.\n\n\n### Acknowledgements\n\nKrallinger, M. et al. The CHEMDNER corpus of chemicals and drugs and its annotation principles. J Cheminform, 2014\n\n\n\n  [1]: http://www.biocreative.org/resources/biocreative-iv/chemdner-corpus/\n  [2]: https://www.researchgate.net/publication/292208132_ChemTok_A_New_Rule_Based_Tokenizer_for_Chemical_Named_Entity_Recognition'","b""['linguistics', 'small', 'featured']""",https://www.kaggle.com/abhinavwalia95/chemdner-iob-annotated-chemical-named-etities
b'Russian Presidental Elections 2018 Voting Data',b'This dataset consists of public voting data given by regional CECs.',"b""### Context\n\nRussian elections are considered to be rigged. To test this hypothesis we scraped data about last presidental elections.\n\n### Content\n\nThis dataset contains data about 2018 presidental elections in Russian Federation. Data was scraped from regional election commitees websites. [This](http://www.vybory.izbirkom.ru/region/izbirkom?action=show&root_a=12000009&vrn=100100084849062\xc2\xaeion=0&global=true&type=0&prver=0&pronetvd=null) is the root website from which you can access any regional EC. Each row represents polling station and have various information about ballot papers and, of course, number of votes given for each candidate.  Polling station id is not unique across all dataset, but it is unique across every region.\nDataset is given in two versions - English, with region names transliterated and columns translated, and Russian.\n\n\n### Acknowledgements\n\nWe were inspired by following papers:\n\n - **A Guide to Election Forensics** by Hicken, Allen and Mebane Jr, Walter R\n - **Testing for voter rigging in small polling stations** by Jimenez, Ra'ul and Hidalgo, Manuel and Klimek, Peter\n - **Election forensics: Vote counts and Benford\xe2\x80\x99s law** by Mebane Jr, Walter R\n - **When Does the Second-Digit Benford\xe2\x80\x99s Law-Test Signal an Election Fraud?** by Shikano, Susumu and Mack, Verena\n - **Statistical detection of systematic election irregularities** by Klimek, Peter and Yegorov, Yuri and Hanel, Rudolf and Thurner, Stefan\n\n### Inspiration\n\nIs it true, that this elections were rigged? How polling station proximity influences the voting process? Can outliers can be detected using this proximity?""","b""['politics', 'geospatial analysis', 'russia', 'political science', 'forensics', 'small', 'featured']""",https://www.kaggle.com/valenzione/russian-presidental-elections-2018-voting-data
b'ACLED Middle East and South East Asia',"b'Middle East ,South East Asia and South Asia Conflicts 2015-2018'","b'### Context\n\nArmed Conflict Location & Event Data Project (ACLED) is a disaggregated conflict collection, analysis and crisis mapping project.  ACLED\xe2\x80\x99s aim is to capture the forms, actors, dates and locations of political violence and protest as it occurs across states. The ACLED team conducts analysis to describe, explore and test conflict scenarios, and makes both data and analysis open to freely use by the public.                 \n\n\n### Content\n\nThis has Conflicts data from 2015 to April 2018.  ACLED collects the dates, actors, types of violence, locations, and fatalities of all reported political violence and protest events across Africa, South Asia, South East Asia and the Middle East. Political violence and protest includes events that occur within civil wars and periods of instability, public protest and regime breakdown.                  \n\n\n### Acknowledgements\n\nThe team at [ACLED](https://www.acleddata.com/about-acled/)                         \nPhoto by Sven Scheuermeier on Unsplash               \n\n\n### Inspiration\n\nAnalyse the conflicts in Asia and provide insights on how to solve them                    \nGo beyond analysis and engage with groups and society to make a **larger impact**            \n'","b""['politics', 'terrorism', 'medium', 'featured']""",https://www.kaggle.com/ambarish/acled-middle-east-and-south-east-asia
b'SF Campaign Finance Data',b'From San Francisco Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License""","b""['socrata', 'finance', 'ethics', 'medium', 'featured']""",https://www.kaggle.com/san-francisco/sf-campaign-finance-data
b'DeepTriage',b'A dataset for automated Google Chromium bug triaging',"b'### Context\n\nFrom the DeepTriage abstract:\n\nFor a given software bug report, identifying an appropriate developer who could potentially fix the bug is the primary task of a bug triaging process. A bug title (summary) and a detailed description is present in most of the bug tracking systems. Automatic bug triaging algorithm can be formulated as a classification problem, which takes the bug title and description as the input, mapping it to one of the available developers (class labels). The major challenge is that the bug description usually contains a combination of free unstructured text, code snippets, and stack trace making the input data highly noisy. In the past decade, there has been a considerable amount of research in representing a bug report using tf-idf based bag-of-words feature (BOW) model. However, BOW model do not consider the syntactical and sequential word information available in the descriptive sentences.\n\nIn this research, we propose a novel bug report representation algorithm using an attention based deep bidirectional recurrent neural network (DBRNN-A) model that learns a syntactic and semantic feature from long word sequences in an unsupervised manner. Instead of BOW features, the DBRNN-A based robust bug representation is then used for training the classification model. Further, using an attention mechanism enables the model to learn the context representation over a long word sequence, as in a bug report. To provide a large amount of data to learn the feature learning model, the unfixed bug reports (constitute about 70% bugs in an open source bug tracking system) are leveraged upon as an important contribution of this research, which were completely ignored in the previous studies.\n\nAnother major contribution is to make this research reproducible by making the source code available and creating a public benchmark dataset of bug reports from three open source bug tracking system: Google Chromium, Mozilla Core, and Mozilla Firefox. For our experiments, we use 383,104 bug reports from Google Chromium, 314,388 bug reports from Mozilla Core, and 162,307 bug reports from Mozilla Firefox. Experimentally we compare our approach with BOW model and softmax classifier, support vector machine, naive Bayes, and cosine distance and observe that DBRNN-A provides a higher rank-10 average accuracy.\n\n### Content\n\nThis dataset contains the bug data for Google Chromium with four different training sets and one test set.\n\n- **classifier_data_0.csv** is a version of training data with no minimum number of occurrences for any class (most unbalanced).\n\n- **classifier_data_5.csv** contains a version of the training data where every class occurs at least 5 times.\n\n- **classifier_data_10.csv** contains a version of the training data where every class occurs at least 10 times.\n\n- **classifier_data_20.csv** contains a version of the training data where every class occurs at least 20 times. (most balanced)\n\n- **deep_data.csv** contains the test data.\n\n*In this data, the classes are the owners.\n\n### Acknowledgements\n\nDeepTriage: Exploring the Effectiveness of Deep Learning for Bug Triaging. Senthil Mani, Anush Sankaran, Rahul Aralikatte, IBM Research, India.\n\nThe dataset, code and paper can be found at this webpage:\nhttp://bugtriage.mybluemix.net/'","b""['medium', 'featured']""",https://www.kaggle.com/crawford/deeptriage
b'Seattle Pet Licenses',b'Pet licenses issued by the Seattle Animal Shelter between 2005 and early 2017',"b""## Context\n\nThe city of Seattle makes available its database of pet licenses issued from 2005 to the beginning of 2017 as part of the city's ongoing [Open Data Initiative](https://data.seattle.gov/). The data is also obtainable from the [Socrata Open Data Access (SODA)](https://data.seattle.gov/Community/Seattle-Pet-Licenses/jguv-t9rb) portal in either CSV or JSON formats. It is also made available here (unofficially, I have no official affiliation with the city of Seattle or the Seattle Animal Shelter) to help spread awareness of the dataset and Seattle's Pet Licensing initiative.\n\n## Content\n\n### Seattle Pet Licenses Dataset\n\nThe data set contains information on licenses issued as far back as 2005 to the end of January 2017. \n\n**Dataset Columns:**\n\n* License Issue Date: Floating Timestamp\n  - Date and time of when the pet license was issued.\n* License Number: Integer\n  - Unique ID for each issued license.\n* Animal's Name: String\n  - Name of the licensed pet.\n* Species: String\n  - Species of the licensed pet. Will be either 'Dog,' 'Cat,' or 'Livestock.'\n* Primary Breed: String\n  - Primary breed of the licensed pet.\n* Secondary Breed: String\n  - Secondary breed (if any) of the licensed pet.\n\n### Washington Zip Codes Tax Returns by Income Bracket\n\nAs part of an analysis done to see if there is a relationship between the volume of pet licenses and the affluence of the particular area, the data also includes the [Statistics of Income 2015 dataset](https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-2015-zip-code-data-soi) that features the number of tax returns received by the IRS from each Seattle zip code broken out by several income brackets. The uploaded data represents a clean set of data for analysis use.\n\n## Acknowledgements\n\nThe Seattle Pet Licenses dataset was compiled by the City of Seattle Department of Finance and Administrative Services through the city of Seattle's Open Data initiative, and all credit goes to the original creators and maintainers of the data, the [Seattle Animal Shelter](http://www.seattle.gov/animalshelter). I am merely trying to make the data available to a broader audience to help spread awareness.\n\nThe [Statistics of Income (SOI) dataset](https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi) is owned and maintained by the IRS. The data presented here is a clean representation of the Washington Zip Code SOI 2015 dataset.\n\n## Inspiration\n\nThe dataset shows there were almost no pets licensed from 2005 up until mid-2014 when volume began rising drastically, for reasons as yet unknown (in that I wasn't able to find any sources mentioning any news that would cause such a significant increase). There also appears to be a massive disparity in the number of dogs licensed compared to cats, even though there are approximately 5 million more owned cats in the United States over dogs. Thus, I hope that by making this data more available, users who analyze the data can find insights and recommendations for the Seattle Animal Shelter to increase pet licensing numbers and help show pet owners who haven't licensed their pets why it is essential.\n\n## Extra\n\nAn [analysis of the Seattle Pet Licenses dataset](https://aaronschlegel.me/extract-analyze-seattle-pet-licenses-dataset.html) with Python can also be found on my website.\n\n## About Seattle Pet Licenses\n\nThe [city of Seattle requires pets over eight weeks old be licensed](https://library.municode.com/wa/seattle/codes/municipal_code?nodeId=TIT9AN_CH9.25ANCO_9.25.050ANLIPEGE). There are several benefits to [licensing one's pet](https://www.seattle.gov/animal-shelter/license), including a return ride home if your pet is lost, and easier contact from a veterinarian if your pet is unfortunately injured. If the licensing is performed at the Seattle Animal Shelter on the third Saturday of any given month, a free rabies vaccine is included, as well as other vaccines and a microchip for a small additional fee.""","b""['time series', 'animals', 'small', 'featured']""",https://www.kaggle.com/aaronschlegel/seattle-pet-licenses
b'Total Public Construction Spending Data',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/we1ky8_ZTHg) by [Bryan Goff](https://unsplash.com/@bryangoffphoto) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/total-public-construction-spending-data
b'Seattle Police Stops',b'From City of Seattle Open Data',"b""### Content  \n\nThis data represents records of police reported stops under Terry v. Ohio, 392 U.S. 1 (1968). Each row represents a unique stop. \n\n- Each record contains perceived demographics of the subject, as reported by the officer making the stop and officer demographics as reported to the Seattle Police Department, for employment purposes. \n\n- Where available, data elements from the associated Computer Aided Dispatch (CAD) event (e.g. Call Type, Initial Call Type, Final Call Type) are included.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ZYfLkRgZJQk) by [Marina Vitale](https://unsplash.com/@marina_mv88) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-terry-stops
b'Stamp Verification (StaVer) Dataset',b'Can you segment and parse stamps on documents?',"b'### Context: \n\nAn automatic system for stamp segmentation and further verification is needed especially for environments like insurance companies where a huge volume of documents is processed daily. However, detection of a general stamp is not a trivial task as it can have different shapes and colors and, moreover, it can be imprinted with a variable quality and rotation. This dataset was collected to help researchers build such a system.\n\n### Content: \n\nThis dataset contains 400 scanned document images. The documents are automatically generated invoices that were printed, stamped and scanned with 200 dpi resolution. They include color logos and color texts which makes the evaluation results more realistic. There are stamps of many different shapes and colors including black ones in the data set, sometimes the stamps are overlapped with signatures or a text. In some documents there are multiple stamps or none at all. The groundtruth consists of binary images with masks of the stamp strokes which allows for accurate pixel-wise evaluation.\nThis dataset contains the following folders, each with 400 items (one for each image):\n\n* **scans**: scans of the stamped genuine documents\n* **ground-truth-maps**: maps defining the region of the stamp(s)\n* **ground-truth-pixel**:    pixel-level ground truth\n* **info**: contains text files with the info for each file. Each info file contains the following information:\n    * signature   [0|1]: signature present [0] or not [1]\n    * textOverlap [0|1]: stamps overlap with printed text [1]\n    * numStamps   [0|...|n]: number of stamps on the page\n    * bwStamp[1|...|n]:  stamp[1|...|n] is black stamp [1] or colored [1]\n\nIn addition, there is a .pdf file will all the images in one file. The complete dataset (including scans with higher resolution) [can be found here](http://madm.dfki.de/downloads-ds-staver). \n\n### Acknowledgements: \n\nThis dataset was collected by Barbora Micenkova\xc2\xb4 and Joost van Beusekom. If you use this dataset in your work, please cite the following paper: \n\nMicenkov, B., & van Beusekom, J. (2011, September). Stamp detection in color document images. In Document Analysis and Recognition (ICDAR), 2011 International Conference on(pp. 1125-1129). IEEE.\n\n### Inspiration: \n\n* Can you segment just the stamps from the background text?\n* Can you use OCR techniques to identify the stamped text?'","b""['image data', 'image processing', 'large', 'featured']""",https://www.kaggle.com/rtatman/stamp-verification-staver-dataset
b'NYS Registered Lobbyist Disclosures',b'From New York State Open Data',"b""### Content  \n\nData provided by Lobbyist in their Biennial Registration and Bi-monthly filings submitted to NYS Joint Commission on Public Ethics  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/BYuttXWcLhc) by [Elena Sarahova](https://unsplash.com/@eessoo) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-registered-lobbyist-disclosures
b'CMS State Summary of Inpatient Charge Data',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain, NA""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/cms-state-summary-of-inpatient-charge-data
b'Seattle Underground Storage Tank (UST) Records',b'From City of Seattle Open Data',"b""### Content  \n\nRecords of Seattle Fire Department (SFD) permits related to decommissioning of a residential heating oil tank, permit code 6103.  A record with incomplete tank info indicates that the required follow-up report has not been received by SFD.  Please note that SFD records begin in 1996 when state requirement was introduced.  Decommissioning of a residential heating oil tank might have occurred prior to 1996, in which SFD will not have a record.\r\nCommercial UST records can be requested through City Public Records Request Center at http://www.seattle.gov/public-records/public-records-request-center  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/tA9L8odSv30) by [Brunel Johnson](https://unsplash.com/@brunels_world) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-underground-storage-tank-ust-records
b'SF Registered Business Locations - San Francisco',b'From San Francisco Open Data',"b""### Content  \n\nThis dataset includes the locations of businesses that pay taxes to the City and County of San Francisco. Each registered business may have multiple locations and each location is a single row. The Treasurer & Tax Collector\xe2\x80\x99s Office collects this data through business registration applications, account update/closure forms, and taxpayer filings. The data is collected to help enforce the Business and Tax Regulations Code including, but not limited to: Article 6, Article 12, Article 12-A, and Article 12-A-1. http://sftreasurer.org/registration  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/102abqkKhbY) by [Rezaul Karim](https://unsplash.com/@reza565) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'business', 'medium', 'featured']""",https://www.kaggle.com/san-francisco/sf-registered-business-locations-san-francisco
b'Nice Ride Minnesota 2017',b'Bike sharing trip and station data from Nice Ride MN for the 2017 year',"b""### Context\n\nBicycle ride-sharing systems have become increasingly popular in major cities.  They allow people to enjoy biking around the city without investing in buying a bike for themselves, by providing affordable bike rentals.  Here in the twin cities (Minneapolis/St. Paul, MN) we have the bike-sharing nonprofit [Nice Ride MN](https://www.niceridemn.org/).  Customers can rent bikes at stations, each of which has docks for several bikes, and are scattered throughout the cities.  Customers can then bike around, and return their bike at any other station (providing there's an empty dock for it).  Nice Ride MN provides public access to their historical data [here](https://www.niceridemn.org/data/).  This dataset contains Nice Ride MN's data from the 2017 year.  The data is published under the [Nice Ride Minnesota Data License Agreement](https://www.niceridemn.org/data_license/).  This dataset also contains daily weather data for the 2017 year from [NOAA](https://www.ncdc.noaa.gov/cdo-web/).\n\n\n### Content\n\nThe dataset contains three CSV files.\n\n**Nice_Ride_2017_Station_Locations.csv** contains information about each station, including location (latitude and longitude), the number of bike docks at that station, and the name of the station.  There is one row per station, and 202 stations in the file.\n\n**Nice_ride_trip_history_2017_season.csv** contains information about each trip in the 2017 year, including the start and end stations, start and end times/dates, the account type of the renter (member/non-member), and the duration of the trip.  There is one row per trip/rental, and 460718 trips in the file.\n\n**WeatherDailyMinneapolis2017.csv** contains daily weather information for Minneapolis/St. Paul.  Each row is a day, and columns include daily high temperature, daily low temperature, and precipitation.\n\n\n### Acknowledgements\n\nAll the ride share data was collected, cleaned, and put together by [Nice Ride MN](https://www.niceridemn.org/).  I'm just uploading it to Kaggle.\n\nThe weather data was downloaded from [NOAA's National Centers for Environmental Information](https://www.ncdc.noaa.gov/cdo-web/).\n\n### Inspiration\n\n- Do the number of docks at each station match the demand at those stations?  Could the number of docks be more optimally distributed?\n- How does riding activity depend on weather?\n- Is there a seasonal dependence of bike demand independent of weather?\n- How do riding patterns differ between members and non-members?  At which stations would it be optimal to place ads for Nice Ride membership?\n- How well can one predict the demand at each station?  \n- How well can one optimize the re-allocation of bikes from full, low-demand stations to empty, high-demand stations?\n- When is the earliest time to start the season, or the latest time to end, without a high risk of incurring a loss for Nice Ride MN?""","b""['weather', 'cycling', 'small', 'featured']""",https://www.kaggle.com/brendanhasz/nice-ride-mn-2017
b'OECD Consumer Price Index of All Items',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/h0xKqdDPLaE) by [Genevieve Perron-Migneron](https://unsplash.com/@gen035) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/oecd-org/oecd-consumer-price-index-of-all-items
b'Jaipur Weather Forecasting',b'Rain Prediction for Dry Regions',"b""### Context\n\nI have gathered this dataset for a specific reason. As I was participating in a hackathon and didn't find any suitable dataset from which I can predict the rainfall of a dry region. Which helps farmer ultimately for growing crops. You can connect me on [LinkedIn][1]\n\n### Content\n\nThe Dataset is fully dedicated for the developers who want to train the model on **Weather Forecasting** of *India Specific Region*. This dataset provides the data from **1st May 2016 to 11 March 2018** of the specific city i.e **Jaipur** in India.\nI have used this dataset to train a Neural Network which gives an accuracy of 90% for weather forecasting. Which you can find on my [Github Profile][2].\n\n### Inspiration\n\nThis dataset is for the one who wants to develop a model to help farmer for saving from huge losses during cultivation time to know about the rainfall from days before. And take respective measures.\n\n\n  [1]: https://www.linkedin.com/in/rajat-/\n  [2]: https://github.com/Rajat-dey""","b""['weather', 'climate', 'india', 'forecasting', 'agriculture', 'small', 'featured']""",https://www.kaggle.com/rajatdey/jaipur-weather-forecasting
b'Cryptocoins Historical Prices',b'A collection of prices for cryptocurrencies ',"b'## Introduction ##\nThis file contains the values of the price for more than 1000 different cryptocurrencies (including scams) recorded on daily base, I decide to include all coins in order to analyze exotic coins and compare with well knows cryptocurrencies.\nAll this dataset come from  [coinmarketcap](https://coinmarketcap.com/)  historical pages, grabbed using just an R script. \nThanks coinmarketcap to making this data available for free (and for every kind of usage).\n\n## The dataset ##\nAvailable columns in the dataset:\n\n1. **Date** - the day of recorded values \n2. **Open** - the opening price (in USD)\n3. **High** - the highest price (in USD)\n4. **Low** - the lowest price (in USD)\n5. **Close** - the closing price (in USD)\n6. **Volume** - total exchanged volume (in USD)\n7. **Market.Cap** - the total market capitalization for the coin (in USD)\n8. **coin** - the name of the coin\n9. **Delta** - calculated as (Close - Open) / Open'","b""['medium', 'featured']""",https://www.kaggle.com/valeriovaccaro/cryptocoinshistoricalprices
b'Random Sample of NIH Chest X-ray Dataset',"b'5,606 images and labels sampled from the NIH Chest X-ray Dataset'","b'# NIH Chest X-ray Dataset Sample\n\n---\n\n### National Institutes of Health Chest X-Ray Dataset\n\nChest X-ray exams are one of the most frequent and cost-effective medical imaging examinations available. However, clinical diagnosis of a chest X-ray can be challenging and sometimes more difficult than diagnosis via chest CT imaging. The lack of large publicly available datasets with annotations means it is still very difficult, if not impossible, to achieve clinically relevant computer-aided detection and diagnosis (CAD) in real world medical sites with chest X-rays. One major hurdle in creating large X-ray image datasets is the lack resources for labeling so many images. Prior to the release of this dataset, [Openi][1] was the largest publicly available source of chest X-ray images with 4,143 images available.\n\nThis NIH Chest X-ray Dataset is comprised of 112,120 X-ray images with disease labels from 30,805 unique patients. To create these labels, the authors used Natural Language Processing to text-mine disease classifications from the associated radiological reports. The labels are expected to be >90% accurate and suitable for weakly-supervised learning. The original radiology reports are not publicly available but you can find more details on the labeling process in this Open Access paper: ""ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases."" (*Wang et al.*)\n\n[Link to paper][30]\n\n[1]: https://openi.nlm.nih.gov/\n\n\n<br>\n### File contents - This is a random sample (5%) of the full dataset:\n\n- **sample.zip**: Contains 5,606 images with size 1024 x 1024\n\n- **sample_labels.csv**: Class labels and patient data for the entire dataset\n    - Image Index: File name\n    - Finding Labels: Disease type (Class label)\n    - Follow-up # \n    - Patient ID\n    - Patient Age\n    - Patient Gender\n    - View Position: X-ray orientation\n    - OriginalImageWidth\n    - OriginalImageHeight\n    - OriginalImagePixelSpacing_x\n    - OriginalImagePixelSpacing_y\n   \n\n\n\n\n<br>\n### Class descriptions\n\nThere are 15 classes (14 diseases, and one for ""No findings"") in the full dataset, but since this is drastically reduced version of the full dataset, some of the classes are sparse with the labeled as ""No findings""\n\n- Hernia  - 13 images\n- Pneumonia  - 62 images\n- Fibrosis  - 84 images\n- Edema  - 118 images\n- Emphysema  - 127 images\n- Cardiomegaly  - 141 images\n- Pleural_Thickening  - 176 images\n- Consolidation  - 226 images\n- Pneumothorax  - 271 images\n- Mass  - 284 images\n- Nodule  - 313 images\n- Atelectasis  - 508 images\n- Effusion  - 644 images\n- Infiltration  - 967 images\n- No Finding - 3044 images\n\n<br>\n### Full Dataset Content\n\n[The full dataset can be found here][3]. There are 12 zip files in total and range from ~2 gb to 4 gb in size. \n\n\n[3]: https://www.kaggle.com/nih-chest-xrays/data\n\n\n<br>\n### Data limitations: \n\n1. The image labels are NLP extracted so there could be some erroneous labels but the NLP labeling accuracy is estimated to be >90%. \n2. Very limited numbers of disease region bounding boxes (See BBox_list_2017.csv)\n3. Chest x-ray radiology reports are not anticipated to be publicly shared. Parties who use this public dataset are encouraged to share their \xe2\x80\x9cupdated\xe2\x80\x9d image labels and/or new bounding boxes in their own studied later, maybe through manual annotation\n\n\n<br>\n### Modifications to original data\n\n- Original TAR archives were converted to ZIP archives to be compatible with the Kaggle platform\n\n- CSV headers slightly modified to be more explicit in comma separation and also to allow fields to be self-explanatory\n\n<br>\n### Citations\n\n- Wang X, Peng Y, Lu L, Lu Z, Bagheri M, Summers RM. ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases. IEEE CVPR 2017, [ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf][30]\n\n- NIH News release: [NIH Clinical Center provides one of the largest publicly available chest x-ray datasets to scientific community][30]\n\n- Original source files and documents: [https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345][31]\n\n<br>\n### Acknowledgements\n\nThis work was supported by the Intramural Research Program of the NClinical Center (clinicalcenter.nih.gov) and National Library of Medicine (www.nlm.nih.gov). \n\n\n  [30]: https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community\n\n  [31]: https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345'","b""['image data', 'healthcare', 'multiclass classification', 'health', 'biotechnology', 'large', 'featured']""",https://www.kaggle.com/nih-chest-xrays/sample
b'Reddit Memes Dataset',b'A collection of the latest memes from the various meme subreddits',"b'### Context\n\nLike memes and love procrastinating on Reddit? Well, this dataset is your chance to do both. :)\n\n\n### Content\n\nThe dataset contains the post ID, the image URL and the up/downvotes and other metadata for that particular meme. This should be a good starting point for common computer vision tasks. \n\n\n### Inspiration\n\nThe data was scraped as a weekend hack to predict the ""dankness"" score of a meme. The work in progress repository can be found here: [github:dankNotDank](https://github.com/Sayan98/dankNotDank)'","b""['internet', 'image data', 'reddit', 'medium', 'featured']""",https://www.kaggle.com/sayangoswami/reddit-memes-dataset
b'Chinese Single Speaker Speech Dataset',b'CSS10 Chinese: Single Speaker Speech Dataset',"b'### Context\n\nCSS10 is a collection of single speaker speech datasets for 10 languages. Each of them consists of audio files recorded by a single volunteer and their aligned text sourced from LibriVox.\n\n### Content\nEach line in `transcript.txt` is delimited by `|` into four fields, i.e., audio file location, original script, normalized script, and audio duration.\n\nVisit [here](https://github.com/kyubyong/css10) to check out our project using this dataset.\n\n### Acknowledgements\n\nWe thank LibriVox and the volunteers.\n \n### Contact\nYou can contact me at kbpark.linguist@gmail.com.\n\nJune, 2018.\n\nKyubyong Park & Tommy Mulc\n'","b""['linguistics', 'medium', 'featured']""",https://www.kaggle.com/bryanpark/chinese-single-speaker-speech-dataset
b'Did it rain in Seattle? (1948-2017)',"b'More than 25,000 consecutive days of Seattle weather data'","b'### Context: \n\nBesides coffee, grunge and technology companies, one of the things that Seattle is most famous for is how often it rains. This dataset contains complete records of daily rainfall patterns from January 1st, 1948 to December 12, 2017. \n\n### Content\n\nThis data was collected at the [Seattle-Tacoma International Airport](https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00024233/detail). The dataset contains five columns: \n\n* DATE = the date of the observation\n* PRCP = the amount of precipitation, in inches \n* TMAX = the maximum temperature for that day, in degrees Fahrenheit\n* TMIN = the minimum temperature for that day, in degrees Fahrenheit\n* RAIN = TRUE if rain was observed on that day, FALSE if it was not\n\n### Acknowledgements: \n\nThis dataset was compiled by NOAA and is in the public domain.\n\n### Inspiration: \n\n* Can you use this dataset to build a model of whether it will rain on a specific day given information on the previous days?\n* Is there a correlation between the minimum and maximum temperature? Can you predict one given the other?\n* Can you model changes in the amount of precipitation over time? Is there seasonality?  '","b""['weather', 'climate', 'united states', 'north america', 'small', 'featured']""",https://www.kaggle.com/rtatman/did-it-rain-in-seattle-19482017
b'Risk of being drawn into online sex work',b'Detecting individuals at risk using semi-supervised learning',"b'### Context\nThis database was used in the paper: [Covert online ethnography and machine learning for detecting individuals at risk of being drawn into online sex work.][1] 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), Barcelona, Spain, 28-31 August.\n\n\n### Content\nThe database includes data scraped from a European online adult forum. Using covert online ethnography we interviewed a small number of participants and determined their risk to either supply or demand sex services through that forum. This is a great dataset for semi-supervised learning. \n\n\n### Inspiration\n\nHow can we identify individuals at risk of being drawn into online sex work? The spread of online social media enables a greater number of people to be involved into online sex trade; however, detecting deviant behaviors online is limited by the low available of data. To overcome this challenge, we combine covert online ethnography with semi-supervised learning using data from a popular European adult forum.\n\n\n  [1]: https://ieeexplore.ieee.org/document/8508276'","b""['small', 'featured']""",https://www.kaggle.com/panoskostakos/online-sex-work
b'UW Madison Courses and Grades 2006-2017',"b'Courses, grades, instructors, and subjects at UW Madison since 2006.'","b'### Content\n\nThe University of Wisconsin - Madison publishes reports for all courses (and sections of these courses), instructors, subjects, and grade reports for each section for every Fall and Spring semester since 2006.\n\nThere are more than 9,000 courses in this dataset. There are nearly 200,000 course sections with grades, with 3 million grades reported in total. 18,000 instructors are included in the dataset, all of whom are associated with various sections that may or may not have grades reported for them.\n\nThe data was retrieved from the UW Madison registrar office, and extracted from PDF files using the open source tool, [madgrades-extractor][1].\n\n### Context\n\nThis dataset was made out of a desire to create a website which could make sense of the PDF grade report files published by my university. The final result was [Madgrades][2], an open source website and REST API designed to do just that. The website uses the same dataset published here but in SQL format, with some additional data generated in order to optimize for particular requests.\n\n### Acknowledgements\n\nThe [UW Madison registrar][3] graciously provides us with all this data for free! Indeed, public universities *are required* to offer this data to the public by law, but often times they will charge exorbitant fees (one university I contacted stated more than $1,000 for the same data).\n\n  [1]: https://github.com/madgrades/madgrades-extractor\n  [2]: https://madgrades.com\n  [3]: https://registrar.wisc.edu/grade-reports/'","b""['education', 'statistics', 'universities and colleges', 'medium', 'featured']""",https://www.kaggle.com/Madgrades/uw-madison-courses
b'SF SFO Gate and Stand Assignment Information',b'From San Francisco Open Data',"b""### Content  \n\nThis data provides information related to actual departure and arrival time of all airline flights arriving and departing out of assigned gates and stands at San Francisco International Airport.  Additional remarks for delayed or cancelled flight operations are included in this dataset. Airport finance and operations collects this data for statistical and billing purposes. The data starts 1/1/2015 and is updated monthly.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/achWgZn1ATc) by [Duncan Sparks](https://unsplash.com/@duncan_sprks) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'utility', 'medium', 'featured']""",https://www.kaggle.com/san-francisco/sf-sfo-gate-and-stand-assignment-information
b'AMAZON Job Skills',b'Software Development jobs ',"b'### Context\n\nI always wanted to know what qualifications are required for getting hired as a software developer in Amazon. So, I decided to do a small project, scraping Amazon job portal at https://amazon.jobs. So I scraped all of the job data from that site by going every job page using Selenium and BeautifulSoup packages. I only take Job Title, Job Location, Job posting date, Job responsibilities, minimum and preferred qualifications for Software Development role.\n\nI will put the Jupyter notebook including all my codes in my Github repository and everyone can extract the same info for other job roles at Amazon.\n\n### Content\n\nThis dataset is collected using Selenium and BeautifulSoup by scraping all of the jobs for Amazon job site. \n\nTitle: The title of the job\n\nlocation: Location of the job\n\nPosting_date : Posting date of the job\n\nDESCRIPTION: Overall description for the job\n\nBASIC QUALIFICATIONS: Minimum Qualifications for the job\n\nPREFERRED QUALIFICATIONS: Preferred Qualifications for the job\n\n### Acknowledgements\n\nThis dataset is collected using Selenium and BeautifulSoup packages. This product uses the Amazon job site.\n\n### Inspiration\n\n1)  You can find most popular skills for Amazon software development Jobs\n2) Create similar job posts\n3) Doing Data Visualization on Amazon jobs (My next step. Stay tuned!)'","b""['data visualization', 'feature engineering', 'databases', 'small', 'featured']""",https://www.kaggle.com/atahmasb/amazon-job-skills
b'Common Mobile/Web App Icons',b'A collection of scraped icon images from the web and mobile apps',"b""### Context\n\nTraining data for creating classifiers to recognize mobile/web app icons.\n\n\n### Content\n\nFirst rough draft of scraping icon images from the web and apps. There may be several misclassified icons in each subdirectory.\n\nFiles beginning with '_' are original images. Files beginning with '~' are augmented versions of the original.\n\n\n### Acknowledgements\n\nMany of the icons were scraped from the [Noun Project][1]\n\n\n  [1]: https://thenounproject.com""","b""['image data', 'mobile web', 'medium', 'featured']""",https://www.kaggle.com/testdotai/common-mobile-web-app-icons
"b'NYS Index, Violent, Property, and Firearm Rates'",b'From New York State Open Data',"b""### Content  \n\nThe Division of Criminal Justice Services (DCJS) collects crime reports from more than 500 New York State police and sheriffs\xe2\x80\x99 departments. DCJS compiles these reports as New York\xe2\x80\x99s official crime statistics and submits them to the FBI under the National Uniform Crime Reporting (UCR) Program. UCR uses standard offense definitions to count crime in localities across America regardless of variations in crime laws from state to state. In New York State, law enforcement agencies use the UCR system to report their monthly crime totals to DCJS. The UCR reporting system collects information on seven crimes classified as Index offenses which are most commonly used to gauge overall crime volume. These include the violent crimes of murder/non-negligent manslaughter, forcible rape, robbery, and aggravated assault; and the property crimes of burglary, larceny, and motor vehicle theft. Firearm counts are derived from taking the number of violent crimes which involve a firearm. Population data are provided every year by the FBI, based on US Census information. Police agencies may experience reporting problems that preclude accurate or complete reporting. The counts represent only crimes reported to the police but not total crimes that occurred.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/AsQs1AziQD4) by [Jordan Wiseman](https://unsplash.com/@jordanwiseman) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""","https://www.kaggle.com/new-york-state/nys-index,-violent,-property,-and-firearm-rates"
b'Data Science for Good: Kiva Crowdfunding',b'Use Kernels to assess welfare of Kiva borrowers for $30k in prizes',"b""[Kiva.org][1] is an online crowdfunding platform to extend financial services to poor and financially excluded people around the world. Kiva lenders have provided over $1 billion dollars in loans to over 2 million people. In order to set investment priorities, help inform lenders, and understand their target communities, knowing the level of poverty of each borrower is critical. However, this requires inference based on a limited set of information for each borrower.  \n\nIn Kaggle Datasets' inaugural [Data Science for Good][2] challenge, Kiva is inviting the Kaggle community to help them build more localized models to estimate the poverty levels of residents in the regions where Kiva has active loans. Unlike traditional machine learning competitions with rigid evaluation criteria, participants will develop their own creative approaches to addressing the objective. Instead of making a prediction file as in a supervised machine learning problem, submissions in this challenge will take the form of Python and/or R data analyses using Kernels, Kaggle's hosted Jupyter Notebooks-based workbench.\n\nKiva has provided a dataset of loans issued over the last two years, and participants are invited to use this data as well as source external public datasets to help Kiva build models for assessing borrower welfare levels. Participants will write kernels on this dataset to submit as solutions to this objective and five winners will be selected by Kiva judges at the close of the event. In addition, awards will be made to encourage public code and data sharing. With a stronger understanding of their borrowers and their poverty levels, Kiva will be able to better assess and maximize the impact of their work.\n\nThe sections that follow describe in more detail how to participate, win, and use available resources to make a contribution towards helping Kiva better understand and help entrepreneurs around the world.\n\n---\n\n\n## Problem Statement\n\nFor the locations in which Kiva has active loans, your objective is to pair Kiva's data with additional data sources to estimate the welfare level of borrowers in specific regions, based on shared economic and demographic characteristics. \n\nA good solution would connect the features of each loan or product to one of several poverty mapping datasets, which indicate the average level of welfare in a region on as granular a level as possible. Many datasets indicate the poverty rate in a given area, with varying levels of granularity. Kiva would like to be able to disaggregate these regional averages by gender, sector, or borrowing behavior in order to estimate a Kiva borrower\xe2\x80\x99s level of welfare using all of the relevant information about them. Strong submissions will attempt to map vaguely described locations to more accurate geocodes.\n\nKernels submitted will be evaluated based on the following criteria: \n\n**1. Localization** - How well does a submission account for highly localized borrower situations? Leveraging a variety of external datasets and successfully building them into a single submission will be crucial. \n\n**2. Execution** - Submissions should be efficiently built and clearly explained so that Kiva\xe2\x80\x99s team can readily employ them in their impact calculations. \n\n**3. Ingenuity** - While there are many best practices to learn from in the field, there is no one way of using data to assess welfare levels. It\xe2\x80\x99s a challenging, nuanced field and participants should experiment with new methods and diverse datasets.  \n\n---\n\n## How to Participate and [Make a Submission \xc2\xbb][3]\n\nTo be considered a participant in the Kiva Crowdfunding Data Science for Good Event, there are a few requirements: \n\n1. **[Everyone must register and accept the rules by filling out this form][10]** (you'll need to be logged into your Kaggle account to view the form). This ensures you're a participant and also means you'll receive update emails from us about key deadlines and announcements throughout the event. \n2. To submit a kernel for consideration in the main prize track, make sure it's public and **[submit it here][11]** (you'll need to be logged into your Kaggle account to view the form). [Read more details here][4]. \n3. To submit a kernel or dataset for consideration in the secondary prize track, all you need to do is make sure it's public and be a registered participant before the deadline. \n\n---\n\n## [Prizes and Eligibility \xc2\xbb][5] \n\nThere is a total prize pool of $30,000 split into two tracks:\n\n* Main prize track for the primary event objective: accurate and localized analyses or methods for assessing poverty levels. ($14,000; five winners total)\n* Upvoted kernels and popular datasets to encourage public sharing of code and data ($16,000; 12 winners total)\n\n**Main Prize Track**\n\nKiva will award $14,000 in total prizes to five winning authors who submit public kernels effectively tackling the objective by the deadline. These kernels must be submitted for consideration by May 15th, 2018. \n\n**Upvoted Kernels and Popular Datasets**\n\nThere is also a separate prize track for public sharing of code and data to encourage ongoing collaboration. Awards of $1,000 each will also be made to authors of the eight top most upvoted kernels. And four awards of $2,000 each will go to the datasets published with the most upvoted kernels used with the event data. \n\n[For more details about the prizes and eligibility click here][6]. \n\n---\n\n## Timeline\n\nAll dates are 11:59PM UTC:\n\n* **3 April 2018**: Kernels Award Announcement (Top 8 upvoted kernels)\n* **3 April 2018**: First Datasets Award Announcement (Top 2 most used data sources published on Kaggle)\n* **15 May 2018**: Challenge Deadline (Kernels for main prize must be submitted and made publicly available to be evaluated for a prize)\n* **22 May 2018:** Winners of the primary prize track will be announced and second datasets award announcement (Second top 2 most used data sources published on Kaggle)\n\n\n---\n\n## Rules\n\nTo be eligible to win a prize in either of the above prize tracks, you must be:\n\n* a registered account holder at Kaggle.com;\n* the older of 18 years old or the age of majority in your jurisdiction of residence;\n* not a resident of Crimea, Cuba, Iran, Syria, North Korea, or Sudan; and\n* not a person or representative of an entity under [U.S. export controls or sanctions][9].\n\nYour kernels and datasets will only be eligible to win if they have been made public on kaggle.com by the above deadline. All prizes are awarded at the discretion of Kiva, and Kiva reserves the right to cancel or modify prize criteria.  \n\nUnfortunately employees, interns, contractors, officers and directors of Kaggle Inc., and their parent companies, are not eligible to win any prizes.\n\n---\n\nPhoto by [Aaron Burden][7] on [Unsplash][8].\n\n\n  [1]: https://www.kaggle.com/kiva\n  [2]: http://blog.kaggle.com/2017/11/16/introducing-data-science-for-good-events-on-kaggle/\n  [3]: https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding/discussion/49867\n  [4]: https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding/discussion/49867\n  [5]: https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding/discussion/49839\n  [6]: https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding/discussion/49839\n  [7]: https://unsplash.com/photos/blPTIZuBhD8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\n  [8]: https://unsplash.com/search/photos/charity?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\n[9]: https://www.treasury.gov/resource-center/sanctions/Programs/Pages/Programs.aspx\n[10]: https://www.kaggle.com/data-science-for-good-kiva-crowdfunding-signup\n[11]: https://www.kaggle.com/data-science-for-good-kiva-crowdfunding-submission""","b""['finance', 'economics', 'geography', 'crowdfunding', 'lending', 'medium', 'featured']""",https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding
b'SF Spending and Revenue',b'From San Francisco Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/-8a5eJ1-mmQ) by [Sharon McCutcheon](https://unsplash.com/@sharonmccutcheon) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/san-francisco/sf-spending-and-revenue
b'SA & Victorian pet ownership data',b'Love animals? Have a crack at providing geographic insights on animal ownership!',"b'###Context...\nEver wondered the what and where of dog ownership? So have we!\n\n\n###Content...\nHave a look at a sample set of South Australian and Victorian animal registration data. Data is publicly available from the data.gov.au website under a creative commons licence. Information includes: breed, location, desexed and colour. Datasets are for the 2015, 2016 & 2017 periods (depending on availability).\nSA information has been consolidated in ~82,500 lines of data!\n\n\n###Acknowledgements...\n\nA big thank you to the SA and Victorian shires for having such great datasets!\n\n\n### Inspiration...\n\nWe love dogs and really want to understand the distribution of pets across SA and Victoria. We will leave it up to you the insights you want to create!'","b""['demographics', 'animals', 'australia', 'pets', 'small', 'featured']""",https://www.kaggle.com/puppygogo/sa-dog-ownership-sample
b'Mussel Watch',b'The longest running contaminant monitoring program in U.S. coastal waters',"b'The National Oceanic and Atmospheric Administration (NOAA) National Status and Trends (NS&T) Mussel Watch Program is a contaminant monitoring program that started in 1986. It is the longest running continuous contaminant monitoring program of its kind in the United States. Mussel Watch monitors the concentration of contaminants in bivalves (mussels and oysters) and sediments in the coastal waters of the U.S., including the Great Lakes, to monitor bivalve health and by extension the health of their local and regional environment.\n\nMussel Watch consults with experts to determine appropriate contaminants to monitor; these include dichlorodiphenyltrichloroethane (DDT), polycyclic aromatic hydrocarbons (PAHs), and polychlorinated biphenyls (PCBs). As of 2008, Mussel Watch monitors approximately 140 analytes. In addition to the effects of contaminants, Mussel Watch is able to assess the effects of natural disasters, such as the 2005 Hurricane Katrina, and environmental disasters, such as the 2010 Deepwater Horizon oil spill. Data collected by Mussel Watch can also be used to monitor the effectiveness of coastal remediation. The Mussel Watch Program utilized its 20 years of monitoring data to effectively analyze the impacts of Hurricane Katrina and has affected regulatory decisions based on the data it has collected on bivalve parasites.\n\nYou can find additional details about the history of the program here.\n\n## Data Notes\n - This version has been consolidated and lightly cleaned from its original format. \n -  It was not possible to acquire data for all sites in mussel watch while preparing the dataset.\n - The pdf manuals are technically for specific sites and may not map perfectly to the data here. You can find manuals specific to each site here if need be. \n\n\n## Acknowledgements\nThis dataset is the result of the work of generations of scientists working for NOAA. You can find [the original data here][1]. \n\n\n  [1]: https://products.coastalscience.noaa.gov/collections/ltmonitoring/nsandt/data2.aspx'","b""['pollution', 'ecology', 'medium', 'featured']""",https://www.kaggle.com/sohier/mussel-watch
b'Freesound Prediction Data',b'1-dimensional convolution on raw audio files ',b'Prediction Files for [Freesound General-Purpose Audio Tagging Challenge](https://www.kaggle.com/c/freesound-audio-tagging)',"b""['classification', 'deep learning', 'medium', 'featured']""",https://www.kaggle.com/fizzbuzz/freesound-prediction-file
b'The reddit self-post classification task',b'Classify reddit self-posts into over 1000 carefully selected categories',"b'###  Introduction\n\nWelcome to the Reddit Self-Post Classification Task (RSPCT)! \n\nThe aim of this dataset was to create an interesting, large text classification problem with many classes, that does not suffer from label sparsity as most datasets of its type do. See the blog post for a more detailed write up, or the paper here. The aim is to classify self-posts into the subreddit into which they were posted. A great deal of effort has gone into selecting a \xe2\x80\x98good\xe2\x80\x99 set of subreddits to minimise overlap in content.\n\nWe recommend you look at the [blogpost write-up](https://www.evolution.ai/blog/page/5/an-imagenet-like-text-classification-task-based-on-reddit-posts/) for this dataset before continuing. There is also a rough draft of a paper [here](https://www.evolution.ai/blog_figures/reddit_dataset/rspct_preprint_v3.pdf) if you have more detailed questions.\n\n### Data\n\nThe data consists of 1.013M self-posts, posted from 1013 subreddits (1000 examples per class). For each post we give the subreddit, the title and content of the self-post.\n\nWe have also given a manual annotation of about 3000 subreddits which went into the creation of this dataset, in subreddit_info.csv, this was the main criteria for selecting which subreddits went into this dataset. We include a top-level category and subcategory for each subreddit, and a reason for exclusion if this does not appear in the data.\n\n### Recommendations\n\nWe recommend splitting out the last 20% of the data as a test set (we have organised so that this is a random, stratified sample of all the data. In our experiments, we have been optimising for the [precision-at-K metric][1] for K = {1, 3, 5}\n\n### Questions that we think would be interesting to answer\n\n - can sequential models (e.g. LSTMs) be trained to be competitive with / outperform bag-of-word approaches?\n - does transfer learning (e.g. OpenAI, ULMFIT) help on this problem? You may want to look at the GitHub page (https://github.com/mikesj-public/rspct-dataset/tree/master) to get hold of a unsupervised training set.\n - can you leverage a hierarchy (such as the one detailed in subreddit_info.csv), to improve accuracy?\n - can you use techniques from [XML (extreme multi-class) machine learning](http://manikvarma.org/downloads/XC/XMLRepository.html) to get a better score on this dataset?\n\n\n  [1]: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Precision_at_K'","b""['classification', 'nlp', 'multiclass classification', 'reddit', 'medium', 'featured']""",https://www.kaggle.com/mswarbrickjones/reddit-selfposts
b'Top 250 Football transfers from 2000 to 2018',b'List of 250 most expensive transfers that took place between 2000 and 2018 ',"b'\nDescription\n-----------\n\n\nThe dataset of top 250 most expensive football transfers from season 2000-2001 until 2018-2019. The dataset is created on 1 August 2018 and for that reason may have an incomplete list of the latest transfer window(Summer 2018)\n\n\nDataset:\n--------\n\nThere are 4700 total rows and 10 columns in this dataset. The columns contain the following information: the name of a football player, selling team and league, the league and team where a player is sold, an estimated market value of a player, an actual value of a transfer, the position of a player and season when a transfer took place.  \n\n'","b""['data visualization', 'sports', 'association football', 'small', 'featured']""",https://www.kaggle.com/vardan95ghazaryan/top-250-football-transfers-from-2000-to-2018
b'Historic Tour De France Dataset',b'This dataset contains variables regarding each stage of the Tour De France',"b'### Context\n\nAs of now the race of Tour De France is traveling around France, and different riders have been doing so for many years. I wanted to explore the history of Tour De France from a data perspective. That was my motivation for gathering this dataset.\n\n### Content\n\nThe dataset contains 2236 stages over 8 different variables:\n\n* Stage                    - The stage number of the stage in the respective year.\n* Date                      - Self explanatory. The date ranges from 1st of July 1903 to 23rd of July 2017.\n* Distance               - The distance in km of the stage.\n* Origin                   - The name of the city for which the stage starts.\n* Destination          - The name of the city for which the stage ends.\n* Type                      - The type of the stage. There are 18 different stages. Some very similar.\n* Winner                 - The name of the winner of the stage.\n* Winner_Country  - The country of the winner.\n\n### Acknowledgements\n\nI want to thank Wikipedia for making their data easy accessible.\nPhoto by Howard Lawrence B on Unsplash.\n\n### Inspiration\n\nI have answer questions of my own in my kernel. There are still lots of questions to answered. Further, one can expand the dataset in many ways.'","b""['eda', 'sports', 'cycling', 'small', 'featured']""",https://www.kaggle.com/ralle360/historic-tour-de-france-dataset
b'Predict Pakistan Elections 2018',b'Help Us Predict the Next Winner',"b'### Context\n\nHere comes the July 25th 2018 and Pakistan will see the 13th election (1954, 1962, 1970, 1977, 1985, 1988, 1990, 1993, 1997, 2002, 2008 and 2013) since independence. It\xe2\x80\x99s middle of the week (Wednesday) with an expected temperature of 27-33 degree Celsius with almost no chances of rain anywhere in the country. \n\nWe predict the historic voters\xe2\x80\x99 turn out in this election of 57-61%. Historically the average turn out is 45% since 1977 (lowest 35% in 1997, highest 55% in 1977 and 53% in last elections). Pakistan ranked 164th out of 169 nations in voters\xe2\x80\x99 turn out; Australia being the first with 94.5% turn out. \n\nVoters\xe2\x80\x99 participation in the country is very diverse, historically Musakhel and Kohlu yield less than 25% whereas Layyah and Khanewal yield more than 60% and everything else is in between. Punjab has the highest and Balochistan has the lowest voters\xe2\x80\x99 turnout.\n\nThe contest will bring 3,675 candidates for 272 national assembly seats, that is 13 candidates on average per seat. PTI has unleashed 244 candidates ([highest in number][1] by any political party). Islamabad will see [76 candidates][2] just for 3 seats fighting to rule the capital that guarantees the psychological edge. \n\nThere a quite few interesting facts about these elections, for example we will see the highest number of Lotas (candidates who often change their party affiliation) ever. PTI believes to win the election no matter what may come while the survey pundits predicts the PML(N) [lead of at least 13%][3] over PTI. \n\nThe history of elections and the charges of corruption, voters\xe2\x80\x99 fraud, ghost votes, interferences by deep state or violence go hand by hand. There is (almost) no country in the world without the fear or accusations of such incidents in their elections. \nWe are releasing the complete National Assembly Elections\xe2\x80\x99 Results dataset for 2002, 2008 and 2013 elections in CSV files for public and calling all data scientists, international observers and journalists out there to help us achieve our inspirations. \n\n### Content\n\nThree CSV files for complete election results for the national assembly of Pakistan for 2002, 2008 and 2013.\nThe file contains Seat, Constituency, Candidates Name, Party Affiliation, Votes, TotalValidVotes, TotalRejectedVotes, TotalVotes, TotalRegisteredVoters and Turnout variables for each seat.\n\n\n### Acknowledgements\n\nThe dataset should be referenced as \xe2\x80\x9cZeeshan-ul-hassan Usmani, Sana Rasheed, Muhammad Usman, Muhammad Ilyas and Qazi Humayun, Pakistan Elections Complete Dataset (2002, 2008, 2013), Kaggle, July 7, 2018.\xe2\x80\x9d\n\n### Inspiration\nHere is the list of ideas we are working on and like you to help with. Please post your kernels and analysis \n\n1.\tMap each NA constituency to a District. Get the list of Districts in Pakistan. So we will know how many constituencies we have in each district and which ones? Please update the dataset version on this page.\n\n2.\tFind and Convert the current 2018 candidates list to Excel sheet and upload here\n\n3.\tFind out total no of candidates in 2018 elections, from each party, from each province, total no of parties and Avg. no of candidates per seat\n\n4.\tCalculate the voter\xe2\x80\x99s turn out in each NA. Highest, lowest etc. Make a historical timeframe so we would know how many people voted in each NA in 2002, 2008 and 2013\n\n5.\tDo analysis on invalid votes in each NA in all elections. Do we see any patterns here?\n\n6.\tCan we predict the effect of rain on voter\xe2\x80\x99s turn out in a given constituency? \n\n7.\tFind out how many NEW candidates we have this time who have never contested any elections before? How many in each party?\n\n8.\tCan we make District Profiles with good visuals and heat-maps of which party would be leading in which district?\n\n9.\tCan we color the map of Pakistan (as we do in the US with Red and Blue) for each district? We can have a color or PML(N), PTI, PPP and MMA (only four major parties to start with)\n\n10.\tCan we find out Swing Districts and the Confirmed Districts for major parties?\n\n11.\tAre there any external datasets that we can join with this dataset to do some analysis? Please post the links or update the datasets here\n\n12.\tMake the Candidates\xe2\x80\x99 profile so we know his party position in each election and whether he lost or won the last election(s). You can  whatever values and information as you like\n\n13.\tGet the ***\xe2\x80\x9cLota\xe2\x80\x9d*** Score for each candidate. So anyone with more than 2 would be a ***\xe2\x80\x9cCertified Lota\xe2\x80\x9d.*** These candidates are the ones who have changed their parties by x no of times, from independent to PPP, from PTI to PML etc.\n\n14.\tGet the \xe2\x80\x9cConfirmed Constituencies\xe2\x80\x9d where historically we have only one sided results. For example, PPP would always win from NA-XYZ or Zardari have never lost an election doesn\xe2\x80\x99t matter where he ran from. Which party would definitely win which seats? \n\n15.\tGet the list of \xe2\x80\x9cSwing Constituencies\xe2\x80\x9d which historically are as random as anybody\xe2\x80\x99s guess. For example, NA-XYZ voted for PTI in 2002, then went to PPP in 2008, then to PMLN in 2013 and so on. Once we have this list we can go further down and talk in detail the margins of win/loss in previous elections, who are the candidates (their profiles, district profiles, voter turnout etc.) and even results of bi-elections. But it is very important to get this list in first place. This is where can apply some models to do predict which way it will sway\n\n16.\tMake the \xe2\x80\x9cParty Potential\xe2\x80\x9d list. For Example, PML(N) with all its candidates, profiles etc. has the potential  to win 86 seats, PTI 65, PPP 43 etc. Here we can predict which party would form the government in which province?\n\n17.\tFind out how many people voted so far in Pakistan in last 3 elections. Max, Min, Avg. Per Seat, Per Province?  Can we hypothesize that that avg. no of voters in Punjab per seat (who go out and vote) is double than the avg. no of voters in KPK? Or voter turnout in Bunner is less than 25% while in Chakwal It is more than 65%?\n\n18.\tPopular Vote winner. Even if PML(N) lose, can we say that it will fetch max no of votes from the country by vote count only? Or is it true for PPP or PTI?\n\n19.\tFind \xe2\x80\x9cFake Candidates\xe2\x80\x9d the people who are running but have no chance to win. Like no past elections or political history. These are the one who will withdraw 24 hours before the elections\n\n20.\tFind the \xe2\x80\x9cIndependents\xe2\x80\x9d who will go to the highest bidder after winning\n\n21.\tFind anything interesting you can on candidates. Like is it true if candidates\xe2\x80\x99 name start from M or A, he has twice the chances of winning than the candidates whose names start with other letters?\n\n22.\tSurprise Me!\n\n\n  [1]: https://gulfnews.com/news/asia/pakistan/pti-fields-highest-number-of-candidates-for-2018-elections-1.2244562\n  [2]: https://www.geo.tv/latest/201359-general-election-76-candidates-to-contest-for-three-na-seats-in-islamabad\n  [3]: https://en.wikipedia.org/wiki/Pakistani_general_election,_2018'","b""['data visualization', 'feature engineering', 'text data', 'regression analysis', 'future prediction', 'medium', 'featured']""",https://www.kaggle.com/zusmani/predict-pakistan-elections-2018
b'OECD Exports of Goods and Services',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/7uLjsxzQUzk) by [Peter Kleinau](https://unsplash.com/@nepumuk) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/oecd-org/oecd-exports-of-goods-and-services
b'NYS Taxable Sales And Purchases Quarterly',b'From New York State Open Data',"b""### Content  \n\nThese statistics come from more than three million data items reported on about 250,000 sales tax returns filed quarterly and on about 300,000 returns filed annually.  The dataset categorizes quarterly sales and purchases data by industry group using the North American Industry Classification System.   The status of data will change as preliminary data becomes final.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Y_x747Yshlw) by [Christian Dubovan](https://unsplash.com/@cdubo) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'industry', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-taxable-sales-and-purchases-quarterly
b'EPL Results 1993-2018',b'Premier League Results with half time scores ',"b'This dataset contains results from every Premier League match from 1993-1994 to 2017-2018. \nIt also includes half time results, but only from 1995-96 to 2017-18. \n\nThis was inspired by the lack of simple, league specific datasets. Instead of having to sift through huge datasets containing virtually every European match result, having smaller league specific sets simplifies analysis. \n\nColumns include Division (denoted as E0), HomeTeam, AwayTeam, FTHG (final time home goals), FTAG (final time away goals), FTR (full time result), HTHG (half time home goals), HTAG (half time away goals), HTR (half time result), and season.\n\nResults come from [this site][1], a football betting site from the UK. They have datasets for each individual season, but I wanted to combine them into one single set for ease of use. \n\n\n  [1]: http://www.football-data.co.uk/data.php'","b""['sports', 'europe', 'association football', 'small', 'featured']""",https://www.kaggle.com/thefc17/epl-results-19932018
b'Los Angeles Posted Street Sweeping Routes',b'From Los Angeles Open Data',"b""### Content  \n\nMotor sweeping program: route #s, boundaries and times for posted routes only. Maps are available as downloadable PDFs under the Attachments section of the About tab.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/L54zc2NEkTQ) by [Kevin Lee](https://unsplash.com/@kevin_lee) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-posted-street-sweeping-routes
b'NY Parking Violations Issued',b'From New York City Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ep416elVnBA) by [Michael Louie](https://unsplash.com/@mlouie45) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'finance', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/ny-parking-violations-issued
b'Los Angeles Listing of Businesses',b'From Los Angeles Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/5c1kq_XmPEY) by [Sasha \xe2\x80\xa2 Stories](https://unsplash.com/@sanfrancisco) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Creative Commons 1.0 Universal (Public Domain Dedication)""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-listing-of-businesses
b'French Single Speaker Speech Dataset',b'CSS10 French: Single Speaker Speech Dataset',"b'### Context\n\nCSS10 is a collection of single speaker speech datasets for 10 languages. Each of them consists of audio files recorded by a single volunteer and their aligned text sourced from LibriVox.\n\n### Content\nEach line in `transcript.txt` is delimited by `|` into four fields, i.e., audio file location, original script, normalized script, and audio duration.\n\nVisit [here](https://github.com/kyubyong/css10) to check out our project using this dataset.\n\n### Acknowledgements\n\nWe thank LibriVox and the volunteers.\n \n### Contact\nYou can contact me at kbpark.linguist@gmail.com.\n\nJune, 2018.\n\nKyubyong Park & Tommy Mulc\n'","b""['linguistics', 'large', 'featured']""",https://www.kaggle.com/bryanpark/french-single-speaker-speech-dataset
b'OECD Consumer Price Index of Harmonized Prices',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/tT-t-qPCruo) by [Alisa Anton](https://unsplash.com/@alisaanton) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'utility', 'small', 'featured']""",https://www.kaggle.com/oecd-org/oecd-consumer-price-index-of-harmonized-prices
b'NYS State University Construction Fund (SUCF)',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'education', 'construction', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-state-university-construction-fund-sucf
b'News Headlines Of India',b'17 Years of headlines focusing on India',"b""### Context\n\nThis dataset is a compilation of **2.7 million** news headlines published by Times of India from **2001 to 2017**, 17 years.\n\nA majority of the data is focusing on Indian local news including national, city level and entertainment.\n\nThis News Dataset is a persistent historical archive of noteable events in the Indian subcontinent from start-2001 to end-2017, recorded in ReaL time by the journalists of India.\n\nAgency Website: https://timesofindia.indiatimes.com\n\nThe individual events can be explored in detail via the archives section.\n\n### Content\n\nCSV Rows: 2,735,346\n\n1. **publish_date**: Date of the article being published online in yyyyMMdd format\n\n2. **headline_category**: Category of the headline, ascii, dot delimited, lowercase values\n\n3. **headline_text**: Text of the Headline in English, very rare non-ascii characters\n\nStart Date: 2001-01-01 End Date: 2017-12-31\n\nSee This Kernal for [Overview of Trends and Categories][1] \n\nFeed Code: w3-event-timsofind; Si.gh.rank: OAT\n\n### Inspiration\n\n\n\nTimes Group as a news agency, reaches out a very wide audience across Asia and drawfs every other agency in the quantity of English Articles published per day. \nDue to the heavy daily volume (avg. 650 articles) over multiple years, this data offers a deep insight into Indian society, its priorities, events, issues and talking points and how they have unfolded over time. \n\nIt is possible to chop this dataset into a smaller piece for a more focused analysis, based on one or more facets. \n\n - Time Range: Records during 2014 election, 2006 Mumbai Bombings\n - One or more Categories: like Mumbai, Movie Releases, ICC updates, Magazine, Middle East\n - One or more Keywords: like crime or ecology related words; names of political parties, celebrities, corporations.\n\n### Acknowledgements\n\nThe headlines are extracted from several GB of raw HTML files using Jsoup, Java and Bash. The entire process takes 7 minutes.\n\nThis logic also : chooses the best worded headline for each article (longest one is usually picked) ; clusters about 17k categories to 200 large groups ; removes records where the date is ambiguous (9k cases) ; finally cleans the selected headline via a string 'domestication' function (which I use for any wild text from the internet).\n\nThe final categories are as per the latest sitemap.  Around 1.5k rare categories remain and these records (~20k) can be filtered out easily during analysis. The category is unknown for ~200k records.\n\nSimilar news datasets exploring other attributes, countries and topics can be seen on my profile.\n\nCitation for usage:\n\n**Rohit Kulkarni** (2017), News Headlines of India 2001-2017 [CSV data file], doi:10.7910/DVN/J7BYRX, Retrieved from: [this url]\n\nThis is an ongoing project by KonivaC. An update may be provided irregularly with the latest events.\n\nDedicated to Sigismund Schlomo Frued a\xc5\xad Subhas Chandra Bose\n\n  [1]: https://www.kaggle.com/therohk/india-news-publishing-trends-and-cities""","b""['cities', 'news agencies', 'historiography', 'medium', 'featured']""",https://www.kaggle.com/therohk/india-headlines-news-dataset
b'Volcanoes on Venus',b'\xc2\xbfCan you detect volcanoes on Venus? ',"b'### Context\n\nNASA\'s Magellan (https://www2.jpl.nasa.gov/magellan/) spacecraft was launched on May 4, 1989 and arrived at Venus on August 10, 1990. The primary objectives of the Magellan mission were to map the surface of Venus with a *synthetic aperture radar* (SAR) and to determine the topographic relief of the planet. At the completion of radar mapping 98% of the surface was imaged at resolutions better than 100 m, and many areas were imaged multiple times.  \nIn the analysis of the data captured by the spacecraft they found volcanoes on the surface on Venus, volcanoes that can be used to make a automatic machine that can detect them.\n\n\n### Content\n\nWe present the data split into *train* and *test*. The input data (*train_images.csv* and *test_images.csv*) consist on Images of one chanel 110x110, pixels from 0 to 255, where every image is one row of 12100 columns (all the 110 rows of 110 columns), this images can contain more then one volcano or maybe none . Associated to this we present the label data or *""ground truth""* (*train_labels.csv* and *test_labels.csv*), which contains four columns, described here:\n\n* Volcano?: if in the image there are volcanoes (**Main target**), 1 or 0.\n\nfor Volcano?=0 this three next features are NaN\n* Type: 1= definitely a volcano,2 =probably, 3= possibly, 4= only a pit is visible\n* Radius: is the radius of the volcan in the center of the image, in *pixels*\n* Number Volcanoes: The number of volcanoes in the image\n\nThe images that have volcanoes, have one centered on the image. The authors quote *""ground truth""*  as a reminder that there is no absolute ground truth for this dataset. No one has been to Venus and image quality does not permit 100%, unambiguos identification of the volcanoes, even by human experts.\n\nThe data is unbalanced and that has to be taken account, the number of volcanoes is lower than no volcanoes.\n\n*Missing Values*  \nSome images contain blank (black) regions which resulted from gaps in the Magellan acquisition or communication processes. These regions can generally be ignored.\n\n## Acknowledgements\nThe original dataset has been carried out in part by the Jet Propulsion Laboratory, California Institute of Technology, under contract with the National Aeroenautics and Space Administration, and thanks to UCI Machine Learning Repository (http://archive.ics.uci.edu/ml) we use the original dataset to create this one to you in Kaggle! \n\n## Inspiration\nJARtool (jartool@aig.jpl.nasa.go) was a pioneering effort to develop an automatic system for cataloging small volcanoes in the large set of Venus images returned by the Magellan spacecraft. We use the original dataset to create this one with the same purpose.'","b""['geography', 'learning', 'astronomy', 'medium', 'featured']""",https://www.kaggle.com/fmena14/volcanoesvenus
b'Ramen Ratings',b'Over 2500 ramen ratings',"b'### Context\n\nThe Ramen Rater is a product review website for the hardcore ramen enthusiast (or ""ramenphile""), with over 2500 reviews to date. This dataset is an export of ""The Big List"" (of reviews), converted to a CSV format.\n\n### Content\n\nEach record in the dataset is a single ramen product review. Review numbers are contiguous: more recently reviewed ramen varieties have higher numbers. Brand, Variety (the product name), Country, and Style (Cup? Bowl? Tray?) are pretty self-explanatory. Stars indicate the ramen quality, as assessed by the reviewer, on a 5-point scale; this is the most important column in the dataset!\n\nNote that this dataset does *not* include the text of the reviews themselves. For that, you should browse through https://www.theramenrater.com/ instead!\n\n### Acknowledgements\n\nThis dataset is republished as-is from the original [BIG LIST](https://www.theramenrater.com/resources-2/the-list/) on https://www.theramenrater.com/.\n\n### Inspiration\n\n* What ingredients or flavors are most commonly advertised on ramen package labels?\n* How do ramen ratings compare against ratings for other food products (like, say, wine)?\n* How is ramen manufacturing internationally distributed?'","b""['food and drink', 'asia', 'small', 'featured']""",https://www.kaggle.com/residentmario/ramen-ratings
b'Genome Information For Sequenced Organisms',"b'taxonomy, statistics and dna sequence links for species with sequenced genomes'","b""### Content\n\nThe provided tables contain meta data which allows for high level analysis of a wide variety of sequenced genomes for multi cell organisms ranging from humans to corn, as we as bacteria and viruses. The tables also contain links to the actual genome sequence data via the 'GenBank FTP' and 'RefSeq FTP' columns. Links in these columns can provide users with the assembled genomes for over 10,000 different species. Summary statistics are also provided, including the taxonomic classification for each organism and information about the size of the genome (in [megabases - mb](https://en.wikipedia.org/wiki/Base_pair)) and the [GC content](https://en.wikipedia.org/wiki/GC-content) of the genome.\n\n\n### Acknowledgements\n\nThese data are taken from the [National Center for Biotechnology Information](https://www.ncbi.nlm.nih.gov/) where they have been made publicly available by the large number of researchers who contributed to the construction of these genomes. \n\n### Inspiration\n\nThe data allow for an exploration of the distribution of species with sequenced genomes across the animal kingdom. The provided tables contain meta data which allows for high level analysis of sequenced genomes, as well as links to the actual genome sequence data via the 'GenBank FTP' and 'RefSeq FTP' columns. Links in these columns can provide users with the assembled genomes for over 10,000 different species!""","b""['biology', 'government agencies', 'diseases', 'health sciences', 'biotechnology', 'small', 'featured']""",https://www.kaggle.com/camnugent/genome-information-for-sequenced-organisms
b'Laptops for Sale - OLX Pakistan',b'OLX ads records scrapped from website of laptop category ',"b""### Context\n\nSelling used items gets pretty tricky when it comes to deciding resale value of an item. The process involves deciding the right price by examining existing items in market of similar kind and observing market trends. Everyone wants to sell in profit but they can\xe2\x80\x99t quote too much that none buys the item nor quote too less to sell in loss. We are interested in developing a system to predict right optimal resale value of product. \n\n### Content\nData was gathered via Web scrapping using online tool (https://scrapy.org) on OLX Pakistan Website. We scrapped data on following dates March'18 - Sept'18. \n\nThese data files were scrapped in json format and were appended into single Dataset having total of records /rows (22098) and total of 7 Attributes. \nThe Description of Attribute is as follows:\n1.\tCondition \xe2\x80\x93 New/Used.\n2.\tCreation Time \xe2\x80\x93 Day when Ad was published on website.\n3.\tDescription \xe2\x80\x93 Description of Ad \n4.\tLocation - Area, City, Province. \n5.\tPrice \xe2\x80\x93  in Rupees\n6.\tTitle \xe2\x80\x93 Title having precise subject of Ad\n7.\tURL \xe2\x80\x93 OLX Website, source where Ad has been published\n\n### Acknowledgements\n\nSource: www.olx.com.pk\n\n### Inspiration\n\nA very good dataset to learn natural language processing troublesome. \n""","b""['nlp', 'text data', 'regression analysis', 'multiclass classification', 'information technology', 'medium', 'featured']""",https://www.kaggle.com/iamosama/olx-pakistan-laptops
b'Air Quality in Madrid (2001-2018)',b'Different pollution levels in Madrid from 2001 to 2018',"b""### Context\n\nIn the recent years, the high levels of pollution during certain dry periods in Madrid has forced the authorities to take measures against the use of cars in the city center, and has been used as a reson to propose drastic modifications in the city's urbanism. Thanks to [Madrid's City Council Open Data website][1], the air quality data has been uploaded is plubicly available. There are several files available, including [daily][2] and [hourly][3] historical data of the levels registered from 2001 to 2018 and [the list of stations being used][4] for pollution and other particles analysis in the city.\n\nHowever, when exploring this data from a data analysis and time series point of view, we found that the format was somehow confusing and not common, and some design decisions in the dataset were far from optimal: The hourly data was split in monthly files containing slightly different formats through the years, which were equally as uncommon: rows are certain measures in certain days, each containing 24 columns (one per hour in the day) that includes a control character. This control character is `V` if the measurement is valid, and mostly (but not exclusively) `N` if not.\n\nThese handicaps when exploring the historical data can ruin the purpose of the Open Data: to be publicly audited, and to be freely explored and used for experimentation. For that reason in Decide we are release our own version of the data, which has been designed for ease of use using common standards and performant formats. This allows to ship a faster, smaller and more convenient and intuitively structured dataset.\n\n### Content\n\nAll the data is extracted from the original files and processed to result in a more convenient format for typical Kaggle purposes. \nWhile the original data includes hours as different columns and measurements as different rows, this version is structured the other way round: Each row is timestamped and the columns are the different measures performed at that point in time in a certain stations. This allows faster preparation for time series analysis and prediction tasks.\n\nThis dataset defines stations as the higher hierarchical level: each individual station history can be individually extracted from the file for further study. Inside each station's DataFrame, all the particles measurements that such station has registered in the period of 2001/01 - 2018/04 (if active this whole time). Not every station has the same equipment, therefore each station can measure only a certain subset of particles. The complete list of possible measurements and their explanations (following [the original explanation document][5]) are:\n\n - `SO_2`: sulphur dioxide level measured in \xce\xbcg/m\xc2\xb3. High levels of sulphur dioxide can produce irritation in the skin and membranes, and worsen asthma or heart diseases in sensitive groups.\n - `CO`: carbon monoxide level measured in mg/m\xc2\xb3. Carbon monoxide poisoning involves headaches, dizziness and confusion in short exposures and can result in loss of consciousness, arrhythmias, seizures or even death in the long term.\n - `NO`: nitric oxide level measured in \xce\xbcg/m\xc2\xb3. This is a highly corrosive gas generated among others by motor vehicles and fuel burning processes.\n - `NO_2`: nitrogen dioxide level measured in \xce\xbcg/m\xc2\xb3. Long-term exposure is a cause of chronic lung diseases, and are harmful for the vegetation.\n - `PM25`: particles smaller than 2.5 \xce\xbcm level measured in \xce\xbcg/m\xc2\xb3. The size of these particles allow them to penetrate into the gas exchange regions of the lungs (alveolus) and even enter the arteries. Long-term exposure is proven to be related to low birth weight and high blood pressure in newborn babies.\n - `PM10`: particles smaller than 10 \xce\xbcm. Even though the cannot penetrate the alveolus, they can still penetrate through the lungs and affect other organs. Long term exposure can result in lung cancer and cardiovascular complications.\n - `NOx`: nitrous oxides level measured in \xce\xbcg/m\xc2\xb3. Affect the human respiratory system worsening asthma or other diseases, and are responsible of the yellowish-brown color of photochemical smog.\n - `O_3`: ozone level measured in \xce\xbcg/m\xc2\xb3. High levels can produce asthma, bronchytis or other chronic pulmonary diseases in sensitive groups or outdoor workers.\n - `TOL`: toluene (methylbenzene) level measured in \xce\xbcg/m\xc2\xb3. Long-term exposure to this substance (present in tobacco smkoke as well) can result in kidney complications or permanent brain damage.\n - `BEN`:  benzene level measured in \xce\xbcg/m\xc2\xb3. Benzene is a eye and skin irritant, and long exposures may result in several types of cancer, leukaemia and anaemias. Benzene is considered a group 1 carcinogenic to humans by the IARC.\n - `EBE`: ethylbenzene level measured in \xce\xbcg/m\xc2\xb3. Long term exposure can cause hearing or kidney problems and the IARC has concluded that long-term exposure can produce cancer.\n - `MXY`: *m*-xylene level measured in \xce\xbcg/m\xc2\xb3.  Xylenes can affect not only air but also water and soil, and a long exposure to high levels of xylenes can result in diseases affecting the liver, kidney and nervous system (especially memory and affected stimulus reaction).\n - `PXY`: *p*-xylene level measured in \xce\xbcg/m\xc2\xb3. See `MXY` for xylene exposure effects on health.\n - `OXY`: *o*-xylene level measured in \xce\xbcg/m\xc2\xb3. See `MXY` for xylene exposure effects on health.\n - `TCH`: total hydrocarbons level measured in mg/m\xc2\xb3. This group of substances can be responsible of different blood, immune system, liver, spleen, kidneys or lung diseases.\n - `CH4`: methane level measured in mg/m\xc2\xb3. This gas is an asphyxiant, which displaces the oxygen animals need to breath. Displaced oxygen can result in dizzinnes, weakness, nausea and loss of coordination.\n - `NMHC`: non-methane hydrocarbons (volatile organic compounds) level measured in mg/m\xc2\xb3. Long exposure to some of these substances can result in damage to the liver, kidney, and central nervous system. Some of them are suspected to cause cancer in humans.\n\nAlso the `master` DataFrame is included the file, which contains information about the active stations. Notice that only active stations are included in there, since the Open Data files do not provide information about the stations that have ceased activity.\n\nUsing this hierarchical structure, we can store it in an HDF5 file, which is also compressed and allows for great performance when accessing contiguous data (which is the casa in this time-indexed design). These modifications allow to encapsulate the same information that is provided in the original page in monthly files adding up to 250MiB in a single, structured file of just 74MiB. Since some people may not be familiar with HDF5 format yet, we provide some snippets to make it easier for you to start exploring the data in Python. You can find a short introduction in to HDF5 format in [this kernel][6].\n\nHowever, if for some reason using HDF5 is still inconvenient for you, this dataset also provides a zip folder containing the same information gathered in plain-text CSV files and a `stations.csv` file equivalent to the `master` dataframe. These CSV files still benefit from the data reorganization but the lack of advatange performances make them much heavier (174MiB compressed, 500MiB uncompressed).\n\n### Source and Licensing\n\nAll the data present in this dataset comes from [Madrid's City Council Open Data website][7], which are the ones to be acknowledged for the data collection. It aims to provide a more convenient format for data scientist, as well as some enhanced context in a single place.\n\nThe data therefore inherits the [Madrid Open Data Terms of Use][8], which allow for free commercial and non-commercial use, and provide no liability on the data. For more details about the licensing, please refer back to the aforementioned document detailing the terms of use (in Spanish).\n\n### Inspiration\n\nThis dataset is created out of the frustation of how inconvenient and irregular the historical data was provided in the Open Data website. It contains in a practical format 18 years (2001-2018) of hourly data in just a single file, which makes this dataset a great playground for time series analysis and other prediction tasks. How do different gases correlate their levels? Are there any changes in trends? Can they be mapped to the recent decisions made by the city council, or do they relate to rainy dates? What is the best model to predict pollution levels? How do the levels interpolate between the location of the stations? Are some gases more common at different elevations? We are looking forward to see what you can come up with!\n\n\n  [1]: https://datos.madrid.es/portal/site/egob\n  [2]: https://datos.madrid.es/sites/v/index.jsp?vgnextoid=aecb88a7e2b73410VgnVCM2000000c205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD\n  [3]: https://datos.madrid.es/sites/v/index.jsp?vgnextoid=f3c0f7d512273410VgnVCM2000000c205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD\n  [4]: https://datos.madrid.es/sites/v/index.jsp?vgnextoid=9e42c176313eb410VgnVCM1000000b205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD\n  [5]: https://datos.madrid.es/FWProjects/egob/Catalogo/MedioAmbiente/Aire/Ficheros/Interprete_ficheros_%20calidad_%20del_%20aire_global_.pdf\n  [6]: https://www.kaggle.com/diegovicente/a-short-introduction-to-hdf5-files\n  [7]: https://datos.madrid.es/portal/site/egob\n  [8]: https://datos.madrid.es/portal/site/egob/menuitem.3efdb29b813ad8241e830cc2a8a409a0/?vgnextoid=108804d4aab90410VgnVCM100000171f5a0aRCRD&vgnextchannel=b4c412b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default""","b""['time series', 'pollution', 'medium', 'featured']""",https://www.kaggle.com/decide-soluciones/air-quality-madrid
b'Weather Conditions in World War Two',b'Daily Weather Summaries from 1940-1945',"b'### Context\n\nWhile exploring the Aerial Bombing Operations of World War Two dataset (https://www.kaggle.com/usaf/world-war-ii), and recalling that the D-Day landings were nearly postponed due to poor weather, I sought out weather reports from the period to compare with missions in the bombing operations dataset. \n\n### Content\n\nThe dataset contains information on weather conditions recorded on each day at various weather stations around the world. Information includes precipitation, snowfall, temperatures, wind speed and whether the day included thunder storms or other poor weather conditions. \n\n### Acknowledgements\n\nThe data are taken from the United States National Oceanic and Atmospheric Administration (https://www.kaggle.com/noaa) National Centres for Environmental Information website: https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/world-war-ii-era-data\n\n### Inspiration\n\nThis dataset is mostly to assist with the analysis of the Aerial Bombing Operations dataset, also hosted on Kaggle. '","b""['weather', 'history', 'utility', 'war', 'medium', 'featured']""",https://www.kaggle.com/smid80/weatherww2
b'Images of Canine Coccidiosis Parasite',b'Microscopy images of Isospora canis oocysts',"b'### Context\n\nThis dataset contains images and labels of Isospora canis and Isospora sp. oocysts, a coccidian parasites that infect intestinal tract in dogs.\n\n\n### Content\n\nThe main image data is in the ""img"" folder, with labels in the ""label"" folder.\n\n\n### Acknowledgements\n\nThis dataset was created at the Faculty of Veterinary Medicine in Zagreb. Images were taken and labeled by Krunoslav Vinicki under the supervision of doc. dr. sc. Franjo Martinkovi\xc4\x87\n\n'","b""['deep learning', 'image data', 'healthcare', 'medicine', 'veterinary medicine', 'medium', 'featured']""",https://www.kaggle.com/kvinicki/canine-coccidiosis
b'World Development Indicators',b'From World Bank Open Data',"b""### Content  \n\nThe primary World Bank collection of development indicators, compiled from officially-recognized international sources. It presents the most current and accurate global development data available, and includes national, regional and global estimates.  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](https://databank.worldbank.org/) and they update their information according the amount of data that is brought in. Explore the World Bank using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using the World Bank's [APIs](data.worldbank.org/developers) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/-VHfqDKgMLk) by [Samantha Sophia](https://unsplash.com/@samanthasophia) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'world', 'countries', 'globalization', 'medium', 'featured']""",https://www.kaggle.com/theworldbank/world-development-indicators
b'/r/science popular comment removal',b'Predicting comment removals to reduce moderator burnout',"b""### Context\n\nIn the *Age of the Internet* we humans as a species have become increasingly connected with each other. Unfortunately, that's not always a good thing. Sometimes we end up inadvertently connecting with people we'd really rather not talk to at all and it ruins our day. In fact, trolls abound on the internet and its become increasingly difficult to find quality online discussions. Many online publishers simply do not allow commenting because of how easy it is for a few trolls to derail an otherwise illuminating discussion. \n\nBut maybe we can fix all that with the power of data science.\n\n### Content\n\nThe dataset is a csv of about 30k reddit comments made in /r/science between Jan 2017 and June 2018. 10k of the comments were removed by moderators; the original text for these comments was recovered using the pushshift.io API. Each comment is a top-level reply to the parent post and has a comment score of 14 or higher. \n\n### Acknowledgements\n\nThe dataset comes from Google BigQuery, Reddit, and Pushshift.io. \n\nThanks to Jesper Wrang of [removeddit](https://removeddit.com/) for advising on how to construct the dataset.\n\nThanks to Jigsaw for hosting the Toxic Comment Classification Kaggle Challenge -- from which I learned a lot about NLP\n\nThanks to the participants of said challenge -- I borrow heavily from your results.\n\n### Inspiration\n\nCan we help reduce moderator burnout by automating comment removal?\nWhat features are most predictive of popular comments getting removed?""","b""['nlp', 'bigquery', 'text data', 'binary classification', 'reddit', 'medium', 'featured']""",https://www.kaggle.com/areeves87/rscience-popular-comment-removal
b'PUBG Match Deaths and Statistics',"b""Over 65 million death entries for PlayerUnknown Battleground's matches""","b""## Introduction\n\nVideo games are a rich area for data extraction due to its digital nature.  Notable examples such as the complex EVE Online economy, World of Warcraft corrupted blood incident and even Grand Theft Auto self-driving cars tells us that fiction is closer to reality than we really think.  Data scientists can gain insight on the logic and decision-making that the players face when put in hypothetical and virtual scenarios. \n\nIn this Kaggle Dataset, I provide over 720,000 competitive matches from the popular game PlayerUnknown's Battlegrounds.  The data was extracted from [pubg.op.gg][1], a game tracker website.  I intend for this data-set to be purely exploratory, however users are free to create their own predictive models they see fit.  \n\n\n## PlayerUnknown's Battlegrounds\n\nPUBG is a first/third-person shooter battle royale style game that matches over 90 players on a large island where teams and players fight to the death until one remains.  Players are airdropped from an airplane onto the island where they are to scavenge towns and buildings for weapons, ammo, armor and first-aid.  Players will then decide to either fight or hide with the ultimate goal of being the last one standing.  A bluezone (see below) will appear a few minutes into the game to corral players closer and closer together by dealing damage to anyone that stands within the bluezone and sparing whoever is within the safe zone.\n\n![pubg bluezone damage][2]\n\n[Read more about PUBG here][3]\n\n## The Dataset\n\nThis dataset provides two zips: aggregate and deaths. \n\n - In deaths, the files record every death that occurred within the 720k matches.  That is, each row documents an event where a player has died in the match.\n - In aggregate, each match's meta information and player statistics are summarized (as provided by pubg).  It includes various aggregate statistics such as player kills, damage, distance walked, etc as well as metadata on the match itself such as queue size, fpp/tpp, date, etc.\n\nThe uncompressed data is divided into 5 chunks of approximately 2gb each.  For details on columns, please see the file descriptions.\n\n### Interpreting Positional Data\nThe X,Y coordinates are all in in-game coordinates and need to be linearly scaled to be plotted on square erangel and miramar maps.  The coordinate min,max are 0,800000 respectively.\n\n## Potential Bias in the Data\n\nThe scraping methodology first starts with an initial seed player, I chose this to be my own account (a rather low rank individual).  I then use the seed player to scrape for all players that it has encountered in its historical matches.  I then take a random subset of 5000 players from this and then scrape for their historical games for the final dataset.  What this could produce is an unrepresentative sample of all games played as it is more likely that I queued and matched with lower rated players and those players more than likely also got matched against lower rated players as well.  Thus, the matches and deaths are more representative of lower tier gameplay but given the simplicity of the dataset, this shouldn't be an issue.\n\n## Acknowledgements\n\n 1. Pubg.op.gg, if this is against the TOS, please let me know and I will take it down\n\n  [1]: http://pubg.op.gg\n  [2]: https://i.redd.it/djzln9jnhrez.jpg\n  [3]: https://en.wikipedia.org/wiki/PlayerUnknown%27s_Battlegrounds""","b""['demographics', 'video games', 'geography', 'large', 'featured']""",https://www.kaggle.com/skihikingkevin/pubg-match-deaths
"b'NYS Vehicle, Snowmobile, and Boat Registrations'",b'From New York State Open Data',"b""### Content  \n\nThis dataset contains the file of vehicle, snowmobile and boat registrations in NYS. Registrations expired more than 2 years are excluded. Records that have a scofflaw, revocation and/or suspension are included with indicators specifying those kinds of records.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/pKeQSunIVo4) by [Rainy Lake](https://unsplash.com/@rainylake) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""","https://www.kaggle.com/new-york-state/nys-vehicle,-snowmobile,-and-boat-registrations"
b'Chicago West Nile Virus Mosquito Test Results',b'From City of Chicago Open Data',"b""### Content  \n\nList of locations and test results for pools of mosquitoes tested through the Chicago Department of Public Health Environmental Health program. The Chicago Department of Public Health maintains an environmental surveillance program for West Nile Virus (WNV).  This program includes the collection of mosquitoes from traps located throughout the city; the identification and sorting of mosquitoes collected from these traps; and the testing of specific species of mosquitoes for WNV.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/pszENPYeVj4) by [Hush Naidoo](https://unsplash.com/@hush52) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'public health', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-west-nile-virus-mosquito-test-results
"b'HDMA Washington State Home Loans, 2016'","b'Data on 466,566 home loans in Washington state'","b'### Context\n\nThe Home Mortgage Disclosure Act (HMDA) requires many financial institutions to maintain, report, and publicly disclose information about mortgages. These public data are important because they help show whether lenders are serving the housing needs of their communities; they give public officials information that helps them make decisions and policies; and they shed light on lending patterns that could be discriminatory.\n\n\n### Content\n\nInside this data set contains 466,566 observations of Washington State home loans - variables include; demographic information, area specific data, loan status, property type, loan type, loan purpose and originating agency.\n\n\n### Acknowledgements\n\nThis data set was compiled by the Consumer Finance Protection Bureau using their automatic filtering for Washington State.\n\n\n### Inspiration\nLooking at home loans in Washington State are there any current trends?\nWhat are the significant factors that go into loan approval decisions?\nAre there any area, demographic or gender bias?\nCan I build a MLA to predict loan decisions?'","b""['finance', 'demographics', 'banking', 'lending', 'home', 'medium', 'featured']""",https://www.kaggle.com/miker400/washington-state-home-mortgage-hdma2016
b'Protein Secondary Structure',b'Curated dataset for protein secondary structure prediction',"b'# Introduction\n\nProtein secondary structure can be calculated based on its atoms\' 3D coordinates once the protein\'s 3D structure is solved using X-ray crystallography or NMR. Commonly, [DSSP](https://swift.cmbi.umcn.nl/gv/dssp/index.html) is the tool used for calculating the secondary structure and assigns one of the following secondary structure types (https://swift.cmbi.umcn.nl/gv/dssp/index.html) to every amino acid in a protein:\n\n1. C: Loops and irregular elements (corresponding to the blank characters output by DSSP)\n1. E: \xce\xb2-strand\n1. H: \xce\xb1-helix\n1. B: \xce\xb2-bridge\n1. G: 3-helix\n1. I: \xcf\x80-helix\n1. T: Turn\n1. S: Bend\n\nHowever, X-ray or NMR is expensive. Ideally, we would like to predict the secondary structure of a protein based on its primary sequence directly, which has had a long history. A review on this topic is published recently, [Sixty-five years of the long march in protein secondary structure prediction: the final stretch?](https://www.ncbi.nlm.nih.gov/pubmed/28040746).\n\nFor the purpose of secondary structure prediction, it is common to simplify the aforementioned eight states (Q8) into three (Q3) by merging (E, B) into E, (H, G, I) into E, and (C, S, T) into C. The current accuracy for three-state (Q3) secondary structure prediction is about ~85% while that for eight-state (Q8) prediction is &lt;70%. The exact number depends on the particular test dataset used.\n\n# Dataset\n\nThe main dataset lists peptide sequences and their corresponding secondary structures. It is a transformation of https://cdn.rcsb.org/etl/kabschSander/ss.txt.gz downloaded at 2018-06-06 from [RSCB PDB](https://www.rcsb.org/) into a tabular structure. If you download the file at a later time, the number of sequences in it will probably increase.\n\n**Description of columns:**\n\n1. **pdb_id**: the id used to locate its entry on https://www.rcsb.org/\n1. **chain_code**: when a protein consists of multiple peptides (chains), the chain code is needed to locate a particular one.\n1. **seq**: the sequence of the peptide\n1. **sst8**: the eight-state (Q8) secondary structure \n1. **sst3**: the three-state (Q3) secondary structure \n1. **len**: the length of the peptide\n1. **has_nonstd_aa**: whether the peptide contains nonstandard amino acids (B, O, U, X, or Z).\n\n**Key steps in the transformation**:\n\n* Both Q3 and Q8 secondary structure sequences are listed. \n* All nonstandard amino acids, which includes B, O, U, X,  and Z, (see [here](http://www.samformat.info/IUPAC-ambiguity-codes) for their meanings) are masked with ""`*`"" character. \n* An additional column (`has_nonstd_aa`) is added to indicate whether the protein sequence contains nonstandard amino acids.\n* A subset of the sequences with low sequence identity and high resolution, ready for training, is also provided\n\nFor details of curation, please see https://github.com/zyxue/pdb-secondary-structure.\n\nA subset (9079 sequences) based on sequences culled by [PISCES](http://dunbrack.fccc.edu/Guoli/pisces_download.php) with more strict quality control is also provided. This dataset is considered ready for training models.\n\nThe culled subset generated on 2018-05-31 with cutoffs of 25%, 2\xc3\x85, and 0.25 for sequence identity, resolution and R-factor respectively, is used.  The URL to the original culled list is  http://dunbrack.fccc.edu/Guoli/culledpdb_hh/cullpdb_pc25_res2.0_R0.25_d180531_chains9099.gz, but it may not be permanently available.  This dataset contains more columns from `cullpdb_pc25_res2.0_R0.25_d180531_chains9099.gz` with self-explanatory names. \n\nFor more about PISCES, please see https://academic.oup.com/bioinformatics/article/19/12/1589/258419.\n\n# Acknowledgements\n\nThe peptide sequence and secondary structure are downloaded from https://cdn.rcsb.org/etl/kabschSander/ss.txt.gz.\nThe culled subset is downloaded from http://dunbrack.fccc.edu/PISCES.php.\n\n# Inspiration\n\nKaggle provides a great platform for sharing ideas and solving data science problem. Sharing a cleaned dataset help prevent others from duplicated work and also provides a common dataset for more comparable benchmark among different methods.'","b""['neural networks', 'healthcare', 'multiclass classification', 'biology', 'bioengineering', 'medium', 'featured']""",https://www.kaggle.com/alfrandom/protein-secondary-structure
b'NYS Council On The Arts Grant Awards',b'From New York State Open Data',"b""### Content  \n\nThis data set identifies grants awarded by the New York State Council on the Arts, beginning in 2003.  The grants are available to non-profit organizations incorporated and doing business in New York State, Indian tribes in New York State, and units of government in municipalities in New York State.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/MzSqFPLo8CE) by [Debby Hudson](https://unsplash.com/@dhudson_creative) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-council-on-the-arts-grant-awards
b'Stack Overflow 2018 Developer Survey',b'Individual responses on the 2018 Developer Survey fielded by Stack Overflow',"b'### Context\n\nEach year, we at [Stack Overflow](https://stackoverflow.com/) ask the developer community about everything from their favorite technologies to their job preferences. This year marks the eighth year we\xe2\x80\x99ve published our Annual Developer Survey results\xe2\x80\x94with the largest number of respondents yet. Over 100,000 developers took the 30-minute survey in January 2018.\n\nThis year, we covered a few new topics ranging from artificial intelligence to ethics in coding. We also found that underrepresented groups in tech responded to our survey at even lower rates than we would expect from their participation in the workforce. Want to dive into the results yourself and see what you can learn about salaries or machine learning or diversity in tech? We look forward to seeing what you find!\n\n### Content\n\nThis 2018 Developer Survey results are organized on Kaggle in two tables:\n\n**survey_results_public** contains the main survey results, one respondent per row and one column per question\n\n**survey_results_schema** contains each column name from the main results along with the question text corresponding to that column\n\nThere are 98,855 responses in this public data release. These responses are what we consider \xe2\x80\x9cqualified\xe2\x80\x9d for analytical purposes based on completion and time spent on the survey and included at least one non-PII question. Approximately 20,000 responses were started but not included here because respondents did not answer enough questions, or only answered questions with personally identifying information. Of the qualified responses, 67,441 completed the entire survey.\n\n### Acknowledgements\n\nMassive, heartfelt thanks to all Stack Overflow contributors and lurking developers of the world who took part in the survey this year. We value your generous participation more than you know.\n\n### Inspiration\n\nAt Stack Overflow, we put developers first and want [all developers to feel welcome and included on our site](https://stackoverflow.blog/2018/04/26/stack-overflow-isnt-very-welcoming-its-time-for-that-to-change/). Can we use our annual survey to understand what kinds of users are less likely to identify as part of our community, participate, or feel kinship with fellow developers? Check out [our blog post](https://stackoverflow.blog/2018/05/30/public-data-release-of-stack-overflows-2018-developer-survey) for more details.'","b""['internet', 'programming languages', 'medium', 'featured']""",https://www.kaggle.com/stackoverflow/stack-overflow-2018-developer-survey
b'Value of Manufacturers Inventories Data Collection',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/GVLhWdib3BU) by [Petter Rudwall](https://unsplash.com/@petterrudwall) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'utility', 'small', 'featured']""",https://www.kaggle.com/census/value-of-manufacturers-inventories-data-collection
b'Point Cloud Segmentation',"b'Segment buildings, trees, and cars in point cloud datasets'","b'### Context\n\nA labeled point-cloud dataset taken from the Semantic3D project (http://semantic3d.net/view_dbase.php?chl=1). The dataset has billions of XYZ-RGB points and labels them into 7 classes.\n\n### Content\n\nThe data are raw ASCII files containing 7 columns (X, Y, Z, Intensity, R, G, B) and the labels are \n\n`{1: man-made terrain, 2: natural terrain, 3: high vegetation, 4: low vegetation, 5: buildings, 6: hard scape, 7: scanning artefacts, 8: cars}` including an 8th class of unlabeled.\n\n### Acknowledgements\n\nThe data are taken directly from the Semantic3D competition and users must check and cite the rules and regulations posted on the original site: http://semantic3d.net/view_dbase.php?chl=1\n\n\n### Inspiration\n\n 1. What sort of models can classify point clouds well? \n 2. What\n        transformations make classification easier?\n 3. Are there certain\n    classes which require more data in order to classify well?'","b""['object segmentation', 'architecture', 'medium', 'featured']""",https://www.kaggle.com/kmader/point-cloud-segmentation
b'Condition of pantograph slide plates',b'Images from pantograph slide plates of various rolling stock vehicles',"b'### Context\n\nWe are - as organisation - ordering, maintaining, modernizing and driving rolling stock on behalf of SBB Passenger Transport. The maintenance of the rolling stock is - generally spoken - based on planned and unplanned maintenance activities or tasks. Condition based maintenance or even predictive maintenance based on data acquisition and analysis is becoming more important. \n \n### Content\n\nWe provide a set of images taken from a roof top of a certain rolling stock fleet, using two high resolution cameras; what is of interes is the ""condition"" of the slider element of the catenary; we are willing to provide these images with the aim, that Image processing and analytics shall help SBB and other railway undertakers to manage their slide elements condition based. We managed in a proof of concept using tensorflow to identify ""angled polish"" and ""damage"" - even - measuring the thickness of the remaining slider element.\n\n### Inspiration\n\nWe are aware, that the data will be in front of the world\'s largest data science community. Therefore we are looking for alternative solutions to detect as much as possible of the condition of said slider. Maybe even from other parts which are shown in the images.'","b""['image data', 'image processing', 'rail transport', 'small', 'featured']""",https://www.kaggle.com/gehrig/pantograph
b'Corn & Soybean Prices 2008-2017',b'Prices with USDA WASDE Monthly Projections',"b'### Context\n\nThe U. S. Department of Agriculture (USDA) issues a monthly World Agricultural Supply and Demand Estimate (WASDE) report which includes projections for the Supply and Demand for various U. S. crops. The data in the reports indicates (amongst other things) projected scarcity of crop supplies - which affects price movements on the commodity markets. (Python Kernel to follow shortly.)\n\n### Content\nThe USDA data was acquired by downloading all the historical WASDE reports starting in May2007 through Mar2018. (A python script aggregated the data and output the CSV files in this dataset.)\n\nThe best way to understand the many columns of data is to look at a single WASDE report and visit the [official website with historical reports][1] - but it can be useful to have the projections arranged by date as presented here. I have generated corresponding files for other crops - if they would be of interest to others I\'d be happy to add them.\n\nThe price data has been scraped from a public website - and rearranged for ease of use.\n\nAt any one time there are multiple commodity contracts open and the ""nearby"" is the contract that will be the first to expire. The ""nearby"" files show the close price of the nearby contract during the period Feb2008 through Dec2017. Included are files for two separate contracts - Soybeans_Jul14 and Corn_Jul14: along with Open, High, Low, Close, Volume and OpenInterest, the last column indicates Total Open Interest across all soybean (and respectively corn) contracts on that date.\n\n### Acknowledgements\n\nThe WASDE data is extracted from (public domain) monthly reports produced by the U. S. Department of Agriculture.\n\nBanner Photo by Henry Be on Unsplash\n\n### Inspiration\nThis dataset is interesting because food security is important in a global as well as a domestic sense. \n\nIt would make me extremely happy to be able to tie up NDVI from MODIS or other satellites to yield estimates and crop identification. [Multiple papers][2] indicate it can be done - but I have yet to find the time to parse the [Cropscape][3] classifications so as to have ground truth for training a model.\n\n\n  [1]: http://usda.mannlib.cornell.edu/MannUsda/viewDocumentInfo.do?documentID=1194\n  [2]: https://calmit.unl.edu/people/agitelson2/pdf/2013/RSE2013_MODIS_Corn_Yield.pdf\n  [3]: https://nassgeodata.gmu.edu/CropScape/'","b""['finance', 'agriculture', 'small', 'featured']""",https://www.kaggle.com/ainslie/usda-wasde-monthly-corn-soybean-projections
b'High Storage System Data for Energy Optimization',b'Different datasets from correct running optimized system and runs with anomalies',"b""### Context\n\nIn the [Smartfactory][1] in Lemgo is a demonstrator of a high storage system. The high storage system was built and used in previous research projects, for example in [IMPROVE][2]. Its focus is on data-driven energy optimization. It is also used to perform anomaly detection using timed automata. \n\n\n### Content\n\n![Visualization of the High storage system][3]\n\nThe high storage system consists of 4 short conveyor belts (BLO, BHL, BHR, BRU) and 2 rails (HR, HL). The two conveyor belts in the middle (BHL, BHR) can be moved in the vertical by the rails, the other ones are fixed and they all have a size of 64cm x 8.5cm x 29.7cm. Each conveyor belt has three induction sensors. The first one is 3.6cm from the left edge, the second one 26.6 cm from the left edge and the last sensor is 3.6cm from the right edge.\n\nIt uses a SPS with Codesys V3, which corresponds to IEC61131-Standard.\n\nThe high storage system transports one package between two spots, as you can see in [this Video][4]. The first run is the non-optimized run. The two conveyor belts in the middle are only moving vertical when they do not move the package horizontal. The second run is the optimized run. While the two conveyor belts in the middle are moving the package horizontal, they move vertical as well.\n\nThe generated data is split in four files. HRSS_normal_standard.csv contains normal runs without failures and not optimized. \n\nHRSS_normal_optimized.csv containes optimized runs without failures. \n\nHRSS_anomalous_standard.csv contains runs with failures and not optimized. \n\nAnd HRSS_anomalous_optimized.csv contains optimized runs with failures. \n\nThe *Label* column in each file marks the rows with anomalies. With these files you can test energy based optimization processes by using the normal non-optimized and normal optimized files.\nFurthermore you can test anomaly detection with the normal and anomaly files.\n\nFor more informations you can read the papers below.\n\n\n### Acknowledgements\n\n\xc2\xa9 Copyright | inIT - Institute Industrial IT \n\n\xc2\xa9 Copyright | Ostwestfalen-Lippe University of Applied Sciences\n\nThis dataset is publicly available for anyone to use under [the following terms][5].\n\nvon Birgelen, Alexander; Niggemann, Oliver: Using Self-Organizing Maps to Learn Hybrid Timed Automata in Absence of Discrete Events. In: 22nd IEEE International Conference on Emerging Technologies and Factory Automation (ETFA 2017) Sep 2017.\nhttps://www.hs-owl.de/init/veroeffentlichungen/publikationen/a/filteroff/3054/single.html\n \nvon Birgelen, Alexander; Niggemann, Oliver: Enable learning of Hybrid Timed Automata in Absence of Discrete Events through Self-Organizing Maps. S.: 37-54, Springer Vieweg, Aug 2018.\nhttps://www.hs-owl.de/init/veroeffentlichungen/publikationen/a/filteroff/3369/single.html\n \nHranisavljevic, Nemanja; Niggemann, Oliver; Maier, Alexander: A Novel Anomaly Detection Algorithm for Hybrid Production Systems based on Deep Learning and Timed Automata. In: International Workshop on the Principles of Diagnosis (DX) Denver, Oct 2016.\nhttps://www.hs-owl.de/init/veroeffentlichungen/publikationen/a/filteroff/2881/single.html\n\nIMPROVE has received funding from the European Union's Horizon 2020 research and innovation programme under Grant Agreement No. 678867\n\n### Inspiration\nIs this dataset useful for you?\n\n\n  [1]: https://www.smartfactory-owl.de/index.php/en/\n  [2]: http://www.improve-vfof.eu/\n  [3]: https://ciit-cloud.init.hs-owl.de/index.php/apps/files_sharing/publicpreview/RswAe6fDJ6g8b9J?x=1903&y=576&a=true&file=HRSS.PNG&scalingup=0\n  [4]: https://www.youtube.com/watch?v=3o8PwyuwXXc\n  [5]: https://creativecommons.org/licenses/by-nc-sa/4.0/""","b""['deep learning', 'model comparison', 'energy', 'optimization', 'model monitoring', 'small', 'featured']""",https://www.kaggle.com/inIT-OWL/high-storage-system-data-for-energy-optimization
b'Agricultural Estimates',b'Main crops production and yield in ARG',b'### Context\nThis dataset contains crops production and yield over the years in Argentina. Data is provided by province and district for each seed or harvest campaign from 1969 to 2017.\n\n### Content\n* Sup. Sembrada (Ha) --- Hectares sown\n* Sup. Cosechada (Ha) --- Hectares harvested\n* Produccion (Tn) --- Tonnes produced\n* Rendimiento (Kg/Ha) --- Harvest performance\n\n### Acknowledgements\nThis dataset was kindly made publicly available by [Datos Argentina][1] under the [ODbL][2] license. \n\nPhoto by [Benjamin Davies][4] on [Unsplash][3].\n\n### Inspiration\nMy Data Science adventure start here. My objective is to use this dataset together with Kaggle Kernels as a starting point in my learning process.\n\n  [1]: http://datos.gob.ar/\n  [2]: https://opendatacommons.org/licenses/odbl/\n  [3]: https://unsplash.com/\n  [4]: https://unsplash.com/@bendavisual',"b""['data cleaning', 'agriculture', 'small', 'featured']""",https://www.kaggle.com/pablolebed/agricultural-estimates-arg
b'Avocado Prices',b'Historical data on avocado prices and sales volume in multiple US markets',"b""### Context\n\nIt is a well known fact that Millenials LOVE Avocado Toast. It's also a well known fact that all Millenials live in their parents basements.\n\nClearly, they aren't buying home because they are buying too much Avocado Toast!\n\nBut maybe there's hope... if a Millenial could find a city with cheap avocados, they could live out the Millenial American Dream.\n\n### Content\n\nThis data was downloaded from the Hass Avocado Board website in May of 2018 & compiled into a single CSV. Here's how the [Hass Avocado Board describes the data on their website][1]:\n\n&gt; The table below represents weekly 2018 retail scan data for National retail volume (units) and price. Retail scan data comes directly from retailers\xe2\x80\x99 cash registers based on actual retail sales of Hass avocados. Starting in 2013, the table below reflects an expanded, multi-outlet retail data set. Multi-outlet reporting includes an aggregation of the following channels: grocery, mass, club, drug, dollar and military. The Average Price (of avocados) in the table reflects a per unit (per avocado) cost, even when multiple units (avocados) are sold in bags. The Product Lookup codes (PLU\xe2\x80\x99s) in the table are only for Hass avocados. Other varieties of avocados (e.g. greenskins) are not included in this table.\n\nSome relevant columns in the dataset:\n\n- `Date` - The date of the observation\n- `AveragePrice` - the average price of a single avocado\n- `type` - conventional or organic\n- `year` - the year\n- `Region` - the city or region of the observation\n- `Total Volume` - Total number of avocados sold\n- `4046` - Total number of avocados with PLU 4046 sold\n- `4225` - Total number of avocados with PLU 4225 sold\n- `4770` - Total number of avocados with PLU 4770 sold\n\n### Acknowledgements\n\nMany thanks to the Hass Avocado Board for sharing this data!!\n\nhttp://www.hassavocadoboard.com/retail/volume-and-price-data\n\n### Inspiration\n\nIn which cities can millenials have their avocado toast AND buy a home?\n\nWas the Avocadopocalypse of 2017 real?\n\n\n  [1]: http://www.hassavocadoboard.com/retail/volume-and-price-data""","b""['food and drink', 'small', 'featured']""",https://www.kaggle.com/neuromusic/avocado-prices
b'Chicago City-Owned Land Inventory',b'From City of Chicago Open Data',"b'### Content  \n\nVacant property owned and managed by the City of Chicago Department of Planning and Development. Information provided in the database, or on the City\xe2\x80\x99s website generally, should not be used as a substitute for title research, title evidence, title insurance, real estate tax exemption or payment status, environmental or geotechnical due diligence, or as a substitute for legal, accounting, real estate, business, tax or other professional advice. The City assumes no liability for any damages or loss of any kind that might arise from the reliance upon, use of, misuse of, or the inability to use the LIS database or the City\xe2\x80\x99s web site and the materials contained on the website. The City also assumes no liability for improper or incorrect use of materials or information contained on its website. All materials that appear in the LIS database or on the City\xe2\x80\x99s web site are distributed and transmitted ""as is,"" without warranties of any kind, either express or implied as to the accuracy, reliability or completeness of any information, and subject to the terms and conditions stated in this disclaimer.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/EK8DxK_7IwY) by [Ferdinand Stohr](https://unsplash.com/@fellowferdi) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'utility', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-city-owned-land-inventory
b'Formula 1 Race Data',b'Race data from 1950 to 2017',"b""### Context\n\nFormula One (also Formula 1 or F1 and officially the FIA Formula One World Championship) is the highest class of single-seat auto racing that is sanctioned by the F\xc3\xa9d\xc3\xa9ration Internationale de l'Automobile (FIA). The FIA Formula One World Championship has been one of the premier forms of racing around the world since its inaugural season in 1950.\n\n\n### Content\n\nThis dataset contains data from 1950 all the way through the 2017 season, and consists of tables describing constructors, race drivers, lap times, pit stops and more.\n\n\n### Acknowledgements\n\nThe data was downloaded from http://ergast.com/mrd/ at the conclusion of the 2017 season. The data was originally gathered and published to the public domain by Chris Newell.\n\n\n### Inspiration\n\nI think this dataset offers an exciting insight into a $ billion industry, enjoyed by hundreds of millions of viewers all over the world. So please, explore and enjoy!""","b""['sports', 'auto racing', 'small', 'featured']""",https://www.kaggle.com/cjgdev/formula-1-race-data-19502017
b'Deodorant Instant Liking Data',b'Assessing if Deodorant is instantly likable or not using Logistic Reg',b'### Context\n\nI have consolidated the survey results of Deodorants using excel into the Data_train_reduced.csv.\n\n### Content\n\nData_train_reduced.csv has survey results of 5 deodorants with several information. I have listed some of the key ones below.\n\n**Dependent variable**\n\nInstant Liking \n\n**Independent variables** (some of them)\n\nRespondent ID\n\nProduct ID\n\nWhere the first few words uttered by the user after using the particular for the first time positive or negative\n\nStrength of the Deo (On a scale of 1 to 5)\n\nIs the Deo addicitive (On a scale of 1 to 5)\n',"b""['logistic regression', 'linear regression', 'small', 'featured']""",https://www.kaggle.com/ramkumarr02/deodorant-instant-liking-data
b'City of Seattle Bicycle Racks',b'From City of Seattle Open Data',"b""### Content  \n\nBicycle racks owned and maintained by SDOT. Location of bicycle racks owned and maintained by SDOT in the GIS for cartographic, analysis, and tracking purposes.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/NN6Njz7fRSo) by [Simon Mumenthaler](https://unsplash.com/@mumenthalers) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'government', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/city-of-seattle-bicycle-racks
b'Spoken Wikipedia Corpus (Dutch)',b'224 hours of Dutch audio with transcriptions',"b'### Context:\n\nThe Spoken Wikipedia project unites volunteer readers of Wikipedia articles. Hundreds of spoken articles in multiple languages are available to users who are \xe2\x80\x93 for one reason or another \xe2\x80\x93 unable or unwilling to consume the written version of the article. This is time-aligned corpus of these spoken articles, well suited to research and fostering new ways of interacting with the material.\n\n### Content:\n\nAll spoken articles use a template with slots: filename, speaker, date and revision spoken, ... to insert the audio player and a display of the meta-data on the Wikipedia page. The template also adds spoken articles to a root category. Templates, categories, and meta-data vary between language communities!\n\nThe Dutch language portion of this corpus contains 3073 articles read by 145 speakers. There are 224 hours of speech, of which 79 hours is aligned at the word level.\n\nEach article is tokenized into sections, sentences, and tokens. Each token is normalized and the normalization is aligned to the audio. Complete information on the annotation schema can be found in the schema file.\nFor each article, the corpus contains: \n\n* audio file(s)\n* original WikiText \n* HTML generated by MediaWiki \n* cleaned and normalized text \n* alignment between text and audio \n* meta-information (who, when, what)\n\nFor additional information and updates, please see [the project website](http://nats.gitlab.io/swc/).\n\n### Acknowledgements: \n\nThis dataset was collected by Arne K\xc3\xb6hn, Florian Stegen and Timo Baumann. If you use this dataset in your work, please cite the following paper:\n\nK\xc3\xb6hn, A., Stegen, F., & Baumann, T. (2016). Mining the Spoken Wikipedia for Speech Data and Beyond. In the Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016).\n\n### Inspiration: \n\nSome possible uses for this corpus include:\n\n* train or evaluate automatic speech recognition systems\n* improve accessibility / spoken article navigation\n* top contributors speak >30 hours, which is enough audio to train synthesis voices\n* analyze prosody of reading (large amounts of diversely read text) \n* analyze prosody of information structure (accessible through links, research on semantic Wikipedia, Dbpedia, ...)'","b""['linguistics', 'europe', 'languages', 'acoustics', 'large', 'featured']""",https://www.kaggle.com/rtatman/spoken-wikipedia-corpus-dutch
b'Segmentation of OCT images (AMD)',b'Optical coherence tomography (OCT) and age-related macular degeneration (AMD)',"b'### Context\n\nImages for segmentation of optical coherence tomography images with age-related macular degeneration.\n\nIndividual SDOCT images and marking: 38400 BScans from 269 AMD patients and 115 normal subjects, their ages, and their corresponding segmentation boundaries on a 5mm diameter centered at the fovea.\n\n### Content\n\n\nIndividual SDOCT images and marking: 38400 BScans from 269 AMD patients and 115 normal subjects, their ages, and their corresponding segmentation boundaries on a 5mm diameter centered at the fovea.\n\nNOTE: These results are based on measurements on Bioptigen system. Our preliminary results indicate differences in measured thickness between and even within manufacturers (e.g., a correction factor of 1.16 would be used to convert our reported thicknesses at central fovea to those from Spectralis [Heidelberg Inc, Heidelberg, Germany]). \n\nFor this study, we used the dataset from the A2A SD-OCT\nStudy, which was registered at ClinicalTrials.gov (Identifier:\nNCT00734487) and approved by the institutional review boards of\nthe 4 A2A SD-OCT clinics (Devers Eye Institute, Duke Eye\nCenter, Emory Eye Center, and National Eye Institute). With\nadherence to the tenets of the Declaration of Helsinki, informed\nconsent was obtained from all subjects.\n\nThe AREDS2 and A2A SD-OCT Study design and protocol for\ngrading fundus photographs (AREDS2) and SD-OCT images\n(A2A SD-OCT) have been described.20,21 In brief, subjects who\nmet the following inclusion criteria were enrolled: between 50 and\n85 years of age, exhibiting intermediate AMD with large drusen\n(&gt;125 mm) in both eyes or large drusen in 1 eligible eye and\nadvanced AMD in the fellow eye, with no history of vitreoretinal\nsurgery or ophthalmologic disease that might affect acuity in either\neye. Age-appropriate control subjects were enrolled with the same\ninclusion criteria as for AREDS2 except that they must have had\nno evidence of macular drusen or AMD in either eye at the baseline\nvisit or in the follow-up years. Stereoscopic color fundus photograph\npairs were taken at the baseline visit as part of the AREDS2\nprotocol20 and then graded by certified readers at the Wisconsin\nFundus Photography Reading Center (University of Wisconsin,\nMadison, WI). For our study, eyes assigned a Wisconsin drusen\narea score of \xe2\x80\x9ccannot grade\xe2\x80\x9d (drusen area was only partially\nvisible for the field under consideration, such as when an\nobscuring lesion or poor photographic quality did not permit\na reasonably confident assessment of drusen) at the Wisconsin\nCenter were excluded.\n\nThe SD-OCT imaging systems from Bioptigen, Inc (Research\nTriangle Park, NC), located at the 4 clinic sites, were used to\nacquire volumetric rectangular (w6.7\x01w6.7 mm) scans as\npreviously published.21 To summarize, for all subjects, 0 and 90\nrectangular volumes centered at the fovea (defined as volumes\nacquired with the fast scan direction oriented horizontally and\nvertically, respectively) with 1000 A-scans per B-scan and 100\nB-scans per volume were captured for both eyes. In the A2A\nSD-OCT Study, of the 345 participants with AMD, 314 had at\nleast 1 eye with intermediate AMD, and of the 122 control subjects\nwithout AMD, 119 had no eye disease at baseline.21 From these, 1\neligible eye of each subject had been randomly selected as the\nstudy eye as detailed by Leuschen et al.21 Eye length was not\nmeasured. Certified SD-OCT readers assessed the scan quality\nfor each volume.21 For this study, we selected the 0 volumes by\ndefault, and any poor-quality (as assessed by graders)\n0 volumes were replaced by a 90 volume from the same visit; if\nboth scan volumes were poor, then the eye was excluded altogether.\nThe excluded eyes were mainly those that contained blank\nor extremely low-quality images due to blinks or imaging errors or\nthose volumes that exhibited significant eye motion or loss of\nfixation during image acquisition. Thus, in this study, we analyzed\n269 of the 314 eyes with intermediate AMD and 115 of the 119\ncontrol (normal) eyes.\n\n\n### Acknowledgements\n\n\nhttp://people.duke.edu/~sf59/Farsiu_Ophthalmology_2013.pdf\nhttp://people.duke.edu/~sf59/RPEDC_Ophth_2013_dataset.htm\n\nS. Farsiu, SJ. Chiu, R.V. O\xe2\x80\x99Connell, F.A. Folgar, E. Yuan, J.A. Izatt, and C.A. Toth\n""Quantitative Classification of Eyes with and without Intermediate Age-related Macular Degeneration Using Optical Coherence Tomography"", \nOphthalmology, 121(1),  162-172 Jan. (2014).\n\nPlease reference [the paper][1] if you would like to use any part of this method or datasets. \nPlease contact Prof. Sina Farsiu, PhD or Prof. Cynthia A. Toth, MD if you have questions about this dataset. \n\nBanner Image by [Harry Quan on Unsplash][2]\n\n\n\n  [1]: http://people.duke.edu/~sf59/Farsiu_Ophthalmology_2013.pdf\n  [2]: https://unsplash.com/photos/G1iYCeCW2EI'","b""['image data', 'medicine', 'object segmentation', 'large', 'featured']""",https://www.kaggle.com/paultimothymooney/farsiu-2014
b'Car Fuel Consumption',"b'Which of two fuels is cheaper, E10 or SP 98?'","b'### Context\n\nI am driving always the same car and i take almost always the same route. However, at the gas station i like to change the gas type; between SP98 (sold as ""Super plus"" sometimes) and SP95 E10 (This is, ""super"" gas with 10% Alcohol). E10 is sold for 1,38\xe2\x82\xac; SP98 is sold for 1,46\xe2\x82\xac; per liter.\n\nFrom my feeling i would say that my car consumes a lot more with E10. From the data, what can we derive there?\nI challenge you to partial out the factor ""E10 gas"" and tell me how much my car really consumes more with it. \n\nI applied my own basic linear regression on it and had as a result that it consumes 0.4 liters more with E10 gas. Linear regressions have the disadvantage that you can only really use them if the features are independent.\n\n\n**I challenge you to predict the consumption depending on the gas type!**\n\n\n### Content\n\nSince a few months, i write down the data of my car\'s display after each ride; while regularly changing the gas type.\n\nIn the file, you will find the displayed distance (km); the consume (L/100km); the average speed (km/h), the temperature i had inside (\xc2\xb0C), the temperature outside (\xc2\xb0C), anything special that happened, if it was raining, if the air condition was on, if it was sunny enough that the car felt warm when i started it... and yes - the gas type i was using. I have also two columns saying how much and which gas type I was buying. Careful with those. The numbers don\'t add exactly up, because I note only the rides that occur under certain conditions: If the car was not cooling down enough to have another independent measure from the one before, i don\'t note it.\n\nI started writing down the data in November, changed to SP98 in winter, and back to E10 in spring. Apart from that, the data is rather clean as i was doing my own project on it already.\n\n### Acknowledgements\n\nThanks to Victor Chernozhukov who was planting this idea in my head, even if it took some years until i finally acted on it. :-)\n\n### Inspiration\n\nI was using a linear regression to partial out the influence of the gas type. The gas type is truly independent from the rest of the variables, so it should be possible without problem. However - depending on how i engineer the other features, the result is between 0.4 and 0.8 liters per 100km influence. A large, single-feature-depending difference usually is a hint for lots of covariance between the features; meaning in turn that linear regression might not be the best tool here.\n\n\n\n'","b""['beginner', 'regression analysis', 'regression', 'small', 'featured']""",https://www.kaggle.com/anderas/car-consume
b'Toy Products on Amazon',"b'10,000 toy products on Amazon.com'","b'###Context\n\nThis is a pre-crawled dataset, taken as subset of a bigger [dataset (more than 7 million products)][1] that was created by extracting data from Amazon.com.\n\n### Content\n\nThis dataset has following fields:\n\n- `product_name`\n- `manufacturer` - The item manufacturer, as reported on Amazon. Some common ""manufacturers"", like Disney, actually outsource their assembly line.\n- `price`\n- `number_available_in_stock`\n- `number_of_reviews`\n- `number_of_answered_questions` - Amazon includes a Question and Answer service on all or most of its products. This field is a count of how many questions that were asked actually got answered.\n- `average_review_rating`\n- `amazon_category_and_sub_category` - A tree-based, `>>`-delimited categorization for the item in question.\n- `customers_who_bought_this_item_also_bought` - References to other items that similar users bought. This is a recommendation engine component that played a big role in making Amazon popular initially.\n- `description`\n- `product_information`\n- `product_description`\n- `items_customers_buy_after_viewing_this_item`\n- `customer_questions_and_answers` - A string entry with all of the product\'s JSON question and answer pairs.\n- `customer_reviews` - A string entry with all of the product\'s JSON reviews.\n- `sellers` - A string entry with all of the product\'s JSON seller information (many products on Amazon are sold by third parties).\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud\'s in-house web-crawling service.\n\n### Inspiration\nThis detailed dataset can be used to answer questions like:\n\n- What types of toys are most popular on Amazon?\n- How dominant are brands in the Amazon toy market?\n- Can you break down reviews to analyze their sentiment and contents?\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=am-kaggle&utm_medium=referral'","b""['internet', 'medium', 'featured']""",https://www.kaggle.com/PromptCloudHQ/toy-products-on-amazon
b'NumtaDB: Bengali Handwritten Digits',b'Build a classification model for Bengali handwritten digits.',"b""###Notice: This page will be used for Kernels, Starter Codes, and Discussions. For competition rules, evaluation metric description, new team registration, data download and result submission click  [here](https://www.kaggle.com/c/numta).\n### Context\n<p>Currently, natural language processing (NLP) research is developing rapidly due to the rise of artificial intelligence (AI). One of the key topics of NLP is optical character recognition (OCR). To build an OCR in Bengali language, digit classification provides a convenient starting point.  We have accumulated a large dataset (85,000+) of Bengali digits (NumtaDB) which can be used by researchers for benchmarking their algorithm. </p>\n\n### Content\n\nThe dataset is a combination of six datasets that were gathered from different sources and at\ndifferent times. However, each of them was checked rigorously under the same evaluation\ncriterion so that all digits were at least legible to one human being without any prior knowledge.\nDescriptions of these datasets including collection methodology, image segmentation and\nextraction and image formats of these datasets are described in [https://bengali.ai/datasets](https://bengali.ai/datasets).\n\nThe sources are labeled from 'a' to 'f'. The training and testing sets have separate subsets\ndepending on the source of the data (training-a, testing-a, etc.). All the datasets have been\npartitioned into training and testing sets so that handwriting from the same subject/contributor\nis not present in both. Dataset-f had no corresponding metadata for contributors for which all of\nit was added to the testing set (testing-f). The metric for the competition is selected to be the\nUnweighted Average Accuracy (UAA). Starter codes for the competition are available at\n[https://github.com/BengaliAI](https://github.com/BengaliAI).\n\n*Two augmented datasets (augmented from test images of dataset 'a' and 'c') are appended to the testing set which consists of the following augmentations:*\n\n - Spatial Transformations: Rotation, Translation, Shear, Height/Width Shift, Channel Shift, Zoom.\n - Brightness, Contrast, Saturation, Hue shifts, Noise.\n - Occlusions.\n - Superimposition (to simulate the effect of text being visible from the other side of a page).\n\n### Inspiration\n\nIf you are a Bengali machine learning enthusiast this is a good starting point to get accustomed to computer vision algorithms using a dataset in your native language.\n\nAlso, the augmented test images challenge the learners to learn about image augmentation and implement their own image augmentation pipeline.\n\n### Acknowledgements\n\nNumerals in dataset 'e' are collected and curated version of [BanglaLekha-Isolated](https://www.sciencedirect.com/science/article/pii/S2352340917301117). We would like to thank the researcher for allowing us to integrate it into our database.\n\n### When referencing this material please cite the below paper\n\n[NumtaDB - Assembled Bengali Handwritten Digits](https://arxiv.org/abs/1806.02452)\n\n**Bibtex**\n\n@article{alam2018numtadb,\n\n  title={NumtaDB-Assembled Bengali Handwritten Digits},\n\n  author={Alam, Samiul and Reasat, Tahsin and Doha, Rashed Mohammad and Humayun, Ahmed Imtiaz},\n\n  journal={arXiv preprint arXiv:1806.02452},\n\n  year={2018}\n\n}\n""","b""['image data', 'image processing', 'large', 'featured']""",https://www.kaggle.com/BengaliAI/numta
b'mlcourse.ai',b'Open Machine Learning Course by OpenDataScience',"b""Open Machine Learning Course [mlcourse.ai](http://mlcourse.ai/) is designed to perfectly balance theory and practice; therefore, each topic is followed by an assignment with a deadline in a week. You can also take part in several Kaggle Inclass competitions held during the course and write your own tutorials. The next session starts on **October 1, 2018**. Fill in [this form](https://docs.google.com/forms/d/1_pDNuVHwBxV5wuOcdaXoxBZneyAQcqfOl4V2qkqKbNQ/) to participate. More info in [GitHub repo](https://github.com/Yorko/mlcourse.ai). \n\n### Outline\nThis is the list of published articles on [medium.com](https://medium.com/open-machine-learning-course) (English), [habr.com](https://habr.com/company/ods/blog/344044/) (Russian), and [jqr.com](https://www.jqr.com/) (Chinese). See Kernels of this Dataset for the same material in English. \n\n1. Exploratory Data Analysis with Pandas [uk](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-1-exploratory-data-analysis-with-pandas-de57880f1a68)  [ru](https://habrahabr.ru/company/ods/blog/322626/), [cn](https://www.jqr.com/article/000079), [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-1-exploratory-data-analysis-with-pandas)\n2. Visual Data Analysis with Python [uk](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-2-visual-data-analysis-in-python-846b989675cd)  [ru](https://habrahabr.ru/company/ods/blog/323210/), [cn](https://www.jqr.com/article/000086), Kaggle Kernels: [part1](https://www.kaggle.com/kashnitsky/topic-2-visual-data-analysis-in-python), [part2](https://www.kaggle.com/kashnitsky/topic-2-part-2-seaborn-and-plotly)\n3. Classification, Decision Trees and k Nearest Neighbors [uk](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-3-classification-decision-trees-and-k-nearest-neighbors-8613c6b6d2cd), [ru](https://habrahabr.ru/company/ods/blog/322534/), [cn](https://www.jqr.com/article/000139), [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn)\n4. Linear Classification and Regression [uk](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-4-linear-classification-and-regression-44a41b9b5220), [ru](https://habrahabr.ru/company/ods/blog/323890/), [cn](https://www.jqr.com/article/000175), Kaggle Kernels: [part1](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-1-ols), [part2](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification), [part3](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-3-regularization), [part4](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit), [part5](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-5-validation)\n5. Bagging and Random Forest [uk](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-5-ensembles-of-algorithms-and-random-forest-8e05246cbba7), [ru](https://habrahabr.ru/company/ods/blog/324402/), [cn](https://www.jqr.com/article/000241), Kaggle Kernels: [part1](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-1-bagging), [part2](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-2-random-forest), [part3](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-3-feature-importance)\n6. Feature Engineering and Feature Selection [uk](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-6-feature-engineering-and-feature-selection-8b94f870706a), [ru](https://habrahabr.ru/company/ods/blog/325422/), [cn](https://www.jqr.com/article/000249), [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection)\n7. Unsupervised Learning: Principal Component Analysis and Clustering [uk](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-7-unsupervised-learning-pca-and-clustering-db7879568417), [ru](https://habrahabr.ru/company/ods/blog/325654/), [cn](https://www.jqr.com/article/000336), [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-7-unsupervised-learning-pca-and-clustering)\n8. Vowpal Wabbit: Learning with Gigabytes of Data [uk](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-8-vowpal-wabbit-fast-learning-with-gigabytes-of-data-60f750086237), [ru](https://habrahabr.ru/company/ods/blog/326418/), [cn](https://www.jqr.com/article/000348), [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-8-online-learning-and-vowpal-wabbit)\n9. Time Series Analysis with Python, part 1 [uk](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-time-series-analysis-in-python-a270cb05e0b3), [ru](https://habrahabr.ru/company/ods/blog/327242/), [cn](https://www.jqr.com/article/000450). Predicting future with Facebook Prophet, part 2 [uk](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-part-3-predicting-the-future-with-facebook-prophet-3f3af145cdc), [cn](https://www.jqr.com/article/000598) Kaggle Kernels: [part1](https://www.kaggle.com/kashnitsky/topic-9-part-1-time-series-analysis-in-python), [part2](https://www.kaggle.com/kashnitsky/topic-9-part-2-time-series-with-facebook-prophet)\n10. Gradient Boosting [uk](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-10-gradient-boosting-c751538131ac), [ru](https://habrahabr.ru/company/ods/blog/327250/), [cn](https://www.jqr.com/article/000573), [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-10-gradient-boosting)\n\n### Assignments\nEach topic is followed by an assignment. See demo versions in this Dataset. Solutions will be discussed in the upcoming run of the course.  \n\n### Kaggle competitions\n1. Catch Me If You Can: Intruder Detection through Webpage Session Tracking. [Kaggle Inclass](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2)\n2. How good is your Medium article? [Kaggle Inclass](https://www.kaggle.com/c/how-good-is-your-medium-article/)\n\n### Rating\nThroughout the course we are maintaining a student rating. It takes into account credits scored in assignments and Kaggle competitions. Top students (according to the final rating) will be listed on a special Wiki page.\n\n### Community\nDiscussions between students are held in the **#mlcourse_ai** channel of the OpenDataScience Slack team. Fill in [this form](https://drive.google.com/open?id=1_pDNuVHwBxV5wuOcdaXoxBZneyAQcqfOl4V2qkqKbNQ) to get an invitation (to be sent in September 2018). The form will also ask you some personal questions, don't hesitate\n\n### Collaboration\nYou can publish Kernels using this Dataset. But please respect others' interests: don't share solutions to assignments and well-performing solutions for Kaggle Inclass competitions. If you notice any typos/errors in course material, please open an [Issue](https://github.com/Yorko/mlcourse.ai/issues) or make a pull request in course [repo](https://github.com/Yorko/mlcourse.ai).\n""","b""['data visualization', 'classification', 'regression', 'clustering', 'medium', 'featured']""",https://www.kaggle.com/kashnitsky/mlcourse
b'California Housing Data (1990)',b'California Housing Price Prediction',"b'# Source\n\nThis is the dataset used in this book: https://github.com/ageron/handson-ml/tree/master/datasets/housing to illustrate a sample end-to-end ML project workflow (pipeline). This is a great book - I highly recommend!\n\nThe data is based on California Census in 1990.\n\n### About the Data (from the book):\n\n""This dataset is a modified version of the California Housing dataset available from Lu\xc3\xads Torgo\'s page (University of Porto). Lu\xc3\xads Torgo obtained it from the StatLib repository (which is closed now). The dataset may also be downloaded from StatLib mirrors.\n\nThe following is the description from the book author:\n\nThis dataset appeared in a 1997 paper titled Sparse Spatial Autoregressions by Pace, R. Kelley and Ronald Barry, published in the Statistics and Probability Letters journal. They built it using the 1990 California census data. It contains one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n\nThe dataset in this directory is almost identical to the original, with two differences: \n207 values were randomly removed from the total_bedrooms column, so we can discuss what to do with missing data.\nAn additional categorical attribute called ocean_proximity was added, indicating (very roughly) whether each block group is near the ocean, near the Bay area, inland or on an island. This allows discussing what to do with categorical data.\nNote that the block groups are called ""districts"" in the Jupyter notebooks, simply because in some contexts the name ""block group"" was confusing.""\n\n### About the Data (From Lu\xc3\xads Torgo page): \nhttp://www.dcc.fc.up.pt/%7Eltorgo/Regression/cal_housing.html\n\nThis is a dataset obtained from the StatLib repository. Here is the included description:\n\n""We collected information on the variables using all the block groups in California from the 1990 Cens us. In this sample a block group on average includes 1425.5 individuals living in a geographically co mpact area. Naturally, the geographical area included varies inversely with the population density. W e computed distances among the centroids of each block group as measured in latitude and longitude. W e excluded all the block groups reporting zero entries for the independent and dependent variables. T he final data contained 20,640 observations on 9 variables. The dependent variable is ln(median house value).""\n\n\n### End-to-End ML Project Steps (Chapter 2 of the book)\n\n1. Look at the big picture \n2. Get the data\n3. Discover and visualize the data to gain insights\n4. Prepare the data for Machine Learning algorithms\n5. Select a model and train it\n6. Fine-tune your model \n7. Present your solution\n8. Launch, monitor, and maintain your system\n\n# The 10-Step Machine Learning Project Workflow (My Version)\n\n1. Define business object\n2. Make sense of the data from a high level\n    - data types (number, text, object, etc.)\n    - continuous/discrete\n    - basic stats (min, max, std, median, etc.) using boxplot\n    - frequency via histogram\n    - scales and distributions of different features\n3. Create the traning and test sets using proper sampling methods, e.g., random vs. stratified\n4. Correlation analysis (pair-wise and attribute combinations)\n5. Data cleaning (missing data, outliers, data errors)\n6. Data transformation via pipelines (categorical text to number using one hot encoding, feature scaling via normalization/standardization, feature combinations)\n7. Train and cross validate different models and select the most promising one (Linear Regression, Decision Tree, and Random Forest were tried in this tutorial)\n8. Fine tune the model using trying different combinations of hyperparameters\n9. Evaluate the model with best estimators in the test set\n10. Launch, monitor, and refresh the model and system\n'","b""['tutorial', 'business', 'housing', 'small', 'featured']""",https://www.kaggle.com/harrywang/housing
b'Hungarian Single Speaker Speech Dataset',b'CSS10 Hungarian: Single Speaker Speech Dataset',"b'### Context\n\nCSS10 is a collection of single speaker speech datasets for 10 languages. Each of them consists of audio files recorded by a single volunteer and their aligned text sourced from LibriVox.\n\n### Content\nEach line in `transcript.txt` is delimited by `|` into four fields, i.e., audio file location, original script, normalized script, and audio duration.\n\nVisit [here](https://github.com/kyubyong/css10) to check out our project using this dataset.\n\n### Acknowledgements\n\nWe thank LibriVox and the volunteers.\n \n### Contact\nYou can contact me at kbpark.linguist@gmail.com.\n\nJune, 2018.\n\nKyubyong Park & Tommy Mulc\n'","b""['linguistics', 'large', 'featured']""",https://www.kaggle.com/bryanpark/hungarian-single-speaker-speech-dataset
b'Cities in Australia',b'List of Australian cities with populations',b'### Context\n\nThis dataset was scraped from  [this wikipedia page][1].\n\n### Content\n\n - GCCSA/SUA: City Name \n - State/Territory: State Name \n - June 2017[2]:  2017 Census Population Count for local government area\n - 2011Census[3]Population: 2011 Census Population Count for local\n   government area \n - Growth: Population growth from 2011 to 2017\n - Percentage of population (June 2017): 2017 Proportion to the\n   population in Australia\n\n### Acknowledgements\n\nOriginal data was collected by [Australian Bureau of Statistics][2].\n\n### Inspiration\n\n - What city/state has the highest growth rate?\n\n  [1]: https://en.wikipedia.org/wiki/List_of_cities_in_Australia_by_population\n  [2]: http://www.abs.gov.au/',"b""['demographics', 'geography', 'utility', 'australia', 'small', 'featured']""",https://www.kaggle.com/koki25ando/city-list-of-australia
b'fastText English Word Vectors Including Sub-words',"b'Word vectors trained on Wikipedia 2017, UMBC webbase corpus, and statmt.org'","b'### English Word Vectors with sub-word information\n\n---\n\n### About fastText<br>\n\nfastText is a library for efficient learning of word representations and sentence classification. One of the key features of fastText word representation is its ability to produce vectors for any words, even made-up ones. Indeed, fastText word vectors are built from vectors of substrings of characters contained in it. This allows you to build vectors even for misspelled words or concatenation of words.\n\n\n### About the vectors<br>\nThese pre-trained vectors contain 1 million word vectors learned with subword information on Wikipedia 2017, the UMBC webbase corpus and the statmt.org news dataset. In total, it contains 16B tokens.\n\nThe first line of the file contains the number of words in the vocabulary and the size of the vectors. Each line contains a word followed by its vectors, like in the default fastText text format. Each value is space separated. Words are ordered by descending frequency.\n\n### Acknowledgements<br>\nThese word vectors are distributed under the Creative Commons Attribution-Share-Alike License 3.0.\n\nP. Bojanowski*, E. Grave*, A. Joulin, T. Mikolov, Enriching Word Vectors with Subword Information<br>\nA. Joulin, E. Grave, P. Bojanowski, T. Mikolov, Bag of Tricks for Efficient Text Classification<br>\nA. Joulin, E. Grave, P. Bojanowski, M. Douze, H. J\xc3\xa9gou, T. Mikolov, FastText.zip: Compressing text classification models<br><br>\n\n(* These authors contributed equally.)'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/facebook/fasttext-english-word-vectors-including-subwords
b'CelebFaces Attributes (CelebA) Dataset',b'Over 200k images of celebrities with 40 binary attribute annotations',"b'### Context\nA popular component of computer vision and deep learning revolves around identifying faces for various applications from logging into your phone with your face or searching through surveillance images for a particular suspect. This dataset is great for training and testing models for face detection, particularly for recognising facial attributes such as finding people with brown hair, are smiling, or wearing glasses. Images cover large pose variations, background clutter, diverse people, supported by a large quantity of images and rich annotations. This data was originally collected by researchers at MMLAB, The Chinese University of Hong Kong (specific reference in Acknowledgment section).\n\n### Content\n**Overall**\n\n- 202,599 number of face images of various celebrities\n- 10,177 unique identities, but names of identities are not given\n- 40 binary attribute annotations per image\n- 5 landmark locations\n\n**Data Files**\n\n- **img_align_celeba.zip**: All the face images, cropped and aligned\n- **list_eval_partition.csv**: Recommended partitioning of images into training, validation, testing sets. Images 1-162770 are training, 162771-182637 are validation, 182638-202599 are testing\n- **list_bbox_celeba.csv**: Bounding box information for each image. ""x_1"" and ""y_1"" represent the upper left point coordinate of bounding box. ""width"" and ""height"" represent the width and height of bounding box\n- **list_landmarks_align_celeba.csv**: Image landmarks and their respective coordinates. There are 5 landmarks: left eye, right eye, nose, left mouth, right mouth\n- **list_attr_celeba.csv**: Attribute labels for each image. There are 40 attributes. ""1"" represents positive while ""-1"" represents negative\n\n### Acknowledgements\nOriginal data and banner image source came from http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\nAs mentioned on the website, the CelebA dataset is **available for non-commercial research purposes only**. For specifics please refer to the website.\n\nThe creators of this dataset wrote the following paper employing CelebA for face detection:\n\n*S. Yang, P. Luo, C. C. Loy, and X. Tang, ""From Facial Parts Responses to Face Detection: A Deep Learning Approach"", in IEEE International Conference on Computer Vision (ICCV), 2015*\n\n### Inspiration\n\n- Can you train a model that can detect particular facial attributes?\n- Which images contain people that are smiling?\n- Does someone have straight or wavy hair?'","b""['classification', 'image data', 'image processing', 'object identification', 'large', 'featured']""",https://www.kaggle.com/jessicali9530/celeba-dataset
b'Yelp Dataset',"b'A trove of reviews, businesses, users, tips, and check-in data!'","b""## Context\n\nThis dataset is a subset of Yelp's businesses, reviews, and user data. It was originally put together for the Yelp Dataset Challenge which is a chance for students to conduct research or analysis on Yelp's data and share their discoveries.  In the dataset you'll find information about businesses across 11 metropolitan areas in four countries. \n\n## Content<br>\nThis dataset contains seven CSV files. The original JSON files can be found in yelp_academic_dataset.zip. <br><br>\nYou may find this documentation helpful:<br>\n[https://www.yelp.com/dataset/documentation/json][1]\n\nIn total, there are :\n\n- 5,200,000 user reviews\n- Information on 174,000 businesses\n- The data spans 11 metropolitan areas\n\n\n## Acknowledgements<br>\nThe dataset was converted from JSON to CSV format and we thank the team of the Yelp dataset challenge for creating this dataset.<br>\n\nBy downloading this dataset, you agree to the [Yelp Dataset Terms of Use][2].<br>\n\n## Inspiration\n\nNatural Language Processing & Sentiment Analysis<br>\nWhat's in a review? Is it positive or negative? Yelp's reviews contain a lot of metadata that can be mined and used to infer meaning, business attributes, and sentiment.\n\nGraph Mining<br>\nWe recently launched our Local Graph but can you take the graph further? How do user's relationships define their usage patterns? Where are the trend setters eating before it becomes popular?\n\n\n  [1]: https://www.yelp.com/dataset/documentation/json\n  [2]: https://s3-media2.fl.yelpcdn.com/assets/srv0/engineering_pages/af4b9cebfb4f/assets/vendor/dataset-challenge-dataset-agreement.pdf""","b""['food and drink', 'large', 'featured']""",https://www.kaggle.com/yelp-dataset/yelp-dataset
b'The World English Bible',"b'A large, single-speaker speech dataset in English'","b""### Context\n\nThe World English Bible is a public domain update of the American Standard Version of 1901 into modern English. Its audio recordings are freely available at http://www.audiotreasure.com/. The only problem when you use those in speech-relevant tasks is that each file is too long. That's why I split each audio file such that an audio clip is equivalent to a verse. Subsequently I aligned them to the text.\n\n### Content\n\nThis dataset is composed of the following:<br>\n- README.md<br>\n- wav files sampled at 12,000 KHZ<br>\n- transcript.txt.<br><br>\n\n`transcript.txt` is in a tab-delimited format. The first column is the audio file paths. The second one is the script. Finally, the rightmost column is the duration of the audio file.\n\n\n### Acknowledgements\n\nI would like to show my respect to Dave, the host of www.audiotreasure.com and the reader of the audio files.\n\n\n### Reference\n\nYou may want to check my project using this dataset at https://github.com/Kyubyong/tacotron.""","b""['linguistics', 'languages', 'large', 'featured']""",https://www.kaggle.com/bryanpark/the-world-english-bible-speech-dataset
b'New York City Inspections',b'From New York City Open Data',"b""### Content  \n\nThis data set features DCA inspections during the last and current calendar years to ensure compliance with local consumer protection and licensing laws, and State and federal regulations.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Y9nzl9tA3Lw) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'business', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/new-york-city-inspections
b'Open Source Bee Hive Labeled Images',b'Data Submitted and Labeled by Beekeepers around the World',"b'# Context\n\nThis dataset is a continuation of the [Annotated Honey Bee Images][1] dataset. While that dataset has exclusively bee images that have been extracted from videos, this dataset consists of labeled images of frames, hives, and more. \n\n\n# Content\n\nThis dataset has been compiled by different beekeepers. \n\nThere are three primary sections: hive, frame, other, and uncategorized.\n\n###**In the ""frame"" folder, there are sub-sections of:**\n\n**american_foulbrood**: contains images of frames affected by American Foulbrood.\n\n**chalkbrood**: contains images of frames with Chalkbrood.\n\n**general_distr**: contains images of frames with a corresponding CSV file giving percentages of the distribution of different elements in the frame.\n\n**laying_pattern**: contains images of frames with brood with a corresponding score about the strength of the laying pattern in the CSV file.\n\n**pollen_color**: contains images of frames with nectar and a corresponding CSV file with the number of different pollen colors. \n\n**robber_bees**: contains two folders with images of frames that have been robbed and are being robbed.\n\n**varroa_present**: contains images of frames with varroa mites present and an accompanying form explaining how the beekeeper had tested for mites and the treatment decision.\n\n**wax_moth**: contains images of frames affected by wax moths.\n\n###**In the ""hive"" folder, there are subsections of:**\n\n**frameabees**: contains hives images and their corresponding frameabees score, indicating the foraging strength of the hive.\n\n**robber_bees**: contains images of the hive currently being robbed, from the outside perspective.\n\n###**In the ""other"" folder, there are subsections of:**\n\n**pollen_tray**: contains images of the pollen tray with a corresponding CSV file containing the number of pollen colors.\n\nIn the ""uncategorized"" folder, there are any images of the hive, from any perspective.\n\n# Acknowledgements\n\nThank you to the beekeepers that have contributed images of their hives or helped label data! If you would like to contribute in **any way**, please contact jy2k16@gmail.com or fill out this form: https://goo.gl/forms/FzSUhw6z9QMSTpaH2. Your help drives this project and the bee conservation movement forward.\n\n##**What you can do to label data:**\n\n1. Visit the ""Uncategorized"" folder and help sort the images into the folders they should be in. If one image can fit more than one description, make a duplicate and add it to both folders. Be aware that some folders have accompanying CSV files where you will need to fill out data about the image!\n\n2. Visit the ""laying_pattern"" or ""pollen_color"" sub-folders in ""frame"". Help add labels about the laying_pattern score or number of pollen colors in the respective images.\n\n3. Visit the ""frameabees"" sub-folder in ""hive"". Help add a frameabees score for the hive images.\n\n4. Visit the ""pollen_tray"" sub-folder in ""other"". Help add a number for the pollen colors for the respective images.\n\n##**What you can do to contribute data:**\n\n1. Take images of your hives, frames, and pollen sheets on your next hive inspection. If your hive encounters any of these problems: American foulbrood, chalkbrood, poor laying pattern, robber bees, varroa mites present, or wax moths, **please take a picture of the affected frame or hive!**\n\n2. Even if your hive is healthy, feel free to take some images of the frames and upload them with labels in these categories: general distributions (of honey, nectar, brood on a single frame) and pollen color.\n\n3. If you spot an interesting characteristic that\'s not included above, feel free to create a new folder in the correct location and add the data. Email me if you have questions! (jy2k16@gmail.com)\n\nCover and thumbnail photo by Damien TUPINIER on Unsplash\n\n# Inspiration\n\nHow can visual information about different aspects of the hive be used to determine different characteristics about the hive condition? (health, queen presence, etc)\n\nHow can we better understand our bees using data from the hive, frames, and even pollen tray?\n\n  [1]: https://www.kaggle.com/jenny18/honey-bee-annotated-images'","b""['animals', 'environment', 'agriculture', 'nature', 'medium', 'featured']""",https://www.kaggle.com/jenny18/open-source-bee-hive-labeled-images
b'Mental Health Patient Activities 2010-2016 NZ',"b'Statistics of Mental Health Patients in New Zealand, 2010 - 2016'","b'### Context\n\nMental health statistics, Patient Activities, New Zealand\n\n\n### Content\n\nCombined Dataset of yearly statistics, for activities undertaken by mental health patients / clients in New Zealand\nJuly 2010 to June 2016.\nPatient counts are divided by:\nAnnual period,\nActivity type,\nGender (Total, Male, Female),\nEthnicity (Maori, Asian, Pacific Island, European, Other),\nAge group (0-85 in 5 year groupings, and +85).\n\nSome Activity Types are absent, discontinued or changed between annual periods.\nSome rows are missing by Gender (1 female, several male).\n\n\n### Acknowledgements\n\nThanks to the NZ ministry of Health for making these datasets public under Creative Commons License.\n\n\n### Inspiration\n\nThere has been much ongoing debate in NZ regarding mental health practice and effectiveness for Indigenous (Maori) people. It is worth seeing how effective changes to mental health practice have been over the past few years and the uptake of relevant activities. \nAdditionally, policy changes that have allowed a large increase in population after 2012 (with a large immigration increase from Asian countries), and frozen or below-inflation increases in mental health funding, may have significantly impacted on the numbers of people seeking mental health, and the ability to treat patients.\n\n\n### Notes\n\nThis dataset will be updated  with additional information on patient intakes / releases, and possibly additional data on agencies and some specific activities, where applicable.'","b""['government', 'mental health', 'small', 'featured']""",https://www.kaggle.com/rask004/mental-health-patient-activities-20102016-nz
b'Traditional Decor Patterns',b'Pattern Classification',"b""# History\nI have made the database of photos sorted by countries and pattern types. Screenshots were performed only on official websites.\n\n# Content\nThe main dataset (decor.zip) is 485 color images (150x150x3) of traditional decor patterns and the file with labels decor.csv. Photo files are in the .png format and the labels are integers and values.\n\nThe file DecorColorImages.h5 consists of preprocessing images of this set: image tensors and targets (labels).\n\n# Acknowledgements\nI have published the data for absolutely free usage by any site visitor. But this database contains the names of famous traditional decor styles, so it can not be used for commercial purposes.\n\n# Usage\nClassification, image recognition or generation, colorizing, etc. in a case of a small number of images are useful exercises. There are three kinds of classification here: by country, by pattern, by types of image (pattern itself or product).\n\n# Improvement\nIt's possible to find lots of ways for improving this set and the machine learning algorithms applying to it because of many traditional patterns in the world.""","b""['classification', 'deep learning', 'photography', 'medium', 'featured']""",https://www.kaggle.com/olgabelitskaya/traditional-decor-patterns
b'Chicago Building Violations',b'From City of Chicago Open Data',"b""### Content  \n\nViolations issued by the Department of Buildings from 2006 to the present.  Lenders and title companies, please note: These data are historical in nature and should not be relied upon for real estate transactions. For transactional purposes such as closings, please consult the title commitment for outstanding enforcement actions in the Circuit Court of Cook County or the Chicago Department of Administrative Hearings. Violations are always associated to an inspection and there can be multiple violation records to one inspection record. Related Applications: Building Data Warehouse http://www.cityofchicago.org/city/en/depts/bldgs/provdrs/inspect/svcs/building_violationsonline.html. The information presented on this website is informational only and does not necessarily reflect the current condition of the building or property. The dataset contains cases where a respondent has been found to be liable as well as cases where the respondent has been found to be not liable.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/qf2Lg1ZtxDc) by [Cristina Gottardi](https://unsplash.com/@cristina_gottardi) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-building-violations
b'U.S. Technology Jobs on Dice.com',"b'22,000 US-based Technology Job Listings'","b""###Context\n\nThis is a pre-crawled dataset, taken as subset of a bigger [dataset (more than 4.6 million job listings)][1] that was created by extracting data from Dice.com, a prominent US-based technology job board.\n\n### Content\n\nThis dataset has following fields:\n\n - advertiserurl \n - company \n - employmenttype_jobstatus \n - jobdescription \n - joblocation_address \n - jobtitle \n - postdate \n - shift \n - skills\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud's in-house web-crawling service.\n\n### Inspiration\nAnalyses of the job description with respect to the job title and skills can be performed.\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=dc-kaggle&utm_medium=referral""","b""['internet', 'medium', 'featured']""",https://www.kaggle.com/PromptCloudHQ/us-technology-jobs-on-dicecom
b'Dividend Growth Investment Data',b'Which stocks to pick for dividend growth',"b""### Context\n\nI like the idea of building passive income. There are many ways out there and one conservative way that has worked since ages is to invest in dividend paying assets. But you never know which one to pick with a good risk/reward ratio. I thought it would be great to have all the data available to have a data driven decision.\n\n\n### Content\n\nThe data is a snapshot of all tradable instruments on robinhood.com by using their API. When I do my research I like to also go through the data on dividend.com, so crawled their website to merge it with the symbols I already got from robinhood.com.    \nI documented and published the script how to create a new snapshot in [this repository](https://github.com/jonnylangefeld/dividend-data-download). Please refer to [the notebook](https://github.com/jonnylangefeld/dividend-data-download/blob/master/download-dividend-data.ipynb) if you want to create your own snapshot.    \nI recommend to use the pickle file (`instruments.p`) with `pd.read_pickle('../input/instruments.p')` because the data is already prepared and in the right shape and order. If you are an R user, you can still read the data with the `instruments.json` file.\n\n\n### Acknowledgements\n\nThanks to robinhood.com and dividend.com for providing this data publicly.\n\n\n### Inspiration\n\nWhich stocks do have the best risk/reward ratio?\n\n### Data description\n\n### Content\n\nCheckout the [repository](https://github.com/jonnylangefeld/dividend-data-download) for a detailed description of each column""","b""['finance', 'small', 'featured']""",https://www.kaggle.com/jonnylangefeld/dividend-growth-investment-data
b'Battery 3D Images',b'3D X-Ray Tomographic Datasets of Cathodes',"b'### Context\n\nThe data are copies of a few of the datasets published by the [Laboratory for Nanoelectronics at ETH Zurich](https://lne.ee.ethz.ch/en/more-information/open-source-data-and-code/battery-microstructure-project.html) \n\n\n### Content\n\nThe datasets are x-ray tomography images of the battery micro- and nanostructures. As the papers below document, a substantial amount of image processing is required to extract meaningful physical and chemical values from these images.\n\n\n### Acknowledgements\n\nThe relevant publications which also contain links to the full collection of datasets.\n\n 1. X\xe2\x80\x90Ray Tomography of Porous, Transition Metal Oxide Based Lithium Ion\n    Battery Electrodes -\n    https://onlinelibrary.wiley.com/doi/full/10.1002/aenm.201200932\n    \n    \n 2. Quantifying Inhomogeneity of Lithium Ion Battery Electrodes and Its\n        Influence on Electrochemical Performance -\n        http://jes.ecsdl.org/content/165/2/A339.abstract\n\n### Inspiration\n\nA number of interesting problems can be addressed with this dataset. \n- A good starting point would be to reproduce the findings of the papers and determine how robust the results are\n- Another interesting problem could be to try and use texture analysis to determine which cathodes are cracked\n- How to segment touching cathodes properly (are there better methods than watershed and rejoin)?\n'","b""['physics', 'chemistry', 'electronics', 'electronics manufacturing', 'large', 'featured']""",https://www.kaggle.com/kmader/battery-3d-images
b'ENEM 2016',"b'Data from ENEM 2016, the Brazilian High School National Exam.'","b'### Context\n\nThis dataset was downloaded from INEP, a department from the Brazilian Education Ministry. It contains data from the applicants for the 2016 National High School Exam.\n\n\n### Content\n\nInside this dataset there are not only the exam results, but the social and economic context of the applicants.\n\n\n### Acknowledgements\n\nThe original dataset is provided by INEP (http://portal.inep.gov.br/microdados).\n\n### Inspiration\n\nThe objective is to explore the dataset to achieve a better understanding of the social and economic context of the applicants in the exams results.'","b""['education', 'large', 'featured']""",https://www.kaggle.com/gbonesso/enem-2016
b'Home Medical Visits - Healthcare',b'Collection of the visits of a Home Medical Services Company during 2 years',"b'## Context  \nThis challenge serves as the virtual space of the HACK & HEALTH 2018 , the Hackathon of big data and health, driven by the City of Terrassa (Barcelona/Spain) that gives the opportunity to provide solutions that improve the life of citizens.  \n\nWith this datasets you will work with a challenging time-series dataset consisting of daily Home Medical Services from\n\nWe are asking you to a challenge for the Prediction of the level of sanitary actions in geographical areas based on environmental agents and its effect on ""Fragile"" people.\n\n## Inspiration\n## Challenges:\n\n### 1 - Impact of the Environment on ""Sensitive"" people\n\nEstablishing a causal link between certain environmental factors and adverse effects on health poses many difficulties. People considered ""sensitive"" are more likely to have harmful effects due to environmental factors. It is necessary to facilitate the integration between existing data in both \xc3\xa1reas (environmental and health) to see the degree of correlation between environmental factors and their effects on fragile people. As an example, one could analyze the effect of the effects of agents such as diesel (traffic level) or nearby gas stations) in people with asthma or the relationship between the level of noise (sensors located in cities) and epileptic people (record of health care in the area).\n\nStep # 2 - Prediction of the level of sanitary actions in geographical areas based on sensorial information and its effect on ""Fragile"" people. The objective of this challenge is to be able to determine in advance the level of burden that health services will have in a given geographical area depending on environmental agents (climate, pollution, etc). It is understood by people fragile, elderly people living alone, or people with specific pathologies. This challenge is related to the previous challenge since without a model of involvement between the environment and health we can not foresee the actions in a geographical area.'","b""['healthcare', 'geospatial analysis', 'pathology', 'small', 'featured']""",https://www.kaggle.com/HackandHealth/home-medical-visits-healthcare
b'Bay Area Rapid Transit Ridership',b'2016-2017 daily station-to-station BART ridership',"b'### Context\nBART, short for ""Bay Area Rapid Transit"", is the transit system severing the San Francisco Bay Area in California. BART operates six routes, 46 stations, and and 112 miles of track. It serves an average weekday ridership of 423,000 people, making it the fifth-busiest rapid transit system in the United States.\n\nThis dataset contains daily information on BART ridership for a period covering all of 2016 and part of 2017. Unlike some other rapid transit system datasets, this data includes movements between specific stations (there are just over 2000 station-to-station combinations).\n\n### Content\nThis dataset is split in three files. `station_info.csv` includes generic information on individual stations. `date-hour-soo-dest-2017.csv` contains daily inter-station ridership for (part of) 2017. `date-hour-soo-dest-2016.csv` contains daily inter-station ridership for all of 2016. \n\n### Acknowledgements\nWould like to thank the BART organization for recording the data and providing it to the public.\n\n    https://www.bart.gov/about/reports/ridership\n\n### Inspiration\n\n* Which BART station is the busiest? \n* What is the least popular BART route?  \n* When is the best time to go to SF if you want to find a seat?\n* Which day of the week is the busiest? \n* How many people take the BART late at night? \n* Does the BART ever stop in a station without anyone going off or on?'","b""['medium', 'featured']""",https://www.kaggle.com/saulfuh/bart-ridership
b'Customer Support on Twitter',b'Over 3 million tweets and replies from the biggest brands on Twitter',"b'The Customer Support on Twitter dataset is a large, modern corpus of tweets and replies to aid innovation in natural language understanding and conversational models, and for study of modern customer support practices and impact.\n\n![Example Analysis - Inbound Volume for the Top 20 Brands](https://i.imgur.com/nTv3Iuu.png)\n\n### Context\nNatural language remains the densest encoding of human experience we have, and innovation in NLP has accelerated to power understanding of that data, but the datasets driving this innovation don\'t match the real language in use today.  The Customer Support on Twitter dataset offers a large corpus of modern English (mostly) conversations between consumers and customer support agents on Twitter, and has three important advantages over other conversational text datasets:\n\n- **Focused** - Consumers contact customer support to have a specific problem solved, and the manifold of problems to be discussed is relatively small, especially compared to unconstrained conversational datasets like the reddit Corpus.\n- **Natural** - Consumers in this dataset come from a much broader segment than those in the Ubuntu Dialogue Corpus and have much more natural and recent use of typed text than the Cornell Movie Dialogs Corpus.\n- **Succinct** - Twitter\'s brevity causes more natural responses from support agents (rather than scripted), and to-the-point descriptions of problems and solutions.  Also, its convenient in allowing for a relatively low message limit size for recurrent nets.\n\n### Inspiration\nThe size and breadth of this dataset inspires many interesting questions:\n\n- Can we predict company responses? Given the bounded set of subjects handled by each company, the answer seems like yes!\n- Do requests get stale?  How quickly do the best companies respond, compared to the worst?\n- Can we learn high quality dense embeddings or representations of similarity for topical clustering?\n- How does tone affect the customer support conversation?  Does saying sorry help?\n- Can we help companies identify new problems, or ones most affecting their customers?\n\n### Content\nThe dataset is a CSV, where each row is a tweet.  The different columns are described below.  Every conversation included has at least one request from a consumer and at least one response from a company.  Which user IDs are company user IDs can be calculated using the `inbound` field.\n\n#### `tweet_id`\nA unique, anonymized ID for the Tweet.  Referenced by `response_tweet_id` and `in_response_to_tweet_id`.\n\n#### `author_id`\nA unique, anonymized user ID.  @s in the dataset have been replaced with their associated anonymized user ID.\n\n#### `inbound`\nWhether the tweet is ""inbound"" to a company doing customer support on Twitter.  This feature is useful when re-organizing data for training conversational models.\n\n#### `created_at`\nDate and time when the tweet was sent.\n\n#### `text`\nTweet content.  Sensitive information like phone numbers and email addresses are replaced with mask values like `__email__`.\n\n#### `response_tweet_id`\nIDs of tweets that are responses to this tweet, comma-separated.\n\n#### `in_response_to_tweet_id`\nID of the tweet this tweet is in response to, if any.\n\n### Contributing\n\nKnow of other brands the dataset should include?  Found something that needs to be fixed?  Start a discussion, or email me directly at `$FIRSTNAME`@`$LASTNAME`.com!\n\n### Acknowledgements\nA huge thank you to my friends who helped bootstrap the list of companies that  do customer support on Twitter!  There are many rocks that would have been left un-turned were it not for your suggestions!\n\n### Relevant Resources\n\n- NLTK - [casual_tokenize for social media text tokenizing](http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.casual.casual_tokenize), [vader sentiment analysis for social media text](http://www.nltk.org/howto/sentiment.html)\n- SciKit Learn - [BoW Count Vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), [Multinomial Naive Bayes Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n- [Topic Modeling via Phrase detection with gensim](https://www.thoughtvector.io/blog/topic-modeling-for-humans-with-phrase-detection/)\n- [facebook research - fastText text classifier](https://github.com/facebookresearch/fastText)'","b""['linguistics', 'business', 'twitter', 'communication', 'medium', 'featured']""",https://www.kaggle.com/thoughtvector/customer-support-on-twitter
b'NYS Child Care Regulated Programs',b'From New York State Open Data',"b""### Content  \n\nInformation on OCFS regulated child care programs, which includes program overview information and violation history.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/-f7bKsvOgwU) by [Bonnie Kittle](https://unsplash.com/@bonniekdesign) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-child-care-regulated-programs
b'Building Data Genome Project',b'Hourly Electrical Meter Data from Non-residential Buildings ',"b'\n\n![building data genome logo](https://raw.githubusercontent.com/buds-lab/the-building-data-genome-project/master/figures/buildingdatagenome1.png)\n\n- Does your data science technique actually scale across hundreds of buildings?\n-  Is it actually faster or more accurate?\n\nThese are questions that researchers should ask when developing data-driven methods. Building performance prediction, classi cation, and clustering algorithms are becoming an essential part of analysis for anomaly detection, control optimization, and demand response. But how do we actually compare, each individual technique against previously created methods?\n\nThe time-series data mining community identifed this problem as early as 2003: \xe2\x80\x9cMuch of this work has very little utility because the contribution made\xe2\x80\x9d...\xe2\x80\x9coffer an amount of improvement that would have been completely dwarfed by the variance that would have been observed by testing on many real world datasets, or the variance that would have been observed by changing minor (unstated) implementation details.\xe2\x80\x9d ([Keogh, E. and Kasetty, S.: On the need for time series data mining benchmarks: A survey and empirical demonstration. Data Mining and Knowledge Discovery, 7(4):349\xe2\x80\x93371, Oct. 2003.](https://link.springer.com/article/10.1023/A:1024988512476))\n\n[They created the time-series data benchmarking set](http://www.cs.ucr.edu/~eamonn/time_series_data/). This data set enables testing of new techniques on an assortment of real world data sets. For commerical buildings data, we are doing the same!\n\n## The need for Benchmarking Data Set for Non-residential Building Data Analytics\n\n### Most of the existing building performance data science studies rely on each individual researcher creating their own methods, finding a case study data set and determining efficacy on their own. Not surprisingly, most of those researcher find positive, yet questionably meaningful results.\n\n![old way](https://raw.githubusercontent.com/buds-lab/the-building-data-genome-project/master/figures/Oldway.png)\n\n\n### Using a large, consistent benchmark data set from hundreds (or thousands) of buildings, a researcher can determine how well their methods actually perform across a heterogeneous data set. If multiple researcher use the same data set, then there can be meaningful comparisons of accuracy, speed and ease-of-use.\n\n![new way](https://raw.githubusercontent.com/buds-lab/the-building-data-genome-project/master/figures/NewWay.png)\n\n## Introducing the Building Data Genome Project\nIt is an open data set from 507 non-residential buildings that includes hourly whole building electrical meter data for one year. Each of the buildings has meta data such as  or area, weather, and primary use type. This data set can be used to benchmark various statistical learning algorithms and other data science techniques. It can also be used simply as a teaching or learning tool to practice dealing with measured performance data from large numbers of non-residential buildings. The charts below illustrate the breakdown of the buildings according to location, building industry, sub-industry, and primary use type.\n\n![meta data](https://raw.githubusercontent.com/buds-lab/the-building-data-genome-project/master/figures/allbars.png)\n\n### Please contribute new data sets or provide analysis examples in Jupyter or R markdown using the data\n\nCitation of Data-Set\n------------\n\n[Clayton Miller, Forrest Meggers, The Building Data Genome Project: An open, public data set from non-residential building electrical meters, Energy Procedia, Volume 122, September 2017, Pages 439-444, ISSN 1876-6102, https://doi.org/10.1016/j.egypro.2017.07.400.](http://www.sciencedirect.com/science/article/pii/S1876610217330047) \n\n[ResearchGate](https://www.researchgate.net/publication/319507342_The_Building_Data_Genome_Project_An_open_public_data_set_from_non-residential_building_electrical_meters)\n\n```\nBibTex:\n@article{Miller2017439,\ntitle = ""The Building Data Genome Project: An open, public data set from non-residential building electrical meters "",\njournal = ""Energy Procedia "",\nvolume = ""122"",\nnumber = """",\npages = ""439 - 444"",\nyear = ""2017"",\nnote = ""\\{CISBAT\\} 2017 International ConferenceFuture Buildings & Districts \xe2\x80\x93 Energy Efficiency from Nano to Urban Scale "",\nissn = ""1876-6102"",\ndoi = ""https://doi.org/10.1016/j.egypro.2017.07.400"",\nurl = ""http://www.sciencedirect.com/science/article/pii/S1876610217330047"",\nauthor = ""Clayton Miller and Forrest Meggers"",\nkeywords = ""Open Data"",\nkeywords = ""Non-Residential Building Meter Data"",\nkeywords = ""Benchmark Data Set"",\nkeywords = ""Big Data"",\nkeywords = ""Machine Learning "",\nabstract = ""Abstract As of 2015, there are over 60 million smart meters installed in the United States; these meters are at the forefront of big data analytics in the building industry. However, only a few public data sources of hourly non-residential meter data exist for the purpose of testing algorithms. This paper describes the collection, cleaning, and compilation of several such data sets found publicly on-line, in addition to several collected by the authors. There are 507 whole building electrical meters in this collection, and a majority are from buildings on university campuses. This group serves as a primary repository of open, non-residential data sources that can be built upon by other researchers. An overview of the data sources, subset selection criteria, and details of access to the repository are included. Future uses include the application of new, proposed prediction and classification models to compare performance to previously generated techniques. ""\n}\n```\n\nGetting Started\n------------\n\nWe recommend you download the [Anaconda Python Distribution](https://www.continuum.io/downloads) and use Jupyter to get an understanding of the data.\n- Raw temporal and meta data are found in `/data/raw/`\n\nExample notebooks are found in `/notebooks/` -- a few good overview examples:\n- [Meta data overview](https://github.com/buds-lab/the-building-data-genome/blob/master/notebooks/00_Meta%20Data%20Exploration.ipynb)\n- [Temporal data overview](https://github.com/buds-lab/the-building-data-genome/blob/master/notebooks/00_Temporal%20Data%20Exploration%20--%20Subset.ipynb)\n\nPublications or Projects that use this data-set:\n------------\n\nPlease update this list if you add notebooks or R-Markdown files to the ``notebook`` folder.\n\n- [Miller, Clayton. \xe2\x80\x9cScreening Meter Data: Characterization of Temporal Energy Data from Large Groups of Non-Residential Buildings.\xe2\x80\x9d ETH Z\xc3\xbcrich, 2017.](https://www.research-collection.ethz.ch/handle/20.500.11850/125778) - [ResearchGate](https://www.researchgate.net/publication/313720565_Screening_Meter_Data_Characterization_of_Temporal_Energy_Data_from_Large_Groups_of_Non-Residential_Buildings)\n- [Temporal Data Mining Library for Buildings](https://github.com/buds-lab/temporal-features-for-nonres-buildings-library)\n\n\n# Contact -- (Add yours if you contribute to the data set)\nDr. Clayton Miller\nBuilding and Urban Data Science (BUDS) Group \nNational University of Singapore\nclayton@nus.edu.sg \nhttp://budslab.org/\n\nCopyright (c) 2016, Clayton Miller\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'","b""['medium', 'featured']""",https://www.kaggle.com/claytonmiller/building-data-genome-project-v1
"b'NYS License, Permit, Non-Driver ID Cards Issued'",b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.""","b""['socrata', 'medium', 'featured']""","https://www.kaggle.com/new-york-state/nys-license,-permit,-non-driver-id-cards-issued"
b'McGill-Billboard Songs and Chord Annotations',b'Chord Recognition with Chromagram Data',"b'### Context\n\nThis Dataset can be used to perform automatic chord recognition or progression.\n\n\n### Content\n\nThis data is separated into metadata and annotations. The metadata files are chromagram representations of songs made with the NNLS:Chroma VAMP Plugin. The metadata is a set of csv files represented by a timestamp then 24 pitch classes of data. Chord Annotations are a tuple of start time, end time, and chord label.\n\n\n### Acknowledgements\n\nhttp://ddmal.music.mcgill.ca/research/billboard\n'","b""['music', 'medium', 'featured']""",https://www.kaggle.com/jacobvs/mcgill-billboard
b'Russian Troll Tweets',"b""3 million tweets from accounts associated with the 'Internet Research Agency'""","b'# 3 million Russian troll tweets\n\nThis data was used in the FiveThirtyEight story [Why We\xe2\x80\x99re Sharing 3 Million Russian Troll Tweets](https://fivethirtyeight.com/features/why-were-sharing-3-million-russian-troll-tweets/).\n\nThis directory contains data on nearly 3 million tweets sent from Twitter handles connected to the Internet Research Agency, a Russian ""troll factory"" and a defendant in [an indictment](https://www.justice.gov/file/1035477/download) filed by the Justice Department in February 2018, as part of special counsel Robert Mueller\'s Russia investigation. The tweets in this database were sent between February 2012 and May 2018, with the vast majority posted from 2015 through 2017.\n\nFiveThirtyEight obtained the data from Clemson University researchers [Darren Linvill](https://www.clemson.edu/cbshs/faculty-staff/profiles/darrenl), an associate professor of communication, and [Patrick Warren](http://pwarren.people.clemson.edu/), an associate professor of economics, on July 25, 2018. They gathered the data using custom searches on a tool called Social Studio, owned by Salesforce and contracted for use by Clemson\'s [Social Media Listening Center](https://www.clemson.edu/cbshs/centers-institutes/smlc/).\n\nThe basis for the Twitter handles included in this data are the [November 2017](https://democrats-intelligence.house.gov/uploadedfiles/exhibit_b.pdf) and [June 2018](https://democrats-intelligence.house.gov/uploadedfiles/ira_handles_june_2018.pdf) lists of Internet Research Agency-connected handles that Twitter [provided](https://democrats-intelligence.house.gov/news/documentsingle.aspx?DocumentID=396) to Congress. This data set contains every tweet sent from each of the 2,752 handles on the November 2017 list since May 10, 2015. For the 946 handles newly added on the June 2018 list, this data contains every tweet since June 19, 2015. (For certain handles, the data extends even earlier than these ranges. Some of the listed handles did not tweet during these ranges.) The researchers believe that this includes the overwhelming majority of these handles\xe2\x80\x99 activity. The researchers also removed 19 handles that remained on the June 2018 list but that they deemed very unlikely to be IRA trolls.\n\nIn total, the nine CSV files include 2,973,371 tweets from 2,848 Twitter handles. Also, as always, caveat emptor -- in this case, tweet-reader beware: In addition to their own content, some of the tweets contain active links, which may lead to adult content or worse.\n\nThe Clemson researchers used this data in a working paper, [Troll Factories: The Internet Research Agency and State-Sponsored Agenda Building](http://pwarren.people.clemson.edu/Linvill_Warren_TrollFactory.pdf), which is currently under review at an academic journal. The authors\xe2\x80\x99 analysis in this paper was done on the data file provided here, limiting the date window to June 19, 2015, to Dec. 31, 2017.\n\nThe files have the following columns:\n\n    Header | Definition\n    ---|---------\n    `external_author_id` | An author account ID from Twitter \n    `author` | The handle sending the tweet\n    `content` | The text of the tweet\n    `region` | A region classification, as [determined by Social Studio](https://help.salesforce.com/articleView?   id=000199367&type=1)\n    `language` | The language of the tweet\n    `publish_date` | The date and time the tweet was sent\n    `harvested_date` | The date and time the tweet was collected by Social Studio\n    `following` | The number of accounts the handle was following at the time of the tweet\n    `followers` | The number of followers the handle had at the time of the tweet\n    `updates` | The number of \xe2\x80\x9cupdate actions\xe2\x80\x9d on the account that authored the tweet, including tweets, retweets and likes\n    `post_type` | Indicates if the tweet was a retweet or a quote-tweet\n    `account_type` | Specific account theme, as coded by Linvill and Warren\n    `retweet` | A binary indicator of whether or not the tweet is a retweet\n    `account_category` | General account theme, as coded by Linvill and Warren\n    `new_june_2018` | A binary indicator of whether the handle was newly listed in June 2018\n\nIf you use this data and find anything interesting, please let us know. Send your projects to oliver.roeder@fivethirtyeight.com or [@ollie](https://twitter.com/ollie).\n\nThe Clemson researchers wish to acknowledge the assistance of the Clemson University Social Media Listening Center and Brandon Boatwright of the University of Tennessee, Knoxville.'","b""['internet', 'politics', 'twitter', 'international relations', 'russia', 'medium', 'featured']""",https://www.kaggle.com/fivethirtyeight/russian-troll-tweets
b'notMNIST',b'A dataset for a more challenging MNIST-like classification task',"b""### Context\n\nThe MNIST dataset is one of the best known image classification problems out there, and a veritable classic of the field of machine learning. This dataset is more challenging version of the same root problem: classifying letters from images. This is a multiclass classification dataset of glyphs of English letters A - J.\n\nThis dataset is used extensively in the Udacity Deep Learning course, and is available in the Tensorflow Github repo (under Examples). I'm not aware of any license governing the use of this data, so I'm posting it here so that the community can use it with Kaggle kernels.\n\n### Content\n\n`notMNIST _large.zip` is a large but dirty version of the dataset with 529,119 images, and `notMNIST_small.zip` is a small hand-cleaned version of the dataset, with 18726 images. The dataset was assembled by Yaroslav Bulatov, and can be obtained on his [blog][1]. According to this blog entry there is about a 6.5% label error rate on the large uncleaned dataset, and a 0.5% label error rate on the small hand-cleaned dataset.\n\nThe two files each containing 28x28 grayscale images of letters A - J, organized into directories by letter. `notMNIST_large.zip` contains 529,119 images and `notMNIST_small.zip` contains 18726 images.\n\n### Acknowledgements\n\nThanks to Yaroslav Bulatov for putting together the dataset.\n\n  [1]: http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html""","b""['deep learning', 'image data', 'image processing', 'multiclass classification', 'medium', 'featured']""",https://www.kaggle.com/jwjohnson314/notmnist
b'Figure Eight: Medical Sentence Summary',b'Medical sentence summary and relation-extraction',"b'# Source\nThe dataset was developed by [figure-eight](https://www.figure-eight.com/dataset/medical-sentence-summary-and-relation-extraction/) and the full version is freely downloadable there as well as indications for how to make similar datasets using their platform.\n\n# About\nThis dataset contains 3,984 medical sentences extracted from PubMed abstracts and relationships between discrete medical terms were annotated. This dataset focuses primarily on \xe2\x80\x9ctreat\xe2\x80\x9d and \xe2\x80\x9ccause\xe2\x80\x9d relationships, with 1,043 sentences containing treatment relations and 1,787 containing causal ones.\n\nHuman-in-the-loop annotators were given two different terms (such as \xe2\x80\x9cLewy Body Dementia\xe2\x80\x9d and \xe2\x80\x9cWell-formed Visual Hallucinations\xe2\x80\x9d) and were asked to mark the relationship between those terms (in this case \xe2\x80\x9cLewy Body Dementia causes Well-Formed Visual Hallucinations).\n\nThis corpus has been referenced in the following papers:\n\n- Anca Dumitrache, Lora Aroyo, Chris Welty: CrowdTruth Measures for Language Ambiguity: The Case of Medical Relation Extraction. LD4IE at ISWC 2015.\n- Anca Dumitrache, Lora Aroyo, Chris Welty: Achieving Expert-Level Annotation Quality with CrowdTruth: The Case of Medical Relation Extraction. BDM2I at ISWC 2015.'","b""['text data', 'text mining', 'medicine', 'small', 'featured']""",https://www.kaggle.com/kmader/figure-eight-medical-sentence-summary
b'New York City Crimes',b'2014-2015 Crimes reported in all 5 boroughs of New York City',"b'### Context\n\nWith this dataset I hope to raise awareness on the trends in crime.\n\n### Content\n\nFor NYPD Complaint Data, each row represents a crime. For information on the columns, please see the attached csv, ""Crime_Column_Description"".\nReported crime go back 5 years but I only attached reported crime from 2014-2015 due to file size. The full report can be found at NYC Open Data (https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i)\n\n### Acknowledgements\n\nI would like to thank NYC Open Data for the dataset.\n\n\n### Inspiration\n\nAdditional things I would like to better understand:\n1.  Differences in crime that exist between the 5 boroughs\n2. A mapping of the crimes per borough\n3. Where do the most dangerous crimes happen and what time?'","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/adamschroeder/crimes-new-york-city
b'OECD Employment Rate: United States',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/Dt9kdskj6ek) by [Drew Coffman](https://unsplash.com/@drewcoffman) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/oecd-org/oecd-employment-rate-united-states
b'Additional resources for Kiva Crowdfunding',b'Region inclusion for Kiva locations with poverty decomposition',"b'### Context\n\nThis dataset contains the locations found in the Kiva datasets included in an administrative or geographical region. You can also find poverty data about this region. This facilitates answering some of the tough questions about a region\'s poverty. \n\n\n### Content\n**In the interest of preserving the original names and spelling for the locations/countries/regions all the data is in Excel format and has no preview** (I think only the Kaggle recommended file types have preview - if anyone can show me how to do this for an xlsx file, it will be greatly appreciated)\n\nThe Tables datasets contain the most recent analysis of the MPI on countries and regions. These datasets are updated regularly.\nIn unique regions_names_from_google_api you will find 3 levels of inclusion for every geocode provided in Kiva datasets. (village/town, administrative region, sub-national region - which can be administrative or geographical). These are the results from the Google API Geocoding process.\n\nFiles:\n\n- **all_kiva_loans.csv**\n\nDropped multiple columns, kept all the rows from loans.csv with names, tags, descriptions and got a csv file of 390MB instead of 2.13 GB. Basically is a simplified version of loans.csv (originally included in the analysis by beluga)\n\n- **country_stats.csv**\n\n1. population source: https://en.wikipedia.org/wiki/List_of_countries_by_population_(United_Nations)\n2. population_below_poverty_line: Percentage \n3. hdi: Human Development Index\n4. life_expectancy: Life expectancy at birth\n5. expected_years_of_schooling: Expected years of schooling\n6. mean_years_of_schooling: Mean years of schooling\n7. gni: Gross national income (GNI) per capita\nThis dataset was originally created by [beluga][1].\n\n\n- **all_loan_theme_merged_with_geo_mpi_regions.xlsx**\n\nThis is the loan_themes_by_region left joined with Tables_5.3_Contribution_of_Deprivations. (all the original entries from loan_themes and only the entries that match from Tables_5; for the regions that lack MPI data, you will find Nan)\n\nThese are the columns in the database:\n\n 1. Partner ID\n 2. Field Partner\n 3. Name\n 4. sector\n 5. Loan Theme ID\n 6. Loan Theme Type\n 7. Country\t\n 8. forkiva\n 9. number\n 10. amount\n 11. geo\n 12. rural_pct\n 13. City\n 14. Administrative region\n 15. Sub-national region\n 16. ISO\n 17. World region\n 18. Population Share of the Region (%)\n 19. region MPI\n 20. Education (%)\n 21. Health (%) \n 22. Living standards (%)\n 23. Schooling (%)\n 24. Child school attendance (%)\n 25. Child Mortality (%)\n 26. Nutrition (%)\n 27. Electricity (%)\n 28. Improved sanitation (%)\n 29. Drinking water (%)\n 30. Floor (%)\n 31. Cooking fuel (%)\n 32. Asset ownership (%)\n\n- **mpi_on_regions.xlsx**\n\nMatched the loans in loan_themes_by_region with the regions that have info regarding MPI. This dataset brings together the amount invested in a region and the biggest problems the said region has to deal with. It is a join between the loan_themes_by_region provided by Kiva and Tables 5.3 Contribution_of_Deprivations.\n\nIt is a subset of the all_loan_theme_merged_with_geo_mpi_regions.xlsx, which contains only the entries that I could match with poverty decomposition data. It has the same columns.\n\n- **Tables_5_SubNational_Decomposition_MPI_2017-18.xlsx**\n\nMultidimensional poverty index decomposition for over 1000 regions part of 79 countries.\n\nTable 5.3: Contribution of deprivations to the MPI, by sub-national regions\t\t\t\t\t\t\nThis table shows which dimensions and indicators contribute most to a region\'s MPI, which is useful for understanding the major source(s) of deprivation in a sub-national region.\n\nSource: http://ophi.org.uk/multidimensional-poverty-index/global-mpi-2016/\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\n- **Tables_7_MPI_estimations_country_levels.xlsx**\n\nMPI decomposition for 120 countries.\n\nTable 7 All Published MPI Results since 2010\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nThe table presents an archive of all MPI estimations published over the past 5 years, together with MPI, H, A and censored headcount ratios. For comparisons over time please use Table 6, which is strictly harmonised. The full set of data tables for each year published (Column A), is found on the \'data tables\' page under \'Archive\'. \t\n\nThe data in this file is shown in interactive plots on Oxford Poverty and Human Development Initiative website. \nhttp://www.dataforall.org/dashboard/ophi/index.php/\n\n- **unique_regions_from_kiva_loan_themes.xlsx**\n\nThese are all the regions corresponding to the geocodes found in Kiva\'s loan_themes_by_region.\nThere are 718 unique entries, that you can join with any database from Kiva that has either a coordinates or region column.  \nColumns:\n\n- geo: pair of Lat, Lon (from loan_themes_by_region)\n\n- City: name of the city (has the most NaN\'s)\n\n- Administrative region: first level of administrative inclusion for the city/location;\n(the equivalent of county for US)\n\n- Sub-national region: second level of administrative inclusion for the geo pair. (like state for US)\n\n- Country: name of the country\n\n\n### Acknowledgements\nThanks to Shane Lynn for the batch geocoding and to Joseph Deferio for reverse geocoding:\n\nhttps://www.shanelynn.ie/batch-geocoding-in-python-with-google-geocoding-api/\n\nhttps://github.com/jdeferio/Reverse_Geocode\n\nThe MPI datasets you can find on the Oxford website (http://ophi.org.uk/) under Research.\n\n""Citation: Alkire, S. and Kanagaratnam, U. (2018)\n\n\xe2\x80\x9cMultidimensional Poverty Index Winter 2017-18: Brief methodological note and results.\xe2\x80\x9d Oxford Poverty and Human Development Initiative, University of Oxford, OPHI Methodological Notes 45.""\t\n\n\n  [1]: https://www.kaggle.com/gaborfodor/additional-kiva-snapshot/data'","b""['demographics', 'geospatial analysis', 'medium', 'featured']""",https://www.kaggle.com/lucian18/mpi-on-regions
b'World Bank GDP ranking',b'From World Bank Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](https://databank.worldbank.org/) and they update their information according the amount of data that is brought in. Explore the World Bank using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using the World Bank's [APIs](data.worldbank.org/developers) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).""","b""['world', 'small', 'featured']""",https://www.kaggle.com/theworldbank/world-bank-gdp-ranking
b'UCI SECOM Dataset',b'Semiconductor manufacturing process dataset',"b""### Context\nManufacturing process feature selection and categorization\n\n### Content\nAbstract: Data from a semi-conductor manufacturing process\n\n- Data Set Characteristics: Multivariate \n- Number of Instances: 1567\n- Area: Computer \n- Attribute Characteristics: Real \n- Number of Attributes: 591 \n- Date Donated: 2008-11-19 \n- Associated Tasks: Classification, Causal-Discovery \n- Missing Values? Yes\n\nA complex modern semi-conductor manufacturing process is normally under consistent \nsurveillance via the monitoring of signals/variables collected from sensors and or \nprocess measurement points. However, not all of these signals are equally valuable \nin a specific monitoring system. The measured signals contain a combination of \nuseful information, irrelevant information as well as noise. It is often the case \nthat useful information is buried in the latter two. Engineers typically have a \nmuch larger number of signals than are actually required. If we consider each type \nof signal as a feature, then feature selection may be applied to identify the most \nrelevant signals. The Process Engineers may then use these signals to determine key \nfactors contributing to yield excursions downstream in the process. This will \nenable an increase in process throughput, decreased time to learning and reduce the \nper unit production costs.\n\nTo enhance current business improvement techniques the application of feature \nselection as an intelligent systems technique is being investigated.\n\nThe dataset presented in this case represents a selection of such features where \neach example represents a single production entity with associated measured \nfeatures and the labels represent a simple pass/fail yield for in house line \ntesting, figure 2, and associated date time stamp. Where .1 corresponds to a pass \nand 1 corresponds to a fail and the data time stamp is for that specific test \npoint.\n\n\nUsing feature selection techniques it is desired to rank features according to \ntheir impact on the overall yield for the product, causal relationships may also be \nconsidered with a view to identifying the key features.\n\nResults may be submitted in terms of feature relevance for predictability using \nerror rates as our evaluation metrics. It is suggested that cross validation be \napplied to generate these results. Some baseline results are shown below for basic \nfeature selection techniques using a simple kernel ridge classifier and 10 fold \ncross validation.\n\nBaseline Results: Pre-processing objects were applied to the dataset simply to \nstandardize the data and remove the constant features and then a number of \ndifferent feature selection objects selecting 40 highest ranked features were \napplied with a simple classifier to achieve some initial results. 10 fold cross \nvalidation was used and the balanced error rate (*BER) generated as our initial \nperformance metric to help investigate this dataset.\n\n\nSECOM Dataset: 1567 examples 591 features, 104 fails\n\nFSmethod (40 features) BER % True + % True - %\nS2N (signal to noise) 34.5 +-2.6 57.8 +-5.3 73.1 +2.1\nTtest 33.7 +-2.1 59.6 +-4.7 73.0 +-1.8\nRelief 40.1 +-2.8 48.3 +-5.9 71.6 +-3.2\nPearson 34.1 +-2.0 57.4 +-4.3 74.4 +-4.9\nFtest 33.5 +-2.2 59.1 +-4.8 73.8 +-1.8\nGram Schmidt 35.6 +-2.4 51.2 +-11.8 77.5 +-2.3\n\n-----------------------------------------------------\n\nAttribute Information:\n\nKey facts: Data Structure: The data consists of 2 files the dataset file SECOM \nconsisting of 1567 examples each with 591 features a 1567 x 591 matrix and a labels \nfile containing the classifications and date time stamp for each example.\n\nAs with any real life data situations this data contains null values varying in \nintensity depending on the individuals features. This needs to be taken into \nconsideration when investigating the data either through pre-processing or within \nthe technique applied.\n\nThe data is represented in a raw text file each line representing an individual \nexample and the features seperated by spaces. The null values are represented by \nthe 'NaN' value as per MatLab.\n\n### Acknowledgements\nAuthors: Michael McCann, Adrian Johnston \n\n### Inspiration\n\n- Semiconductor manufacturing has multi dimensional description of each process. Can we find key performance index by using big data techniques?""","b""['feature engineering', 'categorical data', 'semiconductors', 'small', 'featured']""",https://www.kaggle.com/paresh2047/uci-semcom
b'Homeownership Rate Time Series Collection',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/wdTEHCq1mRo) by [Alan Chen](https://unsplash.com/@chzenan) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/homeownership-rate-time-series-collection
b'Israeli Elections Results (1996-2015)',b'Election results data for the last seven Israeli election cycles',"b'### Context\n\nThe latest version of this dataset contains results from the last seven election cycles in Israel (1996, 1999, 2003, 2006, 2009, 2013 and 2015) . Results are given by voting booths (of comparable sizes of 0-800) and not by settlements (which are very varied - think Tel Aviv compared to a small kibbutz).\n\n### Content\n\nThe first seven columns are information about each settlement (its name, mostly) and voting booth, and from the eighth to the end is the number of votes each party has received in each booth in each year. I\'ve translated the names of most parties (even minor ones), and added links to Wikipedia in the column descriptions - except for very minor parties, who really don\'t matter.\n\n### Acknowledgements\n\nThis data of the 2015 and 2013 elections is freely available at http://votes20.gov.il/ and http://www.votes-19.gov.il/nationalresults. Previous elections results were kindly given by the Central Elections Committee of Israel. I just did the merging and translated the column headers into English. \n\nSettlement names are translated according to [this key](http://www.cbs.gov.il/ishuvim/ishuvim_main.htm) from the Central Bureau of Statistics, which uses the same settlement_code as the election results.\n\nThanks to Gal Bien for all sorts of help with this work, \nand to everyone who did some work on the previous versions!\n\n### Inspiration\nInitially, I started working with this dataset in order to map out the relationships between different parties (i.e which are \'closer\', which are more \'central\') - partly as an ML practice (even a Python exercise...), and partly to find meaningful insights about these relationships.\n\nIn my humble opinion, these relationships are important in Israeli politics, because the composition of the parliament is determined almost directly by the popular vote, but the government is formed by a coalition of parties... so some measure of who can form coalitions is relevant.\n\nEventually, I found out that I can map out not only the correlations network between parties in the same election cycle, but also - with reasonable accuracy - the dynamic ""flow"" of votes from party to party in consecutive election cycles (not only who\'s up and who\'s down, but also who\'s up on the expense of who). Didn\'t think about it in advance, but it\'s nice to stumble on new insights.\n\nSo - enjoy the dataset! Hope you\'ll find something interesting hidden within!'","b""['politics', 'timelines', 'people', 'small', 'featured']""",https://www.kaggle.com/itamarmushkin/israeli-elections-2015-2013
b'levin vehicle telematics',b'Vehicle and Driving Data',"b'We are updating this dataset everymonth. [Access updated data for every month here][1]\n\n### Context\nThe dataset is proprietary  data of Yun Solutions, collected from Beta Testing phase. The dataset contains sensor and OBD data for over 4 months and around 30 vehicles.\n### Content\nThe Dataset contains Vehicle telematics and Driving data. Metadata is explained in the file description on the data tab.\n### Acknowledgements\nWe look forward to analysis on the data.\n### Inspiration\nWe want to make this data accessible for learning and analysis. \n\n\n  [1]: https://mega.nz/#F!TE50HRyK!VTGi_U9KhsS-JJHBRzKKwA'","b""['internet', 'business', 'india', 'automobiles', 'vehicles', 'medium', 'featured']""",https://www.kaggle.com/yunlevin/levin-vehicle-telematics
"b""Tappy Keystroke Data with Parkinson's Patients""",b'Raw data used to predict the onset of Parkinson from typing tendencies',"b'# Introduction\nThis is the keystroke dataset for the study titled \'High-accuracy detection of early Parkinson\'s Disease using multiple characteristics of finger movement while typing\'. This research report is currently under review for publication by PLOS ONE.\n\nThe dataset contains keystroke logs collected from over 200 subjects, with and without Parkinson\'s Disease (PD), as they typed normally on their own computer (without any supervision) over a period of weeks or months (having initially installed a custom keystroke recording app, Tappy). This dataset has been collected and analyzed in order to indicate that the routine interaction with computer keyboards can be used to detect changes in the characteristics of finger movement in the early stages of PD.\n\n# Data\nThe participants, from the U.S., Canada, UK and Australia, had visited the project website and agreed to participate in the study. The research was approved by the Human Research Ethics Committee at Charles Sturt University, Australia, protocol number H17013.\n\nEach data file collected includes the timing information from typing activity as the participants used their various Windows applications (such as email, word processing, web searches and the like). The keystroke acquisition software (\'Tappy\') provided timing accuracy of key press and release timestamps to within several milliseconds.\n\nThe data files comprise two Zip archives, one with the participant detail files and the other with the keystroke data files for each user.\n\n\n### Acknowledgements\n\nThis dataset is from the research article ""High-accuracy detection of early Parkinson\'s Disease using multiple characteristics of finger movement while typing"" by Warwick R. Adams. Read the article here: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0188226#sec008\n\n### Inspiration\n\nWhile this is a difficult dataset to work with, there is a rich trove of information. It is a great set to practice preprocessing, attempt to replicate the results of the article, or do your own analysis of keystroke data.'","b""['preprocessing', 'research', 'diseases', 'neuroscience', 'neurology', 'medium', 'featured']""",https://www.kaggle.com/valkling/tappy-keystroke-data-with-parkinsons-patients
b'NYS Thruway Origin and Destination Information',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Lzh8I23FqRE) by [Jakob Owens](https://unsplash.com/@jakobowens1) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'utility', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-thruway-origin-and-destination-information
b'NYS Active Corporations:  Beginning 1800',b'From New York State Open Data',"b""### Content  \n\nThe Department of State keeps a record of every filing for every incorporated business in the state of New York. This dataset contains information on all active corporations as of the last business day of the specified month and year.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ffWnaif_9T0) by [Scott Webb](https://unsplash.com/@scottwebb) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-active-corporations-beginning-1800
b'Consumer Reviews of Amazon Products',"b'A list of over 34,000 reviews of Amazon products like the Kindle, Fire TV, etc.'","b""# About This Data\nThis is a list of over 34,000 consumer reviews for Amazon products like the Kindle, Fire TV Stick, and more provided by [Datafiniti's Product Database][1]. The dataset includes basic product information, rating, review text, and more for each product. \n\n*Note that this is a sample of a large data set. The full data set is available through Datafiniti.*\n\n# What You Can Do With This Data\nYou can use this data to [analyze Amazon\xe2\x80\x99s most successful consumer electronics product launches][2]; discover insights into consumer reviews and assist with machine learning models. E.g.:\n\n* What are the most reviewed Amazon products?\n* What are the initial and current number of customer reviews for each product?\n* How do the reviews in the first 90 days after a product launch compare to the price of the product?\n* How do the reviews in the first 90 days after a product launch compare to the days available for sale?\n* Map the keywords in the review text against the review ratings to help train sentiment models.\n\n# Data Schema\nA full schema for the data is available in our [support documentation][3].\n\n# About Datafiniti\nDatafiniti provides instant access to web data. We compile data from thousands of websites to create standardized databases of business, product, and property information. [Learn more][4].\n\n# Want More?\nYou can get more data like this by [joining Datafiniti][5] or [requesting a demo][6].\n\n  [1]: https://datafiniti.co/products/product-data/\n  [2]: https://datafiniti.co/amazon-fire-stick-juggernaut/\n  [3]: https://datafiniti-api.readme.io/docs/product-data-schema\n  [4]: https://datafiniti.co\n  [5]: https://portal.datafiniti.co/login\n  [6]: https://datafiniti.co/request-a-demo/""","b""['databases', 'product', 'small', 'featured']""",https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products
b'S&P 500 stock data',b'Historical stock data for all current S&P 500 companies',"b""### Context\n\nStock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here I provide a dataset with historical stock prices (last 5 years) for all companies currently found on the S&amp;P 500 index. \n\nThe script I used to acquire all of these .csv files can be found [in this GitHub repository][1] \nIn the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.\n\nFeb 2018 note: I have just updated the dataset to include data up to Feb 2018. I have also accounted for changes in the stocks on the S&amp;P 500 index (RIP whole foods etc. etc.).\n\n### Content\n\nThe data is presented in a couple of formats to suit different individual's needs or computational limitations. I have included files containing 5 years of stock data (in the all_stocks_5yr.csv and corresponding folder).\n\nThe folder individual_stocks_5yr contains files of data for individual stocks, labelled by their stock ticker name. The all_stocks_5yr.csv contains the same data, presented in a merged .csv file. Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.\n\nAll the files have the following columns:\nDate - in format: yy-mm-dd \n\nOpen - price of the stock at market open (this is NYSE data so all in USD)\n\nHigh - Highest price reached in the day\n\nLow\tClose - Lowest price reached in the day\n\nVolume - Number of shares traded\n\nName - the stock's ticker name\n\n### Acknowledgements\n\nDue to volatility in google finance, for the newest version I have switched over to acquiring the data from The Investor's Exchange api, the simple script I use to do this is found [here][2]. Special thanks to Kaggle, Github, pandas_datareader and The Market.\n\n### Inspiration\n\nThis dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.\nFrom these data informative stock stats such as volatility and moving averages can be easily calculated.\nThe million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!\n\n\n  [1]: http://github.com/CNuge/kaggle_code\n  [2]: https://github.com/CNuge/kaggle_code/blob/master/stock_data/getSandP.py""","b""['finance', 'time series', 'medium', 'featured']""",https://www.kaggle.com/camnugent/sandp500
b'Chicago Transportation Department Permits',b'From City of Chicago Open Data',"b""### Content  \n\nApplications to the Chicago Department of Transportation for permits under its jurisdiction, which typically are permits to block or otherwise affect public streets in some way.  Because all permits start as applications, this dataset also serves as a list of permits granted.  See more information about CDOT permits at http://www.cityofchicago.org/city/en/depts/cdot/provdrs/construction_information/svcs/online-permit-portal.html.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/VmX3vmBecFE) by [Max Bender](https://unsplash.com/@maxwbender) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-transportation-department-permits
b'Files found in open directories',b'Crawled from over 100k FTP and HTTP directory listings',"b""### Context  \nFiles from a website that are exposed in an open directory (often an nginx or Apache directory listing) are scanned by a decentralized crawler (see [project on github][2]). Public FTP servers are also crawled.  \n\n### Content\nFile date and size are taken from a HTTP HEAD response. Some web servers don't always return those values for smaller files (default values are `-1` for the size and `1970-01-01` for the date)  \n\nThis is a sample of the full dataset which can be found [here][1].\n\n  [1]: https://od-db.the-eye.eu/dl\n  [2]: https://github.com/simon987/od-database""","b""['small', 'featured']""",https://www.kaggle.com/simon987/od-database
b'New York State Corporate Tax Credits',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/new-york-state-corporate-tax-credits
b'Segmentation of OCT images (DME)',b'Optical coherence tomography (OCT) and diabetic macular edema (DME)',"b'### Context\n\nImages for segmentation of optical coherence tomography images with diabetic macular edema.\n\n### Content\n\nS. J. Chiu, M. J. Allingham, P. S. Mettu, S. W. Cousins, J. A. Izatt, S. Farsiu, ""Kernel regression based segmentation of optical coherence tomography images with diabetic macular edema"", ( BIOMEDICAL OPTICS EXPRESS), 6(4), pp. 1172-1194, April, 2015  \n\nTo learn our DME classifier, we obtained training data separate from our validation data set.\nWe used the Duke Enterprise Data Unified Content Explorer search engine to retrospectively\nidentify patients within the Duke Eye Center Medical Retina practice with a billing code for\nDME (ICD-9 362.07) associated with their visit. An ophthalmologist then identified six\npatients imaged in clinic using the standard Spectralis (Heidelberg Engineering, Heidelberg,\nGermany) 61-line volume scan protocol with severe DME pathology and varying image\nquality. Averaging of the B-scans was determined by the photographer, and ranged from 9 to\n21 raw images per averaged B-scan. The volumetric scans were Q = 61 B-scans \xc3\x97 N = 768\n231093 - $15.00 USD Received 19 Dec 2014; revised 25 Feb 2015; accepted 27 Feb 2015; published 9 Mar 2015 (C) 2015 OSA 1 Apr 2015 | Vol. 6, No. 4 | DOI:10.1364/BOE.6.001172 | BIOMEDICAL OPTICS EXPRESS 1181 \nA-scans with an axial resolution 3.87 ir = \xc2\xb5m/pixel, lateral resolution ( )j r ranging from\n11.07 \xe2\x80\x93 11.59 \xc2\xb5m/pixel, and azimuthal resolution ( ) kr ranging from 118 \xe2\x80\x93 128 \xc2\xb5m/pixel. \n\nTo generate the target classes for classifier training, we manually segmented fluid-filled\nregions and semi-automatically segmented all eight retinal layer boundaries following the\ndefinitions in Fig. 3. This was done for 12 B-scans within the training data set (two from each\nvolume). The B-scans selected consisted of six images near the fovea (B-scan 31 for all\nvolumes) and six peripheral images (B-scans 1, 6, 11, 16, 21, and 26, one for each of the six\nvolumes). We then used the manual segmentations to assign the true class for each pixel, with\na total of eight possible classes defined in Table 1 and the classified result shown in Fig. 4(a). \n\nWe obtained our validation data set by identifying ten patients with DME that were not\nincluded in the training data set. The method for selecting these data sets is described in\nSection 5.1, with the difference that the images had to be of adequate quality (i.e. layer and\nfluid boundaries needed to be visible). The image acquisition parameters were consistent with\nthe training data set, and lateral and azimuthal resolutions ranged from 10.94 \xe2\x80\x93 11.98\n\xc2\xb5m/pixel and 118 \xe2\x80\x93 128 \xc2\xb5m/pixel, respectively. We made the entire data set available online,\nincluding the training and validation data sets and their corresponding automatic and manual\nsegmentation results. This data set can be found at\nwww.duke.edu/~sf59/Chiu_BOE_2014_dataset.htm. \n\n### Acknowledgements\n\nhttp://people.duke.edu/~sf59/Chiu_BOE_2014_dataset.htm\n\n S. J. Chiu, M. J. Allingham, P. S. Mettu, S. W. Cousins, J. A. Izatt, S. Farsiu, ""Kernel regression based segmentation of optical coherence tomography images with diabetic macular edema"", ( BIOMEDICAL OPTICS EXPRESS), 6(4), pp. 1172-1194, April, 2015   \n\nPlease reference the above paper if you would like to use any part of this datasets. \xe2\x80\x8b\n\n\xe2\x80\x9cAll images included in this website have been fully de-identified. Any dates associated with the imaging files do not relate to the subject or to date of image acquisition. Images are intended for use in research and educational settings.   Commercialization/redistribution of the images is prohibited.    In the unlikely event that you identify any remaining identifiers in the images, you are prohibited from further disclosure and should destroy all copies of the image and immediately notify the owner of this webpage at: sina.farsiu@duke.edu   All use of the images should include citation and credit to this paper.\xe2\x80\x9d\n\nPlease contact Dr. Stephanie Chiu , who published this paper under the supervision of Prof. Sina Farsiu if you have questions about the dataset. \n\nBanner Image by [Harry Quan on Unsplash][1]\n\n\n  [1]: https://unsplash.com/photos/G1iYCeCW2EI'","b""['image data', 'medicine', 'object segmentation', 'medium', 'featured']""",https://www.kaggle.com/paultimothymooney/chiu-2015
b'Seattle Code Violation Cases',b'From City of Seattle Open Data',"b""### Content  \n\nThis data is read only as of April 26, 2018 as we transfer to a new database system. Current and historical information about complaints received that have become cases for further investigation.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/crGG3QXuyPc) by [Jordan Andrews](https://unsplash.com/@exit) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-code-violation-cases
b'Israel Census',b'Demographic population data for towns & neighborhoods',"b'### Context\n\n2008 Population & demographic census data for Israel, at the level of settlements and lower . \n### Content\n\nData provided at the sub-settlement level (i.e neighborhoods). \nVariable names (in Hebrew and English) and data dictionary provided in XLS files. \n2008 statistical area names provided (along with top roads/neighborhoods per settlement). \nExcel data needs cleaning/merging from multiple sub-pages. \n\n### Ideas:\n\n - Combine with voting datasets\n - Correlate population or economic growth over time with demographics\n - Geospatial analysis\n- Merge and clean the data from the sub tables. \n\n### Acknowledgements\n\nData from Israel Central Bureau of Statistics ([CBS][1]): [http://www.cbs.gov.il/census/census/pnimi_page.html?id_topic=12][2]\n\nPhoto by Me (Dan Ofer). \n\n  [1]: http://www.cbs.gov.il/census/census/pnimi_page.html?id_topic=12\n  [2]: http://www.cbs.gov.il/census/census/pnimi_page.html?id_topic=12'","b""['demographics', 'geospatial analysis', 'geography', 'countries', 'populated places', 'small', 'featured']""",https://www.kaggle.com/danofer/israel-census
b'NBA Player Salary Dataset (2017 - 2018)',"b""NBA players' Salary Dataset (2017 - 2018)""","b'### Context\n\nThe dataset was scraped from [Basketball Reference][1]\n\nThis dataset is so simple that only includes information about player names, teams and salary amount. I am hoping to see interesting analysis using not only this dataset but also other external datasets.\n\nI really appreciate any contributions from you!\n\n### Content\n\n 1. Player: Player name \n 2. Tm: Team name each player belongs to at the beginning of the 2017-\n   2018 season\n 3. seson17_18: Salary price for 2017-2018 season (USD)\n\n### Acknowledgements\nOriginal data was collected by NBA.\n\n### Inspiration\n\n - Who gets the most amount of salary?\n - Any other interesting datasets to combine to do nice analysis?\n\n  [1]: https://www.basketball-reference.com/contracts/players.html'","b""['sports', 'united states', 'basketball', 'money', 'small', 'featured']""",https://www.kaggle.com/koki25ando/salary
b'2015 de-identified NY inpatient discharge (SPARCS)',b'Patient characteristics and charges',"b'### Public Health Data\n\nThis is the public dataset made available at https://health.data.ny.gov/Health/Hospital-Inpatient-Discharges-SPARCS-De-Identified/82xm-y6g8 by the Dept of Health of New York state. The following description can be found at that page:\n\n<i>The Statewide Planning and Research Cooperative System (SPARCS) Inpatient De-identified File contains discharge level detail on patient characteristics, diagnoses, treatments, services, and charges. <b>This data file contains basic record level detail for the discharge. The de-identified data file does not contain data that is protected health information (PHI) under HIPAA</b>. The health information is not individually identifiable; all data elements considered identifiable have been redacted. For example, the direct identifiers regarding a date have the day and month portion of the date removed.</i>\n\n### It would be nice to ...\n\n... for example, be able to predict length of stay in the hospital using the parameters likely to be available when teh patient is admitted.'","b""['medium', 'featured']""",https://www.kaggle.com/jonasalmeida/2015-deidentified-ny-inpatient-discharge-sparcs
b'30000+ healthcare jobs from eMedCareers (Europe)',b'This dataset contains 30000 latest job postings in Europe from eMedCareers.',"b'### Context\n\neMedCareers is a job search platform for pharmaceutical, biotechnology or healthcare jobs. This dataset contains 30000 latest job postings in Europe from eMedCareers job portal.\n\n\n### Content\n\nFollowing data fields are included in the dataset:\n\n- category\n- location\n- company name\n- job title\n- job description\n- job type\n- salary offered\n- posting date\n\n### Acknowledgements\n\nThis data was extracted using [JobsPikr][1] - a job data delivery platform that extracts job data from various company sites across the globe on daily basis powered by machine learning techniques.\n\n\n### Inspiration\n\nThe uses of this dataset are endless. Some of the inspirations could be:\n\n- Top paying companies\n- Highest number of job posting by a particular company\n- Location with highest job openings\n- Salary distribution by state\n- Ratio of different job types\n\n  [1]: https://jobspikr.com/?utm_source=rb-kaggle&utm_medium=referral&utm_campaign=emedcareers-dataset'","b""['healthcare', 'europe', 'medium', 'featured']""",https://www.kaggle.com/jobspikr/30000-latest-healthcare-jobs-emedcareers-europe
b'Natural Images',b'A compiled dataset of 6899 images from 8 distinct classes.',"b'### Natural Images\nThis dataset is created as a benchmark dataset for the work on [***Effects of Degradations on Deep Neural Network Architectures***][1]. <br>\nThe source code is publicly available on [***GitHub***][2].\n\n----------\n\n### Description\nThis dataset contains 6,899 images from 8 distinct classes compiled from various sources (see Acknowledgements). The classes include airplane, car, cat, dog, flower, fruit, motorbike and person.\n\n----------\n\n### Acknowledgements\n* **Airplane** images obtained from http://host.robots.ox.ac.uk/pascal/VOC\n* **Car** images obtained from https://ai.stanford.edu/~jkrause/cars/car_dataset.html\n* **Cat** images obtained from https://www.kaggle.com/c/dogs-vs-cats\n* **Dog** images obtained from https://www.kaggle.com/c/dogs-vs-cats\n* **Flower** images obtained from http://www.image-net.org\n* **Fruit** images obtained from https://www.kaggle.com/moltean/fruits\n* **Motorbike** images obtained from http://host.robots.ox.ac.uk/pascal/VOC\n* **Person** images obtained from http://www.briancbecker.com/blog/research/pubfig83-lfw-dataset\n\n----------\n\n### Citation\n@article{roy2018effects, <br>\ntitle={Effects of Degradations on Deep Neural Network Architectures}, <br>\nauthor={Roy, Prasun and Ghosh, Subhankar and Bhattacharya, Saumik and Pal, Umapada}, <br>\njournal={arXiv preprint arXiv:1807.10108}, <br>\nyear={2018} <br>\n}\n\n\n[1]: https://arxiv.org/abs/1807.10108\n[2]: https://github.com/prasunroy/cnn-on-degraded-images\n'","b""['classification', 'deep learning', 'image data', 'multiclass classification', 'medium', 'featured']""",https://www.kaggle.com/prasunroy/natural-images
b'Volcano Eruption Global Distribution',"b'Simple visual aid for volcano eruption date, location and type'","b'## Context: \nWhat is the global distribution of recent eruptions and what type of volcano is associated with each type?  This brief dataset from the National Oceanic and Atmospheric Administration (NOAA) Significant Volcanic Eruption Database contains metrics related to global eruptions.  I chose to use the dataset to produce a global terrain map and HTML file that displays recent eruptions as colored markers associated with the type of volcano as well as a pop up description with location info from the dataset.\n\n## Content:\nThe time period of this dataset is from 2010 to 2018 when this notebook was written.  It contains 36 columns that describe various properties of the volcano as well as data related to economic and human impact of the eruption.  Properties that I feel are relevant and worthy of displaying on a marker pop up are ""Year"", ""Name"", ""Country"", ""Latitude"", ""Longitude"", ""Type"" although there are some tempting ones such as \'TOTAL_DAMAGE_MILLIONS_DOLLARS\' and \'TOTAL_HOUSES_DESTROYED\' that I chose to not include.  This particular slice in time only contains 63 observations.  The NOAA eruptions data is not real time nor is it updated fully as seen in the many null fields.  I believe the data is entered as NOAA becomes aware of various situations related to that event.  For example, as the total economic damage and death toll is finally made public, NOAA updates their database.\n\n## Acknowledgements: \nData was sourced from the NOAA Significant Volcanic Eruption Database\n\nhttps://www.ngdc.noaa.gov/nndc/servlet/ShowDatasets?dataset=102557&search_look=50&display_look=50\n\n##Inspiration:\nI personally think geology is fascinating and I am currently learning Python for data analysis.  The recent eruptions of Mount Kilauea in Hawaii came to mind so I hunted down open datasets that had to do with natural disasters and came upon the site from NOAA.  \n\n##Extensions:\nAlthough this dataset is small, anyone can download the full contents of the database from NOAA and perhaps answer some other **burning** questions:  Do certain types of volcanoes erupt more frequently?  Do certain types of volcanoes cause more economic damage than others?   Is there a correlation between number of lives lost and volcano type or location?  '","b""['data visualization', 'data cleaning', 'environment', 'geology', 'natural disasters', 'small', 'featured']""",https://www.kaggle.com/texasdave/volcano-eruptions
b'Flights in Brazil',"b'Every flight tracked by the National Civil Aviation Agency in Brazil, 2016-17.'","b'### Context\n\nThese are all the flights tracked by the National Civil Aviation Agency, in Brazil, from January 2015 to August 2017.\n\n### Content\n\nThe dataset is in portuguese so I had to remove some characters that were not supported on Kaggle. You can see the translation for the columns in the main dataset description.\n\n - ""Nao Identificado"" means ""Unidentified"".\n\n - UF means the State where the airport is located. For every airport not located in Brazil, the value is N/I.\n\nFeel free to ask me if you need translation of any other word.'","b""['brazil', 'aviation', 'medium', 'featured']""",https://www.kaggle.com/ramirobentes/flights-in-brazil
b'Higher Education Analytics',b'Unit level survey data from 2011-12 to 2015-16.',"b'**Connect/Follow me on [LinkedIn](http://link.rajanand.org/linkedin) for more updates on interesting dataset like this. Thanks.**\n\n###Context\n\nMinistry of Human Resource Development [(MHRD)](http://mhrd.gov.in/), Govt of India has initiated an All India Survey on Higher Education (AISHE) in the year 2010-11 to build a robust database and to assess the correct picture of higher Education in the country. \n\nThe main objectives of the survey was to\n\n- identify & capture all the institutions of higher learning in the country\n- Collect the data from all the higher education institutions on various aspects of higher education.  \n\nData was collected on following broad items\n \n- Institution\xe2\x80\x99s Basic Details\n- Teacher\xe2\x80\x99s Details\n- Details of Non-Teaching Staff\n- Programme conducted under various Faculties/Schools & Departments/Centres\n- Students enrolled in these Programme\n- Examination result of terminal year of each Programme\n- Financial Information such as Receipt and Expenditure under various heads\n- Availability of Infrastructure\n- Scholarships, Loans & Accreditation \n\nsource: AISHE([pdf](http://www.aishe.gov.in/aishe/viewDocument?documentId=6))\n \n###Content\n\nThis dataset contains unit level data from AISHE from 2011-12 to 2015-16.\n\n\ncsv file list:\n\n1. accreditation.csv\n1. college.csv\n1. college_institution.csv\n1. college_institution_accreditation.csv\n1. college_institution_department.csv\n1. college_institution_faculty.csv\n1. college_institution_non_teaching_staff_count.csv\n1. college_institution_student_hostel.csv\n1. college_institution_teaching_staff.csv\n1. college_institution_teaching_staff_sanctioned_strength.csv\n1. course.csv\n1. course_enrolled_foreign_student_count.csv\n1. course_enrolled_student_count.csv\n1. course_examination_result.csv\n1. department.csv\n1. educational_institution_course.csv\n1. enrolled_distance_student_university.csv\n1. enrolled_distance_student_university_count.csv\n1. enrolled_foreign_student_count.csv\n1. enrolled_student_count.csv\n1. examination_result.csv\n1. faculty.csv\n1. faculty_department.csv\n1. infrastructure.csv\n1. loan.csv\n1. MetaData.csv\n1. non_teaching_staff_count.csv\n1. other_minority_college_regular .csv\n1. other_minority_standalone_distance.csv\n1. other_minority_standalone_regular .csv\n1. other_minority_university_distance.csv\n1. other_minority_university_regular .csv\n1. persons_count_by_category.csv\n1. private_students_result.csv\n1. ref_broad_discipline_group.csv\n1. ref_broad_discipline_group_category.csv\n1. ref_college_institution_statutory_body.csv\n1. ref_count_by_category_remarks.csv\n1. ref_country.csv\n1. ref_course_level.csv\n1. ref_course_mode.csv\n1. ref_course_type.csv\n1. ref_diploma_course.csv\n1. ref_district.csv\n1. ref_examination_system.csv\n1. ref_institute_type.csv\n1. ref_institution_management.csv\n1. ref_non_teaching_staff_group.csv\n1. ref_non_teaching_staff_type.csv\n1. ref_programme.csv\n1. ref_programme_broad_discipline_group_and_category.csv\n1. ref_programme_statutory_body.csv\n1. ref_speciality.csv\n1. ref_standalone_institution.csv\n1. ref_state.csv\n1. ref_state_body.csv\n1. ref_student_hostel_type.csv\n1. ref_teaching_staff_designation.csv\n1. ref_teaching_staff_selection_mode.csv\n1. ref_university.csv\n1. ref_university_college_type.csv\n1. ref_university_type.csv\n1. regional_center.csv\n1. scholarship.csv\n1. staff_quarter.csv\n1. standalone_institution.csv\n1. standalone_institution_accreditation.csv\n1. standalone_institution_department.csv\n1. standalone_institution_faculty.csv\n1. standalone_institution_non_teaching_staff_count.csv\n1. standalone_institution_student_hostel.csv\n1. standalone_institution_teaching_staff.csv\n1. standalone_institution_teaching_staff_sanctioned_strength.csv\n1. student_hostel.csv\n1. teaching_staff.csv\n1. teaching_staff_count.csv\n1. teaching_staff_sanctioned_strength.csv\n1. university.csv\n1. university_accreditation.csv\n1. university_department.csv\n1. university_enrolled_distance_student.csv\n1. university_faculty.csv\n1. university_non_teaching_staff_count.csv\n1. university_private_students_result.csv\n1. university_student_hostel.csv\n1. university_teaching_staff.csv\n1. university_teaching_staff_sanctioned_strength.csv\n\n\n\n### Acknowledgements\n\nMinistry of Human Resource Development ([MHRD](http://www.aishe.gov.in/aishe/viewDocument?documentId=19)), Govt of India has published this dataset on [Open Govt Data India Platform](https://data.gov.in/sector/higher-education) under [Govt. open data license - India](https://data.gov.in/government-open-data-license-india).\n\nMHRD has also published some [reports](http://www.aishe.gov.in/aishe/reports) from this survey.\n\n### Inspiration\n\nThis is an interesting dataset to get the holistic picture of higher education system in India. One of the main objective of dept. of higher education is to increase the gross enrolment ratio (GRT) to 15% by 2011-12 and to 21% by [12th five year plan (2012-17)](https://en.wikipedia.org/wiki/Five-Year_Plans_of_India#Twelfth_Plan_.282012.E2.80.932017.29).\n One can look at things like the objective like this has been achieved or can be achieved based on the progress of past data. There are several other things that can be analysed from this dataset.\n\n - Pupil-Teacher Ratio (PTR)\n - Out-Turn\n - Gender Parity Index (GPI) etc.,'","b""['education', 'india', 'large', 'featured']""",https://www.kaggle.com/rajanand/aishe
b'India Socio Economic Data',"b'Population data, housing data, and socio economic data for each district'","b'### Context\n\n2011 India census data. Includes population/demographic data , housing data and socio economic data for each district.\n\n\n### Content\n* india-districts-census-2011.csv - Population enumeration data with expanded columns.\n* india_census_housing-hlpca-full.csv - Housing statistics for total (rural + urban) population by district. \n* gdp_AndhraPradesh1.csv , gdp_AndhraPradesh2 : Contains GDP data for state AP.\n* gdp_ArunachalPradesh.csv: Contains GDP data for state ArunachalPradesh.\n* gdp_Assam1.csv, gdp_Assam2.csv : Contains GDP data for state Assam.\n* gdp_Bihar1.csv , gdp_Bihar2.csv : Contains GDP data for state Bihar.\n* gdp_Chattisgarh.csv : Contains GDP data for state Chattisgarh.\n* gdp_Haryana.csv : Contains GDP data for state Haryana.\n* gdp_HimachalPradesh.csv :  Contains GDP data for state HimachalPradesh.\n* gdp_Jharkhand.csv : Contains GDP data for state Jharkhand.\n* gdp_Karnataka1.csv , gdp_Karnataka2.csv  : Contains GDP data for state Karnataka.\n* gdp_Kerala1.csv , gdp_Kerala2.csv  : Contains GDP data for state Kerala.\n* gdp_MadhyaPradesh.csv :  Contains GDP data for state MadhyaPradesh.\n* gdp_Maharashtra1.csv , gdp_Maharashtra2.csv : Contains GDP data for state Maharashtra.\n* gdp_Manipur.csv : Contains GDP data for state Manipur.\n* gdp_Meghalaya.csv : Contains GDP data for state Meghalaya.\n* gdp_Mizoram.csv : Contains GDP data for state Mizoram.\n* gdp_Odisha1.csv , gdp_Odisha2.csv : Contains GDP data for state Odhisha.\n* gdp_Punjab1.csv , gdp_Punjab2.csv  : Contains GDP data for state Punjab.\n* gdp_Rajasthan1.csv , gdp_Rajasthan2.csv : Contains GDP data for state Rajasthan.\n* gdp_Sikkim.csv : Contains GDP data for state Sikkim.\n* gdp_Tamilnadu.csv : Contains GDP data for state Tamilnadu.\n* gdp_Uttarakhand.csv : Contains GDP data for state Uttarakhand.\n* gdp_UttarPradesh1.csv , gdp_UttarPradesh2.csv : Contains GDP data for state UttarPradesh.\n* gdp_WestBengal1.csv , gdp_WestBengal2.csv : Contains GDP data for state West Bengal.\n\n\n\n### Acknowledgements\nhttps://www.kaggle.com/danofer/india-census\n\nhttps://www.kaggle.com/umeshnarayanappa/explore-census-2001-india\n\nhttp://udise.in/drc.htm\n\nhttps://data.gov.in/catalog/district-wise-gdp-and-growth-rate-current-price2004-05\n\nhttps://data.gov.in/catalog/district-wise-gdp-and-growth-rate-constant-price1999-2000\n\nBanner photo by [@ishant_mishra54 from Unsplash][1].\n\n### Inspiration\n\nWhat are the socioeconomic trends in different parts of India?\n\n\n  [1]: https://unsplash.com/photos/hDHt5F9X7l0'","b""['demographics', 'india', 'statistics', 'small', 'featured']""",https://www.kaggle.com/webaccess/all-census-data
b'Safecast Radiation Measurements',b'80 million radiation readings from volunteers around the world',"b'### Context\n\nSafecast is a volunteer driven non-profit organization whose goal is to create useful, accessible, and granular environmental data for public information and research. Begun in response to the nuclear disaster in Japan in March, 2011, Safecast collects radiation and other environmental data from all over the world. All Safecast data is published, free of charge, under a CC0 designation. \n\nThe official \xe2\x80\x9cSAFECAST data\xe2\x80\x9d published for others to use is collected by Safecast volunteers using professional quality devices. A combination of off the shelf commercial radiation monitors and devices are used in the collection process. Most devices are standardized on the same sensor, the LND7317 which is commonly referred to as the 2\xe2\x80\xb3 pancake. This is a highly sensitive piece of equipment that is used by nuclear professionals all over the world.\n\n\n### Content\n\n""Presently we assume the radiation comes from cesium-137 which is the most prevalent isotope still around from nuclear weapons testing and from the accidents at Chernobyl and Fukushima.  Based on calibration tests of multiple device designs using the same detector, we\'ve settled on a conversion factor of 334. That is, 334CPM from a bGeigie equates to 1uSv/h.<br>\nIt would be more accurate to have conversion factors tuned to each locale based on the spectrum of radiation present, but we don\'t have much of that data and in practice the error is estimated to be relatively small. ""<br>\n- Joe Moross from Safecast\n\n- Captured Time\n  - Time data was captured\n- Latitude\n- Longitude\n- Value\n  - Actual data, in whatever units are in the ""Unit"" field. About 130K out of over 80 million measurements are *not* in CPM (from a 2-inch pancake Geiger tube)\n- Unit\n  - Describes the raw form of the data. The vast majority of the measurements in the database are from Safecast-designed bGeigies, which record radiation levels in CPM (counts per minute)\n- Location Name\n- Device ID\n- MD5Sum\n- Height\n  - Height from the ground in meters\n- Surface\n  - Denotes data recorded very close to a surface such as pavement. This is typically done at 1cm height so should be regarded as contamination density and displayed or analyzed in units such as Becquerels, not as dose data.\n- Radiation\n- Uploaded Time\n- Loader ID\n\n\n\n### Acknowledgements\n\nThank you to Safecast for collecting and sharing this dataset. The source files were downloaded from [Safecast.org][1] and have not been modified.\n\n\n### Inspiration\n\nSafecast shared this datset for the public to have an un-biased source of radiation measurements. Use this dataset to see where Safecast volunteers have recorded data. \n\n[1]: https://blog.safecast.org/downloads/'","b""['large', 'featured']""",https://www.kaggle.com/safecast/safecast
b'Mice Protein Expression',b'Expression levels of 77 proteins measured in the cerebral cortex',"b'### Context\n\nExpression levels of 77 proteins measured in the cerebral cortex of 8 classes of control and Down syndrome mice exposed to context fear conditioning, a task used to assess associative learning.\n\n### Content\n\nThe data set consists of the expression levels of 77 proteins/protein modifications that produced detectable signals in the nuclear fraction of cortex. There are 38 control mice and 34 trisomic mice (Down syndrome), for a total of 72 mice. In the experiments, 15 measurements were registered of each protein per sample/mouse. Therefore, for control mice, there are 38x15, or 570 measurements, and for trisomic mice, there are 34x15, or 510 measurements. The dataset contains a total of 1080 measurements per protein. Each measurement can be considered as an independent sample/mouse. \n\nThe eight classes of mice are described based on features such as genotype, behavior and treatment. According to genotype, mice can be control or trisomic. According to behavior, some mice have been stimulated to learn (context-shock) and others have not (shock-context) and in order to assess the effect of the drug memantine in recovering the ability to learn in trisomic mice, some mice have been injected with the drug and others have not. \n\nClasses: \n\n1. **c-CS-s**: control mice, stimulated to learn, injected with saline (9 mice) \n\n2. **c-CS-m**: control mice, stimulated to learn, injected with memantine (10 mice) \n\n3. **c-SC-s**: control mice, not stimulated to learn, injected with saline (9 mice) \n\n4. **c-SC-m**: control mice, not stimulated to learn, injected with memantine (10 mice) \n\n5. **t-CS-s**: trisomy mice, stimulated to learn, injected with saline (7 mice) \n\n6. **t-CS-m**: trisomy mice, stimulated to learn, injected with memantine (9 mice) \n\n7. **t-SC-s**: trisomy mice, not stimulated to learn, injected with saline (9 mice) \n\n8. **t-SC-m**: trisomy mice, not stimulated to learn, injected with memantine (9 mice)\n\n### Attribute Information\n\n[1] **Mouse ID** \n\n[2:78] **Values of expression levels of 77 proteins**; the names of proteins are followed by N indicating that they were measured in the nuclear fraction. *For example: DYRK1A_n*\n\n[79] **Genotype**: control (c) or trisomy (t) \n\n[80] **Treatment type**: memantine (m) or saline (s) \n\n[81] **Behavior**: context-shock (CS) or shock-context (SC) \n\n[82] **Class**: c-CS-s, c-CS-m, c-SC-s, c-SC-m, t-CS-s, t-CS-m, t-SC-s, t-SC-m\n\n### Acknowledgements\n\nClara Higuera Department of Software Engineering and Artificial Intelligence, Faculty of Informatics and the Department of Biochemistry and Molecular Biology, Faculty of Chemistry, University Complutense, Madrid, Spain. \nEmail: clarahiguera at ucm.es \n\nKatheleen J. Gardiner, creator and owner of the protein expression data, is currently with the Linda Crnic Institute for Down Syndrome, Department of Pediatrics, Department of Biochemistry and Molecular Genetics, Human Medical Genetics and Genomics, and Neuroscience Programs, University of Colorado, School of Medicine, Aurora, Colorado, USA. \nEmail: katheleen.gardiner at ucdenver.edu \n\nKrzysztof J. Cios is currently with the Department of Computer Science, Virginia Commonwealth University, Richmond, Virginia, USA, and IITiS Polish Academy of Sciences, Poland. \nEmail: kcios at vcu.edu \n\n**Source**: [UC Irvine Machine Learning Repository][2]\n\n\n  [2]: https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression\n\n### Inspiration\n\nThe aim is to identify subsets of proteins that are discriminant between the classes. '","b""['multiclass classification', 'biology', 'small', 'featured']""",https://www.kaggle.com/ruslankl/mice-protein-expression
b'Internet Research Agency (IRA) Social Media Data',b'Political Propaganda on Facebook - House Intelligence Committee Report - 2018',"b'### Context\n\nThe Internet Research Agency (IRA) is a notorious Russian \xe2\x80\x9ctroll\xe2\x80\x9d farm that has the strategic goal of sowing discord in the U.S. political system.   On February 16, 2018 Special Counsel Robert S. Mueller III indicted 13 Russian individuals and three Russian organizations for engaging in operations to interfere with U.S. political and electoral processes.  \n\n### Content\n\nFacebook data:\n\n - During the hearing, Committee Members noted the breadth of activity by the IRA on Facebook:  3,393 advertisements purchased (a total 3,519 advertisements total\n   were released after more were identified by the company); More than\n   11.4 million American users exposed to those advertisements; 470 IRA-created Facebook pages; 80,000 pieces of organic content created\n   by those pages; and Exposure of organic content to more than 126\n   million Americans. The Facebook advertisements we are publishing\n   today have been carefully reviewed by the Committee Minority and\n   redacted by Facebook to protect personally-identifiable information\n   (PII). To protect innocent victims, Facebook\xe2\x80\x94at the urging of the\n   Committee Minority\xe2\x80\x94also has notified users whose genuine online\n   events were unwittingly promoted by the IRA.\n\nTwitter data:\n\n - During the Committee\xe2\x80\x99s November 2017 open hearing, the Minority\n   introduced into the record 2,752 Twitter accounts that Twitter\n   identified as connected to the Internet Research Agency (IRA), the\n   Kremlin-linked \xe2\x80\x9ctroll farm.\xe2\x80\x9d These accounts were designed to\n   impersonate U.S. news entities, political parties, and groups focused\n   on social and political issues. During the hearing, the Minority also\n   revealed a selection of Twitter advertisements paid for by Russian\n   news outlet RT, which the January 2017 Intelligence Community\n   Assessment labeled as \xe2\x80\x9cthe Kremlin\xe2\x80\x99s principal international\n   propaganda outlet.\xe2\x80\x9d \n   \n   According to data provided to the Committee by Twitter, a snapshot of\n   relevant Twitter activity in the period between September 1 and\n   November 15, 2016 reveals:  More than 36,000 Russian-linked bot\n   accounts tweeted about the U.S. election More than 36,000\n   Russian-linked bot accounts tweeted about the U.S. election\n   Approximately 288 million impressions of Russian bot tweets; and \n   More than 130,00 tweets by accounts linked to the IRA.  \n\n\nFor more Twitter data, see: ([Link #1][1]), ([Link #2][2]).\n\n### Acknowledgements\n\nDataset description adapted from [original source][3].\n\nBanner Image by [Rob Walsh from Unsplash][4].\n\nRaw Data from [House Intelligence Committee][5].\n\nSupplementary Data from both [DataWorld][6] and [Russian Ad Explorer][7].\n\nAll data was published using Open Data Licenses.\n\n### Inspiration\n\nDid Russia attempt to influence a foreign election?\n\nCan Facebook ads be used to promote political divisions?\n\n\n  [1]: https://www.kaggle.com/fivethirtyeight/russian-troll-tweets\n  [2]: https://www.kaggle.com/vikasg/russian-troll-tweets\n  [3]: https://democrats-intelligence.house.gov/social-media-content/\n  [4]: https://unsplash.com/photos/_KeC-qyKLPY\n  [5]: https://democrats-intelligence.house.gov/social-media-content/\n  [6]: https://data.world/scottcame/us-house-psci-social-media-ads/\n  [7]: https://russian-ad-explorer.github.io/?ad_id=3311'","b""['politics', 'united states', 'twitter', 'russia', 'large', 'featured']""",https://www.kaggle.com/paultimothymooney/russian-political-influence-campaigns
b'Cryptocurrencies',b'Historical price data for 1200 cryptocurrencies (excluding BTC)',"b'### Context\n\nThousands of cryptocurrencies have sprung up in the past few years. Can you predict which one will be the next BTC?\n\n\n### Content\n\nThe dataset contains daily opening, high, low, close, and trading volumes for over 1200 cryptocurrencies (excluding bitcoin).\n\n\n### Acknowledgements\n\nhttps://timescaledata.blob.core.windows.net/datasets/crypto_data.tar.gz\n\n### Inspiration\n\nSpeculative forces are always at work on cryptocurrency exchanges - but do they contain any statistically significant features?'","b""['finance', 'internet', 'small', 'featured']""",https://www.kaggle.com/akababa/cryptocurrencies
b'NY License Applications',b'From New York City Open Data',"b""### Content  \n\nThis data set features license applications received during the last and current calendar years, including applications where a license was issued, denied, withdrawn, or remains pending. For a list of legally operating businesses, please refer to the DCA \xe2\x80\x93 Legally Operating Businesses data set. This data set is updated on a weekly basis.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/w89EjgIcwe8) by [Son Vu Le](https://unsplash.com/@snugshutter59) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'business', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/ny-license-applications
b'Japanese Single Speaker Speech Dataset',b'CSS10 Japanese: Single Speaker Speech Dataset',"b'### Context\n\nCSS10 is a collection of single speaker speech datasets for 10 languages. Each of them consists of audio files recorded by a single volunteer and their aligned text sourced from LibriVox.\n\n### Content\nEach line in `transcript.txt` is delimited by `|` into four fields, i.e., audio file location, original script, normalized script, and audio duration.\n\nVisit [here](https://github.com/kyubyong/css10) to check out our project using this dataset.\n\n### Acknowledgements\n\nWe thank LibriVox and the volunteers.\n \n### Contact\nYou can contact me at kbpark.linguist@gmail.com.\n\nJune, 2018.\n\nKyubyong Park & Tommy Mulc\n'","b""['linguistics', 'large', 'featured']""",https://www.kaggle.com/bryanpark/japanese-single-speaker-speech-dataset
b'Complete Historical Cryptocurrency Financial Data',b'Top 200 Cryptocurrencies by Marketcap',"b'**Context**\n\nRecent growing interest in cryptocurrencies, specifically as a speculative investment vehicle, has sparked global conversation over the past 12 months. Although this data is available across various sites, there is a lack of understanding as to what is driving the exponential rise of many individual currencies. This data set is intended to be a starting point for a detailed analysis into what is driving price action, and what can be done to predict future movement.\n\n**Content**\n\nConsolidated financial information for the top 200 cryptocurrencies by marketcap. Pulled from CoinMarketCap.com. Attributes include:\n\n - Currency name (e.g. bitcoin)\n - Date  \n - Open\n - High\n - Low\n - Close\n - Volume\n - Marketcap\n\n**Inspiration**\n\nFor the past few months I have been searching for a reliable source for historical price information related to cryptocurrencies. I wasn\'t able to find anything that I could use to my liking, so I built my own data set.\n\nI\'ve written a small script that scrapes historical price information for the top 200 coins by market cap as listed on CoinMarketCap.com.\n\nI plan to run some basic analysis on it to answer questions that I have a ""gut"" feeling about, but no quantitative evidence (yet!).\n\nQuestions such as: \n\n - What is the correlation between bitcoin and alt coin prices?\n - What is the average age of the top 10 coins by market cap?\n - What day of the week is best to buy/sell?\n - Which coins in the top two hundred are less than 6 months old?\n - Which currencies are the most volatile? \n - What the hell happens when we go to bed and Asia starts trading?\n\nFeel free to use this for your own purposes! I just ask that you share your results with the group when complete. Happy hunting!'","b""['finance', 'internet', 'business', 'money', 'small', 'featured']""",https://www.kaggle.com/philmohun/cryptocurrency-financial-data
b'LA General City Budget Incremental Changes',b'From Los Angeles Open Data',"b""### Content  \n\nIncremental changes in the budget from year to year, dating back to 2015-2016.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/hPYeUW4nc9Q) by [Peter Y. Chuang](https://unsplash.com/@peterychuang) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/la-general-city-budget-incremental-changes
b'Open Sprayer images',b'A collection of broad leaved dock images for weed sprayer',"b'**OpenSprayer.com**\n\nOpen Sprayer will hopefully be an open sourced autonomous land drone that will propel itself across the fields spraying weeds it can see with its mounted cameras. The project should involve a mix of mechanical engineering, classical software design and machine learning to achieve its goal. The project is meant to be a DIY effort to compete with the big companies like John Deere currently developing similar tech. The benefit of an open design is cheaper capital and maintenance cost. The ability to fix, update and repair your own sprayer would offer a great alternative to the potential high running costs of branded machines.\n\n\nThe data set includes pictures of broad leaved docks and picture of the land without broad leaved docks. I plan to update the images to better reflect the images that the sprayer drone will produce when operating. Give me feedback and I can take more pictures to improve the dataset.\n\n\n\n'","b""['image data', 'agriculture', 'surveillance', 'agronomy', 'medium', 'featured']""",https://www.kaggle.com/gavinarmstrong/open-sprayer-images
b'Frasier Dialogs',b'Dataset of dialogs from the show Frasier',"b""### Context\n\nFraiser is one of the best sitcom from the 90s. This dataset is for people who love the show and find out more about the two snobby brothers, their father, their love life or probably about the little devil Eddie?\n\n\n### Content\nPlease note: the data is not 100% clean yet.  \nCSV files are available as well as a sqlite database.\n\nFor the sqlite database, use a tool like https://sqlitebrowser.org to explore it.\n\n![ER diagram][1]\n\n### Acknowledgements\n\nDialogs are originally from http://www.kacl780.net/frasier/transcripts/  \nPython scraper to download and parse the data can be found at https://github.com/sul4bh/frasier_dialogs\n\n### Inspiration\n\n- How often do the characters complain about rain?\n- How active is Roz's love life over the seasons/episodes?\n- Can you predict a cast based on their dialogs?\n\n  [1]: https://image.ibb.co/mDwJN8/Screen_Shot_2018_06_26_at_12_05_49_AM.png""","b""['linguistics', 'text data', 'entertainment', 'small', 'featured']""",https://www.kaggle.com/sulabhbista/frasier-dialogs
b'AWS Honeypot Attack Data',b'Visualizing Cyber Attacks',"b""### Context\n\n(U) My purpose is to analyze Amazon Web Services (AWS) honeypot data for any trends and/or correlations that could possibly be used in predictive cyber threat vectors.  I spent a lot of time looking for data sets and most of the ones I found had no documentation and the data was hard to interpret just from the file.  This data is well formatted and straight forward.\n\n### Content\n\n(U) The AWS Honeypot Database is an open-source database including information on cyber attacks/attempts. \n\n(U) Data has 451,581 data points collected from 9:53pm on 3 March 2013 to 5:55am on 8 September 2013. \n\n\n### Acknowledgements\n\nhttp://datadrivensecurity.info/blog/pages/dds-dataset-collection.html\nJay Jacobs &amp; Bob Rudis\n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?""","b""['internet', 'crime', 'small', 'featured']""",https://www.kaggle.com/casimian2000/aws-honeypot-attack-data
b'10 Monkey Species',b'Image dataset for fine-grain classification ',"b""\n### Content\nThe dataset consists of two files, training and validation. Each folder contains 10 subforders labeled as n0~n9, each corresponding a species form [Wikipedia's monkey cladogram][1]. Images are 400x300 px or larger and JPEG format (almost 1400 images).  Images were downloaded with help of the [googliser][2] open source code.\n\n    Label mapping:\n    n0, alouatta_palliata\n    n1, erythrocebus_patas\n    n2, cacajao_calvus \n    n3, macaca_fuscata   \n    n4, cebuella_pygmea\n    n5, cebus_capucinus\n    n6, mico_argentatus\n    n7, saimiri_sciureus \n    n8, aotus_nigriceps\n    n9, trachypithecus_johnii\n\n\n - For more information on the monkey species and number of images per class make sure to check `monkey_labels.txt` file. \n\n\n### Aim\n\nThis dataset is intended as a test case for fine-grain classification tasks, perhaps best  used in combination with transfer learning. Hopefully someone can help us expand the number of classes or number of images. \n\n### Acknowledgements\n\nThanks to Romain Renard for his help with the code implementation. Also, thanks to Gustavo Montoya, Jacky Zhang and Sofia Loaiciga  for their help with the dataset curation.\n\n### Notes\nSome demo code for usage of the dataset in combination with Keras can be found in this [repo][3].\n\n\n  [1]: https://en.wikipedia.org/wiki/Monkey\n  [2]: https://github.com/teracow/googliser\n  [3]: https://github.com/slothkong/CNN_classification_10_monkey_species\n""","b""['image data', 'animals', 'medium', 'featured']""",https://www.kaggle.com/slothkong/10-monkey-species
b'The Cure discography',b'Metrics and audio features',"b""### Context\n\nThe Cure is one of my favourites groups, that's why I decided to analyze their discography.\n\n\n### Content\n\nPopularity and audio features for every song and album: \n\n* `track_popularity`. The value will be between 0 and 100, with 100 being the most popular.\n\n* `duration_ms`. The duration of the track in milliseconds.\n\n* `valence`. A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track.\n\n* `danceability`. Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.A value of 0.0 is least danceable and 1.0 is most danceable.\n\n* `energy`. Represents a perceptual measure of intensity and activity (from 0.0 to 1.0).\n\n* `acousticness`. A confidence measure from 0.0 to 1.0 of whether the track is acoustic.\n\n* `loudness`. The overall loudness of a track in decibels (typical range between -60 and 0 db).\n\n* `speechiness`. Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording, the closer to 1.0 the attribute value.\n\n* `instrumentalness`. Predicts whether a track contains no vocals.The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. \n\n* `liveness`. Detects the presence of an audience in the recording. A value above 0.8 provides strong likelihood that the track is live.\n\n* `key_mode`. The key the track is in. \n\nIf you want more information about the metrics, please check [here](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/)\n\n\n### Acknowledgements\n\nI used the function `get_artist_audio_features()` from the `spotifyr` package, in order to retrieve the popularity and audio features for every song and album for a given artist on Spotify.\n\nIf you want more information about this package, please check [here](https://github.com/charlie86/spotifyr).\n\n### Inspiration\n\n* Exploratory Data Analysis\n* Data Visualization\n""","b""['data visualization', 'eda', 'popular culture', 'music', 'small', 'featured']""",https://www.kaggle.com/xvivancos/the-cure-discography
b'Stanford Cars Dataset',"b""16,185 images and 196 classes of all the cars you'll ever dream of""","b'### Context\n3D object representations are valuable resources for multi-view object class detection and scene understanding. Fine-grained recognition is a growing subfield of computer vision that has many real-world applications on distinguishing subtle appearances differences. This cars dataset contains great training and testing sets for forming models that can tell cars from one another. Data originated from Stanford University AI Lab (specific reference below in Acknowledgment section).\n\n### Content\n\nThe Cars dataset contains 16,185 images of 196 classes of cars. The data is split into 8,144 training images and 8,041 testing images, where each class has been split roughly in a 50-50 split. Classes are typically at the level of Make, Model, Year, ex. 2012 Tesla Model S or 2012 BMW M3 coupe.\n\n\n### Acknowledgements\n\nData source and banner image: http://ai.stanford.edu/~jkrause/cars/car_dataset.html\nall bounding boxes and labels for both training and test\nIf you use this dataset, please cite the following paper: \n\n**3D Object Representations for Fine-Grained Categorization**\n\nJonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei\n\n*4th IEEE Workshop on 3D Representation and Recognition, at ICCV 2013 (3dRR-13). Sydney, Australia. Dec. 8, 2013.*\n\n### Inspiration\n- Can you form a model that can tell the difference between cars by type or colour?\n- Which cars are manufactured by Tesla vs BMW?'","b""['classification', 'image data', 'image processing', 'object detection', 'object recognition', 'large', 'featured']""",https://www.kaggle.com/jessicali9530/stanford-cars-dataset
b'NYS Municipal Wastewater Treatment Plants Data',b'From New York State Open Data',"b""### Content  \n\nData containing municipal wastewater treatment plant design other features, with data current through the most recent survey.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/cuQwxtsHH8s) by [Samuel Zeller](https://unsplash.com/@samuelzeller) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'design', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-municipal-wastewater-treatment-plants-data
"b'Population of Towns & Villages (Sagar, MP, INDIA)'",b'Quick and easy query to see Population Distribution between urban and rural area',"b""## Context\n\nIndia is second most populace country in the world after China on a trajectory of overtaking China in terms of population by year 2024. Majority of India's population live in small villages, with primary occupation being Agriculture. India like other countries is on a path or urbanization, thus such a data set will help those trying to better understand Rural Urban distribution. \n\n![SagarDistrict_Map][1] \n\n## Content\n\nThis data currently contains very simple information such as names of villages and towns of a tehsil, their population according to 2011 Census.  This information can be used to see distribution of the population: between urban centers of a tehsil and their rural areas, between urban centers of different tehsil, between different regions. \n\n## Future Plans\n\nTo expand this data with GeoCode information, to allow more deeper analysis. \n\n\n  [1]: http://www.districtsagar.com/Content/slides/Madhya%20Pradesh/districtsagar_1.jpg""","b""['demographics', 'india', 'small', 'featured']""",https://www.kaggle.com/ankitsura/population-of-towns-villages-sagar-mp-india
b'Fantasy Premier League (FPL) 2018-2019',"b'Predict the best team, impress all your hard-to-impress friends! '","b""### Context\n\nhttps://fantasy.premierleague.com/drf/bootstrap-static has the information for each gameweek of the Fantasy Premier league. Since the season hasn't started yet, this currently just holds the information for the last gameweek of last season (2017-18). I will add the new data as and when the API updates. \n\n\n### Content\n\nMost of the columns are pretty self-explanatory. Some things to note::\n\n1. The **Cost** is given in units of 0.1 million pounds. \n2.** Influence**, **Creativity** and **Threat** (and consequently **ICT**) are all metrics that FPL came up with to try and assess player performance. More details may be found here https://www.premierleague.com/news/65567. \n3.  **TSB** refers to the % of FPL user teams that the player is in. \n\n\n### Acknowledgements\n\nhttps://www.reddit.com/r/FantasyPL/ always has good stuff. The FPL website has a very helpful API. \n\n### Inspiration\n\nI found a very nice method to use a Linear Programming optimization to build a first trial team. Reinforcement Learning and MDP would be a more elegant approach, and I would love to see what people can come up with. Currently exploring MCMC to build the ideal team for GW1. The volume of data available will increase with each gameweek, so predictive modeling will become a possibility. ""","b""['sports', 'small', 'featured']""",https://www.kaggle.com/delayedkarma/fantasy-premier-league-20182019
b'SOMASet',b'Synthetic training data for deep CNNs in re-identification',"b'### Context\n\nSOMASet is an synthetic dataset consisting of 100K images of 50 human prototypes (25 female and 25 male), created by mixing three somatotypical \xe2\x80\x9cseeds\xe2\x80\x9d:\n\n - ectomorph (long and lean),\n -  mesomorph (athletic, small waist)\n -  endomorph (soft and round body, large frame),\n\nSOMASet is also accounting for different ethnicities.\n Each of these prototypes wears 11 sets of clothes and assumes 250 different poses, over an outdoor background scene, ray-traced for lifelike illumination.\n\n### Content\n\nThe 100.000 Images are organized inside the `somaset` folder in the following form:\n**/somaset/NN/JJ/XXXX.jpg**\n\n -  NN Is a number between `01` and `50` representing an unique human prototype.\n -  JJ is a number between `01` and `08` use to encode a set of garments (clothes).\n - XXXX is a number between `0001` and `0250` encoding different human posing and camera viewpoint.\n\nYou can read more about details about SOMASet in the Paper, and in the Protocol sention below.\n### Acknowledgements\n\n\xe2\x9a\xa0 IN THE CASE YOU PUBLISH MATERIAL BASED ON THIS DATASET THEN IN YOUR ACKNOWLEDGEMENTS, PLEASE MENTION THE BASE WORK AS A REFERENCE\n\n@article{barbosa2017looking,\n  title={Looking beyond appearances: Synthetic training data for deep cnns in re-identification},\n  author={Barbosa, Igor Barros and Cristani, Marco and Caputo, Barbara and Rognhaugen, Aleksander and Theoharis, Theoharis},\n  journal={Computer Vision and Image Understanding},\n  year={2017},\n  publisher={Academic Press}\n}\n## Protocol\n\nIn this section we present SOMAset, describe the protocol followed for creating it and discuss the features that make it\nunique compared to other existing re-id collections. The human figure is normally defined as a mixture of three main somatotypes [12]: ectomorph (long and lean), mesomorph (athletic, small waist) and endomorph (soft and round body, large frame). We account for these facets using an open-source program for 3D photo-realistic human design, Makehuman, and a rendering engine, Blender. Starting from a generic 3D human model we created 25 male and 25 female subjects, by manually varying the height, weight and body proportions for each subject so as to represent mixtures of the three aforementioned somatotypes. \n\nIn order to further improve the similarity to real acquisitions, we also slightly varied parameters like symmetry and the size of legs and/or arms, so as to better simulate natural body variations. In almost all previous re-identification scenarios, it is\nassumed that subjects do not change their clothes between camera acquisitions. Re-identification datasets adhere to this\nassumption, associating identity to appearance (a particular apparel represents a single subject). With SOMAset, we relax\nthis constraint, rendering each of the 50 subjects with 8 different sets of clothing: 5 of these were shared across the\nsexes while 3 each were exclusive for males / females (thus in total there are 11 types of outfit). In this way, we stimulate\nthe network to focus on morphological cues, other than mere appearance.\n\nIn more detail, the 3 clothing variations dedicated to females are: T-shirt with shorts; blouse with skirt; sport top with leggings. The 3 male clothing variations are: suit; striped shirt with jeans; shirt with black trousers. The shared clothing category includes the following 5 variations: white t-shirt with jeans; long sleeve shirt with jeans; blue T-shirt with jeans; jacket over shirt with jeans; overalls.\n\nOut of the 50 subjects, 16 received Caucasian skin, 16 have darker skin tones, while the remaining 18 have beige skin tones to\nmodel Asian types. We did not include further variations (e.g. structural) of the faces and we did omit hair styles, to bound the number of possible variations. Notably, adopting more types of garments does not seem to affect the performance drastically, after some preliminary experiments, not reported here for the lack of space.\n\nEach of the 400 subject-clothing combinations assumed 250 different poses. These poses are extracted from professionally-captured human motion recordings, provided by the CMU Graphics Lab Motion Capture Database. We opted for extracting poses from a recording titled \xe2\x80\x99navigate\xe2\x80\x99, where the subject walks forwards, backwards and sideways.\n\nEach of the resulting N = 100K subject-clothing-pose combinations (N = 50 subjects \xc3\x97 8 clothing sets \xc3\x97 250 poses) is placed in a realistic scene (see below) and captured by a virtual camera with a randomly chosen viewpoint, following a uniform  distribution. Specifically, we place the subject in a random location over the floor of the scene, and we take 250 different viewpoints uniformly spanning a hemisphere centered 8 meters away from the subject\xe2\x80\x99s initial position. This induces a distance varying from 6 to 10 meters between the camera and the rendered subject-clothing-pose. The different camera viewpoints generate people with diverse image occupancy, different lighting patterns and relative pose w.r.t. the observer. A structured outdoor scene was created for rendering, which covers an area of approximately 900 m2 , where each of the 100K instances was\nlocated. The scene includes trees, buildings, pavement, grass and a vehicle, giving a certain variability as the viewpoint\nchanges. \n\n'","b""['image data', 'large', 'featured']""",https://www.kaggle.com/vicolab/somaset
"b""World Bank's Major Contracts """,b'The largest supply contracts awarded by the World Bank',"b'This set of contract awards includes data on commitments against contracts that were reviewed by the Bank before they were awarded (prior-reviewed Bank-funded contracts) under IDA/IBRD investment projects and related Trust Funds. This dataset does not list all contracts awarded by the Bank, and should be viewed only as a guide to determine the distribution of major contract commitments among the Bank\'s member countries. ""Supplier Country"" represents place of supplier registration, which may or not be the supplier\'s actual country of origin. Information does not include awards to subcontractors nor account for cofinancing. The Procurement Policy and Services Group does not guarantee the data included in this publication and accepts no responsibility whatsoever for any consequences of its use. The World Bank complies with all sanctions applicable to World Bank transactions.\n\n### Acknowledgements\n\nThis dataset was kindly made available by the World Bank. You can find [the original dataset here][1].\n\n### Inspiration\n\n- How do the contract awards compare to each nations\'s voting rights? Are there any unexpected, consistent preferences?\n\n  [1]: https://finances.worldbank.org/Procurement/Major-Contract-Awards/kdui-wcs3/data'","b""['international relations', 'supply chain', 'medium', 'featured']""",https://www.kaggle.com/theworldbank/world-banks-major-contracts
b'EMNIST (Extended MNIST)',b'An extended variant of the full NIST dataset',"b'## EMNIST\n\n---\n\nThe EMNIST dataset is a set of handwritten character digits derived from the NIST Special Database 19  and converted to a 28x28 pixel image format and dataset structure that directly matches the MNIST dataset. Further information on the dataset contents and conversion process can be found in the paper available at [https://arxiv.org/abs/1702.05373v1][1].\n\n## Format\nThere are six different splits provided in this dataset and each are provided in two formats:<br>\n\n1. Binary (see emnist_source_files.zip)\n2. CSV (combined labels and images)\n    - Each row is a separate image\n    - 785 columns\n    - First column = class_label (see mappings.txt for class label definitions)\n    - Each column after represents one pixel value (784 total for a 28 x 28 image)\n\n\n\n\n\n\n### ByClass and ByMerge datsets\nThe full complement of the NIST Special Database 19 is available in the ByClass and ByMerge splits. These two datasets have the same image information but differ in the number of images in each class. Both datasets have an uneven number of images per class and there are more digits than letters. The number of letters roughly equate to the frequency of use in the English language.<br>\n\n- train: 697,932\n- test: 116,323\n- total: 814,255\n- classes: ByClass 62 (unbalanced)  / ByMerge 47 (unbalanced)\n<br>\n\n### Balanced dataset\nThe EMNIST Balanced dataset is meant to address the balance issues in the ByClass and ByMerge datasets. It is derived from the ByMerge dataset to reduce mis-classification errors due to capital and lower case letters and also has an equal number of samples per class. This dataset is meant to be the most applicable.<br>\n\n- train: 112,800\n- test: 18,800\n- total: 131,600\n- classes: 47 (balanced)\n<br>\n\n\n### Letters datasets\nThe EMNIST Letters dataset merges a balanced set of the uppercase and lowercase letters into a single 26-class task. <br>\n\n- train: 88,800\n- test: 14,800\n- total: 103,600\n- classes: 37 (balanced)\n<br>\n\n### Digits and MNIST datsets\nThe EMNIST Digits and EMNIST MNIST dataset provide balanced handwritten digit datasets directly compatible with the original MNIST dataset. <br>\n\n- train: Digits 240,000 / MNIST 60,000\n- test: Digits 40,000 / MNIST 10,000\n- total: Digits 280,000 / MNIST 70,000\n- classes: 47 (balanced)\n<br>\n\n\n### Visual breakdown of EMNIST datasets\nPlease refer to the EMNIST paper for details on the structure of the dataset [https://arxiv.org/abs/1702.05373v1][1].<br>\n![EMNIST datasets breakdown][3]\n\n## Acknowldgements\n\nCohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017). EMNIST: an extension of MNIST to handwritten letters. \n\n\nDataset retrieved from [https://www.nist.gov/itl/iad/image-group/emnist-dataset][4]\n\n\n*Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre van Schaik<br>\nThe MARCS Institute for Brain, Behaviour and Development<br>\nWestern Sydney University<br>\nPenrith, Australia 2751*\n\n\n  [1]: https://arxiv.org/abs/1702.05373v1\n  [2]: http://yann.lecun.com/exdb/mnist/\n  [3]: https://imgur.com/MJo1Kd0.jpg\n  [4]: https://www.nist.gov/itl/iad/image-group/emnist-dataset'","b""['machine learning', 'large', 'featured']""",https://www.kaggle.com/crawford/emnist
b'NYS Lobbying Clients and Lobbyist Data',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Evo4wmtRaPI) by [Alex Radelich](https://unsplash.com/@alexradelich) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-lobbying-clients-and-lobbyist-data
b'Aerial Change Detection in Video Games',b'Scenes Generated in Virtual Battle Station 2',"b'### Context\nWondering if a model can detect visual differences through gaming graphics? If it is possible, does the model have real world applications?\n\nCheck out these images from Virtual Battle Station 2 and see if you can build the model and identify any further trends in this visual dataset.\n\n### Content\nThe dataset consists of before and after scenes with one major difference (new building, road, bush or car) and lots of smaller minor differences (lighting, weather, ...). The goal is to automatically detect the major differences among the noisy background of other smaller differences.\n\n### Acknowledgements\n\nThe original dataset page is down but the full dataset can still be downloaded here: https://computervisiononline.com/dataset/1105138664\nCredit: Nicolas Bourdis, Denis Marraud, Hichem Sahbi\n\n\n### Inspiration\n\nHow well do simulated video game images apply to real world problems?'","b""['image data', 'image processing', 'video games', 'aerospace engineering', 'large', 'featured']""",https://www.kaggle.com/kmader/aerial-change-detection-in-video-games
b'International football results from 1872 to 2018',"b'An up-to-date dataset of nearly 40,000 international football results'","b""### Context\n\nWell, what happened was that I was looking for a semi-definite easy-to-read list of international football matches and couldn't find anything decent. So I took it upon myself to collect it for my own use. I might as well share it.\n\n### Content\n\nThis dataset includes 39,669 results of international football matches starting from the very first official match in 1972 up to 2018.  The matches range from FIFA World Cup to FIFI Wild Cup to regular friendly matches. The matches are strictly men's full internationals and the data does not include Olympic Games or matches where at least one of the teams was the nation's B-team, U-23 or a league select team.\n\n`results.csv` includes the following columns:\n\n* `date` - date of the match\n* `home_team` - the name of the home team\n* `away_team` - the name of the away team\n* `home_score` - full-time home team score including extra time, not including penalty-shootouts\n* `away_score` - full-time away team score including extra time, not including penalty-shootouts\n* `tournament` - the name of the tournament\n* `city` - the name of the city/town/administrative unit where the match was played\n* `country` - the name of the country where the match was played\n* `neutral` - TRUE/FALSE column indicating whether the match was played at a neutral venue\n\nNote on team and country names: \nFor home and away teams the *current* name of the team has been used. For example, when in 1882 a team who called themselves Ireland played against England, in this dataset, it is called Northern Ireland because the current team of Northern Ireland is the successor of the 1882 Ireland team. This is done so it is easier to track the history and statistics of teams. \n\nFor country names, the name of the country *at the time of the match* is used. So when Ghana played in Accra, Gold Coast in the 1950s, even though the names of the home team and the country don't match, it was a home match for Ghana. This is indicated by the neutral column, which says FALSE for those matches, meaning it was **not** at a neutral venue.\n\n### Acknowledgements\n\nThe data is gathered from several sources including but not limited to Wikipedia, fifa.com, rsssf.com and individual football associations' websites.\n\n### Inspiration\n\nSome directions to take when exploring the data:\n\n - Who is the best team of all time\n - Which teams dominated different eras of football\n - What trends have there been in international football throughout the ages - home advantage, total goals scored, distribution of teams' strength etc\n - Can we say anything about geopolitics from football fixtures - how has the number of countries changed, which teams like to play each other\n - Which countries host the most matches where they themselves are not participating in\n - How much, if at all, does hosting a major tournament help a country's chances in the tournament\n - Which teams are the most active in playing friendlies and friendly tournaments - does it help or hurt them\n - Do you dare to make any predictions for 2018 World Cup based on this data?\n\nThe world's your oyster, my friend.\n\n### Contribute\n\nIf you notice a mistake or the results are being updated fast enough for your liking, you can fix that by submitting a pull request on GitHub: https://github.com/martj42/international_results\n\nIf you don't know what that is, google it, it's probably worth knowing. If you still can't be bothered, you can write your grievances onto the message board here on kaggle under the Discussion tab.\n""","b""['sports', 'history', 'countries', 'association football', 'international relations', 'small', 'featured']""",https://www.kaggle.com/martj42/international-football-results-from-1872-to-2017
b'Breast Cancer Wisconsin (Diagnostic) Data Set',b'Predict whether the cancer is benign or malignant',"b'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. \nn the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: ""Robust Linear Programming Discrimination of Two Linearly Inseparable Sets"", Optimization Methods and Software 1, 1992, 23-34]. \n\nThis database is also available through the UW CS ftp server: \nftp ftp.cs.wisc.edu \ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\nAlso can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n\nAttribute Information:\n\n1) ID number \n2) Diagnosis (M = malignant, B = benign) \n3-32) \n\nTen real-valued features are computed for each cell nucleus: \n\na) radius (mean of distances from center to points on the perimeter) \nb) texture (standard deviation of gray-scale values) \nc) perimeter \nd) area \ne) smoothness (local variation in radius lengths) \nf) compactness (perimeter^2 / area - 1.0) \ng) concavity (severity of concave portions of the contour) \nh) concave points (number of concave portions of the contour) \ni) symmetry \nj) fractal dimension (""coastline approximation"" - 1)\n\nThe mean, standard error and ""worst"" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features.  For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n\nMissing attribute values: none\n\nClass distribution: 357 benign, 212 malignant'","b""['healthcare', 'small', 'featured']""",https://www.kaggle.com/uciml/breast-cancer-wisconsin-data
b'NYS Real Property Assessment and Tax Data',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-real-property-assessment-and-tax-data
b'NYS Chemical Dependence Treatment Prog Admissions',b'From New York State Open Data',"b""### Content  \n\nNYS Office of Alcoholism and Substance Abuse Services (OASAS) certified chemical dependence treatment programs report admissions of people served in programs throughout NYS.  This dataset includes the number of admissions to NYS OASAS certified treatment programs aggregated by the program category, county of the program location, age group of client at admission, and the primary substance of abuse group.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/RbwoCABWQ9w) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'alcohol', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-chemical-dependence-treatment-prog-admissions
b'Economic Freedom of the World',b'Economic Freedom of the World: 2018 Annual Report',"b'### Introduction\n\nThe index published in [*Economic Freedom of the World*][1] by the [Fraser Institute][2] measures the degree to which the policies and institutions of countries are supportive of economic freedom. The cornerstones of economic freedom are personal choice, voluntary exchange, freedom to enter markets and compete, and security of the person and privately owned property. Forty-two data points are used to construct a summary index and to measure the degree of economic freedom in five broad areas.\n\n\n### Areas\n\n - **Area 1: Size of Government** - As government spending, taxation, and\n   the size of government-controlled enterprises increase, government\n   decision-making is substituted for individual choice and economic\n   freedom is reduced.\n - **Area 2: Legal System and Property Rights** - Protection of persons and\n   their rightfully acquired property is a central element of both\n   economic freedom and civil society. Indeed, it is the most important\n   function of government.\n - **Area 3: Sound Money** - Inflation erodes the value of rightfully earned\n   wages and savings. Sound money is thus essential to protect property\n   rights. When inflation is not only high but also volatile, it becomes\n   difficult for individuals to plan for the future and thus use\n   economic freedom effectively.\n - **Area 4: Freedom to Trade Internationally** - Freedom to exchange\xe2\x80\x94in its\n   broadest sense, buying, selling, making contracts, and so on\xe2\x80\x94is\n   essential to economic freedom, which is reduced when freedom to\n   exchange does not include businesses and individuals in other\n   nations.\n - **Area 5: Regulation** - Governments not only use a number of tools to\n   limit the right to exchange internationally, they may also develop\n   onerous regulations that limit the right to exchange, gain credit,\n   hire or work for whom you wish, or freely operate your business.\n\n\n  [1]: https://www.fraserinstitute.org/studies/economic-freedom\n  [2]: https://www.fraserinstitute.org/'","b""['economics', 'politics', 'world', 'countries', 'international relations', 'small', 'featured']""",https://www.kaggle.com/gsutters/economic-freedom
b'Classified Ads for Cars',b'Used cars for sale in Germany and Czech Republic since 2015',"b""# Context \n\nThe data was scraped from several websites in Czech Republic and Germany over a period of more than a year. Originally I wanted to build a model for estimating whether a car is a good buy or a bad buy based on the posting. But I was unable to create a model I could be satisfied with and now have no use for this data. I'm a great believer in open data, so here goes.\n\n\n# Content\n\nThe scrapers were tuned slowly over the course of the year and some of the sources were completely unstructured, so as a result the data is dirty, there are missing values and some values are very obviously wrong (e.g. phone numbers scraped as mileage etc.)\n\nThere are roughly 3,5 Million rows and the following columns:\n\n - maker - normalized all lowercase\n - model - normalized all lowercase\n - mileage - in KM\n - manufacture_year\n - engine_displacement - in ccm\n - engine_power - in kW\n - body_type - almost never present, but I scraped only personal cars, no motorcycles or utility vehicles\n - color_slug - also almost never present\n - stk_year - year of the last emission control\n - transmission - automatic or manual\n - door_count\n - seat_count\n - fuel_type - gasoline, diesel, cng, lpg, electric\n - date_created - when the ad was scraped\n - date_last_seen - when the ad was last seen. Our policy was to remove all ads older than 60 days\n - price_eur - list price converted to EUR\n\n\n# Inspiration\n\n - Which factors determine the price of a car?\n - With what accuracy can the price be predicted?\n - Can a model trained on all cars be used to accurately predict prices of models with only a few samples?\n\nIn my analysis, there is too much variance even within individual models to reliably predict the price, can you prove me wrong? I would love to understand what I did wrong if you can.""","b""['automobiles', 'medium', 'featured']""",https://www.kaggle.com/mirosval/personal-cars-classifieds
b'WTA Matches and Rankings',"b""All Women's Tennis Association data you ever wanted""","b""### Context\n\nThe WTA (Women's Tennis Association) is the principal organizing body of women's professional tennis,  it governs its own tour worldwide. On its website, it provides a lot of data about the players as individuals as well the tour matches with results and the current rank during it.\n\nLuckily for us, [Jeff Sackmann](https://github.com/JeffSackmann) scraped the website and collected everything from there and put in a nice way into easily consumable datasets.\n\n_On Jeff's [GitHub account](https://github.com/JeffSackmann) you can find a lot more data about tennis!_\n\n### Content\n\nThe dataset present here is directly downloaded from the source, no alteration on the data was made, the files were only placed in subdirectories so one can easily locate them.\n\nIt covers statistics of players registered on the WTA, the matches that happened on each tour by year, with results, as well some qualifying matches for the tours.\n\nAs a reminder, you may not find all data of the matches prior to 2006, so be warned when working with those sets.\n\n### Acknowledgements\n\nThanks to [Jeff Sackmann](https://github.com/JeffSackmann) for maintaining such collection and making it public!\n\nAlso, a thank you for WTA for collecting those stats and making them accessible to anyone on their site.\n\n### Inspiration\n\nHere are some things to start:\n\n - Which player did the most rapidly climb the ranks through the years?\n - Does the rank correlates with the money earn by the player?\n - What can we find about the age?\n - There is some deterministic factor to own the match?\n\n\n\n\n\n""","b""['sports', 'tennis', 'medium', 'featured']""",https://www.kaggle.com/joaoevangelista/wta-matches-and-rankings
b'Russian Single Speaker Speech Dataset',b'CSS10 Russian: Single Speaker Speech Dataset',"b'### Context\n\nCSS10 is a collection of single speaker speech datasets for 10 languages. Each of them consists of audio files recorded by a single volunteer and their aligned text sourced from LibriVox.\n\n### Content\nEach line in `transcript.txt` is delimited by `|` into four fields, i.e., audio file location, original script, normalized script, and audio duration.\n\nVisit [here](https://github.com/kyubyong/css10) to check out our project using this dataset.\n\n### Acknowledgements\n\nWe thank LibriVox and the volunteers.\n \n### Contact\nYou can contact me at kbpark.linguist@gmail.com.\n\nJune, 2018.\n\nKyubyong Park & Tommy Mulc\n'","b""['linguistics', 'large', 'featured']""",https://www.kaggle.com/bryanpark/russian-single-speaker-speech-dataset
b'GloVe: Global Vectors for Word Representation',b'Pre-trained word vectors from Twitter',"b""The below information is from the project page: https://nlp.stanford.edu/projects/glove/\n\n### Context\nGloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\n\n### Content\nDue to size constraints, only the 25 dimension version is uploaded. Please visit the project page for GloVe of other dimensions.\n\nThis dataset (https://www.kaggle.com/rtatman/glove-global-vectors-for-word-representation) contains GloVe extracted from Wikipedia 2014 + Gigaword 5.\n\n1.   Nearest neighbors\nThe Euclidean distance (or cosine similarity) between two word vectors provides an effective method for measuring the linguistic or semantic similarity of the corresponding words. Sometimes, the nearest neighbors according to this metric reveal rare but relevant words that lie outside an average human's vocabulary.\n2.   Linear substructures\nThe similarity metrics used for nearest neighbor evaluations produce a single scalar that quantifies the relatedness of two words. This simplicity can be problematic since two given words almost always exhibit more intricate relationships than can be captured by a single number. For example, man may be regarded as similar to woman in that both words describe human beings; on the other hand, the two words are often considered opposites since they highlight a primary axis along which humans differ from one another.\n\nIn order to capture in a quantitative way the nuance necessary to distinguish man from woman, it is necessary for a model to associate more than a single number to the word pair. A natural and simple candidate for an enlarged set of discriminative numbers is the vector difference between the two word vectors. GloVe is designed in order that such vector differences capture as much as possible the meaning specified by the juxtaposition of two words.\n\n### Acknowledgements\n\nJeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014.\n\n\n### Inspiration\n\nThe dataset specifically includes tokens extracted from Twitter, which unlike tokens from Wikipedia, include many abbreviations that have interesting content.""","b""['linguistics', 'languages', 'twitter', 'medium', 'featured']""",https://www.kaggle.com/joshkyh/glove-twitter
"b'Dice: d4, d6, d8, d10, d12, d20 Images'","b'Beginner set of 16,000 custom images for categorizing polyhedral dice'","b'# Context\n\nBeginner set of 16,000 custom images for categorizing polyhedral dice\n\n# Content\n\n## Image Organization\n### ~ 85% / 15% (train / valid)\n- all training images are 480x480\n- all d4, d8, d10, and d12 validation images are 480x480\n- most d6 and d20 validation images are 480x480\n- a small percentage of additional d6 and d20 validation images are larger (1024px long side) and completely unlike the training set\n\n## Methodology\n_All images were created, edited, and sorted by Mario Lurig._\n\n- Fixed camera positions (minimum 2 angles) used to capture video on a [rotating platform][1] with two white lights\n\t-  Minimum 5 different dice used on 6 different backgrounds (white and various colors)\n\t-  Video was then exported as images and then batch cropped to 480x480\n- Handheld camera moved over 5+ dice on various wood surfaces (minimum 2) using natural lighting\n\t- Video edited and exported to images then batch cropped to 480x480\n\t- Images that were partially out of crop were manually removed\n\nThe additional d6 and d20 validation images were from my personal image collection or taken additionally on a variety of surfaces with no care for lighting conditions to work as a more robust test.\n\nThe validation images were pulled from the full image set (480x480 images) as a 1/7th slice rather than randomly. If preferred, you could combine train/valid together and randomly assign them via your code; this data organization method was chosen to help beginners.\n\nFinally, images taken in like groups are named in like ways. For instance, d4_angleXXX are all d4 dice taken at an angle. d10_top are all d10 dice taken from the top down. Once again done in an effort to make it easy to add/remove data and see how that changes the results.\n\n_**Note:** There are more d6 and d20 images than d4,d8,d10,d12 due to those two dice being my initial test set before building the rest._\n\n### Inspiration\n\nAs an avid roleplayer and the person behind [HeroMuster.com](https://heromuster.com/), I decided to start learning ML from not only the code and execution side, but also from the data collection/organization side. This felt like a great way to do that.\n\n### Quicky results\n[ResNet101 0.9947 accuracy][2]\n![Confusion Matrix][3]\n\n\n  [1]: https://www.thingiverse.com/make:502149\n  [2]: https://www.kaggle.com/ucffool/fast-ai-resnet101-99-5-or-better\n  [3]: https://i.imgur.com/QXY9zJ2.png'","b""['image data', 'games and toys', 'role-playing games', 'medium', 'featured']""",https://www.kaggle.com/ucffool/dice-d4-d6-d8-d10-d12-d20-images
b'Flower Color Images',b'Set for Classification',"b""### History\nI made the database from the fragments of my own photos of flowers. The images are selected to reflect the flowering features of these plant species.\n\n### Content\nThe content is very simple:  210 images (128x128x3)  with 10 species of flowering plants and the file with labels `flower-labels.csv`. Photo files are in the `.png` format and the labels are the integers.\n\n#### Label => Name\n0 => phlox; 1 => rose; 2 => calendula; 3 => iris; 4 => leucanthemum maximum; \n5 => bellflower; 6 => viola; 7 => rudbeckia laciniata (Goldquelle); 8 => peony; 9 => aquilegia.\n\n### Acknowledgements\nAs an owner of this database, I have published it for absolutely free using by any site visitor.\n\n### Usage\nAccurate classification of plant species with a small number of images isn't a trivial task. I hope this set can be interesting for training skills in this field. A wide spectrum of algorithms can be used for classification.""","b""['classification', 'deep learning', 'image data', 'plants', 'nature', 'medium', 'featured']""",https://www.kaggle.com/olgabelitskaya/flower-color-images
b'ASL Alphabet',b'Image data set for alphabets in the American Sign Language ',"b'### Context\n\nThe data set is a collection of images of alphabets from the American Sign Language, separated in 29 folders which represent the various classes.\n\n### Content\n\nThe training data set contains 87,000 images which are 200x200 pixels. There are 29 classes, of which 26 are for the letters A-Z and 3 classes for *SPACE*, *DELETE* and *NOTHING*.\nThese 3 classes are very helpful in real time applications, and classification.\nThe test data set contains a mere 29 images, to encourage the use of real world test images.\n\n![enter image description here][1]\nhttps://www.nidcd.nih.gov/sites/default/files/Content%20Images/NIDCD-ASL-hands-2014.jpg\n\n### Acknowledgements\n\n### Inspiration\n\nWhat is that person saying?\n\n\n  [1]: https://www.nidcd.nih.gov/sites/default/files/Content%20Images/NIDCD-ASL-hands-2014.jpg'","b""['image data', 'linguistics', 'image processing', 'large', 'featured']""",https://www.kaggle.com/grassknoted/asl-alphabet
b'US Permanent Visa Applications',b'Detailed information on 374k visa decisions',"b""### Context: \nA permanent labor certification issued by the Department of Labor (DOL) allows an employer to hire a foreign worker to work permanently in the United States. In most instances, before the U.S. employer can submit an immigration petition to the Department of Homeland Security's U.S. Citizenship and Immigration Services (USCIS), the employer must obtain a certified labor certification application from the DOL's Employment and Training Administration (ETA). The DOL must certify to the USCIS that there are not sufficient U.S. workers able, willing, qualified and available to accept the job opportunity in the area of intended employment and that employment of the foreign worker will not adversely affect the wages and working conditions of similarly employed U.S. workers.\n\n### Content: \nData covers 2012-2017 and includes information on employer, position, wage offered, job posting history, employee education and past visa history, associated lawyers, and final decision.\n\n### Acknowledgements: \nThis data was collected and distributed by the [US Department of Labor](https://www.foreignlaborcert.doleta.gov/perm.cfm).\n\n### Inspiration: \n* Can you predict visa decisions based on employee/employer/wage?\n* How does this data compare to H1B decisions in this [dataset](https://www.kaggle.com/nsharan/h-1b-visa)?""","b""['government agencies', 'immigration', 'medium', 'featured']""",https://www.kaggle.com/jboysen/us-perm-visas
b'Taylor Swift Song Lyrics from all the albums',"b""All the song lyrics from Taylor Swift's albums""","b'### Context\n\nThis data set was created by [PromptCloud][1] (a Data-as-a-Service provider), using the API exposed by Genius.com.\n\n### Content\n\nIt has the following data fields:\n\n - album name \n - track title \n - track number \n - lyric text \n - line number of the lyric in the track\n - year of release of the album\n\n### Initial analyses\n\nYou can check out [this article][2] to understand the following initial set of analysis:\n\n\xe2\x80\x93 Exploratory analysis\n\n - word counts based on tracks and albums\n - time series analysis of word counts\n - distribution of word counts\n\n\xe2\x80\x93 Text mining\n \n - word cloud\n - bigram network\n - sentiment analysis (includes chord diagram)\n\n  [1]: https://www.promptcloud.com\n  [2]: https://www.promptcloud.com/blog/data-visualization-text-mining-taylor-swift-song-lyrics'","b""['internet', 'music', 'entertainment', 'arts and entertainment', 'performing arts', 'small', 'featured']""",https://www.kaggle.com/PromptCloudHQ/taylor-swift-song-lyrics-from-all-the-albums
"b""PLAYERUNKNOWN'S BATTLEGROUNDS Player Statistics""",b'Player statistics for PUBG. 150 features per player.',"b""### Context\n\nGrab your pans...\n\nPlayer statistics for approximately 85,000 of the top PUBG players (as tracked by https://pubgtracker.com/). All statistics were gathered using aggregate region filters (all regions) and feature labels are subdivided by server type: solo, duo, and squad.\n\n87,898 players with 150 numerical game-play features per player (+2 for player name and PUBG Tracker ID).\n\n### Content\n\nFeatures include KD ratios, wins, losses, damage, wins, top 10's, and movement characteristics (walking/riding distance etc...)\n\n### Acknowledgements\n\nSpecial thanks to pubgtracker.com for their support and aid with gathering this data. More information can be found here:\nhttps://pubgtracker.com/\n\nPLAYERUNKNOWN'S BATTLEGROUNDS is a registered trademark, trademark or service mark of Bluehole, Inc. and its affiliates\nhttps://www.playbattlegrounds.com/main.pu\n\n### Inspiration\n\nAs a gamer addicted to PUBG, it was a blast putting this data set together. Some great project ideas include:\n\na. Visualizations of player skill vs. specific strategies\n\nb. Unsupervised clustering of players based on strategy (for matchmaking or team building)\n\nc. Prediction of features based on player skill and/or strategies""","b""['video games', 'games and toys', 'medium', 'featured']""",https://www.kaggle.com/lazyjustin/pubgplayerstats
b'Kyoto Restaurant Reviews Dataset',b'800+ Restaurants Reviews in Kyoto on Tabelog',"b'### Context\n\nData was scraped from [Tabelog][1].\nWhole scraping script is on [my GitHub page][2].\n\nTabelog is a crowd-sourced restaurant-rating services. This site is the largest restaurant-review site which has 5.9 million reviews of 800,000 lists of restaurants Japan. You can\xe2\x80\x99t only find reviews of restaurants but also you can refer to information of each restaurants and eating places in Japan. \n\nTabelog uses a 5-point scale like other websites such as Yelp and TripAdvisor do. However, unlike Yelp and TripAdvisor, good rating is between 3.00 ~ 4.00 points because users take their ratings seriously and many Michelin-star winners sit around 4.00.&nbsp; \n\n### Content\n\nThe dataset covers over 800 restaurant information in Kyoto Prefecture.\nThe restaurants in the dataset were chosen out of all the restaurants listed on Tabelog based on their review numbers. Information of restaurants without any reviews by Tabelog users were deleted thus each restaurant in the dataset has, at least, over 1 review. \n\n### Acknowledgements\n\nData is from Tabelog.\n\n\n### Inspiration\n\nCan you find the best restaurant in Kyoto?\n\n  [1]: https://tabelog.com/en/\n  [2]: https://github.com/koki25ando/Kyoto-Food-Restaurant-Data-Scraping/blob/master/kyoto.R'","b""['food and drink', 'asia', 'small', 'featured']""",https://www.kaggle.com/koki25ando/tabelog-restaurant-review-dataset
b'Travian Dataset',b'Suitable for evaluating link prediction and community detection algorithms',"b'**Travian Network Datasets**\n\nThe aim of this project is to study the structure of different types of networks that emerge in massively multi-player online games. Travian is a popular browser-based real-time strategy game with more than 5 million players. Players form alliances of up to 60 members under a leader or a leadership team. Each game cycle lasts a fixed period (a few months).\nThis network dataset was designed for studying multiplex network problems, in particular community detection since the ground truth for alliance membership is available. It was extracted from data from a study of virtual organizations conducted by researchers across several institutions, including the University of Arkansas. Data was collected from a 3x server (with a 3.5 month game cycle) based in Germany. These networks are from a 30 day game period.\n\n**Attacks:** This network contains information about raids that occurred between players. The main goal of a raid in Travian is to loot resources.\n\n**Messages:**  Travian has an in-game messaging system (IGM) for player communication. The network contains information about these messages. Based on our analysis, around 70% of messages exchange occur between users in the same alliance, making it a reasonable benchmark for community detection algorithms. Along with the dataset itself, the community structure is also provided.\n\n**Trades:** Represents trades between players (both players must possess a marketplace). Similar to messages, the trades network is appropriate for testing community detection methods. The community structure for the trades network is also available.\n\n**Community Structure:** We treat the alliance membership information as the community structure.\n\n**Citation**\nIf you want to use the network data please cite one of the following papers:\n\n - ""Conflict and Communication in Massively-Multiplayer Online Games"",\n   Alireza Hajibagheri, Kiran Lakkaraju, Gita Sukthankar, Rolf T.\n   Wigand, and Nitin Agrawal. Proceedings of the International\n   Conference on Social Computing, Behavioral-Cultural Modeling, and\n   Prediction. 2015.\n - ""Using Massively Multiplayer Online Game Data to Analyze the Dynamics\n   of Social Interactions"", \nAlireza Hajibagheri, Gita Sukthankar, Kiran\n   Lakkaraju, Hamidreza Alvari, Rolf T Wigand, Nitin Agarwal. Social\n   Interaction in Virtual Worlds. 2017. \n\n\n**Other Publications**\n\nOther aspects of the Travian data have been used by the University of Arkansas team and their colleagues to study virtual teams and organizations. Please see the following publications for more information:\n\n - Social Network Indices as Performance Predictors in a Virtual\n   Organization\n - Cooperation, Coordination, and Trust in Virtual Teams: Insights from\n   Virtual Games\n - A Multi-Level View of the Antecedents and Consequences of Trust in\n   Virtual Leaders\n - The Dynamics of Shared Leadership: Building Trust and Enhancing\n   Performance\n\n**Current Contributors**\n\n - University of Arkansas: Nitin Agarwal, Rolf T. Wigand\n - Sonobi: Alireza Hajibagheri\n - University of Central Florida: Gita Sukthankar\n - Sandia National Labs: Kiran Lakkaraju\n\n**Sponsors**\n\n - University of Arkansas: NSF-0838231\n - University of Central Florida: NSF IIS-0845159'","b""['time series analysis', 'forecasting', 'computer science', 'social sciences', 'communities', 'small', 'featured']""",https://www.kaggle.com/ahajib/travian-dataset
"b'""Mega-sena"" Brazil Lottery'","b'Brazil\'s ""Mega-sena"" lottery rounds'","b'### Context\n\n""Mega-sena"" is a lottery from Brazil and pays millions to the winners. The rounds happens two times a week in every week of the year. You can choose from 6 to 15 numbers to bet in the round. The value o the bid for 6 numbers is R$ 3,50 and for 15 numbers is R$ 17.517,50. They pay 45,3% of the collected value of every round.\n\nYou can have more info here [http://www.loterias.caixa.gov.br/wps/portal/loterias/landing/megasena/][1]\n\n\n### Content\n\nThis dataset have info of all rounds of Brazil lottery that occured since 1996/03/11 (the first one) until the lottery number 2062 that occured in 2018/07/25.\n\nThe contents of this dataset basically are:\n\n- Id: Identity;\n- Concurso: The number of the lottery;\n- Data Sorteio: The date that the round occured;\n- 1\xc2\xaa Dezena: The first draw number;\n- 2\xc2\xaa Dezena: The second draw number;\n- 3\xc2\xaa Dezena: The third draw number;\n- 4\xc2\xaa Dezena: The fourth draw number;\n- 5\xc2\xaa Dezena: The fifth draw number;\n- 6\xc2\xaa Dezena: The sixth draw number;\n- Arrecadacao_Total: The total collected from all bettors for this round of the lottery;\n- Ganhadores_Sena: The quantity of winners that hitted at least six numbers in this round;\n- Cidade: The city of the winner;\n- UF: The state of the winner;\n- Rateio_Sena: The value splited for the winners;\n- Ganhadores_Quina: The quantity of winners that hitted five numbers;\n- Rateio_Quina: The value splited for the winners of five numbers;\n- Ganhadores_Quadra: The quantity of winners that hitted four numbers;\n- Rateio_Quadra: The value splited for the winners of four numbers;\n- Acumulado: A ""yes/no"" field that tells if this round had the values accumulated to the next round;\n- Valor_Acumulado: The value of money accumulated to the next round if no one wins this round;\n- Estimativa_Pr\xc3\xaamio: An estimate of the total prize;\n- Acumulado_Mega_da_Virada: A accumulated value that goes for a special modality of the lottery\n\n### Acknowledgements\n\nThis dataset is public info provided by [http://www.loterias.caixa.gov.br][2]\n\nThe link with most updated lotterys can be downloaded here: [http://www1.caixa.gov.br/loterias/_arquivos/loterias/D_megase.zip][3]\n\n### Inspiration\n\nThere\'s a lot of data science analisys to do here and patterns yet to discover. Maybe someday we can predict the next 6 numbers to win this lottery!\n\n\n  [1]: http://www.loterias.caixa.gov.br/wps/portal/loterias/landing/megasena/\n  [2]: http://www.loterias.caixa.gov.br\n  [3]: http://www1.caixa.gov.br/loterias/_arquivos/loterias/D_megase.zip'","b""['brazil', 'small', 'featured']""",https://www.kaggle.com/viniciusbbizarri/sorteiosmegasena
b'24 thousand tweets later ',b'2017 tweets from incubators and accelerators',b'###Context\n\nI collected this data from incubators and accelerators to find out what they have been talking about in 2017.\n\n###Content\n\nThe data contains the twitter usernames of various organizations and tweets for the year 2017 collected on 28th Dec 2017.\n\n###Acknowledgements\n\nMuch appreciation to @emmanuelkens for helping in thinking through this\n\n###Inspiration\n\nI am very curious to find out what the various organizations have been talking about in 2017. I would also like to find out the most popular organization by tweets and engagement. I am also curious to find out if there is any relationship between the number of retweets a tweet gets and the time of day it was posted!\n',"b""['twitter', 'companies', 'small', 'featured']""",https://www.kaggle.com/derrickmwiti/24-thousand-tweets-later
b'2016 MLB Season',b'Scraped data from https://www.baseball-reference.com/',"b'### Context:\n\nToday, MLB is composed of 30 teams: 29 in the United States and one in Canada. Teams play 162 games each season and five teams in each league advance to a four-round postseason tournament that culminates in the World Series, a best-of-seven championship series between the two league champions that dates to 1903. Baseball broadcasts are aired on television, radio, and the Internet throughout North America and in several other countries throughout the world. MLB has the highest season attendance of any sports league in the world with more than 73 million spectators in 2015.  \n\nSource: https://en.wikipedia.org/wiki/Major_League_Baseball\n\n\n### Content:\n\nI used scrapy to gather data on the 2016 MLB Season.\n\n### Acknowledgements:\n\nAll data has been retrieved from https://www.baseball-reference.com/\n\n### Inspiration:\n\nWho is the greatest baseball team of all time?\n\n'","b""['sports', 'weather', 'united states', 'cities', 'baseball', 'small', 'featured']""",https://www.kaggle.com/cyaris/2016-mlb-season
b'SEA Building Energy Benchmarking',b'From City of Seattle Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/OW4Cu-4ZSos) by [Andrew McSparran](https://unsplash.com/@andrewmcsparran) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'energy', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/sea-building-energy-benchmarking
b'Columbia Object Image Library (COIL-100) Dataset',b'100 different objects imaged at every angle in a 360 rotation',"b'### Context\nCOIL-100 was collected by the Center for Research on Intelligent Systems at the Depart\x01ment of Computer Science\x0c, Columbia University. The database contains color images of 100 objects. The objects were placed on a motorized turntable against a black background and images were taken at pose internals of 5 degrees. This dataset was used in a real-time 100 object recognition system whereby a system sensor could identify the object and display its angular pose.\n\n### Content\nThere are 7,200 images of 100 objects. Each object was turned on a turnable through 360 degrees to vary object pose with respect to a fixed color camera. Images of the objects were taken at pose intervals of 5 degrees. This corresponds to 72 poses per object. There images were then size normalized. Objects have a wide variety of complex geometric and reflectance characteristics. \n\n\n### Acknowledgements\nOriginal data source and banner image: http://www1.cs.columbia.edu/CAVE/software/softlib/coil-100.php\n\nThis dataset is intended for non-commercial research purposes only. When using this dataset, please cite:\n\n""Columbia Object Image Library (COIL-100),""\nS. A. Nene, S. K. Nayar and H. Murase,\nTechnical Report CUCS-006-96, February 1996.\n\n\n### Inspiration\n- Can you train a system to identify objects in real time?'","b""['image data', 'image processing', 'object identification', 'medium', 'featured']""",https://www.kaggle.com/jessicali9530/coil100
b'NY Department of Health and Mental Hygiene',b'From New York City Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'health', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/ny-department-of-health-and-mental-hygiene
b'New York State Index Crimes',b'From New York State Open Data',"b""### Content  \n\nThe Division of Criminal Justice Services (DCJS) collects crime reports from more than 500 New York State police and sheriffs' departments. DCJS compiles these reports as New York's official crime statistics and submits them to the FBI under the National Uniform Crime Reporting (UCR) Program. UCR uses standard offense definitions to count crime in localities across America regardless of variations in crime laws from state to state. In New York State, law enforcement agencies use the UCR system to report their monthly crime totals to DCJS. The UCR reporting system collects information on seven crimes classified as Index offenses which are most commonly used to gauge overall crime volume. These include the violent crimes of murder/non-negligent manslaughter, forcible rape, robbery, and aggravated assault; and the property crimes of burglary, larceny, and motor vehicle theft. Police agencies may experience reporting problems that preclude accurate or complete reporting. The counts represent only crimes reported to the police but not total crimes that occurred.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/7mqsZsE6FaU) by [Matt Popovich](https://unsplash.com/@uh) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/new-york-state-index-crimes
b'All UK Active Companies By SIC And Geolocated',"b'3,801,733 company details'","b'I work with UK company information on a daily basis, and I thought it would be useful to publish a list of all active companies, in a way that could be used for machine learning.\n\nThere are 3,801,733 rows in the dataset, one for each active company. The postcode which is included in the dataset has been geolocated, and the resultant latitude and longitudes have been included, along with the Standard Industrial Classification Code, and date of incorporation.\n\nThe company list is from the publicly available 1st November 2017 Companies House snapshot.  \n\nThe postcode geolocations and SIC Codes are from the gov.uk website.\n\nIn the file AllCompanies.csv each row is formatted as follows:\n\n - CompanyNumber - in the format of 99999999 for England/Wales, SC999999 for Scotland and NI999999 for Northern Ireland.\n - IncorporationDate - in British date format, dd/mm/yyyy\n - RegisteredAddressPostCode - standard British format Postcode\n - Latitude - to 6 decimal places\n - Longitude  - to 6 decimal places\n - SIC - 5 digits or if not known, None - see separate file for description of each code.\n\n**Inspiration**\nPossible uses for this data is to see where certain types of companies are located in the UK, and how over time they multiply and spread throughout the UK.\n\nTraining ML algorithms to predict where there are a high (or low) density of certain types of companies, and where would be a good area for a company to be located, if it wanted minimal competition, or the inverse, where there are clusters of high densities, where it might be easier to recruit specialised staff.\n\nA useful addition would be to overlay population density, which I am currently working on as an option for this dataset. \n\nI am sure there are many more possible uses for this data in ways, that I cannot imagine.\n\nThis is my first go at publishing a dataset on any medium, so any useful tips and hints would be extremely welcome.\n\nLinks to the raw data sources are here:\n\n - Companies House\nhttp://download.companieshouse.gov.uk/en_output.html\n - Postcode to Geolocation \nhttps://data.gov.uk/dataset/national-statistics-postcode-lookup-uk\n - SIC Codes\nhttps://www.gov.uk/government/publications/standard-industrial-classification-of-economic-activities-sic\n'","b""['business', 'medium', 'featured']""",https://www.kaggle.com/dalreada/all-uk-active-companies-by-sic-and-geolocated
"b'Unemployment Rate by Race, Gender, Age Time Series'",b'Explore Time Series from the BLS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Bureau of Labor Statistics](http://www.bls.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according to the frequency that the data updates. Explore the OECD using Kaggle and all of the data sources available through the BLS [organization page](https://www.kaggle.com/bls)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t""","b""['economics', 'small', 'featured']""","https://www.kaggle.com/bls/unemployment-rate-by-race,-gender,-age-time-series"
b'SF Full Time Employees By Job Classification',b'From San Francisco Open Data',"b""### Content  \n\nShows Full Time Employees by Classification. Used with the Salary Ranges by Classification and Job Titles by Classification  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/QckxruozjRg) by [Annie Spratt](https://unsplash.com/@anniespratt) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-full-time-employees-by-job-classification
b'NYS Income Tax Components',b'From New York State Open Data',"b""### Content  \n\nThe Department of Taxation and Finance annually produces a data (study) file and provides a report of statistical information on New York State personal income tax returns that were timely filed. Timely filing means that the tax return was delivered to the Department on or before the due date of the tax return.  The data are from full-year resident, full-year nonresident, and part-year resident returns. This dataset defines individuals filing a resident tax return as full-year residents and individuals filing a nonresident tax return are defined as either a full- year nonresident or a part-year resident.Data presented in this dataset provide the major income tax structure components by size of income.  The components include income, deductions, dependent exemptions, and tax liability. The data also provides this information by size of income and by the filer\xe2\x80\x99s permanent place of residence (county, state or country).  For a more detailed explanation on the determination of residency and components of income see the attachment: NYSTF_PlaceOfResidence_Introduction.Researchers agree to: Use the data for statistical reporting an analysis only. The author will include a disclaimer that states any analyses, interpretations or conclusions were reached by the author and not the New York State Department of Taxation and Finance.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/E7RLgUjjazc) by [Olu Eletu](https://unsplash.com/@flenjoore) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'income', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-income-tax-components
b'Netflix Prize data',"b""Dataset from Netflix's competition to improve their reccommendation algorithm""","b'### Context\n\nNetflix held the Netflix Prize open competition for the best algorithm to predict user ratings for films. The grand prize was $1,000,000 and was won by BellKor\'s Pragmatic Chaos team. This is the dataset that was used in that competition.\n\n\n### Content\n\n**This comes directly from the README:**\n\n\nTRAINING DATASET FILE DESCRIPTION\n================================================================================\n\nThe file ""training_set.tar"" is a tar of a directory containing 17770 files, one\nper movie.  The first line of each file contains the movie id followed by a\ncolon.  Each subsequent line in the file corresponds to a rating from a customer\nand its date in the following format:\n\nCustomerID,Rating,Date\n\n- MovieIDs range from 1 to 17770 sequentially.\n- CustomerIDs range from 1 to 2649429, with gaps. There are 480189 users.\n- Ratings are on a five star (integral) scale from 1 to 5.\n- Dates have the format YYYY-MM-DD.\n\nMOVIES FILE DESCRIPTION\n================================================================================\n\nMovie information in ""movie_titles.txt"" is in the following format:\n\nMovieID,YearOfRelease,Title\n\n- MovieID do not correspond to actual Netflix movie ids or IMDB movie ids.\n- YearOfRelease can range from 1890 to 2005 and may correspond to the release of\n  corresponding DVD, not necessarily its theaterical release.\n- Title is the Netflix movie title and may not correspond to \n  titles used on other sites.  Titles are in English.\n\n\nQUALIFYING AND PREDICTION DATASET FILE DESCRIPTION\n================================================================================\n\nThe qualifying dataset for the Netflix Prize is contained in the text file\n""qualifying.txt"".  It consists of lines indicating a movie id, followed by a\ncolon, and then customer ids and rating dates, one per line for that movie id.\nThe movie and customer ids are contained in the training set.  Of course the\nratings are withheld. There are no empty lines in the file.\n\nMovieID1:\n\nCustomerID11,Date11\n\nCustomerID12,Date12\n\n...\n\nMovieID2:\n\nCustomerID21,Date21\n\nCustomerID22,Date22\n\nFor the Netflix Prize, your program must predict the all ratings the customers\ngave the movies in the qualifying dataset based on the information in the\ntraining dataset.\n\nThe format of your submitted prediction file follows the movie and customer id,\ndate order of the qualifying dataset.  However, your predicted rating takes the\nplace of the corresponding customer id (and date), one per line.\n\nFor example, if the qualifying dataset looked like:\n\n111:\n\n3245,2005-12-19\n\n5666,2005-12-23\n\n6789,2005-03-14\n\n225:\n\n1234,2005-05-26\n\n3456,2005-11-07\n\nthen a prediction file should look something like:\n\n111:\n\n3.0\n\n3.4\n\n4.0\n\n225:\n\n1.0\n\n2.0\n\n\nwhich predicts that customer 3245 would have rated movie 111 3.0 stars on the\n19th of Decemeber, 2005, that customer 5666 would have rated it slightly higher\nat 3.4 stars on the 23rd of Decemeber, 2005, etc.\n\nYou must make predictions for all customers for all movies in the qualifying\ndataset.\n\nTHE PROBE DATASET FILE DESCRIPTION\n================================================================================\n\nTo allow you to test your system before you submit a prediction set based on the\nqualifying dataset, we have provided a probe dataset in the file ""probe.txt"".\nThis text file contains lines indicating a movie id, followed by a colon, and\nthen customer ids, one per line for that movie id.\n\nMovieID1:\n\nCustomerID11\n\nCustomerID12\n\n...\n\nMovieID2:\n\nCustomerID21\n\nCustomerID22\n\nLike the qualifying dataset, the movie and customer id pairs are contained in\nthe training set.  However, unlike the qualifying dataset, the ratings (and\ndates) for each pair are contained in the training dataset.\n\nIf you wish, you may calculate the RMSE of your predictions against those\nratings and compare your RMSE against the Cinematch RMSE on the same data.  See\nhttp://www.netflixprize.com/faq#probe for that value.\n\n\n### Acknowledgements\n\nThe training data came in 17,000+ files. In the interest of keeping files together and file sizes as low as possible, I combined them into four text files: combined_data_(1,2,3,4).txt \n\n\nThe contest was originally hosted at http://netflixprize.com/index.html\n\nThe dataset was downloaded from [https://archive.org/download/nf_prize_dataset.tar][1]\n\n### Inspiration\n\nThis is a fun dataset to work with. You can read about the winning algorithm by BellKor\'s Pragmatic Chaos [here][2]\n[1]: https://archive.org/download/nf_prize_dataset.tar\n[2]: http://netflixprize.com/community/topic_1537.html'","b""['artificial intelligence', 'film', 'large', 'featured']""",https://www.kaggle.com/netflix-inc/netflix-prize-data
b'Financial Well-Being Survey Data',b'Survey data from the Consumer Financial Protection Bureau',"b'### Context\n\nUnderstanding factors that support consumer financial well-being can help practitioners and policymakers empower more families to lead better financial lives to serve their own goals.\n\nA person\xe2\x80\x99s financial well-being comes from their sense of financial security and freedom of choice\xe2\x80\x94both in the present and when considering the future. We measured it using our 10-item Financial Well-Being Scale.\n\nThe survey dataset includes respondents\xe2\x80\x99 scores on that scale, as well as measures of individual and household characteristics that research suggests may influence adults\xe2\x80\x99 financial well-being.\n\n### Content\n\nVariables relating to question in this dataset include Income and employment, Savings and safety nets, Past financial experiences, and Financial behaviors, skills, and attitudes.\n\nFor reference on specific fields, a codebook is available online [here](https://s3.amazonaws.com/files.consumerfinance.gov/f/documents/cfpb_nfwbs-puf-codebook.pdf).\n\n### Acknowledgements\n\nThis survey was originally conducted by the US Consumer Finance Protection Bureau and published online in October 2017 [here](https://www.consumerfinance.gov/data-research/financial-well-being-survey-data/).\n\n'","b""['finance', 'survey analysis', 'small', 'featured']""",https://www.kaggle.com/anthonyku1031/nfwbs-puf-2016-data
b'NYS Bulk Storage Facilities in New York State',b'From New York State Open Data',"b""### Content  \n\nThe dataset shows status information for:\r\n\xe2\x80\xa2\tChemical Bulk Storage (CBS) Facilities pursuant to the Hazardous Substance Bulk Storage Law, Article 40 of ECL; and 6 NYCRR 596-599.\r\n\xe2\x80\xa2\tMajor Oil Storage Facilities (MOSF) pursuant to Article 12 of the Navigation Law and 6 NYCRR Part 610\r\n\xe2\x80\xa2\tPetroleum Bulk Storage (PBS) Facilities registered pursuant to title 10 of Article 17 and 6 NYCRR Part 613.\r\n\r\nInformation may include: Program Number; Program Type; Site Type Name; Program Facility Name; Address; Locality; County; NYSDEC Region; Tank Number; Tank Location; Tank Status; Install Date; Capacity in Gallons; Tank Type; Close Date; Material Name (of substance in tank); Percent (of material in tank - if hazardous substance - CBS tanks only); Expiration Date; (of license or registration); Site Status Name; UTMX and UTMY location coordinates.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/pOGakQBk8RA) by [\xc3\x81lvaro Ib\xc3\xa1\xc3\xb1ez](https://unsplash.com/@aibanez) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-bulk-storage-facilities-in-new-york-state
b'Spoken Verbs',b'Classify simple audio commands',"b'### Context\n\nI want my computer to react to simple, short, predefined commands. I do not need it to understand any meaning or do complex things, just to recognize and react. I created this dataset to explore possible audio classification algorithms that can ultimately be transferred to the real world.\n\n\n### Content\n\nI have selected single-syllable English verbs, obtained their pronounciations (phonemes) via to the British English Example Pronciation dictionary, and let espeak pronounce it varying the pronounciations, stress, pitch, speed and speaker. \n\nYou can play individual words samples with any audio player that understands ogg (e.g. VLC). The samples still sound a bit mechanic, but it is a start.\n\nFor simplicity, consider the dog sub-sample, which only contains four commands: ""chase"" ""fetch"" ""sit"" ""walk"". They are fairly easy for the ear to distinguish, even in poor quality audio.\n\nTo create the classification data set (db.dog.hdf5), I added AURORA noise with varying volume and convertedd the audio data to 24x24 frequency-vs-time ""images"" (spectrograms). \nThe file comes with class labels (word ID).\n\nExample python script to load and train: https://github.com/JohannesBuchner/spoken-command-recognition/blob/master/traincommanddetect_svm.py\n\nMore details and generating scripts can be found at https://github.com/JohannesBuchner/spoken-command-recognition\n\n### Acknowledgements\n\nPronounciation dictionary: BEEP: http://svr-www.eng.cam.ac.uk/comp.speech/Section1/Lexical/beep.html\nNoise samples: AURORA: https://www.ee.columbia.edu/~dpwe/sounds/noise/\neSPEAK: http://espeak.sourceforge.net/ and mbrola voices http://www.tcts.fpms.ac.be/synthesis/mbrola/mbrcopybin.html\n\n\n### Inspiration\n\nThe open question is if these computer-generated data sets, robustified by pronounciation and noise variations, can be transferred into real applications. \n\nAt the moment I see companies trying to solve a hard problem (map arbitrary, open-ended speech to text and identify meaning), while the easier problem of detecting a predefined word and mapping it to a predefined action should be solvable with currently available tools. Machine learning audio training data is lacking, and this aims to solve that.\n\n'","b""['languages', 'human-computer interaction', 'acoustics', 'communication', 'medium', 'featured']""",https://www.kaggle.com/jbuchner/spokenverbs
b'SF Assessor Historical Secured Property Tax Rolls',b'From San Francisco Open Data',"b""### Content  \n\nThis data set includes the Office of the Assessor-Recorder\xe2\x80\x99s secured property tax roll spanning from July 1, 2007 to June 30, 2017. It includes all legally disclosable information, including location of property, value of property, the unique property identifier, and specific property characteristics. The data is used to accurately and fairly appraise all taxable property in the City and County of San Francisco. The Office of the Assessor-Recorder makes no representation or warranty that the information provided is accurate and/or has no errors or omissions.\n\nThis dataset is updated annually after the roll is closed and certified. This typically happens by August of each year.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/h5QNclJUiA8) by [Gus Ruballo](https://unsplash.com/@gusruballo) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/san-francisco/sf-assessor-historical-secured-property-tax-rolls
b'Things on Reddit',b'The top 100 products in each subreddit from 2015 to 2017',"b""![ThingsOnReddit](https://thingsonreddit.com/static/logo_full.png)\n\n## Methodology\n\nThis is a data dump of the top 100 products (ordered by number of mentions) from every subreddit that has posted an amazon product. The data was extracted from [Google Bigquery's Reddit Comment database](https://bigquery.cloud.google.com/dataset/fh-bigquery:reddit_comments). It only extracts Amazon links, so it is certainly a subset of all products posted to Reddit.\n\nThe data is organized in a file structure that follows:\n\n```\nreddits/<first lowercase letter of subreddit>/<subreddit>.csv\n```\n\nAn example of where to find the top products for /r/Watches would be:\n\n```\nreddits/w/Watches.csv\n```\n\n## Definitions\nBelow are the column definitions found in each `<subreddit>.csv` file.\n\n**name**\nThe name of the product as found on Amazon.\n\n**category**\nThe category of the product as found on Amazon.\n\n**amazon_link**\nThe link to the product on Amazon.\n\n**total_mentions**\nThe total number of times that product was found on Reddit.\n\n**subreddit_mentions**\nThe total number of times that product was found on that subreddit.\n\n\n## Want more?\n\nYou can search and discover products more easily on [ThingsOnReddit](https://thingsonreddit.com/)\n\n## Acknowledgements\n\nThis dataset was published by Ben Rudolph on [GitHub](https://github.com/ThingsOnReddit/top-things), and was republished as-is on Kaggle. ""","b""['internet', 'business', 'product', 'reddit', 'small', 'featured']""",https://www.kaggle.com/residentmario/things-on-reddit
b'NBA Enhanced Box Score and Standings (2012 - 2018)',b'Box Scores and Standings stats with advanced calculations',"b'### Context\n\nDataset is based on box score and standing statistics from the NBA.\n\nCalculations such as number of possessions, floor impact counter, strength of schedule, and simple rating system are performed.  \n\nFinally, extracts are created based on a perspective:\n\n- teamBoxScore.csv communicates game data from each teams perspective\n\n- officialBoxScore.csv communicates game data from each officials perspective\n\n- playerBoxScore.csv communicates game data from each players perspective\n\n- standing.csv communicates standings data for each team every day during the season\n\n### Content\n\n**Data Sources**\n\nBox score and standing statistics were obtained by a Java application using RESTful APIs provided by [xmlstats](https://erikberg.com/api).\n\n**Calculation Sources**\n\nAnother Java application performs advanced calculations on the box score and standing data.  \nFormulas for these calculations were primarily obtained from these sources:\n\n- https://basketball.realgm.com/info/glossary\n- https://www.nbastuffer.com/team-evaluation-metrics/\n- https://www.basketball-reference.com/about/glossary.html\n\n### Inspiration\n\n***Favoritism***\n\nDoes a referee impact the number of fouls made against a player or the pace of a game?\n\n***Forcasting***\n\nCan the aggregated points scored by and against a team along with their strength of schedule be used to determine their projected winning percentage for the season?\n\n***Predicting the Past***\n\nFor a given game, can games played earlier in the season help determine how a team will perform?\n\n***Lots of data elements and possibilities.  Let your imagination roam!***'","b""['sports', 'basketball', 'medium', 'featured']""",https://www.kaggle.com/pablote/nba-enhanced-stats
b'EMPRES Global Animal Disease Surveillance',b'Global animal disease outbreaks from the last 2 years',"b'### Context\n\nData downloaded from the EMPRES Global Animal Disease Information System.\n\n\n### Content\n\nData shows the when, where and what of animal disease outbreaks from the last 2 years, including African swine fever, Foot and mouth disease and bird-flu. Numbers of cases, deaths, etc are also included.\n\n\n### Acknowledgements\n\nThis data is from the Food and Agriculture Organization of the United Nations. The EMPRES-i system can be access [here][1]\nRead more about the details of the system [here][2]\n\n\n\n\n  [1]: http://empres-i.fao.org/eipws3g/\n  [2]: http://empres-i.fao.org/eipws3g/assets/docs/about_us_en.pdf'","b""['medicine', 'animals', 'veterinary medicine', 'small', 'featured']""",https://www.kaggle.com/tentotheminus9/empres-global-animal-disease-surveillance
b'NYS Jobs By Industry:  Beginning 2012',b'From New York State Open Data',"b""### Content  \n\nThis data shows jobs by industry, beginning in 2012, created from a dataset of economic profiles of the 10 Empire State Development (ESD) economic development regions. Refer to the About section for the data dictionary and other information.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/HHaKG9DaQ6w) by [Fancycrave](https://unsplash.com/@fancycrave) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-jobs-by-industry-beginning-2012
b'Chicago Lobbyist Data',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'ethics', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-lobbyist-data
b'NYS Dept of Transportation Bridge Conditions',b'From New York State Open Data',"b""### Content  \n\nNew York State inspectors assess all of the bridges every two years including a bridge\xe2\x80\x99s individual parts. Bridges are analyzed for their capacity to carry vehicular loads. Inspectors are required to evaluate, assign a condition score, and document the condition of up to 47 structural elements, including rating 25 components of each span of a bridge, in addition to general components common to all bridges.   The NYSDOT condition rating scale ranges from 1 to 7, with 7 being in new condition and a rating of 5 or greater considered as good conditionBridges that cannot safely carry heavy vehicles, such as some tractor trailers, are posted with weight limits. Based upon inspection and load capacity analysis, any bridge deemed unsafe gets closed.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/tLYBRPWvbWE) by [Ben Dumond](https://unsplash.com/@bendumond) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-dept-of-transportation-bridge-conditions
b'Daily Fantasy Basketball - DraftKings NBA',b'Data for DraftKings NBA Daily Fantasy Basketball Contests',"b'### Context\n\nIn Daily Fantasy Sports (DFS) contests, contestants construct a virtual lineup of players that score points based on their real-world performances. Unlike in season-long Fantasy Sports contests,in DFS contestants submit a new lineup for each set of games. DFS contests are held for several professional sports leagues, including the National Football League (NFL), National Basketball League (NBA), and National Hockey League (NHL). The leading DFS sites today are DraftKings and Fanduel, which control approximately 90% of the $3B DFS market.\n\nThere are three primary types of DFS games: Head-to-Heads (H2Hs), Double-Ups, and Guaranteed Prize Pools (GPPs). In H2H games, two contestants play for a single cash prize. In Double-Up games, a pool of contestants compete to place in the top 50% of lineups, which are awarded twice the entry fee. In GPPs, a pool of contestants compete for a fixed prize structure that tends to be very top heavy; some contests payout hundreds of thousands of dollars to the top finisher.\n\nOver the last year, I have developed a winning system for daily fantasy football and baseball contests. Building this system from scratch was a fantastic compliment to the things I learned as a student, from machine learning and optimization to optimal learning and game theory. I hope others can join me in researching daily fantasy basketball and perhaps get involved with the burgeoning world of daily fantasy sports.\n\n\n### Content\n\nThis dataset contains 20 days of DraftKings NBA contest data scraped between 2017-11-27 and 2017-12-28. For DraftKings NBA daily fantasy basketball contest rules, see https://www.draftkings.com/help/rules/nba.\n\nFormat:\n\n - One folder per day\n - One folder per contest for a given day\n - Salary file (\xe2\x80\x9cDKSalaries.csv\xe2\x80\x9d), payout structure file (\xe2\x80\x9cpayout_structure.csv\xe2\x80\x9d), and contest results file (\xe2\x80\x9ccontest-standings.csv\xe2\x80\x9d) for a given contest. Column headers in each files are pretty self-explanatory.\n - Some additional files (e.g. \xe2\x80\x9cplayers.csv\xe2\x80\x9d, \xe2\x80\x9ccovariance_mat_unfiltered.csv\xe2\x80\x9d, \xe2\x80\x9chist_fpts_mat.csv\xe2\x80\x9d) for a given contest. These files were for my personal research, feel free to use or ignore.\n - \xe2\x80\x9cprojections\xe2\x80\x9d folder contains projections data for each player from rotogrinders and daily fantasy nerd, labeled by date.\n - \xe2\x80\x9ccontests.csv\xe2\x80\x9d contains information about each contest, e.g. entry fee, slate, and contest size.\n\n\n### Acknowledgements\n\nThank you to my friend from college, Michael Chiang, for contributions to this project.\n\n\n### Inspiration\nA few ideas to get started:\n\n - What kind of position ""stacks"" tend to maximize correlation within a lineup?\n - How can you minimize correlation between lineups, such that you maximize your chances of winning a GPP?\n - What are the tendencies of some of the top DFS pros?\n - Can you improve rotogrinders and daily fantasy nerd player projections?\n - Can you predict which players are undervalued (i.e. high fantasy points / salary ratio)?\n - Can you predict the ownership percentage for each player in a given contest?'","b""['machine learning', 'basketball', 'covariance and correlation', 'optimization', 'decision theory', 'medium', 'featured']""",https://www.kaggle.com/alandu20/daily-fantasy-basketball-draftkings
b'Emoji sentiment',b'Are people that use emoji happier?',"b'### Are people that use emoji happier?\n\npaper --> https://arxiv.org/abs/1710.00888\n\nAt ASONAM2017, PydataDubai vol 1.0 @ AWOK, PyDataBCN2017 @ EASDE we have presented the paper Happiness inside a job?... *Many* people in the various audiences asked why we avoid using emojis to predict and profile employees. The answer is that  we prefer to use  links of likes because they are more authentic than words or emojis. In the same way that google page rank is more effective when it looks at links between pages rather than content inside the pages. ... Still people keep asking about it. But there is one thing emoji are good at estimating: author sentiment and that is just possible thanks to the unique characteristics of the dataset at hand.\n\nPrevious research has traditionally analyzed emoji sentiment from the point of view of the **reader** of the content not the author. Here, we analyze emoji sentiment from the author point of view and present a benchmark that was built from an employee happiness dataset where emoji happen to be annotated with daily happiness of the author of the comment. We also found out that people that use emoji are happier!?, muuch happier... But the question is, what did we miss?\n\n\n### Content\n\nThe main table contains columns named after emoji hex codes, a 1 means the emoji appears one time in the comment (row). This dataset is an expanded version of this one, but has different formats, columns and one different table, that is why we decided to release it as separate dataset. as he scripts are not compatible.\n\n\n### Other stuff\n**The R script written on MAC OS does not work in the kaggle platform (because numbers become factors and other little changes in how the code is interpreted...), the full working script (tested on R studio MAC OS) can be found at https://github.com/orioli/emoji-writer-sentiment**\n\nThank you to Lewis Michel\n\n\n'","b""['internet', 'linguistics', 'medium', 'featured']""",https://www.kaggle.com/harriken/emoji-sentiment
b'FIFA WORLD CUP 2018 Players',b'Confirmed list of FIFA World Cup 2018 players by country',b'# Context\n\nThe 2018 World Cup is an international football tournament.\n\n### Content\n\nConfirmed list of FIFA 2018 World Cup players by country\n\n### Acknowledgements\n\nSource: https://img.fifa.com/image/upload/hzfqyndmnqazczvc5xdb.pdf\n\nBanner Image: https://unsplash.com/photos/ChI4eUGTpeY\n\n# Inspiration\n\nWho will the best team be in the 2018 World Cup?\n',"b""['sports', 'small', 'featured']""",https://www.kaggle.com/djamshed/fifa-world-cup-2018-players
b'NYS Residential Homes Energy Efficiency Projects',b'From New York State Open Data',"b""### Content  \n\nIMPORTANT! PLEASE READ DISCLAIMER BEFORE USING DATA. The Residential Existing Homes Program is a market transformation program that uses Building Performance Institute (BPI) Goldstar contractors to install comprehensive energy-efficient improvements.&nbsp; The program is designed to use building science and a whole-house approach to reduce energy use in the State\xe2\x80\x99s existing one-to-four family and low-rise multifamily residential buildings and capture heating fuel and electricity-related savings.&nbsp; The Program provides income-based incentives, including an assisted subsidy for households with income up to 80% of the State or Median County Income, whichever is higher to install eligible energy efficiency improvements including building shell measures, high efficiency heating and cooling measures, ENERGY STAR appliances and lighting. \n&nbsp;\nD I S C L A I M E R: Estimated Annual kWh Savings, Estimated Annual MMBtu Savings, and First Year Energy Savings $ Estimate represent contractor reported savings derived from energy modeling software calculations and not actual realized energy savings. The accuracy of the Estimated Annual kWh Savings and Estimated Annual MMBtu Savings for projects has been evaluated by an independent third party. The results of the impact analysis indicate that, on average, actual savings amount to 35 percent of the Estimated Annual kWh Savings and 65 percent of the Estimated Annual MMBtu Savings. The analysis did not evaluate every single project, but rather a sample of projects from 2007 and 2008, so the results are applicable to the population on average but not necessarily to any individual project which could have over or under achieved in comparison to the evaluated savings. The results from the impact analysis will be updated when more recent information is available. Many factors influence the degree to which estimated savings are realized, including proper calibration of the savings model and the savings algorithms used in the modeling software. Some reasons individual households may realize savings different from those projected include, but are not limited to, changes in the number or needs of household members, changes in occupancy schedules, changes in energy usage behaviors, changes to appliances and electronics installed in the home, and beginning or ending a home business. Beginning November 2017, the Program requires the use of HPXML-compliant modeling software tools and data quality protocols have been implemented to more accurately project savings. For more information, please refer to the Evaluation Report published on NYSERDA\xe2\x80\x99s website at: &nbsp;http://www.nyserda.ny.gov/-/media/Files/Publications/PPSER/Program-Evaluation/2012ContractorReports/2012-HPwES-Impact-Report-with-Appendices.pdf. \n&nbsp;\nThe New York Residential Existing Homes (One to Four Units) dataset includes the following data points for projects completed during Green Jobs Green-NY, beginning November 15, 2010: Home Performance Project ID, Home Performance Site ID, Project County, Project City, Project Zip, Gas Utility, Electric Utility, Project Completion Date, Customer Type, Low-Rise or Home Performance Indicator, Total Project Cost (USD), Total Incentives (USD), Type of Program Financing, Amount Financed Through Program (USD), Pre-Retrofit Home Heating Fuel Type, Year Home Built, Size of Home, Volume of Home, Number of Units, Measure Type, Estimated Annual kWh Savings, Estimated Annual MMBtu Savings, First Year Energy Savings $ Estimate (USD), Homeowner Received Green Jobs-Green NY Free/Reduced Cost Audit (Y/N)  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/561igiTyvSk) by [Jesse Roberts](https://unsplash.com/@jesseroberts) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-residential-homes-energy-efficiency-projects
b'NYS Rochester-Genesee Regional Transport Authority',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/wf5ZJ2s-B7I) by [Emile Seguin](https://unsplash.com/@emileseguin) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-rochester-genesee-regional-transport-authority
b'NYS Manufactured Home Park Registrations',b'From New York State Open Data',"b""### Content  \n\nThis dataset captures the park name, address, and county in which a maufactured home park is located; the number of site capacity and number of occupied sites; and the name and contact number for the park owner/operator. New York State Homes and Community Renewal\xe2\x80\x99s (HCR) Division of Housing and Community Renewal (DHCR) oversees the registration of these parks in accordance with NYS Real Property Law Section 233 sub-section (v.) which requires owners of manufactured home parks with three or more homes register their park with DHCR.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/vUxSIkqveu8) by [Willian Justen de Vasconcellos](https://unsplash.com/@willianjusten) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-manufactured-home-park-registrations
b'NY Public Recycling Bins',b'From New York City Open Data',"b""### Content  \n\nLocations of public recycling bins throughout NYC  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/YYy8DVLiQlo) by [Dustin Lee](https://unsplash.com/@dustinlee) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-public-recycling-bins
b'DDSM Mammography',b'tfrecords files of scans from the DDSM dataset',"b""### Summary\nThis dataset consists of images from the DDSM [1] and CBIS-DDSM [3] datasets. The images have been pre-processed and converted to 299x299 images by extracting the ROIs. The data is stored as tfrecords files for TensorFlow. \n\nThe dataset contains 55,890 training examples, of which 14% are positive and the remaining 86% negative, divided into 5 tfrecords files.\n\n**Note** - The data has been separated into training and test as per the division in the CBIS-DDSM dataset. The test files have been divided equally into test and validation data. However the split between test and validation data was done incorrectly, resulted in the test numpy files containing only masses and the validation files containing only calcifications. These files should be combined in order to have balanced and complete test data.\n\n### Pre-processing\nThe dataset consists of negative images from the DDSM dataset and positive images from the CBIS-DDSM dataset. The data was pre-processed to convert it into 299x299 images.\n\nThe negative (DDSM) images were tiled into 598x598 tiles, which were then resized to 299x299.\n\nThe positive (CBIS-DDSM) images had their ROIs extracted using the masks with a small amount of padding to provide context. Each ROI was then randomly cropped three times into 598x598 images, with random flips and rotations, and then the images were resized down to 299x299.\n\nThe images are labeled with two labels:\n\n 1. label_normal - 0 for negative and 1 for positive\n 2. label - full multi-class labels, 0 is negative, 1 is benign calcification, 2 is benign mass, 3 is malignant calcification, 4 is malignant mass\n\nThe following Python code will decode the training examples:\n\n       features = tf.parse_single_example(\n            serialized_example,\n            features={\n                'label': tf.FixedLenFeature([], tf.int64),\n                'label_normal': tf.FixedLenFeature([], tf.int64),\n                'image': tf.FixedLenFeature([], tf.string)\n            })\n\n        # extract the data\n        label = features['label_normal']\n        image = tf.decode_raw(features['image'], tf.uint8)\n\n        # reshape and scale the image\n        image = tf.reshape(image, [299, 299, 1])\n\nThe training examples do include images which contain content other than breast tissue, such as black background and occasionally overlay text. \n\n### Inspiration\nPrevious work [5] has already dealt with classifying pre-identified lesions, this dataset was created with the intention of classifying raw scans as positive or negative by detecting abnormalities. The ability to automatically detect lesions could save many lives.\n\n### Acknowledgements\n[1] The Digital Database for Screening Mammography, Michael Heath, Kevin Bowyer, Daniel Kopans, Richard Moore and W. Philip Kegelmeyer, in Proceedings of the Fifth International Workshop on Digital Mammography, M.J. Yaffe, ed., 212-218, Medical Physics Publishing, 2001. ISBN 1-930524-00-5.\n\n[2] Current status of the Digital Database for Screening Mammography, Michael Heath, Kevin Bowyer, Daniel Kopans, W. Philip Kegelmeyer, Richard Moore, Kyong Chang, and S. Munish Kumaran, in Digital Mammography, 457-460, Kluwer Academic Publishers, 1998; Proceedings of the Fourth International Workshop on Digital Mammography.\n\n[3] Rebecca Sawyer Lee, Francisco Gimenez, Assaf Hoogi , Daniel Rubin  (2016). Curated Breast Imaging Subset of DDSM. The Cancer Imaging Archive.\n\n[4] Clark K, Vendt B, Smith K, Freymann J, Kirby J, Koppel P, Moore S, Phillips S, Maffitt D, Pringle M, Tarbox L, Prior F. The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository, Journal of Digital Imaging, Volume 26, Number 6, December, 2013, pp 1045-1057.\n\n[5] D. Levy, A. Jain, Breast Mass Classification from Mammograms using Deep Convolutional Neural Networks, arXiv:1612.00542v1, 2016""","b""['image data', 'healthcare', 'health', 'medicine', 'oncology and cancer', 'large', 'featured']""",https://www.kaggle.com/skooch/ddsm-mammography
b'NY City-owned and Leased Property',b'From New York City Open Data',"b""### Content  \n\nThis list is accurate as of the date contained in the Date Created field.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/qGCFN8pbew0) by [Clem Onojeghuo](https://unsplash.com/@clemono2) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'government', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-city-owned-and-leased-property
b'E-Commerce Retail Sales Series Data Collection',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/UsALNdok2m4) by [Scott Van Daalen](https://unsplash.com/@scottvd) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/e-commerce-retail-sales-series-data-collection
b'Malicious and Benign Websites',b'Classify by application and network features',"b""# In process to edition ..\n\n##Context\nMalicious websites are of great concern due it is a problem to analyze one by one and to index each URL in a black list. Unfortunately, there is a lack of datasets with malicious and benign web characteristics. This dataset is a research production of my bachelor students whose aims to fill this gap. \n\n*This is our first dataset version got from our web security project, we are working to improve its results*\n\n##Content\n\nThe project consisted to evaluate different classification models to predict malicious and benign websites, based on application layer and network characteristics. The data were obtained by using different verified sources of benign and malicious URL's, in a low interactive client honeypot to isolate network traffic. We used additional tools to get other information, such as, server country with Whois.\n\nThis is the first version and we have some initial results from applying machine learning classifiers in a bachelor thesis. Further details on the data process making and the data description can be found in the article below.\n\n##URL Dataset\n\nThis is an important topic and one of the most difficult thing to process, according to other articles and another open resource, we used three black list:\n+ machinelearning.inginf.units.it/data-andtools/hidden-fraudulent-urls-dataset\n+ malwaredomainlist.com\n+ zeuztacker.abuse.ch\n\nFrom them we got around 185181 URLs, we supposed that they were malicious according to their information, we recommend in a next research step to verity them though another security tool, such as, VirusTotal.\n\nWe got the benign URLs (345000) from https://github.com/faizann24/Using-machinelearning-to-detect-malicious-URLs.git, similar to the previous step, a verification process is also recommended through other security systems. \n\n##Framework\n\nFirst we made different scripts in Python in order to systematically analyze and generate the information of each URL (**During the next months we will liberate them to the open source community on GitHub**).\n\nFirst we verified that each URL was available through the libraries in Python (such as request), we started with around 530181 samples, but as a results of this step the samples were filtered and we got 63191 URLs.\n\n![Framework to detect malicious websites][1]\n\n## Feature generator:\n\nDuring the research process we found that one way to study a malicious website was the analysis of features from its application layer and network layer, in order to get them, the idea is to apply the dynamic and static analysis.  \nIn the dynamic analysis some articles used web application honeypots kind high interaction, but these resources have not been updated in the last months, so maybe some important vulnerabilities were not mapped. \n\n##Data Description\n\n+ URL: it is the anonimous identification of the URL analyzed in the study\n+ URL_LENGTH: it is the number of characters in the URL \n+ NUMBER_SPECIAL_CHARACTERS: it is number of special characters identified in the URL, such as, \xe2\x80\x9c/\xe2\x80\x9d, \xe2\x80\x9c%\xe2\x80\x9d, \xe2\x80\x9c#\xe2\x80\x9d, \xe2\x80\x9c&\xe2\x80\x9d, \xe2\x80\x9c. \xe2\x80\x9c, \xe2\x80\x9c=\xe2\x80\x9d\n+ CHARSET: it is a categorical value and its meaning is the character encoding standard (also called character set).\n+ SERVER: it is a categorical value and its meaning is the operative system of the server got from the packet response.\n+ CONTENT_LENGTH: it represents the content size of the HTTP header.\n+ WHOIS_COUNTRY: it is a categorical variable, its values are the countries we got from the server response (specifically, our script used the API of Whois).\n+ WHOIS_STATEPRO: it is a categorical variable, its values are the states we got from the server response (specifically, our script used the API of Whois).\n+ WHOIS_REGDATE: Whois provides the server registration date, so, this variable has date values with format DD/MM/YYY HH:MM\n+ WHOIS_UPDATED_DATE: Through the Whois we got the last update date from the server analyzed\n+ TCP_CONVERSATION_EXCHANGE: This variable is the number of TCP packets exchanged between the server and our honeypot client\n+ DIST_REMOTE_TCP_PORT: it is the number of the ports detected and different to TCP\n+ REMOTE_IPS: this variable has the total number of IPs connected to the honeypot\n+ APP_BYTES: this is the number of bytes transfered\n+ SOURCE_APP_PACKETS: packets sent from the honeypot to the server \n+ REMOTE_APP_PACKETS: packets received from the server\n+ APP_PACKETS: this is the total number of IP packets generated during the communication between the honeypot and the server\n+ DNS_QUERY_TIMES: this is the number of DNS packets generated during the communication between the honeypot and the server\n+ TYPE:  this is a categorical variable, its values represent the type of web page analyzed, specifically, 1 is for malicious websites and 0 is for benign websites\n\n## Conclusions and future works\n\n##Acknowledgements\nIf your papers or other works use our dataset, please cite our paper:\n\n Urcuqui, C., Navarro, A., Osorio, J., & Garc\xc4\xb1a, M. (2017). Machine Learning Classifiers to Detect Malicious Websites. CEUR Workshop Proceedings. Vol 1950, 14-17.\n\nIf you need a review article of website cybersecurity state of the art (in English and Spanish): \n\nUrcuqui, C., Pe\xc3\xb1a, M. G., Quintero, J. L. O., & Cadavid, A. N. (2017). Antidefacement. Sistemas & Telem\xc3\xa1tica, 14(39), 9-27\n\nIf you have any question or feedback, please contact me:\nccurcuqui@icesi.edu.co\n\nThank you for your comments, it is so important to get your feedback for our future work\n\n -  deardle\n\n## GitHub\nhttps://github.com/urcuqui/WhiteHat/tree/master/Research/Web%20security\n\n\n  [1]: https://github.com/urcuqui/WhiteHat/blob/master/Research/Web%20security/frameworks/framework%20to%20detect%20malicious%20websites.jpg""","b""['crime', 'machine learning', 'web sites', 'computer security', 'small', 'featured']""",https://www.kaggle.com/xwolf12/malicious-and-benign-websites
b'Yemen Data',"b'Various datasets, covering the war, financial aspects and cholera cases'","b'### Context\n\nFrom wikipedia ... ""*The Yemeni Civil War is an ongoing conflict that began in 2015 between two factions, each claiming to constitute the Yemeni government, along with their supporters and allies. Houthi forces controlling the capital Sana\'a and allied with forces loyal to the former president Ali Abdullah Saleh have clashed with forces loyal to the government of Abdrabbuh Mansur Hadi, based in Aden. Al-Qaeda in the Arabian Peninsula (AQAP) and the Islamic State of Iraq and the Levant have also carried out attacks, with AQAP controlling swathes of territory in the hinterlands, and along stretches of the coast*""\n\n\n### Content\n\nThis is a collection of Yemen-related datasets from various sources, including...\n\n1. [The Yemen Data Project][1] (**data_2017.csv**) \n\n2. [The World Bank][2] (**API_YEM_DS2_en_csv_v2_10049258.csv**,\n    **Metadata_Indicator_API_YEM_DS2_en_csv_v2_10049258.csv**) \n\n3. [The Humanitarian Data Exchange][3] (**Yemen Cholera Outbreak Epidemiology Data - Data_Country_Level.csv**, **Yemen Cholera Outbreak Epidemiology Data - Data_Governorate_Level.csv**) \n\n4. [Yemen map file][4] (**adm1.json**)\n\n### Acknowledgements\n\nAll of the above sites and organisations\n\n\n\n  [1]: http://yemendataproject.org/\n  [2]: https://data.worldbank.org/country/yemen-rep?view=chart\n  [3]: https://data.humdata.org/dataset/yemen-cholera-outbreak-daily-epidemiology-update\n  [4]: https://data.humdata.org/dataset/yemen-json'","b""['war', 'small', 'featured']""",https://www.kaggle.com/tentotheminus9/yemen-data
b'Kiva.DHS.v5',"b""Matching Kiva's borrowers with DHS clusters""","b""### Context\n\n**A. Overview**\n\nThis dataset has been created for the [Data Science for Good: Kiva Crowdfunding][1] challenge with this [code][2]. Using GPS coordinates, Kiva's households were merged with clusters from the Demographic and Health Surveys (DHS) in five Kiva countries (Colombia, Haiti, Philippines, Kenya and Armenia). These countries have very different levels of development, an important criteria for deriving insightful models. Overall, &gt;90.000 DHS households from 6.778 clusters were merged. \n\n**B. Modelling**\n\nGranular and accurate poverty measures are obtained by using a k-nearest neighboor approach to match KIVA borrowers with DHS clusters.  Various maps and statistics are derived to assess the quality of the matching. Other Kagglers, such as [Bukun][3], [M'hamed Jabri][4] and [Fabian Bruckschen][5] have proved the dataset potential while also assessing its accuracy. Many thanks for these nice collaborations.\n\n**C. Available poverty measures** \n\nThree measures form granular 'Targeting Scores' indicating the level of welfare or financial inclusion for Kiva borrowers:\n\n - Multidimensional Poverty Index (MPI),  \n - Asset Poverty Index (API) \n - Nightlight data (Source: VIIRS/NPP Day/Night Band)\n\n\n### Content\n\nSee Data dictionary. Contact me if any query\n\n### Inspiration\n\nHelping the Kiva's challenge moving forward. The resulting dataset with its Poverty Scores (KIVA.DHSv5.csv) offers huge opportunities for tackling the Kiva's challenge. It serves: \n\na) as a proof of concept to develop the approach to more KIVA countries. A high number of additional countries have recent DHS surveys with large sample size and GPS coordinates. Including these country could result in 72% of KIVA loans being covered.\n\nb) as validation for remote sensing-based methods, which spatial coverage will always be superior to survey-based methods.\n\n\n  [1]: https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding\n  [2]: https://www.kaggle.com/fkosmowski/matching-kiva-s-borrowers-with-dhs-clusters/code\n  [3]: https://www.kaggle.com/ambarish\n  [4]: https://www.kaggle.com/mhajabri/\n  [5]: https://www.kaggle.com/fbruckschen""","b""['geospatial analysis', 'crowdfunding', 'small', 'featured']""",https://www.kaggle.com/fkosmowski/kivadhsv1
b'Los Angeles Performance Measures per Department',b'From Los Angeles Open Data',"b""### Content  \n\nPerformance metrics for each department, dating back to Fiscal Year 2012-2013.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/rj2LIYbuluA) by [Randy Colas](https://unsplash.com/@randycolasbe) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-performance-measures-per-department
"b'London Crime Data, 2008-2016'","b'13M Rows of Crime Counts, by Borough, Category, and Month'","b'### Context: \nCrime in major metropolitan areas, such as London, occurs in distinct patterns. This data covers the number of criminal reports by month, LSOA borough, and major/minor category from Jan 2008-Dec 2016.\n\n### Content: \n13M rows containing counts of criminal reports by month, LSOA borough, and major/minor category.\n\n### Acknowledgements: \nTxt file was pulled from [Google Cloud Platform](https://cloud.google.com/bigquery/public-data/) and converted to csv. Photo by [James Sutton](https://unsplash.com/@jamessutton_photography).\n\n### Inspiration: \nAre there seasonal or time-of-week/day changes in crime occurrences? Any boroughs where particular crimes are increasing or decreasing? Policy makers use this data to plan upcoming budgets and deployment--can you use previous year crime reports to reliably predict later trends? If you normalize by borough population, can you find any areas where crime is more or less likely?'","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/jboysen/london-crime
b'NYS Active Real Estate Salespersons and Brokers',b'From New York State Open Data',"b""### Content  \n\nThis data contains active Real Estate Salesperson and Broker Licenses from New York State Department of State (DOS).  Each line will be either an individual or business licensee which holds business address and license number information.  If the license type is an individual, the business name that the individual works for will be listed.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/r3WAWU5Fi5Q) by [Breno Assis](https://unsplash.com/@brenoassis) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'real estate', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-active-real-estate-salespersons-and-brokers
b'Crime in Vancouver',b'Data of crimes in Vancouver (Canada) from 2003 to 2017',"b'### Content\nThe data comes from the [Vancouver Open Data Catalogue](http://data.vancouver.ca/datacatalogue/crime-data.htm).\nIt was extracted on 2017-07-18 and it contains 530,652 records from 2003-01-01 to 2017-07-13.\nThe original data set contains coordinates in UTM Zone 10 (columns X and Y). I also included Latitude and Longitude, which I converted using this spreadsheet that can be found [here](http://www.uwgb.edu/dutchs/UsefulData/HowUseExcel.HTM).\n\nThere\'s also a Google Trends data that shows how often a search-term is entered relative to the total search-volume. From Google Trends:\n\n\n``` \n""Numbers represent search interest relative to the highest point on the chart for the given region and time. A value of 100 is the peak popularity for the term. A value of 50 means that the term is half as popular. Likewise a score of 0 means the term was less than 1% as popular as the peak.""\n```\n\nOriginal data for search term ""crime"" location British Columbia:\nhttps://trends.google.com/trends/explore?date=2004-01-01%202017-06-30&geo=CA-BC&q=crime\n\n\n\n\n### Acknowledgements\nPhoto By Charles de Jesus [CC BY 3.0 (http://creativecommons.org/licenses/by/3.0)], via Wikimedia Commons'","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/wosaku/crime-in-vancouver
b'CNC Mill Tool Wear',b'Variational CNC machining data',"b'### Context\n\nA series of machining experiments were run on 2"" x 2"" x 1.5"" wax blocks in a CNC milling machine in the System-level Manufacturing and Automation Research Testbed (SMART) at the University of Michigan. Machining data was collected from a CNC machine for variations of tool condition, feed rate, and clamping pressure. Each experiment produced a finished wax part with an ""S"" shape - S for smart manufacturing - carved into the top face, as shown in `test_artifact.jpg` (included in the dataset).\n\n### Content \n\nGeneral data from each of the 18 different experiments are given in `train.csv` and includes the experiment number, material (wax), feed rate, and clamp pressure. Outputs per experiment include tool condition (unworn and worn tools) and whether or not the tool passed visual inspection.\n\nTime series data was collected from the 18 experiments with a sampling rate of `100 ms` and are separately reported in files `experiment_01.csv` to `experiment_18.csv`. Each file has measurements from the 4 motors in the CNC (X, Y, Z axes and spindle). These CNC measurements can be used in two ways:\n\n* (1) Taking every CNC measurement as an independent observation where the operation being performed is given in the Machining_Process column. Active machining operations are labeled as ""Layer 1 Up"", ""Layer 1 Down"", ""Layer 2 Up"", ""Layer 2 Down"", ""Layer 3 Up"", and ""Layer 3 Down"". \n* (2) Taking each one of the 18 experiments (the entire time series) as an observation for time series classification\n\nNote that some variables will not accurately reflect the operation of the CNC machine. This can usually be detected by when `M1_CURRENT_FEEDRATE` reads 50, when X1 `ActualPosition` reads 198, or when `M1_CURRENT_PROGRAM_NUMBER` does not read 0. The source of these errors has not been identified.\n\n### Acknowledgements\n\nThis data was extracted using the Rockwell Cloud Collector Agent Elastic software from a CNC milling machine in the System-level Manufacturing and Automation Research Testbed (SMART) at the University of Michigan.\n\n### Inspiration\n\nThe dataset can be used in classification studies such as:\n\n* (1) Tool wear detection --- Supervised binary classification could be performed for identification of worn and unworn cutting tools. Eight experiments were run with an unworn tool while ten were run with a worn tool (see tool_condition column for indication).\n\n* (2) Detection of inadequate clamping --- The data could be used to detect when a workpiece is not being held in the vise with sufficient pressure to pass visual inspection (see passed_visual_inspection column for indication of visual flaws). Experiments were run with pressures of 2.5, 3.0, and 4.0 bar. The data could also be used for detecting when conditions are critical enough to prevent the machining operation from completing (see machining_completed column for indication of when machining was preemptively stopped due to safety concerns).'","b""['classification', 'business', 'research', 'manufacturing', 'operating systems', 'medium', 'featured']""",https://www.kaggle.com/shasun/tool-wear-detection-in-cnc-mill
b'LeapMotion Hand Gesture Dataset for UAV Management',b'Acquired by Leap Motion',"b'### Context\n\nHand  gesture recognition dataset is presented, composed by a set of near infrared images and skeletal information acquired by the Leap Motion sensor.\n\n\n### Content\n\nThe dataset is composed by 11 different hand-gestures  that are performed by 13 different subjects (3 women and 10 men).\n\nThe dataset is structured as follows:\n \n\n - /00  (subject with identifier 00)\n  - /sequence (hand gesture sequences for subject 00) \n     - /cam_b (hand gesture sequences for cam_b gesture) \n         - /train (training hand gesture sequences for cam_b gesture) \n             - /seq_0 (first sequence images for cam_b gesture) \n             - /seq_0/frame_00_01_01_0001.png,...,frame_00_01_01_0010.png,...  (images that corresponds to one repetition of the cam_b hand gesture performed by the subject with identifier 00)\n             - /seq_1\n             - ...\n             - /seq_n\n         - /test (testinghand gesture sequences for cam_b gesture) \n             - /seq_0\n             - /seq_1\n             - ...\n             - /seq_n\n     - /cam_f\n     - ...\n     - /zoom_out\n  - /images  (hand gesture pose images for subject 00) \n     - /down (hand images for down pose for subject 00) \n         - /train (training hand images for down pose for subject 00) \n         - /train/frame_00_01_0001.png,...,frame_00_01_01_0910.png,...  (images that corresponds to the down hand pose performed by the subject with identifier 00)\n         - /test (testing hand images for down pose for subject 00) \n     - /ele\n     - ...\n     - /up\n - /01\n - /02 \n - ...\n - /12  (last subject with identifier 12)'","b""['image data', 'computer science', 'object recognition', 'human-computer interaction', 'large', 'featured']""",https://www.kaggle.com/gti-upm/leaphandgestuav
b'Russian Troll Tweets',"b'200,000 malicious-account tweets captured by NBC'","b'### Context\n\nAs part of the House Intelligence Committee investigation into how Russia may have influenced the 2016 US Election, Twitter released the screen names of almost 3000 Twitter accounts believed to be connected to Russia\xe2\x80\x99s Internet Research Agency, a company known for operating social media troll accounts. Twitter immediately suspended these accounts, deleting their data from Twitter.com and the Twitter API. A team at NBC News including Ben Popken and EJ Fox was able to reconstruct a dataset consisting of a subset of the deleted data for their investigation and were able to show how these troll accounts went on attack during key election moments. This dataset is the body of this open-sourced reconstruction.\n\nFor more background, read the NBC news article publicizing the release: [""Twitter deleted 200,000 Russian troll tweets. Read them here.""](https://www.nbcnews.com/tech/social-media/now-available-more-200-000-deleted-russian-troll-tweets-n844731)\n\n### Content\n\nThis dataset contains two CSV files. `tweets.csv` includes details on individual tweets, while `users.csv` includes details on individual accounts.\n\nTo recreate a link to an individual tweet found in the dataset, replace `user_key` in `https://twitter.com/user_key/status/tweet_id` with the screen-name from the `user_key` field and `tweet_id` with the number in the `tweet_id` field.\n\nFollowing the links will lead to a suspended page on Twitter. But some copies of the tweets as they originally appeared, including images, can be found by entering the links on web caches like `archive.org` and `archive.is`.\n\n### Acknowledgements\n\nIf you publish using the data, please credit NBC News and include a link to this page. Send questions to `ben.popken@nbcuni.com`.\n\n### Inspiration\n\nWhat are the characteristics of the fake tweets? Are they distinguishable from real ones? '","b""['internet', 'politics', 'twitter', 'international relations', 'russia', 'medium', 'featured']""",https://www.kaggle.com/vikasg/russian-troll-tweets
b'SF Curb Ramps',b'From San Francisco Open Data',"b""### Content  \n\nCurb ramp locations and attribute data. These data come from the Curb Ramp Information System (CRIS). Please be advised \xe2\x80\x93 CRIS is a planning tool only. There is no guarantee of attribute accuracy. Also, while the data syncs nightly the underlying system only updates about once a quarter.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/QM5OgKnUwCk) by [Chris Barbalis](https://unsplash.com/@cbarbalis) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-curb-ramps
b'Exoplanets Database',b'Dataset with 3741 extrasolar planets',"b""### Context\n\nExtrasolar planets, or exoplanets for short, are all the fuss in astronomy these days. Each week the news outlets reports increasingly exciting new discoveries. This is now your chance to take a dive in this wonderful data.\n\n\n### Content\n\nThis comprehensive dataset is maintened by [the Extrasolar Planets Encyclopaedia][1], and comprises loads of data for confirmed exoplanets from several different sources, including Kepler (detections by transit), CoRoT (detections by radial velocity) and OGLE (microlensing). A plethora of data is available both for the planets and the host stars.\n\nThe data is well structured in a CSV file, but since it comes from several different sources, some parameters aren't well formated, and require some cleaning and filtering, an additional challenge!\n\n### Acknowledgements\n\nhttp://exoplanet.eu/\n\n### Inspiration\n\nThere's so much data that the sky is the limit (pun intended). What kinds of relationships can you find? For example:\n\n- How does the mass of the planets correlates with their radius? What does this tells us about the planets' compositions? (Hint: There are only two kinds of planets: Gas planets and rocky planets, with low and high densities, respectively)\n\n- How does the size of the planet correlates with the orbital period? And what correlations are there with the spectral type of the host stars?\n\n- Which are the best detection methods? What are their limitations? Why does there are no planets with large orbital periods detected by transit and low mass planets detected by radial velocity?\n\n \n\n  [1]: http://exoplanet.eu/""","b""['small', 'featured']""",https://www.kaggle.com/eduardowoj/exoplanets-database
b'Bundesliga Results 1993-2018',b'Including half time and full time scores',"b'This dataset contains results from every Bundesliga match from 1993-1994 to 2017-2018. \nIt also includes half time results, but only from 1995-96 to 2017-18. Columns include Division (denoted as D1), HomeTeam, AwayTeam, FTHG (final time home goals), FTAG (final time away goals), FTR (full time result), HTHG (half time home goals), HTAG (half time away goals), HTR (half time result), and season.\n\nThis was inspired by the lack of smaller, league specific datasets, in the face of large, all Europe match result sets. \n\nData compiled into one file from [this site][1], a football betting site from the UK. It contains individual datasets for each season, but I combined them into one single set for ease of use. \n\n\n  [1]: http://www.football-data.co.uk/germanym.php'","b""['association football', 'small', 'featured']""",https://www.kaggle.com/thefc17/bundesliga-results-19932018
b'Seattle Electrical Permits',b'From City of Seattle Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-electrical-permits
b'Producer Price Index',b'Statistical measures of change in prices of producer goods',"b'### Context\n\nThe US Bureau of Labor Statistics monitors and collects day-to-day information about the market price of raw inputs and finished goods, and publishes regularized statistical assays of this data. The *Consumer Price Index* and the *Producer Price Index* are its two most famous products. The former tracks the aggregate dollar price of consumer goods in the United States (things like onions, shovels, and smartphones); the latter (this dataset) tracks the cost of raw inputs to the industries *producing* those goods (things like raw steel, bulk leather, and processed chemicals).\n\nThe US federal government uses this dataset to track inflation. While in the short term the raw dollar value of producer inputs may be volatile, in the long term it will always go up due to inflation --- the slowly decreasing buying power of the US dollar.\n\n### Content\n\nThis dataset consists of a packet of files, each one tracking regularized cost of inputs for certain industries. The data is tracked-month to month with an index out of 100.\n\n### Acknowledgements\n\nThis data is published [online](https://www.bls.gov/ppi/data.htm) by the US Bureau of Labor Statistics.\n\n### Inspiration\n\n* How does the Producer Price Index compare against the [Consumer Price Index](https://www.kaggle.com/bls/consumer-price-index)?\n* What have the largest spikes in input costs been, historically? Can you determine why they occurred?\n* What is the overall price index trend amongst US producers?'","b""['economics', 'medium', 'featured']""",https://www.kaggle.com/bls/producer-price-index
b'Who eats the food we grow?',"b'Worldwide food\\feed production and distribution, 1961-2013 '","b""### Context\n\nOur world population is expected to grow from [7.3 billion today to 9.7 billion in the year 2050][1]. Finding solutions for feeding the growing world population has become a hot topic for [food and agriculture organizations][2], [entrepreneurs][3] and [philanthropists][4]. These solutions range from changing the way we [grow our food][5] to changing the [way we eat][6]. To make things harder, the world's climate is changing and it is both affecting and affected by the way we grow our food \xe2\x80\x93 agriculture. \n**This dataset provides an insight on our worldwide food production** - focusing on a comparison between food produced for human consumption and feed produced for animals.\n\n\n\n### Content\n\nThe Food and Agriculture Organization of the United Nations provides [free access to food and agriculture data][7] for over 245 countries and territories, from the year 1961 to the most recent update (depends on the dataset). One dataset from the FAO's database is the Food Balance Sheets. It presents a comprehensive picture of the pattern of a country's food supply during a specified reference period, the last time an update was loaded to the FAO database was in 2013. The food balance sheet shows for each food item the sources of supply and its utilization. This chunk of the dataset is focused on two utilizations of each food item available:\n\n - **Food** - refers to the total amount of the food item available as human food during the reference period.\n - **Feed** - refers to the quantity of the food item available for feeding to the livestock and poultry during the reference period.\n\n### Acknowledgements\n\nThis dataset was meticulously gathered, organized and published by the Food and Agriculture Organization of the United Nations. \n\n### Inspiration\n\nAnimal agriculture and factory farming is a a growing interest of the public and of world leaders.\n\n - Can you find interesting outliers in the data?\n - What are the fastest growing countries in terms of food production\\consumption?\n - Compare between food and feed consumption.\n\n  [1]: http://www.un.org/en/development/desa/news/population/2015-report.html\n  [2]: http://www.fao.org/fileadmin/templates/wsfs/docs/expert_paper/How_to_Feed_the_World_in_2050.pdf\n  [3]: https://www.entrepreneur.com/article/251515\n  [4]: https://canwefeedtheworld.wordpress.com/tag/bill-gates/\n  [5]: https://www.forbes.com/sites/christinatroitino/2017/08/24/memphis-meats-lab-grown-meat-raises-17m-with-help-from-bill-gates-and-richard-branson/#2f8186d43fd0\n  [6]: https://www.peta.org/issues/animals-used-for-food/global-warming/\n  [7]: http://www.fao.org/faostat/en/#home""","b""['animals', 'agriculture', 'small', 'featured']""",https://www.kaggle.com/dorbicycle/world-foodfeed-production
b'Environmental Sound Classification 50',b'raw audio classification of environmental sounds',"b""### Context\n\nAudio classification is often proposed as MFCC classification problem. With this dataset, we intend to give attention to raw audio classification, as performed in the [Wavenet network][1].\n\n### Content\n\nThe dataset consists in 50 `WAV` files sampled at 16KHz for 50 different classes. \n\nTo each one of the classes, corresponds 40 audio sample of 5 seconds each. All of these audio files have been concatenated by class in order to have 50 wave files of 3 min. 20sec.\n\nIn [our example notebook][2], we show how to access the data and visualize a piece of it.\n\n### Acknowledgements\n\nWe have not much credit in proposing the dataset here. Much of the work have been done by the authors of the [ESC-50][3] Dataset for Environmental Sound Classification. In order to fit on Kaggle, we processed the files with the `to_wav.py` file present in the original repository. You might also notice that we transformed the data from `OGG` to `WAV` as the former didn't seem to be supported in Anaconda.\n\n\n### Inspiration\n\nYou might use this dataset to challenge your algorithms in classifying from raw audio ;)\n\n\n  [1]: https://deepmind.com/blog/wavenet-generative-model-raw-audio/\n  [2]: https://www.kaggle.com/mmoreaux/esc50-visualization/\n  [3]: https://github.com/karoldvl/ESC-50""","b""['categorical data', 'acoustics', 'large', 'featured']""",https://www.kaggle.com/mmoreaux/environmental-sound-classification-50
b'Ships in Satellite Imagery',b'Classify ships in San Franciso Bay using Planet satellite imagery',"b'# Context\nSatellite imagery provides unique insights into various markets, including agriculture, defense and intelligence, energy, and finance. New commercial imagery providers, such as [Planet](https://www.planet.com/), are using constellations of small satellites to capture images of the entire Earth every day. \n\nThis flood of new imagery is outgrowing the ability for organizations to manually look at each image that gets captured, and there is a need for machine learning and computer vision algorithms to help automate the analysis process. \n\nThe aim of this dataset is to help address the difficult task of detecting the location of large ships in satellite images. Automating this process can be applied to many issues including monitoring port activity levels and supply chain analysis.\n \n# Content\nThe dataset consists of image chips extracted from Planet satellite imagery collected over the San Francisco Bay and San Pedro Bay areas of California. It includes 4000 80x80 RGB images labeled with either a ""ship"" or ""no-ship"" classification. Image chips were derived from PlanetScope full-frame visual scene products, which are orthorectified to a 3 meter pixel size. \n\nProvided is a zipped directory `shipsnet.zip` that contains the entire dataset as .png image chips. Each individual image filename follows a specific format: {label} __ {scene id} __ {longitude} _ {latitude}.png\n\n- **label:** Valued 1 or 0, representing the ""ship"" class and ""no-ship"" class, respectively. \n- **scene id:** The unique identifier of the PlanetScope visual scene the image chip was extracted from. The scene id can be used with the [Planet API](https://www.planet.com/docs/reference/data-api/) to discover and download the entire scene.\n- **longitude_latitude:** The longitude and latitude coordinates of the image center point, with values separated by a single underscore. \n\nThe dataset is also distributed as a JSON formatted text file `shipsnet.json`. The loaded object contains **data**, **label**, **scene_ids**, and **location** lists. \n\nThe pixel value data for each 80x80 RGB image is stored as a list of 19200 integers within the **data** list. The first 6400 entries contain the red channel values, the next 6400 the green, and the final 6400 the blue. The image is stored in row-major order, so that the first 80 entries of the array are the red channel values of the first row of the image.\n\nThe list values at index *i* in **labels**, **scene_ids**, and **locations** each correspond to the *i*-th image in the **data** list.\n## Class Labels   \nThe ""ship"" class includes 1000 images. Images in this class are near-centered on the body of a single ship. Ships of different sizes, orientations, and atmospheric collection conditions are included. Example images from this class are shown below. \n\n![ship](https://i.imgur.com/tLsSoTz.png)\n\nThe ""no-ship"" class includes 3000 images. A third of these are a random sampling of different landcover features - water, vegetion, bare earth, buildings, etc. - that do not include any portion of an ship. The next third are ""partial ships"" that contain only a portion of an ship, but not enough to meet the full definition of the ""ship"" class. The last third are images that have previously been mislabeled by machine learning models, typically caused by bright pixels or strong linear features. Example images from this class are shown below.\n\n![no-plane](https://imgur.com/Q3daQMC.png)\n# Acknowledgements\nSatellite imagery used to build this dataset is made available through Planet\'s [Open California](https://www.planet.com/products/open-california/) dataset, which is [openly licensed](https://creativecommons.org/licenses/by-sa/4.0/). As such, this dataset is also available under the same CC-BY-SA license. Users can sign up for a free Planet account to search, view, and download thier imagery and gain access to their API. \n'","b""['business', 'medium', 'featured']""",https://www.kaggle.com/rhammell/ships-in-satellite-imagery
b'Chicago Public Right-of-Way Use Permits',b'From City of Chicago Open Data',"b""### Content  \n\nAs described in http://bit.ly/cdotpermitspost, the function of this dataset was replaced by https://data.cityofchicago.org/d/pubx-yq2d on 12/7/2015.  This dataset is historical-only.\r\n\r\nThe Chicago Department of Transportation (CDOT) reviews applications for permits for the temporary use of the public way for construction projects, parades, festivals, block parties, athletic events, etc.This dataset includes permits applied for, issued, amended and expired with permit start dates beginning January 1, 2011. Note a permit may be amended if any details are changed after the initial issuance. For more information about Public Right-of-Way Use Permits, go to http://bit.ly/15ypkkL.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/OQMZwNd3ThU) by [Helloquence](https://unsplash.com/@helloquence) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/chicago/chicago-public-right-of-way-use-permits
b'MyAnimeList Dataset',"b'contains 300k users, 14k anime metadata, and 80mil. ratings from MyAnimeList.net'","b""### Context\n\nThis dataset contains informations about [Anime][1] and [Otaku][2] who watch it. There already is similar dataset https://www.kaggle.com/CooperUnion/anime-recommendations-database but it is few orders of magnitude smaller and is missing many information. This dataset aims to be representative sample of internet otaku community for demographics analysis and trends inside this group. It contains information about users (gender, location, birth date etc.), about anime (airing date, genres, producer...) and anime lists. \nUsers in MyAnimeList can add anime to their lists, and mark it as plan to watch, completed, watching, dropped..., and they can also rate it by score 1-10. \n\nNote: All information gathered here are publicly available, there was no need to be registered anywhere to access the data.\n\nI did analysis of this dataset, showing various interesting trends in otaku culture, it is accessible in this repo with jupyter notebooks: https://github.com/racinmat/mal-analysis all interesting figures and data are in user_analysis.ipynb and basic_analysis.ipynb.\nAnd powerpoint presentation with all interesting figures is here https://github.com/racinmat/mal-analysis/blob/master/prezantace.pptx\n\n### Content\n\nThe dataset contains 3 files: \n\n - AnimeList.csv contains list of anime, with title, title synonyms, genre, studio, licencor, producer, duration, rating, score, airing date, episodes, source (manga, light novel etc.) and many other important data about individual anime providing sufficient information about trends in time about important aspects of anime. Rank is in float format in csv, but it contains only integer value. This is due to NaN values and their representation in pandas.\n\n - UserList.csv contains information about users who watch anime, namely username, registration date (join_date), last online date, birth date, gender, location, and lots of aggregated values from their anime lists. \n\n - UserAnimeList.csv contains anime lists of all users. Per each record, here is username, anime ID, score, status and timestamp when was this record last updated.\n\nThe dataset as a whole contains \n\n - 302 675 unique users\n - 302 573 of them with some demographic data\n - 80 076 112 records in anime lists\n - 46 358 322 of them have ratings \n - 14 478 unique anime\n\nThere is filtered version of dataset is contained in files anime_filtered.csv, animelists_filtered.csv and users_filtered.csv. It consists of users who have birth date, location and gender filled. So it contains lot less animelists data. \nBut all important characteristics like rating mean and variation, or genres in animelists is unchanged when ommiting users with some missing data, so even with filtered data we should get same information.\nThe filtered dataset contains:\n\n - 116 133 unique users with demographic data\n - 35 802 010 records in anime lists\n - 20 726 794 of them have ratings \n - 14 474 unique anime\n\nThere is also cleaned version of the filtered dataset which consists of files anime_cleaned.csv, animelists_cleaned.csv and users_cleaned.csv. This cleaned version has trucated all users with ridiculously large number of episodes in anime which obviously don't have that much episodes, watched episodes larger than number of episodes in individual anime were fixed and seen episodes and watch time were recalculated accordingly. For some users, last online was 1900 year, just weird values, so their last activity was inferred from their last animelist update timestamp. \nMany users incorrectly filled number of rewatched episodes. For anime where more episodes have been watched than that anime has episodes, watched episodes have been rewritten to number of episodes in that anime. Watch time and number of watched episodes have been fixed accordingly.\nUsers too young and too old obviously were truncated too.\n6 users with most episodes seen, suspiciously lots of episodes, were truncated here too. That is too few users to affect any statistics.\nAnime with unknown studio or unknown source were discarded too. Also anime which were not yet aired were discarded. Their ratings were removed too. Removing them did not affect much other statistics, and without studio or source they did not give much information. Mostly unknown and insignificant anime were removed that way. Airing year was calculated for all remaining anime.\n\nmy_status in animelists tables contains integer values. This is their semantics:\n\n- 1: watching\n- 2: completed\n- 3: on hold\n- 4: dropped\n- 6: plan to watch\n\nother values are not known.\n\nData gathering methodology: MAL uses username as main identifier for users. Thus they can not be simply iterated over and usernames must be gathered. I gathered usernames from watching challenge 2015-2018 forum threads, and then from MAL clubs. There is ~80k clubs. I crawled first ~40k of these clubs and got usernames from there.\n\n### Acknowledgements\n\nThis dataset has been crawled from [MyAnimeList.net][3] with https://github.com/racinmat/myanimelist-crawler. This repo is based on https://github.com/Dibakarroy1997/myanimelist-data-set-creator but is fully prepared for long-term data scraping.\nIt uses https://github.com/TimboKZ/kuristina web-server and https://github.com/pushrbx/python3-mal library for scraping itself. \nThumbnail image is from https://www.pinterest.com/pin/717198309380413746/\nMany previous analyses have been made, each of them exploiting different aspects of otaku community. Here are some of them. Lots of them used much smaller dataset, using this data should lead to more precise outputs.\n\n - [Gender split in anime][4]\n - [Anime genres relations][5]\n - [Temporal analysis of moe genre][6]\n - [temporal analysis of some anime][7]\n\n### Inspiration\n\nThis dataset may be used either for recommandation system, or for analysis on otaku culture, to see time trends of individual genres, to see tendencies and customs of user ratings, to find simmilarities or differencies between individual user groups...\nI already performed one analysis, which is available here: https://github.com/racinmat/mal-analysis\n\n  [1]: https://en.wikipedia.org/wiki/Anime\n  [2]: https://en.wikipedia.org/wiki/Otaku\n  [3]: https://myanimelist.net/\n  [4]: https://www.tumblr.com/privacy/consent?redirect=https%3A%2F%2Fbunnyadvocate.tumblr.com%2Fpost%2F164636686962%2Fgender-differences-in-anime-ratings\n  [5]: https://bunnyadvocate.tumblr.com/post/171165531592/mapping-the-anime-fandom?is_related_post=1\n  [6]: https://aquabluesweater.wordpress.com/2010/12/31/genre-over-time-moe/\n  [7]: https://www.datasciencecentral.com/profiles/blogs/anime-reviews-and-scores""","b""['popular culture', 'film', 'large', 'featured']""",https://www.kaggle.com/azathoth42/myanimelist
b'NYS Adult Arrests by County:  Beginning 1970',b'From New York State Open Data',"b""### Content  \n\nThe counts of arrests are derived from information transmitted from law enforcement agencies to the Division of Criminal Justice Services Computerized Criminal History database for fingerprintable offenses.An adult arrest is defined as an arrest of a person 16 years old or older or a juvenile offender prosecuted in adult court.  Fingerprintable offenses (defined in Criminal Procedure Law \xc2\xa7160.10) include any felony, a misdemeanor defined in the penal law, a misdemeanor defined outside the penal law which would constitute a felony if such a person had a previous judgment of conviction for a crime, or loitering for the purpose of engaging in prostitution as defined in subdivision two of Penal Law \xc2\xa7240.37.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/5HzOtV-FSlw) by [niu niu](https://unsplash.com/@anneniuniu) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-adult-arrests-by-county-beginning-1970
b'Minecraft skins',b'7900 Minecraft player skins',b'### Context\n\nThis dataset contains 7.9k Minecraft skins in 64x64 or 64x32 resolutions. Its looks like this texture.\n![enter image description here][1]\n\n\n### Tasks\n\nYou can use these images in your research. For example: GAN for generating new Minecraft skins or Skin2Vec model.\n\n*Turn on your imagination.*\n<br>\n![enter image description here][2]\n\n\n  [1]: https://img1.minebook.me/gallery/med/80822_skin_201209250620581945971.png\n  [2]: https://vignette.wikia.nocookie.net/spongebob/images/9/9d/Spongebob_Imagination_by_kssael.png/revision/latest/scale-to-width-down/580?cb=20120225122618',"b""['image data', 'image processing', 'video games', 'medium', 'featured']""",https://www.kaggle.com/alxmamaev/minecraft-skins
b'Lord of the Rings Data',b'Character Descriptions and Dialogue',"b'\n### Context\n\nThe Lord of the Rings is a film series consisting of three high fantasy adventure films directed by Peter Jackson. They are based on the novel The Lord of the Rings by J. R. R. Tolkien. The films are subtitled The Fellowship of the Ring (2001), The Two Towers (2002) and The Return of the King (2003).  \n\nSource: https://en.wikipedia.org/wiki/The_Lord_of_the_Rings_(film_series)\n\n### Content\n\nlotr_scripts.csv -- Scripts from the LOTR movies\n\nlotr_characters.csv -- Descriptions of Characters from the LOTR movies\n\n### Acknowledgements\n\nI found the original dataset at https://github.com/tianyigu/Lord_of_the_ring_project.\n\nThe data was was scraped from http://lotr.wikia.com and http://www.ageofthering.com with the following scrapers: \nhttps://github.com/tianyigu/Lord_of_the_ring_project/blob/master/LOTR_code/lotr_script_scripy/lotr/lotr/spiders/lotr_spider.py\nhttps://github.com/tianyigu/Lord_of_the_ring_project/blob/master/LOTR_code/lotr_demograph_scripy/lotr/spiders/lotr_spider.py\n\nFor more info, see the following blog post: https://nycdatascience.com/blog/student-works/journey-to-middle-earth-webscraping-the-lord-of-the-ring/\n\nBanner Photo by [Sagittarius Voyage on Unsplash][1]\n\n\n\n  [1]: https://unsplash.com/photos/TWuxRn1iQII'","b""['text data', 'small', 'featured']""",https://www.kaggle.com/paultimothymooney/lord-of-the-rings-data
b'FiveThirtyEight Marriage Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Marriage\n\nThis folder contains data behind the story [Marriage Isn\xe2\x80\x99t Dead \xe2\x80\x94 Yet](http://fivethirtyeight.com/features/marriage-isnt-dead-yet/).\n\nSource for all data is Decennial Census (years 1960 to 2000) and American Community Survey (years 2001-2012), via [IPUMS USA](https://usa.ipums.org/usa/cite.shtml).\n\nExcept in the divorce file, figures represent share of the relevant population that has never been married (MARST == 6 in the IPUMS data). Note that in the story, charts generally show the share that have *ever* been married, which is simply 1 - n. In the divorce file, figures are share of the relevant population that is *currently* divorced, conditional on having ever been married.\n\nVariable names are as follows. Number in variable names are age ranges, so `all_2534` is the marriage rate for everyone ages 25 to 34.\n\nHeader | Description\n---|---------\n`all` | Total (or all men/women in sex-specific files)\n`HS` | High school graduate or less (EDUCD < 65)\n`SC` | Some college (EDUCD >= 65 & <= 100)\n`BAp` | Bachelor's degree or more (EDUCD > 100)\n`BAo` | Bachelor's degree, no graduate degre (EDUCD > 100 & <= 113)\n`GD` | Graduate degree (EDUCD > 113)\n`White` | Non-Hispanic white\n`Black` | Black or African-American\n`Hisp` | Hispanic of any race\n`NE` | New England (REGION == 11)\n`MA` | Mid-Atlantic (REGION == 12)\n`Midwest` | Midwest (REGION == 21-23)\n`South` | South (REGION == 31-34)\n`Mountain` | Mountain West (REGION == 41)\n`Pacific` | Pacific (REGION == 42)\n`poor` | Family income in lowest 25%\n`mid` | Family income in middle 50%\n`rich` | Family income in top 25%\n`work` | Employed 50+ weeks prior year\n`nowork` | Not employed at least 50 weeks prior year\n`nokids_all` | No own children living at home\n`kids_all` | At least one own child living at home\n  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-marriage-dataset
b'India Air Quality Data',"b""India's air pollution levels over the years""","b""### Context\nSince industrialization, there has been an increasing concern about environmental pollution. As mentioned in the WHO report [7 million premature deaths annually linked to air pollution](http://www.who.int/mediacentre/news/releases/2014/air-pollution/en/) , air pollution is the world's largest single environmental risk. Moreover as reported in the NY Times article, [India\xe2\x80\x99s Air Pollution Rivals China\xe2\x80\x99s as World\xe2\x80\x99s Deadliest](https://www.nytimes.com/2017/02/14/world/asia/indias-air-pollution-rivals-china-as-worlds-deadliest.html?_r=0) it has been found that India's air pollution is deadlier than even China's.\n\nUsing this dataset, one can explore India's air pollution levels at a more granular scale.\n\n### Content\nThis data is combined(across the years and states) and largely clean version of the [Historical Daily Ambient Air Quality Data](https://data.gov.in/catalog/historical-daily-ambient-air-quality-data) released by the Ministry of Environment and Forests and Central Pollution Control Board of India under the National Data Sharing and Accessibility Policy (NDSAP).\n\n[Visualization of the Mean RSPM values over the years](https://shrutibhargava94.github.io/india_air_quality_map/)\n\n### Inspiration\nCan we detect local trends? Can we relate the air quality changes to changes in Environmental policy in India?\n\n###Acknowledgements\n[Vishal Subbiah](https://www.kaggle.com/vishalsubbiah) (Data downloading)""","b""['india', 'pollution', 'medium', 'featured']""",https://www.kaggle.com/shrutibhargava94/india-air-quality-data
b'Fashion MNIST',"b'An MNIST-like dataset of 70,000 28x28 labeled fashion images'","b'### Context\n\nFashion-MNIST is a dataset of Zalando\'s article images\xe2\x80\x94consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n\nThe original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. ""If it doesn\'t work on MNIST, it won\'t work at all"", they said. ""Well, if it does work on MNIST, it may still fail on others.""\n\nZalando seeks to replace the original MNIST dataset\n\n### Content\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n\n- To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix. \n- For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.\n<br><br>\n\n\n**Labels**\n\nEach training and test example is assigned to one of the following labels:\n\n- 0\tT-shirt/top\n- 1\tTrouser\n- 2\tPullover\n- 3\tDress\n- 4\tCoat\n- 5\tSandal\n- 6\tShirt\n- 7\tSneaker\n- 8\tBag\n- 9\tAnkle boot\n<br><br>\n\nTL;DR\n\n- Each row is a separate image  \n- Column 1 is the class label. \n- Remaining columns are pixel numbers (784 total). \n- Each value is the darkness of the pixel (1 to 255)\n\n### Acknowledgements\n\n- Original dataset was downloaded from [https://github.com/zalandoresearch/fashion-mnist][1]\n\n- Dataset was converted to CSV with this script: [https://pjreddie.com/projects/mnist-in-csv/][2]\n\n### License\n\nThe MIT License (MIT) Copyright \xc2\xa9 [2017] Zalando SE, https://tech.zalando.com\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \xe2\x80\x9cSoftware\xe2\x80\x9d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \xe2\x80\x9cAS IS\xe2\x80\x9d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n  [1]: https://github.com/zalandoresearch/fashion-mnist\n  [2]: https://pjreddie.com/projects/mnist-in-csv/'","b""['image data', 'multiclass classification', 'object identification', 'clothing', 'medium', 'featured']""",https://www.kaggle.com/zalando-research/fashionmnist
b'World Happiness Report',"b'Happiness scored according to economic production, social support, etc.'","b'### Context \n\nThe World Happiness Report is a landmark survey of the state of global happiness. The first report was published in 2012, the second in 2013, the third in 2015, and the fourth in the 2016 Update. The World Happiness 2017, which ranks 155 countries by their happiness levels, was released at the United Nations at an event celebrating International Day of Happiness on March 20th. The report continues to gain global recognition as governments, organizations and civil society increasingly use happiness indicators to inform their policy-making decisions. Leading experts across fields \xe2\x80\x93 economics, psychology, survey analysis, national statistics, health, public policy and more \xe2\x80\x93 describe how measurements of well-being can be used effectively to assess the progress of nations. The reports review the state of happiness in the world today and show how the new science of happiness explains personal and national variations in happiness. \n\n### Content\n\nThe happiness scores and rankings use data from the Gallup World Poll. The scores are based on answers to the main life evaluation question asked in the poll. This question, known as the Cantril ladder, asks respondents to think of a ladder with the best possible life for them being a 10 and the worst possible life being a 0 and to rate their own current lives on that scale. The scores are from nationally representative samples for the years 2013-2016 and use the Gallup weights to make the estimates representative. The columns following the happiness score estimate the extent to which each of six factors \xe2\x80\x93 economic production, social support, life expectancy, freedom, absence of corruption, and generosity \xe2\x80\x93 contribute to making life evaluations higher in each country than they are in Dystopia, a hypothetical country that has values equal to the world\xe2\x80\x99s lowest national averages for each of the six factors. They have no impact on the total score reported for each country, but they do explain why some countries rank higher than others.\n\n\n### Inspiration\n\nWhat countries or regions rank the highest in overall happiness and each of the six factors contributing to happiness? How did country ranks or scores change between the 2015 and 2016 as well as the 2016 and 2017 reports? Did any country experience a significant increase or decrease in happiness?\n\n**What is Dystopia?**\n\nDystopia is an imaginary country that has the world\xe2\x80\x99s least-happy people. The purpose in establishing Dystopia is to have a benchmark against which all countries can be favorably compared (no country performs more poorly than Dystopia) in terms of each of the six key variables, thus allowing each sub-bar to be of positive width. The lowest scores observed for the six key variables, therefore, characterize Dystopia. Since life would be very unpleasant in a country with the world\xe2\x80\x99s lowest incomes, lowest life expectancy, lowest generosity, most corruption, least freedom and least social support, it is referred to as \xe2\x80\x9cDystopia,\xe2\x80\x9d in contrast to Utopia.\n\n**What are the residuals?**\n\nThe residuals, or unexplained components, differ for each country, reflecting the extent to which the six variables either over- or under-explain average 2014-2016 life evaluations. These residuals have an average value of approximately zero over the whole set of countries. Figure 2.2 shows the average residual for each country when the equation in Table 2.1 is applied to average 2014- 2016 data for the six variables in that country. We combine these residuals with the estimate for life evaluations in Dystopia so that the combined bar will always have positive values. As can be seen in Figure 2.2, although some life evaluation residuals are quite large, occasionally exceeding one point on the scale from 0 to 10, they are always much smaller than the calculated value in Dystopia, where the average life is rated at 1.85 on the 0 to 10 scale.\n\n**What do the columns succeeding the Happiness Score(like Family, Generosity, etc.) describe?**\n\nThe following columns: GDP per Capita, Family, Life Expectancy, Freedom, Generosity, Trust Government Corruption describe the extent to which these factors contribute in evaluating the happiness in each country. \nThe Dystopia Residual metric actually is the Dystopia Happiness Score(1.85) +  the Residual value or the unexplained value for each country as stated in the previous answer.\n\nIf you add all these factors up, you get the happiness score so it might be un-reliable to model them to predict Happiness Scores.\n\n#[Start a new kernel][1]\n\n\n  [1]: https://www.kaggle.com/unsdsn/world-happiness/kernels?modal=true'","b""['economics', 'social sciences', 'emotion', 'small', 'featured']""",https://www.kaggle.com/unsdsn/world-happiness
"b'Chicago Census-Languages, Socioeconomic Indicators'",b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/WTvYWlObUos) by [Aaron Andary](https://unsplash.com/@gentlemendesign) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'education', 'income', 'small', 'featured']""","https://www.kaggle.com/chicago/chicago-census-languages,-socioeconomic-indicators"
b'Spanish Single Speaker Speech Dataset',b'CSS10 Spanish: Single Speaker Speech Dataset',"b'### Context\n\nCSS10 is a collection of single speaker speech datasets for 10 languages. Each of them consists of audio files recorded by a single volunteer and their aligned text sourced from LibriVox.\n\n### Content\nEach line in `transcript.txt` is delimited by `|` into four fields, i.e., audio file location, original script, normalized script, and audio duration.\n\nVisit [here](https://github.com/kyubyong/css10) to check out our project using this dataset.\n\n### Acknowledgements\n\nWe thank LibriVox and the volunteers.\n \n### Contact\nYou can contact me at kbpark.linguist@gmail.com.\n\nJune, 2018.\n\nKyubyong Park & Tommy Mulc\n'","b""['linguistics', 'large', 'featured']""",https://www.kaggle.com/bryanpark/spanish-single-speaker-speech-dataset
b'NYS Transportation Projects in Your Neighborhood',b'From New York State Open Data',"b""### Content  \n\nThis data set contains DOT construction project information. The data is refreshed nightly from multiple data sources, therefore the data becomes stale rather quickly.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/sYK-jN0sKBY) by [Ricardo Gomez Angel](https://unsplash.com/@ripato) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-transportation-projects-in-your-neighborhood
b'Multi-Salient-Object (MSO) Dataset',b'1224 images with varying numbers of objects',"b'### Context\nPeople can immediately and precisely identify that an image contains 1, 2, 3 or 4 items by a simple glance. This phenomenon is known as Subitizing. An interesting data problem is to predict the existence and number of salient objects in a scene using holistic cues. The phenomenon, known as Subitizing, inspires us to pursue the task of Salient Object Subitizing, i.e. predicting the existence and the number of salient objects in a scene using holistic cues. Original data source and paper are by researchers at the Computer Science division of Boston University (specific reference can be found below in Acknowledgment section).\n\n### Content\nTotal of 1224 images originating from four public image datasets: COCO, VOC07, ImageNet and SUN. Each image is labeled as containing 0, 1, 2, 3 or 4+ salient objects by Amazon Mechanic Turk workers. This labelling information along with bounding box annotations can be found in **imgIdx.mat**, a matlab structure array that stores information about the images. The MSO dataset are a subset from the test set of the SOS dataset. The team at Boston University removed some images with severely overlapping salient objects or are ambiguous for labelling the indicated number of salient objects. As such, only 1224 images remain, out of 1380 images from the SOS test set. More than half of the images in the MSO dataset contain either zero salient objects or multiple salient objects. This is designed to provide a more realistic setting to evaluate salient object detection methods.\n\n- 0 salient objects: 338 images\n- 1 salient object: 611 images\n- 2 salient objects: 155 images\n- 3 salient objects: 100 images\n- 4+ salient objects: 20 images\n\n### Acknowledgements\n\nOriginal data source and banner image: http://cs-people.bu.edu/jmzhang/sos.html\n\nUsers of this dataset are asked to cite the paper: \n\nJianming Zhang, Shugao Ma, Mehrnoosh Sameki, Stan Sclaroff, Margrit Betke, Zhe Lin, Xiaohui Shen, Brian Price and Radom\xc3\xadr M\xc4\x9bch. ""Salient Object Subitizing."" To appear in Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.\n\n\n### Inspiration\n\n- Which images contain 2 objects? What about 3 objects?\n\n\n  [1]: https://www.kaggle.com/jessicali9530/mso-dataset/data/image_objectnumdist.jpg'","b""['classification', 'image data', 'image processing', 'object detection', 'object segmentation', 'medium', 'featured']""",https://www.kaggle.com/jessicali9530/mso-dataset
b'Bitcoin Historical Data',"b'Bitcoin data at 1-min intervals from select exchanges, Jan 2012 to November 2018'","b'### Context \nBitcoin is the longest running and most well known cryptocurrency, first released as open source in 2009 by the anonymous Satoshi Nakamoto. Bitcoin serves as a decentralized medium of digital exchange, with transactions verified and recorded in a public distributed ledger (the blockchain) without the need for a trusted record keeping authority or central intermediary. Transaction blocks contain a SHA-256 cryptographic hash of previous transaction blocks, and are thus ""chained"" together, serving as an immutable record of all transactions that have ever occurred. As with any currency/commodity on the market, bitcoin trading and financial instruments soon followed public adoption of bitcoin and continue to grow. Included here is historical bitcoin market data at 1-min intervals for select bitcoin exchanges where trading takes place. Happy (data) mining! \n\n### Content\ncoincheckJPY_1-min_data_2014-10-31_to_2018-06-27.csv\n\nbitflyerJPY_1-min_data_2017-07-04_to_2018-06-27.csv\n\ncoinbaseUSD_1-min_data_2014-12-01_to_2018-06-27.csv\n\nbitstampUSD_1-min_data_2012-01-01_to_2018-06-27.csv \n\nCSV files for select bitcoin exchanges for the time period of Jan 2012 to July 2018, with minute to minute updates of OHLC (Open, High, Low, Close), Volume in BTC and indicated currency, and weighted bitcoin price.  Timestamps are in Unix time.  Timestamps without any trades or activity have their data fields forward filled from the last valid time period. If a timestamp is missing, or if there are jumps, this may be because the exchange (or its API) was down, the exchange (or its API) did not exist, or some other unforseen technical error in data reporting or gathering. All effort has been made to deduplicate entries and verify the contents are correct and complete to the best of my ability, but obviously trust at your own risk. \n\n\n### Acknowledgements and Inspiration\n\nBitcoin charts for the data. The various exchange APIs, for making it difficult or unintuitive enough to get OHLC and volume data at 1-min intervals that I set out on this data scraping project. Satoshi Nakamoto and the novel core concept of the blockchain, as well as its first execution via the bitcoin protocol. I\'d also like to thank viewers like you! Can\'t wait to see what code or insights you all have to share. \n\nI am a lowly Ph.D. student who did this for fun in my meager spare time. If you find this data interesting and you can spare a coffee to fuel my science, send it my way and I\'d be immensely grateful!\n\n1kmWmcQa8qN9ZrdGfdkw8EHKBgugKBRcF'","b""['finance', 'history', 'medium', 'featured']""",https://www.kaggle.com/mczielinski/bitcoin-historical-data
b'VGG-16 ',b'VGG-16 Pre-trained Model for Keras',"b'# VGG16\n\n---\n\n## Very Deep Convolutional Networks for Large-Scale Image Recognition<br>\nIn this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.\n<br>\n\n**Authors: Karen Simonyan, Andrew Zisserman**<br>\n**https://arxiv.org/abs/1409.1556**\n\n---\n\n#VGG Architectures<br>\n![VGG Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/uLXrKxe.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/keras/vgg16
b'SVHN Preprocessed Fragments',b'Image Classification (Digit Recognition)',"b'### Context\n[SVHN](http://ufldl.stanford.edu/housenumbers/) is a real-world image dataset. \n\nFragments of this dataset were preprocessed: \n\n- fields of photos that do not contain digits were cut off;\n- the photos were formatted to the standard 32X32 size;\n- three color channels were converted into one channel (grayscaled);\n- each of the resulting images was represented as an array of numbers;\n- the data were converted into `.csv` files. \n\n### Content\n- 64000 32x32 greyscaled images of number photos with 1-5 digits (represented as arrays). \n- 11 categories of labels (ten ""digit"" categories and one ""empty character"" category). \n- Information about file names in the original dataset.\n\n### Acknowledgements\nThe original data contains a notice ""for non-commercial use only"".\n\n### Inspiration\nImage recognition and classification is a huge part of machine learning practice. In addition, this data is based on real photos.  '","b""['classification', 'deep learning', 'image data', 'multiclass classification', 'numbers', 'large', 'featured']""",https://www.kaggle.com/olgabelitskaya/svhn-preproccessed-fragments
b'Amazon reviews: Kindle Store Category',b'Amazon reviews: Kindle Store category',"b""### Context\n\nA small subset of dataset of product reviews from Amazon Kindle Store category.\n\n### Content\n\n[5-core][1] dataset of product reviews from Amazon Kindle Store category from May 1996 - July 2014. Contains total of 982619 entries. Each reviewer has at least 5 reviews and each product has at least 5 reviews in this dataset.\n\n#### Columns\n\n- `asin` - ID of the product, like B000FA64PK\n- `helpful` - helpfulness rating of the review - example: 2/3.\n- `overall` - rating of the product.\n- `reviewText` - text of the review (heading).\n- `reviewTime` - time of the review (raw).\n- `reviewerID` - ID of the reviewer, like A3SPTOKDG7WBLN\n- `reviewerName` - name of the reviewer.\n- `summary` - summary of the review (description).\n- `unixReviewTime` - unix timestamp.\n\n### Which file to use?\n\nThe dataset originally contained a json file of the reviews, but some people had issues opening it and getting it to work so I've added a csv file which contains same data. You can use whichever one is easier to work with.\n\n### Acknowledgements\n\nThis dataset is taken from Amazon product data, Julian McAuley, UCSD website. http://jmcauley.ucsd.edu/data/amazon/\n\nLicense to the data files belong to them.\n\n### Inspiration\n\n- Sentiment analysis on reviews.\n- Understanding how people rate usefulness of a review/ What factors influence helpfulness of a review.\n- Fake reviews/ outliers.\n- best rated product IDs, or similarity between products based on reviews alone (not the best idea ikr).\n- Any other interesting analysis.\n\n  [1]: https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)""","b""['internet', 'linguistics', 'business', 'medium', 'featured']""",https://www.kaggle.com/bharadwaj6/kindle-reviews
b'NY Traffic Volume Counts (2012-2013)',b'From New York City Open Data',"b""### Content  \n\nTraffic volume counts collected by DOT for New York Metropolitan Transportation Council (NYMTC) to validate the New York Best Practice Model (NYBPM).  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/XS7q-baZrmE) by [Adrian Schwarz](https://unsplash.com/@aeschwarz) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-traffic-volume-counts-2012-2013
b'Uber Movement Data',b'Uber Trips from San Francisco Caltrain Station',"b'### Context\n\nUber Movement provides anonymized data from over two billion trips to help urban planning around the world. See more at [Uber Movement](https://movement.uber.com/?lang=en-US).\n\n\n### Content\n\nThis data set includes the aggregated mean and range for all Uber rides starting from the the San Francisco Caltrain Station, serves dozens of stations between San Francisco and the South Bay.\n\nThe CSV file contains data for all rides between October 2017 and December 2017, inclusive.\n\n### Acknowledgements\n\nThis data was downloaded from [Uber Movement](https://movement.uber.com/?lang=en-US). From the organization:\n\nOver the past six and a half years, we\xe2\x80\x99ve learned a lot about the future of urban mobility and what it means for cities and the people who live in them. We\xe2\x80\x99ve gotten consistent feedback from cities we partner with that access to our aggregated data will inform decisions about how to adapt existing infrastructure and invest in future solutions to make our cities more efficient. We hope Uber Movement can play a role in helping cities grow in a way that works for everyone.\n\n#Inspiration\n\nWhat are traffic patterns like in San Francisco?\n'","b""['road transport', 'small', 'featured']""",https://www.kaggle.com/vaishalij/san-francisco-caltrain-uber-movement-data
b'Grammar and Online Product Reviews',"b'A list of 71,045 online reviews from 1,000 different products.'","b""# About This Data\n\nThis is a list of over 71,045 reviews from 1,000 different products provided by [Datafiniti's Product Database][1]. The dataset includes the text and title of the review, the name and manufacturer of the product, reviewer metadata, and more.\n\n*Note that this is a sample of a large data set. The full data set is available through Datafiniti.*\n\n# What You Can Do With This Data\n\nYou can use this data to assess [how writing quality impacts positive and negative online product reviews][2]. E.g.:\n\n - Do reviewers use punctuation correctly?\n - Does the number of spelling errors differ by rating?\n - What is the distribution of star ratings across products?\n - How does review length differ by rating?\n - How long is the typical review?\n - What is the frequency of words with spelling errors by rating? \n - What is the number of reviews that don\xe2\x80\x99t end sentences with punctuation?\n - What is the proportion of reviews with spelling errors?\n\n# Data Schema\nA full schema for the data is available in our [support documentation][3].\n\n# About Datafiniti\nDatafiniti provides instant access to web data. We compile data from thousands of websites to create standardized databases of business, product, and property information. [Learn more][4].\n\n# Want More?\nYou can get more data like this by [joining Datafiniti][5] or [requesting a demo][6].\n\n  [1]: https://datafiniti.co/products/product-data/\n  [2]: https://datafiniti.co/grammar-of-online-reviews/\n  [3]: https://datafiniti-api.readme.io/docs/product-data-schema\n  [4]: https://datafiniti.co/\n  [5]: https://portal.datafiniti.co/login\n  [6]: https://datafiniti.co/request-a-demo/""","b""['internet', 'databases', 'product', 'recommendation', 'grammar', 'small', 'featured']""",https://www.kaggle.com/datafiniti/grammar-and-online-product-reviews
b'Biomechanical features of orthopedic patients',b'Classifying patients based on six features',"b""### Context\n\n**The data have been organized in two different but related classification tasks.** \n\n- column_3C_weka.csv (file with three class labels)\n  - The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis (150 patients). \n\n- column_2C_weka.csv (file with two class labels)\n  - For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients).\n\n### Content\n\nField Descriptions:\n\nEach patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (each one is a column): \n\n- pelvic incidence\n- pelvic tilt\n- lumbar lordosis angle\n- sacral slope\n- pelvic radius\n- grade of spondylolisthesis\n\n### Acknowledgements\n\nThe original dataset was downloaded from UCI ML repository:\n\nLichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science\n\nFiles were converted to CSV\n\n### Inspiration\n\nUse these biomechanical features to classify patients according to their labels ""","b""['small', 'featured']""",https://www.kaggle.com/uciml/biomechanical-features-of-orthopedic-patients
b'Large Purchases by the State of CA',b'All purchase orders over $5000 from 2012-2015',"b""The State Contract and Procurement Registration System (SCPRS) was established in 2003, as a centralized database of information on State contracts and purchases over $5000. eSCPRS represents the data captured in the State's eProcurement (eP) system, Bidsync, as of March 16, 2009. The data provided is an extract from that system for fiscal years 2012-2013, 2013-2014, and 2014-2015\n\n### Acknowledgements\n\nThis dataset was kindly released by the state of California. You can find the original copy here.""","b""['finance', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/sohier/large-purchases-by-the-state-of-ca
b'Daily Power Production of Solar Panels',b'Cumulative solar power day by day from 2011',"b""### Context\n\nIn oktober 2011 we installed solar pannels (or Photovoltaic Modules) on our roof. The total power of the modules is 5kWp.\nI may seem strange but we have the habbit of making daily recordings of our electricity usage and so it was obvious to make record of the powerproduction of the solar pannels. I am trying to predict the date of the next 1000kWh produced.\n\n\n### Content\n\nThe csv file has two columns: first the date and second the cumulative power in kWh.\n\n\n### Acknowledgements\n\nWe wouldn't be here without the help of others. I have until now worked with the excellent information and sample python programs from Jason Brownlee : https://machinelearningmastery.com/\n\n### Inspiration\n\nI am still working to improve my LSTM performance. I hope some one can get better results in predicting the future power production.""","b""['time series', 'lstm', 'small', 'featured']""",https://www.kaggle.com/fvcoppen/solarpanelspower
b'Open Source Cluster IOTs for RE Malwares',b'VulcanoIO.org  - Open Source Cluster IOTs for RE Malwares.',"b'### Context\n\nEvery day, millions of new malware are created and projected on the Internet with malicious and destructive intent.\n\n\n### Content\n\nThe datasets are malware analytics manually and automatically via sandboxies from October 2014 to December 2016. This dataset presents transactions that have occurred in almost 2 years, where we have 143332 malware scans with varying correlations with each other.\n\nIt has only numeric input variables that are the result of a PCA transformation. Unfortunately, due to a confidentiality issue, we can not offer features like the original and the latest data information.\n\n\n### Acknowledgements\n\nWe thank everyone who sends us hardware donations, amazon gilf cards for hardware purchase and malware sampler for malware analysis, which help us to stay motivated and confident with the continuity of this project. More info vulcanoio.org\n\n\n### Inspiration\n\nThe inspiration for this project is to deepen the studies in analysis in reverse engineering of malware, as well as the fight against cybercrime and better understanding of the attackers, in the creation and execution of malware in vulnerable environments, to their infections.'","b""['crime', 'software', 'engineering', 'free software', 'small', 'featured']""",https://www.kaggle.com/firebits/vulcanoio-org-misp2-4-54-initial-20161127-07h35m
b'Finnish Single Speaker Speech Dataset',b'CSS10 Finnish: Single Speaker Speech Dataset',"b'### Context\n\nCSS10 is a collection of single speaker speech datasets for 10 languages. Each of them consists of audio files recorded by a single volunteer and their aligned text sourced from LibriVox.\n\n### Content\nEach line in `transcript.txt` is delimited by `|` into four fields, i.e., audio file location, original script, normalized script, and audio duration.\n\nVisit [here](https://github.com/kyubyong/css10) to check out our project using this dataset.\n\n### Acknowledgements\n\nWe thank LibriVox and the volunteers.\n \n### Contact\nYou can contact me at kbpark.linguist@gmail.com.\n\nJune, 2018.\n\nKyubyong Park & Tommy Mulc\n'","b""['linguistics', 'large', 'featured']""",https://www.kaggle.com/bryanpark/finnish-single-speaker-speech-dataset
b'Fatal Police Shootings in the US',b'Fatal police shootings in the US since 2015 with additional US census data',"b'The 2014 killing of Michael Brown in Ferguson, Missouri, began the protest movement culminating in Black Lives Matter and an increased focus on police accountability nationwide. \n\nSince Jan. 1, 2015, The Washington Post has been compiling a database of every fatal shooting in the US by a police officer in the line of duty. \nIt\'s difficult to find reliable data from before this period, as police killings haven\'t been comprehensively documented, and the statistics on police brutality are much less available. As a result, a vast number of cases go unreported.\n\nThe Washington Post is tracking more than a dozen details about each killing - including the race, age and gender of the deceased, whether the person was armed, and whether the victim was experiencing a mental-health crisis. They have gathered this information from law enforcement websites, local new reports, social media, and by monitoring independent databases such as ""Killed by police"" and ""Fatal Encounters"". The Post has also conducted additional reporting in many cases.\n\nThere are four additional datasets. These are US census data on poverty rate, high school graduation rate, median household income, and racial demographics. \n\nSource of census data:\nhttps://factfinder.census.gov/faces/nav/jsf/pages/community_facts.xhtml'","b""['crime', 'united states', 'violence', 'death', 'small', 'featured']""",https://www.kaggle.com/kwullum/fatal-police-shootings-in-the-us
b'SF Lobbyist Activity Data',b'From San Francisco Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/x7ZT4z9pj00) by [Emanuel Haas](https://unsplash.com/@dermanuskript) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License""","b""['socrata', 'ethics', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-lobbyist-activity-data
b'SF Mobile Food Facility Permit and Schedule',b'From San Francisco Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-mobile-food-facility-permit-and-schedule
"b""Spotify's Worldwide Daily Song Ranking""",b'The 200 daily most streamed songs in 53 countries',"b'### Context\n\nMusic streaming is ubiquitous. Currently, Spotify plays an important part on that. This dataset enable us to explore how artists and songs\' popularity varies in time.\n\n### Content\n\nThis dataset contains the daily ranking of the 200 most listened songs in 53 countries from 2017 and 2018 by Spotify users. It contains more than 2 million rows, which comprises 6629 artists, 18598 songs for a total count of one hundred five billion streams count.\n\nThe data spans from 1st January 2017 to 9th January 2018 and will be kept up-to-date on following versions. It has been collected from Spotify\'s regional chart [data][1].\n\n### Inspiration\n\n - Can you predict what is the rank position or the number of streams a song will have in the future?\n - How long does songs ""resist"" on the top 3, 5, 10, 20 ranking?\n - What are the signs of a song that gets into the top rank to stay?\n - Do continents share same top ranking artists or songs?\n - Are people listening to the very same top ranking songs on countries far away from each other?\n - How long time does a top ranking song takes to get into the ranking of neighbor countries?\n\n### Example\n\nTo start out, you can take a look into a simple Kernel I have made in order to read the data, filter data from a song, plot is temporal tendency per country than make a simple forecast of the its streams count [here][2].\n\n### Crawler\n\nThe crawler used to collect this data can be found [here][3].\n\n\n  [1]: https://spotifycharts.com/regional\n  [2]: https://www.kaggle.com/edumucelli/initial-analysis-and-forecast-example\n  [3]: https://github.com/edumucelli/spotify-worldwide-ranking'","b""['music', 'medium', 'featured']""",https://www.kaggle.com/edumucelli/spotifys-worldwide-daily-song-ranking
b'Honey Production in the USA (1998-2012)',b'Honey Production Figures and Prices by National Agricultural Statistics Service',"b'### Context\nIn 2006, global concern was raised over the [rapid decline in the honeybee population][1], an integral component to American honey agriculture. Large numbers of hives were lost to Colony Collapse Disorder, a phenomenon of disappearing worker bees causing the remaining hive colony to collapse. Speculation to the cause of this disorder points to hive diseases and pesticides harming the pollinators, though no overall consensus has been reached. Twelve years later, [some industries are observing recovery][2] but the [American honey industry is still largely struggling][3]. The U.S. used to locally produce over half the honey it consumes per year. Now, honey mostly comes from overseas, with 350 of the 400 million pounds of honey consumed every year originating from imports. This dataset provides insight into honey production supply and demand in America by state from 1998 to 2012. \n\n### Content\nThe [National Agricultural Statistics Service (NASS)][4] is the primary data reporting body for the US Department of Agriculture (USDA). NASS\'s mission is to ""provide timely, accurate, and useful statistics in service to U.S. agriculture"".  From datasets to census surveys, their data covers virtually all aspects of U.S. agriculture. Honey production is one of the datasets offered. [Click here][5] for the original page containing the data along with related datasets such as Honey Bee Colonies and Cost of Pollination. Data wrangling was performed in order to clean the dataset. **honeyproduction.csv** is the final tidy dataset suitable for analysis. The three other datasets (which include ""honeyraw"" in the title) are the original raw data downloaded from the site. They are uploaded to this page along with the ""**Wrangling The Honey Production Dataset**"" kernel as an example to show users how data can be wrangled into a cleaner format. Useful metadata on certain variables of the honeyproduction dataset is provided below:\n\n - *numcol*: Number of honey producing colonies. Honey producing colonies are the maximum number of colonies from which honey was taken during the year. It is possible to take honey from colonies which did not survive the entire year\n - *yieldpercol*: Honey yield per colony. Unit is pounds\n - *totalprod*: Total production (numcol x yieldpercol). Unit is pounds\n - *stocks*: Refers to stocks held by producers. Unit is pounds\n - *priceperlb*: Refers to average price per pound based on expanded sales. Unit is dollars.\n - *prodvalue*: Value of production (totalprod x priceperlb). Unit is dollars.\n - Other useful information: Certain states are excluded every year (ex. CT) to avoid disclosing data for individual operations. Due to rounding, total colonies multiplied by total yield may not equal production. Also, summation of states will not equal U.S. level value of production.\n\n### Acknowledgements\nHoney production data was published by the National Agricultural Statistics Service (NASS) of the U.S. Department of Agriculture. \nThe beautiful banner photo was by Eric Ward on Unsplash.\n\n### Inspiration\n\n - How has honey production yield changed from 1998 to 2012? \n - Over time, which states produce the most honey? Which produce the least? Which have experienced the most change in honey yield?\n - Does the data show any trends in terms of the number of honey producing colonies and yield per colony before 2006, which was when concern over Colony Collapse Disorder spread nationwide?\n - Are there any patterns that can be observed between total honey production and value of production every year? How has value of production, which in some sense could be tied to demand, changed every year? \n\n  [1]: http://www.abc.net.au/news/2017-05-08/colony-collapse-ten-years-after-crisis-what-is-happening-to-bees/8507408\n  [2]: https://www.bloomberg.com/news/articles/2017-08-01/good-news-for-bees-as-numbers-recover-while-mystery-malady-wanes\n  [3]: https://www.washingtonpost.com/news/wonk/wp/2015/05/14/dying-bees-could-mean-the-end-of-american-honey/?utm_term=.31aeb8175b56\n  [4]: https://www.nass.usda.gov/About_NASS/index.php\n  [5]: http://usda.mannlib.cornell.edu/MannUsda/viewDocumentInfo.do?documentID=1520'","b""['animals', 'agriculture', 'natural resources', 'small', 'featured']""",https://www.kaggle.com/jessicali9530/honey-production
b'NYS Scholarship Recipients And Dollars',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'education', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-scholarship-recipients-and-dollars
b'British Birdsong Dataset',b'264 recordings from 88 species',"b'### Context: \n\nBirds use songs and calls of varying length and complexity to attract mates, warn of nearby danger and mark their territory. This dataset contains a recordings of different birdsongs from bird species that can be found in Britain (although the recordings themselves are from many different locations).\n\n### Content: \n\nThis is a dataset of bird sound recordings, a specific subset gathered from the Xeno Canto collection to form a balanced dataset across 88 species commonly heard in the United Kingdom. It was originally compiled by Dan Stowell and [shared on Archive.org](https://archive.org/details/xccoverbl_2014).\n\nThe copyright in each audio file is owned by the user who donated the file to Xeno Canto. Please see ""birdsong_metadata.tsv"" for the full listing, which gives the authors\' names and the CC licences applicable for each file. The audio files are encoded as .flac files.\n\n### Acknowledgements: \n\nThese recordings were collected by 68 separate birding enthusiasts and uploaded to and stored by xeno-canto: [www.xeno-canto.org](http://www.xeno-canto.org). If you make use of these recordings in your work, please cite the specific recording and include acknowledgement of and a link to the xeno-canto website.\n\n### Inspiration: \n\n* Can you build a classifier to identify birds based on their songs?\n* Can you visualize the songs of specific birds?\n* Can you generate new birdsongs based on this data?'","b""['animals', 'ecology', 'acoustics', 'nature', 'medium', 'featured']""",https://www.kaggle.com/rtatman/british-birdsong-dataset
b'FIFA World Cup',b'All the results from World Cups',"b'### Context\n\nThe FIFA World Cup is a global football competition contested by the various football-playing nations of the world. It is contested every four years and is the most prestigious and important trophy in the sport of football.\n\n### Content\n\nThe World Cups dataset show all information about all the World Cups in the history, while the World Cup Matches dataset shows all the results from the matches contested as part of the cups.\n\n### Acknowledgements\n\nThis data is courtesy of the FIFA World Cup Archive website.\n\n### Inspiration\n\nCan you predict who will win the next World Cup?'","b""['sports', 'world', 'small', 'featured']""",https://www.kaggle.com/abecklas/fifa-world-cup
b'NY Housing Maintenance Code',b'From New York City Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/mAZdqR8Uwbk) by [Scott Blake](https://unsplash.com/@sunburned_surveyor) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/ny-housing-maintenance-code
b'NYS Current Certified Pesticide Applicators',b'From New York State Open Data',"b""### Content  \n\nThis dataset is a list of pesticide applicators currently certified by New York State Department of Environmental Conservation (DEC) in the various categories of individual certification (6NYCRR Part 325).  It includes certificate number, name, DEC region, expiration date, applicator type and category.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/qwzUtdFIaLI) by [Austin Ban](https://unsplash.com/@austinban) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'utility', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-current-certified-pesticide-applicators
b'FiveThirtyEight Candy Power Ranking Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Candy Power Ranking\n\nThis folder contains the data behind the story [The Ultimate Halloween Candy Power Ranking](http://fivethirtyeight.com/features/the-ultimate-halloween-candy-power-ranking/).\n\n`candy-data.csv` includes attributes for each candy along with its ranking. For binary variables, 1 means yes, 0 means no.\n\nThe data contains the following fields:\n\nHeader | Description\n-------|------------\nchocolate | Does it contain chocolate?\nfruity | Is it fruit flavored?\ncaramel | Is there caramel in the candy?\npeanutalmondy | Does it contain peanuts, peanut butter or almonds?\nnougat | Does it contain nougat?\ncrispedricewafer | Does it contain crisped rice, wafers, or a cookie component?\nhard | Is it a hard candy?\nbar | Is it a candy bar?\npluribus | Is it one of many candies in a bag or box?\nsugarpercent | The percentile of sugar it falls under within the data set.\npricepercent | The unit price percentile compared to the rest of the set.\nwinpercent | The overall win percentage according to 269,000 matchups.\n\n  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.  \n\n[Cover photo](https://unsplash.com/photos/rnLsZUWRnLA) by [Jeff Frenette](https://unsplash.com/@dezjeff) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-candy-power-ranking-dataset
b'Q & A Discussed in Parliament of India',b'88000+ Questions & answers discussed in Rajya Sabha from 2009 till date.',"b""**Connect/Follow me on [LinkedIn](http://link.rajanand.org/linkedin) for more updates on interesting dataset like this. Thanks.**\n\n### Context\nThe Rajya Sabha has published the questions and answers that were discussed in each session on their webiste. But one has to search by question/session/ministry wise to get the detail. There were no direct way to get all the quesions and answers in structured way(i.e, csv) to do an analysis and find insights. So I've written a [web scrapper](https://goo.gl/iDTGBw) in R to scrape the data from the Rajya Sabha website and created csv files for each year.\n\n### Content\nThis dataset helps one to understand what was being discussed in Parliament (Rajya Sabha) of India. There are over 88000+ questions and answers that were discussed in Rajya sabha from 2009 till date (Sep'2017).\n\nVariables detail:\n\n-  `id` - Unique identifier\n-  `answer_date` - Answer date\n-  `ministry` - Ministry name\n-  `question_type` - Type of question (Starred or Unstarred)*\n-  `question_no` - Question number. (This question no. is unique per session)\t\n-  `question_by` - Minister who has raised the question.\n-  `question_title` - Discussion title\t\n-  `question_description` - Detailed question.\n-  `answer` - Detailed answer to the above question.\n\n> *Starred Questions :\n> These are Questions to which answers are desired to be given orally on the floor of the House during the Question Hour. These are distinguished in the printed lists by asterisks. 15 such questions are listed each day.\n\n> Unstarred Questions:\n> These are Questions to which written answers are given by Ministers which are deemed to have been laid on the Table of the House at the end of the Question Hour. Upto 160 such questions are listed each day in a separate list.\n\n[source](http://rajyasabha.nic.in/rsnew/question/rstype.asp)\n\n\n### Acknowledgements\nThanks to [Rajya Sabha](http://rajyasabha.nic.in/) for making the question and answers [searchable.](http://164.100.47.4/newrsquestion/Search_SessionWise.aspx)\n\n\n### Inspiration\nThe below are some of the questions can be answered from this dataset.\n\n- Which state or district names mentioned most in question/answer?\n- Sentiment analysis\n- No. of questions ministry wise\n- No. of questions/answers per day. Typically it should be 175 per day. How many days were less productive?\n- Who has raised more question? etc.\n\n""","b""['linguistics', 'politics', 'india', 'government', 'politicians', 'medium', 'featured']""",https://www.kaggle.com/rajanand/rajyasabha
b'Behavioral Risk Factor Surveillance System',b'Public health surveys of 400k people from 2011-2015',"b""The objective of the BRFSS is to collect uniform, state-specific data on preventive health practices and risk\nbehaviors that are linked to chronic diseases, injuries, and preventable infectious diseases in the adult population.\nFactors assessed by the BRFSS include tobacco use, health care coverage, HIV/AIDS knowledge or prevention,\nphysical activity, and fruit and vegetable consumption. Data are collected from a random sample of adults (one per\nhousehold) through a telephone survey.\n\nThe Behavioral Risk Factor Surveillance System (BRFSS) is the nation's premier system of health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. Established in 1984 with 15 states, BRFSS now collects data in all 50 states as well as the District of Columbia and three U.S. territories. BRFSS completes more than 400,000 adult interviews each year, making it the largest continuously conducted health survey system in the world.\n\n### Content\n\n - Each year contains a few hundred columns. Please see one of the\n   [annual code books][1] for complete details.\n - These CSV files were converted from a SAS data format using pandas; there may be some data artifacts as a result.\n - If you like this dataset, you might also like the data for 2001-2010.\n\n### Acknowledgements\n\nThis dataset was released by the CDC. You can find the original dataset and [additional years of data here][2].\n\n\n  [1]: https://www.cdc.gov/brfss/annual_data/2015/pdf/codebook15_llcp.pdf\n  [2]: https://www.cdc.gov/brfss/annual_data/annual_data.htm""","b""['public health', 'mental health', 'large', 'featured']""",https://www.kaggle.com/cdc/behavioral-risk-factor-surveillance-system
b' Air pressure system failures in Scania trucks',b'Predict failures and minimize costs based on sensor readings',"b'## Context\nThe dataset consists of data collected from heavy Scania trucks in everyday usage. The system in focus is the Air Pressure system (APS) which generates pressurized air that is utilized in various functions in a truck,  such as braking and gear changes. The datasets\' positive class consists of component failures for a specific component of the APS system. The negative class consists of trucks with failures for components not related to the APS. The data consists of a subset of all available data, selected by experts. \n\n### Content\n\nThe training set contains 60000 examples in total in which 59000 belong to the negative class and 1000 positive class. The test set contains 16000 examples. There are 171 attributes per record.\n\nThe attribute names of the data have been anonymized for proprietary reasons. It consists of both single numerical counters and histograms consisting of bins with different conditions. Typically the histograms have open-ended conditions at each end. For example, if we measuring the ambient temperature ""T"" then the histogram could be defined with 4 bins where: \n\nThe attributes are as follows: class, then anonymized operational data. The operational data have an identifier and a bin id, like ""Identifier_Bin"". In total there are 171 attributes, of which 7 are histogram variables. Missing values are denoted by ""na"".\n\n### Acknowledgements\n\nThis file is part of APS Failure and Operational Data for Scania Trucks. It was imported from the [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks).\n\n### Inspiration\n\nThe total cost of a prediction model the sum of `Cost_1`  multiplied by the number of Instances with type 1 failure and `Cost_2` with the number of instances with type 2 failure, resulting in a `Total_cost`. In this case `Cost_1` refers to the cost that an unnecessary check needs to be done by an mechanic at an workshop, while `Cost_2` refer to the cost of missing a faulty truck, which may cause a breakdown.  `Cost_1 = 10` and `Cost_2 = 500`, and `Total_cost = Cost_1*No_Instances + Cost_2*No_Instances`.\n\nCan you create a model which accurately predicts and minimizes [the cost of] failures?'","b""['mechanical engineering', 'medium', 'featured']""",https://www.kaggle.com/uciml/aps-failure-at-scania-trucks-data-set
b'Oakland Coliseum Event Ticket Distribution 2011-18',b'Explore open data from the city of Oakland',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of Oakland in California. The organization has an open data platform found [here](data.oaklandnet.com) and they update their information according to the amount of data that is brought in. Explore Oakland's Data using Kaggle and all of the data sources available through the city of Oakland [organization page](https://www.kaggle.com/cityofoakland)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: NA, Public Domain U.S. Government, Public Domain, Creative Commons 1.0 Universal (Public Domain Dedication)""","b""['socrata', 'sports', 'utility', 'small', 'featured']""",https://www.kaggle.com/cityofoakland/oakland-coliseum-event-ticket-distribution-2011-18
b'NYS Broadband Availability By Municipality',b'From New York State Open Data',"b""### Content  \n\nNew York State has just completed a broadband mapping program as part of the national broadband mapping program funded by the National Telecommunications and Information Administration in the US Department of Commerce. Information about the availability of high-speed Internet services, commonly called Broadband, was collected from broadband provider companies regarding the technology type and speed of services offered. The data was updated every six months for five years, and is shown on the NYS Broadband Map at www.broadbandmap.ny.gov as well as the National Broadband Map at www.broadbandmap.gov. The data on the map depicts broadband availability at the Census Block level. This table summarizes the information for each municipality (town, city, village, Indian Reservation) in New York State.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/FrWStnBsfxI) by [Markus Spiske](https://unsplash.com/@markusspiske) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'internet', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-broadband-availability-by-municipality
b'Blood Cell Images',"b'12,500 images: 4 different cell types'","b""### Context\n\nThe diagnosis of blood-based diseases often involves identifying and characterizing patient blood samples.  Automated methods to detect and classify blood cell subtypes have important medical applications.\n\n### Content\n\nThis dataset contains 12,500 augmented images of blood cells (JPEG) with accompanying cell type labels (CSV).  There are approximately 3,000 images for each of 4 different cell types grouped into 4 different folders (according to cell type).    The cell types are Eosinophil, Lymphocyte, Monocyte, and Neutrophil.  This dataset is accompanied by an additional dataset containing the original 410 images (pre-augmentation) as well as two additional subtype labels (WBC vs WBC) and also bounding boxes for each cell in each of these 410 images (JPEG + XML metadata).  More specifically, the folder 'dataset-master' contains 410 images of blood cells with subtype labels and bounding boxes (JPEG + XML), while the folder 'dataset2-master' contains 2,500 augmented images as well as 4 additional subtype labels (JPEG + CSV).   There are approximately 3,000 augmented images for each class of the 4 classes as compared to 88, 33, 21, and 207 images of each in folder 'dataset-master'.\n\n### Acknowledgements\n\nhttps://github.com/Shenggan/BCCD_Dataset\nMIT License\n\n### Inspiration\n\nThe diagnosis of blood-based diseases often involves identifying and characterizing patient blood samples.\nAutomated methods to detect and classify blood cell subtypes have important medical applications.""","b""['classification', 'image data', 'medicine', 'biology', 'medium', 'featured']""",https://www.kaggle.com/paultimothymooney/blood-cells
b'State of the Union Corpus (1790 - 2018)',b'Full text of the State of the  Union address between 1790 and 2018',"b'### Context: \nThe State of the Union is an annual address by the President of the United States before a joint session of congress. In it, the President reviews the previous year and lays out his legislative agenda for the coming year.\n\n### Content: \nThis dataset contains the full text of the State of the Union address from 1989 (Regan) to 2017 (Trump).\n\n### Inspiration: \nThis is a nice, clean set of texts perfect for exploring Natural Language Processing techniques \n\n* Topic modelling: Which topics have become more popular over time? Which have become less popular?\n* Sentiment analysis: Are there differences in tone between different Presidents? Presidents from different parties?\n* Parsing: Can you train implement a parser to automatically extract the syntactic relationships between words?\n* Authorship identification: Can you correctly identify the author of a previously unseen address?'","b""['linguistics', 'politics', 'presidents', 'small', 'featured']""",https://www.kaggle.com/rtatman/state-of-the-union-corpus-1989-2017
b'Arrest Related Violence in California',"b'Records on use of force incidents, officer deaths, and deaths in prison'","b""### Context\n\nThis dataset provides information on violence in California's criminal justice system, whether the victim was a civilian or an officer or if the incident occurred during the arrest or while a subject was in custody. It's composed of a few related datasets:\n\n- Use of force incidents: The use of force (URSUS) incidents that result in serious bodily injury or death or involved the discharge of a firearm are reported annually from LEAs and other entities throughout the state that employ peace officers. The URSUS data is narrowly defined and does not represent the totality of use of force incidents that occur in California. LEAs are only required to report use of force incidents that result in serious bodily injury or death of either the civilian or the officer and all incidents where there is a discharge of a firearm. As such, caution must be used when using the data for comparisons or in calculating rates.\n\n- Law enforcement officers killed: Law Enforcement Officer's Killed or Assaulted (LEOKA) data are reported as part of the Federal Uniform Crime Reporting (UCR) Program by LEAs throughout the state. LEOKA data are summary data, meaning it is a collection of information describing the totality of incidents, not a collection at the detailed, incident level. LEOKA is a federally mandated collection. From the 1960's until 1990, the CJSC did not retain any of the LEOKA data; the forms were passed along to the Federal Bureau of Investigation (FBI). In 1990, the DOJ began to collect and retain the data from the LEOKA form for statistical purposes, but it wasn't until 2000, that full retention at the State level was defined and standardized.\n\n- Death in Custody & Arrest-Related Deaths: State and local law enforcement agencies and correctional facilities report information on deaths that occur in custody or during the process of arrest in compliance with Section 12525 of the California Government Code. Contributors include: California law enforcement agencies, county probation departments, state hospitals, and state correctional facilities. Data are subject to revision as reports are received by the California Department of Justice (DOJ); figures in previous and current releases may not match.\n\n- Citizens' Complaints Against Peace Officers: State and local law enforcement agencies that employ peace officers provide Citizens' Complaints Against Peace Officers (CCAPO) data via an annual summary. The information includes the number of criminal and non-criminal complaints reported by citizens and the number of complaints sustained. Assembly Bill 953 (2015) modified the reporting requirements to expand the types of findings and also include complaints based upon racial and identity profiling claims. 2016 was the first year of collection under the new reporting requirements.\n\n### Acknowledgements\n\nThis dataset was made available by [the state of California's open justice program](https://openjustice.doj.ca.gov/data).\n\nPhoto by [Meric Dagli](https://unsplash.com/photos/r7GOO6M2TmU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText).""","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/sohier/arrest-related-violence-in-california
b'Universal Product Code Database',b'One million products & their UPC codes',"b'### Context: \n\n\xe2\x80\x9cThe Universal Product Code (UPC) is a barcode symbology that is widely used in the United States, Canada, United Kingdom, Australia, New Zealand, in Europe and other countries for tracking trade items in stores.\n\n\xe2\x80\x9cUPC (technically refers to UPC-A) consists of 12 numeric digits, that are uniquely assigned to each trade item. Along with the related EAN barcode, the UPC is the barcode mainly used for scanning of trade items at the point of sale, per GS1 specifications.[1] UPC data structures are a component of GTINs and follow the global GS1 specification, which is based on international standards. But some retailers (clothing, furniture) do not use the GS1 system (rather other barcode symbologies or article number systems). On the other hand, some retailers use the EAN/UPC barcode symbology, but without using a GTIN (for products, brands, sold at such retailers only).\xe2\x80\x9d\n\n-- Tate. (n.d.). In Wikipedia. Retrieved August 18, 2017, from https://en.wikipedia.org/wiki/Plagiarism. Text reproduced here under a [CC-BY-SA 3.0 license](https://en.wikipedia.org/wiki/Wikipedia%3aText_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License).\n\n### Content:\n\nThis dataset contains just over 1 million UPC codes and the names of the products associated with them.\n\n### Acknowledgements: \n\nWhile UPC\xe2\x80\x99s themselves are not copyrightable, the brand names and trademarks in this dataset remain the property of their respective owners.\n\n### Inspiration: \n\n* Can you use this dataset to generate new product names?\n* Can you use this in conjunction with other datasets to disambiguate products?'","b""['business', 'product', 'supply chain', 'product management', 'medium', 'featured']""",https://www.kaggle.com/rtatman/universal-product-code-database
b'GPS recorded hikes from hikr.org',b'~12000 GPX files and associated meta data of mountain hikes',"b'### Context\n\nhikr.org is a platform where users can post reports about their ski tours or hikes. Some of these posts also contain the original GPX file as it was recorded during the activity.\n\n### Content\n\nThis dataset consists of a sample of approx 12000 such GPX files which were scraped from their website in Spring 2018.\nThe GPX tracks were simplified with gpxpy to reduce the size of the dataset, additional features such as max_elevation etc. were also calculated with gpxpy.\n\nThe difficulty rating of the hikes is based on the SAC Hiking Scale and has been set by the users who did the hike.\n\n### Acknowledgements\nThanks a lot to hikr.org and their users for providing these information publicly.\n\n### Inspiration\nHow long do you think that hike will take?'","b""['sports', 'geography', 'medium', 'featured']""",https://www.kaggle.com/roccoli/gpx-hike-tracks
b'Smart meters in London',b'Smart meter data from London area',"b""### Context\n\nTo better follow the energy consumption, the government wants energy suppliers to install smart meters in every home in England, Wales and Scotland. There are more than 26 million homes for the energy suppliers to get to, with the goal of every home having a smart meter by 2020.\n\nThis roll out of meter is lead by the European Union who asked all member governments to look at smart meters as part of measures to upgrade our energy supply and tackle climate change. After an initial study, the British government decided to adopt smart meters as part of their plan to update our ageing energy system.\n\nIn this dataset, you will find a [refactorised version of the data][1] from the London data store, that contains the energy consumption readings for a sample of 5,567 London Households that took part in the UK Power Networks led Low Carbon London project between November 2011 and February 2014. The data from the smart meters seems associated only to the electrical consumption.\n\nThere is infomations on the ACORN classification details that you can find in this [report][2] or the website of CACI.\n\nI added weather data for London area, I used the [darksky api][3] to collect this data.\n\n### Content\nThere is 19 files in this dataset :\n\n - informations_households.csv : this file that contains all the information on the households in the panel (their acorn group, their tariff) and in which block.csv.gz file their data are stored\n\n - halfhourly_dataset.zip: Zip file that contains the block files with the half-hourly smart meter measurement\n\n - daily_dataset.zip: Zip file that contains the block files with the daily information like the number of measures, minimum, maximum, mean, median, sum and std.\n\n - acorn_details.csv : Details on the acorn groups and their profile of the people in the group, it's come from this [xlsx spreadsheet][4].The first three columns are the attributes studied, the ACORN-X is the index of the attribute. At a national scale, the index is 100 if for one column the value is 150 it means that there are 1.5 times more people with this attribute in the ACORN group than at the national scale. You can find an explanation on the [CACI website][5]\n\n - weather_daily_darksky.csv : that contains the daily data from [darksky api][6]. You can find more details about the parameters in [the documentation of the api][7]\n\n - weather_hourly_darksky.csv : that contains the hourly data from [darksky api][8]. You can find more details about the parameters in [the documentation of the api][9]\n\n### Acknowledgements\nAll the big work of data collection has been done by the [UK power networks][10] for the smart meter data.\n\nThe details related at the acorn group are provided by the CACI.\n\nThe weather data are from [darksky][11].\n\n### Inspiration\nFor me some ideas to analyze the data:\n\n - Segmentation of the consumption daily pattern\n - Disaggregation of the electricity load curve\n - Cross the consumption result and the acorn information\n - Forecast the electricity consumption of a household, I wrote [an article][12] on this subject\n - What if I add electrical heating system ? an EV battery system ?\n - Forecast at a global scale (London consumption)\n\n\n  [1]: https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households\n  [2]: https://acorn.caci.co.uk/downloads/Acorn-User-guide.pdf\n  [3]: https://darksky.net/dev\n  [4]: https://acorn.caci.co.uk/what-is-acorn\n  [5]: https://acorn.caci.co.uk/what-is-acorn\n  [6]: https://darksky.net/dev\n  [7]: https://darksky.net/dev/docs#response-format\n  [8]: https://darksky.net/dev\n  [9]: https://darksky.net/dev/docs#response-format\n  [10]: http://www.ukpowernetworks.co.uk/\n  [11]: https://darksky.net/dev\n  [12]: http://jmdaignan.com/2017/10/20/Maka-a-forecast-system-of-the-national-energy-consumption/""","b""['demographics', 'weather', 'energy', 'home', 'large', 'featured']""",https://www.kaggle.com/jeanmidev/smart-meters-in-london
b'Street View House Numbers (SVHN)',b'Over 600k Real-World Images of House Numbers From Google Street View Images',"b""Dataset uploaded by [Jessica Li][1]\n\n----------\n\n\n### Context\n\nObject recognition and image processing has become one of the hottest topics in machine learning due to its vast and creative potential applications in the real world. The ability to process visual information using machine learning algorithms can be very useful, such as [measuring the quality of NYC Bike Lanes through street imagery][2]. Within this field, the Street View House Numbers (SVHN) dataset is one of the most popular ones. It has been used in [neural networks created by Google][3] to read house numbers and match them to their geolocations. This is a great benchmark dataset to play with, learn and train models that accurately identify street numbers, and incorporate into all sorts of projects.\n\n### Content\n\nThis dataset contains three .zip files that contain over 600k labelled real-world images of house numbers taken from Google Street View. The sequence of numbers in the images are of bounded length. \n\n - **test.zip**: 26,032 digits for testing\n - **train.zip**: 73,257 digits for training\n - **extra.zip**: 531,131 additional, somewhat less difficult samples, to use as extra training data\n\n**Additional Notes**\n \n- There are 10 classes, 1 for each digit. Digit '1' has label 1, '9' has label 9 and '0' has label 10.\n- The images are the original, variable-resolution, color house-number images with character level bounding boxes in .png format.\n- **digitStruct.mat**: Contains bounding box information for each respective .zip file are stored as **digitStruct.mat**, which can be loaded using Matlab. The digitStruct.mat files contain a struct called digitStruct with the same length as the number of original images. \n- Each element in digitStruct has the following fields:\n      - **name**: string containing the filename of the corresponding image\n      - **bbox**: struct array that contains the position, size and label of each digit bounding box in the image. Ex. digitStruct(300).bbox(2).height gives height of the 2nd digit bounding box in the 300th image. \n\n### Acknowledgements\nThe SVHN dataset originates from http://ufldl.stanford.edu/housenumbers/. The banner photo was by Annie Spratt on Unsplash.\n\nThe original paper that introduces and examines this data:\n\nYuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011.\n\n### Inspiration & Resources\n\n- Given the testing and training data, can you train a model (try Keras and/or TensorFlow) that accurately identifies house numbers in an image (with difficulties like picture brightness, blurriness)?\n- What are some interesting datasets that can be merged with object detection datasets like this to form new applications?\n- Additional resources are [Getting Started with SVHN Dataset][4] and [Ji Yan's project][5] that aims to tackle the SHVN dataset using Convolutional Network in Tensorflow.\n\n\n  [1]: https://www.kaggle.com/jessicali9530\n  [2]: https://medium.com/a-r-g-o/classifying-nyc-bike-lane-quality-with-image-processing-and-computer-vision-in-python-76b13147ec2d\n  [3]: https://www.technologyreview.com/s/523326/how-google-cracked-house-number-identification-in-street-view/\n  [4]: https://agi.io/2018/01/31/getting-started-street-view-house-numbers-svhn-dataset/\n  [5]: https://experimentationground.wordpress.com/2016/09/26/digit-recognition-from-google-street-view-images/""","b""['classification', 'image data', 'image processing', 'object detection', 'large', 'featured']""",https://www.kaggle.com/stanfordu/street-view-house-numbers
b'Question Pairs Dataset',b'Can you identify duplicate questions?',"b""# Context\n\nQuora's first public dataset is related to the problem of identifying duplicate questions. At Quora, an important product principle is that there should be a single question page for each logically distinct question. For example, the queries \xe2\x80\x9cWhat is the most populous state in the USA?\xe2\x80\x9d and \xe2\x80\x9cWhich state in the United States has the most people?\xe2\x80\x9d should not exist separately on Quora because the intent behind both is identical. Having a canonical page for each logically distinct query makes knowledge-sharing more efficient in many ways: for example, knowledge seekers can access all the answers to a question in a single location, and writers can reach a larger readership than if that audience was divided amongst several pages.\n\nThe dataset is based on actual data from Quora and will give anyone the opportunity to train and test models of semantic equivalence.\n\n# Content\n\nThere are over 400,000 lines of potential question duplicate pairs. Each line contains IDs for each question in the pair, the full text for each question, and a binary value that indicates whether the line truly contains a duplicate pair.\n\n# Acknowledgements\n\nFor more information on this dataset, check out Quora's [first dataset release page](https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs).\n\n# License\n\nThis data is subject to Quora's [Terms of Service](https://www.quora.com/about/tos), allowing for non-commercial use.""","b""['linguistics', 'languages', 'artificial intelligence', 'medium', 'featured']""",https://www.kaggle.com/quora/question-pairs-dataset
b'Los Angeles Museum Visitors',b'From Los Angeles Open Data',"b""### Content  \n\nIndividual visits to El Pueblo museums, per month.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/xRf_ux39v9w) by [Serge Kutuzov](https://unsplash.com/@serge_k) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'museums', 'small', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-museum-visitors
b'Crime in Baltimore',b'Crime data for 2012-2017',"b""\nAll BPD data on Open Baltimore is preliminary data and subject to change. The information presented through Open Baltimore represents Part I victim based crime data. The data do not represent statistics submitted to the FBI's Uniform Crime Report (UCR); therefore any comparisons are strictly prohibited. For further clarification of UCR data, please visit http://www.fbi.gov/about-us/cjis/ucr/ucr. Please note that this data is preliminary and subject to change. Prior month data is likely to show changes when it is refreshed on a monthly basis. All data is geocoded to the approximate latitude/longitude location of the incident and excludes those records for which an address could not be geocoded. Any attempt to match the approximate location of the incident to an exact address is strictly prohibited.\n\n### Acknowledgements\n\nThis dataset was kindly made available by the City of Baltimore. You can find the original dataset, which is updated regularly, here.\n\n""","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/sohier/crime-in-baltimore
b'Ultra-Trail du Mont-Blanc 2003-2017',b'the most prestigious ultra-trail marathon in the world',"b'### Context  \nThe UTMB(as it\'s more commonly known) takes place once a year on either the last weekend in August or the first weekend of September in the Alps, and follows the route of the Tour du Mont Blanc through France, Italy and Switzerland. It has a distance of approximately 166 kilometres (103 mi), and a total elevation gain of around 9,600 metres (31,500 ft). It is widely regarded as one of the most difficult foot races in the world, and one of the largest with more than 2,000 starters. It is one race during a week-long festival based around Chamonix in France. The races have strict entry and qualification requirements attained by accumulating enough race points through qualifying trail races over the previous two-year period. In 2016 and 2017, 42% and 34% of runners did not finish the UTMB race.\n\nWhile the best runners complete the loop in slightly more than 20 hours, most runners take 32 to 45 hours to reach the finish line. Most runners will have to run through two nights in order to complete the race. There is no prize money awarded.\n\nSince 2006, a second race Courmayeur - Champex - Chamonix (half-loop) has also been organised, and a third race was added in 2009: ""Sur les Traces des Ducs de Savoie"". A fourth shorter ""running"" event - Orsi\xc3\xa8res - Champex - Chamonix - was added in 2014.\n\nLa Petite Trotte \xc3\xa0 L\xc3\xa9on is a non-competitive team event started in 2011. Each team is made of two or three members for safety. The route and direction of the course change every year. In 2015 it was run counter clock-wise.\n\n### Content  \nToday, the races consist of the following;\n\nUTMB: Ultra-Trail du Mont-Blanc (166 km +9,600 m)  \nCCC: Courmayeur - Champex - Chamonix (101 km +6,100 m)  \nTDS: Sur les Traces des Ducs de Savoie (119 km +7,250 m)  \nOCC: Orsi\xc3\xa8res - Champex - Chamonix (53 km +3,300 m)  \nPTL: La Petite Trotte \xc3\xa0 L\xc3\xa9on (approx. 300 km +28,000 m)  \nMCC: De Martigny-Combe \xc3\xa0 Chamonix (40 km +2,300 m)  \nYCC: Youth Chamonix Courmayeur (15 km +1,100 m)  \n\nThe Data set contains the list of runners who did the event(except for 2003). \n\n(source: wikipedia)'","b""['internet', 'sports', 'world', 'running', 'small', 'featured']""",https://www.kaggle.com/ceruleansea/ultratrail-du-montblanc-20032017
b'Portland Oregon Crime Data',"b'By Year, Event, and Location'","b""### Content\n\nThe contents of this data set comes from public data available on the city of Portland website. Each individual crime reported is lists the location, time and date of the incident as well as a the neighborhood in which the event occurred.  \n\nAll data prior to 2015 has the same general format but the newer 2015-17 data needs to be reformatted for easier comparison since it does not match the older organizational scheme.  To this end I will be adding new .csv with 2015 , 2016, and 2017 YTD data broken out.  Coordinate data will also be added to make the data sets more easily comparable and mappable.\n\n*Update:  I created new .csv for each year 2015-2017 changing the formatting from the Portland Police Department's tab separated values to the standard comma separated values.  The pre-2015 data still isn't comparable because of the differences in the crime categorization but I will work creating some sort of key so that the full data set can be analyzed as a single batch of information.* \n\n\n### Acknowledgements\n\nBanner image by Zack Spear on Unsplash.\n\nAll data gathered from [portlandoregon.gov](https://www.portlandoregon.gov/police/71978) and [civicapps.org](http://civicapps.org/datasets/)""","b""['crime', 'small', 'featured']""",https://www.kaggle.com/katzwigmore/portland-oregon-crime-data
b'Low Resolution Range based Face Databas',b'Acquired by a Creative Senz3D',"b'### Context\n\nFace database composed by a set of range images acquired by the latest generation of range / depth cameras: the Creative Senz3D. \n\n### Content\n\nThe database is composed by the faces of 18 people, acquired from different poses: frontal, lateral, etc. Faces have been acquired with and without glasses. The database is structured in different folders as: \n\n* /01: person with identifier 01.\n  * /01/test:  images for testing the person with identifier 01.\n    * /01/test/01_009.png, ..., 03_096.png, ...: images starting with the same identifier as the root folder (01 in this case) are the true/positive samples, while the others are the false/negative samples.\n  * /01/train: images for training the person with identifier 01.\n    * /01/train/01_034.png, ..., 05_g_168.png, ...: images starting with the same identifier as the root folder (01 in this case= are the true/positive samples, while the others are the false/negative samples.\n* /02 \n* /03 \n* /04\n* /04_g: same person as /04, but with glasses.\n* /05\n* ...\n* /18\n\nEvery root folder (01, 02, ...) contains the depth images of one person. The folder name is the identifier of the person (for example 01, 02, etc.). Inside every root folder, there are two sub-folders: test (for testing purposes) and train (for training purposes).'","b""['image data', 'computer science', 'object recognition', 'human-computer interaction', 'medium', 'featured']""",https://www.kaggle.com/gti-upm/lrrfaced
b'Raman spectroscopy of Diabetes',b'Raman Spectroscopy to Screen Diabetes Mellitus with Machine Learning Tools',"b'### Context\n\nThis is the dataset of our work where the application of portable Raman spectroscopy coupled with several supervised machine-learning techniques, is used to discern between diabetic patients (DM2) and healthy controls (Ctrl), with a high degree of accuracy.\n\n### Content\n\nThe 4 CSV files contain the average of  five Raman spectroscopy scans at 12 cm-1 resolution collected at different skin sites, such as the left earlobe, left inner arm, left thumbnail and left median cubital vein, with approximately 15 s total exposure time.  \nPlease download code to read and plot the data from: [https://github.com/guevaracodina/raman-diabetes][1]\n\n### Acknowledgements\nPlease cite:\nGuevara, E., Torres-Galv\xc3\xa1n, J. C., Ram\xc3\xadrez-El\xc3\xadas, M. G., Luevano-Contreras, C., & Gonz\xc3\xa1lez, F. J. (2018). Use of Raman spectroscopy to screen diabetes mellitus with machine learning tools. Biomedical Optics Express, 9(10), 4998\xe2\x80\x935010. https://doi.org/10.1364/BOE.9.004998\n\n_______________________________________________________________________________\nCopyright (C) 2018 Edgar Guevara, PhD\nCONACYT-Universidad Aut\xc3\xb3noma de San Luis Potos\xc3\xad\nCoordinaci\xc3\xb3n para la Innovaci\xc3\xb3n y Aplicaci\xc3\xb3n de la Ciencia y la Tecnolog\xc3\xada\n_______________________________________________________________________________\n\n\n### Inspiration\n\nCan you improve our results? 88.9-90.9% accuracy using artificial neural networks and 76.0-82.5% using PCA-SVM\n\n\n  [1]: https://github.com/guevaracodina/raman-diabetes'","b""['classification', 'healthcare', 'health', 'medicine', 'nutrition', 'small', 'featured']""",https://www.kaggle.com/codina/raman-spectroscopy-of-diabetes
"b""LabelMe - Let's Eat! Labeled images of meals""",b'A curated subset of the LabelMe project with labeled images of table settings',"b'### Context\n\nThe [LabelMe][1] project has been run out of MIT for many years, and allows users to upload and annotate images. Since the labels are crowdsourced, they can be of poor quality. I have been proofreading these labels for several months, correcting spelling mistakes and coalescing similar labels into a single label when possible. I have also rejected many labels that did not seem to make sense.\n\n\n### Content\n\nThe images in the LabelMe project as well as the raw metadata were downloaded from MIT servers. All data is in the public domain. Images within LabelMe may have been taken as far back as the early 2000s, and run up to the present day.\n\nI have worked through 5% of the LabelMe dataset thus far. I decided to create a dataset pertaining to meals (labels such as plate, glass, napkins, fork, etc.) since there were a fair number of those in the 5% I have curated thus far. Most of the images in this dataset are of table settings.\n\nThis dataset contains:\n596 unique images\n2734 labeled shapes outlining objects in these images\n1782 labeled image grids, with a single number representing which portion of a grid cell is filled with a labeled object\n\n\n### Acknowledgements\n\nMany thanks to the [people of the LabelMe project!][2]\n\n\n### Inspiration\n\nI want to see how valuable my curation efforts have been for the LabelMe dataset. I would like to see others build object recognition models using this dataset.\n\n\n  [1]: http://labelme.csail.mit.edu/Release3.0/\n  [2]: http://labelme2.csail.mit.edu/Release3.0/browserTools/php/credits.php'","b""['food and drink', 'image data', 'multiclass classification', 'small', 'featured']""",https://www.kaggle.com/jackcosgrove/labelme-lets-eat
b'NY City Record Online',b'From New York City Open Data',"b""### Content  \n\nThe City Record Online (CROL) is now a fully searchable database of notices published in the City Record newspaper which includes but is not limited to: public hearings and meetings, public auctions and sales, solicitations and awards and official rules proposed and adopted by city agencies.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/P3sLerH3UmM) by [Jay Clark](https://unsplash.com/@jayclark) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/ny-city-record-online
b'NYS Design & Construction Vendor Payments',b'From New York State Open Data',"b""### Content  \n\nThis dataset provides the public with the value of individual payments made to vendors for Professional Services or Construction contacts, by State Contract number.  Data includes individual payments recorded in the specified time frame to vendors for the County in which the work was performed. Statewide payments are also included that are not County specific.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Sk-C-om9Jz8) by [Dayne Topkin](https://unsplash.com/@dtopkin1) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'utility', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-design-construction-vendor-payments
b'NY Multiple Dwelling Registrations',b'From New York City Open Data',"b""### Content  \n\nPursuant to New York City\xe2\x80\x99s Housing Maintenance Code, the Department of Housing \nPreservation and Development (HPD) collects registration information from owners of \nresidential rental units. Owners are required to register if they own residential buildings \nwith three or more units or if they own one- or two-family homes and neither they nor \nmembers of their immediate family live there. Registrations are required upon taking \nownership of a qualifying building, and once a year thereafter.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/o7LDdRDIYiY) by [Christian Regg](https://unsplash.com/@chris_regg) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-multiple-dwelling-registrations
b'DSL Corpus Collection (DSLCC)',b'Multilingual collection of short excerpts of journalistic texts',"b'This is a mirror of the data from original source of the DSLCC at http://ttg.uni-saarland.de/resources/DSLCC/\n\n----\n\n### DSL Corpus Collection (DSLCC).\n\nThe DSLCC is a multilingual collection of short excerpts of journalistic texts. It has been used as the main data set for the DSL shared tasks organized within the scope of the workshop on NLP for Similar languages, Varieties and Dialects (VarDial). For more information, please check the DSL shared task reports (links below) or the website of past editions of VarDial workshop: VarDial 2017 at EACL, VarDial 2016 at COLING, LT4VarDial 2015 at RANLP, and VarDial 2014 at COLING.\n\nSo far, five versions of the DSLCC have been released. Languages included in each version of the DSLCC grouped by similarity are the table below. Click on the respective version to download the dataset.\n\n<center><img src=""https://ibin.co/3i0ehLHlQXng.png"" width=""700"" height=""500""/></center>\n\n\n### Citing the Dataset\n\nIf you used the dataset we kindly ask you to refer to the corpus description paper where you can also find more information about the DSLCC:\n\nLiling Tan, Marcos Zampieri, Nikola Ljube\xc5\xa1i\xc4\x87, J\xc3\xb6rg Tiedemann (2014) Merging Comparable Data Sources for the Discrimination of Similar Languages: The DSL Corpus Collection. Proceedings of the 7th Workshop on Building and Using Comparable Corpora (BUCC). pp. 6-10. Reykjavik, Iceland. [pdf](http://ttg.uni-saarland.de/resources/DSLCC/papers/bucc2014.pdf)  [bib](http://ttg.uni-saarland.de/resources/DSLCC/papers/dslcc.bib)\n\n### The DSL Reports\n\nFor the results obtained by the participants of the four editions of the DSL shared task, please see the shared task reports below. In 2017, the DSL shared task was part of the VarDial evaluation campaign.\n\n2017 - Marcos Zampieri, Shervin Malmasi, Nikola Ljube\xc5\xa1i\xc4\x87, Preslav Nakov, Ahmed Ali, J\xc3\xb6rg Tiedemann, Yves Scherrer, No\xc3\xabmi Aepli (2017) Findings of the VarDial Evaluation Campaign 2017. Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial). pp. 1-15. Valencia, Spain. [pdf](http://web.science.mq.edu.au/~smalmasi/vardial4/pdf/VarDial01.pdf)  [bib](http://ttg.uni-saarland.de/resources/DSLCC/vardial2017.bib)\n\n2016 - Shervin Malmasi, Marcos Zampieri, Nikola Ljube\xc5\xa1i\xc4\x87, Preslav Nakov, Ahmed Ali, J\xc3\xb6rg Tiedemann (2016) Discriminating between Similar Languages and Arabic Dialect Identification: A Report on the Third DSL Shared Task. Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial). pp. 1-14. Osaka, Japan. [pdf](http://aclweb.org/anthology/W/W16/W16-4801.pdf)  [bib](http://aclweb.org/anthology/W/W16/W16-4801.bib)\n\n2015 - Marcos Zampieri, Liling Tan, Nikola Ljube\xc5\xa1i\xc4\x87, J\xc3\xb6rg Tiedemann, Preslav Nakov (2015) Overview of the DSL Shared Task 2015. Proceedings of the Joint Workshop on Language Technology for Closely Related Languages, Varieties and Dialects (LT4VarDial). pp. 1-9. Hissar, Bulgaria. [pdf](http://aclweb.org/anthology/W/W15/W15-5401.pdf) [bib](http://aclweb.org/anthology/W/W15/W15-5401.bib)\n\n2014 - Marcos Zampieri, Liling Tan, Nikola Ljube\xc5\xa1i\xc4\x87, J\xc3\xb6rg Tiedemann (2014) A Report on the DSL Shared Task 2014. Proceedings of the 1st Workshop on Applying NLP Tools to Similar Languages, Varieties and Dialects (VarDial). pp. 58-67. Dublin, Ireland. [pdf](http://aclweb.org/anthology/W/W14/W14-5307.pdf) [bib](http://aclweb.org/anthology/W/W14/W14-5307.bib)\n\n### Additional Datasets\n\nThe following datasets have been used in other shared tasks organized within the scope of the VarDial workshop.\n\n[Arabic Dialect Identification (ADI)](http://alt.qcri.org/resources/ArabicDialectIDCorpus/varDial_DSL_shared_task_2016_subtask2/): A dataset containing four Arabic dialects: Egyptian, Gulf, Levantine, North African, and MSA.\n\n[German Dialect Identification (GDI)](http://www.spur.uzh.ch/en/departments/korpuslab/ArchiMob.html): The ArchiMob corpus containing Swiss German dialects from Basel, Bern, Lucerne, and Zurich.\n\n[Cross-lingual Parsing (CLP)](https://bitbucket.org/hy-crossNLP/vardial2017): Datasets for parsing similar languages: Croatian - Slovenian, Slovak - Czech, Norwegian - Danish and Swedish.\n\n\n### Acknowledgements\n\nCredits of the datasets goes to the original data creators and the VarDial workshop organizers.\n\nCredits of the banner image goest to [G. Crescoli on Unsplash](https://unsplash.com/photos/bSlHKWxxXak)\n\n\n  [1]: http://'","b""['linguistics', 'languages', 'medium', 'featured']""",https://www.kaggle.com/vardial/dslcc
b'NYS Total Income And Tax Liability',b'From New York State Open Data',"b""### Content  \n\nThe Department of Taxation and Finance annually produces a data (study) file and provides a report of statistical information on New York State personal income tax returns that were timely filed. Timely filing means that the tax return was delivered to the Department on or before the due date of the tax return.  The data are from full-year resident, full-year nonresident, and part-year resident returns. This dataset defines individuals filing a resident tax return as full-year residents and individuals filing a nonresident tax return are defined as either a full- year nonresident or a part-year resident.Data presented in this dataset provide the major income tax structure components by size of income.  The components include income, deductions, dependent exemptions, and tax liability. The data also provides this information by size of income and by the filer\xe2\x80\x99s permanent place of residence (county, state or country).  For a more detailed explanation on the determination of residency and components of income see the attachment: NYSTF_PlaceOfResidence_Introduction.Researchers agree to: Use the data for statistical reporting an analysis only. The author will include a disclaimer that states any analyses, interpretations or conclusions were reached by the author and not the New York State Department of Taxation and Finance.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/FumjLlfuvhg) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'income', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-total-income-and-tax-liability
b'NYS Empire Zones Business Annual Reports',b'From New York State Open Data',"b""### Content  \n\nEmployment, investment and tax credit information reported by businesses certified in the Empire Zones Program.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/sD_o5hGKBeE) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-empire-zones-business-annual-reports
b'LA Dept of City Planning Filed and Completed Cases',b'From Los Angeles Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/7OPCH05vzxE) by [Daniel Chen](https://unsplash.com/@d_che) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: NA, Creative Commons 1.0 Universal (Public Domain Dedication)""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/la-dept-of-city-planning-filed-and-completed-cases
b'Thrinaxodon and Broomistega 3D CT',b'Early Triassic Odd Couple: Injured Amphibian and Therapsid Share Burrow',"b'\n### Content\n\nfossil burrow aged of 250 million years from the Karoo basin in South Africa. It contains two skeletons in anatomical connection: the mammalian reptile Thrinaxodon and the amphibian temnospondyl Broomistega. The samples were scanned with X-ray computed tomography at the ESRF syncortron facility in Grenoble, France. The resolution of the raw original data was an isotropic 45.5 microns but the data has been binned to a resolution of 91 microns.\n\n\n### Acknowledgements\n\nThe data are from the PLoSOne Paper http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0064978 titled: Synchrotron Reveals Early Triassic Odd Couple: Injured Amphibian and Aestivating Therapsid Share Burrow. The data are not for commercial use and original authors should be contacted before redistribution.\n\n### Inspiration\n\nTry and build algorithms to automatically segment the fossils and possibly identify different organs and structures inside of them'","b""['image data', 'large', 'featured']""",https://www.kaggle.com/kmader/thrinaxodon-and-broomistega-3d-ct
"b'Face Dataset with Age, Emotion, Ethnicity'","b'An image bounding box dataset with faces marked with emotions, ethnicity, age '","b""### Context\n\nVisualize and browse the dataset below:\n\nhttps://dataturks.com/projects/Mohan/Face%20Dataset%20With%20Emotion_Age_Ethnicity\n\n![enter image description here][1]\n\n\n\n### Content\n\nThe images are market with 4 sets of labels:\n\n 1. Age Range\n 2. Ethnicity\n 3. Gender\n 4. Face emotion\n\nLabel distribution:\n\n![enter image description here][2]\n\nExamples:\n\n![enter image description here][3]\n\n![enter image description here][4]\n\n### Acknowledgements\n\nHere is the original source:\n https://dataturks.com/projects/Mohan/Face%20Dataset%20With%20Emotion_Age_Ethnicity\n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?\n\n\n  [1]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/website/face_emotion.png\n  [2]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/website/face_labels.png\n  [3]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/website/face_emotion_ex1.png\n  [4]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/website/face_emotion_ex_2.png""","b""['image data', 'object detection', 'object segmentation', 'object recognition', 'small', 'featured']""",https://www.kaggle.com/dataturks/face-dataset-with-age-emotion-ethnicity
b'Urban Sound Classification',b'8732 labeled sound excerpts of urban sounds from 10 classes',"b""### Context\n\nThe automatic classification of environmental sound is a growing research field with multiple applications to largescale, content-based multimedia indexing and retrieval. In particular, the sonic analysis of urban environments is the subject of increased interest, partly enabled by multimedia sensor networks, as well as by large quantities of online multimedia content depicting urban scenes.\n\nHowever, while there is a large body of research in related areas such as speech, music and bioacoustics, work on the analysis of urban acoustic environments is relatively scarce.Furthermore, when existent, it mostly focuses on the classification of auditory scene type, e.g. street, park, as opposed to the identification of sound sources in those scenes, e.g.car horn, engine idling, bird tweet. \n\nThere are primarily two major challenges with urban sound research namely\n\n- Lack of labeled audio data. Previous work has focused on audio from carefully produced movies or television tracks from specific environments such as elevators or office spaces and on commercial or proprietary datasets . The large effort involved in manually annotating real-world data means datasets based on field recordings tend to be relatively small (e.g. the event detection dataset of the IEEE AASP Challenge consists of 24 recordings per each of 17 classes).\n\n- Lack of common vocabulary when working on urban sounds.This means the classification of sounds into semantic groups may vary from study to study, making it hard to compare results\nso the objective of this notebook is to address the above two mentioned challenges.\n\n\n### Content\n\nThe dataset is called UrbanSound and contains 8732 labeled sound excerpts (&lt;=4s) of urban sounds from 10 classes: - The dataset contains 8732 sound excerpts (&lt;=4s) of urban sounds from 10 classes, namely:\nAir Conditioner\nCar Horn\nChildren Playing\nDog bark\nDrilling\nEngine Idling\nGun Shot\nJackhammer\nSiren\nStreet Music\nThe attributes of data are as follows:\nID \xe2\x80\x93 Unique ID of sound excerpt\nClass \xe2\x80\x93 type of sound\n\n\n### Acknowledgements\n\nSource of the dataset : https://drive.google.com/drive/folders/0By0bAi7hOBAFUHVXd1JCN3MwTEU\n\nSource of research document : https://serv.cusp.nyu.edu/projects/urbansounddataset/salamon_urbansound_acmmm14.pdf\n\nBanner image by [@hannynaibaho from Unsplash][1].\n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?\n\n\n  [1]: https://unsplash.com/photos/OH2SslaiaIQ""","b""['music', 'sound technology', 'large', 'featured']""",https://www.kaggle.com/pavansanagapati/urban-sound-classification
b'Unicode 10.0 Character Database in JSON',b'Machine-readable information on Unicode 10.0 Characters',"b'### Context: \n\nIn working on Unicode implementations, it is often useful to access the full content of the Unicode Character Database (UCD). For example, in establishing mappings from characters to glyphs in fonts, it is convenient to see the character scalar value, the character name, the character East Asian width, along with the shape and metrics of the proposed glyph to map to; looking at all this data simultaneously helps in evaluating the mapping.\n\nThis is a machine-readable version of the Unicode Character Database in JSON format.\n\n### Content:\n\nThe majority of information about individual codepoints is represented using properties. Each property, except for the Special_Case_Condition and Name_Alias properties, is represented by an attribute. In an XML data file, the absence of an attribute (may be only on some code-points) means that the document does not express the value of the corresponding property. Conversely, the presence of an attribute is an expression of the corresponding property value; the implied null value is represented by the empty string.\n \nThe Name_Alias property is represented by zero or more name-alias child elements. Unlike the situation for properties represented by attributes, it is not possible to determine whether all of the aliases have been represented in a data file by inspecting that data file.\n \nThe name of an attribute is the abbreviated name of the property as given in the file PropertyAliases.txt in version 6.1.0 of the UCD. For the Unihan properties, the name is that given in the various versions of the Unihan database (some properties are no longer present in version 6.1.0).\n \nFor catalog and enumerated properties, the values are those listed in the file PropertyValueAliases.txt in version 6.1.0 of the UCD; if there is an abbreviated name, it is used, otherwise the long name is used.\nNote that the set of possible values for a property captured in this schema may change from one version to the next.\n\nThe following properties are associated with code points:\n\n*     Age property\n*     Name properties\n*     Name Aliases\n*     Block\n*     General Category\n*     Combining properties\n*     Bidirectionality properties\n*     Decomposition properties\n*     Numeric Properties\n*     Joining properties\n*     Linebreak properties\n*     East Asian Width property\n*     Case properties\n*     Script properties\n*     ISO Comment properties\n*     Hangul properties\n*     Indic properties\n*     Identifier and Pattern and programming language properties\n*     Properties related to function and graphic characteristics\n*     Properties related to boundaries\n*     Properties related to ideographs\n*     Miscellaneous properties\n*     Unihan properties\n*     Tangut data\n*     Nushu data\n\nFor additional information, [please consult the full documentation on the Unicode website](https://www.unicode.org/reports/tr42/).\n\n### Acknowledgements: \n\nCopyright \xc2\xa9 1991-2017 Unicode, Inc. All rights reserved. Distributed under the Terms of Use in http://www.unicode.org/copyright.html.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of the Unicode data files and any associated documentation (the ""Data Files"") or Unicode software and any associated documentation\n(the ""Software"") to deal in the Data Files or Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, and/or sell copies of the Data Files or Software, and to permit persons to whom the Data Files or Software are furnished to do so, provided that either\n(a) this copyright and permission notice appear with all copies of the Data Files or Software, or\n(b) this copyright and permission notice appear in associated Documentation.\n'","b""['linguistics', 'languages', 'writing', 'medium', 'featured']""",https://www.kaggle.com/rtatman/unicode-100-character-database-in-json
b'Google Job Skills',b'Find what you need to get a job at Google ',"b'### Context\n\nThere is a question in our mind that which language, skills, and experience should we add to our toolbox for getting a job in Google. Well, I think why not we find out the answer by analyzing the Google Jobs Site. Google published all of their jobs at https://careers.google.com/. So I scraped all of the job data from that site by going every job page using Selenium. I only take Job Title, Job Location, Job responsibilities, minimum and preferred qualifications for this dataset. \n\n\n### Content\n\nThis dataset is collected using Selenium by scraping all of the jobs text for [Google Career site][1]. \nAbout the column\n\n**Title:** The title of the job\n\n**Category:** Category of the job\n\n**Location:** Location of the job\n\n**Responsibilities:** Responsibilities for the job\n\n**Minimum Qualifications:** Minimum Qualifications for the job\n\n**Preferred Qualifications:** Preferred Qualifications for the job\n\n\n### Acknowledgements\n\nThis dataset is collected using Selenium. This product uses the [Google Career site][2] but is not endorsed or certified by [Google Career site][3]. \n\n### Inspiration\n\n - You can find most popular skills for Google Jobs\n - Create identical job posts\n - Most popular languages\n - etc\n\n\n  [1]: https://careers.google.com/\n  [2]: https://careers.google.com/\n  [3]: https://careers.google.com/'","b""['internet', 'databases', 'learning', 'small', 'featured']""",https://www.kaggle.com/niyamatalmass/google-job-skills
b'Chicago Public Passenger Vehicle Licenses',b'From City of Chicago Open Data',"b""### Content  \n\nA public passenger vehicle is a vehicle used for the transportation of passengers for hire by a public chauffeur. The list of public passenger vehicles includes licensed taxicabs (medallions), liveries, ambulances, medicars, charter-sightseeing buses, horse-drawn carriages, and pedicabs. For more information, please see http://www.cityofchicago.org/city/en/depts/bacp/supp_info/bacppublicvehicles.html.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/0wB7Hjcs9TM) by [Dawid Zawila](https://unsplash.com/@davealmine) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'vehicles', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-public-passenger-vehicle-licenses
b'OECD Better Life Index 2017',b'Cleaned dataset for the 2017 OECD Better Life Index',"b""### Content\n\nThis is the Better Life Index for 2017 gathered from the OECD stats page. Grouping labels have been removed and the row for units of measurment for each column has been removed with the units added to the end of each column label as such: (Percentage: 'as pct'; Ratio: 'as rat'; US Dollar: 'in usd'; Average score: 'as avg score'; Years: 'in years'; Micrograms per cubic metre: 'in ugm3'; Hours: 'in hrs'). Also, although included in the report, Brazil, Russia, and South Africa are non-OECD economies at the time of reporting\n\n### Acknowledgements\n\nOECD stats page\nFor full index and others please visit: http://stats.oecd.org/Index.aspx?DataSetCode=BLI""","b""['demographics', 'politics', 'international relations', 'small', 'featured']""",https://www.kaggle.com/jej13b/oecd-better-life-index
"b""Value of Manufacturers' Shipments Data Collection""",b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/wsVFxYDFa9k) by [Alex Ronsdorf](https://unsplash.com/@alex13) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/value-of-manufacturers'-shipments-data-collection
b'Total Construction Spending Data Collection',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/w1DnsX50XHw) by [chuttersnap](https://unsplash.com/@chuttersnap) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'utility', 'small', 'featured']""",https://www.kaggle.com/census/total-construction-spending-data-collection
b'Synthetic Digits',b'Synthetically generated images of English digits embedded on random backgrounds.',"b'### Context\n\nSynthetic digits with noisy backgrounds for testing robustness of classification algorithms.\n\n----------\n\n### Content\nThis dataset contains 12,000 synthetically generated images of English digits embedded on random backgrounds. The images are generated with varying fonts, colors, scales and rotations. The backgrounds are randomly selected from a [***subset***][3] of [***COCO***][4] dataset.\n\n----------\n\n### Acknowledgements\n@article{roy2018effects, <br>\ntitle={Effects of Degradations on Deep Neural Network Architectures}, <br>\nauthor={Roy, Prasun and Ghosh, Subhankar and Bhattacharya, Saumik and Pal, Umapada}, <br>\njournal={arXiv preprint arXiv:1807.10108}, <br>\nyear={2018} <br>\n}\n\nThis dataset is created as a benchmark dataset for the work on [***Effects of Degradations on Deep Neural Network Architectures***][1]. <br>\nThe source code is publicly available on [***GitHub***][2].\n\n[1]: https://arxiv.org/abs/1807.10108\n[2]: https://github.com/prasunroy/cnn-on-degraded-images\n[3]: http://images.cocodataset.org/zips/val2017.zip\n[4]: http://cocodataset.org\n'","b""['classification', 'deep learning', 'image data', 'multiclass classification', 'medium', 'featured']""",https://www.kaggle.com/prasunroy/synthetic-digits
b'Anthony Fantano Reviews',"b""The Internet's busiest music nerd's reviews""","b'### Context\n\nAnthony Fantano aka theneedledrop aka ""Internet\'s busiest music nerd"" is one of the biggest music reviewers on YouTube. This data compiles all of his Album and EP reviews into a csv file.\n\n### Content\n\nThe data was acquired straight from Fantano\'s youtube channel and contains information such as album title, album artist, fave tracks, worst track and score. \n\nAnother table contains the auto-generated captions that play during his videos.\n\n### Acknowledgements\n\nIf you\'d like to check his channel out, click [here](https://www.youtube.com/channel/UCt7fwAhXDy3oNFTAzF2o8Pw).\n\n### Mistakes\nThis data is updated regularly so if you find a mistake please post something in the discussions so I can fix it for future versions. Thanks!'","b""['music', 'musicians', 'small', 'featured']""",https://www.kaggle.com/jaredarcilla/anthony-fantano-reviews
"b""Value of Manufacturers' Unfilled Orders Data""",b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/wnOJ83k8r4w) by [Robin Sommer](https://unsplash.com/@robin_sommer) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/value-of-manufacturers'-unfilled-orders-data
b'Seattle Observed Monthly Rain Gauge Accumulations',b'From City of Seattle Open Data',"b""### Content  \n\nMonthly accumulations for SPU's rain gauges located throughout Seattle city limits.  \n\nAttached in the 'About' section is an image of the rain gauge locations .\n\nDisclaimer:  This data set has been provided by either DNRP or SPU as a public information service. Every reasonable effort has been made to assure the accuracy of this data. However, the data being provided herein are intended for informational purposes only. No guarantee is made as to the accuracy of the data and it should not be relied upon for any purpose other than general information. Furthermore, DNRP and SPU assumes no liability for any errors, omissions, or inaccuracies in the information provided regardless of the cause of such or for any decision made, action taken, or action not taken by the user in reliance upon any data provided herein.\n\nRCW 42.56.060\n\nDisclaimer of public liability.\n\nNo public agency, public official, public employee, or custodian shall be liable, nor shall a cause of action exist, for any loss or damage based upon the release of a public record if the public agency, public official, public employee, or custodian acted in good faith in attempting to comply with the provisions of this chapter.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/VR0s3Yqm2RA) by [Mario Calvo](https://unsplash.com/@mariocalvo) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'weather', 'environment', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-observed-monthly-rain-gauge-accumulations
b'Honeybees and Neonic Pesticides',b'Are Neonic pesticides connected to decline of honeybee colonies?',"b'### Context\n\nThis dataset is inspired by [Honey Production in the USA][1], extended to the period 1998-2017.  Plus, I joined data from USGS\'s Pesticide National Synthesis Project, allowing evaluation of the statistical connections between Honey Production and the use of Neonicotinoid (neonic) pesticides.\n\nThe data will show some interesting facts:\n\xe2\x80\xa2\tNeonic use in the USA began around 2003, but honey production declines started in earlier years.\n\xe2\x80\xa2\tSome states, such as Kansas, have seen devastation in the bee colonies starting around 2003, just neonic usage began.  \n\xe2\x80\xa2\tOther states such as North Dakota, have approximately stable numbers of bee colonies, despite increased use of neonics \n  \n### Content\nYou browse the data here:[Honeybee Data][2].  Play with the variables to find the patterns.\n\n[from Honey Production in the USA] : \nThe National Agricultural Statistics Service (NASS) is the primary data reporting body for the US Department of Agriculture (USDA). NASS\'s mission is to ""provide timely, accurate, and useful statistics in service to U.S. agriculture"". From datasets to census surveys, their data covers virtually all aspects of U.S. agriculture. Honey production is one of the datasets offered. Click here for the original page containing the data along with related datasets such as Honey Bee Colonies and Cost of Pollination. Data wrangling was performed in order to clean the dataset. \n\n[from USGS] : https://water.usgs.gov/nawqa/pnsp/usage/maps/county-level/\nThe USGS data is collected at the county level, by state, by year.  First we restrict the data to include only neonics: Acetamiprid, Clothianidin, Imidacloprid, Nitenpyram, Nithiazine, Thiacloprid and Thiamethoxam.  Next we summarize it to the state level to match the structure of ""Honey Production in the USA"".  \n\n[US Census, by hand]\nI joined a U.S. Census definition of Region to assist grouping the states: South, West, Midwest and Northeast.\n\nFrom USDA data\n\n\xe2\x80\xa2    numcol: Number of honey producing colonies. Honey producing colonies are the maximum number of colonies from which honey was taken during the year. It is possible to take honey from colonies which did not survive the entire year\n\n\xe2\x80\xa2    yieldpercol: Honey yield per colony. Unit is pounds\n\n\xe2\x80\xa2    totalprod: Total production (numcol x yieldpercol). Unit is pounds\n\n\xe2\x80\xa2    stocks: Refers to stocks held by producers. Unit is pounds\n\n\xe2\x80\xa2    priceperlb: Refers to average price per pound based on expanded sales. Unit is dollars.\n\n\xe2\x80\xa2    prodvalue: Value of production (totalprod x priceperlb). Unit is dollars.\n\nFrom USGS Data\n\n\xe2\x80\xa2    nCLOTHIANIDIN: The amount in kg of CLOTHIANIDIN applied\n\n\xe2\x80\xa2    nIMIDACLOPRID: The amount in kg of IMIDACLOPRID applied\n\n\xe2\x80\xa2    nTHIAMETHOXAM: The amount in kg of THIAMETHOXAM applied\n\n\xe2\x80\xa2    nACETAMIPRID: The amount in kg of ACETAMIPRID applied\n\n\xe2\x80\xa2    nTHIACLOPRID: The amount in kg of THIACLOPRID applied\n\n\xe2\x80\xa2    nAllNeonic: The amount in kg of all Neonics applied = (nCLOTHIANIDIN + nIMIDACLOPRID + nTHIAMETHOXAM + nACETAMIPRID + nTHIACLOPRID)\n\n\n### Acknowledgements\n\nThanks to ""Honey Production in the USA"" (Jessica Li).  That\'s a great dataset, and an important idea.\n\nThanks to USDA for collecting the Honey Production Data.\n\nThanks to USGA for collecting very detailed information on pesiticide use.\n\nPhoto Credit to:\nBy linsepatron - https://www.flickr.com/photos/43706167@N03/9246372685/, CC BY 2.0, https://commons.wikimedia.org/w/index.php?curid=33789122\n\n### Inspiration\n\nHoneybees are such hard workers!  They need our help!\n\n - The effect of neonics needs to be understood more deeply.\n - Why do neonics seem to cause such grave harm in some places (e.g. North Dakota) but not so much other places?\n\n\n  [1]: https://www.kaggle.com/jessicali9530/honey-production\n  [2]: http://numbergo.net/NumberGoPublisher/Admin/Account/GuestLogin?token=663bae88-829e-4335-a87a-b04547d6d177 ""Honeybee Data""\n  [3]: http://numbergo.net/NumberGoPublisher/Admin/Account/GuestLogin?token=aa8bd69b-569e-4699-88aa-8541e100a883'","b""['animals', 'environment', 'agriculture', 'natural resources', 'small', 'featured']""",https://www.kaggle.com/kevinzmith/honey-with-neonic-pesticide
b'OpenAddresses - South America',b'Addresses and geolocations for South American countries',"b""### Context\n\nOpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates, street names, house numbers and postal codes. \n\n### Content\n\nThis dataset contains one data file for each of these countries:\n\n* Argentina - argentina.csv\n* Brazil - brazil.csv\n* Chile - chile.csv\n* Columbia - columbia.csv\n* Uraguay - uraguay.csv\n\n\nField descriptions:\n\n* LON - Longitude\n* LAT - Latitude\n* NUMBER - Street number\n* STREET - Street name\n* UNIT - Unit or apartment number\n* CITY - City name\n* DISTRICT - ?\n* REGION - ?\n* POSTCODE - Postcode or zipcode\n* ID - ?\n* HASH - ?\n\n\n### Acknowledgements\n\nData collected around 2017-07-25 by OpenAddresses (http://openaddresses.io).\n\nAddress data is essential infrastructure. Street names, house numbers and\npostal codes, when combined with geographic coordinates, are the hub that\nconnects digital to physical places.\n\nData licenses can be found in LICENSE.txt.\n\nData source information can be found at\nhttps://github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources\n\n\n### Inspiration\n\nUse this dataset to create maps in conjunction with other datasets to map weather, crime, or plan your next canoeing trip.""","b""['internet', 'cities', 'large', 'featured']""",https://www.kaggle.com/openaddresses/openaddresses-south-america
b'350 000+ movies from themoviedb.org',b'More than 350k movies and main casting/crew up to Aug17',"b'### Context\n\nI love movies.\xc2\xa0\n\nI tend to avoid marvel-transformers-standardized products, and prefer a mix of classic hollywood-golden-age and obscure polish artsy movies. Throw in an occasional japanese-zombie-slasher-giallo as an alibi. Good movies don\'t exist without bad movies.\xc2\xa0\n\nOn average I watch 200+ movies each year, with peaks at more than 500 movies. Nine years ago I started to log my movies to avoid watching the same movie twice, and also assign scores. Over the years, it gave me a couple insights on my viewing habits but nothing more than what a tenth-grader would learn at school.\xc2\xa0\n\nI\'ve recently suscribed to Netflix and it pains me to see the global inefficiency of recommendation systems for people like me, who mostly swear by ""La politique des auteurs"". It\'s a term coined by famous new-wave french movie critic Andr\xc3\xa9 Bazin, meaning that the quality of a movie is essentially linked to the director and it\'s capacity to execute his vision with his crew. We could debate it depends on movie production pipeline, but let\'s not for now. Practically, what it means, is that I essentially watch movies from directors who made films I\'ve liked. \n\nI suspect Neflix calibrate their recommandation models taking into account the way the ""average-joe"" chooses a movie. A few months ago I had read a study based on a survey, showing that people chose a movie mostly based on genre (55%), then by leading actors (45%). Director or Release Date were far behind around 10% each. It is not surprising, since most people I know don\'t care who the director is. Lots of US blockbusters don\'t even mention it on the movie poster. I am aware that collaborative filtering is based on user proximity , which I believe decreases (or even eliminates) the need to characterize a movie. So here I\'m more interested in content based filtering which is based on product proximity for several reasons :\n\n- Users tastes are not easily accessible. It is, after all, Netflix treasure chest\n\n- Movie offer on Netflix is so bad for someone who likes author\'s movies that it wouldn\'t help\n\n- Modeling a movie intrinsic qualities is a nice challenge\n\n\nEnough.\n\n""*The secret of getting ahead is getting started*"" (Mark Twain)\n\n![network graph][1]\n\n### Content\nThe primary source is www.themoviedb.org. If you watch obscure artsy romanian homemade movies you may find only 95% of your movies referenced...but for anyone else it should be in the 98%+ range.\n\n- movies details are from www.themoviedb.org API : movies/details\n\n- movies crew & casting are from www.themoviedb.org API : movies/credits\n\n- both can be joined by id\n\n- they contain all 350k movies up, from end of 19th century to august 2017. If you remove short movies from imdb you get similar amounts of movies.\n\n- I uploaded the program to retrieve incremental movie details on github : https://github.com/stephanerappeneau/scienceofmovies/tree/master/PycharmProjects/GetAllMovies (need a dev API key from themoviedb.org though)\n\n- I have tried various supervised (decision tree) / unsupervised (clustering, NLP) approaches described in the discussions, source code is on github : https://github.com/stephanerappeneau/scienceofmovies\n\n- As a bonus I\'ve uploaded the bio summary from top 500 critically-acclaimed directors from wikipedia, for some interesting NLTK analysis\n\nHere is overview of the available sources that I\'ve tried :\n\n**\xe2\x80\xa2 Imdb.com\xc2\xa0free csv dumps** (ftp://ftp.funet.fi/pub/mirrors/ftp.imdb.com/pub/temporaryaccess/) are badly documented, incomplete, loosely structured and impossible to join/merge. There\'s an API hosted by Amazon Web Service : 1\xe2\x82\xac every 100 000 requests. With around 1 million movies, it could become expensive also features are bare. So I\'ve searched for other sources.\xc2\xa0\n\n**\xe2\x80\xa2 www.themoviedb.org**\xc2\xa0is based on crowdsourcing and has an excellent API, limited to 40 requests every 10 seconds. It is quite generous, well documented, and enough to sweep the 450 000 movies in a few days. For my purpose, data quality is not significantly worse than imdb, and as imdb key is also included there\'s always the possibility to complete my dataset later (I actually did it)\n\n**\xe2\x80\xa2 www.Boxofficemojo.com**\xc2\xa0has some interesting budget/revenue figures (which are sorely lacking in both imdb & tmdb), but it actually tracks only a few thousand movies, mainly blockbusters. There are other professional sources that are used by film industry to get better predictive / marketing insights but that\'s beyond my reach for this experiment.\n\xc2\xa0\n**\xe2\x80\xa2 www.wikipedia.com**\xc2\xa0is an interesting source with no real cap on API calls, however it requires a bit of webscraping and for movies or directors the layout and quality varies a lot, so I suspected it\'d get a lot of work to get insights so I put this source in lower priority.\n\n**\xe2\x80\xa2 www.google.com** will ban you after a few minutes of web scraping because their job is to scrap data from others, than sell it, duh.\n\xc2\xa0\n\xe2\x80\xa2 It\'s worth mentionning that there are a **few dumps of Netflix** anonymized user tastes on kaggle, because they\'ve organised a few competitions to improve their recommendation models. https://www.kaggle.com/netflix-inc/netflix-prize-data\n\n\xe2\x80\xa2 Online databases are largely white anglo-saxon centric, meaning bollywood (India is the 2nd bigger producer of movies) offer is mostly absent from datasets. I\'m fine with that, as it\'s not my cup of tea plus I lack domain knowledge. The sheer amount of indian movies would probably skew my results anyway (I don\'t want to have too many martial-arts-musicals in my recommendations ;-)). I have, however, tremendous respect for indian movie industry so I\'d love to collaborate with an indian cinephile !\n![Westerns][2]\n\n### Inspiration\n\nStarting from there, I had multiple problem statements for both supervised / unsupervised machine learning\n\n- Can I program a tailored-recommendation system based on my own criteria ?\n\n- What are the characteristics of movies/directors I like the most ?\n\n- What is the probability that I will like my next movie ?\n\n- Can I find the data ?\n\nOne of the objectives of sharing my work here is to find cinephile data-scientists who might be interested and, hopefully, contribute or share insights :) Other interesting leads : use tagline for NLP/Clustering/Genre guessing, leverage on budget/revenue, link with other data sources using the imdb normalized title, etc.\n\n![Correlation matrix][3]\n\n### Motivation, Disclaimer and Acknowledgements\n- I\'ve graduated from an french engineering school, majoring in artificial intelligence, but that was 17 years ago right in the middle of A.I-winter. Like a lot of white male rocket scientists, I\'ve ended up in one of the leading european investment bank, quickly abandonning IT development to specialize in trading/risk project management and internal politics. My recent appointment in the Data Office made me aware of recent breakthroughts in datascience, and I thought that developing a side project would be an excellent occasion to learn something new. Plus it\'d give me a well-needed credibility which too often lack decision makers when it comes to datascience.\n\n- I\'ve worked on some of the features with C\xc3\xa9dric Paternotte, a fellow friend of mine who is a professor of philosophy of sciences in La Sorbonne. Working with someone with a different background seem a good idea for motivation, creativity and rigor.\n\n- Kudos to www.themoviedb.org or www.wikipedia.com sites, who really have a great attitude towards open data. This is typically NOT the case of modern-bigdata companies who mostly keep data to themselves to try to monetize it. Such a huge contrast with imdb or instagram API, which generously let you grab your last 3 comments at a miserable rate. Even if 15 years ago this seemed a mandatory path to get services for free, I predict one day governments will need to break this data monopoly.\n\n*[Disclaimer : I apologize in advance for my engrish (I\'m french ^-^), any bad-code I\'ve written (there are probably hundreds of way to do it better and faster), any pseudo-scientific assumption I\'ve made, I\'m slowly getting back in statistics and lack senior guidance, one day I regress a non-stationary time series and the day after I\'ll discover I shouldn\'t have, and any incorrect use of machine-learning models]*\n\n![powered by themoviedb.org][4]\n\n\n  [1]: https://img11.hostingpics.net/pics/117765networkgraph.png\n  [2]: https://img11.hostingpics.net/pics/340226westerns.png\n  [3]: https://img11.hostingpics.net/pics/977004matrice.png\n  [4]: https://img11.hostingpics.net/pics/898068408x161poweredbyrectanglegreen.png'","b""['film', 'arts and entertainment', 'actors', 'medium', 'featured']""",https://www.kaggle.com/stephanerappeneau/350-000-movies-from-themoviedborg
"b""Who's the Boss? People with Significant Control""",b'Snapshot of UK Business Ownership Details',"b""### Context: \nThe People with significant control (PSC) snapshot is a data snapshot containing the full list of PSC's provided to Companies House. The Prime Minister first put corporate transparency on the international agenda when he chaired the G8 summit in Lough Erne and secured commitment to action, the commitment to enhance corporate transparency in the UK was reaffirmed at London\xe2\x80\x99s International Anti-Corruption Summit in May 2016. Since then the EU and G20 countries have also agreed to act. The UK is the first country in the G20 to create a public register of this kind.\n\nThe UK has high standards of business behaviour and corporate governance. The overwhelming majority of UK companies contribute productively to the UK economy, abide by the law and make a valuable contribution to society. But there are exceptions.\nSome of the features of the company structure which make it good for business also make it attractive to criminals. Companies can be misused to facilitate a range of criminal activities - from money laundering to tax evasion, corruption to terrorist financing. Sometimes those individuals running companies will not conduct themselves in accordance with the high standards we expect in the UK, posing a risk to other companies and consumers alike.\n\nInformation about the ownership and control of UK corporate entities will bring benefits for law enforcement, business, civil society and citizens. By making this information publicly available, free of charge, the government is setting a standard that we are persuading other countries to follow.\n\n\n### Content: \nA person of significant control is someone that holds more than 25% of shares or voting rights in a company, has the right to appoint or remove the majority of the board of directors or otherwise exercises significant influence or control. This is a snapshot of data in zipped JSON form, as of Aug 23 2017. Daily updated snapshots and streaming API details can be found [here](http://download.companieshouse.gov.uk/en_pscdata.html). The People with Significant Control (PSC) register includes information about the individuals who own or control companies including their name, month and year of birth, nationality, and details of their interest in the company. From 30 June 2016, UK companies (except listed companies) and limited liability partnerships (LLPs) need to declare this information when issuing their annual confirmation statement to Companies House.\n\n\n### Acknowledgements: \n[Guidance here](https://www.gov.uk/government/publications/guidance-to-the-people-with-significant-control-requirements-for-companies-and-limited-liability-partnerships). The data is collected by UK government.\n\n### Inspiration: \n* Who owns the most businesses? In certain areas?\n* Any weird looking situations where ownership might be obscured?""","b""['business', 'large', 'featured']""",https://www.kaggle.com/jboysen/uk-psc
b'OpenAddresses - U.S. Northeast',b'Addresses and geo locations for the U.S. Northeast',"b""### Context\n\nOpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates, street names, house numbers and postal codes. \n\n### Content\n\nThis dataset contains one datafile for each state in the U.S. Northeast region.\n\nStates included in this dataset:\n\n* Connecticut - ct.csv\n* Massachusetts - ma.csv\n* Maine - me.csv\n* New Hampshite - nh.csv\n* New Jersey - nj.csv\n* New York - ny.csv\n* Pennsylvania - pa.csv\n* Rhode Island - ri.csv\n* Vermont - vt.csv\n\nField descriptions:\n\n* LON - Longitude\n* LAT - Latitude\n* NUMBER - Street number\n* STREET - Street name\n* UNIT - Unit or apartment number\n* CITY - City name\n* DISTRICT - ?\n* REGION - ?\n* POSTCODE - Postcode or zipcode\n* ID - ?\n* HASH - ?\n\n\n### Acknowledgements\n\nData collected around 2017-07-25 by OpenAddresses (http://openaddresses.io).\n\nAddress data is essential infrastructure. Street names, house numbers and\npostal codes, when combined with geographic coordinates, are the hub that\nconnects digital to physical places.\n\nData licenses can be found in LICENSE.txt.\n\nData source information can be found at\nhttps://github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources\n\n\n### Inspiration\n\nUse this dataset to create maps in conjunction with other datasets for crime or weather""","b""['large', 'featured']""",https://www.kaggle.com/openaddresses/openaddresses-us-northeast
b'Pulmonary Chest X-Ray Abnormalities',b'Diagnose tuberculosis and other diseases from x-rays',"b'# Content and context\n\nTuberculosis is a disease that affects many people in developing countries. While treatment is possible, it requires an accurate diagnosis first. In these countries projects there are in many cases available X-ray machines (through low-cost projects and donations), but often the radiological expertise is missing for accurately assessing the images. An algorithm that could perform this task quickly and cheaply could drastically improve the ability to diagnose and ultimately treat the disease.\n\nIn more developed countries, X-ray radiography is often used for screening new arrivals and determining eligibility for a work-permit. The task of manually examining images is time consuming and an algorithm could increase efficiency, improve performance and ultimately reduce cost of this screening. \n\nThis dataset contains over 500 x-rays scans with clinical labels collected by radiologists.\n\n# Acknowledgements\nThe two datasets were published together in an analysis here: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4256233/.\nThe datasets come from Shenzhen and Montgomery respectively.\n\n### China Set - The Shenzhen set - Chest X-ray Database\n\nThe standard digital image database for Tuberculosis is created by the National Library of Medicine, Maryland, USA in collaboration with Shenzhen No.3 People\xe2\x80\x99s Hospital, Guangdong Medical College, Shenzhen, China. The Chest X-rays are from out-patient clinics, and were captured as part of the daily routine using Philips DR Digital Diagnose systems. \nNumber of X-rays: \n\n* 336 cases with manifestation of tuberculosis, and \n* 326 normal cases.\n\nIt is requested that publications resulting from the use of this data attribute the source (National Library of Medicine, National Institutes of Health, Bethesda, MD, USA and Shenzhen No.3 People\xe2\x80\x99s Hospital, Guangdong Medical College, Shenzhen, China) and cite the following publications:  \n\n* Jaeger S, Karargyris A, Candemir S, Folio L, Siegelman J, Callaghan F, Xue Z, Palaniappan K, Singh RK, Antani S, Thoma G, Wang YX, Lu PX, McDonald CJ.  Automatic tuberculosis screening using chest radiographs. IEEE Trans Med Imaging. 2014 Feb;33(2):233-45. doi: 10.1109/TMI.2013.2284099. PMID: 24108713\n* Candemir S, Jaeger S, Palaniappan K, Musco JP, Singh RK, Xue Z, Karargyris A, Antani S, Thoma G, McDonald CJ. Lung segmentation in chest radiographs using anatomical atlases with nonrigid registration. IEEE Trans Med Imaging. 2014 Feb;33(2):577-90. doi: 10.1109/TMI.2013.2290491. PMID: 24239990\n\n### Montgomery County X-ray Set\n\nX-ray images in this data set have been acquired from the tuberculosis control program of the Department of Health and Human Services of Montgomery County, MD, USA. This set contains 138 posterior-anterior x-rays, of which 80 x-rays are normal and 58 x-rays are abnormal with manifestations of tuberculosis. All images are de-identified and available in DICOM format. The set covers a wide range of abnormalities, including effusions and miliary patterns. The data set includes radiology readings available as a text file.\n\n# Ideas\n- Experiment with lung segmentation\n- Build disease classifiers for various conditions\n- Test models on data across different manufacturers \n- Build GANs that are able to make the datasets indistinguishable (Adversarial Discriminative Domain Adaptation: https://arxiv.org/abs/1702.05464)'","b""['image data', 'image processing', 'medicine', 'diseases', 'large', 'featured']""",https://www.kaggle.com/kmader/pulmonary-chest-xray-abnormalities
b'TMY3 Solar',b'One Year of Typical Hourly Solar & Weather Data for +1000 US Locations',"b""The TMY3s are data sets of hourly values of solar radiation and meteorological elements for a 1-year period. Their intended use is for computer simulations of solar energy conversion systems and building systems to facilitate performance comparisons of different system types, configurations, and locations in the United States and its territories. Because they represent typical rather than extreme conditions, they are not suited for designing systems to meet the worst-case conditions occurring at a location.\n\nPlease note that TMY3 is NOT the state of the art solar data.  It was used as a key component of investment analyses for several years, but NREL has released a more recent version based on satellite data and updated meteorological models that provides coverage for the entire United States. [That dataset][1] is much too large to publish here, but is highly recommended if you need the best information.\n\n### Content\n\n- Please see the pdf manual for full details of each field; there are several dozen of them. \n- It's important to know that nearly all of the solar data is modeled based on estimates of cloud cover; less than 1% of the stations directly measured sunlight.\n- This data is not appropriate for time series analysis. A typical meteorological year is literally twelve months of real data from twelve different years. Please see the manual for further details.\n\n### Acknowledgements\n\nThis dataset was made available by the [National Renewable Energy Laboratory][2]. You can find [the original dataset here][3].\n\n### If you like\nIf you liked this dataset, you might also enjoy:\n\n- [Google Project Sunroof][4]\n\n- [30 Years of European Wind Generation][5]\n\n- [30 Years of European Solar Generation](https://www.kaggle.com/sohier/30-years-of-european-solar-generation)\n\n\n  [1]: https://nsrdb.nrel.gov/download-instructions\n  [2]: http://www.nrel.gov/\n  [3]: http://rredc.nrel.gov/solar/old_data/nsrdb/1991-2005/tmy3/\n  [4]: https://www.kaggle.com/jboysen/google-project-sunroof\n  [5]: https://www.kaggle.com/sohier/30-years-of-european-wind-generation""","b""['energy', 'large', 'featured']""",https://www.kaggle.com/us-doe/tmy3-solar
"b""Ulabox orders with categories' partials 2017""",b'General data of 30k orders from 10k customers',"b""### Context\n\n__Ulabox__ is the most successful pure-player __online grocery__ in Spain. It picks up more than \xe2\x82\xac1 million in monthly revenue and asserts a customer satisfaction above 95%. It currently serves Madrid and Barcelona with fresh food and the rest of Spain's peninsula with non perishable items.\n\n\n### Content\n\nThe __ulabox_orders_with_categories_partials_2017__ dataset includes a subset of anonymized __30k orders__ from the beginning of 2017. All kind of customers (around 10k) are represented in this dataset: from urban and rural areas, from first-timers to loyal customers.\n\n\n\n### Acknowledgements\n\n*Ulabox* was kindly enough to publish this dataset in Kaggle. However if you use this dataset in a paper or research, please use the following citation:\n\nThe Ulabox Online Supermarket Dataset 2017, accessed from https://www.github.com/ulabox/datasets""","b""['internet', 'food and drink', 'business', 'customer value', 'small', 'featured']""",https://www.kaggle.com/ulabox/ulabox-orders-with-categories-partials-2017
b'NYC Parking Tickets',"b'42.3M Rows of Parking Ticket Data, Aug 2013-June 2017'","b'### Context\n\nThe NYC Department of Finance collects data on every parking ticket issued in NYC (~10M per year!). This data is made publicly available to aid in ticket resolution and to guide policymakers.\n\n\n### Content\n\nThere are four files, covering Aug 2013-June 2017. The files are roughly organized by fiscal year (July 1 - June 30) with the exception of the initial dataset. The initial dataset also lacks 8 columns that are included in the other three datasets (although be warned that these additional data columns are used sparingly). See the dataset descriptions for exact details. Columns include information about the vehicle ticketed, the ticket issued, location, and time.\n\n\n### Acknowledgements\n\nData was produced by NYC Department of Finance. FY2018 data is found [here](https://data.cityofnewyork.us/City-Government/Parking-Violations-Issued-Fiscal-Year-2018/pvqr-7yc4) with updates every third week of the month.\n\n\n### Inspiration\n\n* When are tickets most likely to be issued? Any seasonality?\n* Where are tickets most commonly issued?\n* What are the most common years and types of cars to be ticketed?'","b""['government', 'cities', 'law', 'automobiles', 'large', 'featured']""",https://www.kaggle.com/new-york-city/nyc-parking-tickets
b'NY New York City Leading Causes of Death',b'From New York City Open Data',"b""### Content  \n\nThe leading causes of death by sex and ethnicity in New York City in since 2007.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/-yYaO0ioyOY) by [Abhishek Dhakate](https://unsplash.com/@clikaholic) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'death', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-new-york-city-leading-causes-of-death
b'Crime in Atlanta',"b'Crimes committed in Atlanta, Georgia in 2017'","b""### Context\n\nThis dataset is an exported version of the [Atlanta Crime Data Report](http://www.atlantapd.org/i-want-to/crime-data-downloads), a dataset on crimes in the city of Atalanta, Georgia published by the city's police department.\n\n### Content\n\nThis data is regarding crime data from the City of Atlanta. This area contains weekly crime reports commanders use to best deploy Atlanta officers to combat crime. It also contains a raw crime data dump that is updated weekly. Crime data in this area is counted by incident in the area.\n\n### Acknowledgements\n\nThe original source for this dataset is located [on the Atlanta PD website](http://www.atlantapd.org/i-want-to/crime-data-downloads).\n\n### Inspiration\n\nWhat can you learn about crime in Atlanta from this dataset? How does it compare to crimes committed in other cities with data on Kaggle, like [New York City](https://www.kaggle.com/adamschroeder/crimes-new-york-city)?""","b""['crime', 'small', 'featured']""",https://www.kaggle.com/priscillapun/crime-in-atlanta-2017
b'Sloan Digital Sky Survey RD14',"b'Classification of Stars, Galaxies and Quasars'","b'### Context\n\nI was looking for an unused and interesting dataset to improve my data science skills on when my professor mentioned the Sloan Digital Sky Survey which offers public data of space observations. As I found the data to be super insightful I want to share the data.\n\n### Content\n\nThe data consists of 10,000 observations of space taken by the SDSS. Every observation is described by 17 feature columns and 1 class column which identifies it to be either a star, galaxy or quasar.\n\n### Feature Description\n\nThe table results from a query which joins two tables (actuaclly views): ""PhotoObj"" which contains photometric data and ""SpecObj"" which contains spectral data.\n\n**To ease your start with the data you can read the feature descriptions below:**\n\n#### View ""PhotoObj""\n* objid = Object Identifier\n* ra = J2000 Right Ascension (r-band)\n* dec = J2000 Declination (r-band)\n\nRight ascension (abbreviated RA) is the angular distance measured eastward along the celestial equator from the Sun at the March equinox to the hour circle of the point above the earth in question. When paired with declination (abbreviated dec), these astronomical coordinates specify the direction of a point on the celestial sphere (traditionally called in English the skies or the sky) in the equatorial coordinate system.\n\nSource: https://en.wikipedia.org/wiki/Right_ascension\n\n* u = better of DeV/Exp magnitude fit\n* g = better of DeV/Exp magnitude fit\n* r = better of DeV/Exp magnitude fit\n* i = better of DeV/Exp magnitude fit\n* z = better of DeV/Exp magnitude fit\n\nThe Thuan-Gunn astronomic magnitude system. u, g, r, i, z represent the response of the 5 bands of the telescope.\n\nFurther education: https://www.astro.umd.edu/~ssm/ASTR620/mags.html\n\n* run = Run Number\n* rereun = Rerun Number\n* camcol = Camera column\n* field = Field number\n\nRun, rerun, camcol and field are features which describe a field within an image taken by the SDSS. A field is basically a part of the entire image corresponding to 2048 by 1489 pixels. A field can be identified by:\n- **run** number, which identifies the specific scan,\n- the camera column, or ""**camcol**,"" a number from 1 to 6, identifying the scanline within the run, and\n- the **field** number. The field number typically starts at 11 (after an initial rampup time), and can be as large as 800 for particularly long runs.\n- An additional number, **rerun**, specifies how the image was processed. \n\n#### View ""SpecObj""\n\n* specobjid = Object Identifier\n* class = object class (galaxy, star or quasar object)\n\nThe class identifies an object to be either a galaxy, star or quasar. This will be the response variable which we will be trying to predict.\n\n* redshift = Final Redshift\n* plate = plate number\n* mjd = MJD of observation\n* fiberid = fiber ID\n\nIn physics, **redshift** happens when light or other electromagnetic radiation from an object is increased in wavelength, or shifted to the red end of the spectrum. \n\nEach spectroscopic exposure employs a large, thin, circular metal **plate** that positions optical fibers via holes drilled at the locations of the images in the telescope focal plane. These fibers then feed into the spectrographs. Each plate has a unique serial number, which is called plate in views such as SpecObj in the CAS.\n\n**Modified Julian Date**, used to indicate the date that a given piece of SDSS data (image or spectrum) was taken.\n\nThe SDSS spectrograph uses optical fibers to direct the light at the focal plane from individual objects to the slithead. Each object is assigned a corresponding **fiberID**. \n\n**Further information on SDSS images and their attributes:** \n\nhttp://www.sdss3.org/dr9/imaging/imaging_basics.php\n\nhttp://www.sdss3.org/dr8/glossary.php\n\n### Acknowledgements\n\nThe data released by the SDSS is under public domain. Its taken from the current data release **RD14**.\n\nMore information about the license: \n\nhttp://www.sdss.org/science/image-gallery/\n\nIt was acquired by querying the CasJobs database which contains all data published by the SDSS.\n\nThe exact query can be found at:\n\nhttp://skyserver.sdss.org/CasJobs/ (Free account is required!)\n\nThere are also other ways to get data from the SDSS catalogue. They can be found under:\n\nhttp://www.sdss.org/dr14/\n\nThey really have a huge database which offers the possibility of creating all kinds of tables with respect to personal interests.\n\n**Please don\'t hesitate to contact me regarding any questions or improvement suggestions. :-)**\n\n\n### Inspiration\n\nThe dataset offers plenty of information about space to explore. Also the class column is the perfect target for classification practices!\n\nNote: Since the data was already maintained very well it might not be best dataset to practice data cleaning / filtering...your decision though.'","b""['data visualization', 'classification', 'multiclass classification', 'decision tree', 'space', 'small', 'featured']""",https://www.kaggle.com/lucidlenn/sloan-digital-sky-survey
b'Iowa Liquor Sales',b'12 million alcoholic beverage sales in the Midwest',"b'### Context\n\nThe Iowa Department of Commerce requires that every store that sells alcohol in bottled form for off-the-premises consumption must hold a class ""E"" liquor license (an arrangement typical of most of the state alcohol regulatory bodies). All alcoholic sales made by stores registered thusly with the Iowa Department of Commerce are logged in the Commerce department system, which is in turn [published as open data](https://data.iowa.gov/Economy/Iowa-Liquor-Sales/m3tr-qhgy) by the State of Iowa.\n\n### Content\n\nThis dataset contains information on the name, kind, price, quantity, and location of sale of sales of individual containers or packages of containers of alcoholic beverages.\n\nThis dataset is relatively straightforward, but one source of further information on the contents of the data is [this Gist](https://gist.github.com/dannguyen/18ed71d3451d147af414).\n\n### Acknowledgements\n\nThis data was originally published by the State of Iowa [here](https://data.iowa.gov/Economy/Iowa-Liquor-Sales/m3tr-qhgy) and has been republished as-is on Kaggle.\n\n\n### Inspiration\n\n This data is probably a representative sample of sale activity for alcohol in the United States, and can be used to answer many questions thereof, like: how much alcohol is sold and consumed in the United States? What kind? What are the most popular brands and labels? What are the most popular mixers? What is the distribution of prices paid in-store? Etcetera.'","b""['food and drink', 'alcohol', 'medium', 'featured']""",https://www.kaggle.com/residentmario/iowa-liquor-sales
"b'Dengue, Temperatura e Chuvas em Campinas-SP'",b'Dados Mensais coletados entre 1998 e 2014',"b'### Contexto\n\nDataset contendo o n\xc3\xbamero de casos mensais confirmados de dengue no municipio de Campinas/SP de 1998 a 2015. Al\xc3\xa9m disso foram coletados dados de chuvas, temperatura m\xc3\xa9dia, m\xc3\xadnima e m\xc3\xa1xima na cidade.\n\n### Conte\xc3\xbado\n\n - **M\xc3\xaas:** O m\xc3\xaas no formato AAAA-MM-DD\n - **Casos confirmados:** Total de casos de dengue confirmados no m\xc3\xaas\n - **Chuva:** Total em mm, de chuva na cidade no m\xc3\xaas\n - **Temperatura M\xc3\xa9dia/M\xc3\xadnima e M\xc3\xa1xima:** Temperatura di\xc3\xa1ria M\xc3\xa9dia/M\xc3\xadnima e M\xc3\xa1xima\n\n### Fonte\n\nOs relato de casos de casos de dengue foram colhidos dos org\xc3\xa3os SES (Secretaria Estadual de Sa\xc3\xbade) e SINAM (Sistema de Informa\xc3\xa7ao de Agravos de Notifica\xc3\xa7\xc3\xa3o). Os dados climaticos foram obtidos de tabelas encontradas em ciiagro.sp.gov.br.'","b""['healthcare', 'public health', 'brazil', 'small', 'featured']""",https://www.kaggle.com/renangomes/dengue-temperatura-e-chuvas-em-campinassp
b'30 Years of European Wind Generation',b'Hourly energy potential for 1986-2015',"b""This dataset contains hourly estimates of an area's energy potential for 1986-2015 as a percentage of a power plant's maximum output.\n\nThe overall scope of EMHIRES is to allow users to assess the impact of meteorological\nand climate variability on the generation of solar power in Europe and not to mime the\nactual evolution of wind power production in the latest decades. For this reason, the\nhourly wind power generation time series are released for meteorological conditions of\nthe years 1986-2015 (30 years) without considering any changes in the wind installed\ncapacity. Thus, the installed capacity considered is fixed as the one installed at the end of\n2015. For this reason, data from EMHIRES should not be compared with actual power\ngeneration data other than referring to the reference year 2015. \n\n### Content\n\n- The data is available at both the national level and the NUTS 2 level. [The NUTS 2 system][1] divides the EU into 276 statistical units.\n- Please see the manual for the technical details of how these estimates were generated. \n- This product is intended for policy analysis over a wide area and is not the best for estimating the output from a single system. Please don't use it commercially.\n\n### Acknowledgements\n\nThis dataset was kindly made available by the [European Commission's STETIS program][2]. You can find the original dataset here.\n\n### Inspiration\n\n- How clean is the dataset?\n- What does a typical year look like? One common approach is to stitch together 12 months of raw data, using the 12 most typical months [per this ISO standard][3].\n- Can you identify more useful geographical areas for this sort of analysis, such as valleys that would share similar wind patterns?\n\n## If you like\n\nIf you like this dataset, you might also enjoy:\n-  [30 years of European solar][4]\n- Google's Project Sunroof data\n\n\n  [1]: https://en.wikipedia.org/wiki/Nomenclature_of_Territorial_Units_for_Statistics\n  [2]: https://setis.ec.europa.eu/about-setis\n  [3]: https://www.iso.org/standard/41371.html\n  [4]: https://www.kaggle.com/sohier/30-years-of-european-solar-generation""","b""['energy', 'medium', 'featured']""",https://www.kaggle.com/sohier/30-years-of-european-wind-generation
b'Japanese Whisky Review Dataset',"b'1,000+ Reviews of Japanese Whisky'",b'### Context\n\nThe dataset was scraped from [Master of Malt][1]. You can refer to my scraping code at [Github][2].\n\n### Content\n\n - Bottle_name: Name of whisky\n - Brand: Japanese whisky brand. This dataset covers 4 brands: \n    - Hibiki (\xe9\x9f\xbf)\n    - Yamazaki (\xe5\xb1\xb1\xe5\xb4\x8e)\n    - Hakushu (\xe7\x99\xbd\xe5\xb7\x9e)\n    - Nikka (\xe3\x83\x8b\xe3\x83\x83\xe3\x82\xab)\n - Title: Title of each review\n - Review_Content: Review content\n\nThis dataset includes 1130 reviews of 50 Japanese whisky.\n\n### Acknowledgements\n\nThe original data was collected by [Master of Malt][1].\n\n### Inspiration\n\n - Can you find interesting common words from reviews?\n - Can you identify characteristics of each Japanese whisky brand?\n\n\n  [1]: https://www.masterofmalt.com/\n  [2]: https://github.com/koki25ando/Scraping-Japanese-Whisky-Dataset/blob/master/japanese.R',"b""['food and drink', 'alcohol', 'asia', 'small', 'featured']""",https://www.kaggle.com/koki25ando/japanese-whisky-review
b'Lithuanian parliament votes',b'All available votes made by members of Lithuanian parliament since 1997.',"b'### Context\n\nIn Lithuania, Lithuanian Parliament has sittings several times per week, during each sitting member of parliament vote for proposed questions. Some questions are related to law amendments other questions could be something like ""should we do a break before taking more questions"". In one they there can be several sittings, usually one in the morning and another in the evening.\n\nAll members of parliament (MPs) form parliamentary groups, there is a group having majority of MS\'s and other smaller groups.\n\nIn this dataset you will find all votes made by all MPs since 1997 up until 2017. So that is a lot of data and basically most of the political history of independent Lithuania.\n\n### Content\n\nEach row in `votes.csv` file represents a vote mode by single MP on a single question. Also for each vote there is a number of meta data provided:\n\n- **voting_id** - unique voting id, can be a negative number. You can reconstruct URL to the voting page using this template: `http://www.lrs.lt/sip/portal.show?p_r=15275&p_k=1&p_a=sale_bals&p_bals_id={voting_id}`, replace `{voting_id}` with a voting id.\n- **voter_id** - unique MP id.\n- **time** - date and time when a vote was cast.\n- **group** - abbreviated name of a parliamentary group.\n- **voter** - full name of an MP.\n- **question** - question text, usually question sounds like ""do we accept this proposal or not"", unfortunately title and texts of proposed documents are not included in this dataset.\n- **sitting_type** - one of:\n    - *rytinis* - in the morning\n    - *vakarinis* - in the evening\n    - *neeilinis* - additional sitting\n    - *nenumatytas* - not planned\n- **vote** - vote value, one of:\n    - *1* - aye\n    - *-0.5* - abstain\n    - *-1* - against\n- **n_eligible_voters** - total number of eligible to vote MPs.\n- **n_eligible_voters** - number of MPs who voted in a voting.\n\n\n### Acknowledgements\n\nAll the data where scraped from [Lithuanian Parliament web site](http://www.lrs.lt/sip/portal.show?p_r=15275&p_k=1). Code of web scraper can be found here:\n\nhttps://github.com/sirex/databot-bots/blob/master/bots/lrs/balsavimai.py\n\n### Inspiration\n\nOne of the most interesting questions I would like to get is a way to automatically categorize all the voting by topic. Usually there are several major topics involving multiple documents and many voting sessions, some times these topics can last for years. Unfortunately there is no such field, with a topic, in order to discover a topic one would need to analyze content of documents and probably sitting transcripts to find a topic. But in order to do this, data of documents and sitting transcripts will be needed, I will provide this data some time later.\n\nOther interesting things to look into is how different parliamentary groups or people relates to one another by their votes.'","b""['politics', 'law', 'parties', 'medium', 'featured']""",https://www.kaggle.com/sirexo/lithuanian-paliament-votes
b'Naver Vlive videos dataset',"b'Vlive video details (likes ,views, channels etc)'","b'#Context\n\nVlive is a live streaming platform by Naver that provides high-quality videos and concert streaming. \n\n#Content\n\nThe dataset contains video name, link, likes, views and more. The playlist also included in the dataset and can be identified by isVideo column. It was collected on 6/6/2018.\n\n#Acknowledgements\n\nThe information is collected from http://www.vlive.tv . I do not own any of the information.\n\n#Inspiration\nWhat is the most popular video in Vlive?'","b""['internet', 'web sites', 'digital media', 'video data', 'media studies', 'small', 'featured']""",https://www.kaggle.com/yusian112/vlive
b'NY Neighborhood Development Area Breakdowns',b'From New York City Open Data',"b""### Content  \n\nDemographic statistics broken down by neighborhood development areas  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/xf4dN3ZeQ9k) by [Robert Wiedemann](https://unsplash.com/@antilumen) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-neighborhood-development-area-breakdowns
b'US jobs on Monster.com',"b'22,000 US-based Job Listings'","b'###Context\n\nThis is a pre-crawled dataset, taken as subset of a bigger [dataset (more than 4.7 million job listings)][1] that was created by extracting data from Monster.com, a leading job board.\n\n### Content\n\nThis dataset has following fields:\n\n- `country`\n- `country_code`\n- `date_added`\n- `has_expired` - Always `false`.\n- `job_description` - The primary field for this dataset, containing the bulk of the information on what the job is about.\n- `job_title`\n- `job_type` - The type of tasks and skills involved in the job. For example, ""management"".\n- `location`\n- `organization`\n- `page_url`\n- `salary`\n- `sector` - The industry sector the job is in. For example, ""Medical services"".\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud\'s in-house web-crawling service.\n\n### Inspiration\n\n* What kinds of jobs titles correspond with what kinds of wages?\n* What can you learn about the Moster.com-based US job market based on analyzing the contents of the job descriptions?\n* How do job descriptions different between different industry sectors?\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=mn-kaggle&utm_medium=referral'","b""['internet', 'medium', 'featured']""",https://www.kaggle.com/PromptCloudHQ/us-jobs-on-monstercom
b'ResNet-50',b'ResNet-50 Pre-trained Model for PyTorch',"b'# ResNet-50\n\n---\n\n## Deep Residual Learning for Image Recognition\nDeeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. \n\nAn ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. \n\nThe depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.<br>\n\n**Authors: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun**<br>\n**https://arxiv.org/abs/1512.03385**\n\n---\n\n\nArchitecture visualization: http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006\n\n![Resnet][1]\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/nyYh5xH.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/resnet50
b'TMDB 5000 Movie Dataset',"b'Metadata on ~5,000 movies from TMDb'","b""### Background\nWhat can we say about the success of a movie before it is released? Are there certain companies (Pixar?) that have found a consistent formula? Given that major films costing over $100 million to produce can still flop, this question is more important than ever to the industry. Film aficionados might have different interests. Can we predict which films will be highly rated, whether or not they are a commercial success?\n\nThis is a great place to start digging in to those questions, with data on the plot, cast, crew, budget, and revenues of several thousand films.\n\n### Data Source Transfer Summary\nWe (Kaggle) have removed the original version of this dataset per a [DMCA](https://en.wikipedia.org/wiki/Digital_Millennium_Copyright_Act) takedown request from IMDB. In order to minimize the impact, we're replacing it with a similar set of films and data fields from [The Movie Database (TMDb)](themoviedb.org) in accordance with [their terms of use](https://www.themoviedb.org/documentation/api/terms-of-use). The bad news is that kernels built on the old dataset will most likely no longer work.\n\nThe good news is that:\n\n- You can port your existing kernels over with a bit of editing. [This kernel](https://www.kaggle.com/sohier/getting-imdb-kernels-working-with-tmdb-data/) offers functions and examples for doing so. You can also find [a general introduction to the new format here](https://www.kaggle.com/sohier/tmdb-format-introduction).\n\n- The new dataset contains full credits for both the cast and the crew, rather than just the first three actors.\n\n- Actor and actresses are now listed in the order they appear in the credits. It's unclear what ordering the original dataset used; for the movies I spot checked it didn't line up with either the credits order or IMDB's stars order.\n\n- The revenues appear to be more current. For example, IMDB's figures for Avatar seem to be from 2010 and understate the film's global revenues by over $2 billion.\n\n- Some of the movies that we weren't able to port over (a couple of hundred) were just bad entries. For example, [this IMDB entry](http://www.imdb.com/title/tt5289954/?ref_=fn_t...) has basically no accurate information at all. It lists Star Wars Episode VII as a documentary.\n\n### Data Source Transfer Details\n\n- Several of the new columns contain json. You can save a bit of time by porting the load data functions [from this kernel]().\n\n- Even in simple fields like runtime may not be consistent across versions. For example, previous dataset shows the duration for Avatar's extended cut while TMDB shows the time for the original version.\n\n- There's now a separate file containing the full credits for both the cast and crew.\n\n- All fields are filled out by users so don't expect them to agree on keywords, genres, ratings, or the like.\n\n- Your existing kernels will continue to render normally until they are re-run.\n\n- If you are curious about how this dataset was prepared, the code to access TMDb's API is posted [here](https://gist.github.com/SohierDane/4a84cb96d220fc4791f52562be37968b).\n\nNew columns:\n\n- homepage\n\n- id\n\n- original_title\n\n- overview\n\n- popularity\n\n- production_companies\n\n- production_countries\n\n- release_date\n\n- spoken_languages\n\n- status\n\n- tagline\n\n- vote_average\n\nLost columns:\n\n- actor_1_facebook_likes\n\n- actor_2_facebook_likes\n\n- actor_3_facebook_likes\n\n- aspect_ratio\n\n- cast_total_facebook_likes\n\n- color\n\n- content_rating\n\n- director_facebook_likes\n\n- facenumber_in_poster\n\n- movie_facebook_likes\n\n- movie_imdb_link\n\n- num_critic_for_reviews\n\n- num_user_for_reviews\n\n### Open Questions About the Data\nThere are some things we haven't had a chance to confirm about the new dataset. If you have any insights, please let us know in the forums!\n\n- Are the budgets and revenues all in US dollars? Do they consistently show the global revenues?\n\n- This dataset hasn't yet gone through a data quality analysis. Can you find any obvious corrections? For example, in the IMDb version it was necessary to treat values of zero in the budget field as missing. Similar findings would be very helpful to your fellow Kagglers! (It's probably a good idea to keep treating zeros as missing, with the caveat that missing budgets much more likely to have been from small budget films in the first place).\n\n### Inspiration\n\n- Can you categorize the films by type, such as animated or not? We don't have explicit labels for this, but it should be possible to build them from the crew's job titles.\n\n- How sharp is the divide between major film studios and the independents? Do those two groups fall naturally out of a clustering analysis or is something more complicated going on?\n\n### Acknowledgements\nThis dataset was generated from [The Movie Database](themoviedb.org) API. This product uses the TMDb API but is not endorsed or certified by TMDb.\nTheir API also provides access to data on many additional movies, actors and actresses, crew members, and TV shows. You can [try it for yourself here](https://www.themoviedb.org/documentation/api).\n\n![](https://www.themoviedb.org/assets/static_cache/9b3f9c24d9fd5f297ae433eb33d93514/images/v4/logos/408x161-powered-by-rectangle-green.png)\n\n""","b""['film', 'medium', 'featured']""",https://www.kaggle.com/tmdb/tmdb-movie-metadata
b'NYS Traffic Control Device Inventory',b'From New York State Open Data',"b""### Content  \n\nThe New York State Department of Transportation (NYSDOT) traffic control devices data set is a list of all of the traffic devices that are either owned or maintained by NYSDOT. The devices included are of various types such as traffic signals, street lights, beacons, flashers, navigational lights, Intelligent Transportation Systems (ITS), etc.  Devices in the 5 boroughs of New York City are not owned or maintained by NYSDOT and therefore not represented in this dataset  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Gka_lg_Wf-c) by [Dadan Fitrayana](https://unsplash.com/@dadan76) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'utility', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-traffic-control-device-inventory
b'The SDOBenchmark Dataset',b'A machine learning image dataset for the prediction of solar flares',"b""### Context\n\nSolar flares are intense bursts of radiation which can disrupt the power grids of a continent, shut down the GPS system or irradiate people exposed in space.\nDeveloping systems for predicting solar flares would allow us to precisely aim our observation instruments at upcoming events, and eventually enable countermeasures against such worst-case scenarios.\n\n\n### Content\n\nThe SDOBenchmark dataset has a dedicated webpage at [i4ds.github.io/SDOBenchmark][1], where you will find plenty of information. And if things are still unclear, please don't hesitate to ask questions in the Discussion tab!\n\n\n### Acknowledgements\n\nThis dataset was created by Roman Bolzern and Michael Aerni from the [Institute for Data Science, FHNW, Switzerland][2]. We owe our thanks to [the SDO satellite mission][3], and to [JSOC Stanford][4] for providing the raw data.\n\n\n### Inspiration\n\nThe prediction of solar flares proves to be a challenging problem, some even compare it to weather forecasting. And regarding Machine Learning, we find this dataset to be particularly challenging because of the complexity of a single sample (up to 40 images), the relatively small size of samples (8'000 for training), and the fact that it is a regression problem. Yet Kagglers have proven time and time again that predictions can be made on the most complex of data. By providing this dataset, we hope to encourage Kaggle machine learners to push the envelope of solar flare predictions.\n\n\n  [1]: https://i4ds.github.io/SDOBenchmark\n  [2]: https://www.fhnw.ch/en/about-fhnw/schools/school-of-engineering/institutes/institute-for-data-science\n  [3]: https://sdo.gsfc.nasa.gov/\n  [4]: http://jsoc.stanford.edu/""","b""['image data', 'regression analysis', 'research', 'physics', 'large', 'featured']""",https://www.kaggle.com/fhnw-i4ds/sdobenchmark
b'Environmental variables for world countries',b'Misc climatic and environmental variables for world countries',b'### Context\n\nAssessing country-level social and economic statistics are often limited to socio-economic data. Not any more! This dataset will be maintained and updated with miscellaneous environmental data for countries across the globe.\n\n### Content\n\nThis data is all acquired through Google Earth Engine (https://earthengine.google.com/) where publicly available remote sensing datasets have been uploaded to the cloud to be manipulated by the average Joe like you and I. Most of the data is derived by calculating the mean for each country at a reduction scale of about 10km.  \n\n\n### Inspiration\n\n- Can you use environmental statistics to predict social and economic data? \n- Are people more happy in sunny countries? \n- How do economies in forested countries compare with those dominated by grassland/desert?',"b""['climate', 'countries', 'environment', 'social sciences', 'small', 'featured']""",https://www.kaggle.com/zanderventer/environmental-variables-for-world-countries
"b'SF Dataset Alerts, Inventory, and Profiles'",b'From San Francisco Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License""","b""['socrata', 'utility', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-dataset-alerts-inventory-and-profiles
b'OpenAddresses - Asia and Oceania',b'Addresses and geolocations for Asia and Oceania',"b""### Context\n\nOpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates, street names, house numbers and postal codes. \n\n### Content\n\nThis dataset contains one data file for each of these countries in Asia and Oceania.\n\n* United Arab Emirates - arab_emirates.csv\n* Australia - australia.csv\n* China - china.csv\n* Iceland - iceland.csv\n* Israel - israel.csv\n* Japan - japan.csv\n* Kazakhstan - kazakhstan.csv\n* Kuwait - kuwait.csv\n* New Caldonia - new_caldonia.csv\n* New Zealand - new_zealand.csv\n* Qatar - qatar.csv\n* Saudi Arabia - saudiarabia.csv\n* Singapore - singapore.csv\n* South Korea - south_korea.csv\n* Taiwan - taiwan.csv\n\n\nField descriptions:\n\n* LON - Longitude\n* LAT - Latitude\n* NUMBER - Street number\n* STREET - Street name\n* UNIT - Unit or apartment number\n* CITY - City name\n* DISTRICT - ?\n* REGION - ?\n* POSTCODE - Postcode or zipcode\n* ID - ?\n* HASH - ?\n\n\n### Acknowledgements\n\nData collected around 2017-07-25 by OpenAddresses (http://openaddresses.io).\n\nAddress data is essential infrastructure. Street names, house numbers and\npostal codes, when combined with geographic coordinates, are the hub that\nconnects digital to physical places.\n\nData licenses can be found in LICENSE.txt.\n\nData source information can be found at\nhttps://github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources\n\n\n### Inspiration\n\nUse this dataset to create maps in conjunction with other datasets to map weather, crime, or how your next canoing trip.""","b""['large', 'featured']""",https://www.kaggle.com/openaddresses/openaddresses-asia-and-oceania
b'San Francisco Park Scores',"b'Park evaluation scores, 2005 to 2014'","b""### Context\n\nAverage quarterly park evaluation scores in San Francisco, from Q3 FY2005 to Q4 FY2014. \n\n### Content\n\nData includes merged data with Recreation and Parks Facilities data, including location and descriptions. Location (LatLong) data missing for 775 rows. \n\n### Acknowledgements\n\nThe data is provided by San Francisco Recreation & Parks Department via the San Francisco Open Data Portal.\nSources:\n- [Park Scores 2005-2014][1]\n\n - [Recreation and Parks Facilities][2]\nFacilities maintained by the Recreation and Parks Department. A facility in this dataset represents a structural or physical amenity within a property's boundaries.\n\nPhoto by Casey Horner on Unsplash\n\n### Inspiration\n\n- What local geospatial or demographic effects are there on a parks rating? \n- Are park ratings static over time or do they improve?\n- What facilities have the highest ratings? \n\n  [1]: https://data.sfgov.org/Culture-and-Recreation/Park-Scores-2005-2014/fjq8-r8ws\n  [2]: https://data.sfgov.org/Culture-and-Recreation/Recreation-and-Parks-Facilities/xvq2-rjrk""","b""['demographics', 'politics', 'public administration', 'nature', 'small', 'featured']""",https://www.kaggle.com/danofer/sf-parks
b'JetBrains Developer Survey 2017 & 2018',"b""Data from JetBrains's Developer survey in 2017 and DevEcosystem survey 2018""","b'### Context\n\nThis is data set from JetBrains\'s Python Developer Survey 2017, I have cleaned column names of Raw CSV file\n\n### Content\n\nData set comprises of:\nWhat secondary language developers use alongside python?\nWhat purpose they use python for?\nWhat text editor/IDE they use for python development?\nAge range of developers\n\nAccompanied is a ""PDF"" file listing the questions asked in the survey\n\nNOTE:\n\n - There is separate column for programming languages used alongside python due to a reason that you could\'ve choosen multiple options for question ""What programming language do you use?"" and its same for text editors/IDEs\nSo you can\'\'t melt it.\n - For the question ""Is Python the main language you use for your current projects?"", if answered ""No, I don\xe2\x80\x99t use Python for my current projects"", survey jumped directly to question ""Most of the time, do you...?"", passing on the questions in between""\n\n### Acknowledgements\n\nhttps://www.jetbrains.com/research/python-developers-survey-2017/\n\n### Inspiration\n\nWhat percentage of Python developers also use Javascript?\n'","b""['survey analysis', 'programming', 'programming languages', 'small', 'featured']""",https://www.kaggle.com/avnishnish/jetbrains-python-survey-2017
b'Chicago Budget Ordinance and Recommendations',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-budget-ordinance-and-recommendations
"b'Home, Homeowner Vacancy Rate for the United States'",b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).""","b""['economics', 'utility', 'small', 'featured']""","https://www.kaggle.com/census/home,-homeowner-vacancy-rate-for-the-united-states"
b'World Soccer - archive of soccer results and odds',"b'20+ countries, 16 seasons, 30+ leagues, 130k+ matches with bookies odds'","b""### Context\n\nWe have a few soccer datasets that are already uploaded to the Kaggle platform. \nHowever, after [playing with some hypothesis][1], we found that we need to have updates more often to complete started framework. \n\nMain difference between well-known European Soccer Database are:\n\n- added not only odds per match, but Under Over, Asian Handicaps.\n- more seasons, leagues and matches;\n- up to date data and regular updates of DB\n\nSince, that is first release of dataset, we will fix all bugs to have good training history. \n\n### Content\n\nData Dictionary is described fully here - http://www.football-data.co.uk/notes.txt\n\n### Acknowledgements\n\nThanks to \n\n1. football-data.co.uk for collected results, fixtures and odds\n2. phoebet.com - for technical consultancies and helping to generate the dataset \n\n### Inspiration\n\n- Is it possible to get statistical advantage in long game?\n- When better to use different financial strategies?\n- What is  more promising Ordinar's Or Accumulator Systems?\n\n  [1]: https://www.linkedin.com/pulse/betting-analytics-financial-management-does-matter-part-chernukh/\n\nPS. We are not encourage to play bets or have bonuses from advertisements! We just focused to share and open knowledge to community about this domain as particular case of Arbitrage""","b""['sports', 'medium', 'featured']""",https://www.kaggle.com/sashchernuh/european-football
b'NYS Abandoned Wells',b'From New York State Open Data',"b""### Content  \n\nList of wells that are regulated under the Oil, Gas and Solution Mining Law (ECL Article 23) in New York State that are abandoned and not plugged.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/wfgvng14YKo) by [Sweet Ice Cream Photography](https://unsplash.com/@sweeticecreamwedding) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'geology', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-abandoned-wells
b'New York City - Buildings Database',b'The PLUTO master record of buildings in New York City.',"b'### Context: \nPLUTO is a master record of the locations and characteristics of buildings in New York City. It\xe2\x80\x99s published by the New York City Department of City Planning on an approximately quarterly-to-half-yearly basis, and is one of the more important datasets for civic analysis in New York City.\n\n### Content: \nPLUTO includes information on building height, square footage, location, type, landmark status, number of units, owner, year of construction, and other related fields.\n\n### Acknowledgements: \nThis dataset is published as-is by the New York City Department of Planning.\n\n### Inspiration: \n* What is the distribution of the heights of buildings in New York City? The age?\n* Can you define neighborhoods by clustering similar buildings within them?\n* What (and where) is the split between commercial, residential, and office space in New York City?'","b""['cities', 'civil engineering', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/nyc-buildings
b'World Whisky Distilleries & Brands Dataset',b'World Whisky Distilleries & Brands Dataset',b'### Context\n\nDataset was scraped from [WhiskyBase][1]. \nWhiskybase is founded in 2007 with the goal to create the biggest resource of whisky information in the world. A community driven website built by and for whisky enthusiasts. \nYou can take a look at scraping script on my [GitHub page.][2]\n\n### Content\n\n - Whisky Distillery dataset\n - Whisky Brand Dataset\n\n### Acknowledgements\n\nOriginal database is from [WhiskyBase][3].\n\n\n### Inspiration\n\nCan you find your favorite whisky?\n\n\n  [1]: https://www.whiskybase.com/\n  [2]: https://github.com/koki25ando/Whisky-Distilleries-and-Brands-Around-the-World/blob/master/Whisky.R\n  [3]: https://www.whiskybase.com/',"b""['food and drink', 'alcohol', 'small', 'featured']""",https://www.kaggle.com/koki25ando/world-whisky-distilleries-brands-dataset
b'Telco Customer Churn',b'Focused customer retention programs',"b'### Context\n\n""Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.""  [IBM Sample Data Sets]\n\n### Content\n\nEach row represents a customer, each column contains customer\xe2\x80\x99s attributes described on the column Metadata.\n\n**The data set includes information about:**\n\n+ Customers who left within the last month \xe2\x80\x93 the column is called Churn\n+ Services that each customer has signed up for \xe2\x80\x93 phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n+ Customer account information \xe2\x80\x93 how long they\xe2\x80\x99ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n+ Demographic info about customers \xe2\x80\x93 gender, age range, and if they have partners and dependents\n\n### Inspiration\n\nTo explore this type of models and learn more about the subject.'","b""['churn analysis', 'telecommunications', 'small', 'featured']""",https://www.kaggle.com/blastchar/telco-customer-churn
b'VGG-11 with batch normalization',b'VGG-11 Pre-trained model with batch normalization for PyTorch',"b'# VGG-11\n\n---\n\n## Very Deep Convolutional Networks for Large-Scale Image Recognition<br>\nIn this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.\n<br>\n\n**Authors: Karen Simonyan, Andrew Zisserman**<br>\n**https://arxiv.org/abs/1409.1556**\n\n---\n\n#VGG Architectures<br>\n![VGG Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/uLXrKxe.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/vgg11bn
b'NIH DeepLesion Subset',"b'32,000 random images from the NIH DeepLesion Dataset'","b'# Introduction\n\nThe DeepLesion dataset contains 32,120 axial computed tomography (CT) slices from 10,594 CT scans (studies) of 4,427 unique patients. There are 1\xe2\x80\x933 lesions in each image with accompanying bounding boxes and size measurements, adding up to 32,735 lesions altogether. The full data in its 220GB glory along with substantially more documentation and some test code to explore with are all available from the official site at https://nihcc.app.box.com/v/DeepLesion/\n\n# Data \n\nThe lesion annotations were mined from NIH\xe2\x80\x99s picture archiving and communication system (PACS). Some meta-data are also provided. The contents include:\n\n- Folder \xe2\x80\x9cImages_png\xe2\x80\x9d: png image files. We named each slice with the format \xe2\x80\x9c{patient index}_{study index}_{series index}_{slice index}.png\xe2\x80\x9d, with the last underscore being / or \\ to indicate sub-folders. The images are stored in unsigned 16 bit. One should subtract 32768 from the pixel intensity to obtain the original Hounsfield unit (HU) values.\nWe provide not only the key CT slice that contains the lesion annotation, but also its 3D context (30mm extra slices above and below the key slice). Due to the large size of the data (221GB), this dataset only includes 8GB\n\n- DL_info.csv: The annotations and meta-data. See Section \xe2\x80\x9cAnnotations\xe2\x80\x9d below.\n\n# Acknowledgements / Reference\n\nIf you find the dataset useful for your research projects, please cite our JMI 2018 paper:\n\n- Ke Yan, Xiaosong Wang, Le Lu, Ronald M. Summers, ""DeepLesion: Automated Mining of Large-Scale Lesion Annotations and Universal Lesion Detection with Deep Learning"", Journal of Medical Imaging, 2018.\n\nThe following paper and code are also related with the dataset:\n\n- Ke Yan, Xiaosong Wang, Le Lu, Ling Zhang, Adam Harrison, Mohammadhadi Bagheri, Ronald M. Summers, ""Deep Lesion Graphs in the Wild: Relationship Learning and Organization of Significant Radiology Image Findings in a Diverse Large-scale Lesion Database"", IEEE CVPR, 2018, https://arxiv.org/abs/1711.10535\n'","b""['image data', 'medicine', 'object detection', 'object identification', 'object labeling', 'large', 'featured']""",https://www.kaggle.com/kmader/nih-deeplesion-subset
b'Word2Vec Sample',b'Sample Word2Vec Model',b'### Context\n\nThe [Word2Vec](https://code.google.com/archive/p/word2vec/) sample model redistributed by NLTK is used to demonstrate how word embeddings can be used together with [Gensim](https://radimrehurek.com/gensim/). \n\nThe detailed demonstration can be found on https://github.com/nltk/nltk/blob/develop/nltk/test/gensim.doctest \n\n\n### Acknowledgements\n\nCredit goes to [Word2Vec][1] and [Gensim][2] developers. \n\n\n  [1]: https://code.google.com/archive/p/word2vec/\n  [2]: https://radimrehurek.com/gensim/',"b""['medium', 'featured']""",https://www.kaggle.com/nltkdata/word2vec-sample
b'LA Client Payments to Registered Lobbying Firms',b'From Los Angeles Open Data',"b""### Content  \n\nPayments made by clients to registered Lobbying Firms must be disclosed on a quarterly basis.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/S5RBWuqog4c) by [Sam Wermut](https://unsplash.com/@samwermut1) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'ethics', 'small', 'featured']""",https://www.kaggle.com/cityofLA/la-client-payments-to-registered-lobbying-firms
b'Indian Hotels on Goibibo',"b'4,000 Indian hotels on Goibibo'","b""###Context\n\nThis is a pre-crawled dataset, taken as subset of a bigger [dataset (more than 33344 hotels)][1] that was created by extracting data from goibibo.com, a leading travel site from India.\n\n### Content\n\nThis dataset has following fields:\n\n- `address`\n- `area` - The sub-city region that this hotel is located in, geographically.\n- `city`\n- `country` - Always `India`.\n- `crawl_date`\n- `guest_recommendation` - How many guests that stayed here have recommended this hotels to others on the site.\n- `hotel_brand` - The chain that owns this hotel, if this hotel is part of a chain.\n- `hotel_category`\n- `hotel_description` - A hotel description, as provided by the lister.\n- `hotel_facilities` - \n- `hotel_star_rating` - The out-of-five star rating of this hotel.\n- `image_count` - The number of images provided with the listing.\n- `latitude`\n- `locality`\n- `longitude`\n- `pageurl`\n- `point_of_interest` - Nearby locations of interest.\n- `property_name`\n- `property_type` - The type of property. Usually a hotel.\n- `province`\n- `qts` - Crawl timestamp.\n- `query_time_stamp` - Copy of `qts`.\n- `review_count_by_category` - Reviews for the hotel, broken across several different categories.\n- `room_area`\n- `room_count`\n- `room_facilities`\n- `room_type`\n- `similar_hotel`\n- `site_review_count` - The number of reviews for this hotel left on the site by users.\n- `site_review_rating` - The overall rating for this hotel by users.\n- `site_stay_review_rating`\n- `sitename` - Always `goibibo.com`\n- `state`\n- `uniq_id`\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud's in-house web-crawling service.\n\n### Inspiration\n* Try exploring some of the amenity categories. What do you see?\n* Try applying some natural language processing algorithms to the hotel descriptions. What are the some common words and phrases? How do they relate to the amenities the hotel offers?\n* What can you discover by drilling down further into hotels in different regions?\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=go-kaggle&utm_medium=referral""","b""['internet', 'india', 'hotels', 'small', 'featured']""",https://www.kaggle.com/PromptCloudHQ/hotels-on-goibibo
b'DenseNet-201',b'DenseNet-201 Pre-trained Model for PyTorch',"b'\n# DenseNet-201\n\n---\n\n## Densely Connected Convolutional Networks<br>\n\nRecent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and models are available at this [https URL][1].\n\n**Authors: Gao Huang, Zhuang Liu, Kilian Q. Weinberger, Laurens van der Maaten**<br>\n**https://arxiv.org/abs/1608.06993**\n\n---\n\n\n![DenseNet][2]\n\n## DenseNet Architectures\n![DenseNet Architectures][3]\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://github.com/liuzhuang13/DenseNet\n  [2]: https://imgur.com/wWHWbQt.jpg\n  [3]: https://imgur.com/oiTdqJL.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/densenet201
b'NYS Parole Board Decisions for Initial Interviews',b'From New York State Open Data',"b""### Content  \n\nRepresents Initial interview decisions made by the NYS Board of Parole by crime type and month and calendar year.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/KieCLNzKoBo) by [Sam McGhee](https://unsplash.com/@sammcghee) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-parole-board-decisions-for-initial-interviews
"b'Manchester, NH Crime Reports'",b'Crime Reports for Manchester NH - March 2018',"b'#Acknowledgements\n\nThis data was pulled from [CrimeMapping][1] for the city of Manchester, NH, for the month of March 2018. It breaks down incidents of crime by type, location (street block or intersection), and date-time of the incident. \n\n\n  [1]: https://www.crimemapping.com/map/nh/manchester'","b""['crime', 'united states', 'small', 'featured']""",https://www.kaggle.com/mvalcic/manch-nh-crime
b'Forecasts for Product Demand',b'Make Accurate Forecasts for Thousands of Different Products',"b""### Context\n\nThe dataset contains historical product demand for a manufacturing company with footprints globally. The company provides thousands of products within dozens of product categories. There are four central warehouses to ship products within the region it is responsible for. Since the products are manufactured in different locations all over the world, it normally takes more than one month to ship products via ocean to different central warehouses. If forecasts for each product in different central with reasonable accuracy for the monthly demand for month after next can be achieved, it would be beneficial to the company in multiple ways. \n\n\n### Content\n\n**Historical Product Demand.csv** - CSV data file containing product demand for encoded product id's\n\n## Acknowledgements\n\nThis dataset is all real-life data and products/warehouse and category information encoded. \n\n### Inspiration\n\nIs it possible to make forecasts for thousands of products (some of them are highly variable in terms of monthly demand) for the the month after next?""","b""['business', 'product', 'supply chain', 'medium', 'featured']""",https://www.kaggle.com/felixzhao/productdemandforecasting
b'Air Quality Annual Summary',b'A summary of air quality from 1987 to 2017',"b'###Context:\nThe Environmental Protection Agency (EPA) creates air quality trends using measurements from monitors located across the country. All of this data comes from EPA\xe2\x80\x99s Air Quality System (AQS). Data collection agencies report their data to the EPA via this system and it calculates several types of aggregate (summary) data for EPA internal use. \n\n###Content: \n**Field descriptions:**\n\n1. State Code: The FIPS code of the state in which the monitor resides.\n\n2. County Code: The FIPS code of the county in which the monitor resides.\n\n3. Site Num:A unique number within the county identifying the site.\n\n4. Parameter Code: The AQS code corresponding to the parameter measured by the monitor.\n\n5. POC: This is the \xe2\x80\x9cParameter Occurrence Code\xe2\x80\x9d used to distinguish different instruments that measure the same parameter at the same site.\n\n6. Latitude: The monitoring site\xe2\x80\x99s angular distance north of the equator measured in decimal degrees.\n\n7. Longitude: The monitoring site\xe2\x80\x99s angular distance east of the prime meridian measured in decimal degrees.\n\n8. Datum: The Datum associated with the Latitude and Longitude measures.\n\n9. Parameter Name: The name or description assigned in AQS to the parameter measured by the monitor. Parameters may be pollutants or non-pollutants.\n\n10. Sample Duration: The length of time that air passes through the monitoring device before it is analyzed (measured). So, it represents an averaging period in the atmosphere (for example, a 24-hour sample duration draws ambient air over a collection filter for 24 straight hours). For continuous monitors, it can represent an averaging time of many samples (for example, a 1-hour value may be the average of four one-minute samples collected during each quarter of the hour).\n\n11. Pollutant Standard:A description of the ambient air quality standard rules used to aggregate statistics. (See description at beginning of document.)\n\n12. Metric Used: The base metric used in the calculation of the aggregate statistics presented in the remainder of the row. For example, if this is Daily Maximum, then the value in the Mean column is the mean of the daily maximums.\n\n13. Method Name: A short description of the processes, equipment, and protocols used in gathering and measuring the sample.\n\n14. Year: The year the annual summary data represents.\n\n15. Units of Measure: The unit of measure for the parameter. QAD always returns data in the standard units for the parameter. Submitters are allowed to report data in any unit and EPA converts to a standard unit so that we may use the data in calculations.\n\n16. Event Type: Indicates whether data measured during exceptional events are included in the summary. A wildfire is an example of an exceptional event; it is something that affects air quality, but the local agency has no control over. No Events means no events occurred. Events Included means events occurred and the data from them is included in the summary. Events Excluded means that events occurred but data form them is excluded from the summary. Concurred Events Excluded means that events occurred but only EPA concurred exclusions are removed from the summary. If an event occurred for the parameter in question, the data will have multiple records for each monitor.\n\n17. Observation Count: The number of observations (samples) taken during the year.\n\n18. Observation Percent: The percent representing the number of observations taken with respect to the number scheduled to be taken during the year. This is only calculated for monitors where measurements are required (e.g., only certain parameters).\n\n19. Completeness Indicator: An indication of whether the regulatory data completeness criteria for valid summary data have been met by the monitor for the year. Y means yes, N means no or that there are no regulatory completeness criteria for the parameter.\n\n20. Valid Day Count: The number of days during the year where the daily monitoring criteria were met, if the calculation of the summaries is based on valid days.\n\n21. Required Day Count:  The number of days during the year which the monitor was scheduled to take samples if measurements are required.\n\n22. Exceptional Data Count: The number of data points in the annual data set affected by exceptional air quality events (things outside the norm that affect air quality).\n\n23. Null Data Count: The count of scheduled samples when no data was collected and the reason for no data was reported.\n\n24. Primary Exceedance Count: The number of samples during the year that exceeded the primary air quality standard.\n\n25. Secondary Exceedance Count: The number of samples during the year that exceeded the secondary air quality standard.\n\n26. Certification Indicator: An indication whether the completeness and accuracy of the information on the annual summary record has been certified by the submitter. Certified means the submitter has certified the data (due May 01 the year after collection). Certification not required means that the parameter does not require certification or the deadline has not yet passed. Uncertified (past due) means that certification is required but is overdue. Requested but not yet concurred means the submitter has completed the process, but EPA has not yet acted to certify the data. Requested but denied means the submitter has completed the process, but EPA has denied the request for cause. Was certified but data changed means the data was certified but data was replaced and the process has not been repeated.\n\n27. Num Obs Below MDL: The number of samples reported during the year that were below the method detection limit (MDL) for the monitoring instrument. Sometimes these values are replaced by 1/2 the MDL in summary calculations.\n\n28. Arithmetic Mean: The average (arithmetic mean) value for the year.\n\n29. Arithmetic Standard Dev: The standard deviation about the mean of the values for the year.\n\n30. 1st Max Value: The highest value for the year.\n\n31. 1st Max DateTime: The date and time (on a 24-hour clock) when the highest value for the year (the previous field) was taken.\n\n32. 2nd Max Value: The second highest value for the year.\n\n33. 2nd Max DateTime: The date and time (on a 24-hour clock) when the second highest value for the year (the previous field) was taken.\n\n34. 3rd Max Value: The third highest value for the year.\n\n35. 3rd Max DateTime: The date and time (on a 24-hour clock) when the third highest value for the year (the previous field) was taken.\n\n36. 4th Max Value: The fourth highest value for the year.\n\n37. 4th Max DateTime: The date and time (on a 24-hour clock) when the fourth highest value for the year (the previous field) was taken.\n\n38. 1st Max Non Overlapping Value: For 8-hour CO averages, the highest value of the year.\n\n39. 1st NO Max DateTime: The date and time (on a 24-hour clock) when the first maximum non overlapping value for the year (the previous field) was taken.\n\n40. 2nd Max Non Overlapping Value: For 8-hour CO averages, the second highest value of the year that does not share any hours with the 8-hour period of the first max non overlapping value.\n\n41. 2nd NO Max DateTime: The date and time (on a 24-hour clock) when the second maximum non overlapping value for the year (the previous field) was taken.\n\n42. 99th Percentile: The value from this monitor for which 99 per cent of the rest of the measured values for the year are equal to or less than.\n\n43. 98th Percentile: The value from this monitor for which 98 per cent of the rest of the measured values for the year are equal to or less than.\n\n44. 95th Percentile: The value from this monitor for which 95 per cent of the rest of the measured values for the year are equal to or less than.\n\n45. 90th Percentile: The value from this monitor for which 90 per cent of the rest of the measured values for the year are equal to or less than.\n\n46. 75th Percentile: The value from this monitor for which 75 per cent of the rest of the measured values for the year are equal to or less than.\n\n47. 50th Percentile: The value from this monitor for which 50 per cent of the rest of the measured values for the year are equal to or less than (i.e., the median).\n\n48. 10th Percentile: The value from this monitor for which 10 per cent of the rest of the measured values for the year are equal to or less than.\n\n49. Local Site Name: The name of the site (if any) given by the State, local, or tribal air pollution control agency that operates it.\n\n50. Address: The approximate street address of the monitoring site.\n\n51. State Name: The name of the state where the monitoring site is located.\n\n52. County Name: The name of the county where the monitoring site is located.\n\n53. City Name: The name of the city where the monitoring site is located. This represents the legal incorporated boundaries of cities and not urban areas.\n\n54. CBSA Name: The name of the core bases statistical area (metropolitan area) where the monitoring site is located.\n\n55. Date of Last Change: The date the last time any numeric values in this record were updated in the AQS data system.\n\n###Acknowledgements: \nThese data come from the EPA. You can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the data on Google BigQuery, too: [https://cloud.google.com/bigquery/public-data/epa][1]\n\n\n\n###Inspiration: \nWithin these data are tons of ways for you to learn about air pollution and how it can affect our health and environment. You can also compare key air emissions to gross domestic product, vehicle miles traveled, population, and energy consumption back to 1970. Best of all, you can check out air trends where you live!\n\n\n  [1]: https://cloud.google.com/bigquery/public-data/epa'","b""['climate', 'environment', 'medium', 'featured']""",https://www.kaggle.com/epa/air-quality
b'2016 VOTER Survey Data Set',"b'Unique Longitudinal Data Set on ~8k Voters, 2011-16'","b'### Context\n\n[The Democracy Fund Voter Study Group](https://www.voterstudygroup.org/about) is using a unique longitudinal data set that most recently surveyed 8,000 adults (age 18+) in December 2016 via\xc2\xa0[YouGov](https://today.yougov.com/). Participants were identified from a pool of respondents who participated in a similar survey in December 2011, as well as a second pre-election interview in 2012, and a third interview following the 2012 presidential election. For these 8,000 respondents, we have measures of their political attitudes, values, and affinities in 2011 as well as self-reports of their turnout and vote choice in November 2012.\n\n\n### Content\n\nThe VOTER (Views of the Electorate Research) Survey was conducted by the survey firm [YouGov](https://today.yougov.com/). In total, 8,000 adults (age 18+) with internet access took the survey online between November 29 and December 29, 2016. The estimated margin of error is plus or minus 2.2 percent. YouGov also supplied measures of primary voting behavior from the end of the primary period (July 2016), when these respondents had been contacted as part of a different survey project. \n\nThese respondents were originally interviewed by YouGov in 2011 to 2012 as part of the 2012 Cooperative Campaign Analysis Project (CCAP). In that survey, 45,000 respondents were first interviewed in December 2011 and were interviewed a second time in one of the 45 weekly surveys between January 1 and November 8, 2012. After the November election, 35,408 respondents were interviewed a third time. We invited 11,168 panelists from the 2012 CCAP. Of those invited, 8,637 (77 percent) completed the 2016 VOTER Survey. \n\nThe 2012 CCAP was constructed using YouGov\xe2\x80\x99s sample matching procedure. A stratified sample is drawn from YouGov\xe2\x80\x99s panel, which consists of people who have agreed to take occasional surveys. The strata are defined by the combination of age, gender, race, and education, and each stratum is sampled in proportion to its size in the U.S. population. Then, each element of this sample is matched to a synthetic sampling frame that is constructed from the U.S. Census Bureau\xe2\x80\x99s American Community Survey, the Current Population Survey Voting and Registration Supplement, and other databases. The matching procedure finds the observation in the sample from YouGov\xe2\x80\x99s panel that most closely matches each observation in the synthetic sampling frame on a set of demographic characteristics. The resulting sample is then weighted by a set of demographic and non-demographic variables. \n\nInformation on variables can be found in the [""Guide to the 2016 Voter Survey""](https://www.voterstudygroup.org/publications/2016-elections/data) and included in the dataset.\n\n\n### Acknowledgements\n\n[The Democracy Fund](http://www.democracyfund.org/), a charitable foundation committed to the protection and enhancement of democratic values, found the rise of these movements and candidates worthy of analysis. In May 2016, the Democracy Fund chose to begin a rigorous project that would supply hard data to test proposed theories to explain these phenomenon. Working with\xc2\xa0[Henry Olsen](https://www.voterstudygroup.org/participants/henry-olsen)\xc2\xa0of the\xc2\xa0[Ethics and Public Policy Center](https://eppc.org/)\xc2\xa0and\xc2\xa0[John Sides](https://www.voterstudygroup.org/participants/john-sides)\xc2\xa0of\xc2\xa0[George Washington University](https://www.gwu.edu/), the Democracy Fund assembled a diverse group of scholars and analysts representing political viewpoints from all angles.\n\nAdditional information on participants can be found [here](https://www.voterstudygroup.org/about).\n\nData was originally published [here](https://www.voterstudygroup.org/publications/2016-elections/data).\n\nTo reference\xc2\xa0the VOTER survey, please use this protocol:\nDemocracy Fund Voter Study Group. VIEWS OF THE ELECTORATE RESEARCH SURVEY, December 2016. [Computer File] Release 1: August 28, 2017. Washington DC: Democracy Fund Voter Study Group [producer]\xc2\xa0https://www.voterstudygroup.org/.\n\n\n### Inspiration\n\n[The Democracy Fund Voter Study Group](https://www.voterstudygroup.org/about) has made available a [series of insights](https://www.voterstudygroup.org/publications/2016-elections/data) on the dataset--read them for further data inspiration:\n\n* [Executive Summary](https://www.voterstudygroup.org/publications/2016-elections/executive-summary)\n* [Political Divisions in 2016 and Beyond](https://www.voterstudygroup.org/publications/2016-elections/political-divisions-in-2016-and-beyond)\n* [Race, Religion, and Immigration in 2016](https://www.voterstudygroup.org/publications/2016-elections/race-religion-immigration-2016)\n* [The Story of Trump\'s Appeal](https://www.voterstudygroup.org/publications/2016-elections/story-of-trumps-appeal)\n* [The Five Types of Trump Voters](https://www.voterstudygroup.org/publications/2016-elections/the-five-types-trump-voters)\n* [Methodology](https://www.voterstudygroup.org/publications/2016-elections/methodology)\n* [Read the latest news and updates from (and about) the Democracy Fund Voter Study Group](https://www.voterstudygroup.org/newsroom).'","b""['medium', 'featured']""",https://www.kaggle.com/democracy-fund/2016-voter-survey
b'Seattle Unreinforced Masonry Buildings',b'From City of Seattle Open Data',"b""### Content  \n\nA list of known unreinforced masonry buildings in the Seattle city limits.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/rNbznfUV_y8) by [Mike Wilson](https://unsplash.com/@mkwlsn) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-unreinforced-masonry-buildings
b'Urban Dictionary Words And Definitions',b'Corpus of 2.6 million words with ratings from urban dictionary',"b'### Context\n\nThis dataset contains 2.6 million words from **Urban Dictionary**, including their definitions and votes in CSV format.\n\nSource: https://www.urbandictionary.com\n\nTo lookup a word in the dataset via urban dictionary api: \nhttp://api.urbandictionary.com/v0/define?defid={word_id}\n\n### Content\n\nRows: **2,606,522**\n\nColumn 1: word_id - for usage in urban dictionary api\n\nColumn 2: word - the text being defined\n\nColumn 3: up_votes - thumbs up count as of may 2016\n\nColumn 4: down_votes - thumbs down count as of may 2016\n\nColumn 5: author - hash of username of submitter\n\nColumn 6: definition - text with possible utf8 chars, double semi-colon denotes a newline\n\n### Acknowledgements\n\nOriginal contribution by mitalu: https://archive.org/details/UrbanDictionary1999-May2016DefinitionsCorpus\n\nFeel free to contribute sizeable scrapes done after May 2016 by posting a link to your github here.\n\n### Inspiration\n\nModified and cleaned the original source which is in an un-friendly format.\n\nWith Credits to HotShot Librarian Aaron Peckham.'","b""['internet', 'linguistics', 'medium', 'featured']""",https://www.kaggle.com/therohk/urban-dictionary-words-dataset
b'Austin Waste and Diversion',"b'Garbage In, Garbage Out'","b'### Context: \nThis dataset is trash. Who in Austin makes it, who takes it, and where does it go?\n\n### Content: \nData ranges 2008-2016 and includes dropoff site, load id, time of load, type of load, weight of load, date, route number, and route type (recycling, street cleaning, garbage etc).\n\n### Acknowledgements: \nThis dataset was created by [Austin](https://data.austintexas.gov/) city government and hosted on Google Cloud Platform. You can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the [data on BigQuery, too](https://cloud.google.com/bigquery/public-data/)\n\n### Inspiration: \n* How much trash is Austin generating?\n* Which are the trashiest routes? Who recycles the best?\n* Any seasonal changes?\n* Try to predict trash route usage from historical trash data'","b""['government agencies', 'medium', 'featured']""",https://www.kaggle.com/jboysen/austin-waste
b'NYS Wastewater Treatment Plants',b'From New York State Open Data',"b""### Content  \n\nData regarding wastewater treatment plants with permits issued under the New York State Pollutant Discharge Elimination System  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/21ae7tGpJtE) by [Sweet Ice Cream Photography](https://unsplash.com/@sweeticecreamwedding) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-wastewater-treatment-plants
"b'Chicago Employee Overtime, Supplemental Earnings'",b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.""","b""['socrata', 'small', 'featured']""","https://www.kaggle.com/chicago/chicago-employee-overtime,-supplemental-earnings"
b'Estimate of People of All Ages in Poverty Data',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/R3mRt8VQM10) by [Jamie Street](https://unsplash.com/@jamie452) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/estimate-of-people-of-all-ages-in-poverty-data
b'LISA Traffic Light Dataset',b'More than 44 minutes of annotated traffic light data',"b'## Context\n\nWhen evaluating computer vision projects, training and test data are essential. The used data is a representation of a challenge a proposed system shall solve. It is desirable to have a large database with large variation representing the challenge, e.g detecting and recognizing traffic lights (TLs) in an urban environment. From surveying existing work it is clear that currently evaluation is limited primarily to small local datasets gathered by the authors themselves and not a public available dataset. The local datasets are often small in size and contain little variation. This makes it nearly impossible to compare the work and results from different author, but it also become hard to identify the current state of a field. In order to provide a common basis for future comparison of traffic light recognition (TLR) research, an extensive public database is collected based on footage from US roads. The database consists of continuous test and training video sequences, totaling 43,007 frames and 113,888 annotated traffic lights. The sequences are captured by a stereo camera mounted on the roof of a vehicle driving under both night- and daytime with varying light and weather conditions. Only the left camera view is used in this database, so the stereo feature is in the current state not used.\n\n\n## Content\n\nThe database is collected in San Diego, California, USA. The database provides four day-time and two night-time sequences primarily used for testing, providing 23 minutes and 25 seconds of driving in Pacific Beach and La Jolla, San Diego. The stereo\nimage pairs are acquired using the Point Grey\xe2\x80\x99s Bumblebee XB3 (BBX3-13S2C-60) which contains three lenses which capture images with a resolution of 1280 x 960, each with a Field of View(FoV) of 66\xc2\xb0.  Where the left camera view is used for all the test sequences and training clips. The training clips consists of 13 daytime clips and 5 nighttime clips.\n\n### Annotations\nThe annotation.zip contains are two types of annotation present for each sequence and clip. The first annotation type contains information of the entire TL area and what state the TL is in. This annotation file is called frameAnnotationsBOX, and is generated from the second annotation file by enlarging all annotation larger than 4x4. The second one is annotation marking only the area of the traffic light which is lit and what state it is in. This second annotation file is called frameAnnotationsBULB. \n\nThe annotations are stored as 1 annotation per line with the addition of information such as class tag and file path to individual image files. With this structure the annotations are stored in a csv file, where the structure is exemplified in below listing:\n\n\n``\nFilename;Annotation tag;Upper left corner X;Upper left corner Y;Lower right corner X;Lower right corner Y;Origin file;Origin frame number;Origin track;Origin track frame number\n``\n\n## Acknowledgements\nWhen using this dataset we would appreciate if you cite the following papers:\n\nJensen MB, Philipsen MP, M\xc3\xb8gelmose A, Moeslund TB, Trivedi MM. [Vision for Looking at Traffic Lights: Issues, Survey, and Perspectives](http://ieeexplore.ieee.org/document/7398055/). I E E E Transactions on Intelligent Transportation Systems. 2016 Feb 3;17(7):1800-1815. Available from, DOI: 10.1109/TITS.2015.2509509\n\nPhilipsen, M. P., Jensen, M. B., M\xc3\xb8gelmose, A., Moeslund, T. B., & Trivedi, M. M. (2015, September). [Traffic light detection: A learning algorithm and evaluations on challenging dataset](http://ieeexplore.ieee.org/document/7313470/). In intelligent transportation systems (ITSC), 2015 IEEE 18th international conference on (pp. 2341-2345). IEEE.\n\n### Bibtex\n```\n@article{jensen2016vision,\n  title={Vision for looking at traffic lights: Issues, survey, and perspectives},\n  author={Jensen, Morten Born{\\o} and Philipsen, Mark Philip and M{\\o}gelmose, Andreas and Moeslund, Thomas Baltzer and Trivedi, Mohan Manubhai},\n  journal={IEEE Transactions on Intelligent Transportation Systems},\n  volume={17},\n  number={7},\n  pages={1800--1815},\n  year={2016},\n  doi={10.1109/TITS.2015.2509509},\n  publisher={IEEE}\n}\n```\n\n\n```\n@inproceedings{philipsen2015traffic,\n  title={Traffic light detection: A learning algorithm and evaluations on challenging dataset},\n  author={Philipsen, Mark Philip and Jensen, Morten Born{\\o} and M{\\o}gelmose, Andreas and Moeslund, Thomas B and Trivedi, Mohan M},\n  booktitle={intelligent transportation systems (ITSC), 2015 IEEE 18th international conference on},\n  pages={2341--2345},\n  year={2015},\n  organization={IEEE}\n}\n```'","b""['classification', 'image processing', 'multiclass classification', 'object detection', 'computer science', 'large', 'featured']""",https://www.kaggle.com/mbornoe/lisa-traffic-light-dataset
b'Boardgaming Online Game Records',"b'30k+ playthroughs of the board game ""Through the Ages""'","b'### Context\n\nI scraped data from [boardgaming-online.com](http://boardgaming-online.com/), in order to analyze it and improve my skill at the board game ""[Through the Ages](https://boardgamegeek.com/boardgame/25613/through-ages-story-civilization)"".\n\n### Content\n\nThe raw data consists of over 30k game journals scraped from the website. Each of the game journals is in the form of a `pandas` `DataFrame` serialized to a file as a [pickle](https://docs.python.org/3/library/pickle.html) (a type of object store built into Python). These are uploaded in a `ZIP` file and available from `../input/tta/TTA/` folder when using the dataset in a kernel.\n\nThere are also two cleaned and parsed files ready for further analysis. `TechXYFullAlt` was parsed with customized codes with my knowledge of the game, `NLP34` is just a compressed version of the Journals, suitable for some Natural Language Processing. The [Exploring the Data and some NLP](https://www.kaggle.com/jingking/exploring-the-data-and-some-nlp/) kernel explores in some more details.\n\n### Acknowledgements\n\nI thank the web-administrator for boardgameing-online for tolerating the scraping.\n\n\n### Inspiration\n\nWell, like anyone else who plays a game: how do I win? :P'","b""['board games', 'medium', 'featured']""",https://www.kaggle.com/jingking/boardgaming-online-processed-game-records
b'NY Handyman Work Order (HWO) Charges',b'From New York City Open Data',"b""### Content  \n\nContains information about work orders created to conduct emergency repair work when an owner fails to address a hazardous condition pursuant to the requirements of an HPD issued violation. HPD issues violations when an owner fails to address a condition pursuant New York City Housing Maintenance Code (HMC) or the New York State Multiple Dwelling Law (MDL), a Department of Buildings Declaration of Emergency, a Department of Health Commissioner's Order to Abate or an emergency violation issued by another City Agency. The work orders were carried out by agency staff.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/oSdpVvf7PBs) by [Phil Botha](https://unsplash.com/@philbotha) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-handyman-work-order-hwo-charges
b'US Energy Statistics',b'All data published by the US Energy Information Administration',"b""This dataset contains the entire contents of each major API data set published by the US [Energy Information Administration][1]. That's everything from the hourly electricity consumption in the United States to natural gas futures contracts. \n\nThis data has been lightly reprocessed from the EIA's [bulk download facility][2] by converting each file from a zip of jsons into a single json with the series name as the keys to the specific time series.  Please note that there are thousands of time series in here, and many of them may still require additional cleaning to deal with odd date formats and so on. The file preview is unable to show a complete listing. You can usually find full details of a given time series in the 'description' field.\n\n\n\n  [1]: https://www.eia.gov/\n  [2]: https://www.eia.gov/opendata/bulkfiles.php""","b""['energy', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/sohier/us-energy-statistics
b'Seattle Crime Stats',b'From City of Seattle Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/1LOKfF930E4) by [Nitish Meena](https://unsplash.com/@nitishm) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Creative Commons 1.0 Universal (Public Domain Dedication), Public Domain""","b""['socrata', 'crime', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-crime-stats
b'NYS Capital District Bus Stops',b'From New York State Open Data',"b""### Content  \n\nBus stops from the Capital District Transportation Authority  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/9nxbSS-lK1o) by [freestocks.org](https://unsplash.com/@freestocks) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-capital-district-bus-stops
b'Consumer Business Complaints in Brazil',b'Consumer complaints about issues with business in Brazil',b'### Context\n\nWhen Brazilian consumers need to resolve a dispute with business the first step is to go to a local Procon (Consumer Protection Agency) and file a complaint. The Procon assists the consumer and intermediates the resolution with the company.\n\n\n### Content\n\nThis dataset contains information about complaints filed in Procons between 2012 and 2016.  This data was download from official Brazilian government open data [website](http://dados.gov.br/dataset/cadastro-nacional-de-reclamacoes-fundamentadas-procons-sindec1)',"b""['business', 'brazil', 'medium', 'featured']""",https://www.kaggle.com/gerosa/procon
b'The Works of Charles Darwin',b'Collected from Project Gutenberg [text]',"b'### Context\n\nThis is a collection of all the works of Charles Darwin that are available through [Project Gutenberg](http://www.gutenberg.org/).\n\nThis dataset is subject to the [Project Gutenberg license](http://www.gutenberg.org/wiki/Gutenberg:The_Project_Gutenberg_License).\n\nIt is very possible that I have missed some of his works. Please add them and update the ""Last updated"" date below if you get the chance. Otherwise, if you leave a comment on this dataset, I will try and do so myself.\n\n\n### Content\n\nLast updated: October 13, 2017\n\nThis dataset consists of the following works in TXT format:\n\n1. ""On the Origin of Species by Means of Natural Selection or the Preservation of Favoured Races in the Struggle for Life."" - `pg22764.txt`\n\n1. ""The Formation of Vegetable Mould through the action of worms with observations on their habits"" - `2355-0.txt`\n\n1. ""The Descent of Man and Selection in Relation to Sex, Vol. I (1st edition)"" - `34967-0.txt`\n\n1. ""The Descent of Man and Selection in Relation to Sex Volume II (1st Edition)"" - `36520-0.txt`\n\n1. ""A Monograph on the Sub-class Cirripedia (Volume 1 of 2)"" - `pg31558.txt`\n\n1. ""A Monograph on the Sub-class Cirripedia (Volume 2 of 2)"" - `46408-0.txt`\n\n1. ""The Foundations of the Origin of Species"" - `pg22728.txt`\n\n1. ""Coral Reefs"" - `pg2690.txt`\n\n1. ""More Letters of Charles Darwin Volume II"" - `pg2740.txt`\n\n1. ""The Variation of Animals and Plants under Domestication Volume I"" - `pg2871.txt`\n\n1. ""The Variation of Animals and Plants under Domestication Volume II"" - `pg2872.txt`\n\n1. ""South American Geology"" or ""Geological Observations On South America"" - `pg3620.txt`\n\n1. ""The Different Forms of Flowers on Plants of the Same Species"" - `pg3807.txt`\n\n1. ""The Effects of Cross & Self-Fertilisation in the Vegetable Kingdom"" - `pg4346.txt`\n\n1. ""The Movement and Habits of Climbing Plants"" - `2485-0.txt`\n\n1. ""The Expression of Emotion in Man and Animals"" - `pg1227.txt`\n\n1. ""The Life and Letters of Charles Darwin, Volume I (of II)"" - `pg2087.txt`\n\n1. ""The Life and Letters of Charles Darwin, Volume II (of II)"" - `pg2088.txt`\n\n1. ""More Letters of Charles Darwin Volume I (of II)"" - `pg2739.txt`\n\n1. ""A Naturalist\'s Voyage Round the World The Voyage Of The Beagle"" - `pg3704.txt`\n\n1. ""Charles Darwin: His Life in an Autobiographical Chapter, and in a Selected Series of His Published Letters"" - `pg38629.txt`\n\n1. ""Insectivorous Plants"" - `pg5765.txt`\n\n\n### Acknowledgements\n\nContent taken from [Project Gutenberg](http://www.gutenberg.org/)\n\nImage taken from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Charles_Darwin_by_Julia_Margaret_Cameron_2.jpg)\n\n\n### Inspiration\n\nMaking this data available for any kind of textual analysis. I intend for this to be part of a series.'","b""['biology', 'books', 'scientists', 'medium', 'featured']""",https://www.kaggle.com/fuzzyfroghunter/darwin
b'US Minimum Wage by State from 1968 to 2017',b'US Minimum Wage by State from 1968 to 2017 and 2018 Equivalent Dollars',"b""### Context\n\nWhile looking online for a clean dataset for minimum wage data by state, I was having trouble finding one. Thus, I decided to create one myself and provide it to the community! I truly believe that supporting a country's/state's workers is incredibly important, and support (or lack thereof) should be transparent.\n\nI scraped the data from [the US Department of Labor's website.][2] [The GitHub repository (with R Code for the cleaning process) can be found here!][1]\n\n### Content\n\nThis is a cleaned data set of US state and federal minimum wages from 1968 to 2017 (including 2018 equivalency values). \n\nThe values in the dataset are as follows:\n\n - Year: The year of the data.\n - State: The state or territory of the data.\n - Table_Data: The scraped value from the source.\n - Footnote: The footnote associated with the Table_Data. See more below in the dataset description. You can alternatively find them at [the bottom of the US Department of Labor's page][2].\n - High.Value: As there were some values in Table_Data that had multiple values (usually associated with footnotes), this is the higher of the two values in the table. It could be useful for viewing the proposed minimum wage, because in most cases, the higher value meant that all persons protected under minimum wage laws eventually had minimum wage set at that value.\n - Low.Value: This is the same as High.Value, but has the lower of the two values. This could be useful for viewing the effective minimum wage at the year of setting the minimum wage, as peoples protected under such minimum wage laws made that value during that year (although, in most cases, they had a higher minimum wage after that year).\n - CPI.Average: This is the Consumer Price Index associated with that year. It was used to calculate 2018-equivalent values.\n - High.2018: This is the 2018-equivalent dollars for High.Value.\n - Low.2018: This is the 2018-equivalent dollars for Low.Value. \n\n### Inspiration\n\nSupporting a country's workers is incredibly important, and support (or lack thereof) should be transparent. I am interested to see how minimum wage laws play a role in seeing the ideology of particular areas at a time.\n\n  [1]: https://github.com/Lislejoem/Minimum-Wage-by-State-1968-to-2017/tree/master\n  [2]: https://www.dol.gov/whd/state/stateMinWageHis.htm""","b""['economics', 'united states', 'history', 'money', 'small', 'featured']""",https://www.kaggle.com/lislejoem/us-minimum-wage-by-state-from-1968-to-2017
b'Civilian Unemployment Rate',b'Explore Time Series from the BLS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Bureau of Labor Statistics](http://www.bls.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according to the frequency that the data updates. Explore the OECD using Kaggle and all of the data sources available through the BLS [organization page](https://www.kaggle.com/bls)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/0Hvh69RZjXs) by [Mar\xc3\xada Victoria Heredia Reyes](https://unsplash.com/@_vickyreyes) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/bls/civilian-unemployment-rate
b'NYS Tuition Assistance Program Information',b'From New York State Open Data',"b""### Content  \n\nThe Tuition Assistance Program (TAP), New York's largest student financial aid grant program, helps eligible New York residents attending in-state postsecondary institutions pay for tuition. TAP grants are based on the applicant\xe2\x80\x99s and his or her family\xe2\x80\x99s New York State taxable income.  This data includes TAP award recipients and dollar amounts by college, sector groups, and Level of Study for academic years 2000-2011.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/sI1mbxJFFpU) by [JodyHongFilms](https://unsplash.com/@jhong8) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'education', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-tuition-assistance-program-information
b'NYS Department of State Business Filings',b'From New York State Open Data',"b""### Content  \n\nThe dataset includes demographic information setting forth the number of filings made by business entities with the Department of State\xe2\x80\x99s Division of Corporations.  Such filings are categorized by type and filer.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/sD_o5hGKBeE) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-department-of-state-business-filings
"b""Women's Shoe Prices""","b""A list of 10,000 women's shoes and the prices at which they are sold.""","b""# About This Data\nThis is a list of 10,000 women's shoes and their product information provided by [Datafiniti's Product Database][1]. \n\nThe dataset includes shoe name, brand, price, and more. Each shoe will have an entry for each price found for it and some shoes may have multiple entries. \n\n*Note that this is a sample of a large data set. The full data set is available through Datafiniti.*\n\n# What You Can Do with This Data\nYou can use this data to [determine brand markups, pricing strategies, and trends for luxury shoes][2]. E.g.:\n\n* What is the average price of each distinct brand listed?\n* Which brands have the highest prices?  \n* Which ones have the widest distribution of prices?\n* Is there a typical price distribution (e.g., normal) across brands or within specific brands?\n\nFurther processing data would also let you:\n\n* Correlate specific product features with changes in price.\n* You can cross-reference this data with a sample of our [Men's Shoe Prices](https://data.world/datafiniti/mens-shoe-prices) to see if there are any differences between women's brands and men's brands.\n\n# Data Schema\nA full schema for the data is available in our [support documentation][3].\n\n# About Datafiniti\nDatafiniti provides instant access to web data. We compile data from thousands of websites to create standardized databases of business, product, and property information. [Learn more][4].\n\n# Want More?\nYou can get more data like this by [joining Datafiniti][5] or [requesting a demo][6].\n\n  [1]: https://datafiniti.co/products/product-data/\n  [2]: https://datafiniti.co/luxury-shoe-brand-markup/\n  [3]: https://datafiniti-api.readme.io/docs/product-data-schema\n  [4]: https://datafiniti.co\n  [5]: https://portal.datafiniti.co/login\n  [6]: https://datafiniti.co/request-a-demo/""","b""['business', 'clothing', 'small', 'featured']""",https://www.kaggle.com/datafiniti/womens-shoes-prices
b'NYC Capital Project Schedules and Budgets',b'From New York City Open Data',"b""### Content  \n\nList of capital projects with managing organization, phase status and project costs.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.""","b""['socrata', 'education', 'construction', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-capital-project-schedules-and-budgets
b'Recipient-executed Grants Data',b'From World Bank Financial Open Data',"b""### Content  \n\nA Recipient-executed Grant is a Trust Fund Grant that is provided to a third party under a grant agreement, and for which the Bank plays an operational role - i.e., the Bank normally appraises and supervises activities financed by these funds. This dataset provides data on the amount of grant funds committed in the course of a fiscal year and payments made out of a Trust Fund account to eligible recipients, in accordance with the legal agreements.  In fulfilling its responsibilities, the World Bank as Trustee complies with all sanctions applicable to World Bank transactions. All definitions should be regarded at present as provisional and not final, and are subject to revision at any time.\r\n\r\nData is provided at the individual Trust Fund level and is updated as of 03/14/2013. No further updates are planned for this particular dataset, please visit the Global Partnership and Trust Fund Operations website for more details: http://go.worldbank.org/GABMG2YEI0  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](finances.worldbank.org) and they update their information according the amount of data that is brought in. Explore World Bank's Financial Data using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.\n\nThis dataset is distributed under a [Creative Commons Attribution 3.0 IGO](https://creativecommons.org/licenses/by/3.0/igo/) license.  \n\n[Cover photo](https://unsplash.com/photos/F7KPyatac-g) by [Jackson Hendry](https://unsplash.com/@actionjackson801) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under Creative Commons Attribution 3.0 IGO""","b""['socrata', 'utility', 'small', 'featured']""",https://www.kaggle.com/theworldbank/recipient-executed-grants-data
b'RSNA Bone Age',b'Predict Age from X-Rays',"b'### Context\n\nAt RSNA 2017 there was a contest to correctly identify the age of a child from an X-ray of their hand. This is the dataset on Kaggle making it easier to experiment with and do educational demos. Additionally maybe there are some new ideas for building smarter models for handling X-ray images.\n\n### Content\n\nA number of folders full of images (digital and scanned) with a CSV containing the age (what is to be predicted) and the gender (useful additional information)\n\n\n### Acknowledgements\n\nThe dataset was originally published on [CloudApp](http://rsnachallenges.cloudapp.net/competitions/4#results) as an RSNA challenge.\n\n### Original Dataset Acknowledgements\n\nThe Radiological Society of North America (RSNA) Radiology Informatics Committee (RIC) Pediatric Bone Age Machine Learning Challenge Organizing Committee: \n\n - Kathy Andriole, Massachusetts General Hospital\n - Brad Erickson, Mayo Clinic\n - Adam Flanders, Thomas Jefferson University \n - Safwan Halabi, Stanford University\n - Jayashree Kalpathy-Cramer, Massachusetts General Hospital\n - Marc Kohli, University of California - San Francisco \n - Luciano Prevedello, The Ohio State University\n\nData sets used in the Pediatric Bone Age Challenge have been contributed by Stanford University, the University of Colorado and the University of California - Los Angeles. \n\nThe MedICI platform (built CodaLab) used for the challenge is provided by Jayashree Kalpathy-Cramer, supported through NIH grants (U24CA180927) and a contract from Leidos.\n\n### Inspiration\n\n- Can you predict with better than 4.2 months accuracy? \n- Is identifying the joints an important step?\n- What algorithms work best?\n- What do the algorithms focus on?\n- Is gender a necessary piece of information or can it be automatically derived from the image?'","b""['image data', 'healthcare', 'orthopedic surgery', 'pediatrics', 'large', 'featured']""",https://www.kaggle.com/kmader/rsna-bone-age
b'Robocall Complaints',b'Consumer complaints filed with the FCC ',"b'Individual informal consumer complaint data detailing complaints filed with the Consumer Help Center beginning October 31, 2014. This data represents information selected by the consumer. The FCC does not verify the facts alleged in these complaints.\n\nThis dataset contains everything you need to analyze the jerk companies who call during dinner: time, mode of communication, logged phone number (of the hassler), and what they were trying to do. \n\n### Acknowledgements\n\nThis dataset was kindly made available by the FCC. You can find [the original dataset here][1].\n\n\n  [1]: https://opendata.fcc.gov/Consumer/CGB-Consumer-Complaints-Data/3xyp-aqkj'","b""['telecommunications', 'medium', 'featured']""",https://www.kaggle.com/fcc/robocall-complaints
b'Tatoeba',b'Crowd-source Example Sentence and Translations',b'### Context\n\nTatoeba is a crowd-sourced dataset made up of example sentences and their translations. \n\nThis dump uploaded on Kaggle is downloaded some time in Oct/Nov 2017. The latest dumps can be downloaded from https://tatoeba.org/eng/downloads\n\n### Acknowledgements\n\nCredits goes to the maintainers and the crowd on https://tatoeba.org\n\nCredits of the banner image goes to [Patrick Tomasso](https://unsplash.com/photos/Oaqk7qqNh_c)\n### License\n\nThe official license is CC BY-SA 2.0\n\n',"b""['linguistics', 'languages', 'medium', 'featured']""",https://www.kaggle.com/alvations/tatoeba
b'Iris Dataset (JSON Version)',b'A JSON version of the popular Iris Dataset',"b""### Content\n\nThis is a JSON version of the famous Iris dataset. It's provided as a introduction to the data storage format with a familiar dataset.\n\nIt has five keys: sepalLength, sepalWidth, petalLength, petalWidth and species.\n\n### Acknowledgements\n\nThe citation for this dataset is:\n\nFisher, R. A. (1936) The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7, Part II, 179\xe2\x80\x93188.\n\nThe data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, Bulletin of the American Iris Society, 59, 2\xe2\x80\x935.\n\n### Inspiration\n\nUse this dataset to practice reading JSON data into kernels and manipulating it. ""","b""['classification', 'clustering', 'botany', 'small', 'featured']""",https://www.kaggle.com/rtatman/iris-dataset-json-version
b'Agricultural Survey of African Farm Households',b'Survey of 9500+ households to study impact of climate change on agriculture',"b'### Context\n\n*Abstract*: Surveys for more than 9,500 households were conducted in the growing seasons 2002/2003 or 2003/2004 in eleven African countries: Burkina Faso, Cameroon, Ghana, Niger and Senegal in western Africa; Egypt in northern Africa; Ethiopia and Kenya in eastern Africa; South Africa, Zambia and Zimbabwe in southern Africa. Households were chosen randomly in districts that are representative for key agro-climatic zones and farming systems. The data set specifies farming systems characteristics that can help inform about the importance of each system for a country\xe2\x80\x99s agricultural production and its ability to cope with short- and long-term climate changes or extreme weather events. Further it informs about the location of smallholders and vulnerable systems and permits benchmarking agricultural systems characteristics.\n\n\n### Content\n\nThe data file contains survey data collected from different families and has 9597 rows that represent the households and 1753 columns with details about the households. The questionnaire was organized into seven sections and respondents were asked to relate the information provided to the previous 12 months\xe2\x80\x99 farming season. There are too many columns to describe here, however they are described in detail in this paper: [https://www.nature.com/articles/sdata201620?WT.ec_id=SDATA-201605][1]\n\n* Questionnaire.pdf: This file contains the questionnaire used, a description for each variable name and the question ID.\n\n* SurveyManual.pdf: This file gives further information on the household questionnaire, the research design and surveying. It was produced for the team leaders and interviewers in the World Bank/GEF project.\n\n* AdaptationCoding.pdf: This file describes codes for variables \xe2\x80\x98ad711\xe2\x80\x99 to \xe2\x80\x98ad7625\xe2\x80\x99 from section VII of the questionnaire on adaptation options.\n\nThere is also some description in how the data was collected in Survey.pdf.\n\n\n\n### Acknowledgements\n\nWaha, Katharina; Zipf, Birgit; Kurukulasuriya, Pradeep; Hassan, Rashid (2016): An agricultural survey for more than 9,500 African households. figshare.\nhttps://doi.org/10.6084/m9.figshare.c.1574094\n\nhttps://www.nature.com/articles/sdata201620?WT.ec_id=SDATA-201605\n\n\nThe original DTA file was converted to CSV\n\n\n\n### Inspiration\n\nThis dataset contains a huge amount of information related to farming households in Africa. Data like these are important for studying the impact of global warming on African agriculture and farming families. \n\n\n\n[1]: https://www.nature.com/articles/sdata201620?WT.ec_id=SDATA-201605'","b""['demographics', 'climate', 'agriculture', 'africa', 'medium', 'featured']""",https://www.kaggle.com/crawford/agricultural-survey-of-african-farm-households
b'Example brain mapping dataset',b'Which part of the brain is involved in moving your lips?',"b'### Context\n\nA test-retest fMRI dataset for motor, language and spatial attention functions.\n\n### Content\n\nSingle session, single subject from ds000114 dataset. Full dataset can be found at https://openneuro.org/datasets/ds000114. More info at https://dx.doi.org/10.1186%2F2047-217X-2-6\n\n- BOLD timeseries in standard space (MNI)\n- brain mask in standard space (MNI)\n- timing of in scanner stimuli\n- scanning parameters\n\n# Acknowledgements\n\nBanner Image by [Ken Treloar on Unsplash][1]\n\nFull dataset can be found at https://openneuro.org/datasets/ds000114. More info at https://dx.doi.org/10.1186%2F2047-217X-2-6\n\n  [1]: https://unsplash.com/photos/pFoA5Pphb-Q'","b""['image data', 'mental health', 'medium', 'featured']""",https://www.kaggle.com/chrisfilo/example-brain-mapping-dataset
b'NYS Alternative Fuel Stations in New York',b'From New York State Open Data',"b""### Content  \n\nGo to http://1.usa.gov/1gPN1u8 to access the full database of alternative fuel station locations nationwide, collected and maintained by the U.S. Department of Energy National Renewable Energy Laboratory.  A station appears as one point in the data and on the map, regardless of the number of fuel dispensers or charging outlets at that location.  For EV charging stations for example, the data includes the number of number of charging ports available at the specific station.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/w_a40DuyPAc) by [Karsten W\xc3\xbcrth (@inf1783)](https://unsplash.com/@inf1783) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-alternative-fuel-stations-in-new-york
b'Detailed NFL Play-by-Play Data 2009-2017',b'nflscrapR generated NFL dataset wiith expected points and win probability',"b'### Introduction\n\nThe lack of publicly available National Football League (NFL) data sources has been a major obstacle in the creation of modern, reproducible research in football analytics.  While clean play-by-play data is available via open-source software packages in other sports (e.g. nhlscrapr for hockey; PitchF/x data in baseball; the Basketball Reference for basketball), the equivalent datasets are not freely available for researchers interested in the statistical analysis of the NFL.  To solve this issue, a group of [Carnegie Mellon University statistical researchers](http://www.stat.cmu.edu) including Maksim Horowitz, Ron Yurko, and Sam Ventura, built and released [nflscrapR](https://github.com/maksimhorowitz/nflscrapR) an R package which uses an API maintained by the NFL to scrape, clean, parse, and output clean datasets at the individual play, player, game, and season levels.  Using the data outputted by the package, the trio went on to develop reproducible methods for building expected point and win probability models for the NFL. The outputs of these models are included in this dataset and can be accessed using the nflscrapR package.\n\n### Content\n\nThe dataset made available on Kaggle contains all the regular season plays from the 2009-2016 NFL seasons. The dataset has 356,768 rows and 100 columns. Each play is broken down into great detail containing information on: game situation, players involved, results, and advanced metrics such as expected point and win probability values. Detailed information about the dataset can be found at the following web page, along with more NFL data: https://github.com/ryurko/nflscrapR-data.\n\n### Acknowledgements\n\nThis dataset was compiled by Ron Yurko, Sam Ventura, and myself. Special shout-out to Ron for improving our current expected points and win probability models and compiling this dataset. All three of us are proud founders of the [Carnegie Mellon Sports Analytics Club](http://www.cmusportsanalytics.com/).\n\n### Inspiration\n\nThis dataset is meant to both grow and bring together the community of sports analytics by providing clean and easily accessible NFL data that has never been availabe on this scale for free.'","b""['sports', 'american football', 'medium', 'featured']""",https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016
b'League of Legends Ranked Matches',b'180000 ranked games of League of Legends starting from 2014',"b""### League of Legends Ranked Matches\n\nData about 184070 League of Legends ranked solo games, spanning across several years\n\n### Content\n\n - Matches\n - Player and team stats\n - Bans\n\n### Acknowledgements\n\nI found this data on a SQL database and exported it to CSV. All data belongs ultimately to Riot Games and their data policies applies.\nThese files are presented only as a simpler way to obtain a large dataset without stressing the Riot API and are in no way associated with Riot Games.\nThe data is provided as-is without any warranty on its correctness. If your algorithm catches fire, don't blame me or Riot.\nIf you are Rito and are opposed to sharing this data here, contact me and it will be removed immediately.\n\n### Possible questions\n\n - Can we predict the winner given the teams?\n - Can ranked matchmaking be assumed to be unbiased (or adjusted for red-side advantage)?\n - Does the region affect significantly win rates?\n - Can we compare the data in relation to competitive data (also available on Kaggle)?\n - Can we assess information on the different metas?""","b""['video games', 'medium', 'featured']""",https://www.kaggle.com/paololol/league-of-legends-ranked-matches
b'Speech Accent Archive',b'Parallel English speech samples from 177 countries',"b""### Context: \n\nEveryone who speaks a language, speaks it with an accent. A particular accent essentially reflects a person's linguistic background. When people listen to someone speak with a different accent from their own, they notice the difference, and they may even make certain biased social judgments about the speaker.\n\nThe speech accent archive is established to uniformly exhibit a large set of speech accents from a variety of language backgrounds. Native and non-native speakers of English all read the same English paragraph and are carefully recorded. The archive is constructed as a teaching tool and as a research tool. It is meant to be used by linguists as well as other people who simply wish to listen to and compare the accents of different English speakers.\n\nThis dataset allows you to compare the demographic and linguistic backgrounds of the speakers in order to determine which variables are key predictors of each accent. The speech accent archive demonstrates that accents are systematic rather than merely mistaken speech.\n\nAll of the linguistic analyses of the accents are available for public scrutiny. We welcome comments on the accuracy of our transcriptions and analyses.\n\n\n\n### Content: \n\nThis dataset contains 2140 speech samples, each from a different talker reading the same reading passage. Talkers come from 177 countries and have 214 different native languages. Each talker is speaking in English. \n\nThis dataset contains the following files:\n\n* reading-passage.txt: the text all speakers read\n* speakers_all.csv: demographic information on every speaker\n* recording: a zipped folder containing .mp3 files with speech\n\n\n### Acknowledgements: \n\nThis dataset was collected by many individuals (full list [here](http://accent.gmu.edu/about.php#credits)) under the supervision of Steven H. Weinberger. The most up-to-date version of the archive is hosted by [George Mason University](http://accent.gmu.edu/). If you use this dataset in your work, please include the following citation: \n\nWeinberger, S. (2013). Speech accent archive. George Mason University.\n\nThis datasets is distributed under a CC BY-NC-SA 2.0 license.\n\n### Inspiration: \n\nThe following types of people may find this dataset interesting:\n\n* ESL teachers who instruct non-native speakers of English\n* Actors who need to learn an accent\n* Engineers who train speech recognition machines\n* Linguists who do research on foreign accent\n* Phoneticians who teach phonetic transcription\n* Speech pathologists\n* Anyone who finds foreign accent to be interesting""","b""['linguistics', 'languages', 'acoustics', 'medium', 'featured']""",https://www.kaggle.com/rtatman/speech-accent-archive
b'FiveThirtyEight Comma Survey Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Comma Survey\n\nThis folder contains the data behind the story [Elitist, Superfluous, Or Popular? We Polled Americans on the Oxford Comma](https://fivethirtyeight.com/features/elitist-superfluous-or-popular-we-polled-americans-on-the-oxford-comma/).  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.  \n\n[Cover photo](https://unsplash.com/photos/UC5FpqofFOk) by [Sam McGhee](https://unsplash.com/@sammcghee) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-comma-survey-dataset
b'3 Million German Sentences',b'German language data from the Leipzig Corpus Collection',"b""### Context\n\nThe Leipzig Corpora Collection presents corpora in different languages using the same format and comparable sources. All data are available as plain text files and can be imported into a MySQL database by using the provided import script. They are intended both for scientific use by corpus linguists as well as for applications such as knowledge extraction programs. \n\n### Content\n\nThis dataset contains 3 million sentences taken from newspaper texts in 2015. Non-sentences and foreign language material was removed. In addition to the sentences themselves, this dataset contains information on the frequency of each word. More information about the format and content of these files can be found [here](http://pcai056.informatik.uni-leipzig.de/downloads/corpora/Format_Download_File-eng.pdf).\n\nThe corpora are automatically collected from carefully selected public sources without considering in detail the content of the contained text. No responsibility is taken for the content of the data. In particular, the views and opinions expressed in specific parts of the data remain exclusively with the authors.\n\n### Acknowledgements\n\nThis dataset is released under a [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/) license. If you use this dataset in your work, please cite the following paper:\n\nD. Goldhahn, T. Eckart & U. Quasthoff: Building Large Monolingual Dictionaries at the Leipzig Corpora Collection: From 100 to 200 Languages.\nIn: Proceedings of the 8th International Language Resources and Evaluation (LREC'12), 2012""","b""['linguistics', 'languages', 'medium', 'featured']""",https://www.kaggle.com/rtatman/3-million-german-sentences
b'SCA2 Diffusion Tensor Imaging',b'Imported from https://openneuro.org/datasets/ds001378',"b'Subjects and MRI protocol\n--------------------------------\n\nImported from https://openneuro.org/datasets/ds001378\n\nNine [spinocerebellar ataxia type 2 (SCA2)][1] patients and 16 age-matched healthy controls, were examined twice (SCA2 patients 3.6\xc2\xb10.7 years and controls 3.3\xc2\xb11.0 years apart) on the same 1.5T MRI scanner (Philips Intera, Best, The Netherlands) by acquiring: \n\n - sagittal 3D T1-weighted turbo gradient echo images [repetition time\n   (TR) = 8.1 ms, echo time (TE) = 3.7 ms, flip angle = 8\xc2\xb0, inversion\n   time = 764 ms, field of view (FOV) = 256 mm \xc3\x97 256 mm, matrix size =\n   256 \xc3\x97 256, 160 contiguous slices, slice thickness = 1 mm];\n - axial diffusion-weighted images by using a single-shot echo-planar\n   imaging sequence (TR = 9394 ms, TE = 89 ms, FOV = 256 mm \xc3\x97 256 mm,\n   matrix size = 128\xc3\x97128, 50 slices, slice thickness = 3 mm, no gap,\n   number of excitations = 3). Diffusion sensitizing gradients were\n   applied along 15 non-collinear and non-coplanar directions using\n   b-value of 0 (b0 image) and 1000 s/mm2.\n\nDefacing\n-----------\n\n[Pydeface][2] was used on all anatomical images to ensure de-identification of subjects.\n\nHow to acknowledge\n-------------------------\n\nPlease cite: [Mascalchi M, Marzi C, Giannelli M, Ciulli S, Bianchi A, Ginestroni A, Tessa C, Nicolai E, Aiello M, Salvatore E, Soricelli A, Diciotti S. DTI histogram analysis reveals progression of pontocerebellar degeneration in SCA2. DOI:10.1371/journal.pone.0200258][3]\n\n\n  [1]: https://ghr.nlm.nih.gov/condition/spinocerebellar-ataxia-type-2\n  [2]: https://github.com/poldracklab/pydeface\n  [3]: http://doi.org/10.1371/journal.pone.0200258'","b""['neuroscience', 'medium', 'featured']""",https://www.kaggle.com/openneuro/ds001378
b'NYC Open Market Order (OMO) Charges',b'From New York City Open Data',"b""### Content  \n\nContains information about work orders created to conduct emergency repair work when an owner fails to address a hazardous condition pursuant to the requirements of an HPD issued violation. HPD issues violations when an owner fails to address a condition pursuant New York City Housing Maintenance Code (HMC) or the New York State Multiple Dwelling Law (MDL), a Department of Buildings Declaration of Emergency, a Department of Health Commissioner's Order to Abate or an emergency violation issued by another City Agency. The work orders were issued to a private vendor following the City's Procurement Rules.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/kSlL887znkE) by [Jason Wong](https://unsplash.com/@jasonhk1920) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/nyc-open-market-order-omo-charges
b'NYS Parolees Under Community Supervision',b'From New York State Open Data',"b""### Content  \n\nProvides data about parolees under community supervision on March 31 of the snapshot year. Information includes region of supervision, county of residence, snapshot year, supervision level, gender, age as of the file date, and crime type for most serious instant offense.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/M4QR0XAq4Vw) by [Peter Hershey](https://unsplash.com/@peterhershey) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-parolees-under-community-supervision
b'The Works of Charles Dickens',b'Collected from Project Gutenberg [text]',"b'### Context\n\nThis is a collection of all the works of Charles Dickens that are available through [Project Gutenberg](http://www.gutenberg.org/).\n\nThis dataset is subject to the [Project Gutenberg license](http://www.gutenberg.org/wiki/Gutenberg:The_Project_Gutenberg_License).\n\nIt is very possible that I have missed some of his works. Please add them and update the ""Last updated"" date below if you get the chance. Otherwise, if you leave a comment on this dataset, I will try and do so myself.\n\nI did some very rough deduplication of his works. If I missed anything, please call it out with a comment and I will rectify the situation.\n\n\n### Content\n\nLast updated: October 13, 2017\n\n1. To be Read at Dusk - `924-0.txt`\n\n1. The Seven Poor Travellers - `pg1392.txt`\n\n1. The Pickwick Papers - `580-0.txt`\n\n1. A Message from the Sea - `pg1407.txt`\n\n1. The Old Curiosity Shop - `700-0.txt`\n\n1. Pictures from Italy - `650-0.txt`\n\n1. The Magic Fishbone A Holiday Romance from the Pen of Miss Alice Rainbird, Aged 7 - `pg23344.txt`\n\n1. A Tale of Two Cities A Story of the French Revolution - `98-0.txt`\n\n1. The Life And Adventures Of Nicholas Nickleby - `967-0.txt`\n\n1. Little Dorrit - `963-0.txt`\n\n1. The Uncommercial Traveller - `914-0.txt`\n\n1. Oliver Twist - `pg730.txt`\n\n1. Three Ghost Stories - `1289-0.txt`\n\n1. The Chimes - `653-0.txt`\n\n1. Mugby Junction - `27924-0.txt`\n\n1. Great Expectations - `1400-0.txt`\n\n1. The Battle of Life - `pg676.txt`\n\n1. David Copperfield - `766-0.txt`\n\n1. Bleak House - `pg1023.txt`\n\n1. Sketches by Boz illustrative of everyday life and every-day people - `882-0.txt`\n\n1. The Haunted Man and the Ghost\'s Bargain - `644-0.txt`\n\n1. A Child\'s History of England - `pg699.txt`\n\n1. American Notes for General Circulation - `675-0.txt`\n\n1. Hunted Down [1860] - `807-0.txt`\n\n1. Hard Times - `786-0.txt`\n\n1. The Mystery of Edwin Drood - `564-0.txt`\n\n1. Dickens\' Stories About Children Every Child Can Read - `pg32241.txt`\n\n1. The Cricket on the Hearth A Fairy Tale of Home - `678-0.txt`\n\n1. Our Mutual Friend - `883-0.txt`\n\n1. A Christmas Carol - `pg19337.txt`\n\n1. Barnaby Rudge - `917-0.txt`\n\n1. Some Christmas Stories - `1467-0.txt`\n\n\n### Acknowledgements\n\nContent taken from [Project Gutenberg](http://www.gutenberg.org/)\n\nImage taken from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Charles_Dickens_by_Daniel_Maclise.jpg)\n\n\n### Inspiration\n\nMaking this data available for any kind of textual analysis. I intend for this to be part of a series.'","b""['literature', 'writing', 'books', 'medium', 'featured']""",https://www.kaggle.com/fuzzyfroghunter/dickens
b'Boston Public Schools',b'Geo data for Boston Public Schools',b'Boston Public Schools (BPS) schools for the school year 2018-2019. Updated September 2018.\n\n',"b""['education', 'small', 'featured']""",https://www.kaggle.com/crawford/boston-public-schools
b'E-Commerce Data',b'Actual transactions from UK retailer',"b'### Context\n\nTypically e-commerce datasets are proprietary and consequently hard to find among publicly available data.  However, [The UCI Machine Learning Repository][1] has made this dataset containing actual transactions from 2010 and 2011.  The dataset is maintained  on their site, where it can be found by the title ""Online Retail"".\n\n### Content\n\n""This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.""\n\n### Acknowledgements\n\nPer the UCI Machine Learning Repository, this data was made available by Dr Daqing Chen, Director: Public Analytics group. chend \'@\' lsbu.ac.uk, School of Engineering, London South Bank University, London SE1 0AA, UK.\n\nImage from stocksnap.io.\n\n### Inspiration\n\nAnalyses for this dataset could include time series, clustering, classification and more. \n\n  [1]: http://archive.ics.uci.edu/ml/index.php'","b""['medium', 'featured']""",https://www.kaggle.com/carrie1/ecommerce-data
b'Seattle Parks and Recreation Data',b'From City of Seattle Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'people', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-parks-and-recreation-data
b'New York City Farmers Markets',b'From New York City Open Data',"b""### Content  \n\nLocation and facility information for New York City farmers markets.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is no longer updated.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nPhoto by [Dave Takisaki](https://unsplash.com/photos/TFdkcrw-_4M) on [Unsplash](https://unsplash.com/)""","b""['socrata', 'health', 'small', 'featured']""",https://www.kaggle.com/new-york-city/new-york-city-farmers-markets
b'Synthetic data from a financial payment system',b'Synthetic datasets generated by the BankSim payments simulator',"b'### Context\n\nBankSim is an **agent-based simulator of bank payments** based on a sample of aggregated transactional **data provided by a bank in Spain**. The main purpose of BankSim is the generation of synthetic data that can be used for fraud detection research.  Statistical and a Social Network Analysis (SNA) of relations between merchants and customers were used\nto develop and calibrate the model.  Our ultimate goal is for BankSim to be usable to model relevant scenarios that combine normal payments and injected known fraud signatures.  The data sets generated by BankSim contain no personal information or disclosure of legal and private customer transactions. Therefore, it can be shared by academia, and others, to develop and reason about fraud detection methods. Synthetic data has the added benefit of being easier to acquire, faster and at less cost, for experimentation even for those that have access to their own data. We argue that BankSim generates data that usefully approximates the relevant aspects of the real data. \n\n### Content\n\nWe ran BankSim for 180 steps (approx. six months), several times and calibrated the parameters in order to obtain a distribution that get close enough to be reliable for testing. We collected several log files and selected the most accurate. We injected thieves that aim to steal an average of three cards per step and perform about two fraudulent transactions per day. We produced 594643 records in total. Where 587443 are normal payments and 7200 fraudulent transactions. Since this is a randomised simulation the values are of course not identical to original data.\n\n### Acknowledgements\n\nThis research was conducted during my PhD studies in Sweden at Blekinge Institute of Technology (BTH ww.bth.se). More about it: http://edgarlopez.net\n\n### Original paper\n\nPlease refer to this dataset using the following citations:\n\nLopez-Rojas, Edgar Alonso ; Axelsson, Stefan\nBanksim: A bank payments simulator for fraud detection research Inproceedings\n26th European Modeling and Simulation Symposium, EMSS 2014, Bordeaux, France, pp. 144\xe2\x80\x93152, Dime University of Genoa, 2014, ISBN: 9788897999324.\nhttps://www.researchgate.net/publication/265736405_BankSim_A_Bank_Payment_Simulation_for_Fraud_Detection_Research'","b""['finance', 'medium', 'featured']""",https://www.kaggle.com/ntnu-testimon/banksim1
b'VGG-19 with batch normalization',b'VGG-19 Pre-trained model with batch normalization for PyTorch',"b'# VGG-19\n\n---\n\n## Very Deep Convolutional Networks for Large-Scale Image Recognition<br>\nIn this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.\n<br>\n\n**Authors: Karen Simonyan, Andrew Zisserman**<br>\n**https://arxiv.org/abs/1409.1556**\n\n---\n\n#VGG Architectures<br>\n![VGG Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/uLXrKxe.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/vgg19bn
b'Chicago Sex Offenders',b'From City of Chicago Open Data',"b""### Content  \n\nDescription: Pursuant to the Sex Offender and Child Murderer Community Notification Law, 730 ILCS 152/101,et seq., the Chicago Police Department maintains a list of sex offenders residing in the City of Chicago who are required to register under the Sex Offender Registration Act, 730 ILCS 150/2, et seq. To protect the privacy of the individuals, addresses are shown at the block level only and specific locations are not identified. The data are extracted from the CLEAR (Citizen Law Enforcement Analysis and Reporting) system developed by the Department.\r\nAlthough every effort is made to keep this list accurate and current, the city cannot guarantee the accuracy of this information. Offenders may have moved and failed to notify the Chicago Police Department as required by law. If any information presented in this web site is known to be outdated, please contact the Chicago Police Department at srwbmstr@chicagopolice.org, or mail to Sex Registration Unit, 3510 S Michigan Ave, Chicago, IL 60653.\r\nDisclaimer: This registry is based upon the legislature's decision to facilitate access to publicly available information about persons convicted of specific sexual offenses. The Chicago Police Department has not considered or assessed the specific risk of re-offense with regard to any individual prior to his or her inclusion within this registry, and has made no determination that any individual included within the registry is currently dangerous. Individuals included within this registry are included solely by virtue of their conviction record and Illinois law. The main purpose of providing this data on the internet is to make the information more available and accessible, not to warn about any specific individual. \r\n\r\nAnyone who uses information contained in the Sex Offender Database to commit a criminal act against another person is subject to criminal prosecution.\r\nData Owner: Chicago Police Department.\r\nFrequency: Data is updated daily.\r\nRelated Applications: CLEARMAP (http://j.mp/lLluSa).  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/3Tf1J8q9bBA) by [Markus Spiske](https://unsplash.com/@markusspiske) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'crime', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-sex-offenders
b'NYC Lower Manhattan Retailers',b'From New York City Open Data',"b""### Content  \n\nListing of lower Manhattan retailers  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/EjVWRqzVLP4) by [D\xc6\xb0\xc6\xa1ng Tr\xe1\xba\xa7n Qu\xe1\xbb\x91c](https://unsplash.com/@fanhungry) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-lower-manhattan-retailers
b'Yellow Pages of Pakistan',b'Information of Local Business of Pakistan',b'## Context\n\nI created this dataset to enable everyone to explore local businesses of Pakistan. This dataset might help the local community in gathering information of local businesses. This might also help in local economic development of Pakistan by bridging traders and manufacturers.\n\n## Content\n\n**Geography**: Pakistan\n\n**Time period**: 1990-2017\n\n**Dataset**: The dataset contains information of approx 67000 businesses in Pakistan (~5000 in each csv file)\n\n**Features**:  The dataset has total 7 columns\n - Business Name \n - Contact Name \n - Telephone \n - Website\n - Services (Description of types of products/services provided by the business)\n - Address\n - City\n\n## Acknowledgements\n\nThis Dataset was created by scraping [this][1] website. I wrote the script in Python using BeautifulSoup Library. Link to script: https://tinyurl.com/ybb4bdky\n\n\n## Inspiration\n\nA lot of questions can be answered and analysis can be done using this dataset. Few interesting ideas I can think of are :\n- Applying NLP techniques on Services column to extract business category\n- Clustering of categories of business according to cities\n\n  [1]: http://www.findpk.com/',"b""['business', 'product', 'information', 'small', 'featured']""",https://www.kaggle.com/mpasha96/yellow-pages-of-pakistan
b'CS:GO Competitive Matchmaking Data',b'Damage/Grenade entries on over 410k rounds played in competitive Counterstrike',"b""![enter image dhere][2]\n\n# Introduction\n\nVideo games are a rich area for data extraction due to their digital nature.  Notable examples such as the complex EVE Online economy, World of Warcraft corrupted blood incident and even Grand Theft Auto self-driving cars tells us that fiction is closer to reality than we really think.  Data scientists can gain insight on the logic and decision-making that the players face when put in hypothetical and virtual scenarios. \n\nIn this Kaggle Dataset, I provide just over 1400 competitive matchmaking matches from Valve's game Counter-strike: Global Offensive (CS:GO).  The data was extracted from competitive matchmaking replays submitted to [csgo-stats][1].  I intend for this data-set to be purely exploratory, however users are free to create their own predictive models they see fit.  \n\n### About Counter-Strike: Global Offensive\n\nCounter-Strike: Global Offensive is a first-person shooter game pitting two teams of 5 players against each other.  Within a maximum of 30 rounds, the two teams find themselves on either side as a Counter Terrorist or Terrorist.  Both sides are tasked with eliminating the opposition or, as the terrorist team, planting the C4 bomb at a bomb site and allowing it to explode.  Rounds are played out until either of those two objectives or if the maximum time is reached (in which the counter terrorists then win by default).  At the end of the 15th round, the two teams switch sides and continue until one team reaches 16 round wins first.  CS:GO is widely known for its competitive aspect of technical skill, teamwork and in-game strategies.  Players are constantly rewarded with the efforts they put it in training and learning through advancing in rank.\n\n[Click here to read more about the competitive mechanics of CS:GO.][3]\n\n# Content\n\n**Update September 2018**: It's been about more than a year since I've updated this dataset.  A thread on PRI (see kernels) sparked my interest again in some CS analytics and I thought it'd be cool to replicate the metric for ESEA players to check.  Seeing now that it's extremely hard for me to scale this up (resource wise) to accommodate all current and future ESEA matches, I decided it'd be better for me just to release the data I managed to gather.  The demos were collected over only a small span of two weeks in August and is definitely not representative of CS games over time.  If you have any questions about the new dataset, please don't hesitate to start a thread in Discussion.\n\n**New ESEA Demos**\nThe new ESEA demos are structured a bit differently to save space.  The per-round information (e.g ct, t equipment value, winner, map) are all saved inside `esea_meta_demos.csv`.  The other files have the same format, less the meta-columns.  The kills data have also been added but follow a slightly different format, see the file detail for more info. Any demos that had less than 16 rounds played were excluded, no other data cleaning and assurance was done.  I'm sure there are a lot of matches that spat out weird data. \n\n---\n\nThe dataset provides every successful entry of duels (or battle) that took place for a player.  That is, each row documents an event when a player is hurt by another player (or World e.g fall damage). \n\n`mm_master_demos.csv` contains information on rounds fired, while `mm_grenades_demos.csv` contains information on grenades thrown. The fields in the two datasets are similar: highlights include shooters and victims, event coordinates, and timestamps. The datasets also includes static information on the match winner, player ranks before and after the match, and other miscellaneous match-level metadata.\n\nFor further information on individual fields in the dataset, refer to the [Column Metadata](https://www.kaggle.com/skihikingkevin/csgo-matchmaking-damage/data).\n\n### Interpreting Positional Data\nThis dataset also includes a selection of the game's official radar maps, as well as a table, `map_data.csv`, to aid in mapping data over them. The X,Y coordinates included in the dataset are all in in-game coordinates and need to be linearly scaled to be plotted on any official radar maps.  See [converting to map coordinates][4] for more information.\n\n# Acknowledgements\n\n 1. Definitely the guys from [csgo-stats][6], without them, this wouldn't have been possible! :)\n 2. [/r/globaloffensive][7] for many years of lulz\n 3. [Akiver of CSGO Demo Manager][8] for spending so much time perfecting his demo parser.\n\n\n  [1]: https://csgo-stats.net/\n  [2]: https://i.ytimg.com/vi/_biRQp0oZbk/maxresdefault.jpg\n  [3]: https://en.wikipedia.org/wiki/Counter-Strike:_Global_Offensive#Gameplay\n  [4]: https://github.com/akiver/CSGO-Demos-Manager/blob/376cc90eb49425050b351bc933940480f6d48075/Services/Concrete/Maps/MapService.cs\n  [5]: https://github.com/akiver/CSGO-Demos-Manager/tree/8cfb3cdb760a0a1530f9e3e3e0f76e651ed18f1b/Core/Models/Maps\n  [6]: https://csgo-stats.net/\n  [7]: https://www.reddit.com/r/GlobalOffensive/\n  [8]: https://csgo-demos-manager.com/""","b""['internet', 'video games', 'medium', 'featured']""",https://www.kaggle.com/skihikingkevin/csgo-matchmaking-damage
b'NYS Summary of Real Property Tax Exemptions',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/vAQsbHd18LI) by [Arnaud Mesureur](https://unsplash.com/@tbzr) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-summary-of-real-property-tax-exemptions
b'NFL scores and betting data',b'Scores and descriptive game info for National Football League games',"b'### Context\n\nNational Football League historic game and betting info\n\n### Content\n\nNational Football League (NFL) game results since 1966 with betting odds information since 1979. Dataset was created from a variety of sources including games and scores from a variety of public websites such as ESPN, NFL.com, and Pro Football Reference. Weather information is from NOAA data with NFLweather.com a good cross reference. Betting data was used from http://www.repole.com/sun4cast/data.html for 1978-2013 seasons. Pro-football-reference.com data was then cross referenced for betting lines and odds as well as weather data. From 2013 on betting data reflects lines available at sportsline.com.\n\n\n\n### Acknowledgements\n\nHelpful sites with interest in football and sports betting include:\n\nhttps://github.com/fivethirtyeight/nfl-elo-game\n\nhttp://www.repole.com/sun4cast/data.html\n\nhttps://www.pro-football-reference.com/\n\nhttp://www.espn.com/nfl/\n\nhttp://www.nflweather.com/\n\nhttp://www.noaa.gov/weather\n\nhttps://www.sportsline.com/\n\nhttps://github.com/jp-wright/nfl_betting_market_analysis\n\n\n### Inspiration\n\nCan you build a predictive model to better predict NFL game outcomes and identify successful betting strategies?'","b""['sports', 'american football', 'small', 'featured']""",https://www.kaggle.com/tobycrabtree/nfl-scores-and-betting-data
"b'French employment, salaries, population per town'",b'Some data to show equality and inequalities in France',"b'### Context\n\n[INSEE][1] is the official french institute gathering data of many types around France. It can be demographic (Births, Deaths, Population Density...), Economic (Salary, Firms by activity / size...) and more.  \nIt can be a great help to observe and measure inequality in the french population.\n\n### Content\nFour files are in the dataset :\n\n - base_etablissement_par_tranche_effectif : give information on the number of firms in every french town, categorized by size , come from [INSEE][2].\n   - CODGEO : geographique code for the town (can be joined with *code_insee* column from ""name_geographic_information.csv\')\n   - LIBGEO : name of the town (in french)\n   - REG : region number\n   - DEP : depatment number\n   - E14TST : total number of firms in the town\n   - E14TS0ND : number of unknown or null size firms in the town\n   - E14TS1 : number of firms with 1 to 5 employees in the town\n   - E14TS6 : number of firms with 6 to 9 employees in the town\n   - E14TS10 : number of firms with 10 to 19 employees in the town\n   - E14TS20 : number of firms with 20 to 49 employees in the town\n   - E14TS50 : number of firms with 50 to 99 employees in the town\n   - E14TS100 : number of firms with 100 to 199 employees in the town\n   - E14TS200 : number of firms with 200 to 499 employees in the town\n   - E14TS500 : number of firms with more than 500 employees in the town\n - name_geographic_information : give geographic data on french town (mainly latitude and longitude, but also region / department codes and names )\n   - EU_circo : name of the European Union Circonscription\n   - code_r\xc3\xa9gion : code of the region attached to the town\n   - nom_r\xc3\xa9gion : name of the region attached to the town\n   - chef.lieu_r\xc3\xa9gion : name the administrative center around the town\n   - num\xc3\xa9ro_d\xc3\xa9partement : code of the department attached to the town\n   - nom_d\xc3\xa9partement : name of the department attached to the town\n   - pr\xc3\xa9fecture : name of the local administrative division around the town\n   - num\xc3\xa9ro_circonscription : number of the circumpscription\n   - nom_commune : name of the town\n   - codes_postaux : post-codes relative to the town\n   - code_insee : unique code for the town\n   - latitude : GPS latitude\n   - longitude : GPS longitude\n   - \xc3\xa9loignement : i couldn\'t manage to figure out what was the meaning of this number\n\n - net_salary_per_town_per_category : salaries around french town per job categories, age and sex\n     - CODGEO : unique code of the town\n     - LIBGEO : name of the town\n     - SNHM14 : mean net salary\n     - SNHMC14 : mean net salary per hour for executive\n     - SNHMP14 : mean net salary per hour for middle manager\n     - SNHME14 : mean net salary per hour for employee\n     - SNHMO14 : mean net salary per hour for worker\n     - SNHMF14 : mean net salary for women\n     - SNHMFC14 : mean net salary per hour for feminin executive\n     - SNHMFP14 : mean net salary per hour for feminin middle manager\n     - SNHMFE14 : mean net salary per hour for feminin employee\n     - SNHMFO14 : mean net salary per hour for feminin worker\n     - SNHMH14 : mean net salary for man\n     - SNHMHC14 : mean net salary per hour for masculin executive\n     - SNHMHP14 : mean net salary per hour for masculin middle manager\n     - SNHMHE14 : mean net salary per hour for masculin employee\n     - SNHMHO14 : mean net salary per hour for masculin worker\n     - SNHM1814 : mean net salary per hour for 18-25 years old\n     - SNHM2614 : mean net salary per hour for 26-50 years old\n     - SNHM5014 : mean net salary per hour for >50 years old\n     - SNHMF1814 : mean net salary per hour for women between 18-25 years old\n     - SNHMF2614 : mean net salary per hour for women between 26-50 years old\n     - SNHMF5014 : mean net salary per hour for women >50 years old\n     - SNHMH1814 : mean net salary per hour for men between 18-25 years old\n     - SNHMH2614 : mean net salary per hour for men between 26-50 years old\n     - SNHMH5014 : mean net salary per hour for men >50 years old \n\n - population : [demographic][3] information in France per town, age, sex and living mode\n    - NIVGEO : geographic level (arrondissement, communes...)\n    - CODGEO : unique code for the town\n    - LIBGEO : name of the town (might contain some utf-8 errors, this information has better quality name_geographic_information)\n    - MOCO : cohabitation mode : [list and meaning available in Data description]\n    - AGE80_17 : age category (slice of 5 years) | ex : 0 -> people between 0 and 4 years old\n    - SEXE : sex, 1 for men | 2 for women\n    - NB : Number of people in the category\n\n - departments.geojson : contains the borders of french departments. From [Gregoire David (github)][4]\n\nThese datasets can be merged by : CODGEO = code_insee\n\n### Acknowledgements\nThe entire dataset has been created (and actualized) by INSEE, I just uploaded it on Kaggle after doing some jobs and checks on it. I haven\'t seen INSEE on Kaggle yet but I think it would be great to bring the organization in as a Kaggle actor.\n\n\n### Inspiration\nFirst aim I had creating that dataset was to provide a map of french towns with the number of firm that are settled in by size.  \nNow my goal is to explore inequality between men and women, youngsters and elders, working / social classes.  \nPopulation can also be a great filter to explain some phenomenons on the maps.\n\n\n  [1]: https://www.insee.fr/fr/accueil\n  [2]: https://www.insee.fr/fr/statistiques/1893274\n  [3]: https://www.insee.fr/fr/statistiques/2863607\n  [4]: https://github.com/gregoiredavid/france-geojson/blob/master/departements.geojson'","b""['demographics', 'utility', 'employment', 'medium', 'featured']""",https://www.kaggle.com/etiennelq/french-employment-by-town
b'NYS Local Area Unemployment Statistics (LAUS)',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-local-area-unemployment-statistics-laus
b'Los Angeles City Employee Positions',b'From Los Angeles Open Data',"b""### Content  \n\nThis dataset lists all employee positions (civilian regular authority, commissioners, as-needed, etc) by budgetary department, program, and fund, dating back to Fiscal Year 2012.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/enhLwx5CTno) by [Nicolae Rosu](https://unsplash.com/@nicolaerosu) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-city-employee-positions
b'Chicago Towed Vehicles',b'From City of Chicago Open Data',"b""### Content  \n\nThis dataset displays location for vehicles that have been towed and impounded by the City of Chicago within the last 90 days. Illegally parked vehicles, abandoned vehicles and vehicles used for illegal activities may be towed by the Chicago Police Department, the Department of Streets and Sanitation, the Department of Revenue, Aviation and the office of the City Clerk. After a tow request is issued, an inventory number is assigned by the Department of Streets and Sanitation and a truck is dispatched to tow the requested vehicle to a City auto pound. Disclaimer: This dataset includes vehicles towed or relocated by the City of Chicago; it does not include vehicles towed by a private towing company. \r\n\r\nBackground Information: \r\nAuto Pound Locations (http://j.mp/kG5sgF).\r\nTow Process Overview (http://j.mp/lfBOEP).\r\nCommon Towing Questions (http://j.mp/imFYlp).\r\nParking and Standing Violations (http://j.mp/ifW8Uj).\r\nRelated Applications: Find Your Vehicle (http://j.mp/lWn0S7).  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/-4uuIHGg2SA) by [Gerrie van der Walt](https://unsplash.com/@gitfo) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'vehicles', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-towed-vehicles
b'Global Food & Agriculture Statistics',b'Land use and farming inputs',"b'FAOSTAT provides access to over 3 million time-series and cross sectional data relating to food and agriculture. The full FAO data can be found in the large zipfile, while a (somewhat out of date) summary of FAOSTAT is in the top level csv files. FAOSTAT contains data for 200 countries and more than 200 primary products and inputs in its core data set. The national version of FAOSTAT, CountrySTAT, is being implemented in about 20 countries and three regions. It offers a two-way bridge amongst sub-national, national, regional and international statistics on food and agriculture.\n\n### Acknowledgements\n\nThis dataset was kindly published by the United Nation on the UNData site. You can find [the original dataset here](http://data.un.org/Explorer.aspx).\n\n### License\n[Per the UNData terms of use](http://data.un.org/Host.aspx?Content=UNdataUse): all data and metadata provided on UNdata\xe2\x80\x99s website are available free of charge and may be copied freely, duplicated and further distributed provided that [UNdata](http://data.un.org/Explorer.aspx) is cited as the reference. '","b""['agriculture', 'medium', 'featured']""",https://www.kaggle.com/unitednations/global-food-agriculture-statistics
b'NYS Tax Return Preparers and Facilitators',b'From New York State Open Data',"b""### Content  \n\nThis Dataset contains tax return preparers and facilitators that have registered with the New York State Department of Taxation and Finance pursuant to Tax Law Section 32.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/8lnbXtxFGZw) by [Sharon McCutcheon](https://unsplash.com/@sharonmccutcheon) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-tax-return-preparers-and-facilitators
b'Global Food Prices',b'743k Rows of Monthly Market Food Prices Across Developing Countries',"b'### Context: \nGlobal food price fluctuations can cause famine and large population shifts. Price changes are increasingly critical to policymakers as global warming threatens to destabilize the food supply.\n\n### Content: \nOver 740k rows of prices obtained in developing world markets for various goods. Data includes information on country, market, price of good in local currency, quantity of good, and month recorded.\n\n### Acknowledgements: \nCompiled by the [World Food Program](http://www1.wfp.org/) and distributed by [HDX](https://data.humdata.org/dataset/wfp-food-prices).\n\n### Inspiration: \nThis data would be particularly interesting to pair with currency fluctuations, weather patterns, and/or refugee movements--do any price changes in certain staples predict population upheaval? Do certain weather conditions influence market prices?\n\n### License:\nReleased under [CC BY-IGO](https://creativecommons.org/licenses/by/3.0/igo/legalcode).'","b""['economics', 'food and drink', 'medium', 'featured']""",https://www.kaggle.com/jboysen/global-food-prices
b'NYC Wi-Fi Hotspot Locations',b'From New York City Open Data',"b'### Content  \n\nNYC Wi-Fi Hotspot Locations Wi-Fi Providers: \nCityBridge, LLC (Free Beta): LinkNYC 1 gigabyte (GB), Free Wi-Fi Internet Kiosks\nSpot On Networks (Free) NYC HOUSING AUTHORITY (NYCHA) Properties\nFiberless (Free): Wi-Fi access on Governors Island Free - up to 5 Mbps for users as the part of Governors Island Trust Governors Island Connectivity Challenge\nAT&T (Free): Wi-Fi access is free for all users at all times. \nPartners: In several parks, the NYC partner organizations provide publicly accessible Wi-Fi. Visit these parks to learn more information about their Wi-Fi service and how to connect. \nCable (Limited-Free): In NYC Parks provided by NYC DoITT Cable television franchisees. \nALTICEUSA previously known as \xe2\x80\x9cCablevision\xe2\x80\x9d and SPECTRUM previously known as \xe2\x80\x9cTime Warner Cable\xe2\x80\x9d (Limited Free) Connect for 3 free 10 minute sessions every 30 days or purchase a 99 cent day pass through midnight. Wi-Fi service is free at all times to Cablevision\xe2\x80\x99s Optimum Online and Time Warner Cable broadband subscribers. \nWi-Fi Provider: Chelsea Wi-Fi (Free) Wi-Fi access is free for all users at all times. \nChelsea Improvement Company has partnered with Google to provide Wi-Fi a free wireless Internet zone, a broadband region bounded by West 19th Street, Gansevoort Street, Eighth Avenue, and the High Line Park. \nWi-Fi Provider: Downtown Brooklyn Wi-Fi (Free) \nThe Downtown Brooklyn Partnership - the New York City Economic Development Corporation to provide Wi-Fi to the area bordered by Schermerhorn Street, Cadman Plaza West, Flatbush Avenue, and Tillary Street, along with select public spaces in the NYCHA Ingersoll and Whitman Houses. \nWi-Fi Provider: Manhattan Downtown Alliance Wi-Fi (Free) \nLower Manhattan Several public spaces all along Water Street, Front Street and the East River Esplanade south of Fulton Street and in several other locations throughout Lower Manhattan. \nWi-Fi Provider: Harlem Wi-Fi (Free) \nThe network will extend 95 city blocks, from 110th to 138th Streets between Frederick Douglass Boulevard and Madison Avenue is the free outdoor public wireless network. \nWi-Fi Provider: Transit Wireless (Free) \nWi-Fi Services in the New York City subway system is available in certain underground stations. For more information visit http://www.transitwireless.com/stations/. \nWi-Fi Provider: Public Pay Telephone Franchisees (Free) \nUsing existing payphone infrastructure, the City of New York has teamed up with private partners to provide free Wi-Fi service at public payphone kiosks across the five boroughs at no cost to taxpayers. \nWi-Fi Provider: New York Public Library \nUsing Wireless Internet Access (Wi-Fi): All Library locations offer free wireless access (Wi-Fi) in public areas at all times the libraries are open. \nConnecting to the Library\'s Wireless Network \n\xe2\x80\xa2You must have a computer or other device equipped with an 802.11b-compatible wireless card. \n\xe2\x80\xa2Using your computer\'s network utilities, look for the wireless network named ""NYPL."" \n\xe2\x80\xa2The ""NYPL"" wireless network does not require a password to connect. \nLimitations and Disclaimers Regarding Wireless Access \n\xe2\x80\xa2The Library\'s wireless network is not secure. Information sent from or to your laptop can be captured by anyone else with a wireless device and the appropriate software, within three hundred feet. \n\xe2\x80\xa2Library staff is not able to provide technical assistance and no guarantee can be provided that you will be able to make a wireless connection. \n\xe2\x80\xa2The Library assumes no responsibility for the safety of equipment or for laptop configurations, security, or data files resulting from connection to the Library\'s network  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/UIIwSB8q3mo) by [Etienne Gobeli](https://unsplash.com/@tienou) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-wi-fi-hotspot-locations
b'Recommender Click Logs- Sowiport',b'User behavior for multiple recommender systems',"b'This dataset contains 28 million recommendation and click/no click pairs from users of the Sowiport library. From the abstract of the pre-print discussing the dataset:\n\nStereotype and most-popular recommendations are widely neglected in the\nresearch-paper recommender-system and digital-library community. In other\ndomains such as movie recommendations and hotel search, however, these\nrecommendation approaches have proven their effectiveness. We were\ninterested to find out how stereotype and most-popular recommendations\nwould perform in the scenario of a digital library. Therefore, we\nimplemented the two approaches in the recommender system of GESIS\xe2\x80\x99\ndigital library Sowiport, in cooperation with the recommendations-as-aservice\nprovider Mr. DLib. We measured the effectiveness of most-popular\nand stereotype recommendations with click-through rate (CTR) based on 28\nmillion delivered recommendations. Most-popular recommendations\nachieved a CTR of 0.11%, and stereotype recommendations achieved a CTR\nof 0.124%. Compared to a \xe2\x80\x9crandom recommendations\xe2\x80\x9d baseline (CTR\n0.12%), and a content-based filtering baseline (CTR 0.145%), the results are\ndiscouraging. However, for reasons explained in the paper, we concluded\nthat more research is necessary about the effectiveness of stereotype and\nmost-popular recommendations in digital libraries. \n\n\n\n\nThis dataset was kindly made available by the authors of ""[Stereotype and Most-Popular Recommendations in the Digital Library Sowiport][1]"" under the CC-BY 3.0 license. You can find additional information at http://mr-dlib.org/.\n\n\n  [1]: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HFIV1A'","b""['large', 'featured']""",https://www.kaggle.com/sohier/recommender-click-logs-sowiport
b'NYS Turnstile Usage Data',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ZKWgoRUYuMk) by [Karsten Wurth (@inf1783)](https://unsplash.com/@inf1783) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'medium', 'featured']""",https://www.kaggle.com/new-york-state/nys-turnstile-usage-data
b'Chicago Vacant and Abandoned Buildings-Violations',b'From City of Chicago Open Data',"b""### Content  \n\nVacant and abandoned building violations issued on properties owned by financial institutions since January 1, 2011. Each violation is tied to a Docket Number. A Docket may have more than one violation associated with it. Fees are assessed based on all violations associated with a particular Docket. This dataset displays the most recent action (disposition description) for each violation, the fees and fines associated with the docket and the amount paid or outstanding for the docket. If the docket is a City Non-Suit or the owner is found to be Not Liable, then no payment is required. Note that multiple addresses may be associated with a violation; in these cases, multiple records will be included in this dataset for a single violation. / Data Owners: Administrative Hearings / Finance / Time Period: January 1, 2011 to present  / Update Frequency: Data is updated daily  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/c9A0j0y5yaE) by [Aiden Marples](https://unsplash.com/@mraidenmarples) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-vacant-and-abandoned-buildings-violations
b'NY Buildings Subject to HPD Jurisdiction',b'From New York City Open Data',"b""### Content  \n\nPursuant to New York City\xe2\x80\x99s Housing Maintenance Code, the Department of Housing \nPreservation and Development (HPD) collects information on multiple dwellings in New York \nCity, and other buildings that fall under its jurisdiction. HPD\xe2\x80\x99s Buildings Open Data covers all \nbuildings which meet any of the following criteria: \n \na. HPD has required the owner to register the building under the Housing Maintenance \nCode (HMC) \nb. HPD has initiated a litigation action under the HMC \nc. HPD has received a complaint for the building \nd. HPD has initiated a work order for the purposes of emergency repair, demolition, or \nthe Alternative Enforcement Program (AEP) for the building \ne. HPD has added the property to the AEP program\n\nBuildings are identified by a BuildingID.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/KBy3lVz8Q0I) by [Tyler Nix](https://unsplash.com/@jtylernix) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-buildings-subject-to-hpd-jurisdiction
b'NYS Biodiversity by County',b'From New York State Open Data',"b""### Content  \n\nThe NYS Department of Environmental Conservation (DEC) collects and maintains several datasets on the locations, distribution and status of species of plants and animals. Information on distribution by county from the following three databases was extracted and compiled into this dataset.  First, the New York Natural Heritage Program biodiversity database: Rare animals, rare plants, and significant natural communities. Significant natural communities are rare or high-quality wetlands, forests, grasslands, ponds, streams, and other types of habitats.  Next, the 2nd NYS Breeding Bird Atlas Project database: Birds documented as breeding during the atlas project from 2000-2005.  And last, DEC\xe2\x80\x99s NYS Reptile and Amphibian Database: Reptiles and amphibians; most records are from the NYS Amphibian & Reptile Atlas Project (Herp Atlas) from 1990-1999.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/4Q6kXLAKK_Y) by [Ryk Naves](https://unsplash.com/@ryk) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'animals', 'plants', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-biodiversity-by-county
b'Reviews with conditions',b'A dataset with labelled and unlabelled sentences from reviews with conditions.',"b""### Context\nThis dataset was created during my PhD (http://www.tdg-seville.info/fogallego/Personal%20Info) at the University of Seville. We didn't found any datasets with labelled conditions so we decided to build one since our main goal for the PhD was to be able to identify conditions without relying on user-defined patterns or requiring any specific-purpose dictionaries, taxonomies, or heuristics.\n\nWe presented this dataset in a poster session during Machine Learning Summer School Madrid 2018 (http://mlss.ii.uam.es/mlss2018/posters.html).\n\n\n### Content\nThe reviews in English and Spanish were randomly gathered from ciao.com between April 2017 and May 2017. The sentences were classified into 15 domains according to their sources, namely: adults, baby care, beauty, books, cameras, computers, films,\nheadsets, hotels, music, ovens, pets, phones, TV sets, and video games.\n\nOur dataset consist of two files: sentences.csv and conditions.csv. The first one contains the whole set of sentences and the second one the manually labelled conditions.\n\nIn order to better understand the meaning of each column, I'll explain them in detail:\n\n**sentence.csv:**\n\n - sentence_uuid: the unique identifier of the sentence\n - sentence_text: the text of the sentence\n - language: the language of the sentence\n - domain: the domain of the sentence\n - labelled: whether the sentence was labelled or not\n\n**conditions.csv:**\n\n - sentence_uuid: the unique identifier of the corresponding labelled sentence\n - condition_uuid: the unique identifier of the condition\n - begin_connective: the character position where the connective of the condition starts\n - end_connective: the character position where the connective of the condition ends\n - begin_condition: the character position where the rest of the condition starts\n - end_condition: the character position where the rest of the condition ends\n - language: the language of the corresponding labelled sentence\n - domain: the domain of the corresponding labelled sentence\n\n### Acknowledgements\nMy PhD and this dataset were supported by Opileak.com and the Spanish R&D programme (grants TIN2013-\n40848-R and TIN2013-40848-R).""","b""['nlp', 'text data', 'medium', 'featured']""",https://www.kaggle.com/fogallego/reviews-with-conditions
b'Ethereum Effect impact on PC parts prices',b'Data Warehouse for analysis of Ethereum Effect from 2013 to april 2018',"b""### Context\n\nData warehouse has been created as a University project throughout 3 months (march - may 2018).\n\nI haven't find any useful databases containing historical prices of many computer parts (CPUs, GPUs and RAMs), so I had to web scrap it from web prices comparison engines:\n\n* [PriceSpy.co.uk](https://pricespy.co.uk)\n* [PCPartPicker.com](https://pcpartpicker.com)\n* [Geizhals.eu](https://geizhals.eu)\n\nFor webscrapping I've used Python with [`BeautifulSoup`](https://pypi.org/project/beautifulsoup4/) library as well as [`PCPartPicker-API`](https://pypi.org/project/PCPartPicker-API/).\n\nStuff that I'd like to add but I have no time to do it:\n\n* Compare RAM prices with raising demand for memory chips in smartphones industry and Data Centers for cloud computing\n* Scrap more price comparison engines\n* Add new dimension for `DIM_PROD_GPU` -&gt; `Series`. I've made it too shallow and my analysis wasn't so great, additional step between `Manufacturer` and `Product Name` would make it easier for analytics. \n\n### Content\n\nDatabase contains data about:\n\n* 15 most popular cryptocurrencies and their rates\n* 1664 CPU Products\n* 2054 GPU Products\n* 3706 RAM Products\n* 6 000 000+ records containing products historical prices \n\n### Acknowledgements\n\nFew redditers who helped me to find some libraries and datasets to get inspired with.\n\n[My request post on r/datasets](https://www.reddit.com/r/datasets/comments/83t0ax/request_gpus_price_history/)\n\n\n### Inspiration\n\nAs a gamer I've seen a huge prices spikes on a GPU market and as I haven't find too many analysis about this phenomenon and because it's very *fresh* I thought that might be a good topic to make a Uni project for a Data Warehouse course.\n\n![GPU Sold Out][1]\n[Photo Source][2]\n\nI release this data online so it won't waste. Maybe you will find some more interesting results that I did. \n\n\n### Installation\n\nUploaded csv files have been dumped from my data warehouse. Below you can see whole ERD diagram\n\nOnly difference: `DIM_REGION` contains one additional column that I didn't include in my data warehouse\n\n![ERD Diagram][3]\n\n\n  [1]: https://static.seekingalpha.com/uploads/2017/7/9/4206551-14996557338232787_origin.jpg\n  [2]: https://seekingalpha.com/article/4087298-ethereum-crypto-currency-gpu-sales-peaked-amd-nvidia\n  [3]: https://i.imgur.com/xStwjPO.jpg""","b""['finance', 'internet', 'business', 'countries', 'money', 'medium', 'featured']""",https://www.kaggle.com/raczeq/ethereum-effect-pc-parts
"b'Publication and usage reports, 1998-2017-10 (BR)'",b'Publication and access reports of SciELO Brazil from 1998 to October 2017.',"b""### Context\n\nSciELO (Scientific Electronic Library Online) is an international research communication program launched in 1998 and implemented through a decentralized network of national collections of peer reviewed journals from 15 countries \xe2\x80\x93 12 from Latin America, Portugal, Spain and South Africa \xe2\x80\x93 that jointly publish over 1 thousand journals and about 50 thousand articles per year. A thematic collection on Public Health is also operated by the SciELO Program. All collections are accessible via the network portal \xe2\x80\x93 http://www.scielo.org.\n\nSciELO aims at the progress of research through the improvement of peer reviewed journals from all disciplines published by scientific and professional associations, academic institutions and public or private research and development institutions. The specific objectives are to increase in a sustainable way the quality, visibility, usage, impact and credibility of the indexed journals and the research they communicate. A key characteristic of SciELO is multilingual publishing, so journals can publish articles in one or multiple languages including the simultaneous publishing of the same article in more than one language.\n\nSciELO Program develops itself according to three principles. First, the conception that scientific knowledge is a public good and therefore should be available openly in the Web. Second, the network operation envisaging to strengthen collaboration and interchange of information and experience, creating scale and lessen the costs. Third, quality control as an essential policy and practice at the level of articles, journals and collections, adoption and compliance with bibliographic and interoperability standards.\n\nSciELO operation and development are carried out following three main action lines. The first is professionalization, which means to produce journals according to the state of art. The second is internationalization, which means to strengthen the active participation of SciELO Journals and Program in the international flow of scientific information. The third is operational and financial sustainability, which means to develop conditions to assure journals to be published on time with a well-established financial model.\n\nAll collections follow the SciELO Publishing Model, which comprises three main functions. First, the indexing of journals with metadata of articles, including the bibliographic references of the indexed articles and of the articles they cite. Second, the full text of articles which are available in HTML, PDF and progressively in XML JATS compatible according the SciELO Publishing Schema. Third, the dissemination and interoperability of journals and articles with bibliographic indexes and systems.    \n\nSciELO Brazil, led by SciELO / FAPESP Program, acts as the SciELO Network secretariat and coordinates the maintenance of the methodological and technological platform, while the operation of the network collections and journals are decentralized and led by national research agencies. \n\n\n### Content\n\nThis dataset contains publication and access reports for the documents of the SciELO Brazil collection between 1998 and October 2017.\n\nThe reports present metadata of journals, totals of issues and published documents, thematic areas, authors' affiliation, bibliographic references, use licenses and more. Further details can be found at http://docs.scielo.org/projects/scielo-processing/pt/latest/public_reports.html (in Portuguese, with notes in English).\n""","b""['brazil', 'research', 'medium', 'featured']""",https://www.kaggle.com/scieloorg/publishing-and-usage-reports-1998-201710-br
b'SCOTUS Opinions Corpus',"b'Lots of Big, Important Words'","b'### Context: \n[Free Law Project](https://free.law/) seeks to provide free access to primary legal materials, develop legal research tools, and support academic research on legal corpora. We work diligently with volunteers to expand our efforts at building an open source, open access, legal research ecosystem. Currently Free Law Project sponsors the development of [CourtListener](https://www.courtlistener.com/), Juriscraper, and RECAP. CourtListener is a free legal research website containing millions of legal opinions from federal and state courts. With CourtListener, lawyers, journalists, academics, and the public can research an important case, stay up to date with new opinions as they are filed, or do deep analysis using our raw data.\n\n\n### Content: \nThis dataset contains the corpus of all Supreme Court opinions and some additional supporting information. Corpus was initially collated as individual JSON objects [here](https://www.courtlistener.com/api/); these JSON objects were joined into a single csv. Note that the actual opinions column is rendered in HTML. Citations are links to additional Courtlistener API calls that are not included in this corpus.\n\n### Acknowledgements: \n[CourtListener](https://www.courtlistener.com/api/) scraped and assembled this and other similar legal datasets for public use.\n\n### Inspiration: \n* Can you join this data with other Supreme Court data like [here](https://www.kaggle.com/umichigan/court-justices) and [here](https://www.kaggle.com/wustl/supreme-court)?\n* Sentiment analysis would be particularly illuminating.'","b""['law', 'medium', 'featured']""",https://www.kaggle.com/jboysen/scotus-corpus
b'NYS Unemployment Insurance Data',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-unemployment-insurance-data
b'World Bank Poverty Report',b'National and subnational poverty levels from the World Bank',"b'### Context\n\nPoverty data from the World bank Data includes country and subnational level.\n\n### Content\n\nPoverty data available at the administrative unit level 1, based on national poverty line(s). Administrative unit level 1  is the highest subnational unit level, e.g. state or province level. \n\nAnnual Coverage: 1999 - 2013 Cite: \n\n### Acknowledgements\n\nData from the world bank. Some descriptions from [data.world][1].\nThis dataset is subject to these license terms, including attribution requirements and linking the license terms to: http://web.worldbank.org/WBSITE/EXTERNAL/0,,contentMDK:22547097~pagePK:50016803~piPK:50016805~theSitePK:13,00.html\n\nSource: [http://data.worldbank.org/data-catalog/sub-national-poverty-data][2]\n\n### Inspiration\n\n - linkage to [kiva dataset][3]\n - Differences from Oxford subnational deprivation index (requires matching the geographic regions). \n- Connect with other world bank time-series and try to see if any predictors for change in poverty levels over time can be found (despite the short time-scale). \n- What causes  worsening (rather than a generic improvement/poverty reduction) in some cases/countries/ regions? Especially when the overall country may be doing better, but some regions get worse/poorer? \n\n  [1]: https://data.world/worldbank/sub-national-poverty-data\n  [2]: http://data.worldbank.org/data-catalog/sub-national-poverty-data\n  [3]: https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding'","b""['economics', 'demographics', 'world', 'international relations', 'small', 'featured']""",https://www.kaggle.com/danofer/wb-poverty
b'NYS School Tax Relief (STAR) Reimbursement',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-school-tax-relief-star-reimbursement
b'NYS Inmates Under Custody: Beginning 2008',b'From New York State Open Data',"b""### Content  \n\nRepresents inmates under custody in NYS Department of Corrections and Community Supervision as of March 31 of the snapshot year.  Includes data about admission type, county, gender, age, crime, and facility.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Ismnr6WSHCU) by [Mitch Lensink](https://unsplash.com/@lensinkmitchel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'crime', 'gender', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-inmates-under-custody-beginning-2008
b'Turkish Lira vs USD($) (2002-2018)',"b""turkish currency's value against the dollar""","b'### Context\n\nTurkish Lira vs $USD (2002-2018)\n\n### Content\n\nThe value of turkish lira across dolar from 2002 to 2018 with opening, closing, highest, lowest and percentage differences.\n\nThis file is the value of dollar and turkish lira between years of 2002-2018. Translate of turkish words: Tarih; date \xc5\x9eimdi; the value of 1 dollar to tl, A\xc3\xa7\xc4\xb1l\xc4\xb1\xc5\x9f; Opening, Kapan\xc4\xb1\xc5\x9f; Closing, Y\xc3\xbcksek; Highest, D\xc3\xbc\xc5\x9f\xc3\xbck; Lowest, Fark; Difference.\n\nAs i use it, it is perfect for beginner to play with data. Good luck friend Note: this data is downloaded from \n\n### Acknowledgements\n\nHello everybody\nI found and downloaded this dataset from https://m.tr.investing.com.\nI think this data set is clean and esay to understand( at least for me), so i think it will be helpful for beginners.\nGood luck.\n\nBanner Image by [Fatih Y\xc3\xbcr\xc3\xbcr on Unsplash][1]\n\n\n\n  [1]: https://unsplash.com/photos/S43CFXMiWwM'","b""['small', 'featured']""",https://www.kaggle.com/umar47/usd-try
b'Google-Landmarks Dataset',b'Label famous (and not-so-famous) landmarks in images',"b'Did you ever go through your vacation photos and ask yourself: What is the name of this temple I visited in China? Who created this monument I saw in France? Landmark recognition can help! This technology can predict landmark labels directly from image pixels, to help people better understand and organize their photo collections. Today, a great obstacle to landmark recognition research is the lack of large annotated datasets. This motivated us to release Google-Landmarks, the largest worldwide dataset to date, to foster progress in this problem. \n\nThe dataset is divided into two sets of images, to evaluate two different computer vision tasks: recognition and retrieval. The data was originally described in [1], and published as part of the [Google Landmark Recognition Challenge](https://www.kaggle.com/c/landmark-recognition-challenge) and [Google Landmark Retrieval Challenge](https://www.kaggle.com/c/landmark-retrieval-challenge). \nAdditionally, to spur research in this field, we have open-sourced Deep Local Features (DELF), an attentive local feature descriptor that we believe is especially suited for this kind of task. DELF\'s code can be found on github via [this link](https://github.com/tensorflow/models/tree/master/research/delf).\n\nIf you make use of this dataset in your research, please consider citing:\n\n`H. Noh, A. Araujo, J. Sim, T. Weyand, B. Han, ""Large-Scale Image Retrieval with Attentive Deep Local Features"", Proc. ICCV\'17`\n\n### Challenges\n\nThe two challenges associated to this dataset can be found in the following links:\n\n* [Google Landmark Recognition Challenge](https://www.kaggle.com/c/landmark-recognition-challenge)\n* [Google Landmark Retrieval Challenge](https://www.kaggle.com/c/landmark-retrieval-challenge)\n\n### CVPR\'18 Workshop\n\nThe [Landmark Recognition Workshop](https://landmarkscvprw18.github.io) at [CVPR 2018](http://cvpr2018.thecvf.com/program/workshops) will discuss recent progress on landmark recognition and image retrieval, taking into account the results of the above-mentioned challenges. Top submissions for the challenges will be invited to give talks at the workshop. \n\n### Content\n\nThe dataset contains URLs of images which are publicly available online (this [Python script](https://www.kaggle.com/tobwey/landmark-recognition-challenge-image-downloader) may be useful to download the images). Note that no image data is released, only URLs. \n\nThe dataset contains test images, training images and index images. The test images are used in both tasks: for the recognition task, a landmark label may be predicted for each test image; for the retrieval task, relevant index images may be retrieved for each test image. The training images are associated to landmark labels, and can be used to train models for the recognition and retrieval challenges (for a visualization of the geographic distribution of training images, see [2]). The index images are used in the retrieval task, composing the set from which images should be retrieved.\n\nNote that the test set for both the recognition and retrieval tasks is the same, to encourage researchers to experiment with both. We also encourage participants to use the training data from the recognition task to train models which could be useful for the retrieval task. Note, however, that there are no landmarks in common between the training/index sets of the two tasks.\n\nThe images listed in the dataset are not directly in our control, so their availability may change over time, and the dataset files may be updated to remove URLs which no longer work.\n\n## Dataset construction\n\nThe training and index sets were constructed by clustering photos with respect to their geolocation and visual similarity using an algorithm similar to the one described in [3]. Matches between training images were established using local feature matching. Note that there may be multiple clusters per landmark, which typically correspond to different views or different parts of the landmark. To avoid bias, no computer vision algorithms were used for ground truth generation. Instead, we established ground truth correspondences between test images and landmarks using human annotators.\n\n### License\n\nThe images listed in this dataset are publicly available on the web, and may have different licenses. Google does not own their copyright.\n\n### References\n\n[1] H. Noh, A. Araujo, J. Sim, T. Weyand, B. Han, ""Large-Scale Image Retrieval with Attentive Deep Local Features"", Proc. ICCV\'17\n\n[2] A. Araujo, T. Weyand, ""Google-Landmarks: A New Dataset and Challenge for Landmark Recognition"", Google Research blog post, available online [here](https://research.googleblog.com/2018/03/google-landmarks-new-dataset-and.html)\n\n[3] Y.-T. Zheng, M. Zhao, Y. Song, H. Adam, U. Buddemeier, A. Bissacco, F. Brucher T.-S. Chua, H. Neven, \xe2\x80\x9cTour the World: Building a Web-Scale Landmark Recognition Engine,\xe2\x80\x9d Proc. CVPR\xe2\x80\x9909'","b""['classification', 'deep learning', 'image data', 'image processing', 'computer science', 'medium', 'featured']""",https://www.kaggle.com/google/google-landmarks-dataset
b'VGG-16 with batch normalization',b'VGG-16 Pre-trained model with batch normalization for PyTorch',"b'# VGG-16\n\n---\n\n## Very Deep Convolutional Networks for Large-Scale Image Recognition<br>\nIn this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.\n<br>\n\n**Authors: Karen Simonyan, Andrew Zisserman**<br>\n**https://arxiv.org/abs/1409.1556**\n\n---\n\n#VGG Architectures<br>\n![VGG Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/uLXrKxe.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/vgg16bn
b'NYS Forest Ranger Wildland Fire Reporting',b'From New York State Open Data',"b""### Content  \n\nThis dataset includes details for each wildland fire recorded after 2007 under the jurisdiction of the DEC NYS Forest Rangers. Earlier wildfires (1975-2007) under the jurisdiction of NYS DEC Forest Rangers can be found in the historical wildfire dataset. That dataset was formatted for use with FireFamily Plus. Each wildfire controlled or prescribed fire conducted by NYS DEC Forest Rangers is documented as a single incident in this database.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/L6O2GaNSsWU) by [Andy Watkins](https://unsplash.com/@andywatkins) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-forest-ranger-wildland-fire-reporting
b'120 Million Word Spanish Corpus',b'The Spanish Language portion of the Wikicorpus (v 1.0)',"b""### Context: \nSpanish is the second most widely-spoken language on Earth; over one in 20 humans alive today is a native speaker of Spanish. This medium-sized corpus contains 120 million words of modern Spanish taken from the Spanish-Language Wikipedia in 2010. \n\n### Content: \nThis dataset is made up of 57 text files. Each contains multiple Wikipedia articles in an XML format. The text of each article is surrounded by <doc> tags. The initial <doc> tag also contains metadata about the article, including the article\xe2\x80\x99s id and the title of the article. The text \xe2\x80\x9cENDOFARTICLE.\xe2\x80\x9d appears at the end of each article, before the closing </doc> tag.\n\n### Acknowledgements: \nThis dataset was collected by Samuel Reese, Gemma Boleda, Montse Cuadros, Llu\xc3\xads Padr\xc3\xb3 and German Rigau. If you use it in your work, please cite the following paper:\n\nSamuel Reese, Gemma Boleda, Montse Cuadros, Llu\xc3\xads Padr\xc3\xb3, German Rigau. Wikicorpus: A Word-Sense Disambiguated Multilingual Wikipedia Corpus. In Proceedings of 7th Language Resources and Evaluation Conference (LREC'10), La Valleta, Malta. May, 2010.\n\n### Inspiration: \n\n* Can you create a stop-word list for Spanish based on this corpus? How does it compare to the one in [this dataset](https://www.kaggle.com/rtatman/stopword-lists-for-19-languages)?\n* Can you build a topic model to cluster together articles on similar topics?\n\n###You may also like:\n \n* [Brazilian Portuguese Literature Corpus: 3.7 million word corpus of Brazilian literature published between 1840-1908](https://www.kaggle.com/rtatman/brazilian-portuguese-literature-corpus)\n* [Colonia Corpus of Historical Portuguese: A 5.1 million word corpus of historical Portuguese](https://www.kaggle.com/rtatman/colonia-corpus-of-historical-portuguese)\n* [The National University of Singapore SMS Corpus: A corpus of more than 67,000 SMS messages in Singapore English & Mandarin](https://www.kaggle.com/rtatman/the-national-university-of-singapore-sms-corpus)""","b""['linguistics', 'europe', 'languages', 'south america', 'medium', 'featured']""",https://www.kaggle.com/rtatman/120-million-word-spanish-corpus
b'Business and Industry Reports',"b'7,000 economics time series for 1956-2017'","b""### Context\nAlong with their core mission of counting the US population, the United States Census Bureau gathers a wide range of economic data. This dataset covers 16 of their economic reports and surveys:\n\n- Advance Monthly Sales for Retail and Food Services\n- Construction Spending\n- Housing Vacancies and Homeownership\n- Manufactured Housing Survey (1980-2013)\n- Manufactured Housing Survey (Current)\n- Manufacturers' Shipments, Inventories, and Orders\n- Manufacturing and Trade Inventories and Sales\n- Monthly Retail Trade and Food Services\n- Monthly Wholesale Trade: Sales and Inventories\n- New Home Sales\n- New Residential Construction\n- Quarterly Financial Report\n- Quarterly Services Survey\n- Quarterly Summary of State & Local Taxes\n- Quarterly Survey of Public Pensions\n- U.S. International Trade in Goods and Services\n\n### Content\n- The data csv is arranged in a long format, with the time_series_code column tying it back to the metadata csv. If you're trying to figure out what data is available, you'll want to start with the metadata.\n- Just over a third of the time series store error codes, usually confidence intervals, rather than actual values. The metadata for these time series will have values in the columns `et_code`, `et_desc`, and `et_unit`.\n- All of the dates are stored as complete beginning of the period dates, but all of the time series are at either monthly, quarterly, or annual resolution. Exact days and months are provided for convenience when aligning time series and so that you don't have to unpack period codes like 'Q22009'.\n- There may be many time series bundled under a given data category or description. For example, the largest category (taxes) contains dozens of types of tax categories, and each of those contains a separate time series for each state in the country. \n- Two of the error code time series have non-numeric values. To convert the values column into reasonable units you'll need to drop all entries equal to the string `Less than .05 percent`.\n- The data have been substantially reformatted from how they are\n   provided by the Census Bureau. You can find the script I used to\n   [prepare the data here][1].\n\n\n### Acknowledgements\n\nThis data was kindly made available by the United States Census. You can find [the original data here][2]. If you enjoyed this dataset you might also like one of the  [other US Census datasets available on Kaggle][4].\n\n### Inspiration\n\n- The [National Bureau of Economic Research's macroeconomic history of the United States][3] covers many similar time series, but before the census data was reported. Can you integrate it with this census data? This should allow you to generate many time series stretching from the present back to the 19th century.\n\n\n\n  [1]: https://gist.github.com/SohierDane/2c1b36f653724fbc7d8f26501ef4b88d\n  [2]: https://www.census.gov/econ/currentdata/datasets/index\n  [3]: https://www.kaggle.com/sohier/nber-macrohistory-database\n  [4]: https://www.kaggle.com/census/datasets""","b""['finance', 'economics', 'medium', 'featured']""",https://www.kaggle.com/census/business-and-industry-reports
b'Chicago Current Employee Information',b'From City of Chicago Open Data',"b""### Content  \n\nThis dataset is a listing of all current City of Chicago employees, complete with full names, departments, positions, employment status (part-time or full-time), frequency of hourly employee \xe2\x80\x93where applicable\xe2\x80\x94and annual salaries or hourly rate. For hourly employees, the City is providing the hourly rate and frequency of hourly employees (40, 35, 20 and 10) to allow dataset users to estimate annual wages for hourly employees. Please note that annual wages will vary by employee, depending on number of hours worked and seasonal status. For information on the positions and related salaries detailed in the annual budgets, see https://www.cityofchicago.org/city/en/depts/obm.html  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/taTNP4px3lc) by [Roman Kraft](https://unsplash.com/@romankraft) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-current-employee-information
b'Tweets Dataset for Detection of Cyber-Trolls',b'Tweets classified as aggressive or not to help fight trolls',"b'**Tweets classified as aggressive or not to help fight trolls.**\n\nFull Dataset, Visualization and more details :\nhttps://dataturks.com/projects/abhishek.narayanan/Dataset%20for%20Detection%20of%20Cyber-Trolls\n\n**Examples:**\n![enter image description here][1]\n\n\nThe dataset has 20001 items of which 20001 items have been manually labeled.\n\nThe labels are divided into following 2 categories:\n\n**1 (Cyber-Aggressive)\n0 (Non Cyber-Aggressive)**\n![enter image description here][2]\n\n**Key Features**\n\n20001 items\n2 categories\nHuman labeled dataset\n\n\n  [1]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/cybertroll_1.png\n  [2]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/cybertroll_2.png'","b""['classification', 'linguistics', 'text data', 'twitter', 'small', 'featured']""",https://www.kaggle.com/dataturks/dataset-for-detection-of-cybertrolls
b'The Smell of Fear',b'Identification of markers for human emotions in breath',"b""### Context\n\nWhile the physiological response of humans to emotional events or stimuli is well-investigated for many modalities (like EEG, skin resistance, ...), surprisingly little is known about the exhalation of so-called Volatile Organic Compounds (VOCs) at quite low concentrations in response to such stimuli. VOCs are molecules of relatively small mass that quickly evaporate or sublimate and can be detected in the air that surrounds us. The project introduces a new field of application for data mining, where trace gas responses of people reacting on-line to films shown in cinemas (or movie theaters) are related to the semantic content of the films themselves. To do so, we measured the VOCs from a movie theater over a whole month in intervals of thirty seconds, and annotated the screened films by a controlled vocabulary compiled from multiple sources. \n\n### Content\n\nThe data set consists of two parts, first the measured VOCs, and second the information about the movies. The VOCs are given in the file TOF_CO2_data_30sec.arff which is simply the time of the measurement in the first column, then all measured 400+ VOCs in the other columns. Roughly one measurement was carried out every 30 seconds. The information which movies were shown is given in the file screenings.csv. It gives start time, end time, movie title and how many visitors were in the screening. Additionally, the folder labels_aggregated give a consensus labelling of multiple annotators for the movies. The labels describe the scenes, each label represented by a row, then each column showing if the label is active (1) or not (0). This is available for 6 movies in the data set. \n\nThe goal of our initial analysis was the identification of markers, that is, finding certain VOCs that have a relation to certain labels and therefore emotions. For example, given the scene label blood, is there any increase or decrease in the concentration of a specific VOC?\n\nFurther information is available in our publications [https://doi.org/10.1145/2783258.2783404][1], [https://doi.org/10.1038/srep25464][2], and [https://dx.doi.org/10.1371/journal.pone.0203044][3]\n\n### Acknowledgements\n\nIf you use this data set, please cite:\n    \n&gt; J\xc3\xb6rg Wicker, Nicolas Krauter, Bettina Derstorff, Christof St\xc3\xb6nner,\n&gt; Efstratios Bourtsoukidis, Thomas Kl\xc3\xbcpfel, Jonathan Williams, and\n&gt; Stefan Kramer. 2015. Cinema Data Mining: The Smell of Fear. In\n&gt; Proceedings of the 21th ACM SIGKDD International Conference on\n&gt; Knowledge Discovery and Data Mining (KDD '15). ACM, New York, NY, USA,\n&gt; 1295-1304. DOI: https://doi.org/10.1145/2783258.2783404\n\n\n### Inspiration\n\nWhile the first analysis gave already interesting results, we believe that this data set has a high potential for further analysis. We are currently working on increasing the size of the data. Additionally, multiple follow-up publications are being prepared. There are many posssible tasks, we focus mainly on the identification of markers in the VOC data, but there are many potential interesting findings in the data set. Are movies related based on the VOCs? Could we identify similar scenes based on the VOCs? \n\n\n  [1]: https://doi.org/10.1145/2783258.2783404\n  [2]: https://doi.org/10.1038/srep25464\n  [3]: https://dx.doi.org/10.1371/journal.pone.0203044""","b""['time series', 'film', 'chemistry', 'emotion', 'atmospheric sciences', 'medium', 'featured']""",https://www.kaggle.com/jswicker/the-smell-of-fear
"b'Home Mortgage Disclosure Act Data, NY, 2015'",b'Data on ~440k Home Mortgage Decisions in NY',"b'### Context: \nThe Home Mortgage Disclosure Act (HMDA) requires many financial institutions to maintain, report, and publicly disclose information about mortgages.\n\n### Content: \nThis dataset covers all mortgage decisions made in 2015 for the state of New York. Data for additional states and years can be accessed [here](https://www.consumerfinance.gov/data-research/hmda/explore).\n\n### Acknowledgements: \nThis dataset was compiled by the Consumer Finance Protection Board.\n\n### Inspiration: \n* Where are mortgages most likely to be approved?\n* Can you predict mortgage decisions based on the criteria provided here?'","b""['medium', 'featured']""",https://www.kaggle.com/jboysen/ny-home-mortgage
b'Chicago Public Schools Data',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.""","b""['socrata', 'education', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-public-schools-data
b'GitHub Issues',b'GitHub issue titles and descriptions for NLP analysis.',"b'### Description\nOver 8 million GitHub issue titles and descriptions from 2017.  Prepared from instructions at [How To Create Data Products That Are Magical Using Sequence-to-Sequence Models][1].\n\n### Original Source\nThe data was adapted from GitHub data accessible from [GitHub Archive][2].  The constructocat image is from https://octodex.github.com/constructocat-v2.\n\n### License\n\nMIT License\n\nCopyright (c) 2018 David Shinn\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n  [1]: https://medium.com/@hamelhusain/how-to-create-data-products-that-are-magical-using-sequence-to-sequence-models-703f86a231f8\n  [2]: https://www.githubarchive.org/'","b""['linguistics', 'computers', 'medium', 'featured']""",https://www.kaggle.com/davidshinn/github-issues
b'Wikipedia Article Titles',b'All of the titles of articles on Wikipedia',"b""### Context\n\nWikipedia, the world's largest encyclopedia, is a crowdsourced open knowledge project and website with millions of individual web pages. This dataset is a grab of the title of every article on Wikipedia as of September 20, 2017.\n\n### Content\n\nThis dataset is a simple newline (`\\n`) delimited list of article titles. No distinction is made between redirects (like `Schwarzenegger`) and actual article pages (like `Arnold Schwarzenegger`).\n\n### Acknowledgements\n\nThis dataset was created by scraping [Special:AllPages](https://en.wikipedia.org/w/index.php?title=Special:AllPages) on Wikipedia. It was originally shared [here](https://www.reddit.com/r/datasets/comments/71954f/a_list_of_all_14mil_english_wikipedia_article/).\n\n### Inspiration\n\n* What are common article title tokens? How do they compare against frequent words in the English language?\n* What is the longest article title? The shortest?\n* What countries are most popular within article titles?""","b""['knowledge', 'encyclopedias', 'medium', 'featured']""",https://www.kaggle.com/residentmario/wikipedia-article-titles
b'ResNet-101',b'ResNet-101 Pre-trained Model for PyTorch',"b'# ResNet-101\n\n---\n\n## Deep Residual Learning for Image Recognition\nDeeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. \n\nAn ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. \n\nThe depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.<br>\n\n**Authors: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun**<br>\n**https://arxiv.org/abs/1512.03385**\n\n---\n\n\nArchitecture visualization: http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006\n\n![Resnet][1]\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/nyYh5xH.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/resnet101
b'Jordan vs Lebron',"b""who is better and predict Lebron's future stats""","b""### Context\n\nMichael Jordan is the greatest basketball player of all time, but can Lebron James catches up with him in the remaining career or not? I made some simple EDA to compare two players. \n\n### Content\n\nThis dataset contains Jordan and Lebron's career game log data from nba-reference.com.  The games in total for both players are similar so it is a good sample for comparing two players and dive into their advantages and shortcomings all over their years of NBA career.\n\nThe data labels are quite self-explanatory if you know basic NBA statistics. \nI have tried a basic exploratory data analysis and basic regression analysis which aims at predicting Lebron's future stats.\nIt will be funny to predict Lebron's remaining career accomplishments using his history game data.\n\n### Acknowledgements\n\nnba-reference.com\n\n### Inspiration\n\nHow many times better is Michael Jordan as compared to Lebron James?""","b""['sports', 'small', 'featured']""",https://www.kaggle.com/edgarhuichen/nba-players-career-game-log
b'French Reddit Discussion',"b'A French written dialog corpus from Reddit, with 1,583,083 utterances in total.'","b'LEL\xc3\x9a is a French dialog corpus that contains a rich collection of human-human, spontaneous written conversations, extracted from Reddit\xe2\x80\x99s public dataset available through Google BigQuery. Our corpus is composed of 556,621 conversations with 1,583,083 utterances in total. The code to generate this dataset can be found in our [GitHub Repository][1].\n\nThe archive `spf.tar.gz` contains Reddit discussions in an XML file with the following format:\n\n    <dialog>\n        <s link_id=""4rqtz"" subreddit_id=""2qhjz"">\n            <utt uid=""1"" comment_id=""123"" parent_id=""4rqtz"" score=""1"" create_utc=""12458129356"">Hey, how are you?</utt>\n            <utt uid=""2"" comment_id=""124"" parent_id=""123"" score=""1"" create_utc=""12458129486"">I\xe2\x80\x99m fine thank you!</utt>\n            <utt uid=""1"" comment_id=""125"" parent_id=""124"" score=""1"" create_utc=""12458139804"">Nice!</utt>\n        </s>\n        <s link_id=""8y1br"" subreddit_id=""2qhjz"">\n            <utt uid=""1"" comment_id=""126"" parent_id=""124""  score=""1"" create_utc=""12458129310"">Who\xe2\x80\x99s around for lunch?</utt>\n            <utt uid=""2"" comment_id=""127"" parent_id=""126"" score=""1"" create_utc=""12458139345"">Me!</utt>\n            <utt uid=""3"" comment_id=""128"" parent_id=""127"" score=""1"" create_utc=""12458149382"">Me too!</utt>\n        </s>\n    </dialog>\n\nThe tag attributes can be described as follows:\n\n - `link_id`: ID of the parent Reddit post.\n - `subreddit_id`: ID of the subreddit.\n - `uid`: ID of the comment author.\n - `comment_id`: ID of the Reddit comment.\n - `parent_id`: ID of the parent Reddit comment.\n\nWe have split up the conversation trees into short sequential conversations using a heuristic described in our paper, [LEL\xc3\x9a: A French Dialog Corpus from Reddit][2], however the full conversation trees can be reconstructed using the `comment_id` and `parent_id` attributes of the `<utt>` tag.\n\nData was collected from the following subreddits: /r/france, /r/FrancaisCanadien, /r/truefrance, /r/paslegorafi, and /r/rance.\n\n  [1]: https://github.com/amirbawab/corpus-tools\n  [2]: https://github.com/amirbawab/corpus-tools/blob/master/paper.pdf'","b""['linguistics', 'demographics', 'languages', 'reddit', 'social groups', 'medium', 'featured']""",https://www.kaggle.com/breandan/french-reddit-discussion
b'Blog texts and dominant Jungian cognitive function',"b""Carl Jung's personality type basics together with human language samples""","b""# Context\nTypealyzer.com was created with a couple of hundred hand-annotated texts as training data in 2009 to explore the idea that personality type is reflected in human language. The site allows a user to submit a url to a blog and get back an automatic analysis of the Myers-Briggs type of the writers text. The Myers-Briggs type is a four-letter code describing the dominant and auxiliary psychological function defined by psychologist Carl Jung, together with the introverted or extraverted direction of each of the functions. Jung called the four basic cognitive functions Sensing (S), iNtuition (N), Thinking (T) and Feeling (F). They describe how a person prefers to percieve the world, either by concrete sensory data (Sensing) or more holistic pattern-based interpretations (iNtuition) and wether they put rationality and logic (Thinking) before human concerns (Feeling) when evaluating a situation or vice versa. A good introduction to the dynamism of Jungs personality type theory can be found in the book Was that really me? How Everyday Stress Brings Out Our Hidden Personality by Ph.D. Naomi L. Quenck.\n\nThis user-submitted content makes it possible to see for yourself if the idea holds that personality is reflected in human language and if Carl Jung's intuitive ideas about the human psychology can be confirmed by empirical data.\n\n# Content\nTypealyzer.com allows the user to submit an url to a blog. Back when it was created in 2008, blogs were pretty much the only social media around, but since then people have submitted url:s to all kinds of websites. In this dataset only url:s pointing to wordpress, tumblr and blogspot domains are included. In 2012 we added the possibility for the users to judge how well the text classifier works by also submitting an 'actual' myers-briggs type for the url. We've removed the url and transformed the four-letter myers-briggs code to its dominant cognitive function, which according to the theory should be the most significant aspect of each personality type.\n\n# Acknowledgements\nThe creation of this dataset would not have been possible without the machine learning technology uClassify.com, which powers typealyzer.com. Thank you also to all the members of The Swedish Memetic Society for encouragement and joy while preparing the work for this. A special thanks also to Mikael Huss for being such a kind and generally awesome person and taking the time to help me while I've entered the fascinating world of data science.\n\n# Inspiration\nCan you predict the Jungian cognitive function based on the human language samples?\n\nHow could one create a new and improved typealyzer.com that prevents conflict and relieves stress, anxiety and depression?""","b""['internet', 'linguistics', 'psychometrics', 'medium', 'featured']""",https://www.kaggle.com/mattiasostmar/blog-texts-and-dominant-jungian-cognitive-function
b'NY Active Projects Under Construction',b'From New York City Open Data',"b""### Content  \n\nNew school projects (Capacity) and Capital Improvement Projects (CIP) currently under Construction.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/gKUC4TMhOiY) by [Ousa Chea](https://unsplash.com/@cheaousa) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'education', 'construction', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-active-projects-under-construction
b'Hotel Reviews',"b'A list of 1,000 hotels and their online reviews.'","b""# About This Data\nThis is a list of 1,000 hotels and their reviews provided by [Datafiniti's Business Database][1]. The dataset includes hotel location, name, rating, review data, title, username, and more. \n\n*Note that this is a sample of a large data set. The full data set is available through Datafiniti.*\n\n# What You Can Do With This Data\nYou can use this data to [compare hotel reviews on a state-by-state basis][2]; experiment with sentiment scoring and other natural language processing techniques. The review data lets you correlate keywords in the review text with ratings. E.g.:\n\n* What are the bottom and top states for hotel reviews by average rating?\n* What is the correlation between a state\xe2\x80\x99s population and their number of hotel reviews?\n* What is the correlation between a state\xe2\x80\x99s tourism budget and their number of hotel reviews?\n\n# Data Schema\nA full schema for the data is available in our [support documentation][3].\n\n# About Datafiniti\nDatafiniti provides instant access to web data. We compile data from thousands of websites to create standardized databases of business, product, and property information. [Learn more][4].\n\n# Want More?\nYou can get more data like this by [joining Datafiniti][5] or [requesting a demo][6].\n\n  [1]: https://datafiniti.co/products/business-data/\n  [2]: https://datafiniti.co/state-state-comparison-hotel-reviews/\n  [3]: https://datafiniti-api.readme.io/docs/business-data-schema\n  [4]: https://datafiniti.co\n  [5]: https://portal.datafiniti.co/login\n  [6]: https://datafiniti.co/request-a-demo/""","b""['internet', 'linguistics', 'databases', 'hotels', 'small', 'featured']""",https://www.kaggle.com/datafiniti/hotel-reviews
b'MESSIDOR-2 DR Grades',"b'Adjudicated DR Severity, DME, and Gradability for the MESSIDOR-2 fundus dataset'","b""### Context\n\nThese data represent Diabetic Retinopathy grades (as well as DME and Gradability) for the publicaly available MESSIDOR-2 fundus image database. (http://latim.univ-brest.fr/indexfce0.html)\n\n### Content\n\nThe grades were adjudicated by a panel of three Retina Specialists.\n\n### Acknowledgements\n\nReferences:\n\n[1] Decenci\xc3\xa8re  E, Etienne  D, Xiwei  Z,  et al.  Feedback on a publicly distributed image database: the Messidor database.  Image Anal Stereol. 2014;33(3):231-234. doi:10.5566/ias.1155\n\n[2] Krause, J. et al. Grader variability and the importance of reference standards for evaluating machine learning models for diabetic retinopathy. Ophthalmology (2018). doi:10.1016/j.ophtha.2018.01.034\n\n[3] Gulshan, V. et al. Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs. JAMA 316, 2402\xe2\x80\x932410 (2016)\n                                                                                                                                                                                                          \n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?""","b""['healthcare', 'health', 'ophthalmology', 'small', 'featured']""",https://www.kaggle.com/google-brain/messidor2-dr-grades
b'Turkey Political Opinions',"b'Turkey Political Opinions with Age, Sex, Education, City Features'","b""We need your verdict to build a better model\n&gt; If you have a free time and you provide us with the data via the following link, we are rewarded.\n&gt; link: https://docs.google.com/forms/d/e/1FAIpQLSdGEjXtk_dExehcOgck28nTZ2ncBfMazqcYbYMlJSlcJ5_5JA/viewform\n\n## Context\n10 questions related to this political orientation were asked, and a yes / no feedback was received from them. Apart from that, the gender of the person, age, level of education, region where he lived was added to the questions.\n\n## Content\nThe time range of the data covers 2018. May 11, 2018 through May 13, 2018 was collected via google forms.\n\n## Acknowledgements\nyemregundogmus own the dataset he is a University student in first class statistics, [Click][1] for see his projects or other datasets\n\n## Inspiration\nThis data set is interesting because it reveals the point of view of Turkish people towards political events. With this dataset, people can determine the point of view against the events at the time of election and make a selection work according to it. Or machine-learning algorithms may be required to make forecasts from the machine. In conclusion Decision-Tree can be seen how people's political thoughts have influenced party-based.\n\n## Data Information\n **Features :** \n\n* Cinsiyet : Sex Feature\n* Yas : Age Feature\n* Bolge : Areas inhabited in Turkey\n* Egitim : Education Level \n* (Soru = Question) (Questions include Turkey)\n* Soru1/Question1: Do you think our Economic Status is good?\n* Soru2/Question2: Need Reform in Education?\n* Soru3/Question3: Resolve Privatization Are You?\n* Soru4/Question4: Should the state use a penalty like death penalty for certain crimes?\n* Soru5/Question5: Do you find our journalists neutral enough?\n* Soru6/Question6: From 22:00 am Then Are You Supporting the Prohibition to Buy Drinks?\n* Soru7/Question7: Do You Want to Live in a Secular State?\n* Soru8/Question8: Are you supporting the abortion ban?\n* Soru9/Question9: Do you think that the extraordinary state (Ohal) restricts Freedoms?\n* Soru10/Question10: Would you like a new part of the parliament to enter?\n* Parti : Political View\n\n**Data Review :**\n\n* Evet = Yes \n* Hay\xc4\xb1r = No \n* Erkek = Male \n* Kad\xc4\xb1n = Female\n* Yas = Age\n* Bolge = City \n* Egitim = Education \n* \xc4\xb0lkokul = primary school\n* OrtaOkul = junior high school\n* Lise = High School\n* Lisans = University\n* Lisans \xc3\x9cst\xc3\xbc = MA\n\n\n  [1]: https://www.kaggle.com/yemregundogmus""","b""['classification', 'feature engineering', 'deep learning', 'politics', 'forecasting', 'small', 'featured']""",https://www.kaggle.com/yemregundogmus/turkey-political-opinions
b'Ghana Health Facilities',b'Ownership & Types of Health Facilities in Ghana',"b""## Context\nThis dataset is provided as part of Citizen Data Science project, to gather & provide fairly clean data (which is a challenge in these regions) to support the data science practice in Ghana and other regions at the beginning of their data science learning curve. So you support is welcome\n\nThis dataset provides a listing of healthcare facilities in Ghana, by exploring it we gain new understanding of the country's health infrastructure.\n\n## Content\nThis dataset contains information about health facilities in Ghana organised by Region and District. It also includes the type of health facility and the ownership as well as its geo-location.\n\n## Dataset Usecases (are you up to the task? try any of below)    \n**1.  Learning/familiarisation with cleaning data and resolving in challenging context of data acquisition.**  \n\n**2. Understanding Ghana's health infrastructure**  \n\n**3. Complex Joint of health facilities and tier data**  \nThe health facilities data and the tier data are from difference sources but we like to join them because they refer to the same facility however this join may not be a simple join because the health facility name in both dataset are not exact a string match.    \n\n**4. Understanding the level of access to facilities**  \nCombined with population data we want to understand whether some regions or areas are deprived?    \n\n**Any other creative stuff you can do with this data**\n\n## Inspiration\n-  [Exploratory Analysis](https://www.kaggle.com/datanix/starter-ghana-health-facilities) by: [easimadi](https://www.linkedin.com/in/easimadi)\n-  Curating Ghana's Health Facilities Dataset by [hisham](https://www.linkedin.com/in/hisham-osman-48579558/)\n- [Understanding Ghana's Health Infrastructure](https://public.tableau.com/profile/datanix.ds4good#!/vizhome/ghanahealthinfrastructure/Dashboard1?publish=yes) - Tableau visualisation\n\n## Acknowledgements\naccessed: http://data.gov.gh/dataset/health-facilities   \nsource: http://www.moh-ghana.org/  \n\nby: easimadi""","b""['healthcare', 'small', 'featured']""",https://www.kaggle.com/citizen-ds-ghana/health-facilities-gh
b'Data Science for Good: PASSNYC',b'Help PASSNYC determine which schools need their services the most',"b""# Overview\n\nPASSNYC is a not-for-profit organization that facilitates a collective impact that is dedicated to broadening educational opportunities for New York City's talented and underserved students. New York City is home to some of the most impressive educational institutions in the world, yet in recent years, the City\xe2\x80\x99s specialized high schools - institutions with historically transformative impact on student outcomes - have seen a shift toward more homogeneous student body demographics.\n\nPASSNYC uses public data to identify students within New York City\xe2\x80\x99s under-performing school districts and, through consulting and collaboration with partners, aims to increase the diversity of students taking the Specialized High School Admissions Test (SHSAT). By focusing efforts in under-performing areas that are historically underrepresented in SHSAT registration, we will help pave the path to specialized high schools for a more diverse group of students.\n\n---\n\n# Problem Statement\n\nPASSNYC and its partners provide outreach services that improve the chances of students taking the SHSAT and receiving placements in these specialized high schools. The current process of identifying schools is effective, but PASSNYC could have an even greater impact with a more informed, granular approach to quantifying the potential for outreach at a given school. Proxies that have been good indicators of these types of schools include data on English Language Learners, Students with Disabilities, Students on Free/Reduced Lunch, and Students with Temporary Housing.\n\nPart of this challenge is to assess the needs of students by using publicly available data to quantify the challenges they face in taking the SHSAT. The best solutions will enable PASSNYC to identify the schools where minority and underserved students stand to gain the most from services like after school programs, test preparation, mentoring, or resources for parents. \n\nSubmissions for the Main Prize Track will be judged based on the following general criteria:\n\n* **Performance** - How well does the solution match schools and the needs of students to PASSNYC services? PASSNYC will not be able to live test every submission, so a strong entry will clearly articulate why it is effective at tackling the problem.\n \n* **Influential** - The PASSNYC team wants to put the winning submissions to work quickly. Therefore a good entry will be easy to understand and will enable PASSNYC to convince stakeholders where services are needed the most.\n\n* **Shareable** - PASSNYC works with over 60 partner organizations to offer services such as test preparation, tutoring, mentoring, extracurricular programs, educational consultants, community and student groups, trade associations, and more. Winning submissions will be able to provide convincing insights to a wide subset of these organizations. \n\n---\n\n# How to Participate \n\n### Accept the Rules\nTo be considered a participant in the PASSNYC Data Science for Good Event you must register and accept the rules.\n\nAccept the rules by filling out this form: [SIGNUP FORM](https://www.kaggle.com/data-science-for-good-passnyc-signup)<br>\n(You need to be logged into your Kaggle account)<br>\n\n### Make Submissions\n\nMain Prize Track:\n\n* Be a registered participant by accepting the rules<br>\n* Make your kernel public<br>\n* Submit your kernel(s) by filling out this form [SUBMISSION FORM](https://www.kaggle.com/data-science-for-good-passnyc-submission)<br>\n\nSecondary Prize Track:<br>\n\n* Be a registered participant by accepting the rules<br>\n* Make sure your kernel is public<br>\n\n---\n\n# Prizes and Eligibility\n\n## Main Prize Track ($15,000 total)\n\nPASSNYC will award $15,000 in total prizes to five winning authors who submit public kernels that effectively tackle the objective and use two or more of Socrata\xe2\x80\x99s NYC Open Datasets on Kaggle ([List of public datasets](https://www.kaggle.com/new-york-city/datasets)). These kernels must be submitted for consideration by the deadline.\n\nPrizes:<br>\n\n- 1st place:  $5,000\n- 2nd place: $4,000\n- 3rd place: $3,000\n- 4th place: $1,500\n- 5th place: $1,500\n\n## Secondary Prize Track (swag)\n\nTo encourage collaboration through sharing of code and use of publicly available data, secondary prize awards will be based on popularity (upvotes) and the use of Socrata\xe2\x80\x99s NYC Open Datasets on Kaggle ([List of public datasets](https://www.kaggle.com/new-york-city/datasets)). Winners will be the authors of the top five most upvoted kernels that use two or more sources of Socrata\xe2\x80\x99s NYC Open Data on Kaggle. \n\nPrizes are the winner\xe2\x80\x99s choice of:<br>\n\n- Kaggle No Free Hunch T-shirt\n- Kaggle Tier T-shirt\n- Kaggle Coffee Mug\n- Kaggle Water Bottle\n\n---\n\n# Timeline\n\nAll dates are 11:59PM UTC\n\n- Deadline for secondary prize submissions: **July 17th**\n\n- Deadline for main prize submissions: **August 7th**\n\n- Main prize winners announcement: **August 14th**\n\n---\n\n# Rules\n\nTo be eligible to win a prize in either of the above prize tracks, you must be:\n\n- a registered account holder at Kaggle.com;\n- the older of 18 years old or the age of majority in your jurisdiction of residence;\n- not a resident of Crimea, Cuba, Iran, Syria, North Korea, or Sudan; and\n- not a person or representative of an entity under U.S. export controls or sanctions.\n\nYour kernels will only be eligible to win if they have been made public on kaggle.com by the above deadline. All prizes are awarded at the discretion of PASSNYC, and PASSNYC reserves the right to cancel or modify prize criteria.\n\nUnfortunately employees, interns, contractors, officers and directors of Kaggle Inc., and their parent companies, are not eligible to win any prizes.\n\n""","b""['data visualization', 'demographics', 'education', 'recommendation', 'small', 'featured']""",https://www.kaggle.com/passnyc/data-science-for-good
"b'NYS Air Passenger Traffic, Port Authority of NY NJ'",b'From New York State Open Data',"b""### Content  \n\nThe dataset presented in this forum is monthly data. The Port Authority  collects monthly data for domestic and international, cargo, flights, passengers and aircraft equipment type from each carrier at PANYNJ-operated airports. The data is aggregated and forms the basis for estimating flight fees, parking, concession, and PFC revenues at the Port Authority Airports.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/mytSmcgVHRE) by [chuttersnap](https://unsplash.com/@chuttersnap) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""","https://www.kaggle.com/new-york-state/nys-air-passenger-traffic,-port-authority-of-ny-nj"
b'Twitter Threads',b'...or blog posts? Analyzing engagement in Twitter threads',"b'### Context\n\nWhen Twitter introduced its thread functionality, a debate emerged: ""If you\'re gonna write a f*ck ton of tweets at once, why not write a blog post instead of cluttering my feed?""... ""It\'s easier and user-friendlier to share ideas in a single app""...\n  \nI\'m not getting into that debate. Both blog posts and Twitter threads have their own advantages.  \n    \nBut I noticed a phenomenon while reading threads on Twitter: **the engagement\xe2\x80\x94*retweets, likes and replies*\xe2\x80\x94drops with each subsequent tweet!**\n\nNow, this has some logical explanations. Like, people don\'t want to retweet or like *every* tweet in a thread, because that\'d be annoying. But this trend kept appearing in every single thread I read.  \n  \nIt was bugging me, so I had to gather some data.\n\n### Content\nThe dataset is divided into **five** parts:  \n - `five_ten.csv`: data of threads 5-10 tweets long  \n - `ten_fifteen.csv`: data of threads 10-15 tweets long  \n - `fifteen_twenty.csv`: data of threads 15-20 tweets long  \n - `twenty_twentyfive.csv`: data of threads 20-25 tweets long  \n - `twentyfive_thirty.csv`: data of threads 25-30 tweets long  \n  \n  \nThey all contain the same data:  \n - `id`: Tweet ID (maybe I should remove it to anonymize the data?)  \n - `thread_number`: Thread identifier, used for grouping each thread and its tweets  \n - `timestamp`: Creation date of each tweet\n - `text`: The content of each tweet  \n - `retweets`: Retweet count for each tweet  \n - `likes`: Like count for each tweet  \n - `replies`: Reply count for each tweet  \n  \n  \nEach ""bin"" contains around 100 threads... so in total there are ~500 threads.\n\n### Acknowledgements\n\nThe threads were manually gathered using [Thread Reader][1] (both the web page and the [bot][2]).  \n\n### Disclaimer\nThe content of the threads/tweets **did not** had any influence in choosing a thread or not. The only parameter was the length of the thread (5-30 tweets tops). The tweets collected date from October 2017 to May 2018.\n\n### Inspiration\n  \nSome things I noticed while gathering the data was that political threads have a steadier engagement than, say, art threads. So **context might influence thread engagement**, and it\'d be interesting to do some NLP to figure that out.  \n  \nAlso it\'d be cool to find a ""formula"" for better engagement in Twitter threads, like how long should a thread be? or maybe a probability of engagement based on the success of the initial tweet?  \n  \nFinally, this whole issue reminds me of [the headline problem][3]: most people don\'t go beyond the headline. Maybe Twitter threads suffer from that too.\n\n  [1]: http://threadreaderapp.com/\n  [2]: https://twitter.com/threadreaderapp\n  [3]: https://www.washingtonpost.com/news/the-fix/wp/2014/03/19/americans-read-headlines-and-not-much-else/'","b""['internet', 'nlp', 'linguistics', 'twitter', 'social sciences', 'small', 'featured']""",https://www.kaggle.com/danielgrijalvas/twitter-threads
b'ResNet-18',b'ResNet-18 Pre-trained Model for PyTorch',"b'# ResNet-18\n\n---\n\n## Deep Residual Learning for Image Recognition\nDeeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. \n\nAn ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. \n\nThe depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.<br>\n\n**Authors: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun**<br>\n**https://arxiv.org/abs/1512.03385**\n\n---\n\n\nArchitecture visualization: http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006\n\n![Resnet][1]\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/nyYh5xH.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/resnet18
b'Pollster Politician Job Approval',b'Explore Pollster Political Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Huffington Post through HuffPost Pollster. The organization has poll/survey data available [here](https://elections.huffingtonpost.com/pollster) from various surveyors. Explore HuffPost Pollster data using Kaggle and all of the data sources available through the Huffington Post [organization page](https://www.kaggle.com/huffingtonpost)!  \n\n* Update Frequency: This dataset is updated Weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using HuffPost Pollster's [API](https://app.swaggerhub.com/apis/huffpostdata/pollster-api/2.0.0) and Kaggle's API.""","b""['politics', 'small', 'featured']""",https://www.kaggle.com/huffingtonpost/pollster-politician-job-approval
"b'Chronic illness: symptoms, treatments and triggers'",b'How do treatments and environmental stressors impact symptoms?',"b""###Introduction\n\nFlaredown is an app that helps patients of chronic autoimmune and invisible illnesses improve their symptoms by avoiding triggers and evaluating their treatments. Each day, patients track their symptom severity, treatments and doses, and any potential environmental triggers (foods, stress, allergens, etc) they encounter.\n\n###About the data\n\nInstead of coupling symptoms to a particular illness, Flaredown asks users to create their unique set of conditions, symptoms and treatments (\xe2\x80\x9ctrackables\xe2\x80\x9d). They can then \xe2\x80\x9ccheck-in\xe2\x80\x9d each day and record the severity of symptoms and conditions, the doses of treatments, and \xe2\x80\x9ctag\xe2\x80\x9d the day with any unexpected environmental factors.\n\n**User:** includes an ID, age, sex, and country.\n\n**Condition:** an illness or diagnosis, for example Rheumatoid Arthritis, rated on a scale of 0 (not active) to 4 (extremely active).\n\n**Symptom:** self-explanatory, also rated on a 0\xe2\x80\x934 scale.\n\n**Treatment:** anything a patient uses to improve their symptoms, along with an optional dose, which is a string that describes how much they took during the day. For instance \xe2\x80\x9c3 x 5mg\xe2\x80\x9d.\n\n**Tag:** a string representing an environmental factor that does not occur every day, for example \xe2\x80\x9cate dairy\xe2\x80\x9d or \xe2\x80\x9crainy day\xe2\x80\x9d.\n\n**Food:** food items were seeded from the publicly-available USDA food database. Users have also added many food items manually.\n\n**Weather:** weather is pulled automatically for the user's postal code from the Dark Sky API. Weather parameters include a description, precipitation intensity, humidity, pressure, and min/max temperatures for the day.\n\nIf users do not see a symptom, treatment, tag, or food in our database (for instance \xe2\x80\x9cAbdominal Pain\xe2\x80\x9d as a symptom) they may add it by simply naming it. This means that the data requires some cleaning, but it is patient-centered and indicates their primary concerns.\n\n\n###Suggested Questions\n\n- Does X treatment affect Y symptom positively/negatively/not at all? What are the most strongly-correlated symptoms and treatments?\n- Are there subsets within our current diagnoses that could more accurately represent symptoms and predict effective treatments?\n- Can we reliably predict what triggers a flare for a given user or all users with a certain condition?\n- Could we recommend treatments more effectively based on similarity of users, rather than specific symptoms and conditions? (Netflix recommendations for treatments)\n- Can we quantify a patient\xe2\x80\x99s level of disease activity based on their symptoms? How different is it from our existing measures?\n- Can we predict which symptom should be treated to have the greatest effect on a given illness?\n- How accurately can we guess a condition based on a user\xe2\x80\x99s symptoms?\n- Can we detect new interactions between treatments?\n\nPlease email logan@flaredown.com if you have questions about the project""","b""['healthcare', 'health', 'medicine', 'diseases', 'epidemiology', 'medium', 'featured']""",https://www.kaggle.com/flaredown/flaredown-autoimmune-symptom-tracker
b'NYS Occupational Employment Statistics',b'From New York State Open Data',"b""### Content  \n\nThe Occupational Employment Statistics (OES) survey is a semiannual mail survey of employers that measures occupational employment and occupational wage rates for wage and salary workers in nonfarm establishments, by industry.  OES estimates are constructed from a sample of about 51,000 establishments.  Each year, forms are mailed to two semiannual panels of approximately 8,500 sampled establishments, one panel in May and the other in November.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/fY8Jr4iuPQM) by [Clem Onojeghuo](https://unsplash.com/@clemono2) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'employment', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-occupational-employment-statistics
b'Chicago Public Health Statistics',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'health', 'death', 'life', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-public-health-statistics
b'Arabic Handwritten Digits Dataset',b'Arabic Handwritten Digits Data-set',"b'# Arabic Handwritten Digits Dataset\n\n### Abstract\nIn recent years, handwritten digits recognition has been an important area\ndue to its applications in several fields. This work is focusing on the recognition\npart of handwritten Arabic digits recognition that face several challenges, including\nthe unlimited variation in human handwriting and the large public databases. The\npaper provided a deep learning technique that can be effectively apply to recognizing Arabic handwritten digits. LeNet-5, a Convolutional Neural Network (CNN)\ntrained and tested MADBase database (Arabic handwritten digits images) that contain 60000 training and 10000 testing images. A comparison is held amongst the\nresults, and it is shown by the end that the use of CNN was leaded to significant\nimprovements across different machine-learning classification algorithms.\n\nThe Convolutional Neural Network was trained and tested MADBase database (Arabic handwritten digits images) that contain 60000 training and 10000 testing images. Moreover, the CNN is giving an average recognition accuracy of 99.15%. \n\n### Context\nThe motivation of this study is to use cross knowledge learned from multiple works to enhancement the performance of Arabic handwritten digits recognition. In recent years, Arabic handwritten digits recognition with different handwriting styles as well, making it important to find and work on a new and advanced solution for handwriting recognition. A deep learning systems needs a huge number of data (images) to be able to make a good decisions.\n\n\n### Content\n\nThe MADBase is modified Arabic handwritten digits database contains 60,000 training images, and 10,000 test images. MADBase were written by 700 writers. Each writer wrote each digit (from 0 -9) ten times. To ensure including different writing styles, the database was gathered from different institutions: Colleges of Engineering and Law, School of Medicine, the Open University (whose students span a wide range of ages), a high school, and a governmental institution. \nMADBase is available for free and can be downloaded from (http://datacenter.aucegypt.edu/shazeem/) .\n\n\n\n### Acknowledgements\n\n**CNN for Handwritten Arabic Digits Recognition Based on LeNet-5**\nhttp://link.springer.com/chapter/10.1007/978-3-319-48308-5_54\nAhmed El-Sawy, Hazem El-Bakry, **Mohamed Loey**\nProceedings of the International Conference on Advanced Intelligent Systems and Informatics 2016\nVolume 533 of the series Advances in Intelligent Systems and Computing pp 566-575\n\n### Inspiration\n\nCreating the proposed database presents more challenges because it deals with many issues such as style of writing, thickness, dots number and position. Some characters have different shapes while written in the same position. For example the teh character has different shapes in isolated position.\n\n### Arabic Handwritten Characters Dataset\nhttps://www.kaggle.com/mloey1/ahcd1\n\nBenha University\n\nhttp://bu.edu.eg/staff/mloey\n\nhttps://mloey.github.io/'","b""['writing', 'mathematics', 'medium', 'featured']""",https://www.kaggle.com/mloey1/ahdd1
b'Seattle Library Checkout Records',b'Twelve years of checkout records',"b""### Context\n\nThis dataset includes a log of all physical item checkouts from Seattle Public Library. The dataset begins with checkouts occurring in April 2005, and is regularly updated. Renewals are not included.\n\n### Content\n\nThe dataset contains several types of files:\n\n- Checkout records hold the raw data. I've dropped several columns from these files in order to shrink the total dataset size down from a couple of dozen gigabytes; they can be rebuilt by merging with the library collection inventory.\n- The data dictionary allows you to decode the 'ItemType' column from the checkout records.\n- The library collection inventory is a dataset in its own right and stores important metadata about each title, such as the author and subjects.\n\n### Inspiration\n\n- Can you predict which books will be checked out in the coming month? SPL posts fresh data every month, so you can check your forecast by downloading the new data from them. \n- With a bit of imagination, this can be a great dataset for logistics modeling. Make some assumptions about each [location's](http://www.spl.org/locations) storage capacity and where a book was checked out from and you've got a warehouse resource allocation problem. \n\n### Acknowledgements\n\nThis dataset was kindly made available by the [Seattle Public Library][1]. You can find the original copies of the three component datasets at the following links:\n- [Collection data](https://data.seattle.gov/Community/Library-Collection-Inventory/6vkj-f5xf)\n- [Data dictionary](https://data.seattle.gov/Community/Integrated-Library-System-ILS-Data-Dictionary/pbt3-ytbc)\n- [Checkout records](https://data.seattle.gov/dataset/Checkouts-by-Title-Physical-Items-/3h5r-qv5w)\n\n### Disclaimer\n\nThe data made available here has been modified for use from its original source, which is the City of Seattle. Neither the City of Seattle nor the Office of the Chief Technology Officer (OCTO) makes any claims as to the completeness, timeliness, accuracy or content of any data contained in this application; makes any representation of any kind, including, but not limited to, warranty of the accuracy or fitness for a particular use; nor are any such warranties to be implied or inferred with respect to the information or data furnished herein. The data is subject to change as modifications and updates are complete. It is understood that the information contained in the web feed is being used at one's own risk.\n\nFor the complete terms of use, please see the [City of Seattle Data Policy](https://data.seattle.gov/stories/s/Data-Policy/6ukr-wvup/).\n\n  [1]: https://www.spl.org/""","b""['books', 'libraries', 'large', 'featured']""",https://www.kaggle.com/seattle-public-library/seattle-library-checkout-records
b'Economic calendar (EC) Forex (2011-2018)',"b'Archive of important events, economic news, volatility in a convenient format'","b'\nIntroduction\n------------\n\n   Explore the archive of relevant economic information: relevant news on all indicators with explanations, data on past publications on the economy of the United States, Britain, Japan and other developed countries, volatility assessments and much more. For the construction of their forecast models, the use of in-depth training is optimal, with a learning model built on the basis of EU and Forex data.\n    The economic calendar is an indispensable assistant for the trader.\n\nData set\n--------\n\n   The data set is created in the form of an CSV, Excel spreadsheet (two files 2011-2013, 2014-2018), which can be found at boot time. You can see the source of the data on the site https://www.investing.com/economic-calendar/\n\n![http://comparic.com/wp-content/uploads/2016/12/Economic_Calendar_-_Investing.com_-_2016-12-19_02.45.10.jpg][1]\n\n1. column - Event date\n2. column - Event time (time New York)\n3. column - Country of the event\n4. column - The degree of volatility (possible fluctuations in currency, indices, etc.) caused by this event\n5. column - Description of the event\n6. column - Evaluation of the event according to the actual data, which came out better than the forecast, worse or correspond to it\n7. column - Data format (%, K x103, M x106, T x109)\n8. column - Actual event data\n9. column - Event forecast data\n10. column - Previous data on this event (with comments if there were any interim changes).\n\n\nInspiration\n-------------\n\n 1. Use the historical EU in conjunction with the Forex data (exchange rates, indices, metals, oil, stocks) to forecast subsequent Forex data in order to minimize investment risks (combine fundamental market analysis and technical).\n 2. Historical events of the EU used as a forecast of the subsequent (for example, the calculation of the probability of an increase in the rate of the Fed).\n 3. Investigate the impact of combinations of EC events on the degree of market volatility at different time periods.\n 4. To trace the main trends in the economies of the leading countries (for example, a decrease in the demand for unemployment benefits).\n 5. Use the EU calendar together with the news background archive for this time interval for a more accurate forecast.\n \n\n\n  [1]: http://comparic.com/wp-content/uploads/2016/12/Economic_Calendar_-_Investing.com_-_2016-12-19_02.45.10.jpg'","b""['finance', 'economics', 'artificial intelligence', 'learning', 'money', 'small', 'featured']""",https://www.kaggle.com/devorvant/economic-calendar
"b""Parkinson's Vision-Based Pose Estimation Dataset""","b""Pose estimates of Parkinson's patients using deep learning""","b""### Context\n\nThe data includes 2D human pose estimates of Parkinson's patients performing a variety of tasks (e.g. communication, drinking from a cup, leg agility). Pose estimates were produced using Convolutional Pose Machines (CPM, https://arxiv.org/abs/1602.00134). \n\nThe goal of this project was to use features derived from videos of Parkinson's assessment to predict the severity of parkinsonism and dyskinesia based on clinical rating scales.\n\n### Content\n\nData was acquired as part of a study to measure the minimally clinically important difference in Parkinson's rating scales. Participants received a two hour infusion of levodopa followed by up to two hours of observation. During this time, they were assessed at regular intervals and assessments were video recorded for post-hoc ratings by neurologists. There were between 120-130 videos per task.\n\nThe data includes all movement trajectories (extracted frame-by-frame) from the videos of Parkinson's assessments using CPM, as well as confidence values produced by CPM. Ground truth ratings of parkinsonism and dyskinesia severity are included using the UDysRS, UPDRS, and CAPSIT rating scales. \n\nCamera shake has been removed from trajectories (see paper for more details). No other preprocessing has been performed. Files are saved in JSON format. For information on how to deal with files, see data_import_demo.ipynb or view online at https://github.com/limi44/Parkinson-s-Pose-Estimation-Dataset.\n\n### Acknowledgements\n\nWe would like to acknowledge the staff and patients at Toronto Western Hospital for their time and assistance in this study.\n\n### Citations\n\nIf you use this dataset in your work, please cite the following reference:  \n**M.H. Li, T.A. Mestre, S.H. Fox, and B. Taati, Vision-based assessment of parkinsonism and levodopa-induced dyskinesia with pose estimation, Journal of NeuroEngineering and Rehabilitation, vol. 15, no. 1, p. 97, Nov. 2018. doi:10.1186/s12984-018-0446-z.**  \n\nYou may also find the following paper useful. In this paper, we evaluated the responsiveness of features to clinically relevant changes in dyskinesia severity:  \n**M.H. Li, T.A. Mestre, S.H. Fox, B. Taati, Automated assessment of levodopa-induced dyskinesia: Evaluating the responsiveness of video-based features, Parkinsonism & Related Disorders. (2018). doi:10.1016/j.parkreldis.2018.04.036.**\n\n### Inspiration\n\nIn our study, we aimed to evaluate the readiness of off-the-shelf human pose estimation and deep learning for clinical applications in Parkinson's disease. We hope that others may find this dataset useful for furthering progress in technology-based monitoring of neurological disorders. \n\n### License\n\nThis work is licensed under the Creative Commons Attribution 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.\n\n## Banner\n\nPhoto by jesse orrico on Unsplash.""","b""['medium', 'featured']""",https://www.kaggle.com/limi44/parkinsons-visionbased-pose-estimation-dataset
b'xigua3.0 (Watermelons)',b'Watermelon dataset (\xe8\xa5\xbf\xe7\x93\x9c\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86) in a Chinese introductory ML textbook',"b'### Context\n\nProf. Zhihua Zhou\'s textbook *Machine Learning* inspires a lot of people in the Chinese machine learning community, and I am sure it will continue to attract more people in this filed in the future. The ""xigua"" dataset is used extensively in this book for different algorithms. So, I took the initiative to put in on Kaggle for other people\'s easy access. \n### Content\n\nThis dataset includes categorical as well as numerical features, and labels for each entry (good watermelon or bad watermelon). So you can use this dataset virtually for playing with all kinds machine learning algorithm, such as SVM, naive bayes, clustering, etc.. Have fun exploring!\n\n### Acknowledgements\n\nWe wouldn\'t be here without the help of others.'","b""['beginner', 'classification', 'random forest', 'svm', 'china ', 'small', 'featured']""",https://www.kaggle.com/benjaminwang/xigua30
b'Chicago Bike Racks',b'From City of Chicago Open Data',"b""### Content  \n\nBike racks in Chicago. To view or use the attachment files, compression software and special GIS software, such as ESRI ArcGIS, is required.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/zbUH21c9ARk) by [Christin Hume](https://unsplash.com/@christinhumephoto) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-bike-racks
b'CalCOFI',b'Over 60 years of oceanographic data',"b'### Context\nThe CalCOFI data set represents the longest (1949-present) and most complete (more than 50,000 sampling stations) time series of oceanographic and larval fish data in the world. It includes abundance data on the larvae of over 250 species of fish; larval length frequency data and egg abundance data on key commercial species; and oceanographic and plankton data. The physical, chemical, and biological data collected at regular time and space intervals quickly became valuable for documenting climatic cycles in the California Current and a range of biological responses to them. CalCOFI research drew world attention to the biological response to the dramatic Pacific-warming event in 1957-58 and introduced the term \xe2\x80\x9cEl Ni\xc3\xb1o\xe2\x80\x9d into the scientific literature. \n\nThe [California Cooperative Oceanic Fisheries Investigations][1] (CalCOFI) are a unique partnership of the California Department of Fish & Wildlife, NOAA Fisheries Service and Scripps Institution of Oceanography. The organization was formed in 1949 to study the ecological aspects of the sardine population collapse off California. Today our focus has shifted to the study of the marine environment off the coast of California, the management of its living resources, and monitoring the indicators of El Nino and climate change. CalCOFI conducts quarterly cruises off southern & central California, collecting a suite of hydrographic and biological data on station and underway.  Data collected at depths down to 500 m include: temperature, salinity, oxygen, phosphate, silicate, nitrate and nitrite, chlorophyll, transmissometer, PAR, C14 primary productivity, phytoplankton biodiversity, zooplankton biomass, and zooplankton biodiversity. \n\n### Content\n\nEach table has several dozen columns. Please see this page for the [table details][2].\n\n  [1]: http://calcofi.org/about-calcofi.html\n  [2]: http://www.calcofi.org/new.data/index.php/reporteddata/2013-09-30-23-23-27/database-tables-description'","b""['ecology', 'oceanography', 'medium', 'featured']""",https://www.kaggle.com/sohier/calcofi
b'LA Community-Wide Greenhouse Gas Emissions',b'From Los Angeles Open Data',"b""### Content  \n\nThis greenhouse gas inventory is based on the Global Protocol for Community-Scale Greenhouse Gas Emissions (pdf attached). The City of LA collects and publicly reports these metrics in order to manage and reduce our GHG impact. \n\nData is from 2013. Learn more about the Mayor's Office of Sustainability and our roadmap for a cleaner environment and stronger economy at https://www.lamayor.org/plan  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/9HEY1URQIQY) by [Jason Blackeye](https://unsplash.com/@jeisblack) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'climate', 'environment', 'small', 'featured']""",https://www.kaggle.com/cityofLA/la-community-wide-greenhouse-gas-emissions
b'NBER Macrohistory Database',b'Western economic history data spanning 1785-1974',"b""### Context\nThis data set covers all aspects of the pre-WWI and interwar economies, including production, construction, employment, money, prices, asset market transactions, foreign trade, and government activity. Many series are highly disaggregated, and many exist at the monthly or quarterly frequency. The data set has some coverage of the United Kingdom, France and Germany, although it predominantly covers the United States. For information see:\n\n- Improving the Accessibility of the NBER's Historical Data , by Daniel Feenberg and Jeff Miron. (NBER Working Paper #5186). Published in the Journal of Business and Economic Statistics, Volume 15 Number 3 (July 1997) pages 293-299.\n\nInformation about [seasonal adjustments](http://www.nber.org/databases/macrohistory/contents/sa.html) is available, but in most cases only unadjusted series have been made available here.\n\n### Content\n\nThe data.csv is organized in a long format with columns for the date, variable, and value.  The dates are always the beginning of period date for whatever period existed in the original data. This means that '1920' was converted to January 1st, 1920 while Q2 1920 was converted to April 1, 1920. This is intended as a convenience to make it easier to work with multiple time series from the original mixed frequency data.\n\nThe data is currently organized into 16 chapters:\n\n - Chapter1: Production of Commodities\n - Chapter2: Construction\n - Chapter3: Transportation and Public Utilities\n - Chapter4: Prices\n - Chapter5: Stocks of Commodities\n - Chapter6: Distribution of Commodities\n - Chapter7: Foreign Trade\n - Chapter8: Income and Employment\n - Chapter9: Financial Status of Business\n - Chapter10: Savings and Investment\n - Chapter11: Security Markets\n - Chapter12: Volume of Transactions\n - Chapter13: Interest Rates\n - Chapter14: Money and Banking\n - Chapter15: Government and Finance\n - Chapter16: Leading Indicators\n\nThe dataset has been transformed from its original format. You can find [the data preparation code here](https://gist.github.com/SohierDane/f545be3040a0de86f9016b94576dd24b).\n\n### Acknowledgements\n\nThis dataset was kindly made available by the [National Bureau of Economic Research](http://www.nber.org/) (NBER). You can find [the original dataset here][1].\n\n### Inspiration\n\n - Which major historical events can you detect from the data?\n - With roughly 3,500 time series in the dataset, finding relevant information can be challenging. Can you find a better way of organizing or indexing the data? \n\n  [1]: http://www.nber.org/databases/macrohistory/contents/index.html""","b""['economics', 'history', 'medium', 'featured']""",https://www.kaggle.com/sohier/nber-macrohistory-database
b'YouTube Faces With Facial Keypoints',b'Videos of Celebrity Faces with Facial Keypoints for each Image Frame',"b""### YouTube Faces Dataset with Facial Keypoints\n\nThis dataset is a processed version of the [YouTube Faces Dataset][1], that basically contained short videos of celebrities that are publicly available and were downloaded from YouTube. There are multiple videos of each celebrity (up to 6 videos per celebrity). I've cropped the original videos around the faces, plus kept only consecutive frames of up to 240 frames for each original video. This is done also for reasons of disk space, but mainly to make the dataset easier to use.\n\nAdditionally, for this kaggle version of the dataset I've extracted facial keypoints for each frame of each video using [this amazing 2D and 3D Face alignment library][2] that was recently published. please check out [this video][3] demonstrating the library. It's performance is really amazing, and I feel I'm quite qualified to say that after manually curating many thousands of individual frames and their corresponding keypoints. I removed all videos with extremely bad keypoints labeling. The end result of my curation process is approximately 2800 videos. Right now only 1293 of those videos are uploaded due to dataset size limitations (10GB), but since overall this totals into 155,560 single image frames, I think this is more than enough to do a lot of interesting kernels as well as potentially very interesting research.\n\n### Context\n\nKaggle datasets platform and its integration with kernels is really amazing, but it's yet to have a **videos dataset** (at least that I'm aware of). Videos are special in the fact that they contain rich **spatial patterns** (in this case images of human faces) **and** rich **temporal patterns** (in this case how the faces move in time).\n\nI was also inspired by the [Face Images with Marked Landmark Points][4] dataset uploaded by [DrGuillermo][5] and decided to create and share a dataset that would be similar but would also add something extra. \n\n### Acknowledgements\n\nIf you use The YouTube Faces Dataset, or refer to its results, please cite the following paper:  \nLior Wolf, Tal Hassner and Itay Maoz  \n**Face Recognition in Unconstrained Videos with Matched Background Similarity.**  \nIEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2011. ([pdf][6])\n\nif you use the 2D or 3D keypoints, or refer to its results, please cite the following paper:  \nAdrian Bulat and Georgios Tzimiropoulos.   \n**How far are we from solving the 2D &amp; 3D Face Alignment problem?**   \n(and a dataset of 230,000 3D facial landmarks), arxiv, 2017. ([pdf][7])\n\nAlso, I would like to thank [Gil Levi][8] for pointing out YouTube Faces to me a few years back.\n\n### Inspiration\n\nThe YouTube Faces Dataset was originally intended to be used for face recognition across videos, i.e. given two videos, are those videos of the same person or not?  \n\nI think it can be used to serve many additional goals, especially when combined with the keypoints information. For example, can we build a face movement model and predict what facial expression will come next?  \n\nThis dataset can also be used to test transfer learning between other face datasets (like [Face Images with Marked Landmark Points][9] that I mentioned earlier), or even other types of faces like cat or dog faces (like [here][10] or [here][11]). Also, using the [pre-trained Keras][12] models might be useful ([example kernel][13]).\n\nHave Fun!\n\n\n  [1]: https://www.cs.tau.ac.il/~wolf/ytfaces/\n  [2]: https://github.com/1adrianb/face-alignment\n  [3]: https://www.youtube.com/watch?v=8FdSHl4oNIM\n  [4]: https://www.kaggle.com/drgilermo/face-images-with-marked-landmark-points\n  [5]: https://www.kaggle.com/drgilermo\n  [6]: https://www.cs.tau.ac.il/~wolf/ytfaces/WolfHassnerMaoz_CVPR11.pdf\n  [7]: https://www.adrianbulat.com/downloads/FaceAlignment/FaceAlignment.pdf\n  [8]: https://www.kaggle.com/gillevi\n  [9]: https://www.kaggle.com/drgilermo/face-images-with-marked-landmark-points\n  [10]: https://www.kaggle.com/c/dog-breed-identification\n  [11]: https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition\n  [12]: https://www.kaggle.com/gaborfodor/keras-pretrained-models\n  [13]: https://www.kaggle.com/gaborfodor/use-pretrained-keras-models-lb-0-3""","b""['internet', 'image data', 'popular culture', 'celebrity', 'humans', 'large', 'featured']""",https://www.kaggle.com/selfishgene/youtube-faces-with-facial-keypoints
b'New York City Fee Charges',b'From New York City Open Data',"b""### Content  \n\nContains information about fees assessed against properties by HPD pursuant to the Housing Maintenance Code.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/72qDM1TA5p8) by [Matt Hoffman](https://unsplash.com/@__matthoffman__) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/new-york-city-fee-charges
b'American Time Use Survey',b'Multi-Year Survey Microdata Files from 2003-2015',"b'## Context\n\nThe American Time Use Survey (ATUS) is the Nation\xe2\x80\x99s first federally administered, continuous survey on time use in the United States. The goal of the survey is to measure how people divide their time among life\xe2\x80\x99s activities.\n\nIn ATUS, individuals are randomly selected from a subset of households that have completed their eighth and final month of interviews for the Current Population Survey (CPS). ATUS respondents are interviewed only one time about how they spent their time on the previous day, where they were, and whom they were with. The survey is sponsored by the Bureau of Labor Statistics and is conducted by the U.S. Census Bureau.\n\nThe major purpose of ATUS is to develop nationally representative estimates of how people spend their time. Many ATUS users are interested in the amount of time Americans spend doing unpaid, nonmarket work, which could include unpaid childcare, eldercare, housework, and volunteering. The survey also provides information on the amount of time people spend in many other activities, such as religious activities, socializing, exercising, and relaxing. In addition to collecting data about what people did on the day before the interview, ATUS collects information about where and with whom each activity occurred, and whether the activities were done for one\xe2\x80\x99s job or business. Demographic information\xe2\x80\x94including sex, race, age, educational attainment, occupation, income, marital status, and the presence of children in the household\xe2\x80\x94also is available for each respondent. Although some of these variables are updated during the ATUS interview, most of this information comes from earlier CPS interviews, as the ATUS sample is drawn from a subset of households that have completed month 8 of the CPS. \n\nThe user guide can be found [here](http://www.bls.gov/tus/atususersguide.pdf).\n\n## Content\n\nThere are 8 datasets containing microdata from 2003-2015:\n\n* **Respondent file**: The Respondent file contains information about ATUS respondents, including their labor force status and earnings.\n\n* **Roster file**: The Roster file contains information about household members and nonhousehold children (under 18) of ATUS respondents. It includes information such as age and sex.\n\n* **Activity file**: The Activity file contains information about how ATUS respondents spent their diary day. It includes information such as activity codes, activity start and stop times, and locations. Because Activity codes have changed somewhat between 2003 and 2015, this file uses activity codes that appear in the [2003-2015 ATUS Coding Lexicon (PDF)](http://www.bls.gov/tus/lexiconnoex0315.pdf).\n\n* **Activity summary file**: The Activity summary file contains information about the total time each ATUS respondent spent doing each activity on the diary day. Because Activity codes have changed somewhat between 2003 and 2015, this file uses activity codes that appear in the [2003-2015 ATUS Coding Lexicon (PDF)](http://www.bls.gov/tus/lexiconnoex0315.pdf).\n\n* **Who file**: The Who file includes codes that indicate who was present during each activity.\n\n* **CPS 2003-2015 file**: The ATUS-CPS file contains information about each household member of all individuals selected to participate in ATUS. The information on the ATUS-CPS file was collected 2 to 5 months before the ATUS interview.\n\n* **Eldercare Roster file**: The ATUS Eldercare Roster file contains information about people for whom the respondent provided care. Eldercare data have been collected since 2011.\n\n* **Replicate weights file**: The Replicate weights file contains miscellaneous ATUS weights.\n\nThe ATUS interview data dictionary can be found [here](http://www.bls.gov/tus/atusintcodebk0315.pdf).\n\nThe ATUS Current Population Survey (CPS) data dictionary can be found [here](http://www.bls.gov/tus/atuscpscodebk0315.pdf).\n\nThe ATUS occupation and industry codes can be found [here](http://www.bls.gov/tus/iocodes.htm).\n\nThe ATUS activity lexicon can be found [here](http://www.bls.gov/tus/lexiconnoex0315.pdf).\n\n## Acknowledgements\n\nThe original datasets can be found [here](http://www.bls.gov/tus/datafiles_0315.htm).\n\n## Inspiration\n\nHow do daily activities differ by:\n\n* labor force status\n\n* income\n\n* household composition\n\n* geographical region\n\n* disability status'","b""['demographics', 'time series', 'utility', 'large', 'featured']""",https://www.kaggle.com/bls/american-time-use-survey
b'Pre-trained Word Vectors for Spanish',b'Over 1 million 300-dimensional word vectors for Spanish',"b'### Context:\nWord vectors, also called word embeddings, are a multi-dimensional representation of words based on which words are used in similar contexts. They can capture some elements of words\xe2\x80\x99 meanings. For example, documents which use a lot of words that are clustered together in a vector space representation are more likely to be on similar topics.\n\nWord vectors are very computationally intensive to train, and the vectors themselves will vary based on the documents or corpora they are trained on. For these reasons, it is often convenient to use word vectors which have been pre-trained rather than training them from scratch for each project.\n\n### Content: \nThis dataset contains 1,000,653 word embeddings of dimension 300 trained on the [Spanish Billion Words Corpus](http://crscardellino.me/SBWCE/). These embeddings were trained using [word2vec](https://code.google.com/archive/p/word2vec/). \n###Parameters for Embeddings Training:\nWord embeddings were trained using the following parameters:\n\n* The selected algorithm was the skip-gram model with negative-sampling.\n* The minimum word frequency was 5.\n* The amount of \xe2\x80\x9cnoise words\xe2\x80\x9d for the negative sampling was 20.\n* The 273 most common words were downsampled.\n* The dimension of the final word embedding was 300.\n\nThe original corpus had the following amount of data:\n\n* A total of 1420665810 raw words.\n* A total of 46925295 sentences.\n* A total of 3817833 unique tokens.\n\nAfter the skip-gram model was applied, filtering of words with less than 5 occurrences as well as the downsample of the 273 most common words, the following values were obtained:\n\n* A total of 771508817 raw words.\n* A total of 1000653 unique tokens.\n\n### Acknowledgements: \n\nThis dataset was created by Cristian Cardellino. If you use this dataset in your work, please reference the following citation: \n\nCristian Cardellino: Spanish Billion Words Corpus and Embeddings (March 2016), http://crscardellino.me/SBWCE/\n\n### Inspiration: \nWord vector representations are widely-used in natural language processing tasks.\n\n* Can you improve an existing part of speech tagger in Spanish by using word vectors? You might find it helpful to check out [this paper](http://www.aclweb.org/website/old_anthology/N/N15/N15-1144.pdf).\n* Can you use these word embeddings to improve existing parsers for Spanish? [This paper](http://www.aclweb.org/anthology/P14-2133_) outlines some approaches for this.\n* There has been quite a bit of work recently on how word embeddings might encode implicit gender bias. For example, [this paper](http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf) show how embeddings can capture stereyoptyes about career fields and gender. However, [this recent paper](http://anacode.de/wordpress/wp-content/uploads/2017/06/mccurdy_grammatical_gender.pdf) suggests that for languages with grammatical gender (like Spanish), grammatical gender is more influential than gender bias. Do these word embeddings support that claim?\n\n### You may also like: \n\n* [**GloVe: Global Vectors for Word Representation**. Pre-trained English word vectors from Wikipedia 2014 + Gigaword 5](https://www.kaggle.com/rtatman/glove-global-vectors-for-word-representation)\n* [**20 Million Word Spanish Corpus**. The Spanish Language portion of the Wikicorpus (v 1.0)](https://www.kaggle.com/rtatman/120-million-word-spanish-corpus)'","b""['linguistics', 'languages', 'artificial intelligence', 'large', 'featured']""",https://www.kaggle.com/rtatman/pretrained-word-vectors-for-spanish
b'Classification of Handwritten Letters',b'Images of Russian Letters',"b'## History\nI made the database from my own photos of Russian lowercase letters written by hand. \n\n## Content\n### The GitHub repository with examples\n[GitHub][1] \n\n### The main dataset (`letters.zip`)\n- 1650 (50x33) color images (32x32x3) with 33 letters and the file with labels `letters.txt`. \n- Photo files are in the `.png` format and the labels are integers and values.\n- Additional `letters.csv` file.\n- The file `LetterColorImages.h5` consists of preprocessing images of this set: image tensors and targets (labels).\n\n### The additional dataset (`letters2.zip`)\n- 5940 (180x33) color images (32x32x3) with 33 letters and the file with labels `letters2.txt`. \n- Photo files are in the `.png` format and the labels are integers and values.\n- Additional `letters2.csv` file.\n- The file `LetterColorImages2.h5` consists of preprocessing images of this set: image tensors and targets (labels).\n\n### The additional dataset (`letters3.zip`)\n- 6600 (200x33) color images (32x32x3) with 33 letters and the file with labels `letters2.txt`. \n- Photo files are in the `.png` format and the labels are integers and values.\n- Additional `letters3.csv` file.\n- The file `LetterColorImages3.h5` consists of preprocessing images of this set: image tensors and targets (labels).\n\n#### Letter Symbols =&gt; Letter Labels\n\xd0\xb0=&gt;1, \xd0\xb1=&gt;2, \xd0\xb2=&gt;3, \xd0\xb3=&gt;4, \xd0\xb4=&gt;5, \xd0\xb5=&gt;6, \xd1\x91=&gt;7, \xd0\xb6=&gt;8, \xd0\xb7=&gt;9, \xd0\xb8=&gt;10,\n\xd0\xb9=&gt;11, \xd0\xba=&gt;12, \xd0\xbb=&gt;13, \xd0\xbc=&gt;14, \xd0\xbd=&gt;15, \xd0\xbe=&gt;16, \xd0\xbf=&gt;17, \xd1\x80=&gt;18, \xd1\x81=&gt;19, \xd1\x82=&gt;20,\n\xd1\x83=&gt;21, \xd1\x84=&gt;22, \xd1\x85=&gt;23, \xd1\x86=&gt;24, \xd1\x87=&gt;25, \xd1\x88=&gt;26, \xd1\x89=&gt;27, \xd1\x8a=&gt;28, \xd1\x8b=&gt;29, \xd1\x8c=&gt;30,\n\xd1\x8d=&gt;31, \xd1\x8e=&gt;32, \xd1\x8f=&gt;33\n\n#### Image Backgrounds =&gt; Background Labels\nstriped=&gt;0, gridded=&gt;1, no background=&gt;2, graph paper=&gt;3\n\n## Acknowledgements\nAs an owner of this database, I have published it for absolutely free using by any site visitor.\n\n## Usage\nClassification, image generation, etc. in a case of handwritten letters with a small number of images are useful exercises.\n\n## Improvement\nThere are lots of ways for increasing this set and the machine learning algorithms applying to it. \n - For example: add the same images but written by other person or add capital letters. \n\n\n  [1]: https://github.com/OlgaBelitskaya/deep_learning_projects/tree/master/DL_PP2'","b""['deep learning', 'image data', 'multiclass classification', 'languages', 'photography', 'medium', 'featured']""",https://www.kaggle.com/olgabelitskaya/classification-of-handwritten-letters
b'VGG-13',b'VGG-13 Pre-trained Model for PyTorch',"b'# VGG-13\n\n---\n\n## Very Deep Convolutional Networks for Large-Scale Image Recognition<br>\nIn this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.\n<br>\n\n**Authors: Karen Simonyan, Andrew Zisserman**<br>\n**https://arxiv.org/abs/1409.1556**\n\n---\n\n#VGG Architectures<br>\n![VGG Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/uLXrKxe.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/vgg13
b'Global Aquaculture Imports and Exports',"b'Quantity & Value, Years 2000 - 2015 comparing across regions and countries'","b""### Context\nFish and shrimp play a crucial part as our protein source, as our GDP increase, so does our choice, from meat to fish.\nTherefore the landscape are moving from fishing towards farming.\n\nHow's the aquaculture and fisheries industry developed over time across region, further narrowing down to specific region and country to pinpoint opportunity\n\n### Content\nThis database contains statistics on the annual production of fishery commodities and imports and exports of fishery commodities by country and commodities in terms of volume and value from 2000 to 2015\n\nRegion : Africa, Americas, Asia, Europe, Oceania<br>\nTime: 2000-2015<br>\nImport Export in Quantity(t)<br>\nImport Export in Value(USD '000)<br>\n<br>\ndata from fao.org\n\n### Acknowledgements\nFood and Agriculture Organization of the United Nations\n(Fisheries andAquaculture Department)\n\n### Inspiration\n1. Joined an aquaculture company, take the initiative to quantify industry landscape to support c-suite and sales department in planning to expand Asia market, pinpointed opportunity and route-to-market\n2. Had done all research in excel, trying on python\n3. Signed NDA, therefore insights is limited to basic""","b""['business', 'small', 'featured']""",https://www.kaggle.com/zhengtzer/global-fisheries-aquaculture-department
"b'2,2k+ Scotch Whisky Reviews'","b'Dataset Includes 2,2k+ Scotch Whisky Reviews'",b'### Context\n\nDataset was scraped from [Whisky Advocate][1]. You can take a look at scraping script [here][2].\n\n\n### Content\n\n - name: Name of whisky bottle\n - category: Whisky category\n - review.point: Point marked by each reviewers\n - price: Price of each bottle\n - currency: Unit of price\n - description: Descriptions of reviews\n\n### Acknowledgements\n\nOriginal database is from [Whisky Advocate][3].\n\n\n### Inspiration\n\nCan you find characteristics of each category of whisky?\n\n  [1]: http://whiskyadvocate.com/\n  [2]: https://github.com/koki25ando/Whisky-Data-Scraping/blob/master/whisky.R\n  [3]: http://whiskyadvocate.com/',"b""['food and drink', 'alcohol', 'small', 'featured']""",https://www.kaggle.com/koki25ando/22000-scotch-whisky-reviews
b'Seattle Broadband Speed Test',b'From City of Seattle Open Data',"b""### Content  \n\nBroadband Speed Test  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/qE1jxYXiwOA) by [Petr Sevcovic](https://unsplash.com/@sevcovic23) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-broadband-speed-test
b'MIAS Mammography',b'Looking for breast cancer',"b'\n### Content\n\nThe data is images and labels / annotations for mammography scans. More about the database can be found at [MIAS][1]. The \'Preview\' kernel shows how the Info.txt and PGM files can be parsed correctly.\n\n\n### Labels\n\n- 1st column:\nMIAS database reference number.\n- 2nd column:\nCharacter of background tissue:\n  F  Fatty\n  G  Fatty-glandular\n  D  Dense-glandular\n  \n- 3rd column:\nClass of abnormality present:\n  CALC  Calcification\n  CIRC  Well-defined/circumscribed masses\n  SPIC  Spiculated masses\n  MISC  Other, ill-defined masses\n  ARCH  Architectural distortion\n  ASYM  Asymmetry\n  NORM  Normal\n  \n- 4th column:\nSeverity of abnormality;\n  B  Benign\n  M  Malignant\n  \n- 5th, 6th columns:\nx,y image-coordinates of centre of abnormality.\n- 7th column:\nApproximate radius (in pixels) of a circle enclosing the abnormality.\nThere are also several things you should note:\n\nThe list is arranged in pairs of films, where each pair represents the left (even filename numbers) and right mammograms (odd filename numbers) of a single patient.\nThe size of all the images is 1024 pixels x 1024 pixels. The images have been centered in the matrix.\nWhen calcifications are present, centre locations and radii apply to clusters rather than individual calcifications. Coordinate system origin is the bottom-left corner.\nIn some cases calcifications are widely distributed throughout the image rather than concentrated at a single site. In these cases centre locations and radii are inappropriate and have been omitted.\n\n\n### Acknowledgements/LICENCE\n\n MAMMOGRAPHIC IMAGE ANALYSIS SOCIETY\n                     MiniMammographic Database\n\n                       LICENCE AGREEMENT\n\n\nThis is a legal agreement between you, the end user and the\nMammographic Image Analysis Society (""MIAS""). Upon installing the \nMiniMammographic database (the ""DATABASE"") on your system you are\nagreeing to be bound by the terms of this Agreement.\n\n1. GRANT OF LICENCE\nMIAS grants you the right to use the DATABASE, for research purposes \nONLY. For this purpose, you may edit, format, or otherwise modify the\nDATABASE provided that the unmodified portions of the DATABASE included\nin a modified work shall remain subject to the terms of this Agreement.\n\n2. COPYRIGHT\nThe DATABASE is owned by MIAS and is protected by United Kingdom\ncopyright laws, international treaty provisions and all other\napplicable national laws. Therefore you must treat the DATABASE\nlike any other copyrighted material. If the DATABASE is used in any\npublications then reference must be made to the DATABASE within that\npublication.\n\n3. OTHER RESTRICTIONS\nYou may not rent, lease or sell the DATABASE.\n\n4. LIABILITY\nTo the maximum extent permitted by applicable law, MIAS shall not\nbe liable for damages, other than death or personal injury,\nwhatsoever (including without limitation, damages for negligence,\nloss of business, profits, business interruption, loss of\nbusiness information, or other pecuniary loss) arising out of the\nuse of or inability to use this DATABASE, even if MIAS has been\nadvised of the possibility of such damages. In any case, MIAS\'s\nentire liability under this Agreement shall be limited to the\namount actually paid by you or your assignor, as the case may be,\nfor the DATABASE.\n\n\n### Inspiration\n\nAutomatically finding lesions would be a very helpful tool for physicians, also predicting malignancy based on a found/marked lesion\n\n\n  [1]: http://peipa.essex.ac.uk/info/mias.html'","b""['healthcare', 'health', 'medium', 'featured']""",https://www.kaggle.com/kmader/mias-mammography
b'FCC Net Neutrality Comments (4/2017 - 10/2017)',b'FCC Proceeding #17-108 (text and dupe counts only)',"b""### Recent Updates (11-27-2017)\n\nI've posted a [clustered full dataset](https://www.kaggle.com/jeffkao/fcc-net-neutrality-comments-clustered). This might give you a boost on the work you're doing with the data!\n\nI've posted a [vectorized subset w/ 100,000 data points](https://www.kaggle.com/jeffkao/proc_17_108_level0_unclustered_sample_vectorized/) sampled _after_ manual reduction of the dataset after EDA.\n\n### Context\n\nCleaned data used in researching public comments for FCC Proceeding 17-108 (Net Neutrality Repeal).\n\nData collected from the beginning of submissions (April 2017) until Oct 27th, 2017. The long-running comment scraping script suffered from a couple of disconnections and I estimate that I lost ~50,000 comments because of it. Even though the Net Neutrality Public Comment Period ended on August 30, 2017, the FCC ECFS system continued to take comments afterward, which were included in the analysis.\n\nI did a write-up on the results here:\nhttps://hackernoon.com/more-than-a-million-pro-repeal-net-neutrality-comments-were-likely-faked-e9f0e3ed36a6\n\n### Content\n\nDocument id, Text of the post, and number of duplicates found for that text was all that was necessary to generate the results. Text is raw &amp; unchanged from the original. I'm working hard to get online a fuller set of data w/ other important metadata fields.\n\nCleaned-up notebooks used are available on [github](https://github.com/j2kao/fcc_nn_research). I am posting the notebook for Exploratory Data Analysis first, and will include others as they are cleaned up. Please share with the rest of us what interesting insights you glean from the data! Tweet at me [@jeffykao](https://twitter.com/jeffykao).""","b""['internet', 'linguistics', 'politics', 'medium', 'featured']""",https://www.kaggle.com/jeffkao/proc_17_108_unique_comments_text_dupe_count
b'World Cities Database',b'A database of coordinates for countries and cities',"b'### Context\n\nThis dataset is meant to be used with other datasets that have features like country and city but no latitude/longitude. It is simply a list of cities in the world. Being able to put cities on a map will help people tell their stories more effectively. Another way to think about it is that you can use this make more pretty graphs!\n\n### Content\n\nFields: \n\n- city\n- region\n- country \n- population\n- latitude \n- longitude\n\n### Acknowledgements\nThese data come from Maxmind.com and have not been altered. The original source can be found by clicking [here][1]\n\nAdditionally, the Maxmind sharing license has been included.\n\n### Inspiration\n I wanted to analyze a dataset and make a map, but I was only given a city name without any latitude or longotude coordinates. I found this dataset very helpful and I hoe you do too!\n\n  [1]: https://www.maxmind.com/en/free-world-cities-database'","b""['world', 'countries', 'cities', 'medium', 'featured']""",https://www.kaggle.com/max-mind/world-cities-database
b'All the news',"b'143,000 articles from 15 American publications'","b""### Context\n\nI wanted to see how articles clustered together if the articles were rendered into document-term matrices---would there be greater affinity among political affiliations, or medium, subject matter, etc. The data was scraped using BeautifulSoup and stored in Sqlite, but I've chopped it up into three separate CSVs here, because the entire Sqlite database came out to about 1.2 gb, beyond Kaggle's max.\n\nThe publications include the New York Times, Breitbart, CNN, Business Insider, the Atlantic, Fox News, Talking Points Memo, Buzzfeed News, National Review, New York Post, the Guardian, NPR, Reuters, Vox, and the Washington Post. Sampling wasn't quite scientific; I chose publications based on my familiarity of the domain and tried to get a range of political alignments, as well as a mix of print and digital publications. By count, the publications break down accordingly:\n\nThe data primarily falls between the years of 2016 and July 2017, although there is a not-insignificant number of articles from 2015, and a possibly insignificant number from before then.\n\n### Content\n\n**articles1.csv** - 50,000 news articles (Articles 1-50,000)\n\n**articles2.csv** - 49,999 news articles (Articles 50,001-100,00)\n\n**articles3.csv** - Articles 100,001+\n\n\n\n### Acknowledgements\n\nThanks mostly go to the maesters of Stack Overflow. \n\nFor each publication, I used archive.org to grab the past year-and-a-half of either home-page headlines or RSS feeds and ran those links through the scraper. That is, the articles are not the product of scraping an entire site, but rather their more prominently placed articles. For example, CNN's articles from 5/6/16 were what appeared on the homepage of CNN.com proper, not everything within the CNN.com domain. Vox's articles from 5/6/16 were everything that appeared in the Vox RSS reader. on 5/6/16, and so on. RSS readers are a breeze to scrape, and so I used them when possible, but not every publication uses them or makes them easy to find.\n\n\n![enter image description here][1]\n\nIt's not entirely even---this was something of a collect-it-all approach, and some sites are more prolific than others, and some have data that maintains integrity after scraping more easily than others.\n\n  [1]: http://i.imgur.com/QDPtuEv.png\n\n### Inspiration\n\nSentiment analysis and topic modeling.\n""","b""['journalism', 'medium', 'featured']""",https://www.kaggle.com/snapcrack/all-the-news
b'OpenAddresses - U.S. South',b'Addresses and geo locations for the U.S. South',"b""### Context\n\nOpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates, street names, house numbers and postal codes. \n\n### Content\n\nThis dataset contains one datafile for each state in the U.S. South region (although some are arguably not in the South).\n\nStates included in this dataset:\n\n* Alabama - al.csv\n* Arkansas - ar.csv\n* Washington D.C. - dc.csv\n* Delaware - de.csv\n* Florida - fl.csv\n* Georgia - ga.csv\n* Kentucky - ky.csv\n* Louisiana - la.csv\n* Maryland - md.csv\n* Mississippi - ms.csv\n* North Carolina - nc.csv\n* Oklahoma - ok.csv\n* South carolina - sc.csv\n* Tennessee - tn.csv\n* Texas - tx.csv\n* Virginia - va.csv\n* West Virginia - wv.csv\n\n\nField descriptions:\n\n* LON - Longitude\n* LAT - Latitude\n* NUMBER - Street number\n* STREET - Street name\n* UNIT - Unit or apartment number\n* CITY - City name\n* DISTRICT - ?\n* REGION - ?\n* POSTCODE - Postcode or zipcode\n* ID - ?\n* HASH - ?\n\n\n### Acknowledgements\n\nData collected around 2017-07-25 by OpenAddresses (http://openaddresses.io).\n\nAddress data is essential infrastructure. Street names, house numbers and\npostal codes, when combined with geographic coordinates, are the hub that\nconnects digital to physical places.\n\n\nData licenses can be found in LICENSE.txt.\n\nData source information can be found at\nhttps://github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources\n\n\n### Inspiration\n\nUse this dataset to create maps in conjunction with other datasets for crime or weather""","b""['large', 'featured']""",https://www.kaggle.com/openaddresses/openaddresses-us-south
b'Insightful & Vast USA Statistics',"b'Income, Age, Marriage, Mortgage, Home Equity Loan & Demographics'","b'# Very Important\n\n - Check out the new must-see kernel for this dataset [Click Here][1]\n - Make Sure to upvote for more datasets and kernel :D\n\n\n### Overview:\nExplore the dataset and potentially gain valuable insight into your data science project through interesting features. The dataset was developed for a portfolio optimization graduate project I was working on. The goal was to the monetize risk of company deleveraging by associated with changes in economic data. Applications of the dataset may include. To see the data in action visit my analytics page. [Analytics Page & Dashboard][2] and to access all 295,000+ records [click here][3].\n\n - Mortgage-Backed Securities\n - Geographic Business Investment\n - Real Estate Analysis\n\nFor any questions, you may reach us at  research_development@goldenoakresearch.com. For immediate assistance, you may reach me on at 585-626-2965. *Please Note: the number is my personal number and email is preferred*\n\n### Statistical Themes:\n*Note: in total there are 75 fields the following are just themes the fields fall under*\nHome Owner Costs: Sum of utilities, property taxes.\n\n - **Second Mortgage:** Households with a second mortgage statistics.\n - **Home Equity Loan:** Households with a Home equity Loan statistics.\n - **Debt:** Households with any type of debt statistics.\n - **Mortgage Costs:** Statistics regarding mortgage payments, home equity loans, utilities and property taxes\n - **Home Owner Costs:** Sum of utilities, property taxes statistics\n - **Gross Rent:** Contract rent plus the estimated average monthly cost of utility features\n - **Gross Rent as Percent of Income** Gross rent as the percent of income very interesting\n - **High school Graduation:** High school graduation statistics.\n - **Population Demographics:** Population demographic statistics.\n - **Age Demographics:** Age demographic statistics.\n - **Household Income:** Total income of people residing in the household.\n - **Family Income:** Total income of people related to the householder.\n\n\n\n### Sources, if you wish to get the data your self :) \n2012-2016 ACS 5-Year Documentation was provided by the U.S. Census Reports. Retrieved May 2, 2018, from \n\n - [Census estimate, error, and location data][4]\n - [Census location information][5]\n\n\n###Access All 325,258 Location of Our Most Complete Database Ever:\n**Providing you the potential to monetize risk and optimize your investment portfolio through quality economic features at unbeatable price**.   *Access all 295,000+ records on an incredibly small scale, see links below for more details*:\n\n - **Full Dataset**: [View Full Dataset][7]\n - **Real Estate Research**:  [View Research][8]\n\n\n  [1]: https://www.kaggle.com/alexgeiger/financial-hedging-eda-factor-analysis\n  [2]: https://www.goldenoakresearch.com/analytics\n  [3]: https://www.goldenoakresearch.com/shop\n  [4]: https://www2.census.gov/programs-surveys/acs/summary_file/2016/data/5_year_by_state/\n  [5]: https://www2.census.gov/geo/docs/maps-data/data/gazetteer/2016_Gazetteer/\n  [6]: https://www.ed.gov/\n  [7]: https://www.goldenoakresearch.com/shop\n  [8]: https://www.goldenoakresearch.com/hedging-real-estate-research'","b""['finance', 'economics', 'demographics', 'income', 'medium', 'featured']""",https://www.kaggle.com/goldenoakresearch/us-acs-mortgage-equity-loans-rent-statistics
b'Style Color Images',b'Brand and Product Recognition',"b'# History\nI have made the database of photos sorted by products and brands. Screenshots were performed only on official brand websites.\n\n# Content\nThe main dataset (style.zip) is 2184 color images (150x150x3) with 7 brands and 10 products, and the file with labels `style.csv`.\nPhoto files are in the `.png` format and the labels are integers and values.\n\nThe file `StyleColorImages.h5` consists of preprocessing images of this set: image tensors and targets (labels).\n\n\n# Acknowledgements\nI have published the data for absolutely free using by any site visitor. But this database contains the names of famous brands, so it can not be used for commercial purposes.\n\n# Usage\nClassification, image recognition and colorizing, etc. in a case of a small number of images are useful exercises.\nThe main question we can try to answer with the help of the data is whether the algorithms can recognize the unique design style well enough. To facilitate the task, I chose the most easily recognizable brands with a bright style.\n\n[The example of usage](https://github.com/OlgaBelitskaya/deep_learning_projects/blob/master/DL_PP4/DL_PP4_Solutions.ipynb)\n\n# Improvement\nThere are lots of ways for improving this set and the machine learning algorithms applying to it. At first, it needs to increase the number of photos.'","b""['deep learning', 'image data', 'multiclass classification', 'photography', 'clothing', 'medium', 'featured']""",https://www.kaggle.com/olgabelitskaya/style-color-images
b'Rainfall in India',b'Sub-division wise monthly data for 115 years from 1901-2015.',b'**Connect/Follow me on [LinkedIn](http://link.rajanand.org/linkedin) for more updates on interesting dataset like this. Thanks.**\n\n### Context\nThis data set contains monthly rainfall detail of 36 meteorological sub-divisions of India.\n\n### Content\nTime Period: 1901 - 2015\n\nGranularity: Monthly\n\nLocation: 36 meteorological sub-divisions in India \n\nRainfall unit: mm \n\n### Acknowledgements\n\n[India Meteorological Department(IMD)](http://www.imd.gov.in) Govt. of India has shared this [dataset](https://data.gov.in/catalog/rainfall-india) \nunder [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).\n\n',"b""['weather', 'india', 'small', 'featured']""",https://www.kaggle.com/rajanand/rainfall-in-india
b'TED Talks',"b'Data about TED Talks on the TED.com website until September 21st, 2017'","b""### Context\nThese datasets contain information about all audio-video recordings of TED Talks uploaded to the official TED.com website until September 21st, 2017. The TED main dataset contains information about all talks including number of views, number of comments, descriptions, speakers and titles. The TED transcripts dataset contains the transcripts for all talks available on TED.com.\n\n### Content \n\nThere are two CSV files. \n\n**ted_main.csv** -  Contains data on actual TED Talk metadata and TED Talk speakers.<br>\n**transcripts.csv** - Contains transcript and URL information for TED Talks<br>\n\n\n### Acknowledgements\nThe data has been scraped from the official TED Website and is available under the Creative Commons License.\n\n### Inspiration\n\nI've always been fascinated by TED Talks and the immense diversity of content that it provides for free. I was also thoroughly inspired by a TED Talk that visually explored TED Talks stats and I was motivated to do the same thing, albeit on a much less grander scale.\n\nSome of the questions that can be answered with this dataset:\n1. How is each TED Talk related to every other TED Talk?\n2. Which are the most viewed and most favorited Talks of all time? Are they mostly the same? What does this tell us?\n3. What kind of topics attract the maximum discussion and debate (in the form of comments)?\n4. Which months are most popular among TED and TEDx chapters?\n5. Which themes are most popular amongst TEDsters?""","b""['internet', 'linguistics', 'society', 'digital media', 'medium', 'featured']""",https://www.kaggle.com/rounakbanik/ted-talks
b'Financial Distress Prediction',b'Bankruptcy Prediction',"b'### Context\n\nThis data set deals with the financial distress prediction for a sample of companies.  \n\n\n### Content\n\n**First column**: **Company** represents sample companies.\n\n**Second column**: **Time** shows different time periods that data belongs to. Time series length varies between **1** to **14** for each company.\n\n**Third column**: The target variable is denoted by ""**Financial Distress**"" if it is greater than -0.50 the company should be considered as **healthy** (**0**). Otherwise, it would be regarded as **financially distressed** (**1**). \n\n**Fourth column to the last column**: The features denoted by **x1** to **x83**, are some financial and non-financial characteristics of the sampled companies. These features belong to the previous time period, which should be used to predict whether the company will be financially distressed or not (classification). Feature  **x80**  is a **categorical variable**.\n\nFor example, company 1 is financially distressed at time 4 but company 2 is still healthy at time 14. \n\nThis data set is *imbalanced* (there are 136 financially distressed companies against 286 healthy ones i.e., 136 firm-year observations are financially distressed while 3546 firm-year observations are healthy) and *skewed*, so **f-score** should be employed as the performance evaluation criterion. \n\nIt should be noted that **30%** of this data set should be randomly assigned as **hold-out test set** so the remaining **70%** is used for feature selection and model selection i.e., **train set**.\n\nNote: \n1- This data could be viewed as a classification problem.\n2- This data could also be considered as a regression problem and then the result will be converted into a classification.\n3- This data could be regarded as a multivariate time series classification.\n\n\n### Inspiration\n\n\nWhich features are most indicative of financial distress?\n\nWhat types of machine learning models perform best on this dataset?\n'","b""['finance', 'machine learning', 'small', 'featured']""",https://www.kaggle.com/shebrahimi/financial-distress
b'BLS All Employees by Occupation/Industry',b'Explore Time Series from the BLS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Bureau of Labor Statistics](http://www.bls.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according to the frequency that the data updates. Explore the OECD using Kaggle and all of the data sources available through the BLS [organization page](https://www.kaggle.com/bls)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/bls/bls-all-employees-by-occupation-industry
b'Code of Federal Regulations',b'XML annotated US regulations as of mid 2017',"b'The Code of Federal Regulations (CFR) is the codification of the general and permanent rules and regulations (sometimes called administrative law) published in the Federal Register by the executive departments and agencies of the federal government of the United States. \n\nThe 50 subject matter titles contain one or more individual volumes, which are updated once each calendar year, on a staggered basis. The annual update cycle is as follows: titles 1-16 are revised as of January 1; titles 17-27 are revised as of April 1; titles 28-41 are revised as of July 1; and titles 42-50 are revised as of October 1. Each title is divided into chapters, which usually bear the name of the issuing agency. Each chapter is further subdivided into parts that cover specific regulatory areas. Large parts may be subdivided into subparts. All parts are organized in sections, and most citations to the CFR refer to material at the section level.\n\n\nThe CFR is published in multiple formats by the US Government Publishing Office. You can find the latest version of the XML format here: http://www.gpo.gov/fdsys/bulkdata/CFR.'","b""['government', 'law', 'medium', 'featured']""",https://www.kaggle.com/us-gpo/code-of-federal-regulations
b'Japanese-English Bilingual Corpus',"b""Japanese-English Bilingual Corpus of Wikipedia's Kyoto Articles""","b'### Background\n\nNLP is a hot topic currently! \nTeam AI really want\'s to leverage the NLP research and this an attempt for all the NLP researchers to explore exciting insights from bilingual data\n\nThe Japanese-English Bilingual Corpus of Wikipedia\'s Kyoto Articles\xe2\x80\x9d aims mainly at supporting research and development relevant to high-performance multilingual machine translation, information extraction, and other language processing technologies. \n\n\n### Unique Features\n\nA precise and large-scale corpus containing about 500,000 pairs of manually-translated sentences.\nCan be exploited for research and development of high-performance multilingual machine translation, information extraction, and so on.\n\nThe three-step translation process (primary translation -> secondary translation to improve fluency -> final check for technical terms) has been clearly recorded.\nEnables observation of how translations have been elaborated so it can be applied for uses such as research and development relevant to translation aids and error analysis of human translation.\n\nTranslated articles concern Kyoto and other topics such as traditional Japanese culture, religion, and history.\nCan also be utilized for tourist information translation or to create glossaries for travel guides.\n\nThe Japanese-English Bilingual Kyoto Lexicon is also available. This lexicon was created by extracting the Japanese-English word pairs from this corpus.\n\n\n# Sample\n\nOne Wikipedia article is stored as one XML file in this corpus, and the corpus contains 14,111 files in total.\n\nThe following is a short quotation from a corpus file titled \xe2\x80\x9cRyoan-ji Temple\xe2\x80\x9d.\nEach tag has different implications. For example:\n\n`<j>Original Japanese sentence<j>`\n`<e type=""trans"" ver=""1"">Primary translation</e>`\n`<e type=""trans"" ver=""2"">Secondary translation</e>`\n`<e type=""check"" ver=""1"">Final translation</e>`\n`<cmt>Comment added by translators</cmt>`\n\n# Categories\n\nThe files have been divided into 15 categories: school, railway, family, building, Shinto, person name, geographical name, culture, road, Buddhism, literature, title, history, shrines and temples, and emperor (Click the link to view a sample file for each category).\n\n# Github \nhttps://github.com/venali/BilingualCorpus\n\nExplains how to load the corpus\n### Acknowledgements\n\n The National Institute of Information and Communications Technology (NICT) has created this corpus by manually translating Japanese Wikipedia articles (related to Kyoto) into English.\n\n\n### Licence\nUse and/or redistribution of the Japanese-English Bilingual Corpus of Wikipedia\'s Kyoto Articles and the Japanese-English Bilingual Kyoto Lexicon is permitted under the conditions of Creative Commons Attribution-Share-Alike License 3.0. Details can be found at http://creativecommons.org/licenses/by-sa/3.0/.\n\n### Link to web\nhttps://alaginrc.nict.go.jp/WikiCorpus/index_E.html'","b""['linguistics', 'languages', 'artificial intelligence', 'medium', 'featured']""",https://www.kaggle.com/team-ai/japaneseenglish-bilingual-corpus
b'Meetups data from meetup.com',b'Organized data for various meetup.com entities along with relational schema',"b""### Summary\n\xe2\x80\x9cMeetup is a social networking website that aims to brings people together to do, explore, teach and learn the things\nthat help them come alive.\xe2\x80\x9d\n\nMeetup allows members to find and join groups unified by a common interest. As of 2017, there are 32 million users with\n280 thousand groups available across 182 countries.\n\nA member needs to be able to identify groups and activities which interest them the most to be able to use this platform\nto network effectively.\n\nThe aim of our team was to use this dataset to build a recommender system which will identify and suggest groups and activities to a member based on their interest and additional interests of similar members. Furthermore, a social network analysis was done to identify the relationship between groups and people.\n\n### Database EER diagram\n![EER diagram][1]\n\n### Data Collection Method\n* Data was collected using Meetup API.   \n* Python script was used to ping meetup API and collect responses as JSON objects.  \n* Logical chunks of data were exported and saved as csv files.  \n\n### Data Cleaning\n* Data is filtered to include only 3 cities' information (New York, San Francisco, Chicago).\n* Character encoding is normalized to ASCII characters across tables.\n\n### Example Visualizations\n![Popularity of topics][2]\n![Trends within top topics][3]\n![Popularity of Groups][4]\n![Venue locations][5]\n![Social network analysis using gephi][6]\n\n\n  [1]: https://i.imgur.com/LquWsuq.png\n  [2]: https://i.imgur.com/Nrzbgqa.png\n  [3]: https://i.imgur.com/OLfuQLm.png\n  [4]: https://i.imgur.com/O6VTATS.png\n  [5]: https://i.imgur.com/BM1rg0d.png\n  [6]: https://i.imgur.com/N7UtoyG.png""","b""['internet', 'social groups', 'hobbies', 'medium', 'featured']""",https://www.kaggle.com/sirpunch/meetups-data-from-meetupcom
b'AP (College Board) NY School Level Results',b'From New York City Open Data',"b'### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/3neouxmzIhg) by [Trust ""Tru"" Katsande](https://unsplash.com/@iamtru) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain'","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ap-college-board-ny-school-level-results
b'NYS Fish Stocking Lists (Actual): Beginning 2011',b'From New York State Open Data',"b""### Content  \n\nDEC stocks approximately 900,000 pounds of fish into more than 1,200 public streams, rivers, lakes and ponds across the state. Also included in the data are public stockings by Essex, Onondaga and Warren counties.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/iL-nzcmcnWc) by [Oziel Gomez](https://unsplash.com/@ozgomz) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'lakes', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-fish-stocking-lists-actual-beginning-2011
b'Carbon Monoxide Daily Summary',b'A summary of daily CO levels from 1990 to 2017',"b'###Context: \nCarbon Monoxide (CO) is a colorless, odorless gas that can be harmful when inhaled in large amounts. CO is released when something is burned. The greatest sources of CO to outdoor air are cars, trucks and other vehicles or machinery that burn fossil fuels. A variety of items in your home such as unvented kerosene and gas space heaters, leaking chimneys and furnaces, and gas stoves also release CO and can affect air quality indoors.\n\n###Content: \nThe daily summary file contains data for every monitor (sampled parameter) in the Environmental Protection Agency (EPA) database for each day. This file will contain a daily summary record that is:\n\n1. The aggregate of all sub-daily measurements taken at the monitor.\n2. The single sample value if the monitor takes a single, daily sample (e.g., there is only one sample with a 24-hour duration). In this case, the mean and max daily sample will have the same value.\n\n\nWithin the data file you will find these fields:\n1. State Code: The Federal Information Processing Standards (FIPS) code of the state in which the monitor resides.\n\n2. County Code: The FIPS code of the county in which the monitor resides.\n\n3. Site Num: A unique number within the county identifying the site.\n\n4. Parameter Code: The AQS code corresponding to the parameter measured by the monitor.\n\n5. POC: This is the \xe2\x80\x9cParameter Occurrence Code\xe2\x80\x9d used to distinguish different instruments that measure the same parameter at the same site.\n\n6. Latitude: The monitoring site\xe2\x80\x99s angular distance north of the equator measured in decimal degrees.\n\n7. Longitude: The monitoring site\xe2\x80\x99s angular distance east of the prime meridian measured in decimal degrees.\n\n8. Datum: The Datum associated with the Latitude and Longitude measures.\n\n9. Parameter Name: The name or description assigned in AQS to the parameter measured by the monitor. Parameters may be pollutants or non-pollutants.\n\n10. Sample Duration: The length of time that air passes through the monitoring device before it is analyzed (measured). So, it represents an averaging period in the atmosphere (for example, a 24-hour sample duration draws ambient air over a collection filter for 24 straight hours). For continuous monitors, it can represent an averaging time of many samples (for example, a 1-hour value may be the average of four one-minute samples collected during each quarter of the hour).\n\n11. Pollutant Standard: A description of the ambient air quality standard rules used to aggregate statistics. (See description at beginning of document.)\n\n12. Date Local: The calendar date for the summary. All daily summaries are for the local standard day (midnight to midnight) at the monitor.\n\n13. Units of Measure: The unit of measure for the parameter. QAD always returns data in the standard units for the parameter. Submitters are allowed to report data in any unit and EPA converts to a standard unit so that we may use the data in calculations.\n\n14. Event Type: Indicates whether data measured during exceptional events are included in the summary. A wildfire is an example of an exceptional event; it is something that affects air quality, but the local agency has no control over. No Events means no events occurred. Events Included means events occurred and the data from them is included in the summary. Events Excluded means that events occurred but data form them is excluded from the summary. Concurred Events Excluded means that events occurred but only EPA concurred exclusions are removed from the summary. If an event occurred for the parameter in question, the data will have multiple records for each monitor.\n\n15. Observation Count: The number of observations (samples) taken during the day.\n\n16. Observation Percent: The percent representing the number of observations taken with respect to the number scheduled to be taken during the day. This is only calculated for monitors where measurements are required (e.g., only certain parameters).\n\n17. Arithmetic Mean: The average (arithmetic mean) value for the day.\n\n18. 1st Max Value: The highest value for the day.\n\n19. 1st Max Hour: The hour (on a 24-hour clock) when the highest value for the day (the previous field) was taken.\n\n20. AQI: The Air Quality Index for the day for the pollutant, if applicable.\n\n21. Method Code:  An internal system code indicating the method (processes, equipment, and protocols) used in gathering and measuring the sample. The method name is in the next column.\n\n22. Method Name: A short description of the processes, equipment, and protocols used in gathering and measuring the sample.\n\n23. Local Site Name: The name of the site (if any) given by the State, local, or tribal air pollution control agency that operates it.\n\n24. Address: The approximate street address of the monitoring site.\n\n25. State Name: The name of the state where the monitoring site is located.\n\n26. County Name: The name of the county where the monitoring site is located.\n\n27. City Name: The name of the city where the monitoring site is located. This represents the legal incorporated boundaries of cities and not urban areas.\n\n28. CBSA Name: The name of the core bases statistical area (metropolitan area) where the monitoring site is located.\n\n29. Date of Last Change: The date the last time any numeric values in this record were updated in the AQS data system.\n\n\n\n###Acknowledgements:\nThese data come from the EPA and are current up to May 1, 2017. You can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the data on BigQuery, too: [https://cloud.google.com/bigquery/public-data/epa](https://cloud.google.com/bigquery/public-data/ep).\n\n###Inspiration: \nBreathing air with a high concentration of CO reduces the amount of oxygen that can be transported in the bloodstream to critical organs like the heart and brain. At very high levels, which are  possible indoors or in other enclosed environments, CO can cause dizziness, confusion, unconsciousness and death. Very high levels of CO are not likely to occur outdoors. However, when CO levels are elevated outdoors, they can be of particular concern for people with some types of heart disease. These people already have a reduced ability for getting oxygenated blood to their hearts in situations where the heart needs more oxygen than usual. They are especially vulnerable to the effects of CO when exercising or under increased stress. In these situations, short-term exposure to elevated CO may result in reduced oxygen to the heart accompanied by chest pain also known as angina.'","b""['environment', 'large', 'featured']""",https://www.kaggle.com/epa/carbon-monoxide
b'Cargo 2000 Dataset',b'A Transport and Logistics Case Study Data Set ',"b'### Transport and Logistics Case Study Data Set (Cargo 2000)\n\nCargo 2000 is an initiative of IATA, the International Air Transport Association (Cargo 2000 has been re-branded as Cargo iQ in 2016). It aims at delivering a new quality management system for the air cargo industry. Cargo 2000 allows for unprecedented transparency in the supply chain. Stakeholders involved in the transport process can share agreed Cargo 2000 messages, comprising transport planning, replanning and service completion events. Cargo 2000 is based on the following key principles: (1) Every shipment gets a plan (called a route map) describing predefined monitoring events. (2) Every service used during shipment is assigned a predefined milestone with a planned time of achievement. (3) Stakeholders receive alerts when a milestone has failed and notifications upon milestone completion, which include the effective time the milestone has been achieved.\n\n\n### Content\n\nThe case study data comprises tracking and tracing events from a forwarding company\xe2\x80\x99s Cargo 2000 system for a period of five months. From those Cargo 2000 messages, we reconstructed execution traces of 3,942 actual business process instances, comprising 7,932 transport legs and 56,082 service invocations. Each execution trace includes planned and effective durations (in minutes) for each of the services of the business process (introduced in Section II), as well as airport codes for the DEP (\xe2\x80\x9cdeparture\xe2\x80\x9d) and RCF (\xe2\x80\x9carrival\xe2\x80\x9d) services. Due to the fact that handling of transport documents along the business process differs based on whether the documents are paper-based or electronic, we focus on the flow of physical goods, as our data set did not allow us to discern the different document types.\n\nThe reconstruction process involved data sanitation and anonymization. We filtered overlapping and incomplete Cargo 2000 messages, removed canceled transports (i.e., deleted route maps), sanitized for exceptions from the C2K system (such as events occurring before route map creation) and homogenized the way information was represented in different message types. Finally, due to confidentiality reasons, message fields which might exhibit business critical or customer-related data (such as airway bill numbers, flight numbers and airport codes) have been eliminated or masked.\n\n\n![Transport and Logistics Process used in Case Study][1]\nEach of the transport legs involves the following physical transport services:<br>\n\xe2\x80\xa2 RCS: Check in freight at departure airline. Shipment is checked in and a receipt is produced at departure airport.<br>\n\xe2\x80\xa2 DEP: Confirm goods on board. Aircraft has departed with shipment on board.<br>\n\xe2\x80\xa2 RCF: Accept freight at arrival airline. Shipment is checked in according to the documents and stored at arrival warehouse.<br>\n\xe2\x80\xa2 DLV: Deliver freight. Receipt of shipment was signed at destination airport.<br>\n\n\n\n### Acknowledgements\n\nA. Metzger, P. Leitner, D. Ivanovic, E. Schmieders, R. Franklin, M. Carro, S. Dustdar, and K. Pohl, \xe2\x80\x9c Comparing and combining predictive business process monitoring techniques,\xe2\x80\x9d IEEE Trans. on Systems Man Cybernetics: Systems, 2015.<br>\n\nA. Metzger, R. Franklin, and Y. Engel, \xe2\x80\x9c Predictive monitoring of heterogeneous service-oriented business networks: The transport and logistics case,\xe2\x80\x9d in Service Research and Innovation Institute Global Conference (SRII 2012), ser. Conference Publishing Service (CPS), R. Badinelli, F. Bodendorf, S. Towers, S. Singhal, and M. Gupta, Eds. IEEE Computer Society, 2012.<br>\n\nZ. Feldmann, F. Fournier, R. Franklin, and A. Metzger, \xe2\x80\x9cIndustry article: Proactive event processing in action: A case study on the proactive management of transport processes,\xe2\x80\x9d in Proceedings of the Seventh ACM International Conference on Distributed Event-Based Systems, DEBS 2013, Arlington, Texas, USA, S. Chakravarthy, S. Urban, P. Pietzuch, E. Rundensteiner, and S. Dietrich, Eds. ACM, 2013.<br>\n\n\n  [1]: http://s-cube-network.eu/c2k-files/workflow_UML.png'","b""['road transport', 'shipping', 'small', 'featured']""",https://www.kaggle.com/crawford/cargo-2000-dataset
b'NYS Transportation Fuels Data',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/7rehTDIfR8o) by [Anthony Garand](https://unsplash.com/@garand) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-transportation-fuels-data
b'VGG-11',b'VGG-11 Pre-trained Model for PyTorch',"b'# VGG-11\n\n---\n\n## Very Deep Convolutional Networks for Large-Scale Image Recognition<br>\nIn this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.\n<br>\n\n**Authors: Karen Simonyan, Andrew Zisserman**<br>\n**https://arxiv.org/abs/1409.1556**\n\n---\n\n#VGG Architectures<br>\n![VGG Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/uLXrKxe.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/vgg11
b'Baccarat Shoes Dataset',b'A dataset of baccarat games simulation',"b'### Context\n\nBaccarat is a casino game where the player and the banker compete with each other.\nWith some complex drawing rules, the winner is the one who achieves the highest score. Ties are also possible.\nThe game is shown to be almost symmetric, with a small advantage towards the banker.\nIt is involved in much superstition and is played by many high rollers and asian players.\n\nWhat can you reveal from these shoes? Is there a pattern that can be followed? What are the distributions?\n\n### Content\n\nA dataset with 100000 baccarat shoes simulations. \nWe generate the game from an 8 deck shoe with a cut on 50 cards. \nFirst line represent the burn card and then the game is dealt until the cut card shows up. \nThe data format is JSON.\n\nEach card is represented as a 2 characters string. The first one represents the card rank: \n- \'2\'-\'9\' represents the integer rank. \n- \'0\' represents the \'10\'s\n- \'A\' for aces\n- \'J\' for Jack\n- \'Q\' for queen\n- \'K\' for king.\n\nThe second character represents the suits. The suit does not really matter in the game of baccarat, but it is interesting to have a standard deck. \n- \'H\' for hearts\n- \'C\' for clubs\n- \'D\' for diamonds\n- \'S\' for spades\n\nGiven that a Ten of Spades would be \'0S\' or a 5 of hearts would be \'5H\'.\n\n###Challenges\n\nBaccarat is designed to be a symmetric game, however, many players say that they can detect trends in the data that helps them to predict the game. Can you detect any trends on the data?\n\nThere is special bets called ""Dragon 7"" and the ""Panda 8"" in a game called EZ Baccarat. The Dragon 7 wins when the Banker beats the player with a total 7 obtained with a 3-card hand and it pays 40 to 1. On the other hand, Panda 8 wins when the Player beats the banker with total 8 with a 3-card hand and it pays 25 to 1. These bets are said to be prone to counting techniques, is that true?\n\nCan you come up with a counting system that works for this dataset?\n\nWhat are the distributions of player and banker over these shoes? What hands occur more frequently? What is the longest player/banker winning streak? How often this streak happens?\n\n### Acknowledgements\n\nPhoto by Gianni Zanato on Unsplash'","b""['card games', 'medium', 'featured']""",https://www.kaggle.com/victornascimento/baccarat-dataset
b'Industrial Safety and Health Analytics Database',b'Industrial labor accident data',"b'Context\n-------\nIt is not always easy to find databases from **real-world manufacturing plants** So, I would like to share this database with the community, which comes from **one of the biggest industry in Brazil and in the world**. \n\nThe primary reason why we are sharing this data is that there is an urgent need for companies to understand why employees still suffer some injuries/accidents in plants. Sometimes they also die in such environment. So hope the community help us to explore and take better/newer insights from this data. \n\nContent\n-------\n\nThe database is basically records of accidents from **12 different plants in 03 different countries** which every line in the data is an occurrence of an accident. \n\n - Columns description\n     - **Data**: timestamp or time/date information\n     - **Countries**: which country the accident occurred (anonymized)\n     - **Local**: the city where the manufacturing plant is located (anonymized)\n     - **Industry sector**: which sector the plant belongs to\n     - **Accident level**: from I to VI, it registers how severe was the accident (I means not severe but VI means very severe)\n     - **Potential Accident Level**: Depending on the Accident Level, the database also registers how severe the accident could have been (due to other factors involved in the accident)\n     - **Genre**: if the person is male of female\n     - **Employee or Third Party**: if the injured person is an employee or a third party\n     - **Critical Risk**: some description of the risk involved in the accident\n     - **Description**: Detailed description of how the accident happened.\n\nInspiration\n-----------\n\nWe believe that everyone should work on a **data for a good cause**, especially this one, which can help manufacturing plants to save people lives!'","b""['healthcare', 'statistical analysis', 'manufacturing', 'mining', 'survival analysis', 'small', 'featured']""",https://www.kaggle.com/ihmstefanini/industrial-safety-and-health-analytics-database
"b""Pokemon- Weedle's Cave""","b""Welcome to Weedle's cave""","b""**Welcome to Weedle's cave.** Will you be able to predict the outcome of future matches?\n\nTo do it you will have the pokemon characteristics and the results of previous combats.\n\nThree files are available. The first one contains the Pokemon characteristics (the first column being the id of the Pokemon). The second one contains information about previous combats. The first two columns contain the ids of the combatants and the third one the id of the winner.  **Important**: The Pokemon in the first columns attacks first.\n\nThe goal is to develop a Machine Learning model able to predict the result of future pokemon combats.\n\nIf you have any questions, please email:  t7pokemonchallenge@intelygenz.com\n\n### DISCLAIMER\nThe Pokemon characteristics come from the actual game but the battle data has been generated by a custom algorithm that doesn't take into account some of the game characteristics to simplify the dataset.\n""","b""['video games', 'popular culture', 'small', 'featured']""",https://www.kaggle.com/terminus7/pokemon-challenge
b'German Literature from DigBib.Org',b'Literary works in German (poem novels etc)',"b""### Context\nSince we have French poems in kaggle, https://www.kaggle.com/dmpierre/french-poets-database \nwhy not also have German ones? \n\n### Content\nInside the folder you will see subfolders, whose names are names of the authors. Inside each folder, there are text files with works title as filename.txt.\n \n### Acknowledgements\nAll data is from http://www.digbib.org/ \nPhoto by Victoria Kure-Wu on Unsplash\n\n### Inspiration\nNLP. Auto-generate German text in Goethe style?\nExtract pairs of rhymed words from Rilke's poems?""","b""['literature', 'poetry', 'small', 'featured']""",https://www.kaggle.com/jihyeseo/german-literature-from-digbiborg
b'USP Drug Classification',b'Medical drug code classes & metadata',"b'USP Drug Classifications.\n\nA USP Category is the broadest classification which provides a high level formulary structure designed to include all potential therapeutic agents for diseases and conditions. A USP Class is a more granular classification, occurring within a specific USP Category in the USP Drug Classifications, which provides for therapeutic or pharmacologic groupings of FDA approved medications, consistent with current U.S. healthcare practices and standards of care.\n\n **Data dictionary:** \n\n - https://github.com/Data4Democracy/drug-spending/blob/master/datadictionaries/usp_drug_classification.md\n - https://data.world/data4democracy/drug-spending/workspace/data-dictionary\n\n### Origin:\nKEGG: http://www.genome.jp/kegg-bin/get_htext?htext=br08302.keg\n\nbr08302.keg is a text file with the hierarchical USP drug classifications. Lines beginning with A are USP Categories, subsequent lines beginning with B are USP Classes in that category, lines beginning with C are the drugs (i.e. the general drug compound), and lines beginning with D are example_drugs (i.e. the medication or formulation you would buy) of that drug.\n\nNote that the individual KEGG pages (e.g. D00903) for these drugs have a wealth of information, including product and generic names, chemical formula, additional classes, ATC codes, biochemical information, other classifications, and links to the compound in other databases (e.g. PubChem, DrugBank, etc).\n\n### Background:\nthe USP Drug Classification system (USP DC) is an independent drug classification system currently under development by the USP Healthcare Quality Expert Committee. The USP DC is designed to address stakeholder needs emerging from the extended use of the USP Medicare Model Guidelines (USP MMG) beyond the Medicare Part D benefit.\n\nThe USP DC is intended to be complementary to the USP MMG and is developed with similar guiding principles, taxonomy, and structure of the USP Categories and Classes.\nhttp://www.usp.org/health-quality-safety/usp-drug-classification-system\n\n### Acknowledgements and license:\nhttps://data.world/data4democracy/drug-spending/workspace/file?filename=usp_drug_classification.csv\nhttps://data.world/data4democracy/drug-spending/workspace/data-dictionary\n\n\nhttp://www.usp.org/health-quality-safety/usp-drug-classification-system\n\nhttp://www.usp.org/legal-notices/terms\n'","b""['healthcare', 'united states', 'medicine', 'public health', 'pharmaceutical industry', 'small', 'featured']""",https://www.kaggle.com/danofer/usp-drug-classification
b'Vehicle Number Plate Detection',b'Bounding boxes marked on license plates of vehicles',"b""### Context\n\n**Bounding boxes marked on license plates of vehicles.**\n\nVisualize and browse the dataset here:\nhttps://dataturks.com/projects/devika.mishra/Indian_Number_plates\n\n### Content\n\n![enter image description here][1]\n\nThe dataset has 353 items of which 229 items have been manually labeled.\n\nThe labels are divided into following 1 categories:\n\nnumber_plate\n\nExamples:\n![enter image description here][2]\n\n\n![enter image description here][3]\n\n\n\n**Key Features**\n\n353 items\n1 categories\nHuman labeled dataset\n\n\n### Acknowledgements\n\nWe wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.\n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?\n\n\n  [1]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/nunber_plate_1.png\n  [2]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/nunber_plate_3.png\n  [3]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/nunber_plate_4.png""","b""['image data', 'object detection', 'object recognition', 'object identification', 'small', 'featured']""",https://www.kaggle.com/dataturks/vehicle-number-plate-detection
b'Top 5000 Youtube channels data from Socialblade.',b'General metrics of top 5000 YouTube channels by Socialblade.',"b""### Context\n\nSocialblade is a well known company which maintains statistics of YouTube channels, Instagram accounts and many more. Their website features a page which shows Top 5000 YouTube channels and some basic information about them. \n\nI wanted to use those values for performing EDA, so I decided to scrap it. The data contains Socialblade Rankings of top 5000 YouTube channels. The data can be used for finding useful insights and the revealing possible correlations between the features of the channels and their respective rankings.\n\nNote: This work is not sponsored by Socialblade and is just one of an outcome of a fun project made using Data Science technologies. The project does not aim at violation of any policies or privacy since the data on the website is publicly available.\n\n\n### Content\n\nThe dataset contains the top 5000 rankings of the YouTube channels by a company named Socialblade. The data contains various information on the YouTube channels such as: the Socialblade channel rankings, the grades granted by Socialblade, the YouTube channel name, the number of videos uploaded by the channel, total number of subscribers on the channel and the total number of views on all the video content by the channel.\n\n### Acknowledgements\n\nThe data couldn't have been created without the hardwork of Socialblade team. They actually did the hardwork of ranking and collecting all the necessary metrics of the YouTube channels, I just scraped it using Python. A big shout out and thanks to the Socialblade team for making this possible.\n\n\n### Inspiration\n\nThe dataset can be used to perform exploratory data analysis and visualizations which can help reveal some possible correlations and insights about factors powering the YouTube channel rankings. Though the data delineates only some basic information about the YouTube channels, I'm pretty sure that this data can be very helpful to all the beginners and neophytes of data science.""","b""['beginner', 'eda', 'internet', 'demographics', 'ranking', 'small', 'featured']""",https://www.kaggle.com/mdhrumil/top-5000-youtube-channels-data-from-socialblade
b'Seattle Performance Ranges By Building Type 2016',b'From City of Seattle Open Data',"b""### Content  \n\nSummary energy and building characteristics by building type for non-residential and multifamily buildings 20,000 square feet or greater that benchmark energy data with the City of Seattle. This dataset summarizes information from the full 2016 Building Energy Benchmarking dataset but exludes likely or known errors.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/P0QYU43Cz4s) by [Mariano E. Rodriguez](https://unsplash.com/@marianoerz3) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-performance-ranges-by-building-type-2016
b'NY Power Authority (NYPA) Electric Supply',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'business', 'government', 'energy', 'small', 'featured']""",https://www.kaggle.com/new-york-state/ny-power-authority-nypa-electric-supply
b'Xception',b'Xception Pre-trained Model for Keras',"b'# Xception\n\n---\n\n## Xception: Deep Learning with Depthwise Separable Convolutions<br>\nWe present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.\n\n**Author: Fran\xc3\xa7ois Chollet**<br>\n**https://arxiv.org/abs/1610.02357**\n\n---\n\n\n![Xception architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/tA2qDIQ.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/keras/xception
b'Genesis demonstrator data for machine learning',b'Data with normal behaviour and data with anomalies',"b""Context\n-------\n\nThe Genesis Demonstrator was created during the [OPAK Project][1] and further revised during the European [IMPROVE][2] project. It is a portable pick-and-place demonstrator which uses an air tank to supply all the gripping and storage units. It records 5(+4) continuous signals, 13 discrete signals and 1 Unix Timestamp. Additionally, some datasets contain a Label.\n\nContent\n-------\n\nThe demonstrator sorts different two different materials (wood and metal) into their corresponding target locations. The different modules can be placed at any of the four positions and the PLC program automatically adjusts for the change in location.\n\n\nThe four modules are:<br>\n 1. Storage Magazine<br>\n 2. Sensor<br>\n 3. Metal storage<br>\n 4. Wood storage<br>\n\n\nA linear drive with a pneumatic gripper transports the materials between the different stations. \n\n\nThe procedure follows these steps:<br>\n0)\tIdle, waiting for start button press.<br>\n1)\tHoming, do homing when drive is not homed yet (only after first power on).<br>\n2)\tMove gripper to a position next to the storage module. This avoids collisions of the storage slider and the gripper when\nmaterial is ejected.<br>\n3)\tEject material.<br>\n4)\tMove gripper to storage position.<br>\n5)\tClose the gripper to pick up material.<br>\n6)\tMove to the sensor to detect material type.<br>\n7)\tMove to the corresponding storage box of the detected material.<br>\n8)\tOpen the gripper to release material.<br>\n<br>\n![Picture of the Genesis demonstrator][3]\n<br>\nFirst dataset contains files Genesis_StateMachineLabels.csv and Genesis_AnomalyLabels.csv:<br>\n\nIn this dataset the drive was already homed and the stations were positioned in the following order:<br>\nPosition 1:\tStorage Module<br>\nPosition 2:\tWood Storage<br>\nPosition 3:\tMetal storage<br>\nPosition 4:\tSensor Module<br>\n<br>\n\nBoth data sets contain 16220 observations taken every 50ms through an OPC DA server.\nThey are identical with just the labels being different.\nMissing values and Zero-Variance columns are already removed from the data.\n\n\nThe Label column in Genesis_StateMachineLabel.csv represents the internal state machine of the PLC code.\n\nState Machine description:<br>\n0:\tIdle,<br>\n1:\tHoming,<br>\n2:\tAvoidStorage,<br>\n3:\tActivateStorage,<br>\n4:\tToStorage,<br>\n5:\tCloseGripper,<br>\n6:\tToSensor,<br>\n7:\tToBox,<br>\n8:\tOpenGripper<br>\n<br>\n\nIn the Genesis_AnomalyLabels.csv file the anomaly Labels are manually annotated, checked very carefully and are accurate for each data point!\n\nOnly one type of Anomaly was simulated.\n\n\nAnomaly description:<br>\n0:\tNo anomaly<br>\n1:\tLinear drive jammed / tilted<br>\n2:\tLinear drive breaks free and corrects accumulated lag error<br>\n<br>\n\n![Table with production cycles][4]\n<br>\n<br>\nSecond dataset contains files Genesis_normal.csv, Genesis_lineardrive.csv, Genesis_pressure.csv:\n\nThis dataset contains unlabelled data that contains files with normal runs and runs with errors. \n\n\n\nIn the Genesis_normal.csv file, the Demonstrator worked as intended, without any failures or restrictions. It can be used to compare it with other files for predictive maintenance or anomaly detection.\n\n\n\nIn the Genesis_lineardrive.csv file, the lineardrive was slightly impaired over time, so that the Genesis Demonstrator does not work as intended. This file can be used for predictive maintenance or anomaly detection.\n\n\nIn the Genesis_pressure.csv file, the air pressure was reduced over time, so that the Genesis Demonstrator does not work as intended. This file can be used for predictive maintenance or anomaly detection.<br>\n<br>\nBoth datasets are not necessarily compatible with each other.\n\n\nAcknowledgements\n----------------\n\n\xc2\xa9 Copyright | inIT - Institute Industrial IT \n\n\xc2\xa9 Copyright | Ostwestfalen-Lippe University of Applied Sciences\n\n\nThis dataset is publicly available for anyone to use under [the following terms][5].\n\n\nvon Birgelen, Alexander; Niggemann, Oliver: Anomaly Detection and Localization for Cyber-Physical Production Systems with Self-Organizing Maps. S.: 55-71, Springer Vieweg, Aug 2018.\nhttps://www.hs-owl.de/init/veroeffentlichungen/publikationen/a/filteroff/3373/single.html\n\n\nIMPROVE has received funding from the European Union's Horizon 2020 research and innovation programme under Grant Agreement No. 678867\n\n\n  [1]: https://www.hs-owl.de/init/en/forschung/projekte/b/filteroff/267/single.html\n  [2]: http://www.improve-vfof.eu/\n  [3]: https://ciit-cloud.init.hs-owl.de/index.php/apps/files_sharing/publicpreview/GKEAcfCLGTDGasT?x=1903&y=576&a=true&file=Untitled.png&scalingup=0\n  [4]: https://ciit-cloud.init.hs-owl.de/index.php/apps/files_sharing/publicpreview/aKAaiKZCJjapaCZ?x=1903&y=576&a=true&file=Capture.PNG&scalingup=0\n  [5]: https://creativecommons.org/licenses/by-nc-sa/4.0/""","b""['deep learning', 'model comparison', 'model diagnosis', 'small', 'featured']""",https://www.kaggle.com/inIT-OWL/genesis-demonstrator-data-for-machine-learning
b'The Holy Quran',b'Understanding God - Sacred Meanings',"b'### Context\n\nThe Holy Quran is the central text for 1.5 billion Muslims around the world. It literally means ""The Recitation.""  It is undoubtedly the finest work in Arabic literature and revealed by Allah (God) to His Messenger Prophet Muhammed (Peace Be Upon Him) through angel Gabriel. It was revealed verbally from December 22, 609  (AD) to 632 AD (when Prophet Muhammed (Peace Be Upon Him) died)\n \nThe book is divided into 30 parts, 114 Chapters and 6,000+ verses.\n\nThere has been a lot of questions and comments on the text of this holy book given the contemporary Geo-political situation of the world, wars in the Middle East and Afghanistan and the ongoing terrorism.\n\nI have put this dataset together to call my fellow data scientists to run their NLP algorithms and Kernels to find and explore the sacred text by them selves.  \n \n\n### Content\n\nThe data contains complete Holy Quran in following 21 languages (so data scientists from different parts of the world can work with it). The original text was revealed in Arabic. Other 20 files are the translations of the original text.\n\n1. Arabic (Original Book by God)\n\n2. English (Transalation by Yusuf Ali)\n\n3. Persian (Makarim Sheerazi)\n\n4. Urdu (Jalandhari)\n\n5. Turkish (Y. N. Ozturk)\n\n6. Portuguese (El. Hayek)\n\n7. Dutch (Keyzer)\n\n8. Norwegian (Einar Berg)\n\n9. Italian (Piccardo)\n\n10. French (Hamidullah)\n\n11. German (Zaidan)\n\n12. Swedish (Rashad Kalifa)\n\n13. Indonesia (Bhasha Indoenisan)\n \n14. Bangla\n\n15. Chinese/Madarin\n\n16. Japanese\n\n17. Malay\n\n18. Malayalam\n\n19. Russian\n\n20. Tamil\n\n21. Uzbek\n\n## Inspiration\n\nHere are some ideas to explore:\n\n1. Can we make a word cloud for each chapter\n\n2. Can we make a word cloud of the whole book and find out the frequency of each word\n\n3.  Can we describe or annotate subjects in each chapter and verse\n\n4. Can we find how many times The Quran has mentioned Humans, Women, Humility, Heaven or Hell\n\n5. Can we compare the text with other famous books and see the correlation\n\n6. Can we compare the text with laws in multiple countries to see the resemblance\n\nAny other ideas you can think of\n\nI am looking forward to see your work and ideas and will keep adding more ideas to explore\n\nWelcome on board to learn the finest text on earth with Data Sciences and Machine Learning!\n\n## Updates\n\nComplete Verse-By-Verse Dataset has been shared. A good contribution by Zohaib Ali - https://www.kaggle.com/zohaib1111\n(Nov 20, 2017)'","b""['languages', 'faith and traditions', 'islam', 'medium', 'featured']""",https://www.kaggle.com/zusmani/the-holy-quran
b'Nashville Meetup Network',b'Teaching Dataset for NashNetX Presentation (PyTN)',"b'# Context\n\n`meetup.com` is a website for people organizing and attending regular or semi-regular events (""meet-ups""). The relationships amongst users\xe2\x80\x94who goes to what meetups\xe2\x80\x94are a social network, ideal for graph-based analysis.\n\nThis dataset was generated for a talk titled **Principles of Network Analysis with NetworkX**, [embedded online here](https://vanderbilt365-my.sharepoint.com/:p:/g/personal/bailesk1_vanderbilt_edu/EefqHnnhzAZPmtyGXUARtXQBSIURVE53eH41nvbzvpbvrQ?e=89mHsJ) ([or with notebooks, etc. on Github](https://github.com/stkbailey/nashnetx)). It forms the basis for a series of tutorials I presented on at PyNash and PyTennessee. In them, we work through the basics of graph theory and how to use NetworkX, a popular open-source Python package. We then apply this knowledge to extract insights about the social fabric of Tennessee MeetUp groups. \n\n# Content\n\n#### Graph data\n- `member-to-group-edges.csv`: Edge list for constructing a member-to-group bipartite graph. Weights represent number of events attended in each group.\n- `group-edges.csv`: Edge list for constructing a group-to-group graph. Weights represent shared members between groups.\n- `member-edges.csv`: Edge list for constructing a member-to-member graph. Weights represent shared group membership.\n- `rsvps.csv`: Raw member-to-event attendance data, which was aggregated to form `member-to-group-edges.csv`.\n\n#### Metadata\n- `meta-groups.csv`: Information for each group, including name and category. `group_id` can serve as index.\n- `meta-members.csv`: Information for each member, including name and location. `member_id` can serve as index.\n- `meta-events.csv`: Information for each event, including name and time. `event_id` can serve as index.\n\n# Acknowledgements\n\nI\'d like to acknowledge the folks at MeetUp.com, who have made their database publicly available via a convenient REST API. Even newbies like myself can access and enjoy!\n\n\n  [1]: http://stkbailey.github.io'","b""['tutorial', 'network analysis', 'networks', 'social groups', 'medium', 'featured']""",https://www.kaggle.com/stkbailey/nashville-meetup
b'First Person Narratives of the American South',b'Personal accounts of Southern life between 1860 and 1920',"b'""First-Person Narratives of the American South"" is a collection of diaries, autobiographies, memoirs, travel accounts, and ex-slave narratives written by Southerners. The majority of materials in this collection are written by those Southerners whose voices were less prominent in their time, including African Americans, women, enlisted men, laborers, and Native Americans.\n\nThe narratives available in this collection offer personal accounts of Southern life between 1860 and 1920, a period of enormous change. At the end of the Civil War, the South faced the enormous challenge of re-creating their society after their land had been ravaged by war, many of their men were dead or injured, and the economic and social system of slavery had been abolished. Many farmers, confronted by periodic depressions and market turmoil, joined political and social protest movements. For African Americans, the end of slavery brought hope for unprecedented control of their own lives, but whether they stayed in the South or moved north or west, they continued to face social and political oppression. Most African Americans in the South were pulled into a Darwinistic sharecropper system and saw their lives circumscribed by the rise of segregation. As conservative views faced a growing challenge from Modernist thought, Southern arts, sciences, and religion also reflected the considerable tensions manifested throughout Southern society. Admidst these dramatic changes, Southerners who had lived in the antebellum South and soldiers who had fought for the Confederacy wrote memoirs that and strived to preserve a memory of many different experiences.\nSoutherners recorded their stories of these tumultuous times in print and in diaries and letters, but few first-person narratives, other than those written by the social and economic elite found their way into the national print culture. In this online collection, accounts of life on the farm or in the servants\' quarters or in the cotton mill have priority over accounts of public lives and leading military battles. Each narrative offers a unique perspective on life in the South, and serves as an important primary resource for the study of the American South.\nThe original texts for ""First-Person Narratives of the American South"" come from the University Library of the University of North Carolina at Chapel Hill, which includes the Southern Historical Collection, one of the largest collections of Southern manuscripts in the country and the North Carolina Collection, the most complete printed documentation of a single state anywhere. The DocSouth Editorial Board, composed of faculty and librarians at UNC and staff from the UNC Press, oversees this collection and all other collections on Documenting the American South.\n\n\n### Context\n\nThe North American Slave Narratives collection at the University of North Carolina contains 344 items and is the most extensive collection of such documents in the world.\n\nThe physical collection was digitized and transcribed by students and library employees. This means that the text is far more reliable than uncorrected OCR output which is common in digitized archives.\n\nMore information about the collection and access to individual page images can be be found here: http://docsouth.unc.edu/neh\n\nThe plain text files have been optimized for use in Voyant and can also be used in text mining projects such as topic modeling, sentiment analysis and natural language processing. Please note that the full text contains paratextual elements such as title pages and appendices which will be included in any word counts you perform. You may wish to delete these in order to focus your analysis on just the narratives.\n\nThe .csv file acts as a table of contents for the collection and includes Title, Author, Publication Date a url pointing to the digitized version of the text and a unique url pointing to a version of the text in plain text (this is particularly useful for use with Voyant: http://voyant-tools.org/). \n\n### Copyright Statement and Acknowledgements\n\nWith the exception of ""Fields\'s Observation: The Slave Narrative of a Nineteenth-Century Virginian,"" which has no known rights, the texts, encoding, and metadata available in Open DocSouth are made available for use under the terms of a Creative Commons Attribution License (CC BY 4.0:http://creativecommons.org/licenses/by/4.0/). Users are free to copy, share, adapt, and re-publish any of the content in Open DocSouth as long as they credit the University Library at the University of North Carolina at Chapel Hill for making this material available.\n\nIf you make use of this data, considering letting the holder of the original collection know how you are using the data and if you have any suggestions for making it even more useful. Send any feedback to wilsonlibrary@unc.edu.\n\n### About the DocSouth Data Project\n\nDoc South Data provides access to some of the Documenting The American South collections in formats that work well with common text mining and data analysis tools.\n\nDocumenting the American South is one of the longest running digital publishing initiatives at the University of North Carolina. It was designed to give researchers digital access to some of the library\xe2\x80\x99s unique collections in the form of high quality page scans as well as structured, corrected and machine readable text.\n\nDoc South Data is an extension of this original goal and has been designed for researchers who want to use emerging technology to look for patterns across entire texts or compare patterns found in multiple texts. We have made it easy to use tools such as Voyant (http://voyant-tools.org/) to conduct simple word counts and frequency visualizations (such as word clouds) or to use other tools to perform more complex processes such as topic modeling, named-entity recognition or sentiment analysis.'","b""['linguistics', 'united states', 'history', 'slaves', 'medium', 'featured']""",https://www.kaggle.com/docsouth-data/first-person-narratives-of-the-american-south
b'EMA 65 Crossover ',b'NASDAQ100 daytrader.ai EMA cross over strategy dataset',"b'### Context\n\n - blog:\n  https://medium.com/@coreyauger/part-4-searching-for-signals-5eaa2432e757\n - site: http://daytrader.ai\n\nDay traders identify patterns in the market that tell them when to enter and exit a trade.  They never hold market position over night meaning profit targets for trades are expressed in minutes not days.  To further back their technical analysis they view the data in multiple time domains trying to locate so called ""support"" and ""resistance"" levels.  Many of the technical indicators are based on price alone.  \n\nThis data set should allow a machine algorithm to form better technical indicators then a human, thus allowing it to predict probabilities for entry conditions better then a human day trader.\n\nFor this data set we analysed 7 years of NASDAQ100 data (from 2010 to mid 2017).  Every morning we wait until 90 minutes of trading history has occurred before scanning for a simple pattern.  This pattern is when the 15 minute [EMA][1] crosses over the 65 minute [EMA][2].\n\nSymbols included in the search:\n\n - FB - Facebook\n - BABA - Alibaba\n - GOOG - Google class C\n - AAPL - Apple\n - TSLA - Tesla\n - MSFT - Microsoft\n - NVDA - NVidia\n - AMZN - Amazon\n - CRM - Salesforce\n - GOOGL - Google class A\n - ADBE - Adobe\n - NFLX - Netflix\n - INTC - Intel\n - BIDU - Baidu\n\n### Content\nOnce the pattern has been detected I give you 2400 minute (40 hours) of previous history.  As well as 20 minutes of future history.  \nThe data will be formatted as follows.\n\nFile name: data_**N**_**SYM**.csv \n\n - **N** is an incremental integer\n - **SYM** is the stock symbol ticker (FB, BABA, ect..)\n\nInside each of the csv files you will find 2420 lines of comma separated values, with format:\n\nISO formatted date, closing price, volume.\n\nEg:\n\n    2017-10-17T14:18:00.000Z,201.87,55800.0\n    2017-10-17T14:19:00.000Z,201.21,137786.0\n    2017-10-17T14:20:00.000Z,201.852,103695.0\n    2017-10-17T14:21:00.000Z,201.6,81362.0\n    2017-10-17T14:22:00.000Z,201.54,30183.0\n    2017-10-17T14:23:00.000Z,201.43,72405.0\n    2017-10-17T14:24:00.000Z,201.15,79411.0\n    2017-10-17T14:25:00.000Z,201.48,125713.0\n\nThe task should report a probability that this will be a successful trade or not.\n\nFurther note: One should keep in mind that there are trading fees involved for the entry and exit of the trade.  So in order to profile you will need to beat this spread.\n\n### Acknowledgements\n\nFurther ideas and questions can be directed to http://daytrader.ai\nThanks and I hope you have some fun with this set :)\nblog: https://medium.com/@coreyauger/daytrader-ai-machine-learning-applied-to-intraday-trading-a6b4e44b0274\n\n### Inspiration\n\nThe task should try to predict the label with the lowest possible error\nUseful links:\n\n - [Technical Analysis vs Fundamental Analysis][3]\n- https://medium.com/@coreyauger/daytrader-ai-machine-learning-applied-to-intraday-trading-a6b4e44b0274\n\n\n  [1]: https://www.investopedia.com/terms/e/ema.asp\n  [2]: https://www.investopedia.com/terms/e/ema.asp\n  [3]: https://www.investopedia.com/university/technical/techanalysis2.asp'","b""['deep learning', 'finance', 'time series', 'money', 'medium', 'featured']""",https://www.kaggle.com/daytrader/ema-65-crossover
b'Swiss Coins',b'Count and classify swiss coins from images',"b'### Context\n\nIt is difficult to determine how many coins are in a large pile of money, we want to make an app to automatically count them.\n\n### Content\n\nEach folder has a different type of coin (1fr = 1 franc, 50rp = 50 rappen / cents) and since all of the franc coins have the same back we have a fr_back folder and all of the rappen have the same we have a rp_back\n\n### Acknowledgements\n\nThe data was collected by https://github.com/Zarkonnen/aimeetup_coins\n\n\n### Inspiration\n\nMaking a tool to classify coints'","b""['image data', 'multiclass classification', 'money', 'counting', 'medium', 'featured']""",https://www.kaggle.com/ai-first/swisscoins
b'Consumer Opinion Surveys: OECD Indicators',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/QqE158hev1I) by [James Sutton](https://unsplash.com/@jamessutton_photography) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/oecd-org/consumer-opinion-surveys-oecd-indicators
b'The Complete Pokemon Dataset',b'Data on more than 800 Pokemon from all 7 Generations.',"b'### Context\n\nThis dataset contains information on all 802 Pokemon from all Seven Generations of Pokemon. The information contained in this dataset include Base Stats, Performance against Other Types, Height, Weight, Classification, Egg Steps, Experience Points, Abilities, etc. The information was scraped from http://serebii.net/\n\n\n### Content\n\n* **name:** The English name of the Pokemon\n* **japanese_name:** The Original Japanese name of the Pokemon\n* **pokedex_number:** The entry number of the Pokemon in the National Pokedex\n* **percentage_male:** The percentage of the species that are male. Blank if the Pokemon is genderless.\n* **type1:** The Primary Type of the Pokemon\n* **type2:** The Secondary Type of the Pokemon\n* **classification:** The Classification of the Pokemon as described by the Sun and Moon Pokedex\n* **height_m:** Height of the Pokemon in metres\n* **weight_kg:** The Weight of the Pokemon in kilograms\n* **capture_rate:** Capture Rate of the Pokemon\n* **base_egg_steps:** The number of steps required to hatch an egg of the Pokemon\n* **abilities:** A stringified list of abilities that the Pokemon is capable of having\n* **experience_growth:** The Experience Growth of the Pokemon\n* **base_happiness:** Base Happiness of the Pokemon\n* **against_?:** Eighteen features that denote the amount of damage taken against an attack of a particular type\n* **hp:** The Base HP of the Pokemon\n* **attack:** The Base Attack of the Pokemon\n* **defense:** The Base Defense of the Pokemon\n* **sp_attack:** The Base Special Attack of the Pokemon\n* **sp_defense:** The Base Special Defense of the Pokemon\n* **speed:** The Base Speed of the Pokemon\n* **generation:** The numbered generation which the Pokemon was first introduced\n* **is_legendary:** Denotes if the Pokemon is legendary.\n\n\n### Acknowledgements\n\nThe data was scraped from http://serebii.net/.\n\n\n### Inspiration\n\nPokemon holds a very special place in my heart as it is probably the only video game I have judiciously followed for more than 10 years. With this dataset, I wanted to be able to answer the following questions:\n\n* Is it possible to build a classifier to identify legendary Pokemon?\n* How does height and weight of a Pokemon correlate with its various base stats?\n* What factors influence the Experience Growth and Egg Steps? Are these quantities correlated?\n* Which type is the strongest overall? Which is the weakest?\n* Which type is the most likely to be a legendary Pokemon?\n* Can you build a Pokemon dream team? A team of 6 Pokemon that inflicts the most damage while remaining relatively impervious to any other team of 6 Pokemon.'","b""['video games', 'popular culture', 'small', 'featured']""",https://www.kaggle.com/rounakbanik/pokemon
b'Wikiquote Short English Quotes',b'English quotes shorter than 100 characters (parsed from a Wikiquote data dump)',"b""## Context\n\nThere aren't any large, public datasets of quotes to be found online (at the time of writing). So I decided to create my own by parsing and cleaning up a Wikiquote data dump. To create your own dataset with different languages and cutoff lengths, check out [my Github repository][1].\n\n## Content\n\nquotes-100-en.json\n\nA JSON file containing english quotes less than 100 characters, scraped from Wikiquote.\n\n## Acknowledgments\n\nHuge thanks to all the contributors to [Wikiquote](https://en.wikiquote.org/wiki/Main_Page), and the [Wikimedia Foundation](https://wikimediafoundation.org/wiki/Home).\n\n## Inspiration\n\nAnalysis and interpretation of quotes from important historical figures.\n\n  [1]: https://github.com/heyseth/wickedQuotes""","b""['linguistics', 'small', 'featured']""",https://www.kaggle.com/fantop/wikiquote-short-english-quotes
b'SNAP Benefits Recipients Data Collection',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/Y0AwO4xlX0g) by [Demi Kwant](https://unsplash.com/@iidemii) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/snap-benefits-recipients-data-collection
b'NY Sidewalk Cafe Licenses and Applications',b'From New York City Open Data',"b""### Content  \n\nThis dataset features detailed information about sidewalk caf\xc3\xa9 license applications and, if applicable, issued licenses.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ArT-TOcNZHY) by [Jason Briscoe](https://unsplash.com/@jbriscoe) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'business', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-sidewalk-cafe-licenses-and-applications
b'Chicago Parking Permit Zones',b'From City of Chicago Open Data',"b""### Content  \n\nThis dataset contains all those street segments (individually uniquely identified by Record ID) that have been designated as belonging to a \xe2\x80\x9cResidential Parking Zone.\xe2\x80\x9d  Residential Parking Zones are established by passage of legislation through the Chicago City Council; this data set is updated daily, but major update installments typically occur shortly after City Council Meetings (where/when legislation affecting zones \xe2\x80\x93 such as zone creation or zone modification \xe2\x80\x93 occurs).   (See City Council Meeting schedule: https://chicago.legistar.com/Calendar.aspx.)  The collection of street segments for a single zone (collectively identified by Zone number) are not required to constitute a seamless polygon; however, they must be contiguous; in this sense, \xe2\x80\x9cZones\xe2\x80\x9d often closer resemble a collection of intersecting segments rather than an unbroken area. Segments are commonly categorized as being either \xe2\x80\x9cStandard\xe2\x80\x9d or \xe2\x80\x9cBuffer\xe2\x80\x9d: Standard means that signs exist on the street segment beginning at the low-point and ending at the high-point; Buffer means that physical signs do not exist for that zone on that physical street, but residents of addresses within that segment shall have the privilege to purchase zone products (daily permits and annual passes) for that zone, as if physical signs were installed.  (In this way, segments designated as \xe2\x80\x98Buffer\xe2\x80\x99 can in fact overlap with either other buffers and/or standard segments.)  Physical signs will display the zone number and the day/times when the zone restriction is in effect, e.g., \xe2\x80\x9cAll Times\xe2\x80\x9d / \xe2\x80\x9cAnytime\xe2\x80\x9d; \xe2\x80\x9cMonday through Friday\xe2\x80\x9d; \xe2\x80\x9c6am \xe2\x80\x93 6pm All Days.\xe2\x80\x9d  During restricted days/times, any vehicle parked in the zone which does not display a valid unexpired zone product (either a daily permit or an annual pass printed on the City Vehicle Sticker) is subject to ticketing/enforcement.  Read more about Residential Zone Parking and eligibility to purchase zoned products: http://chicityclerk.com/city-stickers-parking/about-residential-parking.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/zHhFKYYas7o) by [chuttersnap](https://unsplash.com/@chuttersnap) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-parking-permit-zones
b'Arabic Handwritten Characters Dataset',b'Arabic Handwritten Characters Data-set',"b'# Arabic Handwritten Characters Dataset\n\n### Astract\nHandwritten Arabic character recognition systems face several challenges, including the unlimited variation in human handwriting and large public databases. In this work, we model a deep learning architecture that can be effectively apply to recognizing Arabic handwritten characters. A Convolutional Neural Network (CNN) is a special type of feed-forward multilayer trained in supervised mode. The CNN trained and tested our database that contain 16800 of handwritten Arabic characters. In this paper, the optimization methods implemented to increase the performance of CNN. Common machine learning methods usually apply a combination of feature extractor and trainable classifier. The use of CNN leads to significant improvements across different machine-learning classification algorithms. Our proposed CNN is giving an average 5.1% misclassification error on testing data.\n\n### Context\n\nThe motivation of this study is to use cross knowledge learned from multiple works to enhancement the performance of Arabic handwritten character recognition. In recent years, Arabic handwritten characters recognition with different handwriting styles as well, making it important to find and work on a new and advanced solution for handwriting recognition. A deep learning systems needs a huge number of data (images) to be able to make a good decisions.\n\n### Content\n\nThe data-set is composed of **16,800** characters written by 60 participants, the age range is between 19 to 40 years, and 90% of participants are right-hand. Each participant wrote each character (from \xe2\x80\x99alef\xe2\x80\x99 to \xe2\x80\x99yeh\xe2\x80\x99) ten times on two forms as shown in Fig. 7(a) & 7(b). The forms were scanned at the resolution of 300 dpi. Each block is segmented automatically using Matlab 2016a to determining the coordinates for each block. The database is partitioned into two sets: a training set (13,440 characters to 480 images per class) and a test set (3,360 characters to 120 images per class). Writers of training set and test set are exclusive. Ordering of including writers to test set are randomized to make sure that writers of test set are not from a single institution (to ensure variability of the test set).\n\nIn an experimental section we showed that the results were promising with **94.9%** classification accuracy rate on testing images. In future work, we plan to work on improving the performance of handwritten Arabic character recognition.\n\n\n### Acknowledgements\n\nAhmed El-Sawy, **Mohamed Loey**, Hazem EL-Bakry, **Arabic Handwritten Characters Recognition using Convolutional Neural Network**, WSEAS, 2017\nOur proposed CNN is giving an average **5.1%** misclassification error on testing data.\n\n\n### Inspiration\n\nCreating the proposed database presents more challenges because it deals with many issues such as style of writing, thickness, dots number and position. Some characters have different shapes while written in the same position. For example the teh character has different shapes in isolated position.\n\nBenha University\n\nhttp://bu.edu.eg/staff/mloey\n\nhttps://mloey.github.io/'","b""['medium', 'featured']""",https://www.kaggle.com/mloey1/ahcd1
"b'Pollution in Atchison Village, Richmond CA'",b'Pollution and Wind Data from August to November 2015',"b'### Context\nData from refinery monitoring stations in Atchison Village, Richmond CA, United States. This is just a small piece of the data available. I hope to get more data collected in the future.\n\n### Content\n\nVariables Include: Date, Wind Direction, Wind Speed, Xylene, Toluene, Ozone, SO2, and CS2.\n\n### Acknowledgements \nThe data source is http://www.fenceline.org/richmond/data.php\n\nPhoto by veeterzy on Unsplash\n\n### Inspiration\n\nExplore the information provided by Wind Speed and Wind Direction!'","b""['time series', 'health', 'pollution', 'small', 'featured']""",https://www.kaggle.com/nicapotato/pollution-in-atchison-village-richmond-ca
b'Wikia census',b'A census of 300k wikis in Wikia.',"b'### Context\n\nA census of all the wikis hosted in [Wikia][1].\nA dataset consisting on data of more than 300 thousand wikis, such as: language, topic, number of users, admins, articles, edits, pages, number of users with a certain number of contributions, number of bots, etc.\n\nA study of this data has been presented in the [Opensym 2018 conference][2].\nYou can find the Jupyter notebook code regarding that study under the ""Kernels"" section. \n\n### Content\n\nThere are two files of data:\n- wikia_stats_users.csv: general data about each wiki.\n- wikia_stats_users_birthdate.csv: all the data above plus the estimated date of birth.\n\nThe other two .txt files contains pairs of (name, url) of the raw index crawled from the Wikia Sitemap, and the corresponding curated index with only the working wikis.\n\nThe date of the data collection of this second version is October 2018. First version was February 2018.\n\nThe collection of the data has been made using the scripts located here: https://github.com/Grasia/wiki-scripts\n\nThe license of the data is not clearly stated by Wikia, because this data is publicly available in their website but they haven\'t established anything in their [license policy][3].\n\n### Acknowledgements\n\nAll the data is possible thanks to FANDOM, the company supporting Wikia, and thank to all the contributors to the wikis.\n\n### Inspiration\n\nWe want to find the patterns that characterizes a healthy and sustainable online community.\n\nWikia is a huge ecosystem of these communities where small, medium, big as well as young and old community coexist, so it is a perfect scenario to study online collaboration.\n\n### License\nThis data is released under the Creative Commons Attribution-Share Alike License 3.0 (Unported) (CC-BY-SA). Please attribute [FANDOM][4] (The company behind Wikia) and me (Abel Serrano Juste) when using this data.\n\n  [1]: http://www.wikia.com\n  [2]: http://www.opensym.org/wp-content/uploads/2018/07/OpenSym2018_paper_27.pdf\n  [3]: https://www.wikia.com/Licensing\n  [4]: http://fandom.com/'","b""['internet', 'communities', 'platforms', 'medium', 'featured']""",https://www.kaggle.com/abeserra/wikia-census
b'Los Angeles General City Budget Cash Flow',b'From Los Angeles Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Creative Commons 1.0 Universal (Public Domain Dedication)""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-general-city-budget-cash-flow
b'LADOT Traffic Counts Summary',b'From Los Angeles Open Data',"b'### Content  \n\nLADOT automated and manual traffic count summary data for intersections throughout Los Angeles. Manual counts (""MAN"" under the ""Type"" column) are generally 6-hr counts which have been expanded  using a conversion factor.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles\'s Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/CGjiWnl4-l8) by [Frankie Guarini](https://unsplash.com/@frankieguarini) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/ladot-traffic-counts-summary
b'NYS Title and Salary Listing',b'From New York State Open Data',"b""### Content  \n\nThe Title and Salary Listing is a compilation of job titles under the jurisdiction of the Department of Civil Service.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/TTiAJXZACas) by [Renan Kamikoga](https://unsplash.com/@renankamikoga) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['classification', 'socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-title-and-salary-listing
b'Revisiting  a Concrete Strength regression',b'Predictions sensitivity to the training set (1030 concretes samples)',"b'#Context\n\n**Abstract**:\n-------------\n\nConcrete is the most important material in civil engineering.    \nThe concrete compressive strength is a highly nonlinear function of age and ingredients.\n\n#Content\n\n\n**Concrete Compressive Strength Data Set**\n------------------------------------------\n\n**Data Set Information:**\n-------------------------\n\nNumber of instances 1030 \nNumber of Attributes\t9 \nAttribute breakdown\t8 quantitative input variables, and 1 quantitative output variable \nMissing Attribute Values\tNone \n\n\n**Attribute Information:**   \n--------------------------\n\nGiven are the variable name, variable type, the measurement unit and a brief description. The concrete compressive strength is the regression problem. The order of this listing corresponds to the order of numerals along the rows of the database. \n\nName -- Data Type -- Measurement -- Description \n\nCement (component 1) -- quantitative -- kg in a m3 mixture -- Input Variable    \nBlast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input Variable    \nFly Ash (component 3) -- quantitative -- kg in a m3 mixture -- Input Variable    \nWater (component 4) -- quantitative -- kg in a m3 mixture -- Input Variable    \nSuperplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input Variable    \nCoarse Aggregate (component 6) -- quantitative -- kg in a m3 mixture -- Input Variable    \nFine Aggregate (component 7)\t-- quantitative -- kg in a m3 mixture -- Input Variable    \nAge -- quantitative -- Day (1~365) -- Input Variable    \nConcrete compressive strength -- quantitative -- MPa -- Output Variable    \n\n#Acknowledgements\n\n**Source:**\n-----------\n\nOriginal Owner and Donor    \nProf. I-Cheng Yeh    \nDepartment of Information Management    \nChung-Hua University,    \nHsin Chu, Taiwan 30067, R.O.C.    \ne-mail:icyeh \'@\' chu.edu.tw    \nTEL:886-3-5186511    \n\nDate Donated: August 3, 2007    \n\nFrom:  https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength\n\n**Relevant Papers:**   \n--------------------\n\n**Main**    \n1)\tI-Cheng Yeh, ""Modeling of strength of high performance concrete using artificial neural networks,"" Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998). \n\n**Others**    \n\n2)\tI-Cheng Yeh, ""Modeling Concrete Strength with Augment-Neuron Networks,"" J. of Materials in Civil Engineering, ASCE, Vol. 10, No. 4, pp. 263-268 (1998).    \n\n3)\tI-Cheng Yeh, ""Design of High Performance Concrete Mixture Using Neural Networks,"" J. of Computing in Civil Engineering, ASCE, Vol. 13, No. 1, pp. 36-42 (1999).    \n\n4)\tI-Cheng Yeh, ""Prediction of Strength of Fly Ash and Slag Concrete By The Use of Artificial Neural Networks,"" Journal of the Chinese Institute of Civil and Hydraulic Engineering, Vol. 15, No. 4, pp. 659-663 (2003).    \n\n5)\tI-Cheng Yeh, ""A mix Proportioning Methodology for Fly Ash and Slag Concrete Using Artificial Neural Networks,"" Chung Hua Journal of Science and Engineering, Vol. 1, No. 1, pp. 77-84 (2003).    \n\n6)\tYeh, I-Cheng, ""Analysis of strength of concrete using design of experiments and neural networks,"" Journal of Materials in Civil Engineering, ASCE, Vol.18, No.4, pp.597-604 (2006).    \n\n\n**Citation Request:**   \n---------------------\n\nNOTE: Reuse of this database is unlimited with retention of copyright notice for Prof. I-Cheng Yeh and the following published paper:    \n\nI-Cheng Yeh, ""Modeling of strength of high performance concrete using artificial neural networks,"" Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998). \n\n#Inspiration\nCan you predict the strength of concrete?'","b""['random forest', 'linear regression', 'regression analysis', 'decision tree', 'civil engineering', 'small', 'featured']""",https://www.kaggle.com/maajdl/yeh-concret-data
b'Snake Eyes',b'Tiny dice images with translation and rotation for image classification',"b'### Context\n\nInvariance to translation and rotation is an important attribute we would like image classifiers to have in many applications. For many problems, even if there doesn\'t seem to be a lot of translation in the data, augmenting it with these transformations is often beneficial. There are not many datasets where these transformations are clearly relevant, though. The ""Snake Eyes"" dataset seeks to provide a problem where rotation and translation are clearly a fundamental aspect of the problem, and not just something intuitively believed to be involved.\n\n![Snake Eyes example pictures][1]\n\nImage classifiers are frequently utilized in a pipeline where a bounding box is first extracted from the complete image, and this process might provide centered data to the classifier. Some translation might still be present in the data the classifier sees, though, making the phenomenon relevant to classification nevertheless. A Snake Eyes classifier can clearly benefit from such a pre-processing. But the point here is trying to learn how much a classifier can learn to do by itself. In special we would like to demonstrate the ""built-in"" invariance to translations from CNNs.\n\n### Content\n\nSnake Eyes contains artificial images simulating the a roll of one or two dice. The face patterns were modified to contain at most 3 black spots, making it impossible to solve the problem by merely counting them. The data was synthesized using a Python program, each image produced from a set of floating-point parameters modeling the position and angle of each dice.\n\n![Snake Eyes face patterns, with distinctive missing pips][2]\n\nThe data format is binary, with records of 401 bytes. The first byte contains the class (1 to 12, notice it does not start at 0), and the other 400 bytes are the image rows. We offer 1 million images, split in 10 files with 100k records each, and an extra test set with 10,000 images.\n\n### Inspiration\n\nWe were inspired by the popular ""tiny image"" datasets often studied in ML research: MNIST, CIFAR-10 and Fashion-MNIST. Our dataset has smaller images, though, only 20x20, and 12 classes. The reduced proportions should help approximate the actual 3D and 6D manifolds of each class with the available number of data points (1 million images).\n\nThe data is artificial, with limited and very well-defined patterns, noise-free and properly anti-aliased. This is not about improving from 95% to 97% accuracy and wondering if 99% is possible with a deeper network. We don\'t expect less than 100% precision to be achieved with any method eventually. What we are interested to see is how do different methods compare in efficiency, how hard is it to train different models, and how the translation and rotation invariance is enforced or achieved.\n\nWe are also interested in studying the concept of manifold learning. The data has some intra-class variability due to different possible face combinations with two dice. But most of the variation comes from translation and rotation. We hope to have sampled enough data to really allow for the extraction of these manifolds in 400 dimensions, and to investigate topics such as the role of pre-training, and the relation between modeling the manifold of the whole data and of the separate classes.\n\nTranslations alone already create quite non-convex manifolds, but our classes also have the property that some linear combinations are actually a different class (e.g. two images from the ""2"" face make an image from the ""4"" class). We are curious to see how this property can make the problem more challenging to different techniques.\n\nWe are also secretly hoping to have created the image-detection version of the infamous ""spiral"" problem for neural networks. We are offering the prize of one ham sandwich, collected at my local caf\xc3\xa9, to the first person who manages to train a neural network to solve this problem, convolutional or not, and using just traditional techniques such as logistic or ReLU activation functions and SGD training. 99% accuracy is enough. The resulting network may be susceptible to adversarial instances, this is fine, but we\'ll be constantly complaining about it in your ear while you eat the sandwich.\n\n\n  [1]: https://i.imgur.com/gaD5UtQ.png\n  [2]: https://imgur.com/gIcZVLN.png'","b""['image data', 'multiclass classification', 'machine learning', 'geometry', 'medium', 'featured']""",https://www.kaggle.com/nicw102168/snake-eyes
b'NYS Supplemental Security Income (SSI) Data',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-supplemental-security-income-ssi-data
b'Chicago Roadway Construction Moratoriums',b'From City of Chicago Open Data',"b""### Content  \n\nMoratoriums are established by the Department of Transportation as a method of protecting reconstructed or repaved roadways within the boundaries of the city.\n\nBy having access to this Moratorium list in advance, contractors or utilities with projects that require excavation of roadways can more effectively plan and review conflicts that will be encountered. Currently, roadway sections with active moratoriums have special consideration as to method and size of restoration, and additionally, increased permit fees. Three moratorium types are displayed on this web site: (1) Street Construction is used when the street has been reconstructed. By City ordinance, the moratorium is ten (10) years and during this period permit fees are doubled. (2) Street Resurfacing is used when the road has been repaved. By City ordinance, the moratorium is seven (7) years and during this period permit fees are doubled. (3) Median or Median Landscaping is used where landscaped medians or planters exist on the street median. For these moratoriums types, there is no fee adjustment; however, if a construction permit is being requested, the applicant will be directed to review the planned project with the Department of Transportation/Division of Engineering staff for special instructions on how to properly protect or reconstruct street medians.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/sTw2KYpoujk) by [Anthony Ginsbrook](https://unsplash.com/@aginsbrook) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-roadway-construction-moratoriums
b'NYS Liquor Authority Brand Label and Wholesaler',b'From New York State Open Data',"b""### Content  \n\nBrand Label and Wholesale Information for Alcohol Products Registered in NYS.The New York State Alcohol Beverage Control Law specifies that no manufacturer or wholesaler shall sell to any retailer nor shall any retailer purchase any alcoholic beverages unless these beverages are labeled in accordance with the Authority's Rules and Federal Regulations and unless such label shall be registered with and approved by the State Liquor Authority. Effective January 1, 1994, wine does not need to be brand label registered if the wine has received label approval from the Bureau of Alcohol, Tobacco and Firearms (BATF).  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/8P_9QpvLGZ0) by [Tim Wright](https://unsplash.com/@timdwright) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'alcohol', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-liquor-authority-brand-label-and-wholesaler
b'NYC Permitted Event Information',b'From New York City Open Data',"b""### Content  \n\nThis list contains information on approved event applications that will occur within the next month. Please note that Permitted Film Events only reflect those permits which will impact one or more streets for at least five days.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/3Y-sQuz1Ktg) by [Jonathan Percy](https://unsplash.com/@jonathan_percy) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-permitted-event-information
b'Chicago CPS Schools 2013-2014 Academic Year',b'From City of Chicago Open Data',"b""### Content  \n\nList of CPS schools for the 2013-2014 academic year. This dataset includes various identifiers used to identify school districts, including names; local, state, and federal IDs; and geographic descriptions on the location of each school.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/e3Uy4k7ooYk) by [Davide Cantelli](https://unsplash.com/@cant89) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'education', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-cps-schools-2013-2014-academic-year
b'Patent Litigations',"b'Detailed Patent Litigation Data on 74k Cases, 1963-2015'","b'### Context\n\nAchieving the appropriate balance of intellectual property (IP) protection through patent litigation is critical to economic growth. Examining the interplay between US patent law and economic effect is of great interest to many stakeholders. Published in March 2017, this dataset is the most comprehensive public body of information on USPTO patent litigation.\n\n\n### Content\n\nThe dataset covers over 74k cases across 52 years. Five different files (attorneys.csv, cases.csv, documents.csv, names.csv, pacer_cases.csv) detail the litigating parties, their attorneys, results, locations, and dates. The large documents.csv file covers more than 5 million relevant documents (a tool like [split](https://en.wikipedia.org/wiki/Split_(Unix)) might be your friend here).\n\n\n### Acknowledgements\n\nThis data was collected by the Office of the Chief Economist at the USPTO. Data was collected from both the Public Access to Court Electronics Records (PACER), as well as RECAP, an independent PACER repository. Further documentation available via this [paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2942295).\n\n\n### Inspiration\n\nPatent litigation is a tug of war between patent holders, competing parties using similar IP, and government policy. Which industries see the most litigation? Any notable changes over time? Is there a positive (or negative) correlation between litigation, and a company\xe2\x80\x99s economic fortunes?\n\n### License\n\n[Public Domain Mark 1.0](https://creativecommons.org/publicdomain/mark/1.0/)\nAlso see [source](https://www.uspto.gov/learning-and-resources/electronic-data-products/patent-litigation-docket-reports-data).'","b""['law', 'large', 'featured']""",https://www.kaggle.com/uspto/patent-litigations
b'GloVe: Global Vectors for Word Representation',b'Pre-trained word vectors from Wikipedia 2014 + Gigaword 5',"b'### Context\n\nGloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\n\n### Content\n\nThis dataset contains English word vectors pre-trained on the combined Wikipedia 2014 + Gigaword 5th Edition corpora (6B tokens, 400K vocab). All tokens are in lowercase. This dataset contains 50-dimensional, 100-dimensional and 200-dimensional pre trained word vectors. For 300-dimensional word vectors and additional information, please see the [project website][1]. \n\n### Acknowledgements\n\nThis data has been released under the [Open Data Commons Public Domain Dedication and License][2]. If you use this dataset in your work, please cite the following paper: \n\n> Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. URL: https://nlp.stanford.edu/pubs/glove.pdf\n\n### Inspiration\nGloVe embeddings have been used in more than 2100 papers, and counting! You can use these pre-trained embeddings whenever you need a way to quantify word co-occurrence (which also captures some aspects of word meaning.)\n\n  [1]: https://nlp.stanford.edu/projects/glove/\n  [2]: https://opendatacommons.org/licenses/pddl/'","b""['linguistics', 'languages', 'large', 'featured']""",https://www.kaggle.com/rtatman/glove-global-vectors-for-word-representation
b'Chronic Disease Indicators',"b'Disease Data Across the US, 2001-2016'","b""### Context: \nCDC's Division of Population Health provides cross-cutting set of 124 indicators that were developed by consensus and that allows states and territories and large metropolitan areas to uniformly define, collect, and report chronic disease data that are important to public health practice and available for states, territories and large metropolitan areas. In addition to providing access to state-specific indicator data, the CDI web site serves as a gateway to additional information and data resources.\n\n### Content: \nA variety of health-related questions were assessed at various times and places across the US over the past 15 years. Data is provided with confidence intervals and demographic stratification.\n\n### Acknowledgements: \nData was compiled by the CDC.\n\n### Inspiration: \n* Any interesting trends in certain groups?\n* Any correlation between disease indicators and locality hospital spending?""","b""['healthcare', 'medium', 'featured']""",https://www.kaggle.com/cdc/chronic-disease
b'NYS Certified Plant Dealers',b'From New York State Open Data',"b""### Content  \n\nA listing of all certified plant dealers which are licensed by the Department of Agriculture and Markets. Licensing of plant dealers is intended to prevent the introduction of injurious insects, noxious weeds, and plant diseases into the state.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/OOE4xAnBhKo) by [Teemu Paananen](https://unsplash.com/@xteemu) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-certified-plant-dealers
b'#Charlottesville on Twitter',b'A snapshot of American history in the making',"b'Charlottesville, Virgina\n========================\n\nCharlottesville is home to a statue of Robert E. Lee which is slated to be removed. (For those unfamiliar with American history, Robert E. Lee was a US Army general who defected to the Confederacy during the American Civil War and was considered to be one of their best military leaders.) While many Americans support the move, believing the main purpose of the Confederacy was to defend the institution of slavery, many others do not share this view. Furthermore, believing Confederate symbols to be merely an expression of Southern pride, many have not taken its planned removal lightly.\n\nAs a result, many people--including white nationalists and neo-Nazis--have descended to Charlottesville to protest its removal. This in turn attracted many counter-protestors. Tragically, one of the counter-protestors--Heather Heyer--was killed and many others injured after a man intentionally rammed his car into them. In response, President Trump blamed ""both sides"" for the chaos in Charlottesville, leading many Americans to denounce him for what they see as a soft-handed approach to what some have called an act of ""domestic terrorism.""\n\nThis dataset below captures the discussion--and copious amounts of anger--revolving around this past week\'s events.\n\n\nThe Data\n========\n\nDescription\n-----------\n\nThis data set consists of a random sample of 50,000 tweets per day (in accordance with the Twitter Developer Agreement) of tweets mentioning Charlottesville or containing ""#charlottesville"" extracted via the Twitter Streaming API, starting on August 15.  The files were copied from a large Postgres database containing--currently--over 2 million tweets. Finally, a table of tweet counts per timestamp was created using the whole database (not just the Kaggle sample). The data description PDF provides a full summary of the attributes found in the CSV files. \n\nNote: While the tweet timestamps are in UTC, the cutoffs were based on Eastern Standard Time, so the August 16 file will have timestamps ranging from `2017-08-16 4:00:00` UTC to `2017-08-17 4:00:00` UTC.\n\n\nFormat\n------\n\nThe dataset is available as either separate CSV files or a single SQLite database.\n\n\nLicense\n=======\n\nI\'m releasing the dataset under the CC BY-SA 4.0 license. Furthermore, because this data was extracted via the Twitter Streaming API, its use must abide by the [Twitter Developer Agreement][1]. Most notably, the display of individual tweets should satisfy [these requirements][2]. More information can be found in the data description file, or on Twitter\'s website.\n\n\nAcknowledgements\n============\n\nObviously, I would like to thank Twitter for providing a fast and reliable streaming service. I\'d also like to thank the developers of the Python programming language, psycopg2, and Postgres for creating amazing software with which this data set would not exist.\n\nImage Credit\n------------------\n\nThe banner above is a personal modification of these images:\n\n - Evan Nesterak: [Image Source][3] [Image License][4]\n - Wikipedia user Cville Dog [Image Source][5]\n - The Associated Press [Image Source][6]\n\n\nInspiration\n==========\n\nI almost removed the header ""inspiration"" from this section, because this is a rather sad and dark data set. However, this is preciously why this is an important data set to analyze. Good history books have never shied away from unpleasant events, and never should we.\n\nThis data set provides a rich opportunity for many types of research, including:\n\n - Natural language processing\n - Sentiment analysis\n - Data visualization\n\nFurthermore, given the political nature of this dataset, there are a lot of social science questions that can potentially be answered, or at least piqued, by this data.\n\n\n  [1]: https://dev.twitter.com/overview/terms/\n  [2]: https://dev.twitter.com/overview/terms/display-requirements\n  [3]: https://www.flickr.com/photos/153804281@N02/36421659232/ ""Image Source""\n  [4]: https://en.wikipedia.org/wiki/Unite_the_Right_rally#/media/File:White_supremacists_clash_with_police_(36421659232).jpg ""Image License""\n  [5]: https://en.wikipedia.org/wiki/Unite_the_Right_rally#/media/File:Lee_Park,_Charlottesville,_VA.jpg ""Image Source""\n  [6]: https://www.voanews.com/a/rallies-in-aftermath-of-charlottesville-violence/3983710.html ""Image Source""'","b""['internet', 'linguistics', 'politics', 'twitter', 'medium', 'featured']""",https://www.kaggle.com/vincela9/charlottesville-on-twitter
b'City Of Seattle Neighborhood Matching Funds',b'From City of Seattle Open Data',"b""### Content  \n\nSeattle Department Of Neighborhoods - All awarded Neighborhood Matching Funds from 1989 to present. DON  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/dZ4X2zWV7HY) by [Oakie](https://unsplash.com/@notoakie) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/city-of-seattle-neighborhood-matching-funds
b'Financial Statement Extracts',b'Data extracted from filings companies make to the SEC 2015-2017',"b'The Financial Statement Data Sets below provide numeric information from the face financials of all financial statements.  This data is extracted from exhibits to corporate financial reports filed with the Commission using eXtensible Business Reporting Language (XBRL).  As compared to the more extensive Financial Statement and Notes Data Sets, which provide the numeric and narrative disclosures from all financial statements and their notes, the Financial Statement Data Sets are more compact.\n \nThe information is presented without change from the ""as filed"" financial reports submitted by each registrant. The data is presented in a flattened format to help users analyze and compare corporate disclosure information over time and across registrants. The data sets also contain additional fields including a company\'s Standard Industrial Classification to facilitate the data\'s use.\n\n## Content\n\nEach quarter\'s data is stored as a json of the original text files. This was necessary to limit the overall number of files. The `num.txt` file will likely be of most interest.\n\n### Acknowledgements\n\nThis dataset was kindly made available by [the SEC][1]. You can find the original dataset, which is updated quarterly, [here][2].\n\n\n  [1]: https://www.sec.gov\n  [2]: https://www.sec.gov/dera/data/financial-statement-data-sets.html'","b""['finance', 'large', 'featured']""",https://www.kaggle.com/securities-exchange-commission/financial-statement-extracts
b'Boxofficemojo Alltime Domestic Data ',b'Explore the relationship between words used in movie titles and all time gross',"b""## BoxofficeMojo Alltime Domestic Data\n\nData scraped from BoxofficeMojo's listing of the  lifetime gross, ranking and production year of hollywood movies. \nAll is based on domestic gross (does NOT account for inflation). \n\nInteractive dashboard to explore the data: \n\nhttps://www.dashboardom.com/boxofficemojo\n\nAbout the dashboard:\nhttps://www.slideshare.net/eliasdabbas/boxofficemojo-data-interactive-dashboard\n\nScript to scrape the data and analyze words (absolute frequency vs weighted frequency) on DataCamp: \nhttps://www.datacamp.com/community/tutorials/absolute-weighted-word-frequency\n\nQuick result of the analysis (April 2018): \n![](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524577430/output_27_0_kujy3w.png)\n\n\n  [1]: http://www.hello.com""","b""['entertainment', 'small', 'featured']""",https://www.kaggle.com/eliasdabbas/boxofficemojo-alltime-domestic-data
b'DeepSat (SAT-4) Airborne Dataset',"b'500,000 image patches covering four broad land cover classes'","b'### DeepSat SAT-4\n![Sample images][1]<br><br>\nOriginally, images were extracted from the National Agriculture Imagery Program (NAIP) dataset. The NAIP dataset consists of a total of 330,000 scenes spanning the whole of the Continental United States (CONUS). The authors used the uncompressed digital Ortho quarter quad tiles (DOQQs) which are GeoTIFF images and the area corresponds to the United States Geological Survey (USGS) topographic quadrangles. The average image tiles are ~6000 pixels in width and ~7000 pixels in height, measuring around 200 megabytes each. The entire NAIP dataset for CONUS is ~65 terabytes. The imagery is acquired at a 1-m ground sample distance (GSD) with a horizontal accuracy that lies within six meters of photo-identifiable ground control points.\n\nThe images consist of 4 bands - red, green, blue and Near Infrared (NIR). In order to maintain the high variance inherent in the entire NAIP dataset, we sample image patches from a multitude of scenes (a total of 1500 image tiles) covering different landscapes like rural areas, urban areas, densely forested, mountainous terrain, small to large water bodies, agricultural areas, etc. covering the whole state of California. An image labeling tool developed as part of this study was used to manually label uniform image patches belonging to a particular landcover class. \n\nOnce labeled, 28x28 non-overlapping sliding window blocks were extracted from the uniform image patch and saved to the dataset with the corresponding label. We chose 28x28 as the window size to maintain a significantly bigger context, and at the same time not to make it as big as to drop the relative statistical properties of the target class conditional distributions within the contextual window. Care was taken to avoid interclass overlaps within a selected and labeled image patch.\n\n### Content\n\n- Each sample image is 28x28 pixels and consists of 4 bands - red, green, blue and near infrared. \n\n- The training and test labels are one-hot encoded 1x4 vectors\n\n- The four classes represent the four broad land covers which include barren land, trees, grassland and a class that consists of all land cover classes other than the above three. \n\n- Training and test datasets belong to disjoint set of image tiles. \n\n- Each image patch is size normalized to 28x28 pixels.\n\n- Once generated, both the training and testing datasets were randomized using a pseudo-random number generator. \n\n### CSV files<br>\n- X_train_sat4.csv: 400,000 training images, 28x28 images each with 4 channels <br>\n- y_train_sat4.csv: 400,000 training labels, 1x4 one-hot encoded vectors <br>\n- X_test_sat4.csv: 100,000 training images, 28x28 images each with 4 channels <br>\n- y_test_sat4.csv: 100,000 training labels, 1x4 one-hot encoded vectors <br>\n\n### The original MAT file <br>\n- train_x:\t28x28x4x400000 uint8 (containing 400000 training samples of 28x28 images each with 4 channels)<br>\n- train_y:\t400000x4 uint8 (containing 4x1 vectors having labels for the 400000 training samples)<br>\n- test_x:\t28x28x4x100000 uint8 (containing 100000 test samples of 28x28 images each with 4 channels)<br>\n- test_y:\t100000x4 uint8 (containing 4x1 vectors having labels for the 100000 test samples)<br>\n\n### Acknowledgements\n\nThe original MATLAB file was converted to multiple CSV files \n\nThe original SAT-4 and SAT-6 airborne datasets can be found here:<br>\n[http://csc.lsu.edu/~saikat/deepsat/][2]<br>\n\nThanks to:<br>\nSaikat Basu, Robert DiBiano, Manohar Karki and Supratik Mukhopadhyay, Louisiana State University\nSangram Ganguly, Bay Area Environmental Research Institute/NASA Ames Research Center\nRamakrishna R. Nemani, NASA Advanced Supercomputing Division, NASA Ames Research Center\n\n\n\n  [1]: http://csc.lsu.edu/~saikat/deepsat/images/sat_img.png\n  [2]: http://csc.lsu.edu/~saikat/deepsat/'","b""['machine learning', 'large', 'featured']""",https://www.kaggle.com/crawford/deepsat-sat4
b'The National University of Singapore SMS Corpus',"b'A corpus of more than 67,000 SMS messages in Singapore English & Mandarin'","b'### Context: \nShort Message Service (SMS) messages are short messages sent from one person to another from their mobile phones. They represent a means of personal communication that is an important communicative artifact in our current digital era. This dataset contains SMS messages that were collected from users who knew they were participating in a research project and that their messages would be shared publicly. This dataset contains two SMS messages in two languages: Singapore English and Mandarin Chinese.\n\n### Content: \nThis is a corpus of SMS (Short Message Service) messages collected for research at the Department of Computer Science at the National University of Singapore. This dataset consists of 67,093 SMS messages taken from the corpus on Mar 9, 2015. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available. The data collectors opportunistically collected as much metadata about the messages and their senders as possible, so as to enable different types of analyses. \n \n### Acknowledgements: \nThis corpus was collected by Tao Chen and Min-Yen Kan. If you use this data, please cite the following paper:\n\n`Tao Chen and Min-Yen Kan (2013). Creating a Live, Public Short Message Service Corpus: The NUS SMS Corpus. Language Resources and Evaluation, 47(2)(2013), pages 299-355. URL: https://link.springer.com/article/10.1007%2Fs10579-012-9197-9`\n\n### Inspiration: \nThis dataset contains a lot of short, informal texts and is ideal for trying your hand at various natural language processing tasks. There\xe2\x80\x99s also a lot of information about the messages which might reveal interesting insights. Here are some ideas to get you started:\n\n* This dataset contains Singapore English. How well do tools trained on other varieties of English, like stemmers or part of speech taggers, work on it?\n* What time of day are most SMS messages sent? Is this different for the English and Mandarin datasets?\n* Unlike English, Mandarin does not have spaces between words, which can be made up of several characters. Can you build or implement a system for word identification?'","b""['linguistics', 'languages', 'telecommunications', 'medium', 'featured']""",https://www.kaggle.com/rtatman/the-national-university-of-singapore-sms-corpus
b'Chicago Public Health Department Events',b'From City of Chicago Open Data',"b""### Content  \n\nList of public events sponsored or supported by the Chicago Department of Public Health.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/hSAlu33padA) by [not brittany shh pls](https://unsplash.com/@notbritt) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'health', 'public health', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-public-health-department-events
b'LinkNYC Kiosk Information',b'From New York City Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/linknyc-kiosk-information
b'The Tate Collection',"b'Metadata for 70,000 artworks from the Tate'","b'### Context\n\n""Tate is an institution that houses the United Kingdom\'s national collection of British art, and international modern and contemporary art. It is a network of four art museums: Tate Britain, London (until 2000 known as the Tate Gallery, founded 1897), Tate Liverpool (founded 1988), Tate St Ives, Cornwall (founded 1993) and Tate Modern, London (founded 2000), with a complementary website, Tate Online (created 1998). Tate is not a government institution, but its main sponsor is the UK Department for Culture, Media and Sport.\n\n""The name \'Tate\' is used also as the operating name for the corporate body, which was established by the Museums and Galleries Act 1992 as \'The Board of Trustees of the Tate Gallery\'.\n\n""The gallery was founded in 1897, as the National Gallery of British Art. When its role was changed to include the national collection of modern art as well as the national collection of British art, in 1932, it was renamed the Tate Gallery after sugar magnate Henry Tate of Tate & Lyle, who had laid the foundations for the collection. The Tate Gallery was housed in the current building occupied by Tate Britain, which is situated in Millbank, London. In 2000, the Tate Gallery transformed itself into the current-day Tate, or the Tate Modern, which consists of a federation of four museums: Tate Britain, which displays the collection of British art from 1500 to the present day; Tate Modern, which is also in London, houses the Tate\'s collection of British and international modern and contemporary art from 1900 to the present day. Tate Liverpool has the same purpose as Tate Modern but on a smaller scale, and Tate St Ives displays modern and contemporary art by artists who have connections with the area. All four museums share the Tate Collection. One of the Tate\'s most publicised art events is the awarding of the annual Turner Prize, which takes place at Tate Britain.""\n\n-- Tate. (n.d.). In Wikipedia. Retrieved August 18, 2017, from https://en.wikipedia.org/wiki/Plagiarism. Text reproduced here under a [CC-BY-SA 3.0 license](https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License).\n\n### Content\n\nThis dataset contains the metadata for around 70,000 artworks that Tate owns or jointly owns with the National Galleries of Scotland as part of ARTIST ROOMS. Metadata for around 3,500 associated artists is also included.\n\nThe metadata here is released under the Creative Commons Public Domain CC0 licence. Images are not included and are not part of the dataset. \n\nThis dataset contains the following information for each artwork:\n\n* Id\n* accession_number\n* artist\n* artistRole\n* artistId\n* title\n* dateText\n* medium\n* creditLine\n* year\n* acquisitionYear\n* dimensions\n* width \n* height \n* depth\n* units\n* inscription\n* thumbnailCopyright \n* thumbnailUr\n* url\n\n\n### You may also like\n\n* [Museum of Modern Art Collection: Title, artist, date, and medium of every artwork in the MoMA collection](https://www.kaggle.com/momanyc/museum-collection)\n* [The Metropolitan Museum of Art Open Access: Explore information on more than 420,000 historic artworks](https://www.kaggle.com/metmuseum/the-metropolitan-museum-of-art-open-access)'","b""['europe', 'visual arts', 'museums', 'medium', 'featured']""",https://www.kaggle.com/rtatman/the-tate-collection
b'Seinfeld Chronicles',b'Complete Seinfeld Scripts and Episode Details',"b'**A dataset for textual analysis on arguably the best written comedy television show ever.** \n\n\n----------\n### Context\n\nDataset for people who love data science and Seinfeld.\n\n\n----------\n\n\n### Content\n\n - Details about all the episodes.\n - Includes attributes like Director, Episode Name, Air Date etc...\n - Complete Scripts of all the episodes.\n\n----------\n\n\n**Upcoming Update will Include :**\n\n - Stage locations and cast\n\n\n----------\n\n\n### Data Source\n\nThe data is scraped from the fan website [http://www.seinology.com/][1].\n\n\n### [Github Project][3]\n\n\n----------\n\n\n### Possible Explorations\n\n - Train language models on the corpus.\n - Compare the vocabulary with other works on television, film or literature.\n - Find corellation between language complexity and popularity. \n - Train models to generate scripts based on the data.\n - Analyze obscure wods used in the vocabulary of the series. \n\nThese are just basic examples, sky is the limit. \n\n\n----------\n\n\n### Acknowledgements\n\nThe data has been crawled from the [http://www.seinology.com/][4] website.\n\n\n\n----------\n\n### Contributing\n\nChanges and Improvement suggestions are welcome. Feel free to comment new additions that you think are useful or drop a PR on the [github][5] project.\n\n\n  [1]: http://www.seinology.com/\n  [2]: https://wallpapershome.com/images/wallpapers/fifa-18-5120x2880-4k-screenshot-poster-e3-2017-13691.jpg\n  [3]: https://github.com/amanthedorkknight/the-seinfeld-chronicles\n  [4]: http://www.seinology.com/\n  [5]: https://github.com/amanthedorkknight/the-seinfeld-chronicles\n  [6]: https://www.paypal.me/AShrivastava961'","b""['linguistics', 'text data', 'entertainment', 'small', 'featured']""",https://www.kaggle.com/thec03u5/seinfeld-chronicles
b'Top Spotify Tracks of 2017',b'Audio features of top Spotify songs',"b""## Top Spotify Tracks of 2017 ##\nAt the end of each year, Spotify compiles a playlist of the songs streamed most often over the course of that year. This year's playlist (Top Tracks of 2017) included 100 songs. The question is: What do these top songs have in common? Why do people like them?\n\n\n\n**Original Data Source:** \nThe audio features for each song were extracted using the Spotify Web API and the spotipy Python library. Credit goes to Spotify for calculating the audio feature values.\n\n**Data Description:**\nThere is one .csv file in the dataset. (featuresdf.csv) This file includes:\n \n\n - Spotify URI for the song\n - Name of the song\n - Artist(s) of the song\n - Audio features for the song (such as danceability, tempo, key etc.)\n\nA more detailed explanation of the audio features can be found in the Metadata tab.\n\n**Exploring the Data:** \nSome suggestions for what to do with the data:\n \n\n - Look for patterns in the audio features of the songs. Why do people stream these songs the most?\n \n - Try to predict one audio feature based on the others\n\n - See which features correlate the most\n ""","b""['popular culture', 'music', 'small', 'featured']""",https://www.kaggle.com/nadintamer/top-tracks-of-2017
b'An Open Dataset for Human Activity Analysis',"b'Data collected using Smartphone, Smartwatch and Smartglasses'","b""### Context\n\nThe study of human mobility and activities has opened up to an incredible number of studies in the past, most of which included the use of sensors distributed on the body of the subject. More recently, the use of smart devices has been particularly relevant because they are already everywhere and they come with accurate miniaturized sensors. Whether it is smartphones, smartwatches or smartglasses, each device can be used to describe complementary information such as emotions, precise movements, or environmental conditions.\n\n### Content\n\nFirst of all, a smartphone is used to capture mainly contextual data. Two applications are used: a simple data collection application based on the SWIPE open-source sensing system ([SWIPE][1]), and a logbook application for obtaining real data on user activity ([TimeLogger][2]). SWIPE is a platform for sensing, recording and processing human dynamics using smartwatches and smartphones.\n\nThen, a smartwatch is used primarily to capture the user's heart rate. Motion data is also collected, without being at the heart of the dataset due to its need to be configured with a low sampling frequency, which would drastically increase the dataset and drain the battery as well. An application based on SWIPE is used.\n\nFinally, JINS MEME smartglasses are used. This model has the advantage of being compact and simple to carry. It does not have a camera or a screen; it simply has three types of sensors: an accelerometer (for detecting steps or activities), a gyroscope (for head movements) and an occulographic sensor (eye blinking, eye orientation). The official DataLogger application from JINS MEME is used.\n\nFor more information on the dataset please refer to the corresponding publication, available at [An Open Dataset for Human Activity Analysis using Smart Devices][3].\n\nThe current dataset on Kaggle contains smartglasses data with 20ms interval (due to storage limitations), same data with 10ms interval is also available on demand. Contact sasan.jafarnejad [at] uni [dot] lu to receive the 10ms version.\n\n### Acknowledgements\n\nThis work was performed within the eGLASSES project, which is partially funded by NCBiR, FWF, SNSF, ANR and FNR under the ERA-NET CHIST-ERAII framework.\n\n\n  [1]: https://github.com/sfaye/SWIPE\n  [2]: http://www.atimelogger.com/\n  [3]: https://hal.archives-ouvertes.fr/hal-01586802""","b""['consumer electronics', 'medium', 'featured']""",https://www.kaggle.com/sasanj/human-activity-smart-devices
b'SF Street Trees',b'188k Street Trees Around SF',"b'### Context: \nProp. E was a measure on the November 8, 2016 San Francisco ballot regarding responsibility for maintaining street trees and surrounding sidewalks. Voters were asked if the City should amend the City Charter to transfer responsibility from property owners to the City for maintaining trees on sidewalks adjacent to their property, as well for repairing sidewalks damaged by the trees. Prop E passed with almost 80% of the voters\xe2\x80\x99 support. As part of this proposition, a SF tree census was conducted by [SF Public Works](http://sfpublicworks.org/trees).\n\n### Content: \n18 columns of data includes address (including lat/longs), caretaker details, legal details, size of plot, time of planting, surrounding site context, and species.\n\n### Acknowledgements: \nThis data was collected by [SF Public Works](http://sfpublicworks.org/trees). You can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the [data on BigQuery, too](https://cloud.google.com/bigquery/public-data/).\n\n### Inspiration: \n* SF is notorious for it\xe2\x80\x99s microclimates--can you identify zones from particular trees that thrive there?\n* Combine this data with the [NYC Tree Census](https://www.kaggle.com/nycparks/tree-census)--which species are most common? least?'","b""['climate', 'geography', 'nature', 'civil engineering', 'medium', 'featured']""",https://www.kaggle.com/jboysen/sf-street-trees
b'HappyDB',"b'A Corpus of 100,000 Crowdsourced Happy Moments'","b'## Description:\nHappyDB is a corpus of more than 100,000 happy moments crowd-sourced via Amazon\xe2\x80\x99s Mechanical Turk.\n\n> Each worker is given the following task:\nWhat made you happy today? Reflect on the past 24 hours, and recall three actual events that happened to you that made you happy. Write down your happy moment in a complete sentence.\n(Write three such moments.)\n\nThe goal of the corpus is to advance the understanding of the causes of happiness through text-based reflection.\n\nMore information is available on the HappyDB website (https://rit-public.github.io/HappyDB/).\n\n## Content:\n\n- *cleaned\\_hm.csv:* the cleaned-up corpus of 100,000 crowd-sourced happy moments.\nFor cleaning up, we have done spell checking over the whole corpus, and remove empty or one-word statements.\nThe raw happy moments are retained for reference, and the author of each happy\nmoment is represented by the his/her worker ID.\n\n- *demographic.csv:* the demographic information of the worker who provided the\nmoment. \nThe information includes worker id, age, country, gender, marital status, and\nstatus of parenthood.\n\nHave fun with the data!\nFeel free to contact us with any questions.\n\n## Sample questions:\nTo provide some inspiration, here are a few sample interesting exploration questions.\n\n- What are the popular sports/movies/books/purchased products/tourist destinations/... that make people happy?\n- Can we predict gender/marriage status/parenthood/age groups based on happy moment texts?\n- How many indoor and outdoor activities are in the corpus respectively?\n- Can we find interesting ways of clustering happy moments?\n\n## Citation:\nPlease cite the following publication if you are using the dataset for your work: \n\n*HappyDB: A Corpus of 100,000 Crowdsourced Happy Moments, LREC 2018 (to appear)* \n\nAkari Asai, Sara Evensen, Behzad Golshan, Alon Halevy, Vivian Li, Andrei\nLopatenko, Daniela Stepanov, Yoshihiko Suhara, Wang-Chiew Tan and Yinzhan Xu'","b""['linguistics', 'emotion', 'personal life', 'small', 'featured']""",https://www.kaggle.com/ritresearch/happydb
b'NYC Locations Providing Seasonal Flu Vaccinations',b'From New York City Open Data',"b""### Content  \n\nLocation and facility information for places in New York City providing seasonal flu vaccinations.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/IzZaM0B7cQU) by [Alexander Londo\xc3\xb1o](https://unsplash.com/@birdseyehtx) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'health', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-locations-providing-seasonal-flu-vaccinations
b'Chicago Sidewalk Cafe Permits',b'From City of Chicago Open Data',"b""### Content  \n\nA list of permits for sidewalk cafes -- outdoor restaurant seating on the public way.  Businesses may begin sidewalk cafe operations on March 1 and operate through December 1.\r\n\r\nFor more information on this type of permit, see https://www.cityofchicago.org/city/en/depts/bacp/supp_info/sidewalk_cafe_current_permits.html.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Kwdp-0pok-I) by [Nafinia Putra](https://unsplash.com/@nputra) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'business', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-sidewalk-cafe-permits
b'CMS National Summary of Inpatient Charge Data',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain, NA""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/cms-national-summary-of-inpatient-charge-data
b'Dark Net Marketplace Data (Agora 2014-2015)',"b'Includes over 100,000 unique listings of drugs, weapons and more'","b'### Context\n\nThis data set was made from an html rip made by reddit user ""usheep"" who threatened to expose all the vendors on Agora to the police if they did not meet his demands (sending him a small monetary amount ~few hundred dollars in exchange for him not leaking their info). Most information about what happened to ""usheep"" and his threats is nonexistent. He posted the html rip and was never heard from again. Agora shut down a few months after. It is unknown if this was related to ""usheep"" or not, but the raw html data remained. \n\n### Content\n\nThis is a data parse of marketplace data ripped from Agora (a dark/deep web) marketplace from the years 2014 to 2015. It contains drugs, weapons, books, services, and more. Duplicate listings have been removed and prices have been averaged of any duplicates. All of the data is in a csv file and has over 100,000 unique listings. \n\nIt is organized by:\n\n***Vendor:*** The seller<br>\n***Category:*** Where in the marketplace the item falls under<br>\n***Item:*** The title of the listing<br>\n***Description:*** The description of the listing<br>\n***Price:*** Cost of the item (averaged across any duplicate listings between 2014 and 2015)<br>\n***Origin:*** Where the item is listed to have shipped from<br>\n***Destination:*** Where the item is listed to be shipped to (blank means no information was provided, but mostly likely worldwide. I did not enter worldwide for any blanks however as to not make assumptions)<br>\n***Rating:*** The rating of the seller (a rating of [0 deals] or anything else with ""deals"" in it means there is not concrete rating as the amount of deals is too small for a rating to be displayed)<br>\n***Remarks:*** Only remark options are blank, or ""Average price may be skewed outliar > .5 BTC found"" which is pretty self explanatory.<br>\n\n###Acknowledgements\n\nThough I got this data from a 3rd party, it seems as though it originally came from here: https://www.gwern.net/DNM-archives\nGwern Branwen seems to have complied all of his dark net marketplace leaks and html rips and has a multitude of possible uses for the data at the link above. It is free for anyone to use as long as proper credit is given to the creator. I would be happy to parse more data if anyone would like to request a specific website and/or format.\n\n### Inspiration\n\nThis data could be used to track drug dealers across different platforms. Potentially find correlations between different drugs and from where/to they ship in the world to show correlations between types of drugs and where drug dealers that supply them are located. Prices can estimate drug economies in certain regions of the world. Similar listings from 2 different vendors can perhaps point to competition to corner a market, or even show that some vendors may work together to corner a market. There are quite a few opportunities to do some really great stuff to find correlations between illegal drugs, weapons, and more in order to curb the flow of dark net drug trade by identifying high risk regions or vendors. I can potentially do a new parse of other websites so you can find correlations across websites rather than just within Agora.'","b""['internet', 'crime', 'illegal drugs', 'small', 'featured']""",https://www.kaggle.com/philipjames11/dark-net-marketplace-drug-data-agora-20142015
b'New York City - East River Bicycle Crossings',b'Daily bicycle counts for major bridges in NYC',"b'### Context\n\nThe New York City Department of Transportation collects daily data about the number of bicycles going over bridges in New York City. This data is used to measure bike utilization as a part of transportation planning. This dataset is a daily record of the number of bicycles crossing into or out of Manhattan via one of the East River bridges (that is, excluding Bronx thruways and the non-bikeable Hudson River tunnels) for a stretch of 9 months.\n\n### Content\n\nA count of the number of bicycles on each of the bridges in question is provided on a day-by-day basis, along with information on maximum and minimum temperature and precipitation.\n\n### Acknowledgements\n\nThis data is published in an Excel format by the City of New York ([here](https://data.cityofnewyork.us/Transportation/Bicycle-Counts-for-East-River-Bridges/gua4-p9wg)). It has been processed into a CSV file for use on Kaggle.\n\n### Inspiration\n\n* In this dataset, how many bicycles cross into and out of Manhattan per day?\n* How strongly do weather conditions affect bike volumes?\n* What is the top bridge in terms of bike load?'","b""['cities', 'road transport', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-east-river-bicycle-crossings
b'New York State Executive Budget Appropriations',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/new-york-state-executive-budget-appropriations
b'MaxEnt NE Chunker',b'ACE Named Entity Chunker (Maximum entropy)',"b""### Context\n\nThe `maxent_ne_chunker` contains two pre-trained English named entity chunkers trained on an ACE corpus (perhaps [ACE \nACE 2004 Multilingual Training Corpus]( https://catalog.ldc.upenn.edu/LDC2005T09)?)\n\nIt will load an `nltk.chunk.named_entity.NEChunkParser` object and it is used by the [`nltk.ne_chunk()`](https://github.com/nltk/nltk/blob/develop/nltk/chunk/__init__.py) function.\n\nRobert M. Johnson has written an [excellent expository of what the pre-trained model is doing under the hood](http://mattshomepage.com/articles/2016/May/23/nltk_nec/)\n\nFrom the [relation extraction code](https://github.com/nltk/nltk/blob/develop/nltk/sem/relextract.py#L31) function in NLTK, it lists the following tags for the ACE tagset:\n\n - LOCATION\n - ORGANIZATION\n - PERSON\n - DURATION\n - DATE\n - CARDINAL\n - PERCENT\n - MONEY\n - MEASURE\n - FACILITY\n - GPE\n\n### Content\n\nThe `maxent_ne_chunker.zip` contains\n - **english_ace_binary.pickle**:  Chunks the input POS tagged sentence and labeled positive NEs as `NE`. \n - **english_ace_multiclass.pickle**: Chunks the input POS tagged sentence and outputs the repsective NE labels under the ACE tagset.\n - **PY3**: Subdirectory that contains the Python3 compatiable pickles as above\n\n\n### Acknowledgements\n\nWe're not sure who exactly to credit for this pre-trained model, it'll be great if anyone who knows help to document this on https://github.com/nltk/nltk/issues/1783""","b""['medium', 'featured']""",https://www.kaggle.com/nltkdata/maxent-ne-chunker
b'Chicago Average Daily Traffic Counts',b'From City of Chicago Open Data',"b""### Content  \n\nAverage Daily Traffic (ADT) counts are analogous to a census count of vehicles on city streets. These counts provide a close approximation to the actual number of vehicles passing through a given location on an average weekday. Since it is not possible to count every vehicle on every city street, sample counts are taken along larger streets to get an estimate of traffic on half-mile or one-mile street segments. ADT counts are used by city planners, transportation engineers, real-estate developers, marketers and many others for myriad planning and operational purposes.\nData Owner: Transportation.\nTime Period: 2006.\nFrequency: A citywide count is taken approximately every 10 years. A limited number of traffic counts will be taken and added to the list periodically.\nRelated Applications: Traffic Information Interactive Map (http://webapps.cityofchicago.org/traffic/).  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/CvGHUJ2qA14) by [Omar Prestwich](https://unsplash.com/@omarprestwich) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-average-daily-traffic-counts
b'NYS Hydropower Allocations',b'From New York State Open Data',"b""### Content  \n\nThis dataset contains the New York Power Authority\xe2\x80\x99s hydropower customers having an allocation of Expansion Power, Replacement Power, and/or Preservation Power, including their location, amount of allocation, and amount of jobs committed.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/FUeb2npsblQ) by [American Public Power Association](https://unsplash.com/@publicpowerorg) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-hydropower-allocations
b'National Accounts',b'Global GDP & Government Expenditures since 1946',"b'The Economic Statistics Branch of the United Nations Statistics Division (UNSD) maintains and annually updates the National Accounts Official Country Data database. This work is carried out in accordance with the recommendation of the Statistical Commission at its first session that the Statistics Division of the United Nations should publish regularly the most recent available data on national accounts for as many countries and areas as possible. The database contains detailed official national accounts statistics in national currencies as provided by the National Statistical Offices. \n\nData are available for most of the countries or areas of the world and form a valuable source of information on their economies. The database contains data as far back as 1946, up to the year t-1, with data for most countries available from the 1970s. The database covers not only national accounts main aggregates such as gross domestic product, national income, saving, value added by industry and household and government consumption expenditure and its relationships; but also detailed statistics for institutional sectors (including the rest of the world), comprising the production account, the generation of income account, the allocation of primary income account, the secondary distribution of income account, the use of disposable income account, the capital account and the financial account, if they are compiled by countries. \n\nThe statistics for each country or area are presented according to the uniform table headings and classifications as recommended in the United Nations System of National Accounts 1993 (1993 SNA). A summary of the 1993 SNA conceptual framework, classifications and definitions are included in the yearly publication \xe2\x80\x9cNational Accounts Statistics, Main Aggregates and Detailed Tables\xe2\x80\x9d.\n\n### Acknowledgements\n\nThis dataset was kindly published by the United Nation on the UNData site. You can find [the original dataset here](http://data.un.org/Explorer.aspx).\n\n### License\n[Per the UNData terms of use](http://data.un.org/Host.aspx?Content=UNdataUse): all data and metadata provided on UNdata\xe2\x80\x99s website are available free of charge and may be copied freely, duplicated and further distributed provided that [UNdata](http://data.un.org/Explorer.aspx) is cited as the reference. '","b""['economics', 'medium', 'featured']""",https://www.kaggle.com/unitednations/national-accounts
b'English Word Frequency',b'\xe2\x85\x93 Million Most Frequent English Words on the Web',"b'### Context: \n\nHow frequently a word occurs in a language is an important piece of information for natural language processing and linguists. In natural language processing, very frequent words tend to be less informative than less frequent one and are often removed during preprocessing. Human language users are also sensitive to  word frequency. How often a word is used affects language processing in humans. For example, [very frequent words are read and understood more quickly](http://econtent.hogrefe.com/doi/abs/10.1027/1618-3169/a000123?journalCode=zea) and can be [understood more easily in background noise](http://asa.scitation.org/doi/abs/10.1121/1.1918432).\n\n### Content: \n\nThis dataset contains the counts of the 333,333 most commonly-used single words on the English language web, as derived from the Google Web Trillion Word Corpus.\n\n### Acknowledgements: \n\nData files were derived from the Google Web Trillion Word Corpus (as [described](https://research.googleblog.com/2006/08/all-our-n-gram-are-belong-to-you.html) by Thorsten Brants and Alex Franz, and [distributed](https://catalog.ldc.upenn.edu/LDC2006T13) by the Linguistic Data Consortium) by Peter Norvig. You can find more information on these files and the code used to generate them [here](http://norvig.com/ngrams/).\n\nThe code used to generate this dataset is distributed under the [MIT License](https://en.wikipedia.org/wiki/MIT_License). \n\n### Inspiration:\n\n* Can you tag the part of speech of these words? Which parts of speech are most frequent? Is this similar to other languages, like [Japanese](https://www.kaggle.com/rtatman/japanese-lemma-frequency)?\n* What differences are there between the very frequent words in this dataset, and the the frequent words in other corpora, such as the [Brown Corpus](https://www.kaggle.com/nltkdata/brown-corpus) or the [TIMIT corpus](https://www.kaggle.com/nltkdata/timitcorpus)? What might these differences tell us about how language is used? '","b""['internet', 'linguistics', 'languages', 'small', 'featured']""",https://www.kaggle.com/rtatman/english-word-frequency
b'OpenCorpora: Russian',b'A Tagged 1.5 Million Word Corpus of Russian',"b'### Context: \n\n\xe2\x80\x9cRussian is an East Slavic language and an official language in Russia, Belarus, Kazakhstan, Kyrgyzstan and many minor or unrecognised territories. It is an unofficial but widely spoken language in Ukraine and Latvia, and to a lesser extent, the other countries that were once constituent republics of the Soviet Union and former participants of the Eastern Bloc.\xe2\x80\x9d -- [\xe2\x80\x9cRussian Language\xe2\x80\x9d on Wikipedia](https://en.wikipedia.org/wiki/Russian_language)\n\nRussian has around 150 million native speakers and 110 million non-native speakers. Russian in written in [Cyrillic script](https://en.wikipedia.org/wiki/Cyrillic_script). This dataset is a morphologically, syntactically and semantically annotated corpus of texts in Russian, fully accessible to researchers and edited by users.\n\n### Content: \n\nThis dataset is encoded in UTF-8. There are two files included in this dataset: the corpus and the dictionary. The corpus is in .json format, while the dictionary is in plain text. \n\n#### Dictionary\nIn the dictionary, each entry is a lemma, presented with all of its tagged derivations. The tags depend on the part of speech of the lemma. Some examples are:\n\n* Nouns: part of speech, animacy, gender & number, case\n* Verbs: Part of speech, aspect, transitivity, gender & number, person, tense, mood\n* Adjectives: part of speech (ADJF), gender, number, case\n\nA Python script to convert the tags in this corpus to [this set](https://en.wikipedia.org/wiki/List_of_glossing_abbreviations) more commonly used in English-language linguistics can be found [here](https://github.com/kmike/russian-tagsets/blob/master/russian_tagsets/ruscorpora.py).\n\nSample dictionary entries: \n\n    1\n    \xd0\x81\xd0\x96\tNOUN,anim,masc sing,nomn\n    \xd0\x95\xd0\x96\xd0\x90\tNOUN,anim,masc sing,gent\n    \xd0\x95\xd0\x96\xd0\xa3\tNOUN,anim,masc sing,datv\n    \xd0\x95\xd0\x96\xd0\x90\tNOUN,anim,masc sing,accs\n    \xd0\x95\xd0\x96\xd0\x9e\xd0\x9c\tNOUN,anim,masc sing,ablt\n    \xd0\x95\xd0\x96\xd0\x95\tNOUN,anim,masc sing,loct\n    \xd0\x95\xd0\x96\xd0\x98\tNOUN,anim,masc plur,nomn\n    \xd0\x95\xd0\x96\xd0\x95\xd0\x99\tNOUN,anim,masc plur,gent\n    \xd0\x95\xd0\x96\xd0\x90\xd0\x9c\tNOUN,anim,masc plur,datv\n\n    41\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\xae\tVERB,impf,intr sing,1per,pres,indc\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\x95\xd0\x9c\tVERB,impf,intr plur,1per,pres,indc\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\x95\xd0\xa8\xd0\xac\tVERB,impf,intr sing,2per,pres,indc\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\x95\xd0\xa2\xd0\x95\tVERB,impf,intr plur,2per,pres,indc\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\x95\xd0\xa2\tVERB,impf,intr sing,3per,pres,indc\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\xae\xd0\xa2\tVERB,impf,intr plur,3per,pres,indc\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\x9b\tVERB,impf,intr masc,sing,past,indc\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\x9b\xd0\x90\tVERB,impf,intr femn,sing,past,indc\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\x9b\xd0\x9e\tVERB,impf,intr neut,sing,past,indc\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\x9b\xd0\x98\tVERB,impf,intr plur,past,indc\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\x99\tVERB,impf,intr sing,impr,excl\n    \xd0\x81\xd0\xa0\xd0\x9d\xd0\x98\xd0\xa7\xd0\x90\xd0\x99\xd0\xa2\xd0\x95\tVERB,impf,intr plur,impr,excl\n\n#### Corpous\n\nIn this corpus, each word has been grammatically tagged. You can access individual tokens using the following general path: \n\nJSON > text > paragraphs > paragraph > [paragraph number] > sentence > [sentence number] > tokens > [token number] \n\nEach token has: \n* A unique id  number (@id)\n* The text of the token (@text)\n* information on the lemma (under \xe2\x80\x9cl\xe2\x80\x9d), including the id number of the lemma as found in the dictionary\n\nYou can see an example of the token portion of the .json structure below:\n\n                 {\n                    ""@id"": 1714292,\n                    ""@text"": ""\xd1\x81\xd0\xb2\xd0\xb0\xd1\x82"",\n                    ""tfr"": {\n                      ""@t"": ""\xd1\x81\xd0\xb2\xd0\xb0\xd1\x82"",\n                      ""@rev_id"": 3754311,\n                      ""v"": {\n                        ""l"": {\n                          ""@id"": 314741,\n                          ""@t"": ""\xd1\x81\xd0\xb2\xd0\xb0\xd1\x82"",\n                          ""g"": [\n                            {\n                              ""@v"": ""NOUN""\n                            },\n                            {\n                              ""@v"": ""anim""\n                            },\n                            {\n                              ""@v"": ""masc""\n                            },\n                            {\n                              ""@v"": ""sing""\n                            },\n                            {\n                              ""@v"": ""nomn""\n                            }\n                          ]\n                        }\n                      }\n                }\n              }\n\n### Acknowledgements: \n\nThis dataset was collected and annotated by, among others, Svetlana Alekseeva, Anastasia Bodrova, Victor Bocharov, Dmitry Granovsky, Irina Krylova, Maria Nikolaeva, Catherine Protopopova, Alexander Chuchunkov, Anastasia Shimorina, Vasily Alekseev, Natalia Ostapuk, Maria Stepanova and Alexey Surikov. The code used to collect and clean this data is [available online](https://github.com/OpenCorpora/opencorpora).\n\nIt is reproduced here under a [CC-BY-SA license](https://creativecommons.org/licenses/by-sa/3.0/deed.ru).\n\nMore information on this corpus and its most recent version can be found [here (in Russian.)](http://opencorpora.org/)\n\n'","b""['linguistics', 'languages', 'russia', 'medium', 'featured']""",https://www.kaggle.com/rtatman/opencorpora-russian
b'FiveThirtyEight College Majors Dataset',b'Explore Data from FiveThirtyEight',"b""  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.  \n\n[Cover photo](https://unsplash.com/photos/AEdeZdlGn3Q) by [Daoudi Aissa](https://unsplash.com/@dannyeve) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-college-majors-dataset
b'MSME Country Indicators and Sources',b'From World Bank Financial Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](finances.worldbank.org) and they update their information according the amount of data that is brought in. Explore World Bank's Financial Data using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.\n\nThis dataset is distributed under a [Creative Commons Attribution 3.0 IGO](https://creativecommons.org/licenses/by/3.0/igo/) license.  \n\nThis dataset is distributed under the following licenses: Creative Commons Attribution 3.0 IGO""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/theworldbank/msme-country-indicators-and-sources
b'Austin Weather',"b'Historical temperature, precipitation, humidity, and windspeed for Austin, Texas'","b""### Context\nThis dataset is meant to complement the [Austin Bikesharing Dataset](https://www.kaggle.com/jboysen/austin-bike).\n\n### Content\nContains the:  \n**Date** (YYYY-MM-DD)  \n**TempHighF** (High temperature, in Fahrenheit)  \n**TempAvgF** (Average temperature, in Fahrenheit)  \n**TempLowF** (Low temperature, in Fahrenheit)  \n**DewPointHighF** (High dew point, in Fahrenheit)  \n**DewPointAvgF** (Average dew point, in Fahrenheit)  \n**DewPointLowF** (Low dew point, in Fahrenheit)  \n**HumidityHighPercent** (High humidity, as a percentage)  \n**HumidityAvgPercent** (Average humidity, as a percentage)  \n**HumidityLowPercent** (Low humidity, as a percentage)  \n**SeaLevelPressureHighInches** (High sea level pressure, in inches)  \n**SeaLevelPressureAvgInches** (Average sea level pressure, in inches)  \n**SeaLevelPressureLowInches** (Low sea level pressure, in inches)  \n**VisibilityHighMiles** (High visibility, in miles)  \n**VisibilityAvgMiles** (Average visibility, in miles)  \n**VisibilityLowMiles** (Low visibility, in miles)  \n**WindHighMPH** (High wind speed, in miles per hour)  \n**WindAvgMPH** (Average wind speed, in miles per hour)  \n**WindGustMPH** (Highest wind speed gust, in miles per hour)  \n**PrecipitationSumInches** (Total precipitation, in inches)  ('T' if Trace)  \n**Events** (Adverse weather events.  ' ' if None)  \n\nThis dataset contains data for every date from 2013-12-21 to 2017-07-31.\n\n### Acknowledgements\nThis dataset was obtained from WeatherUnderground.com, at the [Austin KATT station](https://www.wunderground.com/history/airport/KATT/).\n\n### Inspiration\nCan we use this dataset to explain some of the variation in the [Austin Bikesharing Dataset](https://www.kaggle.com/jboysen/austin-bike)?""","b""['utility', 'small', 'featured']""",https://www.kaggle.com/grubenm/austin-weather
b'Forest Cover Type Dataset',b'Tree types found in the Roosevelt National Forest in Colorado',"b'### Context\n\nThis dataset contains tree observations from four areas of the Roosevelt National Forest in Colorado. All observations are cartographic variables (no remote sensing) from 30 meter x 30 meter sections of forest. There are over half a million measurements total!\n\n### Content\n\nThis dataset includes information on tree type, shadow coverage, distance to nearby landmarks (roads etcetera), soil type, and local topography.\n\n### Acknowledgement\n\nThis dataset is part of the UCI Machine Learning Repository, and the original source can be found [here](https://archive.ics.uci.edu/ml/datasets/Covertype). The original database owners are Jock A. Blackard, Dr. Denis J. Dean, and Dr. Charles W. Anderson of the Remote Sensing and GIS Program at Colorado State University. \n\n### Inspiration\n\n* Can you build a model that predicts what types of trees grow in an area based on the surrounding characteristics? A past Kaggle competition project on this topic can be found [here](https://www.kaggle.com/c/forest-cover-type-prediction).\n* What kinds of trees are most common in the Roosevelt National Forest?\n* Which tree types can grow in more diverse environments? Are there certain tree types that are sensitive to an environmental factor, such as elevation or soil type?'","b""['plants', 'ecology', 'botany', 'medium', 'featured']""",https://www.kaggle.com/uciml/forest-cover-type-dataset
b'NYS Waterbody Classifications',b'From New York State Open Data',"b'### Content  \n\nThis data set provides the water quality classifications of New York State\'s lakes, rivers, streams and ponds, collectively referred to as waterbodies. All water bodies in the state are provided a water quality classification based on existing, or expected best usage, of each waterbody or waterbody segment. Under New York State\'s Environmental Conservation Law (ECL), Title 5 of Article 15, certain waters of the state are protected on the basis of their classification. Streams and small waterbodies located in the course of a stream that are designated as C (T) or higher (i.e., C (TS), B, or A) are collectively referred to as ""protected streams.""  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/kNIDFv5ee_g) by [Yuriy Garnaev](https://unsplash.com/@ygar) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-waterbody-classifications
b'NY Borough Enrollment Offices',b'From New York City Open Data',"b""### Content  \n\nDepartment of Education borough enrollment offices  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/QZub8Ni3x_c) by [Jony Ariadi](https://unsplash.com/@joniastin) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'education', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-borough-enrollment-offices
b'Bias Media CAT',b'Sentiment Bias of News on Catalonia Independence Crisis',"b'# What I talk about when I talk about Catalonia\nThis is my grain of sand to help in the Catalonia [Independence][1] crisis. The Iberian media has been a key driver to incubate disaffection between Catalonia and Spain. For example, a leading newspaper tweeted boycott and Catalonia [9 times][6] in the last month. In this dataset we analyze:\n\n- [tweets][6] \n- topics of [tweets][8] and \n- sentiment differentials in [news][7] \n\n![fig1][4]\n### Context\nThe [dramatic][5] Catalonia independence crisis offers a unique opportunity to analyze bias in news reporting as opinions on the issue are quite polarized (See #catalanReferendum on twitter). In this dataset, we compare how different newspapers (NYT, Washington-Post, Bloomberg...) have reported one singular specific event in the saga: The reply of the Spanish Government to M.H. Puigdemont speech of October 11th of 2017. \nFor each of the 30 newspapers considered, the most popular news article that reported this news is represented as a row in the dataset.  Why this news? The Spanish government, published a pdf called (""requerimiento"") which was faxed to Puigdemont. The document requires that  Puigdemont reply in five days a clarification of the meaning of his speech. \nThis ""clean"" news offers a rare example where the news is about a written document rather than a speech or an action (usually subjected to more interpretations and biases)\n\n### Content\n- news_...csv each row contains the news article and its translation to English.\n- all3.csv contains 100k tweets.\n\n### Acknowledgements\nAll the journalists who made this dataset possible. Thanks to @DataCanary for helping make the visualizations better!\n\n### Inspiration\nI always thought that sentiment analysis was a useless topic, but here there is a chance to use an objective measure to show how polarized reporting has become, (even if sentiment does not account for fakenews, nuances or sarcasm). The linear regressions shows that news written in Spanish language are less positive about the event than the global mean. In other words, sentiment seems strongly biased by language. Bias by location of the newspapers is also analyzed. \n### Disclaimer\nNote that the \'bing\' scale is used. Other scales such AFINN might yield different results.\n\n  [1]: https://en.wikipedia.org/wiki/Catalan_independence#2017_referendum\n  [2]: https://www.kaggle.io/svf/1670183/ed71332d0833236e33cb23ae4f952a1c/__results___files/figure-html/unnamed-chunk-5-1.png\n  [3]: https://www.kaggle.com/harriken/bias-news/output\n  [4]: https://1.bp.blogspot.com/-uADXuUKpRJg/WeT67Sq-PVI/AAAAAAAACow/MN7UNgZsy20MMSod-ZzmR0uUwtJYQpAvwCLcBGAs/s1600/Screen%2BShot%2B2017-10-16%2Bat%2B10.22.20%2BPM.png\n  [5]: http://bit.ly/2xJUOVV\n  [6]: https://www.kaggle.com/harriken/what-i-talk-about-when-i-talk-about-catalonia\n  [7]: https://www.kaggle.com/diamazov/location-bias\n  [8]: https://www.kaggle.com/harriken/the-great-catalan-cyberwar-gensim\n'","b""['linguistics', 'politics', 'journalism', 'cognitive biases', 'biases', 'medium', 'featured']""",https://www.kaggle.com/harriken/bias-media-cat
b'DeepSat (SAT-6) Airborne Dataset',"b'405,000 image patches each of size 28x28 and covering 6 landcover classes '","b'### DeepSat SAT-6\n![Sample images][1]<br><br>\nOriginally, images were extracted from the National Agriculture Imagery Program (NAIP) dataset. The NAIP dataset consists of a total of 330,000 scenes spanning the whole of the Continental United States (CONUS). The authors used the uncompressed digital Ortho quarter quad tiles (DOQQs) which are GeoTIFF images and the area corresponds to the United States Geological Survey (USGS) topographic quadrangles. The average image tiles are ~6000 pixels in width and ~7000 pixels in height, measuring around 200 megabytes each. The entire NAIP dataset for CONUS is ~65 terabytes. The imagery is acquired at a 1-m ground sample distance (GSD) with a horizontal accuracy that lies within six meters of photo-identifiable ground control points.\n\nThe images consist of 4 bands - red, green, blue and Near Infrared (NIR). In order to maintain the high variance inherent in the entire NAIP dataset, we sample image patches from a multitude of scenes (a total of 1500 image tiles) covering different landscapes like rural areas, urban areas, densely forested, mountainous terrain, small to large water bodies, agricultural areas, etc. covering the whole state of California. An image labeling tool developed as part of this study was used to manually label uniform image patches belonging to a particular landcover class. \n\nOnce labeled, 28x28 non-overlapping sliding window blocks were extracted from the uniform image patch and saved to the dataset with the corresponding label. We chose 28x28 as the window size to maintain a significantly bigger context, and at the same time not to make it as big as to drop the relative statistical properties of the target class conditional distributions within the contextual window. Care was taken to avoid interclass overlaps within a selected and labeled image patch.\n\n### Content\n\n- Each sample image is 28x28 pixels and consists of 4 bands - red, green, blue and near infrared. \n\n- The training and test labels are one-hot encoded 1x6 vectors\n\n- The six classes represent the six broad land covers which include barren land, trees, grassland, roads, buildings and water bodies. \n\n- Training and test datasets belong to disjoint set of image tiles. \n\n- Each image patch is size normalized to 28x28 pixels.\n\n- Once generated, both the training and testing datasets were randomized using a pseudo-random number generator. \n\n### CSV files<br>\n- X_train_sat6.csv: 324,000 training images, 28x28 images each with 4 channels <br>\n- y_train_sat6.csv: 324,000 training labels, 1x6 one-hot encoded vectors <br>\n- X_test_sat6.csv: 81,000 training images, 28x28 images each with 4 channels <br>\n- y_test_sat6.csv: 81,000 training labels, 1x6 one-hot encoded vectors <br>\n\n### The original MAT file <br>\n- train_x:\t28x28x6x324000 uint8 (containing 400000 training samples of 28x28 images each with 4 channels)<br>\n- train_y:\t324,000x6 uint8 (containing 6x1 vectors having labels for the 400000 training samples)<br>\n- test_x:\t28x28x6x18000 uint8 (containing 100000 test samples of 28x28 images each with 4 channels)<br>\n- test_y:\t81,000x6 uint8 (containing 6x1 vectors having labels for the 100000 test samples)<br>\n\n### Acknowledgements\n\nThe original MATLAB file was converted to multiple CSV files \n\nThe original SAT-4 and SAT-6 airborne datasets can be found here:<br>\n[http://csc.lsu.edu/~saikat/deepsat/][2]<br>\n\nThanks to:<br>\nSaikat Basu, Robert DiBiano, Manohar Karki and Supratik Mukhopadhyay, Louisiana State University\nSangram Ganguly, Bay Area Environmental Research Institute/NASA Ames Research Center\nRamakrishna R. Nemani, NASA Advanced Supercomputing Division, NASA Ames Research Center\n\n\n\n  [1]: http://csc.lsu.edu/~saikat/deepsat/images/sat_img.png\n  [2]: http://csc.lsu.edu/~saikat/deepsat/'","b""['image data', 'multiclass classification', 'geography', 'machine learning', 'large', 'featured']""",https://www.kaggle.com/crawford/deepsat-sat6
b'Chicago Taxi Rides 2016',b'Details of taxi rides in Chicago',"b'### Context\n\nThis dataset includes taxi trips for 2016, reported to the City of Chicago in its role as a regulatory agency. To protect privacy but allow for aggregate analyses, the Taxi ID is consistent for any given taxi medallion number but does not show the number, Census Tracts are suppressed in some cases, and times are rounded to the nearest 15 minutes. Due to the data reporting process, not all trips are reported but the City believes that most are. See http://digital.cityofchicago.org/index.php/chicago-taxi-data-released for more information about this dataset and how it was created.\n\n### Content\n\nPlease see the data dictionary for details of specific fields. We also shrunk the original files by roughly two thirds by dropping redundant columns and remapping several others to use shorter IDs. For example, the taxi_id column used to be a 128 character string. We\xe2\x80\x99ve replaced it with an integer containing at most four digits.\n\nThe redundant columns were unique_key, pickup_location, and dropoff_location. The remapped columns were taxi_id, company, pickup_census_tract, dropoff_census_tract, pickup_latitude, pickup_longitude, dropoff_latitude, and dropoff_longitude. The original versions of those columns can be unpacked using the column_remapping.json.\n\n### Acknowledgements\n\nThis dataset was kindly made publically available by the City of Chicago at: https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew\n\nPlease note that this site provides applications using data that has been modified for use from its original source, www.cityofchicago.org, the official website of the City of Chicago.  The City of Chicago makes no claims as to the content, accuracy, timeliness, or completeness of any of the data provided at this site.  The data provided at this site is subject to change at any time.  It is understood that the data provided at this site is being used at one\xe2\x80\x99s own risk.\n\n### Inspiration\n\n - How centralized is Chicago? In other words, what portion of trips are\n   to or from downtown?\n - Chicago has an extensive metro system. Are taxis competing with the\n   trains by covering similar routes or supplementing public transit by\n   getting people to and from train stations?\n\n### Use this dataset with BigQuery\nYou can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the data on BigQuery, too: https://cloud.google.com/bigquery/public-data/chicago-taxi.\nBigQuery hosts the full version of this dataset, which extends from 2013 through the present.'","b""['road transport', 'large', 'featured']""",https://www.kaggle.com/chicago/chicago-taxi-rides-2016
b'Bagrut grades in Israeli high schools (2013-2016)',"b'Over 60,000 average Bagrut grades in Israel'","b""# Info\n\n**Te'udat Bagrut** (Hebrew: \xd7\xaa\xd7\xa2\xd7\x95\xd7\x93\xd7\xaa \xd7\x91\xd7\x92\xd7\xa8\xd7\x95\xd7\xaa\xe2\x80\xac) is a certificate which attests that a student has successfully passed Israel's high school matriculation examination. Bagrut is a prerequisite for higher education in Israel. A Bagrut certificate is awarded to students who pass the required written (and in some cases oral) subject-matter examinations with a passing mark (56% or higher) in each exam. The Bagrut certificate however should not be confused with a high school diploma (te'udat g'mar tichon, Hebrew: \xd7\xaa\xd7\xa2\xd7\x95\xd7\x93\xd7\xaa \xd7\x92\xd7\x9e\xd7\xa8 \xd7\xaa\xd7\x99\xd7\x9b\xd7\x95\xd7\x9f\xe2\x80\xac), which is a certificate awarded by the Ministry of Education attesting that a student has completed 12 years of study. (Source: Wikipedia)\n\n\n# Content\n\nThis file contains over 60,000 average Bagrut grades that were taken between 2013 and 2016 by over 1800 schools in various subjects.\n\nThis data was posted under the Israeli Freedom of Information law and was formatted by me""","b""['education', 'small', 'featured']""",https://www.kaggle.com/emachlev/bagrut-israel
b'2018 World Cup',b'FiveThirtyEight Predictions',"b'### Acknowledgements\n\nREADME.md at [GitHub][1]:\n\n""See https://data.fivethirtyeight.com/ for a list of the data and code we\'ve published. \n\nUnless otherwise noted, our data sets are available under the Creative Commons Attribution 4.0 International License, and the code is available under the MIT License. If you find this information useful, please let us know.""\n\n  [1]: https://github.com/fivethirtyeight/data'","b""['sports', 'association football', 'small', 'featured']""",https://www.kaggle.com/chauce/2018-world-cup-predictions
b'Santa Barbara Corpus of Spoken American English',"b'Transcribed recordings of natural, conversational speech'","b'### Context: \n\nThe Santa Barbara Corpus of Spoken American English is based on hundreds of recordings of natural speech from all over the United States, representing a wide variety of people of different regional origins, ages, occupations, and ethnic and social backgrounds. It reflects many ways that people use language in their lives: conversation, gossip, arguments, on-the-job talk, card games, city council meetings, sales pitches, classroom lectures, political speeches, bedtime stories, sermons, weddings, and more. The corpus was collected by the University of California, Santa Barbara Center for the Study of Discourse, Director John W. Du Bois (UCSB), Associate Editors: Wallace L. Chafe (UCSB), Charles Meyer (UMass, Boston), and Sandra A. Thompson (UCSB).\n\nEach speech file is accompanied by a transcript in which phrases are time stamped with respect to the audio recording. Personal names, place names, phone numbers, etc., in the transcripts have been altered to preserve the anonymity of the speakers and their acquaintances and the audio files have been filtered to make these portions of the recordings unrecognizable. Pitch information is still recoverable from these filtered portions of the recordings, but the amplitude levels in these regions have been reduced relative to the original signal. The audio data consists of MP3 format speech files, recorded in two-channel pcm, at 22050Hz.\n\n### Contents: \n\nThis dataset contains part one of the corpus. The other three parts and additional information can be found [here](http://www.linguistics.ucsb.edu/research/santa-barbara-corpus#Contents). The following information is included in this dataset:\n\n* Recordings: 14 recordings as .mp3 files\n* Transcripts: Time-aligned transcripts for all 14 recordings, in the [CHAT format](http://childes.talkbank.org/)\n* Metadata: A .csv with demographic information on speakers, as well as which recordings they appear in. (Some talkers appear in more than one recording.)\n\n\n### Acknowledgements: \n\nThe Santa Barbara Corpus was compiled by researchers in the Linguistics Department of the University of California, Santa Barbara. The Director of the Santa Barbara Corpus is John W. Du Bois, working with Associate Editors Wallace L. Chafe and Sandra A. Thompson (all of UC Santa Barbara), and Charles Meyer (UMass, Boston). For the publication of Parts 3 and 4, the authors are John W. Du Bois and Robert Englebretson.\n\nIt is distributed here under an [CC BY-ND 3.0 US license]( https://creativecommons.org/licenses/by-nd/3.0/us/).\n\n### Inspiration: \n\n* Currently, the transcriptions are close transcriptions and include disfluencies and overlaps. Can you use NLP to convert them to broad transcriptions without this information?\n* Can you create a phone-aligned transcription of this dataset? You might find it helpful to use [forced alignment](https://www.eleanorchodroff.com/tutorial/kaldi/kaldi-forcedalignment.html). '","b""['linguistics', 'languages', 'large', 'featured']""",https://www.kaggle.com/rtatman/santa-barbara-corpus-of-spoken-american-english
b'U.S. Federal Superfund Sites',"b'The most polluted sites in the US, from free-form text to socioeconomics'","b""### Context\n\nFederal Superfund sites are some of the most polluted in the United States.  This dataset contains a multifaceted view of Superfunds, including free-form text descriptions, geography, demographics and socioeconomics.\n\n\n### Content\n\nThe core data was scraped from the [National Priorities List (NPL)](https://www.epa.gov/superfund/national-priorities-list-npl-sites-state) provided by the U.S. Environmental Protection Agency (EPA).  This table provides basic information such as site name, site score, date added, and links to a site description and current status.  Apache Tika was used to extract text from the site description pdfs.  The addresses were scraped from site status pages, and used to geocode to latitude and longitude and Census block group.  The block group assignment was used to join with the Census Bureau's [planning database](https://www.census.gov/research/data/planning_database/2015/), a rich source of nationwide demographic and socioeconomic data.  The full source code used to generate the data can be found [here, on github](https://github.com/4d4stra/Federal_Superfunds).\n\nI have provided three separate downloads to explore:\n\n - priorities_list_full.json: the NPL containing all geographic, site information, text descriptions, and Census Bureau data from the relevant block groups.\n - pdb_tract.csv: the planning database aggregated on the tract level with an additional indicator (has_superfund) noting whether or not the tract contains the address of a Superfund site.\n - pdb_block_group.csv: the planning database aggregated on the block group level with an additional indicator (has_superfund) noting whether or not the block group contains the address of a Superfund site.\n\nSome caveats:\n\n 1. The planning database contains 300+ columns.  For a full description of these columns, please see the documentation [here](https://www.census.gov/research/data/planning_database/2015/).\n 2. Since the Google geocoder is relatively aggressive in providing address matches, geocoding was done through a hierarchy of queries (full address, city-state-zip, and zipcode only) to prevent gross errors.  The address string used to geocode is noted through the 'geocode_source' column.\n 3. While this data is linked to demographic and socioeconomic data based on either the block group (tract for pdb_tract.csv), the impacts of a particular site's pollution may extend beyond these geographic regions.\n\n### Acknowledgements\n\nI would like to thank the EPA and the Census Bureau for making such detailed information publicly available.  For relevant academic work, please see [Burwell-Naney et al. (2013)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4228303/) and references, both to and therein.\n\nPlease let me know if you have any suggestions for improving the dataset!""","b""['linguistics', 'demographics', 'pollution', 'sociology', 'medium', 'featured']""",https://www.kaggle.com/srrobert50/federal-superfunds
b'Common Voice',"b'500 hours of speech recordings, with speaker demographics'","b""### General Information\n\nCommon Voice is a corpus of speech data read by users on the Common Voice website (http://voice.mozilla.org/), and based upon text from a number of public domain sources like user submitted blog posts, old books, movies, and other public speech corpora. Its primary purpose is to enable the training and testing of automatic speech recognition (ASR) systems.\n\n### Structure\n\nThe corpus is split into several parts for your convenience. The subsets with \xe2\x80\x9cvalid\xe2\x80\x9d in their name are audio clips that have had at least 2 people listen to them, and the majority of those listeners say the audio matches the text. The subsets with \xe2\x80\x9cinvalid\xe2\x80\x9d in their name are clips that have had at least 2 listeners, and the majority say the audio does *not* match the clip. All other clips, ie. those with fewer than 2 votes, or those that have equal valid and invalid votes, have \xe2\x80\x9cother\xe2\x80\x9d in their name.\n\nThe \xe2\x80\x9cvalid\xe2\x80\x9d and \xe2\x80\x9cother\xe2\x80\x9d subsets are further divided into 3 groups:\n\n* dev - for development and experimentation\n* train - for use in speech recognition training\n* test - for testing word error rate\n\n### Organization and Conventions\n\nEach subset of data has a corresponding csv file with the following naming convention:\n\n\xe2\x80\x9ccv-{type}-{group}.csv\xe2\x80\x9d\n\nHere \xe2\x80\x9ctype\xe2\x80\x9d can be one of {valid, invalid, other}, and \xe2\x80\x9cgroup\xe2\x80\x9d can be one of {dev, train, test}. Note, the invalid set is not divided into groups.\n\nEach row of a csv file represents a single audio clip, and contains the following information:\n\n* filename - relative path of the audio file\n* text - supposed transcription of the audio\n* up_votes - number of people who said audio matches the text\n* down_votes - number of people who said audio does not match text\n* age - age of the speaker, if the speaker reported it\n  *  teens: '< 19'\n  *   twenties: '19 - 29'\n  *   thirties: '30 - 39'\n  *   fourties: '40 - 49'\n  *   fifties: '50 - 59'\n  *   sixties: '60 - 69'\n  *   seventies: '70 - 79'\n  *   eighties: '80 - 89'\n  *   nineties: '> 89'\n* gender - gender of the speaker, if the speaker reported it\n  *   male\n  *   female\n  *   other\n* accent - accent of the speaker, if the speaker reported it\n  *   us: 'United States English'\n  *   australia: 'Australian English'\n  *   england: 'England English'\n  *   canada: 'Canadian English'\n  *   philippines: 'Filipino'\n  *   hongkong: 'Hong Kong English'\n  *   indian: 'India and South Asia (India, Pakistan, Sri Lanka)'\n  *   ireland: 'Irish English'\n  *   malaysia: 'Malaysian English'\n  *   newzealand: 'New Zealand English'\n  *   scotland: 'Scottish English'\n  *   singapore: 'Singaporean English'\n  *   southatlandtic: 'South Atlantic (Falkland Islands, Saint Helena)'\n  *   african: 'Southern African (South Africa, Zimbabwe, Namibia)'\n  *   wales: 'Welsh English'\n  *   bermuda: 'West Indies and Bermuda (Bahamas, Bermuda, Jamaica, Trinidad)'\n\nThe audio clips for each subset are stored as mp3 files in folders with the same naming conventions as it\xe2\x80\x99s corresponding csv file. So, for instance, all audio data from the valid train set will be kept in the folder \xe2\x80\x9ccv-valid-train\xe2\x80\x9d alongside the \xe2\x80\x9ccv-valid-train.csv\xe2\x80\x9d metadata file.\n\n### Acknowledgments\n\nThis dataset was compiled by Michael Henretty, Tilman Kamp, Kelly Davis & The Common Voice Team, who included the following acknowledgments:\n\nWe sincerely  thank all of the people who donated their voice on the Common Voice website and app. You are the backbone of this project, and we thank you for making this possible!\n\nWe also thank our community on Discourse (https://discourse.mozilla-community.org/c/voice) and Github (https://github.com/mozilla/voice-web), you have made this project better every step of the way.\n\nAnd special thanks to Mycroft, SNIPS.ai, Mythic, Tatoeba.org, Bangor University, and SAP for joining us on this journey. We look forward to working more with each of you.""","b""['linguistics', 'languages', 'acoustics', 'large', 'featured']""",https://www.kaggle.com/mozillaorg/common-voice
b'InceptionResNetV2',b'InceptionResNetV2 Pre-trained Model for Keras',"b'# Inception-Resnet-V2\n\n---\n\n## Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning<br>\nVery deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question of whether there are any benefit in combining the Inception architecture with residual connections. Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4, we achieve 3.08 percent top-5 error on the test set of the ImageNet classification (CLS) challenge<br>\n\n**Authors: Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi**<br>\n**https://arxiv.org/abs/1602.07261**\n\n---\n\n## InceptionResnetV2 Architecture\n\n![InceptionResnetV2 Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://1.bp.blogspot.com/-O7AznVGY9js/V8cV_wKKsMI/AAAAAAAABKQ/maO7n2w3dT4Pkcmk7wgGqiSX5FUW2sfZgCLcB/s1600/image00.png'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/keras/inceptionresnetv2
b'EEG data from basic sensory task in Schizophrenia',b'Button press and auditory tone event related potentials from 81 human subjects',"b'### Context\n\nHumans (and many other animals) have the ability to reduce or suppress their brains\' responses to sensory consequences that are a result of their own actions.  The nervous system accomplishes this with a  corollary discharge forward model system in which an ""efference copy"" of an impending motor plan is transmitted from motor to sensory cortex where it generates a ""corollary discharge"" representation of the expected sensory consequences of the imminent motor act.  For example, when you move your eyes from left to right, your brain knows the environment is not shifting.  When you speak, your auditory cortex has a reduced response to the expected sound of your voice.\n\nSchizophrenia is a chronic mental illness that affects about 1% of people across the globe.  One possible explanation for some of the symptoms of schizophrenia is that one or more problems with the corollary discharge process in the nervous system makes it difficult for patients to differentiate between internally and externally generated stimuli.  Therefore, studying this process and its relationship to symptoms in the illness might allow us to better understand abnormal brain processes in patients with this diagnosis.\n\nIn a previously published EEG experiment ([full report][1]), we used a simple button pressing task in which subjects either (1) pressed a button to immediately generated a tone, (2) passively listened to the same tone, or (3) pressed a button without generating a tone to study the corollary discharge in people with schizophrenia and comparison controls.  We found that comparison controls suppressed the N100, a negative deflection in EEG brain wave 100 milliseconds after the onset of a sound, when they pressed a button to generate a tone compared to passive playback, but patients with schizophrenia did not.  This data set is a larger sample replication of that previous study.  Specifically, EEG data from 22 controls and 36 patients with schizophrenia have been combined with 10 controls and 13 patients from the previous report.\n\n### Methods\n\nDue to the size of the raw EEG data, some pre-processing was done prior to upload.  EEG data acquisition parameters and the experimental task was identical to that described in our paper.  However, pre-processing differed.  All individual subject data had at least the following data processing steps applied, in this order:\n\n 1. Re-reference to averaged ear lobes\n\n2.  0.1 Hz high-pass filter\n\n3.  Interpolation of outlier channels in the continuous EEG data (outliers defined as in [this paper][2])\n\n4.  Chop continous data into single trial epochs 1.5 seconds before and after task events (3s total)\n\n5.  Baseline correction -100 to 0ms\n\n6.  Canonical correlation analysis to remove muscle and high-frequency white noise artifacts\n\n7.  Rejection of outlier single trials (outliers defined as in [this paper][3])\n\n8.  Removal of outlier components from a spatial independent components analysis (outliers defined as in [this paper][4])\n\n9.  Interpolation of outlier channels within single trials (outliers defined as in [this paper][5])\n\nDerived data includes event-related potential (ERP) averages for 9 electrode sites analyzed in our previous report, including Fz, FCz, Cz, FC3, FC4, C3, C4, CP3, CP4 (pictured below):\n\n![montage][6]\n\nThe ERPs are calculated by averaging across trials for every sample in the time series, separately for each subject, electrode, and condition.\n\n### Content\n\nThe single trial data from all 64 channels are too large to be uploaded for all 81 subjects, but those interested in that type of data will find one subject (subject 21 in **21.csv**) among the data files.  This includes all his data after the pre-processing step 9 listed above.\n\nFor those interested in comparing patients with schizophrenia to control subjects, the **ERPdata.csv** file contains the averaged, ERP time series for all subjects, conditions, and the 9 electrodes mentioned above.  These data, along with the subject information in **demographic.csv** could be used to replicate the analyses in our prior report.\n\nFor those interested in single trial categorization/prediction like the [grasp-and-lift][8] challenge or the [face decoding][9] challenge, the **mergedTrialData.csv** contains summary measurements from nearly 24,000 individual trials (all subjects and conditions are included).\n\n\n### Acknowledgements\n\nFunding for the study procedures, initial analyses and publications came from the National Institute of Mental Health.  Please see [grant info][10] for additional details, and cite this NIMH project number (R01MH058262) in any work related to these data.  All study participants gave written, informed consent to participate in this study, which received Institutional Review Board approval.\n\n\n  [1]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4059422/ ""full report""\n  [2]: https://www.ncbi.nlm.nih.gov/pubmed/20654646 ""this paper""\n  [3]: https://www.ncbi.nlm.nih.gov/pubmed/20654646 ""this paper""\n  [4]: https://www.ncbi.nlm.nih.gov/pubmed/20654646 ""this paper""\n  [5]: https://www.ncbi.nlm.nih.gov/pubmed/20654646 ""this paper""\n  [6]: https://www.biosemi.com/pics/cap_64_layout_medium.jpg ""montage""\n  [8]: https://www.kaggle.com/c/grasp-and-lift-eeg-detection ""grasp-and-lift""\n  [9]: https://www.kaggle.com/c/decoding-the-human-brain ""face decoding""\n  [10]: https://projectreporter.nih.gov/project_info_description.cfm?aid=9187052&icde=36876449 ""grant info""'","b""['time series', 'mental health', 'neuroscience', 'large', 'featured']""",https://www.kaggle.com/broach/button-tone-sz
b'NYC Most Popular Baby Names',b'From New York City Open Data',"b""### Content  \n\nPopular Baby Names by Sex and Ethnic Group\nData were collected through civil birth registration. Each record represents the ranking of a baby name in the order of frequency. Data can be used to represent the popularity of a name. Caution should be used when assessing the rank of a baby name if the frequency count is close to 10; the ranking may vary year to year.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/sVwzvlpeEAU) by [freestocks.org](https://unsplash.com/@freestocks) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'health', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-most-popular-baby-names
b'NY Completed Percent for Art Projects',b'From New York City Open Data',"b""### Content  \n\nThis data set contains the current listing of Department of Cultural Affairs completed Percent for Art projects.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/F5-Z1H7lJaA) by [Sarah Noltner](https://unsplash.com/@sarah_noltner) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-completed-percent-for-art-projects
b'Upvoted Kaggle Datasets',b'2150 Kaggle datasets with at least two votes',"b'### Context\n\nKaggle dataset becomes a popular growing place to share datasets. Almost every day there will be new datasets uploaded. I am curious to explore what can be extracted from the information of each dataset.\n\n### Content\nThis dataset consists 2150 datasets information in 15 columns:\n\n - Title\n\n - Subtitle\n\n - Owner\n\n - Vote\n\n - Version History\n\n - Tags\n\n - Datatype\n\n - Size\n\n - License\n\n - Views\n\n - Downloads\n\n - Kernels\n\n - Topics\n\n - URL\n\n - Description\n\n### Acknowledgements\nAll data were taken from Kaggle website. Collected on 26 Feb 2018\n\n### Inspiration\nWith this dataset, we may try to predict the upcoming datasets uploaded, including its topics, number of votes, number of downloads, etc. Data visualization involving clustering may be performed also.'","b""['databases', 'information', 'small', 'featured']""",https://www.kaggle.com/canggih/voted-kaggle-dataset
b'Blue Plaques',b'Almost 40000 blue plaque historical markers worldwide',"b'### Context\n\nBlue plaques are a well-known and very popular permanent historical marker scheme administered in the United Kingdom that has since spread to many other countries in Europe and the world. According to Wikipedia:\n\n* A blue plaque is a permanent sign installed in a public place in the United Kingdom and elsewhere to commemorate a link between that location and a famous person or event, serving as a historical marker. The brainchild of British politician William Ewart in 1863, it is the oldest such scheme in the world.\n\n   The world\'s first blue plaques were erected in London in the 19th century to mark the homes and workplaces of famous people. This scheme continues to the present day...the term ""blue plaque"" may be used narrowly to refer to the official English Heritage scheme, but is often used informally to encompass all similar schemes.""\n\nHere\'s what a model blue plaque looks like:\n\n<img src=""https://i.imgur.com/rTGViJh.png""/>\n\n(image via [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Ian_Fleming_-_22_Ebury_Street_Blue_Plaque.jpg))\n\nThis dataset contains data about most of the blue plaques installed in Europe as of June 2017, as reported by [Open Plaques](http://openplaques.org/).\n\n### Content\n\nThis dataset contains information on the location of each plaque, who the subject is, and metadata about the person or organization being recognized.\n\n### Acknowledgements\n\nThis dataset is republished as-is from the original on [Open Plauqes](http://openplaques.org/pages/data).\n\n### Inspiration\n\n* Where are the blue plaques located?\n* What kinds of people and places get awarded a plaque?\n* What is the geospatial distribution of these plaques throughout the UK? Worldwide?'","b""['europe', 'history', 'culture and humanities', 'medium', 'featured']""",https://www.kaggle.com/residentmario/blue-plaques
b'VGG-19',b'VGG-19 Pre-trained Model for Keras',"b'# VGG19\n\n---\n\n## Very Deep Convolutional Networks for Large-Scale Image Recognition<br>\nIn this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.\n<br>\n\n**Authors: Karen Simonyan, Andrew Zisserman**<br>\n**https://arxiv.org/abs/1409.1556**\n\n---\n\n#VGG Architectures<br>\n![VGG Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/uLXrKxe.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/keras/vgg19
b'DJ Mag Top 100 History Dataset',b'DJ Mag Ranking Top 100 from 2004 to 2017',"b""### Context\n\nI just wanted to share the dataset I scraped from [DJ Mag Official Website][1] to create [shiny visualization app][2].\n\n!! Dataset will be updated as soon as possible after this year's announcement on 21st October.\n\n### Content\n\nDJ Magazine (aka DJ Mag) is a British monthly magazine dedicated to EDM and DJs. It was founded in 1991. **Top 100 DJs** is one of the magazine\xe2\x80\x99s biggest property and it provides a list of the world\xe2\x80\x99s most popular DJs every year since 2004. The poll attracted over 1 million votes in 2015, and now it is considered as one of the world\xe2\x80\x99s biggest biggest music polls.\n\nFor more information, visit https://djmag.com/.<br>\nScraping Script: [DJ Mag Ranking Scraping Script][3]\n\n - rvest & tidyverse  packages are used to collect and clean data.\n\nDataset includes all the DJ Mag ranking history from 2004 to 20017. <br>\n\n - Year: year\n - Ranking: Ranking number\n - DJ: DJ name\n - Change: ranking change from last year\n\n### Acknowledgements\n\nI really appreciate [DJ Mag official][4] for making dataset public and [UNICEF][5] for supporting the activity every year.\n\n\n### Inspiration\n\nCan you find how has the EDM music industry has changed?<br>\nPlease share your reports using this dataset. Your contributions are always welcome!!!\n\n\n  [1]: https://djmag.com/top100djs\n  [2]: https://koki25ando.shinyapps.io/dj_history/\n  [3]: https://github.com/koki25ando/DJ-Mag-History-Data/blob/master/DJ_Mag.R\n  [4]: https://djmag.com/\n  [5]: https://www.unicef.org/""","b""['music', 'entertainment', 'arts and entertainment', 'musicians', 'musical groups', 'small', 'featured']""",https://www.kaggle.com/koki25ando/dj-mag-top-100-history-dataset
b'Adverse Pharmaceuticals Events',b'FDA Adverse Event Reporting System (FAERS) Data',"b'### Context: \nIdentification of adverse drug reactions (ADRs) during the post-marketing phase is one of the most important goals of drug safety surveillance. Spontaneous reporting systems (SRS) data, which are the mainstay of traditional drug safety surveillance, are used for hypothesis generation and to validate the newer approaches. The publicly available US Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS) data requires substantial curation before they can be used appropriately, and applying different strategies for data cleaning and normalization can have material impact on analysis results. \n\n### Content: \nWe provide a curated and standardized version of FAERS removing duplicate case records, applying standardized vocabularies with drug names mapped to RxNorm concepts and outcomes mapped to SNOMED-CT concepts, and pre-computed summary statistics about drug-outcome relationships for general consumption. This publicly available resource, along with the source code, will accelerate drug safety research by reducing the amount of time spent performing data management on the source FAERS reports, improving the quality of the underlying data, and enabling standardized analyses using common vocabularies.\n\n### Acknowledgements: \nData available from [this source](http://datadryad.org/resource/doi:10.5061/dryad.8q0s4).\n\nWhen using this data, please cite the original publication:\n\nBanda JM, Evans L, Vanguri RS, Tatonetti NP, Ryan PB, Shah NH (2016) A curated and standardized adverse drug event resource to accelerate drug safety research. Scientific Data 3: 160026. http://dx.doi.org/10.1038/sdata.2016.26\n\nAdditionally, please cite the Dryad data package:\n\nBanda JM, Evans L, Vanguri RS, Tatonetti NP, Ryan PB, Shah NH (2016) Data from: A curated and standardized adverse drug event resource to accelerate drug safety research. Dryad Digital Repository. http://dx.doi.org/10.5061/dryad.8q0s4\n\n\n### Inspiration: \n* This is a large-ish dataset (~4.5 gb uncompressed), so try out your batch processing skills in a Kernel\n* What groups of drugs are most risky?\n* What medical conditions are most at risk to drug-associated risks?\n'","b""['government agencies', 'pharmaceutical industry', 'pharmaceuticals policy', 'large', 'featured']""",https://www.kaggle.com/fda/adverse-pharmaceuticals-events
b'JCPenney products',"b'20,000 product listings from JCPenney'","b""###Context\n\nThis is a pre-crawled dataset, taken as subset of a bigger [dataset (more than 3.7 million products)][1] that was created by extracting data from jcpenney.com, a well known retailer.\n\n### Content\n\nThis dataset has following fields:\n\n- sku\n- name_title\n- description\n- list_price\n- sale_price\n- category\n- category_tree\n- average_product_rating\n- product_url\n- product_image_urls\n- brand\n- total_number_reviews\n- reviews\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud's in-house web-crawling service.\n\n### Inspiration\nAnalyses of list price,  sale price, rating and reviews can be performed.\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=jc-kaggle&utm_medium=referral""","b""['internet', 'medium', 'featured']""",https://www.kaggle.com/PromptCloudHQ/all-jc-penny-products
b'Statbunker Football Statistics',"b'For anyone who enjoys football, and analyzing football stats'","b""### Context\n\nThis is a data dump of the football section of Statbunker's searchable football statistics database. \nI have uploaded League data for these European leagues:\n\n 1. Premier League\n 2. Bundesliga\n 3. La Liga\n 4. French Ligue 1\n 5. Eredivisie\n 6. Serie A\n 7. Scottish Premiership\n\n\n### Content\n\nI have pulled data for the following seasons:\n\n - 2014-15 \n - 2015-16\n - 2016-17\n - 2017-18 (Current)\n\nBased on the following disciplines:\n\n - Player stats\n - Away attendance\n - Home attendance\n - League Nationalities\n - League Tables\n - Team Defense\n - Team Offense\n\n\n### Acknowledgements\n\nAll data pulled can be found on the Statbunker website: https://www.statbunker.com/\n\n\n### Inspiration\n\nFor anyone who enjoys footbal, and analyzing football stats.\nPlease feel free to run kernels!""","b""['sports', 'europe', 'statistics', 'statistical analysis', 'association football', 'small', 'featured']""",https://www.kaggle.com/cclayford/statbunker-football-stats
b'Electoral Donations in Brazil',b'Statistical analysis of Brazil in 2014',"b""### Context\n\nBrazil has elections every two years, but alternating between two different types of elections, each type occurring every four years. There are the municipal elections, where mayors and city council members are elected (the last one occurred in 2016) and general elections where president, governors, senators and congressmen (regional and national) are elected (the last one occurred in 2014). Brazil has 26 federal units plus the federal district. Each one of these units (regions) elects its senators, congressmen and governors.\n\nFor each federal unit, Brazil's TSE provides information on the donations declared by the three entities: candidates, parties and committees. The data comprises information describing every donation received. The donations can be divided in two categories with respect to the donor: they can come from legal persons (private citizens, identified by the CPF (CPF is an identification number used by the Brazilian tax revenue office. It is roughly the Brazilian analogue to a social security number. With the same purpose, companies are identified with a similar number called CNPJ number) or from legal entities (i.e. companies, identified by the CNPJ number). Also, some entities can make donations among them (the party can give part of the money from a given donation to a candidate). In this type of transaction, the information on the original donor is also specified in the declarations. From now on, these type of donations will be referred to as non-original donations. Apart from information concerning each Brazilian federal unit separately, one can also obtain the information declared by the parties and committees at national level and for the presidential campaign (which has national and not regional scope).\n\n### Related paper:\n\nhttps://arxiv.org/pdf/1707.08826.pdf""","b""['finance', 'crime', 'politics', 'medium', 'featured']""",https://www.kaggle.com/felipeleiteantunes/electoral-donations-brazil2014
b'NYS OTDA LIM - Lottery Intercept Match',b'From New York State Open Data',"b""### Content  \n\nThis dataset from the Office of Temporary and Disability Assistance (OTDA) Audit public assistance (PA) recoveries through lottery intercept matches (LIM).  The dataset provides information on intercepts of lottery winnings of PA recipients to repay PA benefits received, aggregated by month, year, district and total amount recovered for that district by assistance type.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/RSsqjpezn6o) by [dylan nolte](https://unsplash.com/@dylan_nolte) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-otda-lim-lottery-intercept-match
b'515K Hotel Reviews Data in Europe',b'Can you make your trip more cozy by using data science?',"b""### Acknowledgements\n\nThe data was scraped from [Booking.com][1]. All data in the file is publicly available to everyone already. Data is originally owned by [Booking.com][2]. Please contact me through my [profile][3] if you want to use this dataset somewhere else.\n\n### Data Context\n\nThis dataset contains 515,000 customer reviews and scoring of 1493 luxury hotels across Europe. Meanwhile, the geographical location of hotels are also provided for further analysis.\n\n### Data Content\n\nThe csv file contains 17 fields. The description of each field is as below:\n\n - Hotel_Address: Address of hotel. \n - Review_Date: Date when reviewer posted the corresponding review.\n - Average_Score: Average Score of the hotel, calculated based on the latest comment in the last year.\n - Hotel_Name: Name of Hotel\n - Reviewer_Nationality: Nationality of Reviewer\n - Negative_Review: Negative Review the reviewer gave to the hotel. If the reviewer does not give the negative review, then it should be: 'No Negative'\n - Review_Total_Negative_Word_Counts: Total number of words in the negative review.\n - Positive_Review: Positive Review the reviewer gave to the hotel. If the reviewer does not give the negative review, then it should be: 'No Positive'\n - Review_Total_Positive_Word_Counts: Total number of words in the positive review.\n - Reviewer_Score: Score the reviewer has given to the hotel, based on his/her experience\n - Total_Number_of_Reviews_Reviewer_Has_Given: Number of Reviews the reviewers has given in the past.\n - Total_Number_of_Reviews: Total number of valid reviews the hotel has.\n - Tags: Tags reviewer gave the hotel.\n - days_since_review: Duration between the review date and scrape date.\n - Additional_Number_of_Scoring: There are also some guests who just made a scoring on the service rather than a review. This number indicates how many valid scores without review in there.\n - lat: Latitude of the hotel\n - lng: longtitude of the hotel\n\n*In order to keep the text data clean, I removed unicode and punctuation in the text data and transform text into lower case. No other preprocessing was performed.*\n\n### Inspiration\n\nThe dataset is large and informative, I believe you can have a lot of fun with it! Let me put some ideas below to futher inspire kagglers!\n\n - Fit a regression model on reviews and score to see which words are more indicative to a higher/lower score\n - Perform a sentiment analysis on the reviews\n - Find correlation between reviewer's nationality and scores.\n - Beautiful and informative visualization on the dataset.\n - Clustering hotels based on reviews\n - Simple recommendation engine to the guest who is fond of a special characteristic of hotel.\n\nThe idea is unlimited! Please, have a look into data, generate some ideas and leave a master kernel here! I am ready to upvote your ideas and kernels! Cheers!\n\n \n\n\n  [1]: http://www.booking.com\n  [2]: http://www.booking.com\n  [3]: https://www.kaggle.com/jiashenliu""","b""['internet', 'business', 'hotels', 'life', 'leisure', 'medium', 'featured']""",https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe
b'UK Traffic Counts',b'Details of traffic in England and Wales',"b'Data are available for each junction to junction link on the major road network (motorways and A roads). Data are also available for the sample of points on the minor road network (B, C and unclassified roads) that are counted each year, and these counts are used to produce estimates of traffic growth on minor roads.\n\nThe data are produced for every year, and are in three formats: a) the raw manual count data collected by trained enumerators; b) Annual Average Daily Flows (AADFs) for count points on major roads and minor roads; and c) traffic figures for major roads only. Explanatory notes (metadata) are available for each dataset, and in one combined note.\n\nA description of how annual road traffic estimates are produced is available at https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/270083/contents-page.pdf\n\nThis dataset was kindly released by the British Department of Transportation. You can find the original dataset here.'","b""['road transport', 'medium', 'featured']""",https://www.kaggle.com/sohier/uk-traffic-counts
b'Median Duration of Unemployment',b'Explore Time Series from the BLS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Bureau of Labor Statistics](http://www.bls.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according to the frequency that the data updates. Explore the OECD using Kaggle and all of the data sources available through the BLS [organization page](https://www.kaggle.com/bls)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/vJhaBoSLPKc) by [Vidar Nordli-Mathisen](https://unsplash.com/@vidarnm) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/bls/median-duration-of-unemployment
b'Hindi Health Dataset',b'HHD Corpus worthy for NLP tasks',"b'### Context\n\nA rapid march towards several smart health programs that are available online in the Hindi language, namely- https://www.onlymyhealth.com/hindi.html; https://pmsma.nhp.gov.in/; https://play.google.com/store/apps/details?id=com.knowledgeworld.HealthTipsHindi necessitates an emergence of the Hindi Health Data (HHD) corpus.\n\n\n### Content\n\nHHD corpus is crawled using python 2.7.11 from Indian websites and four gazetteer lists- Person, Disease, Consumable and Symptom are detailed in our published research papers. (please refer ### Acknowledgements) \n\n\n### Acknowledgements\n\nSpecial thanks goes to Dr. Anuja Arora, Associate Professor, CSE & IT, Jaypee Institute of Information Technology, Noida, India; Prof. Devendra K. Tayal, Dean (A& R), Indira Gandhi Delhi Technical University for Women, New Delhi, India.\n\nCitations-\n1. Jain, A., and Arora, A. Named Entity Recognition in Hindi Using Hyperspace Analogue to Language and Conditional Random Field. Pertanika Journal of Science and Technology, UPM, vol. 26, no. 4, pp. 1801-1822, 2018.\n2. Jain, A., Tayal, D.K., and Arora, A. OntoHindi NER- An Ontology Based Novel Approach For Hindi Named Entity Recognition. International Journal of Artificial Intelligence, vol. 16, no. 2, pp. 1-36, 2018.\n\n\n### Inspiration\n\nHHD corpus can help researchers to upgrade their research in the Hindi language while utilizing the health related entities. Some of these entities are available in a ready made mode within the corpus such as Disease while others need to be explored such as Diagnosis. In addition to the Named Entity Recognition, the corpus can be useful to perform various other Natural Language Processing tasks such as Question Answering, Co-reference Resolution, Parsing and many more.   '","b""['linguistics', 'healthcare', 'artificial intelligence', 'computer science', 'diseases', 'small', 'featured']""",https://www.kaggle.com/aijain/hindi-health-dataset
b'SF City Facilities and Sub-Facilities',b'From San Francisco Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-city-facilities-and-sub-facilities
b'15 Years Of Power Outages',"b'Power outages across the United States, compiled and standardized'","b""### Context\n\nIt's important to understand when and why outages occur, as energy is one of the most important resources we have.\n\n### Content\n\nThe dataset contains outage data from year 2000 up until 2014, with the following information:\n\n - Event Description: Reason of the outage (e.g. Vandalistm, Severe Weather, etc)\n - Year: Year of the outage (e.g. 2014)\n - Month: Month of the outage (e.g. November)\n - Date Event Began: Date of the outage (e.g. 11/13/2017)\n - Time Event Began: Time the outage was registered (e.g. 15:05:00)\n - Date of Restoration: Date the outage was resolved\n - Time of Restoration: Time the outage was resolved\n - Respondent: The company that acted upon the outage\n - Geografic Area: Region of the outage (e.g. Missisippi, Texas, New York, Salt Lake City, etc)\n - NERG Region: (NERC refers to the __[North American Electricity Reliability Corporation](https://www.nerc.com/Pages/default.aspx)__, formed to ensure the reliability of the grid).\n - Demand Loss (MW): How much energy was not transmited/consumed during the outage.\n - Number of customers affected: How many consumers (e.g. homes, offices, industry, etc) were left to their devices.\n - Tags: Summary event description (e.g. wild fire, vandalism, severe weather)\n\n### Inspiration\n\nWhen looking at this dataset, one can raise several questions: \n\n - What causes outages?\n - What are the most common causes?\n - Where and when is it more common?\n - When is it more impactful?\n\nWith that, perhaps, the biggest question of all can be answered: what could be done to improve the situation?\n\n### Acknowledgements\n\nThis data was compiled by the reporter __[Jordan Wirfs-Brock](http://insideenergy.org/author/jbrock/)__ and the original post can be found at http://insideenergy.org/2014/08/18/data-explore-15-years-of-power-outages/#comment-3862651149 The source material is publicly available at https://www.oe.netl.doe.gov/OE417_annual_summary.aspx.""","b""['weather', 'categorical data', 'energy', 'small', 'featured']""",https://www.kaggle.com/autunno/15-years-of-power-outages
b'Hateful Users on Twitter',b'Detecting hate speech with context',"b'# Context\n\nThis dataset contains a network of 100k users, out of which ~5k were annotated as hateful or not. \nFor each user, several content-related, network-related and activity related features were provided. \nCheck [this repo](https://github.com/manoelhortaribeiro/HatefulUsersTwitter) for analysis and a straightforward classification approach and [this repo](https://github.com/manoelhortaribeiro/graphsage_hateful_users) where we employed GraphSage, a network embedding method;\n\n*Hint*: Try to use not only the content associated with each user but also Twitter\'s network structure.\n\n# Content\n\n- `users_anon_neighborhood.csv`  file with several features for each user as well as the avg for some features for their 1-neighborhood (ppl they tweeted). Notice that `c_` are attributes calculated for the 1-neighborhood of a user in the retweet network (averaged out).\n\n- `users_clean.graphml` networkx compatible file with retweet network. User id\'s correspond to those in  `users_anon_neighborhood.csv`!\n\nIf you\'re keen on the original tweets, contact me :).\n\n## For reproducibility purposes\n\nThis are the files used by GraphSage [here](https://github.com/manoelhortaribeiro/graphsage_hateful_users). They come in a special format :); I\'ve added ""_""\n\n- `_users_(hate|suspended)_(glove|all).content` files with the feature vector for each user and their classes, the ones with `hate` label users as either `hateful`, `normal` or `other`, whereas the ones with `suspended` label users as either `suspended` or active. The ones with `glove` have only the glove vectors as features, the ones with `all` have other attributes related to users activity and network centrality. This is only for the GraphSage algorithm.\n\n- `_user.edges` file with all the (directed) edges in the retweet graph.\n\n# Attributes description\n\n      hate :(""hateful""|""normal""|""other"")\n      if user was annotated as hateful, normal, or not annotated.\n      \n      (is_50|is_50_2) :bool\n      whether user was deleted up to 12/12/17 or 14/01/18. \n      \n      (is_63|is_63_2) :bool\n      whether user was suspended up to 12/12/17 or 14/01/18. \n            \n      (hate|normal)_neigh :bool\n      is the user on the neighborhood of a (hateful|normal) user? \n      \n      [c_] (statuses|follower|followees|favorites)_count :int\n      number of (tweets|follower|followees|favorites) a user has.\n      \n      [c_] listed_count:int\n      number of lists a user is in.\n        \n      [c_] (betweenness|eigenvector|in_degree|outdegree) :float\n      centrality measurements for each user in the retweet graph.\n      \n      [c_] *_empath :float\n      occurrences of empath categories in the users latest 200 tweets.\n      \n      [c_] *_glove :float          \n      glove vector calculated for users latest 200 tweets.\n      \n      [c_] (sentiment|subjectivity) :float\n      average sentiment and subjectivity of users tweets.\n      \n      [c_] (time_diff|time_diff_median) :float\n      average and median time difference between tweets.\n      \n      [c_] (tweet|retweet|quote) number :float\n      percentage of direct tweets, retweets and quotes of an user.\n      \n      [c_] (number urls|number hashtags|baddies|mentions) :float\n      number of bad words|mentions|urls|hashtags per tweet in average.\n      \n      [c_] status length :float\n      average status length.\n      \n      hashtags :string\n      all hashtags employed by the user separated by spaces.\n\n'","b""['internet', 'crime', 'network analysis', 'large', 'featured']""",https://www.kaggle.com/manoelribeiro/hateful-users-on-twitter
b'1k Pharmaceutical Pill Image Dataset',b'Speckled pills CNN feature extracted for unique individual identification',"b""### Context\n1K dataset of speckled pharmaceutical pills. Using a CNN to extract features and create binary hash code, these pills can be retrieved from a mobile device for remote identification. Every pill can be tracked using a mobile phone app.![Mobile pill identification app][1]\n\n### Content\n1 K pharmaceutical pills jpeg images that have been convoluted by: rotations, grey scale, noise, non-pill \n\n\n### Acknowledgements\nSpecial thanks for Funding and support of Microsoft - Paul DeBaun and  NWCadence- Steve Borg\n\n### Inspiration\n\nThe Pill Crisis in America\n1) Fake Fentanyl             - killing young people\xc2\xa0\n2) Opioid Abuse             - killing all ages of people\xc2\xa0\n3) Fake Online Drugs    -  killing unknown numbers\n4) Non-Compliance       -  killing older people\n\n- Non-Compliance\xc2\xa0 up to 90% of diabetics don't take their meds enough to benefit\xc2\xa0\n- Up to 75% of hypertensive patients do not adhere to their medicine\xc2\xa0\n- Less than 27% depressed patients adhere to their medication\n- 41-59% of mentally ill take their meds infrequently or not at all\n- 33% of patients with schizophrenia don\xe2\x80\x99t take their medicine at all\n\n\n  [1]: http://www.jellirolls.com/trumed/images/TruScan-app.jpg""","b""['image data', 'healthcare', 'multiclass classification', 'pharmacy', 'small', 'featured']""",https://www.kaggle.com/trumedicines/1k-pharmaceutical-pill-image-dataset
b'Malaysia GE14 Election Results',"b'Parliamentary, State and Total Votes'","b""### Context\n\nElection Results for Malaysian GE14 Election \n\n\n### Content\nThis is the parliamentary & State election results for GE 14 organized by candidate. Some notes on the data:\n\nGender L = Male(Lelaki), P=Female(Perempuan)\nStatus KLH = Lose(Kalah), MNG = Win(Menang)\nPerkerjaan = Job (Ahli Perniaga = Business Owner, Tiada=None, Usahawan=Entrepreneur etc. \n\n\n\n### Acknowledgements\n\nData was collected by [Sinar Project][1]\n\n\n### Inspiration\n\nSince this is a landmark election for Malaysia being the first time in it's history there has been a change of government it will be interesting see the types of candidates, the voting spreads by states. I will try to get GE13 election data for a comparison.\n\n\n  [1]: https://sinarproject.org/en""","b""['government', 'small', 'featured']""",https://www.kaggle.com/terenctb/malaysia-ge14-election-results-parliament
b'Non-invasive Blood Pressure Estimation',b'Vital signals and reference blood pressure values acquired from 26 subjects.',"b""## Abstract\nThis dataset provides a collection of vital signals and reference blood pressure values acquired from 26 subjects that can be used for the purpose of non-invasive cuff-less blood pressure estimation.\n \n## Source\nCreators: Amirhossein Esmaili, Mohammad Kachuee, Mahdi Shabany\nDepartment of Electrical Engineering, Sharif University of Technology, Tehran, Iran\nDate: October 2017\n \n \n## Relevant Information\nThis dataset is to be used for research methods trying to estimate blood pressure in a cuff-less non-invasive manner. For each subject in this dataset, phonocardiogram (PCG), electrocardiogram (ECG), and photoplethysmogram (PPG) signals are acquired. Alongside the acquisition of the signals per subject, a number of reference BPs are measured. Here, a signal from a force-sensing resistor (FSR), placed under the cuff of the BP reference device, is used to distinguish exact moments of reference BP measurements, which are corresponding to the inflation and deflation of the cuff. The signal from FSR is also included in our dataset. For each subject, age, weight, and height are also recorded.\n \n## Attribute Information\nIn the dataset, corresponding to each subject there is a \xe2\x80\x9c.json\xe2\x80\x9d file. In each file, we have the following attributes:\n\n\xe2\x80\x9cUID\xe2\x80\x9d: Subject number\n\n\xe2\x80\x9cage\xe2\x80\x9d: Age of the subject\n\n\xe2\x80\x9cweight\xe2\x80\x9d: Weight of the subject (Kg)\n\n\xe2\x80\x9cheight\xe2\x80\x9d: Height of the subject (cm)\n\n\xe2\x80\x9cdata_PCG\xe2\x80\x9d: Acquired PCG signal from chest (Fs = 1 KHz)\n\n\xe2\x80\x9cdata_ECG\xe2\x80\x9d: Acquired ECG signal (Fs = 1 KHz)\n\n\xe2\x80\x9cdata_PPG\xe2\x80\x9d: Acquired PPG signal from fingertip (Fs = 1 KHz)\n\n\xe2\x80\x9cdata_FSR\xe2\x80\x9d: Acquired FSR signal (Fs = 1 KHz)\n\n\xe2\x80\x9cdata_BP\xe2\x80\x9d: reference systolic blood pressure (SBP) and diastolic blood pressure (DBP) values acquired from the subjects. To distinguish the time instances in the signals in which SBP and DBP values are measured, FSR signal can be used. For more details, please refer to our paper.\n\n**Please note that the FSR signal should be inverted prior to any analysis to reflect the instantaneous cuff pressure.** Also, the moment of each reference device measurement is approximately the time at which the cuff pressure drops with a considerable negative slope.\n\n\n## Relevant Papers\nA. Esmaili, M. Kachuee, M. Shabany, Nonlinear Cuffless Blood Pressure Estimation of Healthy Subjects Using Pulse Transit Time and Arrival Time, IEEE Transactions on Instrumentation and Measurement, 2017.\n\nA. Esmaili, M. Kachuee, M. Shabany, Non-invasive Blood Pressure Estimation Using Phonocardiogram, IEEE International Symposium on Circuits and Systems (ISCAS'17), 2017.\n \n## Citation Request\nA. Esmaili, M. Kachuee, M. Shabany, Nonlinear Cuffless Blood Pressure Estimation of Healthy Subjects Using Pulse Transit Time and Arrival Time, IEEE Transactions on Instrumentation and Measurement, 2017.\n \n \n \n""","b""['healthcare', 'health sciences', 'medium', 'featured']""",https://www.kaggle.com/mkachuee/noninvasivebp
b'Syria: River and Lake Shapefiles',b'For mapmaking purposes',"b'### Context\n\nSyria, officially known as the Syrian Arab Republic, is a country in Western Asia, bordering Lebanon and the Mediterranean Sea to the west, Turkey to the north, Iraq to the east, Jordan to the south, and Israel to the southwest. \n\nSource: https://en.wikipedia.org/wiki/Syria\n\n### Content\n\nShapefiles for plotting the rivers and lakes of Syria. All lines and polygons are clipped to Syrian borders. When coerced to a SpatialPolygonsDataFrame includes a column indicating whether perennial or intermittent.\n\n### Acknowledgements\n\nAll files courtesy of Digital Chart of the World (DCW) via [www.diva-gis.org](https://)'","b""['geospatial analysis', 'geography', 'small', 'featured']""",https://www.kaggle.com/bigironsphere/syria-river-and-lake-shapefiles
b'A Million News Headlines',b'News headlines published over a period of 15 years.',"b'### Context\n\nThis contains data of news headlines published over a period of 15 years.\n\nSourced from the reputable Australian news source ABC (Australian Broadcasting Corp.)\n\nAgency Site: http://www.abc.net.au/\n\n### Content\n\nFormat: CSV ; Single File\n\n 1. publish_date: Date of publishing for the article in yyyyMMdd format\n 2. headline_text: Text of the headline in Ascii , English , lowercase\n\nStart Date: 2003-02-19 End Date: 2017-12-31\n\nTotal Records: **1,103,665**\n\nFeed Code: w3-event-abcaus; Si.gh.rank: BJL\n\n### Acknowledgements\n\nDedicated to Jane Goodall a\xc5\xad Steve Irwin\n\nCitation for usage:\n\n**Rohit Kulkarni** (2017), A Million News Headlines [CSV Data file], doi:10.7910/DVN/SYBGZL, Retrieved from: [this url]\n\n### Inspiration\n\nI look at this news dataset as a summarised historical record of noteworthy events in the globe from early-2003 to end-2017 with a more granular focus on Australia.\n\nThis includes the entire corpus of articles published by the ABC website in the given time range. \nWith a volume of 200 articles per day and a good focus on international news, we can be fairly certain that every event of significance has been captured here.\n\nDigging into the keywords, one can see all the important episodes shaping the last decade and how they evolved over time.\nEx: financial crisis, iraq war, multiple US elections, ecological disasters, terrorism, famous people, Australian crimes  etc.\n\n### Similar Work\nYour code can be reused with minimal changes across all these datasets\n\n - 3M Clickbait Headlines for 6 years: [Examine the Examiner][1]\n - 1.3M Global Headlines from 20K sources over 1 week: [Global News Week][2]\n - 2.6M News Headlines from India from 2001-2017: [Headlines of India][3]\n\n\n  [1]: https://www.kaggle.com/therohk/examine-the-examiner\n  [2]: https://www.kaggle.com/therohk/global-news-week\n  [3]: https://www.kaggle.com/therohk/india-headlines-news-dataset'","b""['linguistics', 'news agencies', 'sociology', 'historiography', 'medium', 'featured']""",https://www.kaggle.com/therohk/million-headlines
b'US Population By Zip Code',b'For both 2000 and 2010',"b'### Content\n\nThe United States census count (also known as the Decennial Census of Population and Housing) is a count of every resident of the US. The census occurs every 10 years and is conducted by the United States Census Bureau. Census data is publicly available through the census website, but much of the data is available in summarized data and graphs. The raw data is often difficult to obtain, is typically divided by region, and it must be processed and combined to provide information about the nation as a whole.\nThe United States census dataset includes nationwide population counts from the 2000 and 2010 censuses. Data is broken out by gender, age and location using zip code tabular areas (ZCTAs) and GEOIDs. ZCTAs are generalized representations of zip codes, and often, though not always, are the same as the zip code for an area. GEOIDs are numeric codes that uniquely identify all administrative, legal, and statistical geographic areas for which the Census Bureau tabulates data. GEOIDs are useful for correlating census data with other censuses and surveys.\n\n### Dataset Description\n\n| geo_id      | STRING  | Geo code                                                                                                                                                                       |\n|-------------|---------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| minimum_age | INTEGER | The minimum age in the age range. If null, this indicates the row as a total for male, female, or overall population.                                                          |\n| maximum_age | INTEGER | The maximum age in the age range. If null, this indicates the row as having no maximum (such as 85 and over) or the row is a total of the male, female, or overall population. |\n| gender      | STRING  | male or female. If empty, the row is a total population summary.                                                                                                               |\n| population  | INTEGER | The total count of the population for this segment.                                                                                                                            |\n\n### Acknowledgements\n\nThis dataset was created by the [United States Census Bureau][1].\n\n### Use this dataset with BigQuery\nYou can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the data on BigQuery, too: https://cloud.google.com/bigquery/public-data/international-census.\n\n  [1]: https://www.census.gov/'","b""['demographics', 'utility', 'medium', 'featured']""",https://www.kaggle.com/census/us-population-by-zip-code
b'Bike Sharing in Washington D.C. Dataset',b'Rental bikes in 2011 and 2012 with corresponding weather and seasonal info',"b'### Context\n\nBike sharing systems are a new generation of traditional bike rentals where the whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back to another position. Currently, there are about over 500 bike-sharing programs around the world which are composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues. \n\nApart from interesting real-world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a **virtual sensor network** that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.\n\nThis dataset contains the hourly and daily count of rental bikes between years **2011** and **2012** in [Capital bikeshare system][1] in **Washington, DC** with the corresponding weather and seasonal information.\n\n### Content\n\nBoth **hour.csv** and **day.csv** have the following fields, except *hr* which is not available in day.csv\n\n- **instant:** Record index\n- **dteday:** Date\n- **season:** Season (1:springer, 2:summer, 3:fall, 4:winter)\n- **yr:** Year (0: 2011, 1:2012)\n- **mnth:** Month (1 to 12)\n- **hr:** Hour (0 to 23)\n- **holiday:** weather day is holiday or not (extracted from [Holiday Schedule][2])\n- **weekday:** Day of the week\n- **workingday:** If day is neither weekend nor holiday is 1, otherwise is 0.\n+ **weathersit:** (extracted from [Freemeteo][3])\n- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n- **temp:** Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n- **atemp:** Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n- **hum:** Normalized humidity. The values are divided to 100 (max)\n- **windspeed:** Normalized wind speed. The values are divided to 67 (max)\n- **casual:** count of casual users\n- **registered:** count of registered users\n- **cnt:** count of total rental bikes including both casual and registered\n\n### Acknowledgements\n\nHadi Fanaee-T \nLaboratory of Artificial Intelligence and Decision Support (LIAAD), University of Porto \nINESC Porto, Campus da FEUP \nRua Dr. Roberto Frias, 378 \n4200 - 465 Porto, Portugal \n\nOriginal Source: http://capitalbikeshare.com/system-data \n\nWeather Information: http://www.freemeteo.com \n\nHoliday Schedule: http://dchr.dc.gov/page/holiday-schedule\n\n\n  [1]: https://www.capitalbikeshare.com/system-data\n  [2]: http://dchr.dc.gov/page/holiday-schedule\n  [3]: http://www.freemeteo.com'","b""['data visualization', 'eda', 'feature engineering', 'regression analysis', 'categorical data', 'small', 'featured']""",https://www.kaggle.com/marklvl/bike-sharing-dataset
b'New York City Air Quality',b'From New York City Open Data',"b""### Content  \n\nDataset contains information on New York City air quality surveillance data  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/_rNVw54xZZg) by [Hermes Rivera](https://unsplash.com/@hermez777) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'health', 'surveillance', 'small', 'featured']""",https://www.kaggle.com/new-york-city/new-york-city-air-quality
b'International Greenhouse Gas Emissions',b'A global GHG inventory from 1990-2017',"b'The Greenhouse Gas (GHG) Inventory Data contains the most recently submitted information, covering the period from 1990 to the latest available year, to the extent the data have been provided. The GHG data contain information on anthropogenic emissions by sources and removals by sinks of the following GHGs (carbon dioxide (CO2), methane (CH4), nitrous oxide (N2O), hydrofluorocarbons (HFCs), perfluorocarbons (PFCs), unspecified mix of HFCs and PFCs, sulphur hexafluoride (SF6) and nitrogen triflouride (NF3)) that are not controlled by the Montreal Protocol.\n\nGHG emission inventories are developed by Parties to the Convention using scientific and methodological guidance from the Intergovernmental Panel on Climate Change (IPCC), such as 2006 IPCC Guidelines for National Greenhouse Gas Inventories, Revised Guidelines for National Greenhouse Gas Inventories (1996), IPCC Good Practice Guidance and Uncertainty Management in National Greenhouse Gas Inventories (2000) and IPCC Good Practice Guidance on Land Use, Land-use Change and Forestry (2003).\nLast update in UNdata: 23 Mar 2017 with data released in Nov 2016.\n\n### Acknowledgements\n\nThis dataset was kindly published by the United Nation on the UNData site. You can find [the original dataset here](http://data.un.org/Explorer.aspx).\n\n### License\n[Per the UNData terms of use](http://data.un.org/Host.aspx?Content=UNdataUse): all data and metadata provided on UNdata\xe2\x80\x99s website are available free of charge and may be copied freely, duplicated and further distributed provided that [UNdata](http://data.un.org/Explorer.aspx) is cited as the reference. '","b""['climate', 'earth sciences', 'small', 'featured']""",https://www.kaggle.com/unitednations/international-greenhouse-gas-emissions
b'2016 Parties in New York',b'225k noise complaints to the police about ongoing parties in the city',"b'### Context\n\nThis dataset contains all noise complaints calls that were received by the city police with complaint type ""Loud music/Party"" in 2016. The data contains the time of the call, time of the police response, coordinates, and part of the city.\n\nThis data should help match taxi rides from ""New York City Taxi Trip Duration"" competition to the night rides of partygoers. \n\n### Content\n\nThe New York city hotline receives non-urgent community concerns, which are made public by the city through NYC Open Data portal. The full dataset contains a variety of complaints ranging from illegal parking to customer complaints. This dataset focuses on Noise complaints that were collected in 2016 and indicate ongoing party in a given neighborhood. \n\n### Acknowledgements\n\n[https://opendata.cityofnewyork.us/][1] - NYC Open Data portal contains many other interesting datasets\nPhoto by [Yvette de Wit][2] on [Unsplash][3]\n\n\n### Inspiration\n\nAfter a fun night out in the city majority of people are too exhausted to travel by public transport, so they catch a cab to their home. I hope this data will help the community to find the patterns in the data that will lead to better solutions.\n\n\n  [1]: https://opendata.cityofnewyork.us/\n  [2]: https://unsplash.com/@yvettedewit\n  [3]: https://unsplash.com/'","b""['cities', 'parties', 'medium', 'featured']""",https://www.kaggle.com/somesnm/partynyc
b'Toxic Release Inventory',b'US EPA data on release of toxic chemicals for 1987-2016',"b""### Context\n\nThis database is managed by the  US Environmental Protection Agency and contains information reported annually by some industry groups as well as federal facilities. Each year, companies across a wide range of industries (including chemical, mining, paper, oil and gas industries) that produce more than 25,000 pounds or handle more than 10,000 pounds of a listed toxic chemical must report it to the TRI. The TRI threshold was initially set at 75,000 pounds annually. If the company treats, recycles, disposes, or releases more than 500 pounds of that chemical into the environment (as opposed to just handling it), then they must provide a detailed inventory of that chemical's inventory.\n\n### Content\n- There are roughly 100 columns in this dataset; please see the `tri_basic_data_file_format_v15.pdf` for details. You may also wish to consult `factors_to_consider_6.15.15_final.pdf` for general background about interpreting the data.\n- I've merged all of the TRI basic data files into a single large csv. You will probably need to process it in batches or use a tool like Dask to stay within kernel memory limits.\n- Please note that the 2016 data remains preliminary at the time of this release.\n\n### Acknowledgements\n\nThis dataset was released by the [US EPA][1]. You can find the original dataset, more detailed versions of the data,  and a great deal of background information here: https://www.epa.gov/toxics-release-inventory-tri-program/tri-data-and-tools\n\n### Inspiration\n\nThe EPA runs an annual university contest. Their [list of previous winners][2] contains a lot of great ideas that people have had for this dataset in the past. The 2017 competition is already over, but you can find [the rules here][3].\n\n\n  [1]: https://www.epa.gov/\n  [2]: https://www.epa.gov/toxics-release-inventory-tri-program/2016-2017-tri-university-challenge-academic-partners-0\n  [3]: https://www.epa.gov/toxics-release-inventory-tri-program/2017-tri-university-challenge""","b""['utility', 'government agencies', 'pollution', 'large', 'featured']""",https://www.kaggle.com/epa/toxic-release-inventory
b'MaxEnt Treebank POS Tagger',b'Maximum Entropy POS Tagger',b'### Context\n\nThis was the original pre-trained POS tagger that `nltk.pos_tag` used. \n\nThis is the infamous maximum entropy POS tagger that gained a lot of heat when [no one knew where exactly the model came from](https://github.com/nltk/nltk/issues/1063).\n\n### Acknowledge\n\nWe would like to know who to acknowledge too ;P',"b""['medium', 'featured']""",https://www.kaggle.com/nltkdata/maxent-treebank-pos-tagger
b'Flipkart Products',"b'20,000 products on Flipkart'","b""###Context\n\nThis is a pre-crawled dataset, taken as subset of a bigger [dataset (more than 5.8 million products)][1] that was created by extracting data from Flipkart.com, a leading Indian eCommerce store.\n\n### Content\n\nThis dataset has following fields:\n\n- product_url\n- product_name\n- product_category_tree\n- pid\n- retail_price\n- discounted_price\n- image\n- is_FK_Advantage_product\n- description\n- product_rating\n- overall_rating\n- brand\n- product_specifications\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud's in-house web-crawling service.\n\n### Inspiration\nAnalyses of the pricing, product specification and brand can be performed.\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=fl-kaggle&utm_medium=referral""","b""['internet', 'medium', 'featured']""",https://www.kaggle.com/PromptCloudHQ/flipkart-products
b'HSE Thai Corpus',b'A 35 Million Word Corpus of Thai',"b'### Context: \n\nThe Thai language is the primary language of Thailand and a recognized minority language in Cambodia. It has approximately twenty million native speakers, in addition to 44 million second language speakers. It is written in Thai script (also called the Thai alphabet) which is notable for being the first writing system to incorporate tonal markers. Thai is written without spaces between words.\n\n### Content: \n\nThe HSE Thai Corpus is a corpus of modern texts written in Thai language. The texts, containing in whole 50 million tokens, were collected from various Thai websites (mostly news websites). To make it easier for non-Thai-speakers to comprehend and use texts in the corpus the researchers decided to separate words in each sentence with spaces.\n\nThe data for the corpus was collected by means of Scrapy. To tokenize texts the Pythai module was used. The text in this dataset is encoded in UTF-8.\n\nThe corpus can be searched using a web interface at [this site](http://web-corpora.net/ThaiCorpus/search/?interface_language=en).\n\nThis dataset contains text from two sources: Wikipedia and thaigov.go.th. The former is licensed under a [standard Wikipedia license](https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License), and the latter under an Open Government License for Thailand, which can be viewed [here](https://data.go.th/TermsAndConditions.aspx) (In Thai).\n\n### Acknowledgements: \n\nThe Thai Corpus was developed by the team of students of HSE School of Linguistics in Moscow under the guidance of professor Boris Orekhov. The team consisted of Grigory Ignatyev, Alexandra Ershova, Anna Kuznetsova, Tatyana Shalganova, Daniil Kolomeytsev and Nikolai Mikulin. The consulting help on Thai language was provided by Nadezhda Motina. Natalia Filippova, Elizaveta Kuzmenko, Tatyana Gavrilova, Elena Krotova, Elmira Mustakimova, Olga Sozinova, Aleksandra Martynova, Maria Sheyanova, Marina Kustova and Julia Badryzlova also contributed to the project.\n\n### Inspiration: \n\n* In this corpus, unlike in most written Thai, words have been separated for you with spaces. Can you remove spaces and write an algorithm to identify word boundaries?'","b""['internet', 'linguistics', 'languages', 'asia', 'medium', 'featured']""",https://www.kaggle.com/rtatman/hse-thai-corpus
b'Kospi Stock Price',b'Korean Stock Kospi Prices',"b""# Context\n\nI got all these .csv files using `pandas data reader` but getting every single kospi data through `pandas data reader` is annoying. so I decided to share this files.\n\n# Content\n\n### Files\n\nkospi.csv contains average kospi price. you can use this for checking whether if korean stock is day-off or not.\nxxxxxx.csv contains each single price records. xxxxxx is it's unique ticker.\n\n### Columns\n\nDate\n\n```\nformat - \\d{4}-\\d{2}-\\d{2}\n```\n\nOpen\n\n```\nformat - \\d{1,}\\.\\d{1}\n```\n\nHigh\n\n```\nformat - \\d{1,}\\.\\d{1}\n```\n\nLow\n\n```\nformat - \\d{1,}\\.\\d{1}\n```\n\nClose\n\n```\nformat - \\d{1,}\\.\\d{1}\n```\n\n Adj Close\n\n```\nformat - \\d{1,}\\.\\d{1}\n```\n\nVolume\n\n```\nformat - \\d+\n```\n\n# Acknowledgements\n\n[blog post](https://gomjellie.github.io/%ED%8C%8C%EC%9D%B4%EC%8D%AC/pandas/%EC%A3%BC%EC%8B%9D/2017/06/09/pandas-datareader-stock.html) which describes how i got these data's. you might need this to update csv files.\n\n[git repository](https://github.com/gomjellie/kospi-kosdaq-csv) git repository \n\n\n# Inspiration\n\nGood luck.""","b""['finance', 'economics', 'medium', 'featured']""",https://www.kaggle.com/gomjellie/kospi-price-data
b'NYS OASAS Medicaid Trend Recipient Summary Profile',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-oasas-medicaid-trend-recipient-summary-profile
b'US Facility-Level Air Pollution (2010-2014)',b'EPA Toxic & Greenhouse Gas Emissions Data',"b'### Context\n\nThis dataset includes the 2010-2014 ""Facility-Level"" emissions data, combined with geographical & industry-related data.  It is based on the EPA\'s [Toxic Release Inventory (TRI)][1] & [Greenhouse Gas Reporting Inventory (GHG)][2], the national system of nomenclature that is used to describe the industry-related emissions.\n\nAlthough the EPA publishes and maintains the TRI & GHG report in various forms, the combination of the two is not readily available. Hence this dataset. \n\n### Content\n\nThe CSV has 28 columnar variables defined as: \n\n1. UniqueID\n2. Facility name\n3. Rank TRI \'14\n4. Rank GHG \'14\n5. Latitude\n6. Longitude\n7. Location address\n8. City\n9. State\n10. ZIP\n11. County\n12. FIPS code\n13. Primary NAICS\n14. Second primary NAICS\n15. Third primary NAICS\n16. Industry type\n17. Parent companies 2014 (GHG)\n18. Parent companies 2014 (TRI)\n19. TRI air emissions 14 (in pounds)\n20. TRI air emissions 13 [and previous years]\n21. GHG direct emissions 14 (in metric tons)\n22. GHG direct emissions 13 [and previous years]\n23. GHG Facility Id\n24. Second GHG Facility Id [and Third, Fourth, etc.]\n25. TRI Id\n26. Second TRI Id [and Third, Fourth, etc.]\n27. FRS Id\n28. Second FRS Id [and Third, Fourth, etc.]\n\n\n\n### Acknowledgements\n\nThis dataset was made available by the [Center for Public Integrity][3]. \n\n\n  [1]: https://www.epa.gov/toxics-release-inventory-tri-program\n  [2]: https://www.epa.gov/ghgemissions/us-greenhouse-gas-inventory-report-1990-2014\n  [3]: https://www.publicintegrity.org'","b""['demographics', 'united states', 'pollution', 'small', 'featured']""",https://www.kaggle.com/jaseibert/us-facilitylevel-air-pollution-20102014
b'Seattle Police Department 911 Incident Response',b'1.4 million responses from 2009 onwards',"b'This dataset records police responses to 911 calls in the city of Seattle.\n \n## Acknowledgements\nThis dataset was kindly made available by the City of Seattle. They update the data daily; you can find [the original version here][1].\n\n## Inspiration\n\n - The study discussed in [this Atlantic article][2] reviewing 911 calls in Milwaukuee found that that incidents of police violence lead to large drops in the number of 911 calls. Does this hold true for Seattle as well? This dataset technically only contains the responses to 911 calls rather than the calls themselves, but it should be feasible to use the responses as a decent proxy for calls.\n\n\n  [1]: https://data.seattle.gov/Public-Safety/Seattle-Police-Department-911-Incident-Response/3k2p-39jp\n  [2]: https://www.theatlantic.com/politics/archive/2016/09/police-violence-lowers-911-calls-in-black-neighborhoods/501908/'","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/sohier/seattle-police-department-911-incident-response
b'echocardiogram-UCI',b'health issues and survival rate',"b""## Context ##\nAll the patients suffered heart attacks at some point in the past. Some are still alive and some are not. The survival and still-alive variables, when taken together, indicate whether a patient survived for at least one year following the heart attack. \n\n## Content ##\nThis dataset consists of 132 instances of patients for 12 variables describing the patient's heart attack and condition.\n\n## Acknowledgements ##\nDataset Link: https://archive.ics.uci.edu/ml/datasets/echocardiogram   \nBanner Photo by [rawpixel.com on Unsplash][1]\n\n## Insight ##\nThe problem addressed by past researchers was to predict from the other variables whether or not the patient will survive at least one year. The most difficult part of this problem is correctly predicting that the patient will NOT survive. (Part of the difficulty seems to be the size of the data set.)\n\n\n  [1]: https://unsplash.com/photos/XNRHhomhRU4""","b""['health', 'medicine', 'biology', 'small', 'featured']""",https://www.kaggle.com/loganalive/echocardiogram-uci
b'Ukrainian Parliament Daily Agenda Results',b'Sessions of the Verkhovna Rada',"b'## Context\n\nData on parliamentary agendas and actions taken by the Verkhovna Rada (\xd0\x92\xd0\xb5\xd1\x80\xd1\x85\xd0\xbe\xd0\xb2\xd0\xbd\xd0\xb0 \xd0\xa0\xd0\xb0\xd0\xb4\xd0\xb0), the Ukrainian parliament, in 2014 through 2017.\n\n## Content\nFor the period of 27th Nov 2014 through 17th Oct 2017:\n\n* List of deputies\n* List of parliamentary fractions\n* Session Days\n* Daily agenda results, including:\n  - total voting result\n  - individual deputy votes\n  - speech authors and timings, no full text\n  - registration performed as the session day starts\n\n## Acknowledgements\nSourced from: [http://data.rada.gov.ua/open/data/ppz-skl8][1], on the Ukrainian government open data portal. Thanks to everyone who made this open data possible.\n\nPhoto by <a href=""https://unsplash.com/photos/8wdhTMhTAc4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText"">Illia Cherednychenko</a> on Unsplash.\n\n  [1]: http://data.rada.gov.ua/open/data/ppz-skl8\n\n## Inspiration\n* How are the Ukranian parliamentary factions structured?\n* Does parliamentary activity in this dataset reflect the ongoing political events in the country?'","b""['politics', 'politicians', 'medium', 'featured']""",https://www.kaggle.com/subota/ukrainian-parliament-daily-agenda-result
b'NYS Title V Emissions Inventory: Beginning 2010',b'From New York State Open Data',"b""### Content  \n\nA list by county of New York State Title V facilities and the air pollutants emitted from those facilities.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/8GSKSEREWyo) by [Amber Mason](https://unsplash.com/@amberella) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'utility', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-title-v-emissions-inventory-beginning-2010
"b'U.S. Public Pensions Data, fiscal years 2001-2016'","b'Trends in Investments, Benefits, and Funding for U.S. Public Pensions'","b'### Context\n\nThe Public Plans Dataset compiles publicly-available information on major U.S. public pension plans from their annual reporting.  This includes state-level plans as well as some large plans from localities such as New York City and Chicago.\n\n### Content\n\nThe Public Plans Dataset has data compiled from the actuarial reports and CAFRs (comprehensive annual financial reports) for major plans. It includes balance sheet (assets/liabilities), income (e.g., investment income), and cash flow (e.g., benefit payments) information. In addition, there are items such as number of beneficiaries receiving payment, the number of active participants, the number vested, etc.\n\nThe current set covers fiscal years 2001 - 2016, which usually run mid-year to mid-year (this can differ by plan).  \n\n### Acknowledgements\n\nData from Public Plans Data: http://publicplansdata.org/public-plans-database/\n\nThe Public Plans Data project comes out of a partnership between the Center for Retirement Research at Boston College (CRR) and the Center for State and Local Government Excellence (SLGE). The National Association of State Retirement Administrators (NASRA), which has been collecting and sharing public plan data since 2001, supports the partnership by providing review and assistance on the development of data models, validation of data, and development and administration of surveys. More here: http://publicplansdata.org/about/our-research/\n\nCover Photo by ashutosh nandeshwar on Unsplash\n\n\n### Inspiration\n\nThe Center for Retirement Research often produces research briefs based on this data, which can be found here:\nhttp://publicplansdata.org/research/issue-briefs/?category=crr\n\nQuestions I have been pursuing using this data:\n\n* What has been driving decreasing funded ratios in U.S. pensions?\n* Which pension plans are sustainable? Which are in trouble?\n* Is there a link between pension fundedness and investment strategy?\n\nIt may be useful to link these data sets to information on various state/local revenue amounts, in order to determine sustainability of pension costs.'","b""['finance', 'demographics', 'government', 'small', 'featured']""",https://www.kaggle.com/meepbobeep/us-public-pensions-data-fiscal-years-20012016
b'Stanford Open Policing Project - Ohio',b'Data on Traffic and Pedestrian Stops by Police in Ohio',"b""###Context: \n\nOn a typical day in the United States, police officers make more than 50,000 traffic stops. The Stanford Open Policing Project team is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public.\n\nIf you'd like to see data regarding other states, please go to https://www.kaggle.com/stanford-open-policing.\n\n### Content: \n\nThis dataset includes over 1 gb of stop data from Ohio. Please see the data readme for the full details of the available fields.\n\n###Acknowledgements:\n\nThis dataset was kindly made available by the [Stanford Open Policing Project][1]. If you use it for a research publication, please cite their [working paper][2]:\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, V. Ramachandran, C. Phillips, S. Goel. (2017) \xe2\x80\x9cA large-scale analysis of racial disparities in police stops across the United States\xe2\x80\x9d.\n\n###Inspiration: \n\n - How predictable are the stop rates? Are there times and places that\n   reliably generate stops?\n - Concerns have been raised about jurisdictions using civil forfeiture\n   as a funding mechanism rather than to properly fight drug\n   trafficking. Can you identify any jurisdictions that may be\n   exhibiting this behavior?\n\n  [1]: https://openpolicing.stanford.edu/\n  [2]: https://5harad.com/papers/traffic-stops.pdf""","b""['crime', 'law', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/stanford-open-policing/stanford-open-policing-project-ohio
b'Between Our Worlds: An Anime Ontology',"b'A Linked Open Dataset of Over 390,000 Anime'","b'### Context: \n\n**Linked data**: \xe2\x80\x9cLinked open data is linked data that is open content. In computing, linked data (often capitalized as Linked Data) is a method of publishing structured data so that it can be interlinked and become more useful through semantic queries. It builds upon standard Web technologies such as HTTP, RDF and URIs, but rather than using them to serve web pages for human readers, it extends them to share information in a way that can be read automatically by computers. This enables data from different sources to be connected and queried.\xe2\x80\x9d -- [\xe2\x80\x9cLinked Open Data\xe2\x80\x9d on Wikipedia](https://en.wikipedia.org/wiki/Linked_data#Linked_open_data)\n\n**Anime**: \xe2\x80\x9cAnime is a Japanese term for hand-drawn or computer animation. The word is the abbreviated pronunciation of ""animation"" in Japanese, where this term references all animation. Outside Japan, anime is used to refer specifically to animation from Japan or as a Japanese-disseminated animation style often characterized by colorful graphics, vibrant characters and fantastical themes.\xe2\x80\x9d -- [\xe2\x80\x9cAnime\xe2\x80\x9d on Wikipedia](https://en.wikipedia.org/wiki/Anime)\n\nThis dataset is a linked open dataset that contains information on 391706 anime titles.\n\n### Content: \n\nThis dataset contains two files. The first is the native [N-Triples format](https://en.wikipedia.org/wiki/N-Triples), which is suitable for tasks. The second is a .csv containing three columns:\n\n* **Anime**: the title of the anime\n* **Concept**: the concept\n* **Value**: the value of the concept for that anime\n\nThe .csv is not a true linked data dataset, since it has removed many of the relevant URL\xe2\x80\x99s. However, it should prove easier for data analysis.\n\n### Acknowledgements: \n\nThis dataset has been collected and maintained by Pieter Heyvaert. It is \xc2\xa9 Between Our Worlds and reproduced here under an [MIT license](https://opensource.org/licenses/MIT). You can find more information on this dataset and the most recent version [here](https://betweenourworlds.org/). \n\n### Inspiration: \n\n* Many anime have summaries, under the \xe2\x80\x9cdescription\xe2\x80\x9d concept. Can you use these to identify common themes in anime? What about training an anime description generator? \n* Can you plot the number of titles released over time? Has the rate of anime production increased or decreased over time?\n'","b""['internet', 'popular culture', 'information technology', 'medium', 'featured']""",https://www.kaggle.com/rtatman/between-our-worlds-an-anime-ontology
b'Austin Bike Share Trips',b'Information on 649k Bike Rides Across Austin',"b'### Context: \nBike shares are becoming a popular alternative means of transportation. The City of Austin makes data available on >649k bike trips over 2013-2017.\n\n### Content: \nThis data includes information on bike trip start location, stop location, duration, type of bike share user. Bike station location data is also provided.\n\n###Dataset Description\n\n***Use this dataset with BigQuery***\n\nYou can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the [data on BigQuery, too](https://cloud.google.com/bigquery/public-data/).\n\n***austin_bikeshare_trips.csv***\n\n* bikeid: integer id of bike \n* checkout_time: HH:MM:SS, see start time for date stamp\n* duration_minutes: int minutes of trip duration\n* end_station_id: integer id of end station\n* end_station_name: string of end station name\n* month: month, integer\n* start_station_id: integer id of start station\n* start_station_name: string of start station name\n* start_time: YYYY-MM-DD HH:MM:SS\n* subscriber_type: membership typ e.g. walk up, annual, other bike share, etc\n* trip_id: unique trip id int\n* year: year of trip, int\n\n***austin_bikeshare_stations.csv***\n\n* latitude: geospatial latitude, precision to 5 places\n* location: (lat, long)\n* longitude: geospatial longitude, precision to 5 places\n* name: station name, str\n* station_id: unique station id, int\n* status: station status (active, closed, moved, ACL-only)\n\n\n### Acknowledgements: \nThis dataset is available from [Google Public Data](https://cloud.google.com/bigquery/public-data/ ).\n\n### Inspiration: \n* What stations are most popular? At certain times?\n* What are the average user trip? \n* Can you predict station usage to improve the ability of bike share employees to supply high-use stations?'","b""['cycling', 'medium', 'featured']""",https://www.kaggle.com/jboysen/austin-bike
b'Brazilian Portuguese Literature Corpus',b'3.7 million word corpus of Brazilian literature published between 1840-1908',"b'### Context: \nBrazilian literature is the literature written in the Portuguese language by Brazilians or in Brazil, including works written prior to the country\xe2\x80\x99s independence in 1822. Throughout its early years, literature from Brazil followed the literary trends of Portugal, whereas gradually shifting to a different and authentic writing style in the course of the 19th and 20th centuries, in the search for truly Brazilian themes and use of the Portuguese language.\n\n### Content: \nThis dataset contains over 3.7 million words of Brazilian literature written between 1840 and 1908. There are 81 distinct works in this corpus, written by Adolfo Caminha, Aluisio Azevedo, Bernardo Guimaraes, Joaquim Manuel de Macedo, Jose de Alencar, Machado de Assis and Manuel Antonio de Almeida.\n\n### Inspiration: \n\n*  Can you automatically identify topics/themes in each of these works?\n*  Can you automatically identify the author of a specific text? (You might want to split each author\xe2\x80\x99s works into a test set and training set.)'","b""['linguistics', 'languages', 'brazil', 'literature', 'medium', 'featured']""",https://www.kaggle.com/rtatman/brazilian-portuguese-literature-corpus
b'Brazilian Stock Market Tweets with Emotions',b'Tweets related to IBOVESPA stocks with emotions annotated by crowdsourcing',"b'### Context\n\nThis corpus was created during my PhD research at the Institute of Computing, from University of Campinas under supervision of Professors Ariadne Carvalho and Norton Roman. It consists on a crowd-sourcing experiment for annotating emotions on tweets related to the Brazilian stock market.\n\n### Content\n\nWe made available the following output from our annotation system:\n\n**tweets_annotators.csv**: A list of all annotators and their profiles (without personal information)\n\n**tweets.csv**: A list of all tweets available for annotation\n\n**tweets_annotations.csv**: All the individual annotations with emotions, also indicating the annotator and the tweet id and \nthe annotation date and time\n\n**tweets_stocks.csv**: The final corpus with annotations after considering the majority of annotators, containing only tweets with at least 3 annotations\n\n**tweets_stocks-full_agreement.csv**: A tweets_stocks.csv subset containing only tweets annotated by at least 3 people, in which all of them agreed upon the emotions or only one marked as ""don\'t know""\n'","b""['finance', 'twitter', 'brazil', 'emotion', 'small', 'featured']""",https://www.kaggle.com/fernandojvdasilva/stock-tweets-ptbr-emotions
b'YouTube Comedy Slam',b'Votes for the funniest videos',"b""### Context\n\nThis dataset provides user vote data on which video from a pair of videos was funnier. YouTube Comedy Slam was a discovery experiment running on YouTube 2011 and 2012. In the experiment, pairs of videos were shown to users and the users voted for the video that they found funniest. \n\n### Content\n\nThe datasets includes roughly 1.7 million votes recorded chronologically. The first 80% are provided here as the training dataset and the remaining 20% as the testing dataset. \n\nEach row in this text file represents one anonymous user vote and there are three comma-separated fields. \n\n- The first two fields are YouTube video IDs. \n- The third field is either 'left' or 'right'. \n  - Left indicates the first video from the pair was voted to be funnier than the second. Right indicates the opposite preference.\n\n### Acknowledgements\n\nSanketh Shetty, 'Quantifying comedy on YouTube: why the number of o's in your LOL matter,' Google Research Blog, [https://research.googleblog.com/2012/02/quantifying-comedy-on-youtube-why.html][1].\n\nDataset was downloaded from UCI ML repository:\n[https://archive.ics.uci.edu/ml/datasets/YouTube+Comedy+Slam+Preference+Data][2]\n\n  [1]: https://research.googleblog.com/2012/02/quantifying-comedy-on-youtube-why.html\n  [2]: https://archive.ics.uci.edu/ml/datasets/YouTube+Comedy+Slam+Preference+Data\n\n### Inspiration\n\nPredict which videos are going to be funny!""","b""['humor', 'medium', 'featured']""",https://www.kaggle.com/uciml/youtube-comedy-slam
b'FiveThirtyEight Airline Safety Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Airline Safety\n\nThis folder contains the data behind the story [Should Travelers Avoid Flying Airlines That Have Had Crashes in the Past?](http://fivethirtyeight.com/features/should-travelers-avoid-flying-airlines-that-have-had-crashes-in-the-past/)\n\nHeader | Definition\n---|---------\n`airline` | Airline (asterisk indicates that regional subsidiaries are included)\n`avail_seat_km_per_week` | Available seat kilometers flown every week\n`incidents_85_99` | Total number of incidents, 1985\xe2\x80\x931999\n`fatal_accidents_85_99` | Total number of fatal accidents, 1985\xe2\x80\x931999\n`fatalities_85_99` | Total number of fatalities, 1985\xe2\x80\x931999\n`incidents_00_14` | Total number of incidents, 2000\xe2\x80\x932014\n`fatal_accidents_00_14` | Total number of fatal accidents, 2000\xe2\x80\x932014\n`fatalities_00_14` | Total number of fatalities, 2000\xe2\x80\x932014\n\nSource: [Aviation Safety Network](http://aviation-safety.net)\n  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.  \n\n[Cover photo](https://unsplash.com/photos/aSJxeQAMDpA) by [Anton Porsche](https://unsplash.com/@superanton) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-airline-safety-dataset
b'Deceptive Opinion Spam Corpus',b'A corpus of truthful and deceptive hotel reviews',"b'### Context\nThis corpus consists of truthful and deceptive hotel reviews of 20 Chicago hotels. The data is described in two papers according to the sentiment of the review. In particular, we discuss positive sentiment reviews in [1] and negative sentiment reviews in [2].\nWhile we have tried to maintain consistent data preprocessing procedures across the data, there are differences which are explained in more detail in the associated papers. Please see those papers for specific details.\n\n### Content\nThis corpus contains:\n\n* 400 truthful positive reviews from TripAdvisor (described in [1])\n* 400 deceptive positive reviews from Mechanical Turk (described in [1])\n* 400 truthful negative reviews from Expedia, Hotels.com, Orbitz, Priceline, TripAdvisor and Yelp (described in [2])\n* 400 deceptive negative reviews from Mechanical Turk (described in [2])\n\nEach of the above datasets consist of 20 reviews for each of the 20 most popular Chicago hotels (see [1] for more details). The files are named according to the following conventions:\nDirectories prefixed with fold correspond to a single fold from the cross-validation experiments reported in [1] and [2].\n\n### Hotels included in this dataset\n\n* affinia: Affinia Chicago (now MileNorth, A Chicago Hotel)\n* allegro: Hotel Allegro Chicago - a Kimpton Hotel\n* amalfi: Amalfi Hotel Chicago\n* ambassador: Ambassador East Hotel (now PUBLIC Chicago)\n* conrad: Conrad Chicago\n* fairmont: Fairmont Chicago Millennium Park\n* hardrock: Hard Rock Hotel Chicago\n* hilton: Hilton Chicago\n* homewood: Homewood Suites by Hilton Chicago Downtown\n* hyatt: Hyatt Regency Chicago\n* intercontinental: InterContinental Chicago\n* james: James Chicago\n* knickerbocker: Millennium Knickerbocker Hotel Chicago\n* monaco: Hotel Monaco Chicago - a Kimpton Hotel\n* omni: Omni Chicago Hotel\n* palmer: The Palmer House Hilton\n* sheraton: Sheraton Chicago Hotel and Towers\n* sofitel: Sofitel Chicago Water Tower\n* swissotel: Swissotel Chicago\n*  talbott: The Talbott Hotel\n\n### References\n[1] M. Ott, Y. Choi, C. Cardie, and J.T. Hancock. 2011. Finding Deceptive Opinion Spam by Any Stretch of the Imagination. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies.\n\n[2] M. Ott, C. Cardie, and J.T. Hancock. 2013. Negative Deceptive Opinion Spam. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.\n\n### Acknowledgements\nIf you use any of this data in your work, please cite the appropriate associated paper (described above). Please direct questions to Myle Ott (myleott@cs.cornell.edu).'","b""['linguistics', 'languages', 'small', 'featured']""",https://www.kaggle.com/rtatman/deceptive-opinion-spam-corpus
b'Every song you have heard (almost)!',"b'Over 500,000 song lyrics, urls for over a million artists'","b""### Context\n\nI collected this data to create a machine learning model capable of writing it's own poems. I came up with the idea of using songs as a source. The dataset creation journey wasn't easy because each song has it's own unique page with lyrics. I quickly realized that there weren't a lot of places to extracting data in a straightforward manner.  Scraping pages one at a time (when there are over a million of them) is a slow task. There is a lot to play with here.\n\n\n### Content\n\nThere are three data files. The main dataset is split up into 2 files, each containing ~250,000 songs with their artists and lyrics. \n\n**Lyrics1** - Contains 250,000 songs with artist and lyrics\n\n**Lyrics2** - Contains an additional 250,000 songs with artist and lyrics \n\n**ArtistUrl.csv** -Contains URL data for where the lyrics were gathered\n\n\n### Acknowledgements\n\nFor people interested in seeing how I collected the data: [GITHUB PROJECT][1].\n\n[https://www.lyrics.com/][2] deserves major credit for the existence of this dataset.\n\n## Inspiration\n\nThis started off as a source for some kind of intelligent poet which writes poems on it's own. It would be great to see what the artificially intelligent world has to express once it knows enough, and beautifully if at all?\n\n![enter image description here][3]\n  [1]: https://github.com/SoumitraAgarwal/Webscraping-Text-Data\n  [2]: http://www.lyrics.com\n  [3]: https://unsplash.com/photos/6mXWOm43zZg/download?force=true""","b""['internet', 'languages', 'music', 'medium', 'featured']""",https://www.kaggle.com/artimous/every-song-you-have-heard-almost
b'Star Wars Movie Scripts',b'May the Force be with you',"b""### Context\n\nThis is my particular tribute to the [Star Wars Day](https://en.wikipedia.org/wiki/Star_Wars_Day), on May 4.\n\nStar Wars is a popular film franchise that takes place in a galaxy far, far away. This is a collection of script dialogue between characters for the first three movies (episodes 4-6). Since it's a holiday (and just because Star Wars is an awesome movie), this data should serve as a fun way to implement text mining and linguistics.\n\n### Content\n\n**SW_EpisodeIV.txt** - Script from the Episode IV:  A New Hope with columns `character` and `dialogue`.\n\n**SW_EpisodeV.txt** - Script from the Episode V: The Empire Strikes Back with columns `character` and `dialogue`.\n\n**SW_EpisodeVI.txt** - Script from the Episode VI: Return of the Jedi with columns `character` and `dialogue`.\n\n**wordcloud_masks.zip** - Zip file including the masks used for the worclouds. \n\n### Acknowledgements\n\nThe input files from **Gaston Sanchez** are available [here](https://github.com/gastonstat/StarWars/tree/master/Text_files)\n\nStar Wars is owned by [Lucasfilms][1]. I do not own any of the rights to this information.\n\n### Inspiration\n\n- Try text mining!\n- Use this data to produce a sentiment analysis\n\n\n  [1]: http://lucasfilm.com/""","b""['text mining', 'popular culture', 'small', 'featured']""",https://www.kaggle.com/xvivancos/star-wars-movie-scripts
b'NY Daily Inmates In Custody',b'From New York City Open Data',"b""### Content  \n\nDaily inmates in custody with attributes (custody level, mental health designation, race, gender, age, leagal status, sealed status, security risk group membership, top charge,  and infraction flag). This data set excludes Sealed Cases. Resulting summaries may differ slightly from other published statistics.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/6L-CyQwz8W8) by [Fredrik \xc3\x96hlander](https://unsplash.com/@fredrikohlander) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-daily-inmates-in-custody
b'NYS Energy Efficiency Portfolio Standard Prog Data',b'From New York State Open Data',"b""### Content  \n\nThe Energy Efficiency Portfolio Standard (EEPS) Program encourages cost-effective electric and natural gas energy efficiency across New York State.  New York State\xe2\x80\x99s utilities and the New York State Energy Research and Development Authority (NYSERDA) administer energy efficiency programs to achieve energy efficiency savings. EEPS energy efficiency programs provide technical services, information and customer incentives to encourage customers in implementing energy efficiency measures.  This data includes the list of energy efficiency programs and the estimated energy savings reported for each program.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/lFDlj80gJ4A) by [Axel Antas-Bergkvist](https://unsplash.com/@abl) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-energy-efficiency-portfolio-standard-prog-data
b'New York State Annual Population Estimates',b'From New York State Open Data',"b""### Content  \n\nResident population of New York State and counties.  Estimates are based on Census counts (base population), intercensal estimates, and postcensal estimates.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/7hmCn_YE3aU) by [Andre Benz](https://unsplash.com/@trapnation) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/new-york-state-annual-population-estimates
b'Asbestos Clean-up in Poland',b'Is Poland on track to be free of asbestos by 2032?',"b'### Context\n\nFirst, what is asbestos? Well it is a mineral that can be pulled into fine fibres with high resistance to heat, electricity and chemical corrosion. In the past it was a common ingredient in construction materials (caveat: this is at least true for the European Union). Why in the past? Asbestos is a threat to health due to its very fibre structure. Those microscopic fibers can become trapped in the respiratory system, causing cancer and other disease decades after exposure.\n\nSecond, where is Poland?! The answer depends on how grumpy the internet is on that day. My home country, Poland, is located in the Eastern or Central Europe. Poland joined the European Union in 2004 and suddenly stuff was required of her. Strangely enough, Poland is the only European country that plans to be free of asbestos by 2032. The National Asbestos Cleaning Program program was initiated in 2009 with one of the aims to create a complete database of asbestos contamination by 2012. In this blog post I\xe2\x80\x99m hoping to shed some light on the progress of this ambitious plan.\n\n### Content\n\nThe database is run by the Ministry of Development and should be updated yearly. It was originally uploaded on March 21st 2016 and then updated 8 months later. As far as I can see they don\xe2\x80\x99t keep older versions. The spreadsheet contains columns with the total number of asbestos in the given location (in kilograms), how much of that has been utilised (also in kilograms) and how much still needs to be utilised (not kidding). There is also name of the place and its code TERYT. TERYT translates as the National Official Register of the Territorial Division of the Country. It is a very useful thing in identifying cities and regions, especially for languages that include certain letters with diacritics, the overdot, the tail and the stroke. As a side note, TERYT code for asbestos dataset was incomplete i.e. missing the last digit (!). In addition, there was no metadata that describes the data collection process or time when it was taken.\n\n### Acknowledgements\n\nThis dataset was downloaded from the Polish Public Data and  is considered public data and can be used under following restrictions:\n- One should inform about the source of this data and the creation time of reused information as well\n\n### Inspiration\n\nIs Poland on track to be free of asbestos by 20132?'","b""['pollution', 'small', 'featured']""",https://www.kaggle.com/pinsleepe/asbestos-cleanup-in-poland
"b'Homicide Reports, 1980-2014'",b'Can you develop an algorithm to detect serial killer activity?',"b""# Content\n\nThe Murder Accountability Project is the most complete database of homicides in the United States currently available. This dataset includes murders from the FBI's Supplementary Homicide Report from 1976 to the present and Freedom of Information Act data on more than 22,000 homicides that were not reported to the Justice Department. This dataset includes the age, race, sex, ethnicity of victims and perpetrators, in addition to the relationship between the victim and perpetrator and weapon used.\n\n# Acknowledgements\n\nThe data was compiled and made available by the Murder Accountability Project, founded by Thomas Hargrove.""","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/murderaccountability/homicide-reports
b'NYS Earned Income Tax Credit (EITC) Claims',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/kJklWKtND7w) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-earned-income-tax-credit-eitc-claims
b'Indian Startup Funding',b'Funding details of the startups in India',"b'### Context\n\nInterested in the Indian startup ecosystem just like me? Wanted to know what type of startups are getting funded in the last few years? Wanted to know who are the important investors? Wanted to know the hot fields that get a lot of funding these days? \n This dataset is a chance to explore the Indian start up scene. Deep dive into funding data and derive insights into the future!\n\n### Content\n\nThis dataset has funding information of the Indian startups from January 2015 to August 2017. It includes columns with the date funded, the city the startup is based out of, the names of the funders, and the amount invested (in USD).  \n\nFor more information on the values of individual fields, check out the [Column Metadata](https://www.kaggle.com/sudalairajkumar/indian-startup-funding/data).\n\n### Acknowledgements\n\nThanks to [trak.in][1] who are generous enough to share the data publicly for free. \n\n\n\n### Inspiration\n\nPossible questions which could be answered are:\n\n* How does the funding ecosystem change with time?\n* Do cities play a major role in funding?\n* Which industries are favored by investors for funding?\n* Who are the important investors in the Indian Ecosystem?\n* How much funds does startups generally get in India?\n\n  [1]: http://trak.in/'","b""['finance', 'india', 'lending', 'small', 'featured']""",https://www.kaggle.com/sudalairajkumar/indian-startup-funding
b'CPI for All Urban Consumers: All Items',b'Explore Time Series from the BLS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Bureau of Labor Statistics](http://www.bls.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according to the frequency that the data updates. Explore the OECD using Kaggle and all of the data sources available through the BLS [organization page](https://www.kaggle.com/bls)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/bls/cpi-for-all-urban-consumers-all-items
b'Chicago Flu Shot Clinic Locations - 2012',b'From City of Chicago Open Data',"b""### Content  \n\nList of Chicago Department of Public Health free flu clinics offered throughout the city. For more information about the flu, go to http://bit.ly/9uNhqG.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/H7VezrWRqCg) by [Marcus Wright](https://unsplash.com/@marcuswright) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'health', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-flu-shot-clinic-locations-2012
b'Indian Hotels on Cleartrip',b'This dataset contains Indian hotel (5000) present on Cleartrip.com',"b""### Context\n\nThis is a pre-crawled dataset, taken as subset of a [bigger dataset (more than 42,000 hotels)][1] that was created by extracting data from Cleartrip.com, a leading travel portal in India. \n\n### Content\n\nAnalyses can be performed on the hotel description, facilities and various ratings to name a few.\n\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud's in-house web-crawling service.\n\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=kaggle&utm_medium=referral""","b""['internet', 'hotels', 'medium', 'featured']""",https://www.kaggle.com/PromptCloudHQ/indian-hotels-on-cleartrip
"b'French Presidential Election, 2017'",b'Results of both rounds at polling station level',"b""Presidential elections have just finished in France, with two rounds on April 23rd and May 7th 2017. The results of the elections are available online for each ~67000 polling stations around the country. This data can be used to gain insights about both the electorate and the candidates.\nExamples of basic questions worth looking at are: \n\n - How are candidates' scores correlated with each other? Can you infer 'political affinity' of the candidates just looking at the data, without any other a priori knowledge? \n\n - How are scores of various candidates correlated with the turnout? Supporters of which candidate are the most 'participative'? \n\n - How did the votes get redistributed from the first to the second round? Can you build an a posteriori predictive model of the second round results taking as an input the results of the first round ?\n\n - The data provides coordinates of each polling station. Can you gain any insight from the geography?\n\nSome preliminary analysis is described in two blog posts [here][1] and [here][2].\nThis dataset is inspired by an analogous one for the [2016 US elections][3] by Ben Hamner.\n\n[1]: https://grishaoryol.wordpress.com/2017/05/17/vote-transfers-in-french-election/\n[2]: https://grishaoryol.wordpress.com/2017/05/24/french-presidential-elections-2-the-turnout/\n[3]: https://www.kaggle.com/benhamner/2016-us-election""","b""['politics', 'medium', 'featured']""",https://www.kaggle.com/grishasizov/frenchpresidentialelection2017
b'Describing New York City Roads',b'A Collection of Road Variables in New York for the Taxi Playground Challenge',"b'### Author\'s Note:\n\nThis dataset was originally coined: ""Speed Limits in New York City"". Since then, I have changed the name of the dataset to ""Describing New York City Roads"" to better reflect the contents of the dataset.\n\n\\- Curtis\n\n### Context\n\n\n**New York City Speed Limits**\n\n\nThe New York Department of Transportation Regulates the speed limits for its roads (Afterall, we can\'t be hitting 88 MPH on a regular day). This dataset describes the speed limits for particular road segments of New York City streets.\n\n\n\n**The New York City Centerline**\n\nWhich streets are inherently faster? How will speed limits come into play? How will nearby bike lanes slow down vehicles (and ultimately taxis)? These are the kinds of questions that can only be answered with contextual data of the streets themselves.\n\n\nFortunately, most major cities provide a public Centerline file that describes the path of all railroads, ferry routes, and streets in the city. I\'ve taken the New York City Centerline and packaged a dataset that tries to extract meaning out of all the road connections within the city.\n\n## Content\n\n### New York City Speed Limits\n\nEvery speed limit region is a straight line. (Which represents a segment of road). These lines are expressed by two pairs of coordinates.\n\n\n**lat1** - The first latitude coord\n\n**lon1** - The first longitude coord\n\n**lat2** - The second latitude coord\n\n**lat2** - The second longitude coord\n\n**street** - The name of the street the speed limit is imposed on\n\n**speed** - The speed limit of that road section\n\n**signed** - Denotes if there is a physical sign on the street that displays the speed limit to cars.\n\n**region** - The city region that the road resides in. There are 5 regions: (Bronx, Brooklyn, Manhattan, Queens, and Staten Island)\n\n**distance** - The length of the speed limit road section (in Miles).\n\n\n\n\n### The New York City Centerline\n\n**street** - The name of the street\n\n**post_type**\\* - The extension for the street name.\n\n**st_width** - The width of the street (in feet). There are varying widths for the size of a street so it was hard to derive a lane count/ street using this feature. As a rule of thumb, the average lane is around 12 feet wide.\n\n**bike_lane** - Defines which segments are part of the bicycle network as defined by the NYC Department of Transportation. There are 11 classes: \n\n - 1 =  Class I\n\n - 2 = Class II\n\n - 3 = Class III\n\n - 4 = Links\n\n - 5 = Class I, II\n\n - 6 = Class II, III\n\n - 7 = Stairs\n\n - 8 = Class I, III\n\n - 9 = Class II, I\n\n - 10 = Class III, I\n\n - 11 = Class III, II\n\nBike class information: https://en.wikipedia.org/wiki/Cycling_in_New_York_City#Bikeway_types\n\n\n\n\n**bike_traf_dir**\\*\\* - Describes the direction of traffic: (FT = With, TF = Against, TW = Two-Way)\n\n**traf_dir**\\*\\* - Describes the direction of traffic: (FT = With, TF = Against, TW = Two-Way)\n\n**rw_type** - The type of road. There are 6 types of roads: (1 = Street, 2 = Highway, 3 = Bridge, 4 = Tunnel, 9 = Ramp, 13 = U-Turn). Note: I parsed awkward path types such as ""Ferry route"" and ""trail"".\n\n**start_contour**\\*\\*\\* - Numeric value indicating the vertical position of the feature\'s ""from"" node relative to grade level.\n\n**end_contour**\\*\\*\\* - Numeric value indicating the vertical position of the feature\'s ""to"" node relative to grade level.\n\n**snow_pri** - The Department of Sanitation (DSNY) snow removal priority designation.\n\n - V = Non-DSNY\n\n - C = Critical (These streets have top priority)\n\n - S = Sector (These streets are second priority)\n\n - H = Haulster (Small spreaders with plows attached for treating areas with limited accessibility - can hold two tons of salt)\n\n\n\n**region** - The city region that the road resides in. There are 5 regions: (Bronx, Brooklyn, Manhattan, Queens, and Staten Island)\n\n**length** - The length of the road (in Miles). \n\n**points** -  The coordinates that define the road. Each coordinate is separated by \'|\' and the lat and lon values per coordinate are\nseparated by \';\'. (Side note: Round road sections are plotted by points along the curve).\n\n\n\n*For those who may not be aware, road names are based on a convention. ""Avenue""s, ""Boulevard""s, and ""Road""s are different for distinct reasons. I left these fields in the dataset in case you wish to find any patterns that are pertinent to those types of roads. To learn more about road conventions, visit this link: http://calgaryherald.com/news/local-news/in-naming-streets-strict-rules-dictate-roads-rises-trails-and-more\n\n\n**To explain how direction works I\'ll provide you with an image: http://imgur.com/a/UflwX. Think of every road on the centerline as a vector. It points from one location to another. It always points from the very first coordinate to the very last coordinate. Now pay attention to the direction of the road (circled). Note how it points in the same direction as the vector denoted by the centerline data. The ""traf_dir"" attribute of the street is ""FT"" because the vector is headed in the same direction as traffic is (it is a one-way street). For ""traf_dir"" with a value of ""TW"", the direction of the vector doesn\'t matter as the road is a two-way street.\n\n\n***I\'ve had little luck finding what the ""grade levels"" represent. The original aliases are ""TO_LVL_CO"" and ""FRM_LVL_CO"". I\'ll keep searching tonight and will try to dig up what elevation these grades represent. I highly suspect the grades are contour lines because I know they have some relevance to elevation.  In the meantime here are the ""grades"" that each value represents:\n\n - 1 = Below Grade 1\n\n - 2 = Below Grade 2\n\n - 3 = Below Grade 3\n\n - 4 = Below Grade 4\n\n - 5 = Below Grade 5\n\n - 6 = Below Grade 6\n\n - 7 = Below Grade 7\n\n - 8 = Below Grade 8\n\n - 9 = Below Grade 9\n\n - 10 = Below Grade 10\n\n - 11 = Below Grade 11\n\n - 12 = Below Grade 12\n\n - 13 = At Grade\n\n - 14 = Above Grade 1\n\n - 15 = Above Grade 2\n\n - 16 = Above Grade 3\n\n - 17 = Above Grade 4\n\n - 18 = Above Grade 5\n\n - 19 = Above Grade 6\n\n - 20 = Above Grade 7\n\n - 21 = Above Grade 8\n\n - 22 = Above Grade 9\n\n - 23 = Above Grade 10\n\n - 24 = Above Grade 11\n\n - 25 = Above Grade 12\n\n - 26 = Above Grade 13\n\n - 99 = Not Applicable\n\n\n\n\nAll in all, their documentation could be better and here is a reference to it if you want to look at the source: (https://data.cityofnewyork.us/api/views/exjm-f27b/files/cba8af99-6cd5-49fd-9019-b4a6c2d9dff7?download=true&filename=Centerline.pdf)\n\n\n\n### Acknowledgements\n\nI want to thank the New York City Department of Transportation (NYCDOT) and the city of New York for aggregating the original data sets.\n\n\n**New York City Speed Limits**\nhttp://www.nyc.gov/html/dot/html/about/vz_datafeeds.shtml\n28\xe2\x80\x9011 Queens Plaza, 8th FL\nLong Island City, New York 11101\n\n\n**The New York City Centerline**\nhttps://catalog.data.gov/dataset/nyc-street-centerline-cscl\ndata.cityofnewyork.us\nNew York, NY 10007'","b""['road transport', 'taxi services', 'medium', 'featured']""",https://www.kaggle.com/splacorn/speed-limits-in-nyc-taxi-playground-challenge
"b'Stack Overflow Developer Survey, 2017'","b'A look into the lives of over 64,000 Stack Overflow developers'","b'Every year, Stack Overflow conducts a massive survey of people on the site, covering all sorts of information like programming languages, salary, code style and various other information. This year, they amassed more than 64,000 responses fielded from 213 countries.\n\n### Data\n\nThe data is made up of two files:  \n1. `survey_results_public.csv` - CSV file with main survey results, one respondent per row and one column per answer  \n2. `survey_results_schema.csv` - CSV file with survey schema, i.e., the questions that correspond to each column name\nm\n### Acknowledgements\n\nData is directly taken from [StackOverflow](https://insights.stackoverflow.com/survey/) and licensed under the [ODbL license](http://opendatacommons.org/licenses/odbl/1.0/).'","b""['internet', 'information technology', 'medium', 'featured']""",https://www.kaggle.com/stackoverflow/so-survey-2017
b'go-nuts archive',b'200k raw emails from go-nuts Google group',"b""### Context\n\nI wanted to create a dataset to practice NLP using Go. go-nuts is an official Go mailing list, and it's messages are an ideal candidate.\n\n\n### Content\n\nThis dataset was created by crawling Google Groups using [ggmbox](https://github.com/vmarkovtsev/ggmbox). It is possible to fetch raw emails given their ID, so first all the topics were discovered and listed and then individual emails fetched. This dataset has **30043 topics with 190773 messages**.\n\n`golang-nuts.tar.xz` is the fetched emails as of 2018/02/24 and `index.json.gz` is metadata of each discussion topic. There is also `threads.csv.gz` with plain text messages per topic, in logical order and with some filtering performed. E.g. citations were removed. If you want to improve it or write a custom information extractor, refer to [parse.go](https://github.com/vmarkovtsev/ggmbox/blob/master/parse.go). Python users: emails can be loaded with [`email.message_from_file()`](https://docs.python.org/3/library/email.parser.html#email.message_from_file) but some additional work may be required to decode base64-encoded parts of some files, see [MIME](https://en.wikipedia.org/wiki/MIME).\n\n### Acknowledgements\n\nThe rights on the email contents belong to their respective authors. Idiomatic Go reviews of ggmbox code were done (and not finished yet!) by [Francesc Campoy](https://twitter.com/francesc). Crawling speed is thanks to [Scrapy](https://scrapy.org/). Hardware and mental support by [source{d}](https://sourced.tech). Idea inspired by [GopherCon Russia](https://www.gophercon-russia.ru/).""","b""['linguistics', 'programming', 'programming languages', 'medium', 'featured']""",https://www.kaggle.com/vmarkovtsev/gonuts
b'NYS Biological Monitoring Sampling Locations',b'From New York State Open Data',"b""### Content  \n\nThe Division of Water Stream Biomonitoring Unit (SBU) dataset contains the point sampling locations at which benthic macroinvertebrates, field chemistry, and at some locations, sediment, fish or diatoms have been collected as part of the Rotating Integrated Basin Studies (RIBS) program, Rapid Biological Assessments (RAS), or special studies. The data collected are used for water quality assessment (input to the Waterbody Inventory, completion of the 305(b) report and 303(d) list of impaired Waters) and for track-down of water quality problems. The data set is maintained by the Division of Water, Bureau of Water Assessment and Management, Stream Biomonitoring Unit.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/rFBA42UFpLs) by [Matthew Smith](https://unsplash.com/@whale) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'rivers', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-biological-monitoring-sampling-locations
b'Cato 2017 Human Freedom Index',b'Personal and Economic ratings of freedom among various dimensions',"b'### Context\n\nThis dataset is a copy of the 2017 Human Freedom Index dataset released by the [Cato Institute](https://www.cato.org/), a libertarian think tank. The dataset uses 2015 data and index-ranks human freedoms in various countries around the world. For more on the Cato Institute, which funded this study, refer to [its Wikipedia article](https://en.wikipedia.org/wiki/Cato_Institute).\n\n### Content\n\nThe data contains a sequence of hierarchical related metrics rated from 0 to 10, with each record corresponding with a country. The data itself in original form can be found at https://www.cato.org/human-freedom-index, alongside an almost 400-page report.\n\nTo see the list of metrics refer [here](https://www.doyouevendata.com/wp-content/uploads/2018/03/cato.gif).\n\n### Acknowledgements\n\nThis dataset was produced by the [Cato Institute](https://www.cato.org).\n\n### Inspiration\n\nI have uploaded this dataset in the potential to find use with the Kiva microfinance data.  Kiva involves lending to poor entrepreneurs and folk around the world who have difficulty accessing credit.  Greater personal and economic freedom leads to greater personal and market growth, allowing entrepreneurs to grow themselves and others into achieving higher standards of living.'","b""['economics', 'politics', 'countries', 'women', 'small', 'featured']""",https://www.kaggle.com/doyouevendata/cato-2017-human-freedom-index
b'Family Households with Married Couples Data',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nHousehold is an occupied housing unit.\n Householder is a person in whose name the housing unit is rented or owned. This person must be at least 15 years old.\n Family household is a household in which there is at least 1 person present who is related to the householder by birth, marriage or adoption. \n Family is used to refer to a family household. In general, family consists of those related to each other by birth, marriage or adoption.\n\n This data uses the householder's person weight to describe characteristics of people living in households. As a result, estimates of the number of households do not match estimates of households from the Housing Vacancy Survey (HVS). The HVS is weighted to housing units, rather than the population, in order to more accurately estimate the number of occupied and vacant housing units. For more information about the source and accuracy statement of the Annual Social and Economic Supplement (ASEC) of the Current Population Survey (CPS) see the technical documentation accessible at: http://www.census.gov/programs-surveys/cps/technical-documentation/complete.html  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n* Observation Start: 1940-01-01  \n* Observation End  : 2018-01-01  \n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\nThis data was released under: [Families and Living Arrangements](https://www.census.gov/topics/families/families-and-households.html)  \nDataset Source of Release: [U.S. Bureau of the Census](http://www.census.gov/)""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/family-households-with-married-couples-data
b'Indoor location determination with RSSI',"b'120K RSSI samples to determine X,Y,Z coordinates in a two-level building'","b'### Context\n\nIn 2007, I wrote my masters thesis on indoor location determination using Wi-Fi received signal strength indicator (RSSI). As a part of my research, I gathered 120K RSSI samples from 4 access points on floor 1 and 2 of the building of my faculty. I wrote a custom software to do this (no reliable open source software for this at the time) and sampling was a long and painful process. With my limited ML learning skills at the time, I came up with a simple algorithm that was able to find the location of a Wi-Fi device in that building with 85% accuracy. \nI imagine this is a solved problem now and state of the art indoor positioning systems are way more accurate today. Yet, I decided to find and publish this data set because it\'s small and simple enough for practice and at the same time, it has some peculiarity for advanced data science and ML fun. \n\n### Content\nThe samples were taken in a two-level building. Each row in the dataset is a single RSSI sample from one of the 4 access points.\nAccess points are identified by one of the letters A, B, C, or D. Physical coordinates of the location where each sample was taken is identified by X,Y, Z coordinates with Z being the floor (1 or 2). At each coordinate, multiple samples are taken, where sample number is identified by a field name *sequence*.  The reason for taking multiple samples is that signal strength fluctuates due to things like scattering and reflection, specially in buildings with moving objects and people. So, to have reliable measurements, one needs 10s of samples from each access points to make for the variability.\n\nHaving- said this, each row of the sample set has the format:\n**ap ,signal, sequence ,x,y,z** where:\n\n**ap:** Access point identifier. one of A, B, C or D\n\n**signal:** Signal strength from access point *ap*.  **Note:** RSSI values in the table are negated. That is, smaller values in this cell mean stronger signal reception from the access point.\n\n**sequence:** The sequence of sample from this particular access point at this particular coordinate\n\n**x,y,z:**: Coordinates where this sample was taken\n\nNote: do not assume all locations have the same number of samples from all access points. For example, at location (x=1,y=1,z=1)\nwe might have  *a* samples from *A*, *b* samples from *B*, *c* samples from *C* and *d* samples from *D* and *a != b != c!= d*. Why? That\'s because in some areas we might have poor reception (or complete lack thereof) from an access point and so we end up with fewer or no samples. \n\nHere\'s the floor plan of the building where sampling took place  \n\n![Image](https://www.dropbox.com/s/fcv42i0d9egvadr/floor-plan.png?raw=1)\n\nThese are the locations of the access points:\n\n{""A"": (23, 17, 2), ""B"": (23, 41, 2), ""C"" : (1, 15, 2), ""D"": (1, 41, 2)}\n\nYou can also find the location of access points on the map. \n\nBy poking at this data and comparing it with the floor plan, you\'ll learn interesting things about Wi-Fi radio signals (in 2.4 GHz frequency) and how they behave in indoors. One challenge is to come up with a ML model that given RSSI from the 4 access points finds the (x,y,z) coordinates of the location.'","b""['internet', 'small', 'featured']""",https://www.kaggle.com/amirma/indoor-location-determination-with-rssi
b'European Parliament - Questions and Declarations',b'Explore EU Data from EU Parliament',"b""### Content  \n\nParliamentary questions are questions addressed by Members of the European Parliament to other European Union Institutions and bodies. They are a direct form of parliamentary scrutiny of other EU institutions and bodies. \n\nThere are three categories of parliamentary questions:\n\n- Questions for oral answer dealt with during plenary sittings, and included in the day's debates. They may be followed by a resolution (Rule 128) \n\n- Questions for Question Time asked during the period set aside for questions during plenary sittings (Rule 129) \n\n- Written questions with a request for a written answer (Rule 130) \n\nA written declaration is a text of a maximum of 200 words relating exclusively on a matter falling within the competence of the European Union. They do not, however, bind Parliament, that is, they cannot be considered as an act of the Parliament representing its position, but only those of its authors and signatories.  \n\n### Context  \n\nThis is a dataset from European Parliament hosted by the EU Open Data Portal. The Open Data Portal is found [here](http://data.europa.eu/euodp/en/home) and they update their information according the amount of data that is brought in. Explore European Parliament data using Kaggle and all of the data sources available through the European Parliament [organization page](https://www.kaggle.com/eu-parliament)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using the EU ODP [API](http://data.europa.eu/euodp/en/developerscorner) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\nThis dataset is distributed under the following license: [Legal Notice](http://ec.europa.eu/geninfo/legal_notices_en.htm)  \n\n[Cover photo](https://unsplash.com/photos/dsvJgiBJTOs) by [Will van Wingerden](https://unsplash.com/@willvanw) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['europe', 'small', 'featured']""",https://www.kaggle.com/eu-parliament/european-parliament-questions-and-declarations
b'Total Operating Expenses Time Series Collection',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/tdo2GLH18Ls) by [Gabriel Gurrola](https://unsplash.com/@gabrielgurrola) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/total-operating-expenses-time-series-collection
b'Amazon Reviews for Sentiment Analysis',b'A few million Amazon reviews in fastText format',"b""This dataset consists of a few million Amazon customer reviews (input text) and star ratings (output labels) for learning how to train fastText for sentiment analysis.\n\nThe idea here is a dataset is more than a toy - real business data on a reasonable scale - but can be trained in minutes on a modest laptop.\n\n# Content\n\nThe [fastText supervised learning tutorial](https://github.com/facebookresearch/fastText/blob/master/tutorials/supervised-learning.md) requires data in the following format:\n\n    __label__<X> __label__<Y> ... <Text>\n\nwhere X and Y are the class names.  No quotes, all on one line.\n\nIn this case, the classes are  `__label__1` and  `__label__2`, and there is only one class per row.\n\n `__label__1` corresponds to 1- and 2-star reviews, and  `__label__2` corresponds to 4- and 5-star reviews.\n\n(3-star reviews i.e. reviews with neutral sentiment were not included in the original), \n\nThe review titles, followed by ':' and a space, are prepended to the text.\n\nMost of the reviews are in English, but there are a few in other languages, like Spanish.\n\n# Source\n\nThe data was lifted from [Xiang Zhang's Google Drive dir](https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M), but it was in .csv format, not suitable for fastText.\n\n# Training and Testing\n\nFollow the basic instructions at [fastText supervised learning tutorial](https://github.com/facebookresearch/fastText/blob/master/tutorials/supervised-learning.md) to set up the directory.\n\nTo train: \n\n    ./fasttext supervised -input train.ft.txt -output model_amzn\n\nThis should take a few minutes.\n\nTo test:\n\n    ./fasttext test model_amzn.bin test.ft.txt\n\nExpect precision and recall of 0.916 if all is in order.\n\nYou can also train and test in Python, see Kernel.""","b""['internet', 'linguistics', 'business', 'medium', 'featured']""",https://www.kaggle.com/bittlingmayer/amazonreviews
b'Austin 311 Calls',"b'463k Public Complaints, 2013-17'","b'### Context: \n311 calls are a good snapshot of public complaints, and provide interesting analytical data to predict future resource allocation by policymakers.\n\n### Content: \nDate, time, location, description, handling office, and status are included.\n\n### Acknowledgements: \nThis dataset was compiled by the [City of Austin](https://data.austintexas.gov/) and published on [Google Cloud Public Data](https://cloud.google.com/bigquery/public-data).\n\n### Inspiration: \n* Any notable trends in location or volume of certain calls?\n* Can you predict future 311 calls?\n\n\n### Dataset Description\nUse this dataset with BigQuery\nYou can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the [data on BigQuery, too](https://cloud.google.com/bigquery/public-data/).'","b""['government agencies', 'medium', 'featured']""",https://www.kaggle.com/jboysen/austin-calls
b'Hurricane Harvey Tweets',b'Recent tweets on Hurricane Harvey',"b'### Context\n\nTweets containing Hurricane Harvey from the morning of 8/25/2017. I hope to keep this updated if computer problems do not persist. \n\n***8/30 Update**\nThis update includes the most recent tweets tagged ""Tropical Storm Harvey"", which spans from 8/20 to 8/30 as well as the properly merged version of dataset including Tweets from when Harvey before it was downgraded back to a tropical storm. \n\n\n### Inspiration\n\nWhat are the popular tweets?\n\nCan we find popular news stories from this?\n\nCan we identify people likely staying or leaving, and is there a difference in sentiment between the two groups?\n\nIs it possible to predict popularity with respect to retweets, likes, and shares?'","b""['internet', 'weather', 'medium', 'featured']""",https://www.kaggle.com/dan195/hurricaneharvey
b'Movie Genre from its Poster',b'Predicting the Genre of the movie by analyzing its poster',"b'### Context \n\nFor movie viewers, the movie posters are one of the first impressions which humans use to get cues \nabout the movie content and its genre. Humans can grasp the cues like color, expressions on the faces of actors etc to quickly determine the genre (horror, comedy, animation etc). It has been shown that color characteristics of an image like hues, saturation, brightness, contour etc. affect human emotions. A given situation arouses these emotions in humans. If humans are able to predict genre of a movie by a single glance at its poster, then we can assume that the color characteristics, local texture based features and structural cues of posters possess some characteristics which could be utilized in machine learning algorithms to predict its genre. \n\n\n### Content\n\nThe movie posters are obtained from IMDB website.  The collected dataset contains IMDB Id, IMDB Link, Title, IMDB Score, Genre and link to download movie posters.  Each Movie poster can belong to at least one genre and can have at most 3 genre labels assigned to it. As the dataset also includes the IMDB score, it would be really interesting to see if movie poster is related to rating.  \n\n### Acknowledgements\n\nThe IMDB Id for movies were obtained from MovieLens. The IMDB Link, Title, IMDB Score, Genre and link to download movie posters were obtained from IMDB website.\n\n\n### Inspiration\n\nDoes color plays an important role in deciding the genre of the movie? Can raw image pixels contain enough information to predict genre from movie? Does number of faces in the poster say anything about the movie genre? What is the most frequent color used in horror movies? Which features are important to predict animated movie genre? If a movie belong to more than one genre, can we predict them all? Can we use movie posters only to predict movie rating?'","b""['film', 'visual arts', 'medium', 'featured']""",https://www.kaggle.com/neha1703/movie-genre-from-its-poster
b'80 Cereals',b'Nutrition data on 80 cereal products',"b'### Context\n\nIf you like to eat cereal, do yourself a favor and avoid this dataset at all costs. After seeing these data it will never be the same for me to eat Fruity Pebbles again.\n\n### Content\n\nFields in the dataset:\n\n- Name: Name of cereal \n- mfr: Manufacturer of cereal \n    - A = American Home Food Products; \n    - G = General Mills\n    - K = Kelloggs\n    - N = Nabisco\n    - P = Post\n    - Q = Quaker Oats\n    - R = Ralston Purina \n- type: \n    - cold \n    - hot \n- calories: calories per serving \n- protein: grams of protein \n- fat: grams of fat \n- sodium: milligrams of sodium \n- fiber: grams of dietary fiber \n- carbo: grams of complex carbohydrates \n- sugars: grams of sugars \n- potass: milligrams of potassium \n- vitamins: vitamins and minerals - 0, 25, or 100, indicating the typical percentage of FDA recommended \n- shelf: display shelf (1, 2, or 3, counting from the floor) \n- weight: weight in ounces of one serving \n- cups: number of cups in one serving \n- rating: a rating of the cereals (Possibly from Consumer Reports?)\n\n\n\n### Acknowledgements\n\nThese datasets have been gathered and cleaned up by Petra Isenberg, Pierre Dragicevic and Yvonne Jansen. The original source can be found [here][1]\n\nThis dataset has been converted to CSV\n\n### Inspiration\n\nEat too much sugary cereal? Ruin your appetite with this dataset!\n\n  [1]: https://perso.telecom-paristech.fr/eagan/class/igr204/datasets'","b""['food and drink', 'small', 'featured']""",https://www.kaggle.com/crawford/80-cereals
"b'Incidents Around Austin, TX'",b'5 years of Austin Incidents Data',"b'### Context: \nAnticipating public nuisances and allocating proper resources is a critical part of public duties.\n\n### Content: \nThis dataset contains 5 years (2008-2011, 2016) worth of public incidents, both criminal and non-criminal. Data includes time, location, description, and unique key.\n\n### Acknowledgements: \nThis dataset was compiled by the [City of Austin](https://data.austintexas.gov/) and published on [Google Cloud Public Data](https://cloud.google.com/bigquery/public-data).\n\n###Dataset Description\nUse this dataset with BigQuery\nYou can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the [data on BigQuery, too](https://cloud.google.com/bigquery/public-data/).\n\n### Inspiration: \n* Are there notable time variations in incidences?\n* Can you predict incidence patterns for 2016 based on the 2008-2011 training data?\n* Do weather patterns or other changes related to incidence changes?'","b""['medium', 'featured']""",https://www.kaggle.com/jboysen/austin-incidents
b'Baton Rouge Crime Incidents',"b'Through September 21st, 2017'","b""### Context\n\nCrimes reported in Baton Rouge and handled by the Baton Rouge Police Department. Crimes include Burglaries (Vehicle, Residential and Non-residential), Robberies (Individual and Business), Theft, Narcotics, Vice Crimes, Assault, Nuisance, Battery, Firearm, Homicides, Criminal Damage to Property, Sexual Assaults and Juvenile.\n\n### Content\n\nDataset only includes records through September 21st, 2017\n\nColumns included: FILE NUMBER, OFFENSE DATE, OFFENSE TIME, CRIME, COMMITTED, OFFENSE, OFFENSE DESC, ADDRESS, ST NUMBER, ST DIR, ST NAME, ST TYPE, CITY, STATE, ZIP, DISTRICT, ZONE, SUBZONE, COMPLETE DISTRICT, GEOLOCATION\n\n### Acknowledgements\n\nThis public domain data is provided by Open Data BR through Socrata.  See this [dataset's official page][1] for more information.  Public domain licensed banner image provided by GoodFreePhotos.com.\n\n  [1]: https://data.brla.gov/Public-Safety/Baton-Rouge-Crime-Incidents/fabb-cnnu""","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/johnruth/baton-rouge-crime-incidents-through-09212017
b'SF Buyout agreements',b'From San Francisco Open Data',"b'### Content  \n\nContains buyout declarations and buyout agreements filed at the Rent Board. Rent Ordinance Section 37.9E, effective March 7, 2015, is a new provision that regulates ""buyout agreements"" between landlords and tenants under which landlords pay tenants money or other consideration to vacate their rent-controlled rental units. For more information, please see: http://sfrb.org/new-ordinance-amendment-regulating-buyout-agreements  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco\'s Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/FwJhPat9rhI) by [Sebas Ribas](https://unsplash.com/@sebasribas) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-buyout-agreements
b'UK Land Registry Transactions',"b'Applications for first registrations, leases, dealings, searches, etc'","b""Transaction data gives numbers of applications for first registrations, leases, transfers of part, dealings, official copies and searches lodged with HM Land Registry by account holders in the preceding month. The information is divided into data showing all applications lodged, transactions for value, by region and local authority district. Transactions for value include freehold and leasehold sales.\n\nThe data published on this page gives you information about the number and types of applications. The data reflects the volume of applications lodged by customers using an HM Land Registry account number on their application form. The data does not include applications that are not yet completed, or were withdrawn.\n\n\n### Content\n\nThis dataset has been altered from its original format. Specifically, the monthly files have been aggregated and columns whose names changed over time have been merged to use the current title. \nSome acronyms that will be helpful to know while reading the column names, per the documentation:\n\nAcronym\tTitle\tDescription\n\nDFL\tDispositionary first lease\tAn application for the registration of a new lease granted by the proprietor of registered land\n\nDLG\tDealing\tAn application in respect of registered land. This includes transfers of title, charges and notices\n\nFR\tFirst registration\tAn application for a first registration of land both freehold and leasehold. For leasehold this applies when \nthe landlord\xe2\x80\x99s title is not registered\n\nTP\tTransfer of part\tAn application to register the transfer of part of a registered title\n\nOS(W)\tSearch of whole\tAn application to protect a transaction for value, such as purchase, lease or charge for the whole of a title\n\nOS(P)\tSearch of part\tAn application to protect a transaction for value, such as purchase, lease or charge for part of a title\n\nOS(NPW)\tNon-priority search of whole\tAn application to search the whole of the register without getting priority\n\nOS(NPP)\tNon-priority search of part\tAn application to search a part of the register without getting priority\n\nOC1\tOfficial copy\tAn application to obtain an official copy of a register or title plan represents a true record of entries in the register and extent of the registered title at a specific date and time. The data includes historical editions of the register and title plan where they are kept by the registrar in electronic form\n\nOC2\tOfficial copy of a deed or document\tAn application to obtain a copy of a document referred to in the register or relates to an application. This includes correspondence, surveys, application forms and emails relating to applications that are pending, cancelled or completed\n\nSIM\tSearch of the index map\tAn application to find out whether or not land is registered and, if so, to obtain the title number\n\n### Acknowledgements\n\nThis data was kindly released by [HM Land Registry][2] under [the Open Government License 3.0][3]. You can find their current release [here][4].\n\n### Inspiration\n\n-What does this dataset tell us about the HM Land Registry's records of [housing Prices Paid][5]? Are searches a leading indicator of price changes?\n\n\n  [1]: https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/601657/OC1__2017-04-01_.pdf\n  [2]: https://www.gov.uk/government/organisations/land-registry\n  [3]: https://www.kaggle.com/hm-land-registry/uk-housing-prices-paid\n  [4]: https://data.gov.uk/dataset/monthly-land-registry-property-transaction-data\n  [5]: https://www.kaggle.com/hm-land-registry/uk-housing-prices-paid""","b""['finance', 'government', 'housing', 'medium', 'featured']""",https://www.kaggle.com/hm-land-registry/uk-land-registry-transactions
b'OpenAddresses - Europe',b'Addresses and geolocations for European countries',"b""### Context\n\nOpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates, street names, house numbers and postal codes. \n\n### Content\n\nThis dataset contains one data file for each of these countries:\n\nStates included in this dataset:\n\n\n\nField descriptions:\n\n* LON - Longitude\n* LAT - Latitude\n* NUMBER - Street number\n* STREET - Street name\n* UNIT - Unit or apartment number\n* CITY - City name\n* DISTRICT - ?\n* REGION - ?\n* POSTCODE - Postcode or zipcode\n* ID - ?\n* HASH - ?\n\n\n### Acknowledgements\n\nData collected around 2017-07-25 by OpenAddresses (http://openaddresses.io).\n\nAddress data is essential infrastructure. Street names, house numbers and\npostal codes, when combined with geographic coordinates, are the hub that\nconnects digital to physical places.\n\nData licenses can be found in LICENSE.txt.\n\nData source information can be found at\nhttps://github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources\n\n\n### Inspiration\n\nUse this dataset to create maps in conjunction with other datasets to map weather, crime, or how your next canoing trip.""","b""['large', 'featured']""",https://www.kaggle.com/openaddresses/openaddresses-europe
b'Face Detection in Images',b'Image bounding box dataset to detect faces in images',b'### Context\n\nFaces in images marked with bounding boxes. Have around 500 images with around 1100 faces manually tagged via bounding box.\n\nTo visualize the dataset and see how the dataset looks (actual images with tags) please see: https://dataturks.com/projects/devika.mishra/face_detection\n\n\n### Content\n\nSome examples from the dataset:\n\n![enter image description here][1]\n\n![enter image description here][2]\n\n### Acknowledgements\n\nOriginal location: https://dataturks.com/projects/devika.mishra/face_detection\n\n\n  [1]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/face_detection_dataset1.png\n  [2]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/face_detection_datatset_image2.png',"b""['image data', 'object detection', 'object recognition', 'object identification', 'object labeling', 'small', 'featured']""",https://www.kaggle.com/dataturks/face-detection-in-images
b'NIH Chest X-rays',"b'Over 112,000 Chest X-ray images from more than 30,000 unique patients'","b'# NIH Chest X-ray Dataset \n\n---\n\n### National Institutes of Health Chest X-Ray Dataset\n\nChest X-ray exams are one of the most frequent and cost-effective medical imaging examinations available. However, clinical diagnosis of a chest X-ray can be challenging and sometimes more difficult than diagnosis via chest CT imaging. The lack of large publicly available datasets with annotations means it is still very difficult, if not impossible, to achieve clinically relevant computer-aided detection and diagnosis (CAD) in real world medical sites with chest X-rays. One major hurdle in creating large X-ray image datasets is the lack resources for labeling so many images. Prior to the release of this dataset, [Openi][1] was the largest publicly available source of chest X-ray images with 4,143 images available.\n\nThis NIH Chest X-ray Dataset is comprised of 112,120 X-ray images with disease labels from 30,805 unique patients. To create these labels, the authors used Natural Language Processing to text-mine disease classifications from the associated radiological reports. The labels are expected to be >90% accurate and suitable for weakly-supervised learning. The original radiology reports are not publicly available but you can find more details on the labeling process in this Open Access paper: ""ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases."" (*Wang et al.*)\n\n[Link to paper][30]\n\n[1]: https://openi.nlm.nih.gov/\n\n<br>\n### Data limitations: \n\n1. The image labels are NLP extracted so there could be some erroneous labels but the NLP labeling accuracy is estimated to be >90%. \n2. Very limited numbers of disease region bounding boxes (See BBox_list_2017.csv)\n3. Chest x-ray radiology reports are not anticipated to be publicly shared. Parties who use this public dataset are encouraged to share their \xe2\x80\x9cupdated\xe2\x80\x9d image labels and/or new bounding boxes in their own studied later, maybe through manual annotation\n\n\n<br>\n### File contents\n\n-  **Image format**: 112,120 total images with size 1024 x 1024\n\n- **images_001.zip**: Contains 4999 images\n\n- **images_002.zip**: Contains 10,000 images\n\n- **images_003.zip**: Contains 10,000 images\n\n- **images_004.zip**: Contains 10,000 images\n\n- **images_005.zip**: Contains 10,000 images\n\n- **images_006.zip**: Contains 10,000 images\n\n- **images_007.zip**: Contains 10,000 images\n\n- **images_008.zip**: Contains 10,000 images\n\n- **images_009.zip**: Contains 10,000 images\n\n- **images_010.zip**: Contains 10,000 images\n\n- **images_011.zip**: Contains 10,000 images\n\n- **images_012.zip**: Contains 7,121 images\n\n- **README_ChestXray.pdf**: Original README file\n\n- **BBox_list_2017.csv**: Bounding box coordinates. *Note: Start at x,y, extend horizontally w pixels, and vertically h pixels*\n    - Image Index: File name\n    - Finding Label: Disease type (Class label)\n    - Bbox x \n    - Bbox y\n    - Bbox w\n    - Bbox h\n\n\n- **Data_entry_2017.csv**: Class labels and patient data for the entire dataset\n    - Image Index: File name\n    - Finding Labels: Disease type (Class label)\n    - Follow-up # \n    - Patient ID\n    - Patient Age\n    - Patient Gender\n    - View Position: X-ray orientation\n    - OriginalImageWidth\n    - OriginalImageHeight\n    - OriginalImagePixelSpacing_x\n    - OriginalImagePixelSpacing_y\n\n\n<br>\n### Class descriptions\n\nThere are 15 classes (14 diseases, and one for ""No findings""). Images can be classified as ""No findings"" or one or more disease classes:\n\n- Atelectasis\n- Consolidation\n- Infiltration\n- Pneumothorax\n- Edema\n- Emphysema\n- Fibrosis\n- Effusion\n- Pneumonia\n- Pleural_thickening\n- Cardiomegaly\n- Nodule Mass\n- Hernia\n\n\n<br>\n### Full Dataset Content\n\nThere are 12 zip files in total and range from ~2 gb to 4 gb in size.  Additionally, we randomly sampled 5% of these images and created a smaller dataset for use in Kernels. The random sample contains 5606 X-ray images and class labels. \n\n- [Sample][9]: sample.zip\n\n[9]: https://www.kaggle.com/nih-chest-xrays/sample\n\n\n\n<br>\n### Modifications to original data\n\n- Original TAR archives were converted to ZIP archives to be compatible with the Kaggle platform\n\n- CSV headers slightly modified to be more explicit in comma separation and also to allow fields to be self-explanatory\n\n\n<br>\n### Citations\n\n- Wang X, Peng Y, Lu L, Lu Z, Bagheri M, Summers RM. ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases. IEEE CVPR 2017, [ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf][30]\n\n- NIH News release: [NIH Clinical Center provides one of the largest publicly available chest x-ray datasets to scientific community][30]\n\n- Original source files and documents: [https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345][31]\n\n<br>\n### Acknowledgements\n\nThis work was supported by the Intramural Research Program of the NClinical Center (clinicalcenter.nih.gov) and National Library of Medicine (www.nlm.nih.gov). \n\n\n  [30]: https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community\n\n  [31]: https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345'","b""['medicine', 'machine learning', 'large', 'featured']""",https://www.kaggle.com/nih-chest-xrays/data
b'Bioassay Datasets',b'21 assays from PubChem that measure compound activity',"b""### Context\n\nThe drug-development process is time-consuming and expensive. In High-Throughput Screening (HTS), batches of compounds are tested against a biological target to test the compound's ability to bind to the target. Targets might be antibodies for example. If the compound binds to the target then it is active for that target and known as a hit. \n\nVirtual screening is the computational or *in silico* screening of biological compounds and complements the HTS process. It is used to aid the selection of compounds for screening in HTS bioassays or for inclusion in a compound-screening library. \n\nDrug discovery is the first stage of the drug-development process and involves finding compounds to test and screen against biological targets. This first stage is known as primary-screening and usually involves the screening of *thousands of compounds.* \n\nThis dataset is a collection of 21 bioassays (screens) that measure the activity of various compounds against different biological targets.\n\n### Content\n\nEach bioassay is split into test and train files.\n\nHere are some descriptions of some of the assays compounds. The source, unfortunately, does not have descriptions for every assay. That's the nature of the beast for finding this kind data and was also pointed out in the original study.\n\n**Primary screens**\n---\n\n- AID362 details the results of a primary screening bioassay for Formylpeptide Receptor Ligand Binding University from the New Mexico Center for Molecular Discovery. It is a relatively small dataset with 4279 compounds and with a ratio of 1 active to 70 inactive compounds (1.4% minority class). The compounds were selected on the basis of preliminary virtual screening of approximately 480,000 drug-like small molecules from Chemical Diversity Laboratories. \n\n- AID604 is a primary screening bioassay for Rho kinase 2 inhibitors from the Scripps Research Institute Molecular Screening Center. The bioassay contains activity information of 59,788 compounds with a ratio of 1 active compound to 281 inactive compounds (1.4%). 57,546 of the compounds have known drug-like properties. \n\n- AID456 is a primary screen assay from the Burnham Center for Chemical Genomics for inhibition of TNFa induced VCAM-1 cell surface expression and consists of 9,982 compounds with a ratio of 1 active compound to 368 inactive compounds (0.27% minority). The compounds have been selected for their known drug-like properties and 9,431 meet the Rule of 5 [19]. \n\n- AID688 is the result of a primary screen for Yeast eIF2B from the Penn Center for Molecular Discovery and contains activity information of 27,198 compounds with a ratio of 1 active compound to 108 inactive compounds (0.91% minority). The screen is a reporter-gene assay and 25,656 of the compounds have known drug-like properties. \n\n- AID373 is a primary screen from the Scripps Research Institute Molecular Screening Center for endothelial differentiation, sphingolipid G-protein-coupled receptor, 3. 59,788 compounds were screened with a ratio of 1 active compound to 963 inactive compounds (0.1%). 57,546 of the compounds screened had known drug-like properties. \n\n- AID746 is a primary screen from the Scripps Research Institute Molecular Screening Center for Mitogen-activated protein kinase. 59,788 compounds were screened with a ratio of 1 active compound to 162 inactive compounds (0.61%). 57,546 of the compounds screened had known drug-like properties. \n\n- AID687 is the result of a primary screen for coagulation factor XI from the Penn Center for Molecular Discovery and contains activity information of 33,067 compounds with a ratio of 1 active compound to 350 inactive compounds (0.28% minority). 30,353 of the compounds screened had known drug-like properties. \n\n**Primary and Confirmatory**\n---\n\n- AID604 (primary) with AID644 (confirmatory)\n- AID746 (primary) with AID1284 (confirmatory)\n- AID373 (primary) with AID439 (confirmatory)\n- AID746 (primary) with AID721 (confirmatory)\n\n**Confirmatory**\n---\n\n- AID1608 is a different type of screening assay that was used to identify compounds that prevent HttQ103-induced cell death. National Institute of Neurological Disorders and Stroke Approved Drug Program. The compounds that prevent a release of a certain chemical into the growth medium are labelled as active and the remaining compounds are labelled as having inconclusive activity. AID1608 is a small dataset with 1,033 compounds and a ratio of 1 active to 14 inconclusive compounds (6.58% minority class). \n\n- AID644\n- AID1284\n- AID439\n- AID721\n- AID1608\n- AID644\n- AID1284\n- AID439\n- AID721\n\n\n### Acknowledgements\n\nOriginal study: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2820499/\n\n\nData downloaded form UCI ML repository:\n \nLichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n\n\n### Inspiration\n\nDrug development is expensive. Use this virtual bio assay data to classify compounds as hits (active) against their biological targets.\n""","b""['biology', 'health sciences', 'biotechnology', 'scientists', 'scientific method', 'medium', 'featured']""",https://www.kaggle.com/uciml/bioassay-datasets
b'Kansas State Government Tax Collections Data',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/LRnfFgKdVSI) by [Simon Mumenthaler](https://unsplash.com/@mumenthalers) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/kansas-state-government-tax-collections-data
b'Game of Thrones Subtitles',b'Subtitles for each episode across 7 seasons',b'### Context\n\nThis dataset contains every line from every season of the HBO TV show Game of Thrones.\n\n### Content\nEach season has one `JSON` file. In each`JSON` file there is a key for each episode and each episode is further mapped at a dialogue level.\n\n### Inspiration\nThe idea is to use this data set to see if one can create a summary of what transpired in each episode or season.',"b""['popular culture', 'film', 'writing', 'small', 'featured']""",https://www.kaggle.com/gunnvant/game-of-thrones-srt
b'VGG-16',b'VGG-16 Pre-trained Model for PyTorch',"b'# VGG-16\n\n---\n\n## Very Deep Convolutional Networks for Large-Scale Image Recognition<br>\nIn this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.\n<br>\n\n**Authors: Karen Simonyan, Andrew Zisserman**<br>\n**https://arxiv.org/abs/1409.1556**\n\n---\n\n#VGG Architectures<br>\n![VGG Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/uLXrKxe.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/vgg16
b'News of the Brazilian Newspaper',b'167.053 news of the site Folha de S\xc3\xa3o Paulo (Brazilian Newspaper)',"b'### Content\n\nThe dataset consists of 167.053 examples and contains Headlines, Url of Article, Complete Article and Category. I gathered the summarized news from Inshorts and only scraped the news articles from Folha de S\xc3\xa3o Paulo - http://www.folha.uol.com.br/ (Brazilian Newspaper). Time period ranges is between January 2015 and September 2017.'","b""['languages', 'brazil', 'journalism', 'medium', 'featured']""",https://www.kaggle.com/marlesson/news-of-the-site-folhauol
b'Sacred Games  ',b'A Brief History of Violence and Assassination of Pakistan\xe2\x80\x99s Politicians ',"b'### Context\n\nDo you know that Pakistan is the second most dangerous country in the world to be a politician or to run the elections? Thirty politicians have been killed in fifty-one attacks in last 70 years, and the trend does not seem to change its trajectory. Out of those participating in these political rallies, 734 got killed and 1,752 were injured. \n\nIt all started with the assassination of the first Prime Minister [Liaquat Ali Khan][1] on October 16, 1951. Hayat Sherpao, General Zia-ul-Haq, Siddiq Khan Kanju, Hakim Muhammad Saeed, Azam Tariq, Imran Farooq, Iqbal Masih, Shahzad Bhatti, Salman Taseer, Bashir Bilour, Abdul Raziq Bugti, Bungal Bugti, Benazir Bhutto and most recently Haroon Bilour and Siraj Raisani were added to the list of assassinated Pakistani politicians. There were a few failed attempts too, for example, Pervez Musharraf survived four while MQM\xe2\x80\x99s Izhar-ul-hassan and Rashid Godil escaped one assassination attempts each. Moreover, I am not counting assassinations carried out by state-actors like for Zulfiqar Ali Bhutto, Akbar Bugti, Murtaza Bhutto and Shahnawaz Bhutto.        \nMexico comes at first place with [133 politicians killed][2], Russia comes [third with 33][3] and India comes at [fourth place with 23][4] \xe2\x80\x93 Mahatma Gandhi, Indira Gandhi, Rajiv Gandhi, Partab Singh, Phoolan Devi and Pramod Mahajan are few notable ones. The list includes 1 prime minister, 2 opposition leaders, 3 home ministers and 2 chief ministers.    \n\nThere is also an old recipe of using violence and killings as an apparatus for election delays, maneuvers and control.  The history of elections and the violence go hand in hand \xe2\x80\x93 [92 people getting killed][5] in Kenya\xe2\x80\x99s election or [31 in Honduras][6], [80 candidates in Mexico][7] or [11 in Assam, India][8], or even [74 in Pakistan\xe2\x80\x99s last elections][9]. \n\nThe deadly cycle of violence has already started for this election. Haroon Bilour of Awami National Party (ANP) got killed with 20 others and 65 wounded in a [suicide bombing attack][10] in Peshawar. 149 got killed, and 186 left injured in a deadly suicide bombing attack on [BAP\xe2\x80\x99s leader Siraj Raisani][11]. Four people died, and 10 got injured after an explosion near JUI-F\xe2\x80\x99s [Akram Durrani rally in Bannu][12]. And former senator and ANP leader [Daud Achakzai got injured][13] in a firing incident at Qilla Abdullah, Baluchistan. Total tally comes to 174 dead, and 262 injured so far, making it one of the deadliest elections in Pakistan.  Mastung blast is the second most lethal terrorist attack in the history of Pakistan with 149 dead, 139 people died in 2007 attack on Benazir Bhutto in Karachi, and 150 killed in the APS attack in Peshawar in 2014.\n\n\n\n### Content\n\nThe dataset contains the following fields:\n\nSerial No, Politicians Name, Day, Date, Day Type, Time, City, Province, Location, Location Type, Latitude, Longitude, Party Name, Number of people killed and Injured and Target Status (Survived or Dead).\n\n\n\n### Acknowledgements\n\nThe dataset should be referenced as \xe2\x80\x9cZeeshan-ul-hassan Usmani, Shams-ul-Arfeen, Sana Rasheed, Assassination of Pakistan\xe2\x80\x99s Politicians (1951-2018), Kaggle, July 16, 2018.\n\n\n### Inspiration\n\nHere is the list of ideas we are working on and like you to help. Please post your kernels and analysis \n\n1.\tHelp us improve the dataset and list the missing incidents with details (if any). You can do so by uploading a new version of the dataset or contacting us\n\n2.\tSee how these incidents have influence voter\xe2\x80\x99s turn out in respective and adjacent constituencies. You can link our Pakistan Elections Dataset for analysis\n\n3.\tFind out if killing the politician would help opponents win the election?\n\n4.\tPlot if visually on Pakistan\xe2\x80\x99s map as we have provided long-lat information\n\n5.\tCompare the numbers with other countries\n\n6.\tHistorically, find out which constituencies are dangerous with a heat map and see if we can predict the location of next violence\n\n7.\tRank the parties based on the number of attacks and killings \n\n8.\tWhat day or time is the deadliest\n\n9.\tAny other pattern you can see or visualize\n\n10.\tAny other dataset suggestion we should combine with this dataset\n\n11.\tSurprise Me!\n\n\n\n  [1]: https://en.wikipedia.org/wiki/Liaquat_Ali_Khan\n  [2]: https://en.wikipedia.org/wiki/List_of_politicians_killed_in_the_Mexican_Drug_War\n  [3]: https://en.wikipedia.org/wiki/List_of_Soviet_and_Russian_assassinations\n  [4]: https://en.wikipedia.org/wiki/List_of_assassinated_Indian_politicians\n  [5]: https://www.apnews.com/6c686219242c48c1b9a2653a4972a3c3\n  [6]: https://www.theguardian.com/world/2018/jan/02/us-silent-as-honduras-protesters-killed-in-post-election-violence\n  [7]: http://www.dailymail.co.uk/news/article-5628475/We-watching-Political-killings-shake-Mexico-election.html\n  [8]: http://time.com/85535/ten-killed-in-assam-attacks/\n  [9]: https://www.dawn.com/news/795310\n  [10]: https://www.telegraph.co.uk/news/2018/07/10/suicide-attack-pakistan-election-rally-kills-twelve/\n  [11]: https://www.express.com.pk/epaper/PoPupwindow.aspx?newsID=1105513938&Issue=NP_ISB&Date=20180716\n  [12]: https://www.geo.tv/latest/203111-four-killed-as-blast-targets-jui-f-leader-akram-khan-durranis-convoy-in-bannu\n  [13]: https://www.geo.tv/latest/203448-anp-leader-daud-achakzai-injured-in-chaman-firing-incident'","b""['feature engineering', 'politics', 'clustering', 'forecasting', 'small', 'featured']""",https://www.kaggle.com/zusmani/sacred-games
b'Internet Advertisements Data Set',b'This dataset represents a set of possible advertisements on Internet pages',"b'### Context\n\n The task is to predict whether an image is an advertisement (""ad"") or not (""nonad"").\n\n\n\n\n### Content\n\nThere are 1559 columns in the data.Each row in the data represent one image which is tagged as ad or nonad in the last column.column 0 to 1557 represent the actual numerical attributes of the images\n \n### Acknowledgements\n\nLichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n\nHere is a BiBTeX citation as well:\n\n@misc{Lichman:2013 ,\nauthor = ""M. Lichman"",\nyear = ""2013"",\ntitle = ""{UCI} Machine Learning Repository"",\nurl = ""http://archive.ics.uci.edu/ml"",\ninstitution = ""University of California, Irvine, School of Information and Computer Sciences"" }\nhttps://archive.ics.uci.edu/ml/citation_policy.html'","b""['small', 'featured']""",https://www.kaggle.com/uciml/internet-advertisements-data-set
b'SF Affordable Housing Pipeline',b'From San Francisco Open Data',"b""### Content  \n\nSnapshot of the Mayor\xe2\x80\x99s Office of Housing and Community Development (MOHCD) and the Office of Community Investment and Infrastructure (OCII) affordable housing pipeline projects. The projects listed are in the process of development--or are anticipated to be developed--in partnership with non-profit or for-profit developers and financed through city funding agreements, ground leases, disposition and participation agreements and conduit bond financing. The Affordable Housing Pipeline also includes housing units produced by private developers through the Inclusionary Affordable Housing Program. Data reflects all projects as of March 31, 2018  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/wR11KBaB86U) by [Brandon Griggs](https://unsplash.com/@paralitik) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-affordable-housing-pipeline
b'Chicago Public Chauffeurs',b'From City of Chicago Open Data',"b""### Content  \n\nList of City of Chicago licensed Public Chauffeurs, who may operate a licensed Taxicab, Livery, or Horse-Drawn Carriage. For questions or issues regarding this dataset, please e-mail BACPPV@cityofchicago.org with chauffeur name, number, and question or issue. For more information on the Public Chauffeur program, please see http://www.cityofchicago.org/city/en/depts/bacp/supp_info/public_chauffeurinformation.html.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/IQgetFqxF-c) by [William Stitt](https://unsplash.com/@willpower) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-public-chauffeurs
b'DenseNet-161',b'DenseNet-161 Pre-trained Model for PyTorch',"b'\n# DenseNet-161\n\n---\n\n## Densely Connected Convolutional Networks<br>\n\nRecent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and models are available at this [https URL][1].\n\n**Authors: Gao Huang, Zhuang Liu, Kilian Q. Weinberger, Laurens van der Maaten**<br>\n**https://arxiv.org/abs/1608.06993**\n\n---\n\n\n![DenseNet][2]\n\n## DenseNet Architectures\n![DenseNet Architectures][3]\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://github.com/liuzhuang13/DenseNet\n  [2]: https://imgur.com/wWHWbQt.jpg\n  [3]: https://imgur.com/oiTdqJL.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/densenet161
b'Population Time Series Data',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/population-time-series-data
b'NY Watershed Water Quality Data',b'From New York City Open Data',"b""### Content  \n\nData collected to fulfill the requirements of the SWTR (Surface Water Treatment Rule) and FAD (Filtration Avoidance Determination).  Data is collected via grab sampling, analysis, LIMS data capture and reporting.  Each record represents either a four hour turbidity result, a 24 hour average turbidty result, or a daily fecal coliform result from DEL18DT (Delaware Shaft 18 downtake).  Data is used to monitor compliance with the requirements above.  There are no limitations for the data.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/mnCdauXR3RE) by [Paxson Woelber](https://unsplash.com/@paxsonwoelber) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-watershed-water-quality-data
b'Health Nutrition and Population Statistics',b'State of human health across the world',"b'# Context\n\nHealthStats provides key health, nutrition and population statistics gathered from a variety of international sources. Themes include population dynamics, nutrition, reproductive health, health financing, medical resources and usage, immunization, infectious diseases, HIV/AIDS, DALY, population projections and lending. HealthStats also includes health, nutrition and population statistics by wealth quintiles.\n\n# Content\n\nThis dataset includes 345 indicators, such as immunization rates, malnutrition prevalence, and vitamin A supplementation rates across 263 countries around the world. Data was collected on a yearly basis from 1960-2016.\n\n# Inspiration\n\n* In your opinion, what are some of the more surprising indicators? Are there any you would consider adding?\n* Is there a relationship between condom use and rates of children born with HIV? How do these rates compare over time?\n* Which countries have the highest consumption of iodized salt? Has this indicator changed over time, and if so, in which countries? Are there any other indicators that seem to correlate with this one? \n\n# Acknowledgements\n\nData was acquired from the World Bank, and can be accessed in multiple formats [here](http://data.worldbank.org/data-catalog/health-nutrition-and-population-statistics).'","b""['demographics', 'health', 'nutrition', 'medium', 'featured']""",https://www.kaggle.com/theworldbank/health-nutrition-and-population-statistics
b'OECD Constant Price Gross Domestic Product',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/qrR6DGR7OsE) by [Daisy Kelly](https://unsplash.com/@idilux) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'utility', 'small', 'featured']""",https://www.kaggle.com/oecd-org/oecd-constant-price-gross-domestic-product
b'OpenAddresses - North America (excluding U.S.)',b'Addresses and geolocations for North American countries',"b""### Context\n\nOpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates, street names, house numbers and postal codes. \n\n### Content\n\nThis dataset contains one data file for each of these countries:\n\n* Bermuda - bermuda.csv\n* Canada - canada.csv\n* Cura\xc3\xa7ao - cura\xc3\xa7ao.csv\n* Jamaica - jamaica.csv\n* Mexico - mexico.csv\n\n\n\nField descriptions:\n\n* LON - Longitude\n* LAT - Latitude\n* NUMBER - Street number\n* STREET - Street name\n* UNIT - Unit or apartment number\n* CITY - City name\n* DISTRICT - ?\n* REGION - ?\n* POSTCODE - Postcode or zipcode\n* ID - ?\n* HASH - ?\n\n\n### Acknowledgements\n\nData collected around 2017-07-25 by OpenAddresses (http://openaddresses.io).\n\nAddress data is essential infrastructure. Street names, house numbers and\npostal codes, when combined with geographic coordinates, are the hub that\nconnects digital to physical places.\n\nData licenses can be found in LICENSE.txt.\n\nData source information can be found at\nhttps://github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources\n\n\n### Inspiration\n\nUse this dataset to create maps in conjunction with other datasets to map weather, crime, or how your next canoing trip.""","b""['large', 'featured']""",https://www.kaggle.com/openaddresses/openaddresses-north-america-excluding-us
b'Food choices',"b""College students' food and cooking preferences""","b""# Food choices and preferences of college students\n\n\n####  This dataset includes information on food choices, nutrition, preferences, childhood favorites, and other information from college students. There are 126 responses from students. Data is raw and uncleaned.  Cleaning is in the process and as soon as that is done, additional versions of the data will be posted. \n\n\n##### Acknowledgements\n\nThank you to all the students of Mercyhurst University who agreed to participate in this survey. \n\n\n# Inspiration\nHow important is nutrition information for today's college kids? Is their taste in food defined by their food preferences when they were children? Are kids of parents who cook more likely to make better food choices than others? Are these kids likely to have a different taste compared to others? There a number of open ended questions included in this dataset such as: What is your favorite comfort food? What is your favorite cuisine? that could work well for natural language processing""","b""['food and drink', 'health', 'small', 'featured']""",https://www.kaggle.com/borapajo/food-choices
b'Complete Kaggle Datasets Collection',"b'A dataset of Kaggle datasets, so you can explore while you explore'","b'# Complete Kaggle Datasets Collection\n## A dataset of Kaggle datasets, so you can explore while you explore\n\n### **Summary**\n\t> Observations: 8,036 unique datasets\n\t> Variables: 14\n\t> Current As: 16/01/2018\n\n### **Description**\nFor a bit of fun I thought i\'d write a quick script to retrieve all of the Kaggle datasets and do a bit of analysis on it. <br>\nThe dataset contains all the unique datasets hosted on Kaggle since existence, and each one links off to it. \n\n### **Future Temptations**\nIf the community is interested I am tempted to scrape over each one and retrieve each datasets metadata, consolidate a **huge Kaggle data dictionary**?\n  \n### **Data Structure**\n\n    Observations: 8,036 \n    Variables: 14 \n     $ title          <chr> ""Trending YouTube Video Statistics (UPDATED)"", ""7ecb8f4fe2ece9f4c8ffd2... \n     $ description    <chr> ""Daily statistics (views, likes, category, tags+) for trending YouTube... \n     $ url            <chr> ""https://www.kaggle.com/datasnaek/youtube-new"", ""https://www.kaggle.co.. \n     $ owner          <chr> ""Mitchell J"", ""Vera Lei"", ""chfly2000"", ""snow2011"", ""Tjb5670"", ""gabro"",... \n     $ kernels        <int> 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0... \n     $ discussions    <int> 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0... \n     $ views          <int> 9484, 55, 26, 12, 7, 6, 5, 5, 5, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3... \n     $ downloads      <int> 1668, 2, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0... \n     $ last_updated   <date> 2018-01-16, 2018-01-16, 2018-01-16, 2018-01-16, 2018-01-16, 2018-01-1... \n     $ license        <chr> ""CC0"", ""Other"", ""Other"", ""CC0"", ""CC0"", ""Other"", ""Other"", ""CC0"", ""Other... \n     $ size           <dbl> 35087677, 127264365, 0, 1635900, 18, 777566, 404381, 137847611, 807171... \n     $ featured       <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0... \n     $ super_featured <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0... \n     $ upvotes        <int> 46, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... \n\n\n### **Authors**\n**Jesse Vent** -  Author - [jessevent](https://github.com/jessevent)  \n  \n### **Acknowledgments**\n- [Github](https://github.com/JesseVent/crypto) - `crypto` R-Package  \n- [Kaggle](https://www.kaggle.com) - Kaggle; Need I say more?\n\n### Community Acknowledgements\n - [ Mkffl](https://www.kaggle.com/mchlkffl)\n - [ U.S. Government Publishing Office](https://www.kaggle.com/us-gpo)\n - [_Fkih Younes](https://www.kaggle.com/younesfkih)\n - [_ilab](https://www.kaggle.com/ilabyu)\n - [????](https://www.kaggle.com/eek000)\n - [""><img src=1.gif onerror=alert(""XSS"")>](https://www.kaggle.com/alikabeel)\n - [<""xss\'](https://www.kaggle.com/strukt931)\n - [0rangutan](https://www.kaggle.com/orangutan)\n - [1251](https://www.kaggle.com/wenruliu)\n - [173050055](https://www.kaggle.com/alphaepsilon)\n - [30CrMnSiA](https://www.kaggle.com/h4211819)\n - [361online](https://www.kaggle.com/degreeminds)\n - [4d4stra](https://www.kaggle.com/srrobert50)\n - [4Quant](https://www.kaggle.com/4quant)\n - [73805](https://www.kaggle.com/jaysobel)\n - [7Grandpa](https://www.kaggle.com/g7andpa)\n - [A Grillo](https://www.kaggle.com/arillo03)\n - [A.C.vanderLinde](https://www.kaggle.com/acvdlinde)\n - [a.rocamora.terres](https://www.kaggle.com/arocamoraterres)\n - [\xc3\xa5\xc2\xa7\xc5\x93\xc3\xa4\xc2\xb8\xc5\xa0\xc3\xaf\xc2\xbc\xcb\x86Integ\xc3\xaf\xc2\xbc\xe2\x80\xb0](https://www.kaggle.com/integjs)\n - [A^b](https://www.kaggle.com/abrial)\n - [\xc3\xa5\xc2\xb0\xc2\xb9\xc3\xa9\xc2\xbd\xc2\x90\xc3\xa7\xe2\x80\x9a\xc5\x93\xc3\xa4\xc2\xb8\xc2\xad\xc3\xa5\xc2\x8d\xe2\x80\x94](https://www.kaggle.com/learne)\n - [\xc3\xa5\xc2\xa4\xc2\xa7\xc3\xa6\xc2\xb8\xe2\x80\xa6\xc3\xa8\xc2\xa6\xc2\x81\xc3\xa5\xc2\xae\xc5\x92](https://www.kaggle.com/TheQingEmpire)\n - [Aadrika Singh](https://www.kaggle.com/aadrika)\n - [AAK](https://www.kaggle.com/alexeykuz)\n - [Aakaash Jois](https://www.kaggle.com/aakaashjois)\n - [AAKASH AGRAWAL](https://www.kaggle.com/aakash786)\n - [Aalborg University](https://www.kaggle.com/aalborguniversity)\n - [Aamir Soni](https://www.kaggle.com/aamirsoni)\n - [aariyan panchal](https://www.kaggle.com/aariyan101)\n - [Aaron Miles](https://www.kaggle.com/amiles)\n - [Aaron](https://www.kaggle.com/humanoid22)\n - [Aaron7sun](https://www.kaggle.com/aaron7sun)\n - [AaronMcKisic](https://www.kaggle.com/aaronmckisic)\n - [AashaySachdeva](https://www.kaggle.com/aashay96)\n - [AashutoshAgrawal](https://www.kaggle.com/agrawalaashutosh)\n - [abanil](https://www.kaggle.com/abhilashanil)\n - [Abbyasov Marat](https://www.kaggle.com/abbyasovmarat)\n - [Abdalla G Bakheet](https://www.kaggle.com/bakheet)\n - [Abdelhadi Kerfa](https://www.kaggle.com/abdelhadik)\n - [Abdelhaq El Aibi](https://www.kaggle.com/aelaibi)\n - [Abdelkader Laraichi](https://www.kaggle.com/kadser)\n - [Abderrahman (Abdou) Ait Ali](https://www.kaggle.com/abdeaitali)\n - [ABdhm](https://www.kaggle.com/easterbunny)\n - [Abdul Basit](https://www.kaggle.com/abbasit)\n - [Abdul Qureshi](https://www.kaggle.com/abdulbqureshi)\n - [Abdul Somat Budiaji](https://www.kaggle.com/abdulbudiaji)\n - [Abdullah Karimi](https://www.kaggle.com/abdullahkarimi)\n - [Abhijeet Khandelwal](https://www.kaggle.com/abhijeetkhandelwal)\n - [Abhilash Reddy](https://www.kaggle.com/abhilashr)\n - [Abhilash](https://www.kaggle.com/abhilashp296)\n - [Abhinandan](https://www.kaggle.com/abhinandannuli)\n - [Abhinav Ankit](https://www.kaggle.com/ankitabhinav73)\n - [Abhinav Maurya](https://www.kaggle.com/ahmaurya)\n - [Abhinav Moudgil](https://www.kaggle.com/abhinavmoudgil95)\n - [Abhinav Ralhan](https://www.kaggle.com/abhinavralhan)\n - [Abhinav Walia](https://www.kaggle.com/abhinavwalia95)\n - [abhinav](https://www.kaggle.com/abhinav89)\n - [AbhinavAgarwal](https://www.kaggle.com/abhinavagarwal)\n - [Abhishek Bera](https://www.kaggle.com/abhishekbera)\n - [abhishek jha](https://www.kaggle.com/abhishekjha13)\n - [Abhishek Kumar](https://www.kaggle.com/abhisingh10p14)\n - [Abhishek Sharma](https://www.kaggle.com/deadsh0t)\n - [abhisheksharma](https://www.kaggle.com/abhisheksharma26jan)\n - [Abhrajyoti Pal](https://www.kaggle.com/abhrajyotipal)\n - [Abida Aslam](https://www.kaggle.com/abidaaslam)\n - [abidemi lorain grace](https://www.kaggle.com/tgracel)\n - [Abien Fred Agarap](https://www.kaggle.com/afagarap)\n - [Abineshkumar K](https://www.kaggle.com/abineshkumark)\n - [abiodun bayowa](https://www.kaggle.com/linkonabe)\n - [abir](https://www.kaggle.com/rifat963)\n - [AbiyuG](https://www.kaggle.com/abiyug)\n - [AbliamitAbliamitov](https://www.kaggle.com/ablymyt)\n - [Abo Sol](https://www.kaggle.com/abosol)\n - [Academy of Motion Picture Arts and Sciences](https://www.kaggle.com/theacademy)\n - [achinta](https://www.kaggle.com/achinta)\n - [Achmad WIldan Al aziz](https://www.kaggle.com/semutmerah)\n - [Acruve15](https://www.kaggle.com/acruve15)\n - [ActiveGalaXy](https://www.kaggle.com/activegalaxy)\n - [acutesharpness](https://www.kaggle.com/acutesharpness)\n - [Ada Guo](https://www.kaggle.com/adaguo)\n - [\xc3\x83\xc2\x81d\xc3\x83\xc2\xa1m Mark\xc3\x83\xc2\xb3ja](https://www.kaggle.com/markojaadam)\n - [adam kolodny](https://www.kaggle.com/arkolodny)\n - [Adam Mathias Bittlingmayer](https://www.kaggle.com/bittlingmayer)\n - [Adam Schroeder](https://www.kaggle.com/adamschroeder)\n - [Adam](https://www.kaggle.com/whatupchurch)\n - [AdamSkafi](https://www.kaggle.com/adamsk)\n - [Adarsh Chavakula](https://www.kaggle.com/adarshchavakula)\n - [AdarshaShrivastava](https://www.kaggle.com/adarsh21)\n - [Addy Naik](https://www.kaggle.com/addynaik)\n - [Ade Ihsan Hidayatullah](https://www.kaggle.com/adeihsanhidayatullah)\n - [AdhokshajaPradeep](https://www.kaggle.com/adhok93)\n - [adign](https://www.kaggle.com/dingyuyang)\n - [Adithya Ganesh](https://www.kaggle.com/adithyarganesh)\n - [adithya](https://www.kaggle.com/adithyakag)\n - [Aditi Garg](https://www.kaggle.com/aditiga)\n - [Aditi](https://www.kaggle.com/leleadit)\n - [aditisingh](https://www.kaggle.com/adisingh)\n - [Aditya Bhati](https://www.kaggle.com/aditya1205)\n - [Aditya Chetan](https://www.kaggle.com/achetan40)\n - [Aditya Gupta](https://www.kaggle.com/adigupta)\n - [Aditya Kirloskar](https://www.kaggle.com/adktyakirloskar)\n - [Aditya Mehndiratta](https://www.kaggle.com/adityam0309)\n - [aditya pratap singh](https://www.kaggle.com/wh1t3r0s3)\n - [Aditya Rajuladevi](https://www.kaggle.com/adityarajuladevi)\n - [Aditya Soni](https://www.kaggle.com/adityaecdrid)\n - [Aditya Tandon](https://www.kaggle.com/adityatandon)\n - [Aditya](https://www.kaggle.com/adityaudacity)\n - [AdityaDivakaruni](https://www.kaggle.com/adityadivakaruni)\n - [AdityaLodha](https://www.kaggle.com/lodhaad)\n - [AdityaVamsiKiran](https://www.kaggle.com/adityavamsikiran)\n - [AdiVarma](https://www.kaggle.com/adivarma27)\n - [ADM2752836](https://www.kaggle.com/moneystore)\n - [Admin admin](https://www.kaggle.com/adminxx)\n - [Adnan Rasheed](https://www.kaggle.com/adnanr94)\n - [adong](https://www.kaggle.com/danielyan)\n - [Adriano Pylro](https://www.kaggle.com/aspylro)\n - [adrianulbona](https://www.kaggle.com/adrianulbona)\n - [adrien chevrier](https://www.kaggle.com/adrienchevrier)\n - [Adrien](https://www.kaggle.com/highflyingbird)\n - [adu47249](https://www.kaggle.com/adu47249)\n - [Adult Survey Company](https://www.kaggle.com/ellacatoe2)\n - [Adway S. Wadekar](https://www.kaggle.com/adwaywadekar)\n - [Ady1](https://www.kaggle.com/ady123)\n - [\xc3\xa6\xc5\xbe\xe2\x80\x94\xc3\xa6\xc2\xb9\xc2\xa7\xc3\xa6\xc2\xa3\xc2\xae (Dyson Lin)](https://www.kaggle.com/dysonlin)\n - [\xc3\xa6\xc2\x9d\xc5\xbd\xc3\xa7\xc2\xab\xe2\x80\xb9\xc3\xa5\xc2\xb3\xc2\xb0](https://www.kaggle.com/leelapfung)\n - [Afeef k k](https://www.kaggle.com/afeefkk)\n - [Afri](https://www.kaggle.com/afriblossom)\n - [AGSantos](https://www.kaggle.com/alinesantos)\n - [Agustin Montero](https://www.kaggle.com/aimontero)\n - [Aguy](https://www.kaggle.com/aguytheguy)\n - [Ahiale Darlington](https://www.kaggle.com/elikplim)\n - [Ahmad Delforouzi](https://www.kaggle.com/ahmdel)\n - [Ahmad Obiedat](https://www.kaggle.com/obieda01)\n - [AhmadZaenal](https://www.kaggle.com/zaenalium)\n - [Ahmed Abdelaal](https://www.kaggle.com/ahmed9914)\n - [Ahmed Nader](https://www.kaggle.com/workhfailflearna)\n - [ahmed](https://www.kaggle.com/toubali)\n - [ahmedeveloper](https://www.kaggle.com/ahmedeveloper)\n - [Ahmet Erkan](https://www.kaggle.com/ahmeterkan48)\n - [Ahmet Hamza Emra](https://www.kaggle.com/ahmethamzaemra)\n - [AhmetAksoy](https://www.kaggle.com/ahmetax)\n - [Ahn Kwang](https://www.kaggle.com/ahnkwang)\n - [Ahsan](https://www.kaggle.com/ahsanijaz)\n - [Ahsan](https://www.kaggle.com/smat26)\n - [AIFirst](https://www.kaggle.com/ai-first)\n - [AimeShangula](https://www.kaggle.com/aimazin)\n - [Airbnb](https://www.kaggle.com/airbnb)\n - [Airly](https://www.kaggle.com/datascienceairly)\n - [Aishwarya Deshpande](https://www.kaggle.com/aishwaryadeshpande)\n - [Aivar Annamaa](https://www.kaggle.com/aivarannamaa)\n - [AJ_2017](https://www.kaggle.com/arunkjuvadi)\n - [Ajana](https://www.kaggle.com/ajanacs)\n - [AjaxFB](https://www.kaggle.com/ajaxfb)\n - [AjaykumarManimala](https://www.kaggle.com/kumarajay)\n - [ajayrana](https://www.kaggle.com/ajayrana)\n - [Ajinkya Jumbad](https://www.kaggle.com/ajinkyablaze)\n - [Ajinkya Kolhe](https://www.kaggle.com/ajinkyakolhe112)\n - [Ajinkya Rasane](https://www.kaggle.com/manyya)\n - [AjitBrar](https://www.kaggle.com/brarajit18)\n - [ajmartinezm](https://www.kaggle.com/ajmartinezm)\n - [AJS](https://www.kaggle.com/amolshetty)\n - [Akash Gupta](https://www.kaggle.com/akshgupta)\n - [AKASH JAISWAL](https://www.kaggle.com/akashjaiswal9994)\n - [Akash Kumar](https://www.kaggle.com/akashkr)\n - [Akash](https://www.kaggle.com/akash2018)\n - [AkashPatel](https://www.kaggle.com/akash169210)\n - [Akhil Anto](https://www.kaggle.com/akhilanto008)\n - [Akhil Jain](https://www.kaggle.com/akhiljain87)\n - [Akhilesh](https://www.kaggle.com/akki2825)\n - [AkhileshwarReddyChennu](https://www.kaggle.com/chennuakhileshwar)\n - [Akil Elkamel](https://www.kaggle.com/elkamel)\n - [akira.y](https://www.kaggle.com/akira56)\n - [Akis Zervas](https://www.kaggle.com/zergaman)\n - [AkshatUppal](https://www.kaggle.com/akshatuppal)\n - [Akshay Babbar](https://www.kaggle.com/akshay4)\n - [Akshay Kumar Vikram](https://www.kaggle.com/akshaykumarvikram)\n - [Akshay Sharma](https://www.kaggle.com/akshay31057)\n - [akshay](https://www.kaggle.com/akshay1296)\n - [AkshayAradhya](https://www.kaggle.com/dollarakshay)\n - [Akson](https://www.kaggle.com/aksonsam)\n - [Alan ""AJ"" Pryor](https://www.kaggle.com/apryor6)\n - [Alan Du](https://www.kaggle.com/alandu20)\n - [Albert Costas](https://www.kaggle.com/acostasg)\n - [AlbertJiang](https://www.kaggle.com/jsl9208)\n - [Alberto Almui\xc3\x83\xc2\xb1a](https://www.kaggle.com/albertogonzalez)\n - [Alberto Artasanchez](https://www.kaggle.com/alberto33)\n - [Alberto Barradas](https://www.kaggle.com/abcsds)\n - [Alberto Martinho](https://www.kaggle.com/ammm92)\n - [Albyati](https://www.kaggle.com/albyati)\n - [Alec](https://www.kaggle.com/cooperscoupe)\n - [AleenahKhan](https://www.kaggle.com/aleenah)\n - [Alejandro Taboada](https://www.kaggle.com/aleecai)\n - [Alejandro](https://www.kaggle.com/luisalejandro)\n - [Aleksandr Ivanov](https://www.kaggle.com/aleksandrivanov)\n - [Aleksandr Shevchenko](https://www.kaggle.com/alshevchenko)\n - [Aleksey Bilogur](https://www.kaggle.com/residentmario)\n - [Alessandro De Vito](https://www.kaggle.com/alessandrodevito)\n - [Alex Acosta](https://www.kaggle.com/checoalejandro)\n - [Alex K](https://www.kaggle.com/alexey2004)\n - [Alex Klibisz](https://www.kaggle.com/alexklibisz)\n - [Alex Korablev](https://www.kaggle.com/avkorablev)\n - [Alex Lee](https://www.kaggle.com/leealex0201)\n - [Alex Miasoedov](https://www.kaggle.com/msoedov)\n - [Alex Xiaotong Gui](https://www.kaggle.com/alexgui)\n - [Alex_deng](https://www.kaggle.com/dengjianbo)\n - [Alex](https://www.kaggle.com/russianzebra)\n - [Alexander Kireev](https://www.kaggle.com/alexanderkireev)\n - [Alexander Konshin](https://www.kaggle.com/sashulyak)\n - [Alexander Long](https://www.kaggle.com/alexlong)\n - [Alexander Mamaev](https://www.kaggle.com/alxmamaev)\n - [Alexander Minushkin](https://www.kaggle.com/miniushkin)\n - [Alexander Raboin](https://www.kaggle.com/successf2fe)\n - [Alexander Shakhov](https://www.kaggle.com/centurion1986)\n - [Alexander](https://www.kaggle.com/janiobachmann)\n - [AlexanderGlulkhovtsev](https://www.kaggle.com/glukalex)\n - [alexattia](https://www.kaggle.com/alexattia)\n - [Alexey Filimonchuk](https://www.kaggle.com/apachaika)\n - [Alexey Rozhnev](https://www.kaggle.com/rozhnevay)\n - [Alexis Carrillo](https://www.kaggle.com/acarrillor)\n - [Alexis Fossart](https://www.kaggle.com/neomatamune)\n - [AlexisGlennEspina](https://www.kaggle.com/silveriron)\n - [AlexLight](https://www.kaggle.com/rotinhfhffh)\n - [alexnavarrete](https://www.kaggle.com/alexnavarrete)\n - [Alexstrasza](https://www.kaggle.com/lwm520kaggle)\n - [AlexZhang](https://www.kaggle.com/trescommas)\n - [ALFONSOREYES](https://www.kaggle.com/msfz751)\n - [AlfredoQuintana](https://www.kaggle.com/qalfredo)\n - [Ali Ghafour](https://www.kaggle.com/ali2020armor)\n - [Ali Hussain](https://www.kaggle.com/alihussain1993)\n - [alifarsi](https://www.kaggle.com/alifarsi)\n - [alifatemy](https://www.kaggle.com/alifatemy53)\n - [Aliia Salakheeva](https://www.kaggle.com/amalgama)\n - [alimbekovkz](https://www.kaggle.com/alimbekovkz)\n - [Alin Secareanu](https://www.kaggle.com/secareanualin)\n - [Alishan Kaisani](https://www.kaggle.com/alishankaisani)\n - [Allan Scott](https://www.kaggle.com/allanscott)\n - [Allan](https://www.kaggle.com/allank)\n - [Allen Institute for Artificial Intelligence](https://www.kaggle.com/allenai)\n - [AllHailSammy](https://www.kaggle.com/wangshangsam)\n - [Allsmiles](https://www.kaggle.com/a115miles)\n - [Alok Nimrani](https://www.kaggle.com/aloknimrani)\n - [Alon](https://www.kaggle.com/alonyoeli)\n - [alopez247](https://www.kaggle.com/alopez247)\n - [Alp Ko\xc3\x83\xc2\xa7](https://www.kaggle.com/alpkoc)\n - [alphaHaxor](https://www.kaggle.com/alphahaxor)\n - [alphajuliet](https://www.kaggle.com/alphajuliet)\n - [AltonLu](https://www.kaggle.com/altonlu)\n - [AlukoSayo](https://www.kaggle.com/alukosayoenoch)\n - [Alvaro Flores](https://www.kaggle.com/afflores)\n - [\xc3\x83\xc2\x81lvaro L\xc3\x83\xc2\xb3pez Garc\xc3\x83\xc2\xada](https://www.kaggle.com/alvarolopez)\n - [Alvaro Soares](https://www.kaggle.com/alvarosoares)\n - [Alvaro Trancon](https://www.kaggle.com/atrancon)\n - [Alvin Mbabazi](https://www.kaggle.com/ambabazi)\n - [AlwaysChaCha](https://www.kaggle.com/alwayschacha)\n - [Alyssa](https://www.kaggle.com/avenn98)\n - [Aman Agarwal](https://www.kaggle.com/firstofhisname)\n - [Aman Ajmera](https://www.kaggle.com/amanajmera1)\n - [aman mahendra](https://www.kaggle.com/mahendra635)\n - [Aman Shrivastava](https://www.kaggle.com/thec03u5)\n - [Amandeep Rathee](https://www.kaggle.com/arathee2)\n - [Amar Basic](https://www.kaggle.com/amarba)\n - [Amber Song](https://www.kaggle.com/zizhensong)\n - [Amer](https://www.kaggle.com/arabbo)\n - [Amey Goel](https://www.kaggle.com/ameygoel)\n - [Amil Khare](https://www.kaggle.com/axelius)\n - [Amin Ghaderi](https://www.kaggle.com/amnghd)\n - [Amine GHERBI](https://www.kaggle.com/gherbox)\n - [AMiner](https://www.kaggle.com/aminer)\n - [AminS](https://www.kaggle.com/aminsorkhei)\n - [Amir Aharon](https://www.kaggle.com/aharonamir)\n - [Amir Rezaei](https://www.kaggle.com/rtzrnsh)\n - [Amit Maurya](https://www.kaggle.com/akm5160)\n - [amit](https://www.kaggle.com/gaurav0651)\n - [Amita Dhainje](https://www.kaggle.com/dhainjeamita)\n - [AmitaAshokDhainje](https://www.kaggle.com/monsterinc)\n - [amitani](https://www.kaggle.com/amitani)\n - [Amlan Praharaj](https://www.kaggle.com/amlanpraharaj)\n - [Amol Naik](https://www.kaggle.com/dynamic22)\n - [Amro](https://www.kaggle.com/am1to2)\n - [amrrs](https://www.kaggle.com/nulldata)\n - [Anand Jeyahar](https://www.kaggle.com/anandjeyahar)\n - [Anand](https://www.kaggle.com/asranand7)\n - [AnantBhardwaj](https://www.kaggle.com/anantb)\n - [Ananya Nayan](https://www.kaggle.com/dragonheir)\n - [Anas Aboureada](https://www.kaggle.com/anasfullstack)\n - [Anastasios Zouzias](https://www.kaggle.com/zouzias)\n - [Ancient One](https://www.kaggle.com/dominhtuan)\n - [AndersKetelsen](https://www.kaggle.com/andersketelsen)\n - [Anderson Chaves](https://www.kaggle.com/apachaves)\n - [Andi Fauzi Firdaus](https://www.kaggle.com/andifirdaus)\n - [Andieminogue](https://www.kaggle.com/andieminogue)\n - [Andre Holzner](https://www.kaggle.com/holzner)\n - [Andre Sionek](https://www.kaggle.com/andresionek)\n - [Andrea Cesarini](https://www.kaggle.com/cesaaar)\n - [Andrea Girardi](https://www.kaggle.com/girardi69)\n - [andrea leo](https://www.kaggle.com/andrealeo)\n - [Andrea](https://www.kaggle.com/dalpozz)\n - [Andreas Kappl](https://www.kaggle.com/andikappl)\n - [Andreas Klintberg](https://www.kaggle.com/andreasklintberg)\n - [Andrei Dukhounik](https://www.kaggle.com/dukhovnik)\n - [Andres C](https://www.kaggle.com/andrescala)\n - [Andres Hernandez](https://www.kaggle.com/andres111mejia)\n - [AndresFelipeBayonaChinchilla](https://www.kaggle.com/afbayonac)\n - [Andressa Coelho](https://www.kaggle.com/andressacoelho)\n - [Andrew Dacenko](https://www.kaggle.com/andrewdacenko)\n - [Andrew Gross](https://www.kaggle.com/apgross)\n - [Andrew Kirk](https://www.kaggle.com/ajskirk)\n - [Andrew Kreimer](https://www.kaggle.com/algonell)\n - [Andrew Thompson](https://www.kaggle.com/snapcrack)\n - [Andrew Truman](https://www.kaggle.com/killbot)\n - [Andrew wang](https://www.kaggle.com/tuilipai)\n - [Andrew Yue Xie](https://www.kaggle.com/andyxie)\n - [andrew.chen](https://www.kaggle.com/andrwechen2121)\n - [Andrew](https://www.kaggle.com/axaxax)\n - [Andrew](https://www.kaggle.com/indrija)\n - [AndrewEhsaei](https://www.kaggle.com/aehsaei)\n - [AndrewMalinow, PhD](https://www.kaggle.com/amalinow)\n - [andrewnachtigal](https://www.kaggle.com/andrewnachtigal)\n - [Andrey Dotsenko](https://www.kaggle.com/hawker)\n - [Andrey](https://www.kaggle.com/andreybulezyuk)\n - [Andrey](https://www.kaggle.com/andreysurovtsev)\n - [Andrey](https://www.kaggle.com/dronio)\n - [Andriy Gudziy](https://www.kaggle.com/andreyka2)\n - [Andry Ml](https://www.kaggle.com/andrianirina)\n - [Andy Friedman](https://www.kaggle.com/afriedman412)\n - [Andy Harless](https://www.kaggle.com/aharless)\n - [Andy Levitskyy](https://www.kaggle.com/andygoo)\n - [AndyKlyman](https://www.kaggle.com/andyandy)\n - [Angela Houston](https://www.kaggle.com/angelarenahouston)\n - [AngelaLocoro](https://www.kaggle.com/alocoro)\n - [Angeline Pld](https://www.kaggle.com/anplaud)\n - [Angga Purnama](https://www.kaggle.com/anggagewor)\n - [anil](https://www.kaggle.com/anilspyd3r)\n - [AnilKumarPallekonda](https://www.kaggle.com/apallekonda)\n - [AnimatronBot](https://www.kaggle.com/animatronbot)\n - [Aniruddha Achar](https://www.kaggle.com/aniruddhaachar)\n - [Aniruddha Ghosh](https://www.kaggle.com/aniruddha07)\n - [Anirudh K. Muralidhar](https://www.kaggle.com/anirudh796)\n - [Anish N Sharma](https://www.kaggle.com/anish9167473766)\n - [anjali reddy](https://www.kaggle.com/anjalichappidi)\n - [Anji](https://www.kaggle.com/anji763)\n - [Ankit Agarwal](https://www.kaggle.com/ankitagarwal4)\n - [Ankit Akash Jha](https://www.kaggle.com/ankitakash)\n - [Ankit Biradar Crixus](https://www.kaggle.com/ankitbiradar)\n - [Ankit Chaubal](https://www.kaggle.com/ankitchaubal)\n - [ANKIT JINDAL](https://www.kaggle.com/ankiijindae)\n - [Ankit](https://www.kaggle.com/ankit2106)\n - [ankita](https://www.kaggle.com/ankitasahni)\n - [Ankur Joshi](https://www.kaggle.com/joshiankur)\n - [ankur](https://www.kaggle.com/ankur2012iitg)\n - [AnkurSaikia](https://www.kaggle.com/anksaiki)\n - [AnkushAnshuman](https://www.kaggle.com/bytekiller)\n - [anmol](https://www.kaggle.com/studmol)\n - [Anna Montoya](https://www.kaggle.com/annavictoria)\n - [Anna Montoya](https://www.kaggle.com/datafordays)\n - [AnnaMongillo](https://www.kaggle.com/anm431)\n - [Annanya Pratap](https://www.kaggle.com/annan170101008)\n - [annecool37](https://www.kaggle.com/annecool37)\n - [Annie Pi](https://www.kaggle.com/anniepi)\n - [anokas](https://www.kaggle.com/anokas)\n - [ansh.g](https://www.kaggle.com/anshg98)\n - [Anshul Jain](https://www.kaggle.com/ajnatural)\n - [Anshul Kwatra](https://www.kaggle.com/kwatraanshul7)\n - [Anthony DeLuca](https://www.kaggle.com/anthonydeluca)\n - [Anthony Goldbloom](https://www.kaggle.com/antgoldbloom)\n - [Anthony Nguyen](https://www.kaggle.com/anovaguy)\n - [AnthonyAllen](https://www.kaggle.com/antallen)\n - [Anton Bobanev](https://www.kaggle.com/antfarol)\n - [Anton Dmitriev](https://www.kaggle.com/velavok)\n - [Anton Lytyakov](https://www.kaggle.com/lytyakov)\n - [Anton Prokopyev](https://www.kaggle.com/prokopyev)\n - [Anton Savchenko](https://www.kaggle.com/tonyplaysguitar)\n - [Antonio Coelho](https://www.kaggle.com/antoniobap)\n - [Antonio Domenzain](https://www.kaggle.com/mrpredictit)\n - [Antonio Guimarey Mar\xc3\x83\xc2\xb3n](https://www.kaggle.com/manchitas)\n - [Antonio Javier Gonz\xc3\x83\xc2\xa1lez Ferrer](https://www.kaggle.com/jgonzalezferrer)\n - [AntonioFeregrinoBola\xc3\x83\xc2\xb1os](https://www.kaggle.com/ioexception)\n - [AntonioIvanovski](https://www.kaggle.com/ivanovskia1)\n - [antonyj](https://www.kaggle.com/antonyj453)\n - [Antti-Paladin](https://www.kaggle.com/anttipaladin)\n - [anttip](https://www.kaggle.com/anttip)\n - [Anu](https://www.kaggle.com/anupamakhan)\n - [Anubhav Dhiman](https://www.kaggle.com/dhimananubhav)\n - [Anuj Anand Gagrai](https://www.kaggle.com/anuj8june)\n - [Anuj Goyal](https://www.kaggle.com/goyalanuj53)\n - [Anujay Saraf](https://www.kaggle.com/anujaysaraf)\n - [Anupama Jha](https://www.kaggle.com/dyanamites)\n - [Anurag Gothwal](https://www.kaggle.com/anuraggothwal)\n - [anurag K](https://www.kaggle.com/anurag98k)\n - [Anurag Maurya](https://www.kaggle.com/anurag16ph20003)\n - [Anurag Sharma](https://www.kaggle.com/anu0012)\n - [Anurag](https://www.kaggle.com/ozoneforlife)\n - [AnuragPuri](https://www.kaggle.com/anurag010puri)\n - [Anuraj](https://www.kaggle.com/anurajkr)\n - [Anvesh Tummala](https://www.kaggle.com/anvesh525)\n - [APARAJITA TIWARI](https://www.kaggle.com/aparajitatiwari)\n - [apollonius](https://www.kaggle.com/apollonius)\n - [Apoorv Agnihotri](https://www.kaggle.com/apoorvagni)\n - [ApoorvaJha](https://www.kaggle.com/apoorvajha)\n - [AppleCrazy](https://www.kaggle.com/applecrazy)\n - [Apratim Bhattacharya](https://www.kaggle.com/apratim87)\n - [Arasaraja](https://www.kaggle.com/arasaraja)\n - [Arash](https://www.kaggle.com/arashnic)\n - [Aravindhan S](https://www.kaggle.com/aravindhans)\n - [ArcGIS Open Data](https://www.kaggle.com/arcgisopendata)\n - [Archana Khanal](https://www.kaggle.com/akhanal0)\n - [Archangell](https://www.kaggle.com/archangell)\n - [Arda Mavi](https://www.kaggle.com/ardamavi)\n - [Arden Tran](https://www.kaggle.com/ardentran)\n - [areeves87](https://www.kaggle.com/areeves87)\n - [Ariful Ambia](https://www.kaggle.com/nomanvb)\n - [Arihant Jain](https://www.kaggle.com/arihant456)\n - [Arijit Mukherjee](https://www.kaggle.com/zed9941)\n - [Arion AI](https://www.kaggle.com/ariontraining)\n - [Arion](https://www.kaggle.com/arionai)\n - [AritraSen](https://www.kaggle.com/aritrase)\n - [Arizona Secretary of State](https://www.kaggle.com/arizonaSecofState)\n - [ArjoonnSharma](https://www.kaggle.com/arjoonn)\n - [Arjun](https://www.kaggle.com/monsterspy)\n - [arkz](https://www.kaggle.com/arkzyyy)\n - [Armin Talic](https://www.kaggle.com/armintalic)\n - [Armineh Nourbakhsh](https://www.kaggle.com/arminehn)\n - [ArnaudLievin](https://www.kaggle.com/arnaudlievin)\n - [Arnoud](https://www.kaggle.com/arnoudbuzing)\n - [arokkones](https://www.kaggle.com/arokkones)\n - [Arooj Anwar Khan](https://www.kaggle.com/aroojanwarkhan)\n - [Arpan Dhatt](https://www.kaggle.com/arpandhatt)\n - [Arpi Sinanyan](https://www.kaggle.com/arpisinanyan)\n - [arsenland](https://www.kaggle.com/arsenland)\n - [ArshadSiddhiqui](https://www.kaggle.com/dsmailarshad)\n - [Arslan Zulfiqar](https://www.kaggle.com/arslanzulfiqar)\n - [Artem Larionov](https://www.kaggle.com/alarionov)\n - [artemzraev](https://www.kaggle.com/landish145)\n - [Arthur Stsepanenka](https://www.kaggle.com/kingarthur7)\n - [arthur163](https://www.kaggle.com/arthur163)\n - [artlee](https://www.kaggle.com/artlee)\n - [Arun Joseph](https://www.kaggle.com/joarun)\n - [Arun Kumar](https://www.kaggle.com/mohochirps)\n - [Arun Menon](https://www.kaggle.com/menon444)\n - [Arun](https://www.kaggle.com/arunkumar413)\n - [arvidzt](https://www.kaggle.com/arvidzt)\n - [arvind bhatt](https://www.kaggle.com/arvindbhatt)\n - [Arvindhan Rameshbabu](https://www.kaggle.com/ara0303)\n - [Arwin Neil Baichoo](https://www.kaggle.com/arwinneil)\n - [AsadMahmood](https://www.kaggle.com/asad1m9a9h6mood)\n - [asado23](https://www.kaggle.com/jlealtru)\n - [asfdafaE](https://www.kaggle.com/inugami)\n - [ashish bansal](https://www.kaggle.com/ashishbansal23)\n - [Ashish Chauhan](https://www.kaggle.com/ashchauh)\n - [Ashish gupta](https://www.kaggle.com/darksoulz)\n - [Ashish Khanna](https://www.kaggle.com/askhanna)\n - [Ashish Sonavane](https://www.kaggle.com/ashis170122009)\n - [Ashita Gupta](https://www.kaggle.com/ashitagupta127)\n - [ashleysmith](https://www.kaggle.com/ashleysmith)\n - [Ashok Kumar Pant](https://www.kaggle.com/ashokpant)\n - [Ashok Lathwal](https://www.kaggle.com/codename007)\n - [ASHUTOSH KUMAR](https://www.kaggle.com/ashukr)\n - [ashvinking](https://www.kaggle.com/ashvinking)\n - [ashwani](https://www.kaggle.com/ashwaninsit)\n - [Asim Irshad](https://www.kaggle.com/asimirshad)\n - [AskarNurbekov](https://www.kaggle.com/alfazick)\n - [Asma BELHAOUA](https://www.kaggle.com/younasm)\n - [asper](https://www.kaggle.com/zbasper)\n - [ASSO PAVIC - Angers Smart City](https://www.kaggle.com/assopavic)\n - [Astandri K](https://www.kaggle.com/astandrik)\n - [Atanas Atanasov](https://www.kaggle.com/atanasova)\n - [Atefeh Goodarzi](https://www.kaggle.com/goodarzi)\n - [athabascaAI](https://www.kaggle.com/athabascaai)\n - [Athni](https://www.kaggle.com/athniv)\n - [athontz](https://www.kaggle.com/athontz)\n - [Atikur Rahman](https://www.kaggle.com/atikur)\n - [Atul A](https://www.kaggle.com/atulnet)\n - [Aty Rachmawati](https://www.kaggle.com/atyrachm)\n - [Aubert Sigouin](https://www.kaggle.com/aubertsigouin)\n - [August](https://www.kaggle.com/xinyaol)\n - [AugustinPottier](https://www.kaggle.com/tspmsa)\n - [Augusto Pertence](https://www.kaggle.com/pertence)\n - [aumas](https://www.kaggle.com/aumashe)\n - [aurelian](https://www.kaggle.com/aurelian)\n - [Aurelio Agundez](https://www.kaggle.com/aagundez)\n - [auriml](https://www.kaggle.com/auriml)\n - [AustinSonger](https://www.kaggle.com/austinvernsonger)\n - [Australian Bureau of Statistics](https://www.kaggle.com/australian-bureau-of-statistics)\n - [Austro](https://www.kaggle.com/austro)\n - [autuanliu](https://www.kaggle.com/autuanliuyc)\n - [Avani Gupta](https://www.kaggle.com/finessefidelity)\n - [AvirudhTheraja](https://www.kaggle.com/singularity99)\n - [Avkash](https://www.kaggle.com/avkash)\n - [Awesome](https://www.kaggle.com/awesome1296)\n - [aWright](https://www.kaggle.com/ktownactuary)\n - [AXA_FOSSOUO](https://www.kaggle.com/fossouodonald)\n - [\xc3\xa3\xc2\x81\xc5\xb8\xc3\xa3\xc2\x81\xe2\x80\xb9\xc3\xa3\xc2\x81\xc2\xa8\xc3\xa3\xe2\x80\x9a\xe2\x80\x9a](https://www.kaggle.com/stakatomo)\n - [AYAN MAITY](https://www.kaggle.com/ayanmaity)\n - [AyanTiwari](https://www.kaggle.com/tiwariayan)\n - [Aydin Ayanzadeh](https://www.kaggle.com/ayanzadeh93)\n - [AymanFawzy](https://www.kaggle.com/aymanfsherief)\n - [Aysun](https://www.kaggle.com/aysunfar)\n - [Ayush Sharma](https://www.kaggle.com/ashar97)\n - [ayush](https://www.kaggle.com/ayush77)\n - [AyushDewan](https://www.kaggle.com/ayushdewan)\n - [AyushThada](https://www.kaggle.com/itsayushthada)\n - [Azeem Bootwala](https://www.kaggle.com/azeembootwala)\n - [Babu Priyavrat](https://www.kaggle.com/geoclarity)\n - [babuloseo](https://www.kaggle.com/babuloseo)\n - [babybear](https://www.kaggle.com/yixiongbao)\n - [Bachi](https://www.kaggle.com/bachii)\n - [Backblaze](https://www.kaggle.com/backblaze)\n - [bacon](https://www.kaggle.com/mak1337)\n - [Badari Vishal Madduluri](https://www.kaggle.com/bvmadduluri)\n - [bader](https://www.kaggle.com/sulemanbader)\n - [Badri Adhikari](https://www.kaggle.com/badriadhikari)\n - [bagmanas](https://www.kaggle.com/bagman)\n - [bahadir60](https://www.kaggle.com/bahadir60)\n - [Bai Li](https://www.kaggle.com/luckyt)\n - [Baking Pi](https://www.kaggle.com/raspberrypie)\n - [Baligh Mnassri](https://www.kaggle.com/mnassrib)\n - [Bank of England](https://www.kaggle.com/bank-of-england)\n - [BaptisteAmato](https://www.kaggle.com/maewanto)\n - [Bargava](https://www.kaggle.com/rouseguy)\n - [Baris Simsek](https://www.kaggle.com/simsek)\n - [Barney Farrell](https://www.kaggle.com/farrelbkaggle)\n - [BaronChen](https://www.kaggle.com/baronccc)\n - [Barton.news](https://www.kaggle.com/bartondotnews)\n - [Bas Hilgers](https://www.kaggle.com/bashilgers)\n - [Basil](https://www.kaggle.com/basilh)\n - [Bastien Javaux](https://www.kaggle.com/babalerouge)\n - [Batangas](https://www.kaggle.com/batangas)\n - [batzig](https://www.kaggle.com/batziggy)\n - [Bayarjargal](https://www.kaggle.com/glbayaraa)\n - [Bazinga](https://www.kaggle.com/bazingasu)\n - [BB](https://www.kaggle.com/qexhft)\n - [Beavis Butthead](https://www.kaggle.com/beavis192)\n - [BEC14](https://www.kaggle.com/solimany)\n - [bedy](https://www.kaggle.com/bedykharisma)\n - [behzadgolshan](https://www.kaggle.com/behzadgolshan)\n - [Beili Zheng](https://www.kaggle.com/beilizheng)\n - [Bello Gbadebo](https://www.kaggle.com/gbahdeyboh)\n - [beluga](https://www.kaggle.com/gaborfodor)\n - [belvederethecat](https://www.kaggle.com/belvederethecat)\n - [Ben Dilday](https://www.kaggle.com/bdilday)\n - [Ben Hamner](https://www.kaggle.com/benhamner)\n - [Ben Ho](https://www.kaggle.com/benho15027668g)\n - [Ben Rudolph](https://www.kaggle.com/benrudolph)\n - [Ben](https://www.kaggle.com/jbthornt02)\n - [Benben Zhang](https://www.kaggle.com/huaiyu)\n - [Benf](https://www.kaggle.com/benoit72)\n - [Benjamin Taylor](https://www.kaggle.com/bentaylor)\n - [Benjamin Visser](https://www.kaggle.com/noqcks)\n - [BenjaminSwedlove](https://www.kaggle.com/jackofalltools)\n - [Berhane](https://www.kaggle.com/berhag)\n - [Berkeley Earth](https://www.kaggle.com/berkeleyearth)\n - [Bernardo Lares](https://www.kaggle.com/bernardolares)\n - [Bert Carremans](https://www.kaggle.com/bertcarremans)\n - [BethTseng](https://www.kaggle.com/feliatseng)\n - [Bhamin Patel](https://www.kaggle.com/bhamin)\n - [Bharadwaj Srigiriraju](https://www.kaggle.com/bharadwaj6)\n - [Bharani](https://www.kaggle.com/ananbharani)\n - [Bharath NR](https://www.kaggle.com/bharathnr)\n - [Bharath Posa](https://www.kaggle.com/bharathposa)\n - [Bhargav](https://www.kaggle.com/bhargav99)\n - [Bhaskar Voleti](https://www.kaggle.com/voletibhaskar)\n - [BhatNasir](https://www.kaggle.com/nasir94)\n - [bhavesh](https://www.kaggle.com/bhavesh3184)\n - [Bhavna Chawla](https://www.kaggle.com/bhavnachawla)\n - [Bhupen](https://www.kaggle.com/ancientaxe)\n - [Bhushan Sonawane](https://www.kaggle.com/bhushan23)\n - [Bhuwan pandeya](https://www.kaggle.com/pandeya)\n - [Bianca Kramer](https://www.kaggle.com/bmkramer)\n - [Bibin Paul](https://www.kaggle.com/bibinpaul)\n - [bielrv](https://www.kaggle.com/bielrv)\n - [BigBlessLee](https://www.kaggle.com/gviso97)\n - [bigdatachennai](https://www.kaggle.com/bigdatachennai)\n - [bigzhao](https://www.kaggle.com/bigzhao)\n - [BilalMahmood](https://www.kaggle.com/dsbilalmahmood)\n - [Bill S](https://www.kaggle.com/dex314)\n - [BillurEngin](https://www.kaggle.com/bengin)\n - [Bin Ury](https://www.kaggle.com/teddyerror)\n - [BingLi](https://www.kaggle.com/lbxyzz)\n - [Binks](https://www.kaggle.com/binksbiz)\n - [BinRoot](https://www.kaggle.com/binroot)\n - [BioSENSE @ UC Berkeley School of Information](https://www.kaggle.com/berkeley-biosense)\n - [birdie](https://www.kaggle.com/sengzhaotoo)\n - [biswa](https://www.kaggle.com/biswa491)\n - [bitroy](https://www.kaggle.com/bitroy)\n - [bkKaggle](https://www.kaggle.com/bkkaggle)\n - [BlackLee1994](https://www.kaggle.com/blacklee1994)\n - [BlairJennings](https://www.kaggle.com/blair0011)\n - [BlazeJ](https://www.kaggle.com/jblazez94)\n - [Blissoft](https://www.kaggle.com/blissoft)\n - [Blitzer](https://www.kaggle.com/blitzr)\n - [Bo Ju](https://www.kaggle.com/bogof666)\n - [Bob Zhang](https://www.kaggle.com/hzha3196)\n - [bob-li](https://www.kaggle.com/libowei)\n - [bobbob](https://www.kaggle.com/bobconbob)\n - [BobitaSingha](https://www.kaggle.com/bobita)\n - [Bogdan Puida](https://www.kaggle.com/dubiousone)\n - [Bojan Tunguz](https://www.kaggle.com/tunguz)\n - [BoltzmannBrain](https://www.kaggle.com/boltzmannbrain)\n - [Bongo](https://www.kaggle.com/sbongo)\n - [Boon P](https://www.kaggle.com/boonpalipatana)\n - [BoraPajo](https://www.kaggle.com/borapajo)\n - [Boris Marjanovic](https://www.kaggle.com/borismarjanovic)\n - [Bostjan Mrak](https://www.kaggle.com/bostjanm)\n - [Botao_Deng](https://www.kaggle.com/bdeng3)\n - [BOTSHOT](https://www.kaggle.com/alaaeddinemahi)\n - [boyofans](https://www.kaggle.com/boyofans)\n - [bpali26](https://www.kaggle.com/bpali26)\n - [bqlearner](https://www.kaggle.com/bqlearner)\n - [BrahanyaaSomasundaram](https://www.kaggle.com/brahanyaa)\n - [Brandon Lawrence](https://www.kaggle.com/hypersymmetry)\n - [Brandon Trabuco](https://www.kaggle.com/btrabucco)\n - [BrandtCowan](https://www.kaggle.com/brandtcowan)\n - [Brandy Chang](https://www.kaggle.com/brandychang)\n - [Brave](https://www.kaggle.com/javierbravo)\n - [breadsh](https://www.kaggle.com/echodll)\n - [BreanaMurphy](https://www.kaggle.com/breana)\n - [breandan](https://www.kaggle.com/breandan)\n - [Brendan Finan](https://www.kaggle.com/bfinan)\n - [Brendan Murphy](https://www.kaggle.com/bmurphmedia)\n - [BrendaSo](https://www.kaggle.com/sogun3)\n - [Breyonce Bugg](https://www.kaggle.com/breyonce)\n - [Brian Gonzalez](https://www.kaggle.com/brianbgonz)\n - [Brian Ho](https://www.kaggle.com/medsp3c)\n - [Brian J](https://www.kaggle.com/dalreada)\n - [Brian Liao](https://www.kaggle.com/phyred23)\n - [Brian McGarry](https://www.kaggle.com/bmcgarry194)\n - [Brian Roach](https://www.kaggle.com/broach)\n - [Brian Rouse](https://www.kaggle.com/roustekbio)\n - [Brian Rushton](https://www.kaggle.com/brirush)\n - [Brian W. Shreeves](https://www.kaggle.com/brianwshreeves)\n - [Brian](https://www.kaggle.com/bkkb82787)\n - [Briane Paul Samson](https://www.kaggle.com/brianesamson)\n - [BrianOn99](https://www.kaggle.com/brianon99)\n - [BrickettaSwiss](https://www.kaggle.com/brickettaswiss)\n - [Brihi Joshi](https://www.kaggle.com/brihijoshi)\n - [BRIJ NANDA](https://www.kaggle.com/brijnanda)\n - [Brijesh Singh](https://www.kaggle.com/brajput24)\n - [Brnt](https://www.kaggle.com/bat0485)\n - [bronson](https://www.kaggle.com/jsultan)\n - [brontosaur](https://www.kaggle.com/mikaelhuss)\n - [Brouillette](https://www.kaggle.com/brouillette)\n - [brucelees](https://www.kaggle.com/brucelees)\n - [BruceRowan](https://www.kaggle.com/rowanbruce)\n - [Bruno Flores](https://www.kaggle.com/brunoflrs)\n - [Bryan Arnold](https://www.kaggle.com/puremath86)\n - [Bryan Chen](https://www.kaggle.com/bycnnn)\n - [Bryan Park](https://www.kaggle.com/bryanpark)\n - [bryandrive](https://www.kaggle.com/bryansibaja)\n - [BryanMaloney](https://www.kaggle.com/bryanmaloney)\n - [Bryant Trombly](https://www.kaggle.com/btrombly)\n - [Bryce Freshcorn](https://www.kaggle.com/brycecf)\n - [Bryn Humphreys](https://www.kaggle.com/brynja)\n - [bshivaani](https://www.kaggle.com/bsivavenu)\n - [bssasikanth](https://www.kaggle.com/bssasikanth)\n - [BTH Project](https://www.kaggle.com/mlprojectbth)\n - [btolar1](https://www.kaggle.com/btolar1)\n - [buggs23](https://www.kaggle.com/buggs23)\n - [bughunter atgoogle](https://www.kaggle.com/testacc01)\n - [Buket Konuk Hirst](https://www.kaggle.com/buketko)\n - [Bukun](https://www.kaggle.com/ambarish)\n - [bulblight](https://www.kaggle.com/bulblight)\n - [BurakH](https://www.kaggle.com/burakhmmtgl)\n - [BuryBuryZymon](https://www.kaggle.com/maheshdadhich)\n - [Buzz Zhang](https://www.kaggle.com/fengerzh)\n - [\xc3\xa7\xe2\x80\x9d\xc2\xb3\xc3\xa5\xc2\xb0\xc2\x8f\xc3\xa8\xe2\x84\xa2\xc5\xbd](https://www.kaggle.com/charleshen)\n - [\xc3\xa7\xc2\xa7\xe2\x80\xb9\xc3\xa4\xc2\xb9\xe2\x80\xb9\xc3\xa7\xc2\x81\xc2\xb5\xc3\xa7\xc2\xbe\xc2\xbd](https://www.kaggle.com/jdreamer)\n - [Caio Correia](https://www.kaggle.com/caimocor)\n - [Caio Lente](https://www.kaggle.com/ctlente)\n - [Caio Moreno](https://www.kaggle.com/caiomsouza)\n - [CaiqueCassemiro](https://www.kaggle.com/caiquecassemiro)\n - [Caitlin Furby](https://www.kaggle.com/cfurby243)\n - [Caleb Willms](https://www.kaggle.com/cwillms)\n - [CalebFackler](https://www.kaggle.com/cafackl93)\n - [California Environmental Protection Agency](https://www.kaggle.com/calepa)\n - [Calvin Chan](https://www.kaggle.com/calvin20cc)\n - [Cam Nugent](https://www.kaggle.com/camnugent)\n - [Cameron Chandler](https://www.kaggle.com/blazethrower)\n - [Cameron](https://www.kaggle.com/cameronsim)\n - [CamilaSampaio](https://www.kaggle.com/sampaioc)\n - [Camille Debrun](https://www.kaggle.com/debrun)\n - [Campbell McGrouther](https://www.kaggle.com/capramambrica)\n - [canuto](https://www.kaggle.com/cdpilcol)\n - [Caparrini](https://www.kaggle.com/caparrini)\n - [Caramba Donkey](https://www.kaggle.com/carambadonkey)\n - [Cards Against Humanity](https://www.kaggle.com/cardsagainsthumanity)\n - [Carl Jackson](https://www.kaggle.com/despard)\n - [Carl Thom\xc3\x83\xc2\xa9](https://www.kaggle.com/carlthome)\n - [CarlesBalsach](https://www.kaggle.com/cabaki)\n - [Carlos Aguayo](https://www.kaggle.com/carlosaguayo)\n - [Carlos Beltr\xc3\x83\xc2\xa1n Villamizar](https://www.kaggle.com/carlosbeltranv)\n - [Carlos Brioso](https://www.kaggle.com/cbrioso)\n - [Carlos Paradis](https://www.kaggle.com/carlosparadis)\n - [Carlos Rafael](https://www.kaggle.com/crmercado)\n - [Carlos Vouking](https://www.kaggle.com/carlosvouking)\n - [CarlosMoncayo](https://www.kaggle.com/quecarajos)\n - [Carly Wright](https://www.kaggle.com/wrightca)\n - [Caroline Cypranowska](https://www.kaggle.com/cypranowska)\n - [Carrie](https://www.kaggle.com/carrie1)\n - [Carsten Behring](https://www.kaggle.com/behrica)\n - [Cataras](https://www.kaggle.com/cataras)\n - [Cathie So](https://www.kaggle.com/socathie)\n - [Cauim](https://www.kaggle.com/cauimsouza)\n - [CCCHEUNG](https://www.kaggle.com/cccheung)\n - [cclark](https://www.kaggle.com/cclark)\n - [cecil kim](https://www.kaggle.com/jy199412)\n - [cedrikfd](https://www.kaggle.com/cedrikfd)\n - [Celio Larcher](https://www.kaggle.com/celiolarcher)\n - [Cem Karabulut](https://www.kaggle.com/cemkarabulut)\n - [Cenk Bircano\xc3\x84\xc5\xb8lu](https://www.kaggle.com/cenkbircanoglu)\n - [Center for Medicare and Medicaid](https://www.kaggle.com/center-for-medicare-and-medicaid)\n - [Centers for Disease Control and Prevention](https://www.kaggle.com/cdc)\n - [Centers for Medicare & Medicaid Services](https://www.kaggle.com/cms)\n - [Central Bureau of Statistics](https://www.kaggle.com/ilcbs)\n - [Ceshine Lee](https://www.kaggle.com/ceshine)\n - [cgaete](https://www.kaggle.com/cgaete)\n - [Chad Schirmer](https://www.kaggle.com/schirmerchad)\n - [Chaitanya Bapat](https://www.kaggle.com/chaibapat)\n - [ChamberUnderground](https://www.kaggle.com/karrrimba)\n - [Chandan Singh](https://www.kaggle.com/chandan2495)\n - [chandlervan](https://www.kaggle.com/chandlervan)\n - [Chandra Bhushan Roy](https://www.kaggle.com/chandraroy)\n - [chansh](https://www.kaggle.com/chansh)\n - [Chanwoo Kim](https://www.kaggle.com/kcw0425)\n - [Chaochana Siparitat](https://www.kaggle.com/chaochana)\n - [Chara Remoundou](https://www.kaggle.com/chararem)\n - [Charles Jansen](https://www.kaggle.com/cjansen)\n - [CharlesYang](https://www.kaggle.com/charlesxjyang)\n - [Charlie H.](https://www.kaggle.com/archaeocharlie)\n - [Charlie Monk](https://www.kaggle.com/charliemonk)\n - [Charlie](https://www.kaggle.com/cjdaffern)\n - [Charmi](https://www.kaggle.com/trivedicharmi)\n - [Chase Bank](https://www.kaggle.com/chasebank)\n - [Chase Willden](https://www.kaggle.com/chasewillden)\n - [Chaton](https://www.kaggle.com/phperet)\n - [Chekos](https://www.kaggle.com/chekos)\n - [Chella Priyadharshini](https://www.kaggle.com/chellaindu)\n - [Chen Chen](https://www.kaggle.com/powderist)\n - [Chen Shuyao](https://www.kaggle.com/typewind)\n - [Chen](https://www.kaggle.com/tcpsyc)\n - [Cheng ZHANG](https://www.kaggle.com/zhangcheng1006)\n - [Cheng](https://www.kaggle.com/gtitw456)\n - [chengzhan](https://www.kaggle.com/chengzhan)\n - [Chennai Kaggler\'s Forum](https://www.kaggle.com/chennaikagglersforum)\n - [Chenxi_Ge](https://www.kaggle.com/atlasgcx)\n - [cheshire](https://www.kaggle.com/cheshire)\n - [Chester Cheng](https://www.kaggle.com/chez8990)\n - [Chetan Malhotra](https://www.kaggle.com/debuggermalhotra)\n - [chetan](https://www.kaggle.com/chetanism)\n - [Chewable](https://www.kaggle.com/chewable21)\n - [chfly2000](https://www.kaggle.com/chfly2000)\n - [Chi ](https://www.kaggle.com/chinguyen2303)\n - [Chia S\xc3\xa1\xc2\xba\xc2\xbd Kinh Nghi\xc3\xa1\xc2\xbb\xe2\x80\xa1m \xc3\x84\xc2\x90i Du L\xc3\xa1\xc2\xbb\xe2\x80\xb9ch H\xc3\xa1\xc2\xbb\xe2\x84\xa2i An \xc3\x84\xc2\x90\xc3\x83\xc2\xa0 N\xc3\xa1\xc2\xba\xc2\xb5ng](https://www.kaggle.com/dulichhoian)\n - [Chia Yi](https://www.kaggle.com/chiayii)\n - [Chicago Police Department](https://www.kaggle.com/chicagopolice)\n - [chickgod](https://www.kaggle.com/chickgod)\n - [Chidi](https://www.kaggle.com/chidi18)\n - [Chinelo Okpalaonwuka](https://www.kaggle.com/tessyo)\n - [Ching](https://www.kaggle.com/hchings)\n - [ChinkiRai](https://www.kaggle.com/chinki)\n - [ChinkitPatel](https://www.kaggle.com/chinkitp)\n - [chip0001](https://www.kaggle.com/chip0001)\n - [Chippy](https://www.kaggle.com/nigelcarpenter)\n - [ChiragBalakrishna](https://www.kaggle.com/chiragbalakrishna)\n - [Chithra MS](https://www.kaggle.com/suchi96)\n - [chloesh](https://www.kaggle.com/chenxt74)\n - [ChNaveen](https://www.kaggle.com/navinch)\n - [Chonlapat Patanajirasit](https://www.kaggle.com/chonlapat)\n - [Chris Bartel](https://www.kaggle.com/cbartel)\n - [Chris Brent](https://www.kaggle.com/chrisbrent)\n - [Chris Buetti](https://www.kaggle.com/chrisbuetti)\n - [Chris Crawford](https://www.kaggle.com/crawford)\n - [Chris Cross](https://www.kaggle.com/crailtap)\n - [Chris Evi-Parker](https://www.kaggle.com/chrisparker126)\n - [Chris Formey](https://www.kaggle.com/cformey24)\n - [Chris G](https://www.kaggle.com/cjgdev)\n - [Chris H.](https://www.kaggle.com/hurlburt)\n - [Chris Murphy](https://www.kaggle.com/muchris08)\n - [Chris Pierse](https://www.kaggle.com/xenogearcap)\n - [Chris Roth](https://www.kaggle.com/cjroth)\n - [Chris Scott](https://www.kaggle.com/scottdchris)\n - [Chris](https://www.kaggle.com/kingchris)\n - [Chris](https://www.kaggle.com/rootuser)\n - [ChrisAddy](https://www.kaggle.com/chrisaddy)\n - [chrisb](https://www.kaggle.com/chrisbellec)\n - [ChrisClark](https://www.kaggle.com/cwclark)\n - [ChrisDoil](https://www.kaggle.com/chrisdoil)\n - [ChrisM!](https://www.kaggle.com/ksuchris2000)\n - [Christ<svg/onload=alert(1)>](https://www.kaggle.com/john6qaz)\n - [ChristenLucido](https://www.kaggle.com/clucido1)\n - [Christian Nygaard](https://www.kaggle.com/cnygaard)\n - [Christian Safka](https://www.kaggle.com/csafka)\n - [Christian Urcuqui](https://www.kaggle.com/xwolf12)\n - [Christian Vorhemus](https://www.kaggle.com/christianvorhemus)\n - [ChristianTrachsel](https://www.kaggle.com/ctrachsel)\n - [Christina Mak](https://www.kaggle.com/christinamak)\n - [Christophe Chabreuil](https://www.kaggle.com/ethique)\n - [Christopher Clayford](https://www.kaggle.com/cclayford)\n - [Christopher Lambert](https://www.kaggle.com/theriley106)\n - [Christopher](https://www.kaggle.com/dellenzhang)\n - [ChristopherZerafa](https://www.kaggle.com/zerafachris)\n - [ChristopheS](https://www.kaggle.com/christophes)\n - [ChrisY1001](https://www.kaggle.com/chrisy1001)\n - [Chtholly](https://www.kaggle.com/gzt940726)\n - [Chuck Ephron](https://www.kaggle.com/chuckephron)\n - [Chuck-Yin](https://www.kaggle.com/chuckyin)\n - [churandy](https://www.kaggle.com/angelmm)\n - [Cigil Achenkunju](https://www.kaggle.com/cigilak)\n - [Cindyyyyyy](https://www.kaggle.com/cindy1028)\n - [CITIES](https://www.kaggle.com/cities)\n - [Citrahsagala](https://www.kaggle.com/citrahsagala)\n - [City of Chicago](https://www.kaggle.com/chicago)\n - [City of Los Angeles](https://www.kaggle.com/cityofLA)\n - [City of New York](https://www.kaggle.com/new-york-city)\n - [citylines.co](https://www.kaggle.com/citylines)\n - [ckeller](https://www.kaggle.com/ckeller)\n - [Clalby](https://www.kaggle.com/clalby)\n - [Claudio Sanhueza](https://www.kaggle.com/csanhueza)\n - [clayd](https://www.kaggle.com/dustincm)\n - [clement gauchy](https://www.kaggle.com/clgauch)\n - [clemetine](https://www.kaggle.com/clemetine)\n - [Cleuton Sampaio](https://www.kaggle.com/cleuton)\n - [Cliff Saito](https://www.kaggle.com/rcscyto)\n - [clim](https://www.kaggle.com/slickwilly)\n - [coconup](https://www.kaggle.com/coconup)\n - [code_thief](https://www.kaggle.com/jiachenyao)\n - [CodingVanGogh](https://www.kaggle.com/lohithbr)\n - [cogs](https://www.kaggle.com/cogitoe)\n - [ColaCole](https://www.kaggle.com/colecola)\n - [colemaclean](https://www.kaggle.com/colemaclean)\n - [ColinMorris](https://www.kaggle.com/colinmorris)\n - [College Board](https://www.kaggle.com/collegeboard)\n - [Colliaux R\xc3\x83\xc2\xa9mi](https://www.kaggle.com/simirec)\n - [Colt Bauman](https://www.kaggle.com/cabauman)\n - [Committee to Protect Journalists](https://www.kaggle.com/cpjournalists)\n - [Connecticut Open Data](https://www.kaggle.com/Connecticut-open-data)\n - [Conobrodel](https://www.kaggle.com/conobrodel)\n - [Conor MacBride](https://www.kaggle.com/macbride)\n - [ConoStabile](https://www.kaggle.com/cono94)\n - [Consumer Financial Protection Bureau](https://www.kaggle.com/cfpb)\n - [CooperUnion](https://www.kaggle.com/CooperUnion)\n - [coplin](https://www.kaggle.com/coplin)\n - [coredesign](https://www.kaggle.com/coredesign)\n - [Corentin Rdn](https://www.kaggle.com/gumcher)\n - [CorneliaVanDerWalt](https://www.kaggle.com/echochi)\n - [Cornell University](https://www.kaggle.com/Cornell-University)\n - [CosmikAlpha](https://www.kaggle.com/cosmikalpha)\n - [Cosmin Stamate](https://www.kaggle.com/stamate)\n - [CostalAether](https://www.kaggle.com/costalaether)\n - [Costas Voglis](https://www.kaggle.com/voglinio)\n - [coulet.simon](https://www.kaggle.com/couletsimon)\n - [Courtney Wanson](https://www.kaggle.com/cpw1108)\n - [cpossehl](https://www.kaggle.com/cpossehl)\n - [cricketsavant](https://www.kaggle.com/imrankhan17)\n - [CristhianBoujon](https://www.kaggle.com/overflow012)\n - [Cristiano](https://www.kaggle.com/cristianounix)\n - [Cristina](https://www.kaggle.com/cristinaholgado)\n - [criticalhits](https://www.kaggle.com/criticalhits)\n - [Cro-Magnon](https://www.kaggle.com/robertoruiz)\n - [Crowdflower](https://www.kaggle.com/crowdflower)\n - [csbond007](https://www.kaggle.com/csbond007)\n - [csgwon](https://www.kaggle.com/csgwon)\n - [csungroup67](https://www.kaggle.com/csun0485)\n - [Currie32](https://www.kaggle.com/currie32)\n - [Curtis Chong](https://www.kaggle.com/splacorn)\n - [Cutechick](https://www.kaggle.com/limkongkong)\n - [CWILOC](https://www.kaggle.com/cwiloc)\n - [Cyphers](https://www.kaggle.com/bcyphers)\n - [Cyril Ma](https://www.kaggle.com/cyrilma)\n - [CYZhao0709](https://www.kaggle.com/cyzhao0709)\n - [d pc](https://www.kaggle.com/dddpppccc)\n - [\xc3\x90\xe2\x80\x93\xc3\x91\xc6\x92\xc3\x90\xc2\xbb\xc3\x90\xc2\xb4\xc3\x91\xe2\x80\xb9\xc3\x90\xc2\xb7\xc3\x90\xc2\xb6\xc3\x90\xc2\xb0\xc3\x90\xc2\xbd\xc3\x90\xc2\xa1\xc3\x90\xc2\xb0\xc3\x90\xc2\xb3\xc3\x90\xc2\xb8\xc3\x90\xc2\xbc\xc3\x90\xc2\xb1\xc3\x90\xc2\xb0\xc3\x90\xc2\xb5\xc3\x90\xc2\xb2](https://www.kaggle.com/cruigo93)\n - [Daan Sterk](https://www.kaggle.com/daansterk)\n - [Dada123](https://www.kaggle.com/travelerforfun)\n - [Dahee](https://www.kaggle.com/smiledana)\n - [DAI GUANYU](https://www.kaggle.com/encoreg34979)\n - [Daia Alexandru](https://www.kaggle.com/alexandrudaia)\n - [Daigo Miyoshi](https://www.kaggle.com/daigomiyoshi)\n - [Daisuke Ishii](https://www.kaggle.com/daiearth22)\n - [Daisuke](https://www.kaggle.com/daisukesatow)\n - [Dale Matthews](https://www.kaggle.com/dalematthews)\n - [dalgacik](https://www.kaggle.com/dalgacik)\n - [Dalia Research](https://www.kaggle.com/daliaresearch)\n - [DALX555](https://www.kaggle.com/alexanderdeaquiz)\n - [Damian Denesha](https://www.kaggle.com/ddenesha)\n - [Damian Eliel Aleman](https://www.kaggle.com/daleman)\n - [Damiano](https://www.kaggle.com/damianpanek)\n - [Damien BENESCHI](https://www.kaggle.com/damienbeneschi)\n - [Dan Chrispine](https://www.kaggle.com/dantest232)\n - [Dan Emery](https://www.kaggle.com/demery)\n - [Dan Ofer](https://www.kaggle.com/danofer)\n - [Dan Van Der Meulen](https://www.kaggle.com/dav204)\n - [Dan Wilden](https://www.kaggle.com/dwilden)\n - [Dan Winchester](https://www.kaggle.com/danwinchester)\n - [Dan Xu](https://www.kaggle.com/dxcffz)\n - [dan_lo](https://www.kaggle.com/inphime)\n - [Dan](https://www.kaggle.com/dan195)\n - [Danai Avgerinou](https://www.kaggle.com/danavg)\n - [dananos](https://www.kaggle.com/dananos)\n - [DanB](https://www.kaggle.com/dansbecker)\n - [danerbland](https://www.kaggle.com/danerbland)\n - [Daniel Esteves](https://www.kaggle.com/danielesteves)\n - [Daniel Franch](https://www.kaggle.com/franchenstein)\n - [Daniel Grijalva](https://www.kaggle.com/danielgrijalvas)\n - [Daniel Labbe](https://www.kaggle.com/dlabbe1005)\n - [Daniel Pye](https://www.kaggle.com/djpye18)\n - [Daniel S. Panizzo](https://www.kaggle.com/danielpanizzo)\n - [Daniel S\xc3\x83\xc2\xa1nchez](https://www.kaggle.com/danielsanchez)\n - [Daniel Silion](https://www.kaggle.com/danielsilion)\n - [Daniel Sobrado](https://www.kaggle.com/danielsobrado)\n - [Daniele](https://www.kaggle.com/john8qaz)\n - [DanielHKL](https://www.kaggle.com/danielhkl)\n - [DanielVargas](https://www.kaggle.com/danvargg)\n - [DanielViray](https://www.kaggle.com/danielviray)\n - [danielwatabe](https://www.kaggle.com/danielwatabe)\n - [Danil Zherebtsov](https://www.kaggle.com/danilz)\n - [danishxavier](https://www.kaggle.com/danishxr)\n - [Dano](https://www.kaggle.com/danimal)\n - [DanyaKosmin](https://www.kaggle.com/pluchme)\n - [daoduySon](https://www.kaggle.com/sondaoduy)\n - [darcy](https://www.kaggle.com/cuteshrimp)\n - [Daria Glebova](https://www.kaggle.com/dashaaa)\n - [DarkLord](https://www.kaggle.com/sharmaharsh)\n - [Data Hunter](https://www.kaggle.com/petromin)\n - [Data Quantum](https://www.kaggle.com/dataquantum)\n - [Data to Information to Knowledge to Wisdom](https://www.kaggle.com/d2i2k2w)\n - [data-refinement](https://www.kaggle.com/data-refinement)\n - [DataCanary](https://www.kaggle.com/datacanary)\n - [DataDopeBoy](https://www.kaggle.com/floydba)\n - [Datafiniti](https://www.kaggle.com/datafiniti)\n - [Datagraver](https://www.kaggle.com/datagraver)\n - [dataist](https://www.kaggle.com/dataistic)\n - [datamin2017](https://www.kaggle.com/datamin2017)\n - [DataP](https://www.kaggle.com/dattapiy)\n - [DataSF](https://www.kaggle.com/datasf)\n - [dataspartan](https://www.kaggle.com/dataspartan)\n - [Datastreamer](https://www.kaggle.com/dataforyou)\n - [datatest84](https://www.kaggle.com/datatest84)\n - [datath\xc3\x83\xc2\xa8que](https://www.kaggle.com/datatheque)\n - [Dave D Harsh](https://www.kaggle.com/harshdave)\n - [Dave Fisher-Hickey](https://www.kaggle.com/daveianhickey)\n - [DaveRosenman](https://www.kaggle.com/daverosenman)\n - [David Azria](https://www.kaggle.com/davidscdf)\n - [David Baker](https://www.kaggle.com/dabaker)\n - [David Bialer](https://www.kaggle.com/dbialer)\n - [David Calloway](https://www.kaggle.com/echooooo)\n - [David Chudzicki](https://www.kaggle.com/dchudz)\n - [David Cohen](https://www.kaggle.com/dcohen21)\n - [David Cooperberg](https://www.kaggle.com/hugsandbubbles)\n - [David de la Iglesia Castro](https://www.kaggle.com/daavoo)\n - [David Havera](https://www.kaggle.com/djhavera)\n - [David Odhiambo](https://www.kaggle.com/ajuoga)\n - [David Prakash](https://www.kaggle.com/davidprakash)\n - [David Rubal](https://www.kaggle.com/drubal)\n - [David Schwertfeger](https://www.kaggle.com/dschwertfeger)\n - [David Skipper Everling](https://www.kaggle.com/everling)\n - [David Str\xc3\x83\xc2\xb6m](https://www.kaggle.com/yberstrumpf)\n - [david_becks](https://www.kaggle.com/becksddf)\n - [David](https://www.kaggle.com/daalgi)\n - [David](https://www.kaggle.com/davidbijl)\n - [David](https://www.kaggle.com/davidtal)\n - [David](https://www.kaggle.com/ywang311)\n - [davide andreazzini](https://www.kaggle.com/andreazzini)\n - [DavidParr](https://www.kaggle.com/davidrgp)\n - [DavidShahrestani](https://www.kaggle.com/davidshahrestani)\n - [DavidWesley-James](https://www.kaggle.com/davewj03)\n - [DavidYang](https://www.kaggle.com/imhappyfeel)\n - [Dayana Moncada](https://www.kaggle.com/dmonca63)\n - [dazhangyu](https://www.kaggle.com/dazhangyu)\n - [\xc3\x90\xc2\x90\xc3\x90\xc2\xbb\xc3\x90\xc2\xb8\xc3\x91\xc2\x81\xc3\x90\xc2\xb0 \xc3\x90\xc5\xb8\xc3\x91\xc6\x92\xc3\x90\xc2\xb3\xc3\x90\xc2\xb0\xc3\x91\xe2\x80\xa1\xc3\x90\xc2\xb5\xc3\x90\xc2\xb2\xc3\x90\xc2\xb0](https://www.kaggle.com/alisapugacheva)\n - [\xc3\x90\xc2\x90\xc3\x90\xc2\xbb\xc3\x90\xc2\xb5\xc3\x90\xc2\xba\xc3\x91\xc2\x81\xc3\x90\xc2\xb0\xc3\x90\xc2\xbd\xc3\x90\xc2\xb4\xc3\x91\xe2\x82\xac (CMF DA)](https://www.kaggle.com/a1essandr0)\n - [\xc3\x90\xc2\x90\xc3\x90\xc2\xbd\xc3\x90\xc2\xb4\xc3\x91\xe2\x82\xac\xc3\x90\xc2\xb5\xc3\x90\xc2\xb9\xc3\x90\xc2\xa2\xc3\x90\xc2\xb8\xc3\x90\xc2\xbc\xc3\x90\xc2\xbe\xc3\x91\xe2\x80\x9e\xc3\x90\xc2\xb5\xc3\x90\xc2\xb5\xc3\x90\xc2\xb2](https://www.kaggle.com/timerlan)\n - [dddhiraj](https://www.kaggle.com/ddhiraj)\n - [Death Penalty Information Center](https://www.kaggle.com/usdpic)\n - [deathmood](https://www.kaggle.com/deathmood)\n - [Debanjan](https://www.kaggle.com/debanjanpaul)\n - [Debashish Dalal](https://www.kaggle.com/devashish0507)\n - [DebayanDasgupta](https://www.kaggle.com/xortical)\n - [DebdootSheet](https://www.kaggle.com/debdoot)\n - [DebiRath](https://www.kaggle.com/debirath)\n - [dechavez005](https://www.kaggle.com/dechavez005)\n - [deeley](https://www.kaggle.com/deeley)\n - [Deena Liz John](https://www.kaggle.com/deenaliz)\n - [deep](https://www.kaggle.com/deepak2873)\n - [Deep](https://www.kaggle.com/indranil9999)\n - [deepak gupta](https://www.kaggle.com/jigsawcoder)\n - [deepak](https://www.kaggle.com/dmail44)\n - [DeepakGupta](https://www.kaggle.com/deepakg578)\n - [DeepakKandasamy](https://www.kaggle.com/deepak95)\n - [DeepakMittal](https://www.kaggle.com/deepak242424)\n - [DeepAnalytics](https://www.kaggle.com/datasicencelab)\n - [delepp](https://www.kaggle.com/cuddihyt)\n - [DeltoiX](https://www.kaggle.com/deltoix)\n - [deluxe hotel In dalhousie](https://www.kaggle.com/hotelbluemagnet)\n - [deluXe](https://www.kaggle.com/johannesbernhard)\n - [Demetri Pananos](https://www.kaggle.com/demetrip)\n - [Democracy Fund](https://www.kaggle.com/democracy-fund)\n - [DenisAfonin](https://www.kaggle.com/denisafonin)\n - [Dennys Mallqui](https://www.kaggle.com/m3g4r00t)\n - [Department of Defense](https://www.kaggle.com/usdod)\n - [Department of Homeland Security](https://www.kaggle.com/dhs)\n - [Department of Justice](https://www.kaggle.com/doj)\n - [Department of Transportation](https://www.kaggle.com/usdot)\n - [Derek Chia](https://www.kaggle.com/derekchia)\n - [Derek Li](https://www.kaggle.com/dereklip2)\n - [Derek Y](https://www.kaggle.com/jinyuederek)\n - [Derek Zhi](https://www.kaggle.com/derekdb)\n - [Derek](https://www.kaggle.com/derekdixu)\n - [Derrick M](https://www.kaggle.com/derrickmwiti)\n - [derrine](https://www.kaggle.com/derr1011)\n - [Destin](https://www.kaggle.com/destin369y)\n - [Devansh Besain](https://www.kaggle.com/devanshbesain)\n - [devashismohapatra](https://www.kaggle.com/devashis86)\n - [Developers Area](https://www.kaggle.com/devarea)\n - [DeveshMaheshwari](https://www.kaggle.com/devm2024)\n - [Devin Anderson](https://www.kaggle.com/deanders991)\n - [Devious Dus](https://www.kaggle.com/deviousdud)\n - [Devji Chhanga](https://www.kaggle.com/idevji1)\n - [DevjyotiChandra](https://www.kaggle.com/devjyotichandra)\n - [Dexteritas](https://www.kaggle.com/sameermehra)\n - [dgoke1](https://www.kaggle.com/dgokeeffe)\n - [DhaferMalouche](https://www.kaggle.com/dhafermalouche)\n - [Dhananjay Shembekar](https://www.kaggle.com/dhananjays)\n - [Dhruv Desai](https://www.kaggle.com/dhruvdesai)\n - [DhruvMangtani](https://www.kaggle.com/dhruvm)\n - [Dian Purnama](https://www.kaggle.com/purnama)\n - [Diego Villacreses](https://www.kaggle.com/diegov)\n - [DigitalCowboy](https://www.kaggle.com/digitalcowboy)\n - [Dileep Pandey](https://www.kaggle.com/dileeppandey)\n - [dilzeem](https://www.kaggle.com/dilzeem)\n - [DimitriF](https://www.kaggle.com/dimitrif)\n - [ding](https://www.kaggle.com/nidhi06)\n - [Diogo Cortez](https://www.kaggle.com/dlcortez)\n - [Dipanjan](https://www.kaggle.com/deeiip)\n - [Dipika Baad](https://www.kaggle.com/dipikabaad0107)\n - [dish](https://www.kaggle.com/blogdish)\n - [divyajain](https://www.kaggle.com/jain6968)\n - [Divyam Soni](https://www.kaggle.com/divyam811)\n - [Divyansh](https://www.kaggle.com/divyansh91)\n - [DivyanshKumar](https://www.kaggle.com/divyanshk1)\n - [Divyojyoti Sinha](https://www.kaggle.com/divsinha)\n - [dmi3kno](https://www.kaggle.com/dmi3kno)\n - [Dmitrii Petukhov](https://www.kaggle.com/jandevel)\n - [dmitrijsc](https://www.kaggle.com/dmitrijsc)\n - [Dmitriy Sakharov](https://www.kaggle.com/tomatiks)\n - [Dmitry](https://www.kaggle.com/callmemb7)\n - [DMPierre](https://www.kaggle.com/dmpierre)\n - [\xc3\x90\xc2\x90\xc3\x91\xe2\x82\xac\xc3\x91\xe2\x80\x9a\xc3\x90\xc2\xb5\xc3\x90\xc2\xbc \xc3\x90\xe2\x80\xba\xc3\x91\xc2\x8f\xc3\x90\xc2\xbd](https://www.kaggle.com/arli2016)\n - [DobroeZlo](https://www.kaggle.com/uruzaner)\n - [Documenting the American South (DocSouth)](https://www.kaggle.com/docsouth-data)\n - [Doe Jhon](https://www.kaggle.com/drisicus)\n - [\xc3\x90\xc5\x93\xc3\x90\xc2\xb8\xc3\x91\xe2\x80\xa6\xc3\x90\xc2\xb0\xc3\x90\xc2\xb8\xc3\x90\xc2\xbb\xc3\x90\xc5\x93\xc3\x90\xc2\xb0\xc3\x90\xc2\xba\xc3\x91\xc2\x81\xc3\x91\xc5\xbd\xc3\x91\xe2\x80\x9a\xc3\x90\xc2\xb5\xc3\x90\xc2\xbd\xc3\x90\xc2\xba\xc3\x90\xc2\xbe](https://www.kaggle.com/michaelmigm)\n - [Dom Hall](https://www.kaggle.com/domhall)\n - [Domenico Delle Side](https://www.kaggle.com/nicodds)\n - [dominic](https://www.kaggle.com/dominicondigo)\n - [Dominik Gawlik](https://www.kaggle.com/dgawlik)\n - [Don Browning](https://www.kaggle.com/dbrowning)\n - [Donfuzius](https://www.kaggle.com/donfuzius)\n - [DongGeun Oh](https://www.kaggle.com/dhehdrmssla)\n - [Dongwoo Kim](https://www.kaggle.com/nobaksan)\n - [Donyoe](https://www.kaggle.com/donyoe)\n - [Dor Oppenheim](https://www.kaggle.com/dorbicycle)\n - [Doran Wu](https://www.kaggle.com/doranwu)\n - [Doug Friedman](https://www.kaggle.com/realdoug)\n - [Doug Hersak](https://www.kaggle.com/doughersak)\n - [Dr. Ahmad Al Sallab](https://www.kaggle.com/ahmadelsallab)\n - [Dr. Rich](https://www.kaggle.com/rhuebner)\n - [Dr.D.Lakshmi](https://www.kaggle.com/lakshmilovemysoul)\n - [dr.priskott](https://www.kaggle.com/drpriskott)\n - [Dragon](https://www.kaggle.com/sharmavaibhav)\n - [DrBenLyons](https://www.kaggle.com/drbenlyons)\n - [Drew Pope](https://www.kaggle.com/drewsy1991)\n - [DrGuillermo](https://www.kaggle.com/drgilermo)\n - [DRISS AIT LABSIR](https://www.kaggle.com/drissaitlabsir27)\n - [drjkuo](https://www.kaggle.com/drjkuo)\n - [Dromosys](https://www.kaggle.com/dromosys)\n - [drop-out](https://www.kaggle.com/dropout)\n - [Dryad Digital Repository](https://www.kaggle.com/dryad)\n - [DSafonov](https://www.kaggle.com/denasafonov)\n - [DSEverything](https://www.kaggle.com/dongxu027)\n - [Dsloet](https://www.kaggle.com/dsloet)\n - [DuaaNasif](https://www.kaggle.com/rezan1990)\n - [ducky](https://www.kaggle.com/ducky7)\n - [DucThanhNguyen](https://www.kaggle.com/ducthanhnguyen)\n - [dust](https://www.kaggle.com/stardust0)\n - [Dversteele](https://www.kaggle.com/dversteele)\n - [Dyadya Bogdan](https://www.kaggle.com/rfrgwglkfwgp)\n - [Dylan Amelot](https://www.kaggle.com/spektrum)\n - [Dylan Willow](https://www.kaggle.com/dmw5859)\n - [Dylan](https://www.kaggle.com/dylanli)\n - [dzoulouvincisavitriDVSInformatique_ma_passion](https://www.kaggle.com/dzoulou)\n - [E.Nikumanesh.Germany](https://www.kaggle.com/esmaeil391)\n - [\xc3\xab\xc2\xb2\xc2\xa4\xc3\xac\xc5\xbe\xc2\xa0\xc3\xab\xc2\xaf\xc2\xbc](https://www.kaggle.com/frbenjamin)\n - [\xc3\xaa\xc2\xb2\xc2\xbd\xc3\xab\xc2\xa6\xc2\xbc \xc3\xaa\xc2\xb3\xc2\xbd](https://www.kaggle.com/klkwak)\n - [eagle](https://www.kaggle.com/xiaohuihui)\n - [Eagles2F](https://www.kaggle.com/eagles2f)\n - [Earless Abdul](https://www.kaggle.com/earlessabdul)\n - [Ebrahimi](https://www.kaggle.com/shebrahimi)\n - [eccc](https://www.kaggle.com/eeeeee)\n - [ecerulm](https://www.kaggle.com/ecerulm)\n - [ecodan](https://www.kaggle.com/ecodan)\n - [Ed King](https://www.kaggle.com/kinguistics)\n - [Eden](https://www.kaggle.com/eosdatascience)\n - [Edern Haumont](https://www.kaggle.com/xaxetrov)\n - [edgano](https://www.kaggle.com/edgano)\n - [Edi Mala](https://www.kaggle.com/edimala)\n - [Edilson Augusto](https://www.kaggle.com/edilsoneasj)\n - [Edit Osikovicz](https://www.kaggle.com/osiditti)\n - [Edith](https://www.kaggle.com/statsisfun37)\n - [Edmon](https://www.kaggle.com/edmonwales)\n - [Edo Miyazaki](https://www.kaggle.com/leiyiting01)\n - [EdoardoPiccari](https://www.kaggle.com/edopic)\n - [Eduardo](https://www.kaggle.com/edumucelli)\n - [EduardoMagalh\xc3\x83\xc2\xa3esOliveira](https://www.kaggle.com/edumagalhaes)\n - [Edward Turner](https://www.kaggle.com/eaturner)\n - [Edwin Kestler](https://www.kaggle.com/kestler)\n - [edX](https://www.kaggle.com/edx)\n - [Efrain Guzman](https://www.kaggle.com/efrainguzman45)\n - [Eibriel](https://www.kaggle.com/eibriel)\n - [Eidan Cohen](https://www.kaggle.com/eidanch)\n - [EigenLaw](https://www.kaggle.com/eigenlaw)\n - [Ekansg Garg](https://www.kaggle.com/ekanshgarg1997)\n - [Ekianjo](https://www.kaggle.com/sanqualis)\n - [Eldar Tinjic](https://www.kaggle.com/eldart)\n - [EleanorBlum](https://www.kaggle.com/eblum1)\n - [EleanorXu](https://www.kaggle.com/jingbinxu)\n - [Electoral Commission](https://www.kaggle.com/electoralcommission)\n - [Electronic Frontier Foundation](https://www.kaggle.com/eff)\n - [Elemente N](https://www.kaggle.com/elemente)\n - [Elen Vardanyan](https://www.kaggle.com/lnvardanyan)\n - [Elena Cuoco](https://www.kaggle.com/elenacuoco)\n - [ElenaCall](https://www.kaggle.com/ehcall)\n - [Eli Cerdan](https://www.kaggle.com/ecerdan1)\n - [Elias Barba Moral](https://www.kaggle.com/eliasbarba)\n - [elias8888](https://www.kaggle.com/elias8888)\n - [Eliezer Bourchardt](https://www.kaggle.com/eliezerfb)\n - [ElitCenkAlp](https://www.kaggle.com/elitcenk)\n - [Eliud Kagema](https://www.kaggle.com/kagema)\n - [Elizabeth Sam](https://www.kaggle.com/elizabethsam)\n - [Elkana Rosenblatt](https://www.kaggle.com/elkanathegreat)\n - [EllaRabinovich](https://www.kaggle.com/ellarabi)\n - [Elliptic to Quantum](https://www.kaggle.com/smortezavi)\n - [ema](https://www.kaggle.com/emanueleg)\n - [email365](https://www.kaggle.com/contacts365)\n - [EmersonPereiraBertolo](https://www.kaggle.com/ebertolo)\n - [Emil Andreas Lund](https://www.kaggle.com/nuquist)\n - [Emil Nikolov](https://www.kaggle.com/enikolov)\n - [Emil.P](https://www.kaggle.com/roswellwayoff)\n - [EmilioMC](https://www.kaggle.com/newpye)\n - [Emily](https://www.kaggle.com/happydoc)\n - [emirozbir](https://www.kaggle.com/emirozbir)\n - [Emma](https://www.kaggle.com/emmabel)\n - [Emmanuel Kens](https://www.kaggle.com/emmanuelkens)\n - [EN Kim biokpc](https://www.kaggle.com/biokpc)\n - [\xc3\xa9\xc5\x93\xc5\x93\xc3\xa9\xe2\x80\xba\xc2\xaa\xc3\xa5\xc2\x8d\xc6\x92\xc3\xa5\xc2\xb9\xc2\xb4](https://www.kaggle.com/wangqiqi)\n - [eoveson](https://www.kaggle.com/eoveson)\n - [epattaro](https://www.kaggle.com/epattaro)\n - [Epiphany](https://www.kaggle.com/epyfany)\n - [Eran Machlev](https://www.kaggle.com/emachlev)\n - [Eric Grinstein](https://www.kaggle.com/egrinstein)\n - [Eric McCracken](https://www.kaggle.com/epm5122)\n - [Eric Oakley](https://www.kaggle.com/eoakley)\n - [Eric Vos](https://www.kaggle.com/a45632)\n - [Eric You](https://www.kaggle.com/circador)\n - [EricFeng](https://www.kaggle.com/ericfeng84)\n - [Erich Rodrigues](https://www.kaggle.com/eferrares)\n - [Erik van de Ven](https://www.kaggle.com/erikvdven)\n - [Erik](https://www.kaggle.com/erik404)\n - [ErikHambardzumyan](https://www.kaggle.com/erikhambardzumyan)\n - [eros](https://www.kaggle.com/erossmith)\n - [Erun Noid](https://www.kaggle.com/erunoid)\n - [Esha Somavarapu](https://www.kaggle.com/eshasomavarapu)\n - [Especuloide](https://www.kaggle.com/robervalt)\n - [Espen Sonneland](https://www.kaggle.com/essonnel)\n - [Espen](https://www.kaggle.com/ewolsen)\n - [esperto](https://www.kaggle.com/esperto007)\n - [Eswar](https://www.kaggle.com/eswarreddy)\n - [Etherqua](https://www.kaggle.com/etherqua)\n - [Etienne LQ](https://www.kaggle.com/etiennelq)\n - [Eugene](https://www.kaggle.com/domainsindex)\n - [European Centre for Medium-Range Weather Forecasts](https://www.kaggle.com/ECMWF)\n - [European Space Agency](https://www.kaggle.com/europeanspaceagency)\n - [Eurostat](https://www.kaggle.com/eurostat)\n - [Evan Jung](https://www.kaggle.com/j2hoon85)\n - [EvanPayne](https://www.kaggle.com/jpayne)\n - [Everton Seiei Arakaki](https://www.kaggle.com/evertonsa)\n - [EveryPolitician](https://www.kaggle.com/everypolitician)\n - [Evgeniy Malishev](https://www.kaggle.com/evgeniymalishev)\n - [Evgeniy Vasilev](https://www.kaggle.com/somesnm)\n - [evil.com](https://www.kaggle.com/bujaja)\n - [evren leet](https://www.kaggle.com/evren1337)\n - [Eyy\xc3\x83\xc2\xbcb Sari](https://www.kaggle.com/shabeyyub)\n - [Ezequiel Bequet](https://www.kaggle.com/ebequet)\n - [Fabia](https://www.kaggle.com/fabiaforever)\n - [Fabiano Bizarro](https://www.kaggle.com/fabianobizarro)\n - [Fabio Correa Cordeiro](https://www.kaggle.com/fabiocorreacordeiro)\n - [Fabiola](https://www.kaggle.com/fabiolabusch)\n - [fabiolux](https://www.kaggle.com/fabioluciani)\n - [Facebook](https://www.kaggle.com/facebook)\n - [FAD2018](https://www.kaggle.com/fadpl2015)\n - [Faguilar-V](https://www.kaggle.com/fermatsavant)\n - [Faisal](https://www.kaggle.com/faisalhussainsabir)\n - [Faizal Abd Kadir](https://www.kaggle.com/faizalabdkadir)\n - [Fan Fei Chong](https://www.kaggle.com/clarkchong)\n - [fandang](https://www.kaggle.com/fandang)\n - [Fangda](https://www.kaggle.com/fondaxu)\n - [Far East Group](https://www.kaggle.com/takashifc)\n - [Faraz](https://www.kaggle.com/ffaraz)\n - [Farhan Karim](https://www.kaggle.com/farhankarim1)\n - [faronFeng](https://www.kaggle.com/faronfeng)\n - [Fatihah Ulya](https://www.kaggle.com/ulaaidesu)\n - [fatima-ezzahra elaamraoui](https://www.kaggle.com/feelaamr)\n - [FatimaLidia](https://www.kaggle.com/lidiapacaje)\n - [FAUZI](https://www.kaggle.com/m0fauzi)\n - [fayomi](https://www.kaggle.com/fayomi)\n - [FCiceri](https://www.kaggle.com/fciceri17)\n - [Federal Aviation Administration](https://www.kaggle.com/faa)\n - [Federal Bureau of Investigation](https://www.kaggle.com/fbi-us)\n - [Federal Communications Commission](https://www.kaggle.com/fcc)\n - [Federal Deposit Insurance Corporation](https://www.kaggle.com/fdic)\n - [Federal Election Commission](https://www.kaggle.com/fec)\n - [Federal Emergency Management Agency](https://www.kaggle.com/fema)\n - [Federal Reserve](https://www.kaggle.com/federalreserve)\n - [Federico Bayl\xc3\x83\xc2\xa9](https://www.kaggle.com/fedebayle)\n - [Federico Soldo](https://www.kaggle.com/fedesoldo)\n - [FedericoSarrocco](https://www.kaggle.com/fede2000)\n - [Felipe Hoffa](https://www.kaggle.com/fhoffa)\n - [FelipeArgolo](https://www.kaggle.com/argolof)\n - [FelipeLeiteAntunes](https://www.kaggle.com/felipeleiteantunes)\n - [Felix Gutierrez](https://www.kaggle.com/felix4guti)\n - [FelixZhao](https://www.kaggle.com/felixzhao)\n - [FelypeBastos](https://www.kaggle.com/felypebastos)\n - [FeMO](https://www.kaggle.com/femannso)\n - [FenilSuchak](https://www.kaggle.com/fenil9)\n - [Fernanda Castro](https://www.kaggle.com/fercs89)\n - [Fernando Lopez](https://www.kaggle.com/felmco)\n - [FernandoBecerra](https://www.kaggle.com/dferbt)\n - [festa78](https://www.kaggle.com/festa78)\n - [Fifth Tribe](https://www.kaggle.com/fifthtribe)\n - [figshare](https://www.kaggle.com/figshare)\n - [Filemide](https://www.kaggle.com/filemide)\n - [Filipe Morandi](https://www.kaggle.com/tockie94)\n - [Filippo](https://www.kaggle.com/filippoo)\n - [finintelligence.com](https://www.kaggle.com/finintelligence)\n - [Firdha Amelia](https://www.kaggle.com/firdhaamelia)\n - [FiveThirtyEight](https://www.kaggle.com/fivethirtyeight)\n - [Fizmath](https://www.kaggle.com/fizmath)\n - [Flaredown](https://www.kaggle.com/flaredown)\n - [flashthunder](https://www.kaggle.com/thunderflash)\n - [FlavienGelineau](https://www.kaggle.com/flaviengelineau)\n - [Florian Pydde](https://www.kaggle.com/flopych)\n - [FlorianTHAUNAY](https://www.kaggle.com/flotha)\n - [Florin Langer](https://www.kaggle.com/florinlanger)\n - [flx1](https://www.kaggle.com/felixkagg)\n - [foenix](https://www.kaggle.com/foenix)\n - [folaraz](https://www.kaggle.com/folaraz)\n - [Food and Drug Administration](https://www.kaggle.com/fda)\n - [foolius](https://www.kaggle.com/antediemterzium)\n - [fordeletion](https://www.kaggle.com/fordeletion)\n - [Fornax.ai](https://www.kaggle.com/fornaxai)\n - [Fortune](https://www.kaggle.com/fortune-inc)\n - [Foxtrot](https://www.kaggle.com/zygmunt)\n - [Fr\xc3\x83\xc2\xa9d\xc3\x83\xc2\xa9ric Girod](https://www.kaggle.com/fredgirod)\n - [Fracking Analysis](https://www.kaggle.com/frackinganalysis)\n - [fran](https://www.kaggle.com/franhb)\n - [Francis Paul Flores](https://www.kaggle.com/grosvenpaul)\n - [Francisco Glez](https://www.kaggle.com/fgm1477)\n - [Francisco Mendez](https://www.kaggle.com/fcostartistican)\n - [Francisco Penovi](https://www.kaggle.com/fpenovi)\n - [FrancisGeek](https://www.kaggle.com/francisgeek)\n - [Frank He](https://www.kaggle.com/isawall317)\n - [Frank Pac](https://www.kaggle.com/frankpac)\n - [Frank](https://www.kaggle.com/fdraeger)\n - [FrankFernandes](https://www.kaggle.com/frankfernandes)\n - [frankie](https://www.kaggle.com/superfrankie)\n - [Franklin Bradfield](https://www.kaggle.com/shellshock1911)\n - [freddie](https://www.kaggle.com/estepona)\n - [Fredrik Jonsson](https://www.kaggle.com/freddejn)\n - [Free Code Camp](https://www.kaggle.com/freecodecamp)\n - [freeCodeCamp](https://www.kaggle.com/free-code-camp)\n - [Freedom House](https://www.kaggle.com/freedomhouse)\n - [French dude](https://www.kaggle.com/frenchdude)\n - [FUNGYueHoi](https://www.kaggle.com/fungyuehoi)\n - [FunnyMango](https://www.kaggle.com/madhurrajn)\n - [FuzzyFrogHunter](https://www.kaggle.com/fuzzyfroghunter)\n - [G1nG0](https://www.kaggle.com/umlsmith390)\n - [Gabriel Forsythe y Korzeniewicz](https://www.kaggle.com/gabfyk)\n - [Gabriel Gutierrez Corral](https://www.kaggle.com/gabrielguc)\n - [Gabriel Joshua Miguel](https://www.kaggle.com/gabbygab)\n - [Gabriel Moreira](https://www.kaggle.com/gspmoreira)\n - [Gabriel Preda](https://www.kaggle.com/gpreda)\n - [gabrielacaesar](https://www.kaggle.com/gabrielacaesar)\n - [GabrielAvellaneda](https://www.kaggle.com/gavellaneda)\n - [Gabriele Angeletti](https://www.kaggle.com/blackecho)\n - [Gabriele Baldassarre](https://www.kaggle.com/gabrio)\n - [gabro](https://www.kaggle.com/nighrtwing)\n - [Gael Kngm](https://www.kaggle.com/gakngm)\n - [Gagan](https://www.kaggle.com/oberoigagan)\n - [GaganBhatia](https://www.kaggle.com/gagandeep16)\n - [GajendraBadwal](https://www.kaggle.com/gajendrabadwal)\n - [ganesh](https://www.kaggle.com/gpandi007)\n - [GaoweiWang](https://www.kaggle.com/peanutmochi)\n - [GarryKevin](https://www.kaggle.com/codedexter)\n - [Gary Ramah](https://www.kaggle.com/garyramah)\n - [Gasimov Aydin](https://www.kaggle.com/aydin1918)\n - [Gaspare](https://www.kaggle.com/gaspare)\n - [Gaurav Arora](https://www.kaggle.com/aroragaura)\n - [Gaurav Sharma](https://www.kaggle.com/gauravsharma74)\n - [GAURAVJAIN](https://www.kaggle.com/gauravjain)\n - [Gautam Doshi](https://www.kaggle.com/gndoshi)\n - [GauthamSenthil](https://www.kaggle.com/overratedgman)\n - [Gavin Cheng](https://www.kaggle.com/winjia)\n - [GavinArmstrong](https://www.kaggle.com/gavinarmstrong)\n - [GAz113](https://www.kaggle.com/gaz113)\n - [geco](https://www.kaggle.com/gecosistema)\n - [GECOdavide](https://www.kaggle.com/gecodavide)\n - [gellowmellow](https://www.kaggle.com/thir13enth)\n - [GeneBurin](https://www.kaggle.com/kiwiphrases)\n - [genexpres](https://www.kaggle.com/genexpres)\n - [Gennadii](https://www.kaggle.com/gennadiiturutin)\n - [GeoffNoble](https://www.kaggle.com/geoffnoble)\n - [GeoNames](https://www.kaggle.com/geonames)\n - [GeoNSoo Kim](https://www.kaggle.com/geonsookim)\n - [George B](https://www.kaggle.com/georgeb1)\n - [GeorgeMcIntire](https://www.kaggle.com/geomack)\n - [Georgii Vyshnia](https://www.kaggle.com/gvyshnya)\n - [georginarose](https://www.kaggle.com/georginarose)\n - [Gerardo Suarez ](https://www.kaggle.com/mcditoos)\n - [GerardoSegura](https://www.kaggle.com/gsegura)\n - [GetTheData](https://www.kaggle.com/getthedata)\n - [Getting_started](https://www.kaggle.com/shivrajp)\n - [Gevault](https://www.kaggle.com/gevault)\n - [Gevorg Aghekyan](https://www.kaggle.com/gevvahraf)\n - [Gfan](https://www.kaggle.com/ggggfan)\n - [Ggzet](https://www.kaggle.com/gagazet)\n - [GIANT: Machine learning for smart environments](https://www.kaggle.com/giantuji)\n - [Gibs](https://www.kaggle.com/notgibs)\n - [gift](https://www.kaggle.com/tohfarabab)\n - [giginim](https://www.kaggle.com/giginim)\n - [giim](https://www.kaggle.com/gimunu)\n - [gilad](https://www.kaggle.com/giladstern)\n - [GilSousa](https://www.kaggle.com/gilsousa)\n - [GilVolpe](https://www.kaggle.com/gilvolpe)\n - [Gin04kg](https://www.kaggle.com/itoeiji)\n - [GiologicX](https://www.kaggle.com/giologicx)\n - [GiorgioRoffo](https://www.kaggle.com/groffo)\n - [Giovanni Gonzalez](https://www.kaggle.com/giovamata)\n - [girish bansal](https://www.kaggle.com/girishbansal)\n - [Girish Murthy](https://www.kaggle.com/gimurthy)\n - [Github](https://www.kaggle.com/github)\n - [Giulia Carra](https://www.kaggle.com/gcarra)\n - [Giuseppe](https://www.kaggle.com/peppuce)\n - [GKHI](https://www.kaggle.com/girishiyer)\n - [GL_Li](https://www.kaggle.com/madaha)\n - [Global Footprint Network](https://www.kaggle.com/footprintnetwork)\n - [GMAdevs](https://www.kaggle.com/gmadevs)\n - [Gnana Prasath](https://www.kaggle.com/gnanaprasath007)\n - [Gnanesh](https://www.kaggle.com/gnanesh)\n - [gnania527](https://www.kaggle.com/greenreddy0)\n - [GodEater](https://www.kaggle.com/abidislam8042)\n - [Gokagglers ](https://www.kaggle.com/loveall)\n - [Gokul Alex](https://www.kaggle.com/gokulbabyalex)\n - [Gokul Alex](https://www.kaggle.com/gokulbalex)\n - [Golden Oak Research Group](https://www.kaggle.com/goldenoakresearch)\n - [GomteshHatgine](https://www.kaggle.com/gomtesh)\n - [Goneee](https://www.kaggle.com/goneee)\n - [Gonzalo Falloux](https://www.kaggle.com/gfalloux)\n - [Google Brain](https://www.kaggle.com/google-brain)\n - [Google Natural Language Understanding Research](https://www.kaggle.com/google-nlu)\n - [Google News Lab](https://www.kaggle.com/GoogleNewsLab)\n - [Googleboy](https://www.kaggle.com/heyanlin)\n - [Gopal ](https://www.kaggle.com/gopaltathe)\n - [Gopal Chettri](https://www.kaggle.com/gopalchettri)\n - [GOPALJAISWAL](https://www.kaggle.com/gopaljaiswal49)\n - [Gopi Vasudevan](https://www.kaggle.com/gopivasudevan)\n - [Gor Khachatryan ](https://www.kaggle.com/gorkhachatryan01)\n - [Gorodec](https://www.kaggle.com/vukw11)\n - [gourabbhattacharyya](https://www.kaggle.com/gourabbhattacharyya)\n - [goutham](https://www.kaggle.com/gouthamr92)\n - [Government of France](https://www.kaggle.com/government-of-france)\n - [GovLab](https://www.kaggle.com/govlab)\n - [GowTham](https://www.kaggle.com/gowtham121)\n - [gpoudel](https://www.kaggle.com/gpoudel)\n - [Graham Daley](https://www.kaggle.com/gdaley)\n - [Grainsan](https://www.kaggle.com/grainsan)\n - [GreatImposter](https://www.kaggle.com/chemcnabb)\n - [greekygeek](https://www.kaggle.com/greekygeek)\n - [greenet09](https://www.kaggle.com/greenet09)\n - [Greg](https://www.kaggle.com/gregnetols)\n - [GregKondla](https://www.kaggle.com/kondla)\n - [Gregory](https://www.kaggle.com/gtruden)\n - [GregorySmith](https://www.kaggle.com/gregorut)\n - [gregv](https://www.kaggle.com/gregvial)\n - [Greycop](https://www.kaggle.com/harshith2794)\n - [GrishaSizov](https://www.kaggle.com/grishasizov)\n - [group09](https://www.kaggle.com/group09)\n - [GroupLens](https://www.kaggle.com/grouplens)\n - [GrubenM](https://www.kaggle.com/grubenm)\n - [Gudang ](https://www.kaggle.com/gudangpaper)\n - [guik](https://www.kaggle.com/guik39)\n - [Guilherme Diaz-B\xc3\x83\xc2\xa9rrio](https://www.kaggle.com/gdberrio)\n - [Guilherme Diego](https://www.kaggle.com/guidiego)\n - [Guilherme Folego](https://www.kaggle.com/gfolego)\n - [Guillaume Vinet](https://www.kaggle.com/guillaumevinet)\n - [GuillaumeTouzin](https://www.kaggle.com/gtouzin)\n - [Gummula Srikanth](https://www.kaggle.com/gummulasrikanth)\n - [Gun Violence Archive](https://www.kaggle.com/gunviolencearchive)\n - [GunheePark](https://www.kaggle.com/gunhee)\n - [gunner38](https://www.kaggle.com/gunner38)\n - [Gurpreet Singh](https://www.kaggle.com/gpsingh12)\n - [GurpreetSingh](https://www.kaggle.com/singh0)\n - [Gus Segura](https://www.kaggle.com/kyanyoga)\n - [Gus](https://www.kaggle.com/alexey789)\n - [Gustavo Bonesso](https://www.kaggle.com/gbonesso)\n - [Gustavo Felhberg](https://www.kaggle.com/gfelhber)\n - [Gustavo Palacios](https://www.kaggle.com/gpalacios)\n - [Gustavo Torres](https://www.kaggle.com/gustavoatt)\n - [GustavoFelhberg](https://www.kaggle.com/gusfelhberg)\n - [gutsyrobot](https://www.kaggle.com/gutsyrobot)\n - [Guy T.](https://www.kaggle.com/guizer)\n - [Gyan](https://www.kaggle.com/gyan7611)\n - [GyanendraMishra](https://www.kaggle.com/gyani95)\n - [H1kkiGakki](https://www.kaggle.com/wochidadonggua)\n - [H3MANT](https://www.kaggle.com/hemant1garhwal)\n - [Hacker News](https://www.kaggle.com/hacker-news)\n - [hacker1](https://www.kaggle.com/hacker1)\n - [haemin Jeong](https://www.kaggle.com/illgorhek)\n - [haho](https://www.kaggle.com/facetoface)\n - [Haibo](https://www.kaggle.com/sealyu)\n - [Haitam Abdoullah](https://www.kaggle.com/haitamdata)\n - [Haitao Chen](https://www.kaggle.com/haitch)\n - [Hakan Eren](https://www.kaggle.com/hakaneren)\n - [Hakan Toguc](https://www.kaggle.com/hakantoguc)\n - [Hakeem Frank](https://www.kaggle.com/hakeemtfrank)\n - [Hakky](https://www.kaggle.com/sthakky)\n - [hakmesyo](https://www.kaggle.com/hakmesyo)\n - [Hakob Sukiasyan](https://www.kaggle.com/sukiasyan)\n - [HamaChi](https://www.kaggle.com/hamachi)\n - [Hamad42](https://www.kaggle.com/hamad42)\n - [Hammad A. Usmani](https://www.kaggle.com/saturday)\n - [hamza el karoui](https://www.kaggle.com/helkaroui)\n - [Hamza Zafar](https://www.kaggle.com/hamzafar)\n - [Hani Ramadhan](https://www.kaggle.com/haniramadhan)\n - [Hanna](https://www.kaggle.com/abiboka)\n - [Hansel D\'Souza](https://www.kaggle.com/hdza1991)\n - [HansMaulwurf](https://www.kaggle.com/maulwurf1)\n - [Hao](https://www.kaggle.com/markcrass)\n - [Haohan Wang](https://www.kaggle.com/wanghaohan)\n - [HaoyuZhao](https://www.kaggle.com/bigtreezhao)\n - [HaozhengNi](https://www.kaggle.com/haozheng0512)\n - [Hard_Core](https://www.kaggle.com/samwhitehill)\n - [Hari Krishna K](https://www.kaggle.com/khari14)\n - [Hari prasath](https://www.kaggle.com/savitar)\n - [haris21gr](https://www.kaggle.com/haris21gr)\n - [harlfoxem](https://www.kaggle.com/harlfoxem)\n - [HarmanpreetSingh](https://www.kaggle.com/harmanpreet93)\n - [Harold Almon](https://www.kaggle.com/haroldalmon)\n - [Haroon Ahmed](https://www.kaggle.com/hahmed747)\n - [HarpieCrispi](https://www.kaggle.com/harpiechoise)\n - [Harry Peter](https://www.kaggle.com/hritc2)\n - [Harry](https://www.kaggle.com/gemzhx)\n - [Harry](https://www.kaggle.com/harry007)\n - [HarryQuake](https://www.kaggle.com/harryzhenchen)\n - [HarryTan](https://www.kaggle.com/harry688tan96)\n - [Harsh B. Gupta](https://www.kaggle.com/lucifer007h)\n - [Harsh Mehta](https://www.kaggle.com/harshmehta6711)\n - [Harsha](https://www.kaggle.com/harshaneigapula)\n - [HarshaVardhan](https://www.kaggle.com/harsha547)\n - [Harshit Joshi](https://www.kaggle.com/hj5992)\n - [Harshit Sinha](https://www.kaggle.com/hsinha53)\n - [HARSHITAGUPTA](https://www.kaggle.com/harshitagpt)\n - [HarshitMehta](https://www.kaggle.com/harshit92)\n - [HarshitSrivastava](https://www.kaggle.com/harshit9211)\n - [Harshoday](https://www.kaggle.com/harshoday)\n - [HarshPandya](https://www.kaggle.com/hvp4259)\n - [HarshVardhan](https://www.kaggle.com/harshvardhan0709)\n - [Harvard University](https://www.kaggle.com/harvard-university)\n - [hashus](https://www.kaggle.com/hhnigdeli)\n - [Hasil Sharma](https://www.kaggle.com/hasilsharma)\n - [HassanAftabMughal](https://www.kaggle.com/hassanaftab)\n - [hassankhanyusufzai](https://www.kaggle.com/hassankhanyusufzai)\n - [hatem](https://www.kaggle.com/hatemben)\n - [Hax S](https://www.kaggle.com/agnt47x)\n - [Hazrat Ali](https://www.kaggle.com/hazrat)\n - [HDKIM](https://www.kaggle.com/leadbest)\n - [heatingSmoke](https://www.kaggle.com/heatingsmoke)\n - [hectopascal](https://www.kaggle.com/hectopascal)\n - [Hedi Ho](https://www.kaggle.com/sivanhedi9ty)\n - [Hefen Zhou](https://www.kaggle.com/hofen168)\n - [heidogsdf](https://www.kaggle.com/heidot)\n - [Heihei](https://www.kaggle.com/tamatoa)\n - [Heiko](https://www.kaggle.com/marc000)\n - [Heitor Tomaz](https://www.kaggle.com/heitortomaz)\n - [hellenandreea](https://www.kaggle.com/hellenandreea)\n - [Hello ML World ](https://www.kaggle.com/helloworldml)\n - [Hellrider](https://www.kaggle.com/hellrider)\n - [Hemant Sain](https://www.kaggle.com/moose9200)\n - [Hemanth k](https://www.kaggle.com/hemanth171)\n - [Hemanth Kumar Veeranki](https://www.kaggle.com/iamzero1)\n - [hemanthgowda](https://www.kaggle.com/hemanth123)\n - [Hena](https://www.kaggle.com/henajose)\n - [Hendrik \xc3\x85\xc2\xa0uvalov](https://www.kaggle.com/hendriksuvalov)\n - [Hendrik Hilleckes](https://www.kaggle.com/hhllcks)\n - [HenrikHeggland](https://www.kaggle.com/henrikheggland)\n - [Henry](https://www.kaggle.com/hhenry)\n - [HenryWConklin](https://www.kaggle.com/henrywconklin)\n - [Heraldo Reis](https://www.kaggle.com/heraldoreis)\n - [Herimanitra](https://www.kaggle.com/herimanitra)\n - [Hervind](https://www.kaggle.com/hervind)\n - [Heuristic](https://www.kaggle.com/heuristicsoft)\n - [heymeredith](https://www.kaggle.com/meredithslota)\n - [hhl028](https://www.kaggle.com/hhl028)\n - [hidark](https://www.kaggle.com/hidark)\n - [Hidehisa Arai](https://www.kaggle.com/hidehisaarai1213)\n - [hieuvt](https://www.kaggle.com/hieuvt0401)\n - [Hill YU](https://www.kaggle.com/hillyu)\n - [Hillary Dawkins](https://www.kaggle.com/hdawkins)\n - [Himanshu Chaudhary](https://www.kaggle.com/him4318)\n - [Himanshu Garg](https://www.kaggle.com/himansiitian)\n - [Himanshu Shekhar](https://www.kaggle.com/himanshushekhar8)\n - [himanshu0113](https://www.kaggle.com/himanshu0113)\n - [HimanshuRai](https://www.kaggle.com/himanshu14)\n - [Hioki Ryuji ](https://www.kaggle.com/lazon282)\n - [Hiro Ari](https://www.kaggle.com/hiro0107)\n - [HiroyukiSHINODA](https://www.kaggle.com/mirandora)\n - [HIT_CS_LI BO](https://www.kaggle.com/luodian)\n - [hitcs_1150310416](https://www.kaggle.com/tom12254)\n - [hitcs_jiangzhenfei](https://www.kaggle.com/zhenfeij)\n - [hitcs_yuhong_zhong](https://www.kaggle.com/yuhongzhong)\n - [Hitesh Desai](https://www.kaggle.com/hpdesai07)\n - [hlnaima](https://www.kaggle.com/hnaima)\n - [HM Land Registry](https://www.kaggle.com/hm-land-registry)\n - [Homo Deus](https://www.kaggle.com/gnarkill2000)\n - [Hong](https://www.kaggle.com/ekgp8595)\n - [Honggu](https://www.kaggle.com/honggulin)\n - [honlamlai](https://www.kaggle.com/lamlam009)\n - [Hossein Banki Koshki](https://www.kaggle.com/hobako1993)\n - [How Toai](https://www.kaggle.com/howtoai)\n - [Howard Smith](https://www.kaggle.com/hasmith2017)\n - [hrfm](https://www.kaggle.com/hrfm318274)\n - [Hssan Driss](https://www.kaggle.com/hdriss)\n - [HTan](https://www.kaggle.com/magicii0716)\n - [Hu Yao](https://www.kaggle.com/tshuyao)\n - [huang xuan](https://www.kaggle.com/hxyhitsz)\n - [Huang, Peng-Hsuan](https://www.kaggle.com/randyrose2017)\n - [Huangkai Yu\xc3\xa3\xc6\x92\xc2\xbe(\xc3\x82\xc2\xb0\xc3\x90\xc2\xb4\xc3\x82\xc2\xb0)\xc3\xa3\xc6\x92\xc5\xbd](https://www.kaggle.com/huyu0153)\n - [HuayuanTu](https://www.kaggle.com/tuhuayuan)\n - [Hubert Wassner](https://www.kaggle.com/hwassner)\n - [Hugh](https://www.kaggle.com/hughqi)\n - [Hugo Mathien](https://www.kaggle.com/hugomathien)\n - [HugoDarwood](https://www.kaggle.com/hugodarwood)\n - [Hugues Talbot (ESIEE)](https://www.kaggle.com/talbothugues)\n - [Huijun Zhao](https://www.kaggle.com/huijunzhao)\n - [huimin](https://www.kaggle.com/hanhuimin)\n - [Huiyu YE](https://www.kaggle.com/rx00ye)\n - [Human Computation](https://www.kaggle.com/humancomp)\n - [Humberto Brand\xc3\x83\xc2\xa3o](https://www.kaggle.com/brandao)\n - [HungDo](https://www.kaggle.com/hungdo1291)\n - [Hunter Anderson](https://www.kaggle.com/huntsdesk)\n - [Hunter McGushion](https://www.kaggle.com/huntermcgushion)\n - [Hunterr](https://www.kaggle.com/hunterrnoobatpro)\n - [Husein Zolkepli](https://www.kaggle.com/huseinzol05)\n - [HUSEYiNKiliC](https://www.kaggle.com/huseyinkilic)\n - [Husnain wajid](https://www.kaggle.com/great22)\n - [Hussien El-Sawy](https://www.kaggle.com/hussienelsawy)\n - [HustTiger](https://www.kaggle.com/husttiger)\n - [HuyNguyen](https://www.kaggle.com/baohuy)\n - [hwhy](https://www.kaggle.com/hanyan)\n - [hyuan](https://www.kaggle.com/haoyuan80s)\n - [Hyun Ook Ryu](https://www.kaggle.com/ryutek)\n - [HYUNJUNGBYEON](https://www.kaggle.com/hjtk09)\n - [I,Coder](https://www.kaggle.com/ash316)\n - [i2i2i2](https://www.kaggle.com/i2i2i2)\n - [IagoD\xc3\x83\xc2\xadaz](https://www.kaggle.com/iagodiaz)\n - [Ian Chu Te](https://www.kaggle.com/ianchute)\n - [Ian Nanez](https://www.kaggle.com/greenteamaster)\n - [ianmobbs](https://www.kaggle.com/ianmobbs)\n - [Iary Joseph](https://www.kaggle.com/iaryjoseph)\n - [IbrahimAljarah](https://www.kaggle.com/aljarah)\n - [ibrahimkhaleelullah](https://www.kaggle.com/ibrahimuta)\n - [ibrarhussain](https://www.kaggle.com/ibrar1234)\n - [icebear](https://www.kaggle.com/nminhptnk)\n - [idiosyncraticee](https://www.kaggle.com/idiosyncraticee)\n - [Iditarod Trail Committee](https://www.kaggle.com/iditarod)\n - [Idris Kuti](https://www.kaggle.com/idriskuti)\n - [Ifechide Monyei](https://www.kaggle.com/mimg22)\n - [IfeoluwaAkande](https://www.kaggle.com/samuelhify)\n - [Ignacio Chavarria](https://www.kaggle.com/ignacioch)\n - [Igor Alexeev](https://www.kaggle.com/algor1)\n - [Igor Lemes](https://www.kaggle.com/igorlemes)\n - [Igor Nikolskiy](https://www.kaggle.com/yesbutwhatdoesitmean)\n - [Igun](https://www.kaggle.com/igunawan)\n - [IHME](https://www.kaggle.com/IHME)\n - [Ilenia](https://www.kaggle.com/ileniar)\n - [ilias sekkaf](https://www.kaggle.com/iliassekkaf)\n - [IlknurIcke](https://www.kaggle.com/ilknuricke)\n - [Ilko Masaldzhiyski](https://www.kaggle.com/masaldzhiyski)\n - [Imad Khan](https://www.kaggle.com/imadmkhan)\n - [Imam Digmi](https://www.kaggle.com/imamdigmi)\n - [Imran Arif](https://www.kaggle.com/imranarif)\n - [In\xc3\x83\xc2\xa8s Potier](https://www.kaggle.com/inespotier)\n - [inaba](https://www.kaggle.com/minaba)\n - [Indicium](https://www.kaggle.com/indicium)\n - [InfiniteWing](https://www.kaggle.com/infinitewing)\n - [INFINITYLABS](https://www.kaggle.com/INFINITYLABS)\n - [inooooooovation](https://www.kaggle.com/emotionevil)\n - [inquisitor](https://www.kaggle.com/torkehmaidah)\n - [Institute for Computing Education at Georgia Tech](https://www.kaggle.com/iceatgt)\n - [Institute for Public Policy and Social Research](https://www.kaggle.com/ippsr)\n - [Institute of Museum and Library Services](https://www.kaggle.com/imls)\n - [Interaction Engineering Laboratory](https://www.kaggle.com/inteng)\n - [interface](https://www.kaggle.com/interface)\n - [Internal Revenue Service](https://www.kaggle.com/irs)\n - [Internet Association](https://www.kaggle.com/deleted=dkaing)\n - [Internet Association](https://www.kaggle.com/InternetAssociation)\n - [intest](https://www.kaggle.com/intest)\n - [InVinoVeritas](https://www.kaggle.com/reneverbrugge)\n - [\xc3\x8e\xc5\x93\xc3\x8e\xc2\xb1\xc3\x8f\xc2\x81\xc3\x8e\xc2\xb9\xc3\x8e\xc2\xbf\xc3\x8f\xe2\x80\x9a \xc3\x8e\xc5\x93\xc3\x8e\xc2\xb9\xc3\x8f\xe2\x80\xa1\xc3\x8e\xc2\xb1\xc3\x8e\xc2\xb7\xc3\x8e\xc2\xbb\xc3\x8e\xc2\xb9\xc3\x8e\xc2\xb4\xc3\x8e\xc2\xb7\xc3\x8f\xe2\x80\x9a KazAnova](https://www.kaggle.com/kazanova)\n - [IpLee](https://www.kaggle.com/petein)\n - [Irfan](https://www.kaggle.com/irfanazeem)\n - [IrfanWahyudin](https://www.kaggle.com/irfanwahyudin)\n - [Irina Kalatskaya](https://www.kaggle.com/ikalats)\n - [IrinaAchkasova](https://www.kaggle.com/irinaachkasova)\n - [Irio Musskopf](https://www.kaggle.com/iriomk)\n - [Iryna](https://www.kaggle.com/papshoika)\n - [Isaac A.](https://www.kaggle.com/zico2188)\n - [Isaac Blinder](https://www.kaggle.com/isaacblinder)\n - [Isaac34](https://www.kaggle.com/isaac34mi)\n - [IsaacSim](https://www.kaggle.com/gilgarad)\n - [Isabella Plonk](https://www.kaggle.com/irplonk)\n - [ishaan](https://www.kaggle.com/ishaanv)\n - [Ishank Saxena](https://www.kaggle.com/theishank)\n - [ishigen](https://www.kaggle.com/ishimotoyoshitake)\n - [ishiryish](https://www.kaggle.com/ishiryish)\n - [Ishnoor](https://www.kaggle.com/ishnoor)\n - [isildaaa](https://www.kaggle.com/kokukk)\n - [ismail turkmen](https://www.kaggle.com/ihturkmen)\n - [Itamar Mushkin](https://www.kaggle.com/itamarmushkin)\n - [itest](https://www.kaggle.com/itest123)\n - [Itzik Yohanan](https://www.kaggle.com/yohanan)\n - [Ivan Jakovcevic](https://www.kaggle.com/ivanjakovcevic)\n - [Ivan Mazharov](https://www.kaggle.com/ivanmaz)\n - [Ivan Tsy](https://www.kaggle.com/boltozakrut)\n - [Ivan](https://www.kaggle.com/demesgal)\n - [ivanloginov](https://www.kaggle.com/ivanloginov)\n - [Ivo Penkov](https://www.kaggle.com/ipenkov)\n - [Iwase Yuya](https://www.kaggle.com/iwayu0521)\n - [Izabella](https://www.kaggle.com/malina015)\n - [Izzie Toren](https://www.kaggle.com/ytoren)\n - [izzuddin](https://www.kaggle.com/izzuddin8803)\n - [Izzy](https://www.kaggle.com/izzykayu)\n - [J from the Riverside](https://www.kaggle.com/jfromtheriverside)\n - [J.DavidCorrea](https://www.kaggle.com/jdavidcorrea)\n - [J\xc3\x83\xc2\xb6rg Eitner](https://www.kaggle.com/laudanum)\n - [J\xc3\x83\xc2\xb6rgen Sinka](https://www.kaggle.com/sinxtus)\n - [Jaak Ungro](https://www.kaggle.com/jaakungro)\n - [Jacco Jurg](https://www.kaggle.com/jaccojurg)\n - [Jack Blarr](https://www.kaggle.com/jbb5614)\n - [Jack Cook](https://www.kaggle.com/jackcook)\n - [Jack Cosgrove](https://www.kaggle.com/jackcosgrove)\n - [Jack Ho](https://www.kaggle.com/sjaytw)\n - [Jack Miller](https://www.kaggle.com/jmiller87)\n - [Jack Sunny](https://www.kaggle.com/jackchuisunnyfung)\n - [Jack](https://www.kaggle.com/jackchui)\n - [Jack](https://www.kaggle.com/jackml)\n - [Jack](https://www.kaggle.com/passwordqk)\n - [JackLiu](https://www.kaggle.com/hong1970)\n - [Jackson Harper](https://www.kaggle.com/jacksonharper)\n - [Jackson Raja](https://www.kaggle.com/jacksonranjith)\n - [Jacky Wong](https://www.kaggle.com/jwwork1810)\n - [JackyD](https://www.kaggle.com/soarjacky)\n - [Jaclyn A](https://www.kaggle.com/andersonje0113)\n - [Jaco de Groot](https://www.kaggle.com/jacodegroot)\n - [Jacob Boysen](https://www.kaggle.com/jboysen)\n - [JacobGoozner](https://www.kaggle.com/jacobgoozner)\n - [jaehyeon yu](https://www.kaggle.com/wogus934)\n - [jaewonk](https://www.kaggle.com/jaewonk)\n - [Jaffer Syed](https://www.kaggle.com/sydjaffy)\n - [Jagan](https://www.kaggle.com/jagangupta)\n - [jagannath neupane](https://www.kaggle.com/jneupane12)\n - [Jaime Valero](https://www.kaggle.com/jaimevalero)\n - [Jaish K](https://www.kaggle.com/jaishofficial)\n - [Jake Gnieser](https://www.kaggle.com/jgnieser)\n - [Jake Rohrer](https://www.kaggle.com/jakerohrer)\n - [Jake Toffler](https://www.kaggle.com/jtoffler)\n - [Jake Waitze](https://www.kaggle.com/jwaitze)\n - [Jakub Pubrat](https://www.kaggle.com/purbar)\n - [Jalaz Kumar](https://www.kaggle.com/jaykay12)\n - [james ahn](https://www.kaggle.com/jahn105)\n - [James Clavin](https://www.kaggle.com/clavin)\n - [James Condon](https://www.kaggle.com/jamesjjcondon)\n - [James D.](https://www.kaggle.com/chrundle)\n - [James Littiebrant](https://www.kaggle.com/speckledpingu)\n - [James Mathews](https://www.kaggle.com/jamesmathews)\n - [James Tollefson](https://www.kaggle.com/jamestollefson)\n - [James](https://www.kaggle.com/jameszhou92)\n - [jamesbasker](https://www.kaggle.com/jamesbasker)\n - [JamesG](https://www.kaggle.com/jgregs)\n - [JamesS](https://www.kaggle.com/flenderson)\n - [jamesyang96](https://www.kaggle.com/jamesyang96)\n - [JamesYuan](https://www.kaggle.com/jyuan1986)\n - [Jan Bodnar](https://www.kaggle.com/jbodnar)\n - [Jan Charles Maghirang Adona](https://www.kaggle.com/septa97)\n - [Jan Christian Blaise Cruz](https://www.kaggle.com/jcblaise)\n - [Jan Nordin](https://www.kaggle.com/northon)\n - [jana](https://www.kaggle.com/jana36)\n - [Janani Damodaran Gantal](https://www.kaggle.com/gantal)\n - [Janek](https://www.kaggle.com/jasiekl)\n - [janice](https://www.kaggle.com/janice0717)\n - [Janzen Liu](https://www.kaggle.com/janzenliu)\n - [Jason A. Hatton](https://www.kaggle.com/jacksapper)\n - [Jason A](https://www.kaggle.com/jayfang)\n - [Jason Benner](https://www.kaggle.com/jasonbenner)\n - [Jason Liu](https://www.kaggle.com/jiashenliu)\n - [Jason McNeill](https://www.kaggle.com/txtrouble)\n - [Jason Nguyen](https://www.kaggle.com/flyingwombat)\n - [Jason Schenck](https://www.kaggle.com/jsche4)\n - [Jason.F_CN](https://www.kaggle.com/sharpsword)\n - [Jason](https://www.kaggle.com/jmg007007)\n - [Jason](https://www.kaggle.com/sanjaydeo96)\n - [JasonHuang](https://www.kaggle.com/jwlzdh1)\n - [jasonzhang](https://www.kaggle.com/djzhangbi)\n - [jatin raina](https://www.kaggle.com/jatinraina)\n - [Jatin Shah](https://www.kaggle.com/jatinshah)\n - [Jaturong Kongmanee](https://www.kaggle.com/dillsunnyb11)\n - [javascript:alert(8007);](https://www.kaggle.com/asiftesting)\n - [Javier Villanueva-Valle](https://www.kaggle.com/sivlemx)\n - [Javier](https://www.kaggle.com/javierfuenca)\n - [Jay I](https://www.kaggle.com/jayram)\n - [Jay Kulshreshtha](https://www.kaggle.com/jsk2017)\n - [Jay Ravaliya](https://www.kaggle.com/jayrav13)\n - [jay333](https://www.kaggle.com/jkjay333)\n - [Jaya Gupta](https://www.kaggle.com/jayagupta678)\n - [Jayanth Yetukuri](https://www.kaggle.com/jayanthyetukuri)\n - [Jayanth](https://www.kaggle.com/jayanthkaggle)\n - [Jayavardhan Reddy](https://www.kaggle.com/jayavardhanr)\n - [jayjay](https://www.kaggle.com/jayjay75)\n - [JayLee](https://www.kaggle.com/jeffy0637)\n - [JBD ](https://www.kaggle.com/jdirmeitis)\n - [jbfields](https://www.kaggle.com/jbfields)\n - [JD Torres](https://www.kaggle.com/jdtorres10)\n - [Jean Pierre Rukundo](https://www.kaggle.com/jprukundo)\n - [Jean-MarcBouvier](https://www.kaggle.com/jbouv27)\n - [Jean-Michel D.](https://www.kaggle.com/jeanmidev)\n - [Jean-NicholasHould](https://www.kaggle.com/nickhould)\n - [Jean-Phillipe](https://www.kaggle.com/jonavery)\n - [Jeanpat](https://www.kaggle.com/jeanpat)\n - [JeevanNagaraj](https://www.kaggle.com/jeevannagaraj)\n - [Jeff Kao](https://www.kaggle.com/jeffkao)\n - [Jeff Ussing](https://www.kaggle.com/jeffussing)\n - [Jeff](https://www.kaggle.com/gobert)\n - [JefferyT](https://www.kaggle.com/jefferyt)\n - [JeffTennis](https://www.kaggle.com/jtennis)\n - [Jegs](https://www.kaggle.com/simjeg)\n - [JegyeongKim](https://www.kaggle.com/jegyeongkim)\n - [Jekaterina Kokatjuhha](https://www.kaggle.com/jkokatjuhha)\n - [jekwon](https://www.kaggle.com/jekwon)\n - [Jemilu Mohammed](https://www.kaggle.com/jangot)\n - [Jenkins Ruban](https://www.kaggle.com/jenkinsruban)\n - [Jens Laufer](https://www.kaggle.com/jenslaufer)\n - [jenvo](https://www.kaggle.com/themonster2015)\n - [Jeongmin Ha](https://www.kaggle.com/daneul94)\n - [Jerad Rose](https://www.kaggle.com/jeradrose)\n - [Jeremy Seibert](https://www.kaggle.com/jaseibert)\n - [Jeremy Wang](https://www.kaggle.com/jeremy4555)\n - [jeremymiles](https://www.kaggle.com/jeremymiles)\n - [JeremyWickman](https://www.kaggle.com/jeremywickman)\n - [Jerrin Joe Varghese](https://www.kaggle.com/jerrinv)\n - [jerryg](https://www.kaggle.com/gaojianj96)\n - [JerryWang](https://www.kaggle.com/miningjerry)\n - [Jesse Montgomery](https://www.kaggle.com/jlmontie)\n - [Jessica Yung](https://www.kaggle.com/jessicayung)\n - [Jessie-Raye Bauer](https://www.kaggle.com/jrbauer)\n - [Jesus Jara L\xc3\x83\xc2\xb3pez](https://www.kaggle.com/jesusjara)\n - [Jesus Santander](https://www.kaggle.com/rymnikski)\n - [Jguerreiro](https://www.kaggle.com/jguerreiro)\n - [JhonatanZubieta](https://www.kaggle.com/yosuer)\n - [JiachuanDeng](https://www.kaggle.com/jiachuandeng)\n - [JiaJane](https://www.kaggle.com/s663962004)\n - [Jiaming Huang](https://www.kaggle.com/hjmjerry)\n - [Jian W](https://www.kaggle.com/jhw6976)\n - [Jian Zhang](https://www.kaggle.com/jianzhang1)\n - [Jiang Yu](https://www.kaggle.com/nguwijy)\n - [jiangzuo](https://www.kaggle.com/jiangzuo)\n - [JiansheFeng](https://www.kaggle.com/jianshefeng)\n - [Jibsgrl](https://www.kaggle.com/jibsgrl)\n - [Jigarkumar Patel](https://www.kaggle.com/jigarpatel)\n - [Jihane HAMMOUT](https://www.kaggle.com/jhammout)\n - [Jihye Sofia Seo](https://www.kaggle.com/jihyeseo)\n - [Jiji](https://www.kaggle.com/daifarij)\n - [Jill_M](https://www.kaggle.com/jillm5)\n - [JimmyMarguerite](https://www.kaggle.com/djim02)\n - [Jin Liu](https://www.kaggle.com/jinliu)\n - [Jin-HwaChiu](https://www.kaggle.com/jhchiuh)\n - [Jindong Wang](https://www.kaggle.com/jindongwang92)\n - [Jindra Lacko](https://www.kaggle.com/jlacko)\n - [jinesh John](https://www.kaggle.com/jinesh777)\n - [Jing Zhang](https://www.kaggle.com/jingzbu)\n - [Jing](https://www.kaggle.com/jinghuang)\n - [JingdaZhou](https://www.kaggle.com/zhou854)\n - [jingjuewang](https://www.kaggle.com/juejuewang)\n - [jingli](https://www.kaggle.com/jacklizhi)\n - [jingwang](https://www.kaggle.com/evelynwang16)\n - [Jinner](https://www.kaggle.com/what0919)\n - [Jinsoo Yeo](https://www.kaggle.com/jinsooyeo)\n - [Jinze He](https://www.kaggle.com/jinze1234599)\n - [Jiri Roznovjak](https://www.kaggle.com/jiriroz)\n - [Jirka Vrany](https://www.kaggle.com/jirivrany)\n - [Jitendra Rajpurohit](https://www.kaggle.com/jitendra1998)\n - [JitendraKumarBansal](https://www.kaggle.com/jbansal)\n - [jiuzhang](https://www.kaggle.com/jiuzhang)\n - [jjjooo1](https://www.kaggle.com/jjjooo1)\n - [JLucas](https://www.kaggle.com/jlucas)\n - [jmataya](https://www.kaggle.com/jmataya)\n - [JO-Team](https://www.kaggle.com/melissaangel)\n - [Jo\xc3\x83\xc2\xa3o Pedro Peinado](https://www.kaggle.com/joaopmpeinado)\n - [Joao Januario](https://www.kaggle.com/joaojanuario)\n - [Joao Pedro Evangelista](https://www.kaggle.com/joaoevangelista)\n - [JobsPikr](https://www.kaggle.com/JobsPikrHQ)\n - [Joe Kim](https://www.kaggle.com/joewkim)\n - [Joe Philleo](https://www.kaggle.com/joephilleo)\n - [Joe Ramir](https://www.kaggle.com/jraramirez)\n - [Joe Young](https://www.kaggle.com/jsphyg)\n - [joejoe](https://www.kaggle.com/joejoe2)\n - [Joel Jacobsen](https://www.kaggle.com/jej13b)\n - [Joel Lee](https://www.kaggle.com/jzerox2)\n - [Joel Wilson](https://www.kaggle.com/joelwilson)\n - [joeland209](https://www.kaggle.com/joeland209)\n - [Joerg Simon Wicker](https://www.kaggle.com/jswicker)\n - [joeymeyer](https://www.kaggle.com/joeymeyer)\n - [Joffles](https://www.kaggle.com/kembles5)\n - [Johannes Plambeck](https://www.kaggle.com/jplambeck)\n - [JohannesBuchner](https://www.kaggle.com/jbuchner)\n - [JohanneslaPoutre](https://www.kaggle.com/jlapoutre)\n - [John Bourassa](https://www.kaggle.com/johink)\n - [John Doe](https://www.kaggle.com/gwhittington)\n - [John Doe](https://www.kaggle.com/heyushin)\n - [John Doe](https://www.kaggle.com/mimlmmj01ky8aka4)\n - [john doe](https://www.kaggle.com/z3r0s3c0)\n - [john joe](https://www.kaggle.com/missedsss)\n - [John Jones](https://www.kaggle.com/jajones1097)\n - [John Lin](https://www.kaggle.com/ironcrow)\n - [John Mark](https://www.kaggle.com/juandimarq)\n - [John Olafenwa](https://www.kaggle.com/johnolafenwa)\n - [John Ostrowski](https://www.kaggle.com/ostrowski)\n - [John Ruth](https://www.kaggle.com/johnruth)\n - [John Sumerel](https://www.kaggle.com/johnluke999)\n - [John Traavis](https://www.kaggle.com/mvsk93)\n - [John Wu](https://www.kaggle.com/leapoahead)\n - [john](https://www.kaggle.com/devilvrs)\n - [John](https://www.kaggle.com/qeyzn2143)\n - [John](https://www.kaggle.com/yszhong)\n - [john2](https://www.kaggle.com/z3r0s3c)\n - [JohnCurcio](https://www.kaggle.com/jcurcio)\n - [Johnd](https://www.kaggle.com/samuel86)\n - [johndebugger](https://www.kaggle.com/johnzyh)\n - [JohnHeyrich](https://www.kaggle.com/johnney12)\n - [JohnJayChou&MichelleZhuang](https://www.kaggle.com/John-Michelle)\n - [JohnnyHa](https://www.kaggle.com/johnnyjai)\n - [JohnWorne](https://www.kaggle.com/johnworne)\n - [JohnX](https://www.kaggle.com/kennethjohn)\n - [jolhe006](https://www.kaggle.com/jolhe006)\n - [jomendes](https://www.kaggle.com/jomendes)\n - [Jon B](https://www.kaggle.com/derpferd)\n - [Jon Hong](https://www.kaggle.com/jonmhong)\n - [jon.bill](https://www.kaggle.com/iwilldoit)\n - [Jonah Mary17](https://www.kaggle.com/jonahmary17)\n - [jonahelisio](https://www.kaggle.com/jonahelisio)\n - [Jonatan Cisneros](https://www.kaggle.com/jonatancr)\n - [Jonathan](https://www.kaggle.com/jonathankeith)\n - [Jonathan](https://www.kaggle.com/jonomendelson)\n - [JonathanPhoon](https://www.kaggle.com/jphoon)\n - [Jones](https://www.kaggle.com/marshald)\n - [Jonh Doe](https://www.kaggle.com/msusername)\n - [JoniHoppen](https://www.kaggle.com/joniarroba)\n - [JoostLubach](https://www.kaggle.com/joostlubach)\n - [Jordan Goblet](https://www.kaggle.com/jordangoblet)\n - [Jordan Meta](https://www.kaggle.com/jordan26)\n - [Jordan Tremoureux](https://www.kaggle.com/jtremoureux)\n - [JorgeZazueta](https://www.kaggle.com/zazueta)\n - [Jos\xc3\x84\xe2\x80\x94Andr\xc3\x84\xe2\x80\x94sAlvarezCabrera](https://www.kaggle.com/josealvarez97)\n - [Jos\xc3\x83\xc2\xa9 Vicente](https://www.kaggle.com/pepe93)\n - [Jos\xc3\x83\xc2\xa9Prado](https://www.kaggle.com/xpecttrum)\n - [Jose Berengueres](https://www.kaggle.com/harriken)\n - [Jose Fco Morales](https://www.kaggle.com/jos3fc0)\n - [Jose Lery Nunes](https://www.kaggle.com/lerynunes)\n - [Jose Luis Juarez Ruelas](https://www.kaggle.com/imajor)\n - [Jose Manuel Vera](https://www.kaggle.com/jomavera)\n - [Jose Toro](https://www.kaggle.com/soulstuff)\n - [jose](https://www.kaggle.com/josemayorga)\n - [Josep A.](https://www.kaggle.com/josepandreu)\n - [Joseph Leichter](https://www.kaggle.com/joeleichter)\n - [Joseph](https://www.kaggle.com/josephshieh)\n - [JosephBae](https://www.kaggle.com/joebae)\n - [Josh Haimson](https://www.kaggle.com/joshhaimson)\n - [Josh Wheeler](https://www.kaggle.com/slaffterphish)\n - [josh woulfe](https://www.kaggle.com/woulfe64)\n - [josh777](https://www.kaggle.com/josh777)\n - [joshkyh](https://www.kaggle.com/joshkyh)\n - [JoshMcKenney](https://www.kaggle.com/jmckenney1)\n - [Joshua Schnessl](https://www.kaggle.com/jschnessl)\n - [joshuaherman](https://www.kaggle.com/aconsapart)\n - [JosS](https://www.kaggle.com/josdatalake)\n - [jossssss](https://www.kaggle.com/joswx21)\n - [JPSS](https://www.kaggle.com/jatindersehdev)\n - [jr91](https://www.kaggle.com/jacobrichards91)\n - [jruots](https://www.kaggle.com/jruots)\n - [jruvika](https://www.kaggle.com/jruvika)\n - [jrvalentin](https://www.kaggle.com/jrvalentin)\n - [jscharbach](https://www.kaggle.com/jscharbach)\n - [Juan Corporan](https://www.kaggle.com/siriuscorp)\n - [Juan R](https://www.kaggle.com/merkabahnk)\n - [JUAN SOLER-COMPANY](https://www.kaggle.com/joansolcom)\n - [JuanRodriguez](https://www.kaggle.com/juanroma)\n - [Juanu](https://www.kaggle.com/juanumusic)\n - [jujuuu](https://www.kaggle.com/jujuuu)\n - [Julian Christov](https://www.kaggle.com/jchristov)\n - [Julian Simon de Castro](https://www.kaggle.com/juliansimon)\n - [julie](https://www.kaggle.com/juliecav)\n - [Julien Frisch](https://www.kaggle.com/jfrisch)\n - [Jun Zhu](https://www.kaggle.com/nookki)\n - [Juncheng ZHOU](https://www.kaggle.com/junchengzhou)\n - [Junfeng Zhang](https://www.kaggle.com/junfeng142857)\n - [JuniaGeorge](https://www.kaggle.com/juniag11)\n - [Junki Cho](https://www.kaggle.com/jungi21cc)\n - [Juran](https://www.kaggle.com/littlewhilte)\n - [Just try](https://www.kaggle.com/helensy)\n - [Justin Pan](https://www.kaggle.com/justinpan)\n - [JustinMoore](https://www.kaggle.com/lazyjustin)\n - [JuturuPavan](https://www.kaggle.com/juturu97)\n - [jvent](https://www.kaggle.com/jessevent)\n - [jvm56](https://www.kaggle.com/jvm056)\n - [Jwuthrich](https://www.kaggle.com/jwuthrich)\n - [Jyothi Kamakshi](https://www.kaggle.com/jyothikamakshi)\n - [Jyoti Sharma](https://www.kaggle.com/jyoti1706)\n - [Jyun-Ting](https://www.kaggle.com/b04202048)\n - [jyzaguirre](https://www.kaggle.com/jyzaguirre)\n - [JZ2771](https://www.kaggle.com/jz2771)\n - [k6box](https://www.kaggle.com/bjaton)\n - [K\xc3\x83\xc2\xa4rt](https://www.kaggle.com/kartilja)\n - [K\xc3\x83\xc2\xa2z\xc3\x84\xc2\xb1m An\xc3\x84\xc2\xb1l Eren](https://www.kaggle.com/kazimanil)\n - [Kaan Can](https://www.kaggle.com/kanncaa1)\n - [Kaan Ulgen](https://www.kaggle.com/kulgen)\n - [kaffes](https://www.kaggle.com/kaffes)\n - [kagami](https://www.kaggle.com/kagami)\n - [Kaggle](https://www.kaggle.com/kaggle)\n - [KaggleRay](https://www.kaggle.com/kaggleray)\n - [kaguser](https://www.kaggle.com/kaguser)\n - [kaho](https://www.kaggle.com/sdcskaho)\n - [Kai Wang](https://www.kaggle.com/wangk4)\n - [Kaique da Silva](https://www.kaggle.com/kdwyzstk)\n - [Kairit](https://www.kaggle.com/kpeekman)\n - [kajot](https://www.kaggle.com/piotrgrabo)\n - [kalcal](https://www.kaggle.com/kalcal)\n - [KalyanYerra](https://www.kaggle.com/yerra1)\n - [Kamal raj](https://www.kaggle.com/kamalkraj)\n - [Kamau John](https://www.kaggle.com/sophicist)\n - [kambarakun](https://www.kaggle.com/kambarakun)\n - [kamesh s](https://www.kaggle.com/kameshsoft)\n - [Kamil Jurek](https://www.kaggle.com/kamiljurek)\n - [Kamil Kaczmarek](https://www.kaggle.com/kamilkk)\n - [Kamlesh](https://www.kaggle.com/iamkamleshrangi)\n - [kamran](https://www.kaggle.com/kamrankausar)\n - [Kande Bonfim](https://www.kaggle.com/kandebonfim)\n - [Kane](https://www.kaggle.com/kaneca)\n - [Kanika Narang](https://www.kaggle.com/kanikanarang94)\n - [KanikaChopra](https://www.kaggle.com/kanikachopra)\n - [Kanishka Misra](https://www.kaggle.com/kanishkamisra)\n - [KanishkPratapSingh](https://www.kaggle.com/kanishkapsingh)\n - [KannanPiedy](https://www.kaggle.com/kenstars)\n - [Karamveer](https://www.kaggle.com/karamveer)\n - [Karan Thakkar](https://www.kaggle.com/thakkark1313)\n - [KaranSharma](https://www.kaggle.com/karan1276)\n - [KardoPaska](https://www.kaggle.com/kardopaska)\n - [KarelVerhoeven](https://www.kaggle.com/karelrv)\n - [Karim Ardi](https://www.kaggle.com/fadomp)\n - [KarimBELAYATI](https://www.kaggle.com/belayati)\n - [KarimNahas](https://www.kaggle.com/karimnahas)\n - [Karmanya Aggarwal](https://www.kaggle.com/calmdownkarm)\n - [KarmoT](https://www.kaggle.com/tarmokullas)\n - [Karolina Wullum](https://www.kaggle.com/kwullum)\n - [Kartheek](https://www.kaggle.com/kartheek588)\n - [karthickveerakumar](https://www.kaggle.com/karthickveerakumar)\n - [KarthickVel](https://www.kaggle.com/kkarthick12)\n - [karthik](https://www.kaggle.com/karthik10111)\n - [Karthiks](https://www.kaggle.com/kar446)\n - [karthikziffer](https://www.kaggle.com/karthikziffer)\n - [Kartik](https://www.kaggle.com/kartik71)\n - [KartikPatnaik](https://www.kaggle.com/numberswithkartik)\n - [kashif kaleem](https://www.kaggle.com/kashifkaleem)\n - [Kashish Suneja](https://www.kaggle.com/kashish52)\n - [kashyap](https://www.kaggle.com/prashantkashyap)\n - [Kasper Nielsen](https://www.kaggle.com/kappernielsen)\n - [Kate](https://www.kaggle.com/katerynad)\n - [Katrina Ni](https://www.kaggle.com/katrinadataing)\n - [katzwigmore](https://www.kaggle.com/katzwigmore)\n - [Kaus](https://www.kaggle.com/kaus19)\n - [Kaushik S](https://www.kaggle.com/kaushik3497)\n - [Kaveti Naveen Kumar](https://www.kaggle.com/naveenkaveti)\n - [Kaylan Foster](https://www.kaggle.com/kfoster)\n - [Kayode Emmanuel Oluwatobi](https://www.kaggle.com/tobinfinity)\n - [Kazuki](https://www.kaggle.com/gotoukaz)\n - [KedanLi](https://www.kaggle.com/likedan55)\n - [Keelan Robinson](https://www.kaggle.com/keelanrobinson)\n - [Keheira](https://www.kaggle.com/keheira)\n - [Keik@](https://www.kaggle.com/lucianakeiko)\n - [keisei](https://www.kaggle.com/keisei)\n - [Keita Shimizu](https://www.kaggle.com/keitashimizu)\n - [Kelvin Wellington](https://www.kaggle.com/odartey)\n - [Kelvin Xiao](https://www.kaggle.com/xiaotawkaggle)\n - [Kemal Yilmaz](https://www.kaggle.com/kemaly)\n - [Kemical](https://www.kaggle.com/kemical)\n - [Ken Yamaji](https://www.kaggle.com/kenyam)\n - [KendallGillies](https://www.kaggle.com/kendallgillies)\n - [KenichiNakatani](https://www.kaggle.com/kenichinakatani)\n - [Kenji Kondo](https://www.kaggle.com/kkondo)\n - [Kenneth Benavides](https://www.kaggle.com/dragondeldesierto)\n - [Kenneth Chua](https://www.kaggle.com/kencjy)\n - [kenomaru](https://www.kaggle.com/kenomaru)\n - [KentaroTakemoto](https://www.kaggle.com/takemoto)\n - [Kenton W. Murray](https://www.kaggle.com/kentonnlp)\n - [Keras](https://www.kaggle.com/keras)\n - [Keval M](https://www.kaggle.com/kevalm)\n - [Kevin ](https://www.kaggle.com/kevin11522914)\n - [Kevin Chow](https://www.kaggle.com/kchow23)\n - [Kevin Mader](https://www.kaggle.com/kmader)\n - [Kevin Mario Gerard](https://www.kaggle.com/kevinmariogerard)\n - [Kevin Moodley](https://www.kaggle.com/kevinmgp)\n - [Kevin Pertsovsky](https://www.kaggle.com/kpertsovsky)\n - [Kevin Ree](https://www.kaggle.com/kevinree)\n - [Kevin Soucy](https://www.kaggle.com/kevinsoucy)\n - [Kevin](https://www.kaggle.com/kevinv)\n - [kevin](https://www.kaggle.com/lijiangwei)\n - [Kevin](https://www.kaggle.com/taiden)\n - [KevinH](https://www.kaggle.com/kevinmh)\n - [kevv](https://www.kaggle.com/kevvvv)\n - [Khac Bao Anh NGUYEN](https://www.kaggle.com/baoanh)\n - [Khai Xiang](https://www.kaggle.com/eigenvectors)\n - [khaled salah](https://www.kaggle.com/bekaaa)\n - [Khashayar Baghizadeh Hosseini](https://www.kaggle.com/heptapod)\n - [Kheirallah Samaha](https://www.kaggle.com/khsamaha)\n - [Khepry Quixote](https://www.kaggle.com/khepryquixote)\n - [Khushboo](https://www.kaggle.com/khushboosrivastava2)\n - [Kiefer Smith](https://www.kaggle.com/ksmith)\n - [Kilian Batzner](https://www.kaggle.com/batzner)\n - [Kilian. O](https://www.kaggle.com/brindesable)\n - [Kim Schreier](https://www.kaggle.com/scki1016)\n - [Kimos](https://www.kaggle.com/kimosoo)\n - [Kimura](https://www.kaggle.com/nocotan)\n - [Kingsley Samuel](https://www.kaggle.com/kelvinkins)\n - [Kiran Ganji](https://www.kaggle.com/kiranganji99)\n - [Kiran Gutha](https://www.kaggle.com/gkiranseo)\n - [KiranKarri](https://www.kaggle.com/kirankarri)\n - [KirthikaBabu](https://www.kaggle.com/kirthi2609)\n - [Kishan P](https://www.kaggle.com/omsairam)\n - [kishore](https://www.kaggle.com/fuck123)\n - [Kittisak](https://www.kaggle.com/kittisaks)\n - [kiweee](https://www.kaggle.com/kiweee)\n - [KiyonariHarigae](https://www.kaggle.com/cloudysunny14)\n - [KK](https://www.kaggle.com/kilimnik)\n - [KK](https://www.kaggle.com/kkonakan)\n - [KK16](https://www.kaggle.com/kkanda)\n - [KKDDAll](https://www.kaggle.com/c55303)\n - [kktestin2\'""](https://www.kaggle.com/kktesting2)\n - [Kleber Bernardo](https://www.kaggle.com/kleberbernardo)\n - [km1west](https://www.kaggle.com/km1west)\n - [KMMR](https://www.kaggle.com/kruark)\n - [Kmuvunyi](https://www.kaggle.com/kmuvunyi)\n - [Kola Adebayo](https://www.kaggle.com/adekola)\n - [Kondalarao Vonteru](https://www.kaggle.com/sunnysai12345)\n - [Konstantin Lopuhin](https://www.kaggle.com/lopuhin)\n - [Konstantin](https://www.kaggle.com/iskynet)\n - [Konstantinos Bazakos](https://www.kaggle.com/thebuzz)\n - [Korakot Chaovavanich](https://www.kaggle.com/korakot)\n - [Kory Becker](https://www.kaggle.com/primaryobjects)\n - [kosiewmm](https://www.kaggle.com/kosiewmm)\n - [Kostiantyn Isaienkov](https://www.kaggle.com/isaienkov)\n - [Kostya](https://www.kaggle.com/ktochylin)\n - [Kote42](https://www.kaggle.com/nbolton04)\n - [Kotobotov](https://www.kaggle.com/kotobotov)\n - [KOUASSI Konan Jean-Claude](https://www.kaggle.com/kjeanclaude)\n - [Kozlova](https://www.kaggle.com/geitursdottir)\n - [KP](https://www.kaggle.com/skihikingkevin)\n - [kpapamih](https://www.kaggle.com/kpapamih)\n - [kravdiy](https://www.kaggle.com/kravdiy)\n - [Krishna Agarwal](https://www.kaggle.com/kriaga)\n - [Krishna Bharadwaj](https://www.kaggle.com/bharadwajpro)\n - [KrishnaDheeraj](https://www.kaggle.com/dheerajkrishna90)\n - [Krishnan](https://www.kaggle.com/krishnansailam)\n - [KrishnaPraveen](https://www.kaggle.com/felicis)\n - [KrishnaThiyagarajan](https://www.kaggle.com/krisht)\n - [KrisMurphy](https://www.kaggle.com/krismurphy01)\n - [Kristian H](https://www.kaggle.com/morphlng7)\n - [Kristjan P\xc3\x83\xc2\xa4rn](https://www.kaggle.com/kraalike)\n - [KristofferHess](https://www.kaggle.com/kristofferhess)\n - [Kristopher Sheets, PhD](https://www.kaggle.com/sheetskg)\n - [Krithel](https://www.kaggle.com/krithel)\n - [Krizs\xc3\x83\xc2\xb3 Gergely](https://www.kaggle.com/lucifer19)\n - [krsimons](https://www.kaggle.com/krsimons)\n - [ksayantani](https://www.kaggle.com/ksayantani)\n - [Ksenia Sukhova](https://www.kaggle.com/tovarischsukhov)\n - [kso.](https://www.kaggle.com/fanatiks)\n - [kumar abhishek](https://www.kaggle.com/kumarabhishekone)\n - [Kumar Nityan Suman](https://www.kaggle.com/knityansuman)\n - [Kumar](https://www.kaggle.com/amitabh08)\n - [Kumaran K](https://www.kaggle.com/kumarandatascientist)\n - [kumarbhrgv](https://www.kaggle.com/kumarbhrgv)\n - [KumarHalake](https://www.kaggle.com/kumarhalake)\n - [Kunal Kotian](https://www.kaggle.com/kunalkotian)\n - [Kunal Singh](https://www.kaggle.com/kunaliitkgp)\n - [Kunal Vaishnavi](https://www.kaggle.com/kunalvaishnavi)\n - [kunalkumawat](https://www.kaggle.com/kunalkk99)\n - [kunimune](https://www.kaggle.com/muni0893)\n - [Kuntal Sardar](https://www.kaggle.com/kuntalcse006)\n - [Kushal](https://www.kaggle.com/pkushal)\n - [Kushneryk Pavel](https://www.kaggle.com/kushneryk)\n - [KutsalBaran\xc3\x83\xe2\x80\x93zkurt](https://www.kaggle.com/makerb)\n - [kveykva](https://www.kaggle.com/kveykva)\n - [kvpratama](https://www.kaggle.com/kvpratama)\n - [Kwan Lowe](https://www.kaggle.com/digitalhermit)\n - [kwangrok lee](https://www.kaggle.com/krleee)\n - [kwtcut](https://www.kaggle.com/kwtcut)\n - [Kyle McClurg](https://www.kaggle.com/kmcclurg)\n - [kyle moon](https://www.kaggle.com/mooneruma)\n - [L Sun](https://www.kaggle.com/luelly)\n - [La Sul](https://www.kaggle.com/laoralipow)\n - [LA Times Data Desk](https://www.kaggle.com/la-times)\n - [Lacie ](https://www.kaggle.com/laciecool)\n - [LacksonMundira](https://www.kaggle.com/lmundira)\n - [LAdams](https://www.kaggle.com/laa283)\n - [lahouarami](https://www.kaggle.com/lahouarami)\n - [LaiyiLin](https://www.kaggle.com/lylin84)\n - [lakshadvani](https://www.kaggle.com/lakshadvani)\n - [Lakshya Khandelwal](https://www.kaggle.com/lakshyak)\n - [Lalit Khandelwal](https://www.kaggle.com/lalitkhandelwal)\n - [Lalit Parihar](https://www.kaggle.com/lalitparihar44)\n - [lalitsomnathe](https://www.kaggle.com/lalitsomnathe)\n - [lalthan](https://www.kaggle.com/lalthan)\n - [lamda-dev](https://www.kaggle.com/lamdadev)\n - [langzi](https://www.kaggle.com/q525614)\n - [Lantana Camara](https://www.kaggle.com/lantanacamara)\n - [LanVuku\xc3\x85\xc2\xa1i\xc3\x84\xc2\x8d](https://www.kaggle.com/lanls1)\n - [Lasteg](https://www.kaggle.com/zxspectrum)\n - [LastJedi76](https://www.kaggle.com/romuloflores)\n - [Laura](https://www.kaggle.com/lctc12)\n - [Laurae](https://www.kaggle.com/laurae2)\n - [LauraMoen](https://www.kaggle.com/moenl742)\n - [Lauren BK](https://www.kaggle.com/laurenbk)\n - [Laurenstc](https://www.kaggle.com/laurenstc)\n - [LaurentBerder](https://www.kaggle.com/lberder)\n - [lavi](https://www.kaggle.com/anchal479)\n - [LavishGulati](https://www.kaggle.com/lavishgulati)\n - [lazkol](https://www.kaggle.com/lazkol)\n - [LE PALLEC Cl\xc3\x83\xc2\xa9ment](https://www.kaggle.com/clementlepallec)\n - [Leandro dos Santos Coelho](https://www.kaggle.com/lscoelho)\n - [Leandro Silva](https://www.kaggle.com/leandrodoze)\n - [Learner](https://www.kaggle.com/gaurav2555)\n - [Lee Worthington](https://www.kaggle.com/lworthington)\n - [LeeYun](https://www.kaggle.com/leeyun)\n - [lefant](https://www.kaggle.com/lefant)\n - [Lehmaudar](https://www.kaggle.com/lehmaudar)\n - [Lei Ding](https://www.kaggle.com/bigding)\n - [leigh](https://www.kaggle.com/ljewell)\n - [Leo Arruda](https://www.kaggle.com/leoarruda)\n - [Leo](https://www.kaggle.com/tondji)\n - [Leon Martin ](https://www.kaggle.com/leonmartin)\n - [Leon](https://www.kaggle.com/laleon)\n - [Leonardo Ferreira](https://www.kaggle.com/kabure)\n - [Leonidas](https://www.kaggle.com/nnair25)\n - [LeonPaul](https://www.kaggle.com/leonpaul93)\n - [Leroberge](https://www.kaggle.com/leroberge)\n - [Lesoler](https://www.kaggle.com/lesoler)\n - [LesPaulCustom](https://www.kaggle.com/lespaulcustom)\n - [LeticiaFilgueiras](https://www.kaggle.com/filgueirasl)\n - [LeviMa](https://www.kaggle.com/levima)\n - [Lewis](https://www.kaggle.com/lewisyang)\n - [Lexie Dempsey](https://www.kaggle.com/ard5001)\n - [Lgpatel](https://www.kaggle.com/lgp33333)\n - [Liam Cusack](https://www.kaggle.com/lrcusack)\n - [LiamLarsen](https://www.kaggle.com/kingburrito666)\n - [librahu](https://www.kaggle.com/librahu)\n - [Lieven23](https://www.kaggle.com/lieven23)\n - [light-boat](https://www.kaggle.com/lightcc)\n - [lihan](https://www.kaggle.com/llihan)\n - [Lihaoyang](https://www.kaggle.com/gerryl)\n - [Liisi](https://www.kaggle.com/liisirammo)\n - [LiLi](https://www.kaggle.com/lorcha)\n - [Liling Tan](https://www.kaggle.com/alvations)\n - [Lilit Janjughazyan](https://www.kaggle.com/ljanjughazyan)\n - [limi44](https://www.kaggle.com/limi44)\n - [Liming](https://www.kaggle.com/tongjiyiming)\n - [limmen](https://www.kaggle.com/limmen)\n - [Limon M](https://www.kaggle.com/limonm)\n - [Lin Gao](https://www.kaggle.com/gao297)\n - [Lin Ying Lung](https://www.kaggle.com/shadowkshs)\n - [lincoln](https://www.kaggle.com/bharaniabhishek123)\n - [Lindada](https://www.kaggle.com/a763337092)\n - [Lingzhi](https://www.kaggle.com/vrtjso)\n - [LinkanRay](https://www.kaggle.com/linkanray)\n - [Lisa](https://www.kaggle.com/arpitajena)\n - [lisjin](https://www.kaggle.com/lisjin)\n - [Lislejoem](https://www.kaggle.com/lislejoem)\n - [Lissette Guzman](https://www.kaggle.com/lissetteg)\n - [litianyi](https://www.kaggle.com/evelisky)\n - [Little Boat](https://www.kaggle.com/xiaozhouwang)\n - [Litu Rout](https://www.kaggle.com/liturout)\n - [liuenda](https://www.kaggle.com/liuenda)\n - [liuxiaoliu](https://www.kaggle.com/hana0211)\n - [LiuYang](https://www.kaggle.com/liuyangbeta)\n - [liuyongqi](https://www.kaggle.com/baodier)\n - [liuzhe0125](https://www.kaggle.com/liuzhe0125)\n - [livi](https://www.kaggle.com/livvlivi)\n - [liwste](https://www.kaggle.com/liwste)\n - [Liza Bolton](https://www.kaggle.com/dataembassy)\n - [ljhuang](https://www.kaggle.com/cshlj199)\n - [lkytal](https://www.kaggle.com/lkytal)\n - [lnicalo](https://www.kaggle.com/lnicalo)\n - [LogHorizon](https://www.kaggle.com/loghorizon)\n - [logwinner](https://www.kaggle.com/hassanouda)\n - [lohith](https://www.kaggle.com/lohitharcot)\n - [lomungo](https://www.kaggle.com/lomungo)\n - [looo](https://www.kaggle.com/luogangnk)\n - [Lorna Maria](https://www.kaggle.com/lornamariak)\n - [Louis Marmet](https://www.kaggle.com/marmetl)\n - [louis](https://www.kaggle.com/louissg)\n - [Louis](https://www.kaggle.com/ttetls)\n - [LouweAL](https://www.kaggle.com/anneloes)\n - [loyf](https://www.kaggle.com/lclave)\n - [LPitre](https://www.kaggle.com/lpitre)\n - [LuanHo](https://www.kaggle.com/luanho)\n - [Lu\xc3\x83\xc2\xads Gustavo Modelli](https://www.kaggle.com/gustavomodelli)\n - [lubaroli](https://www.kaggle.com/lubaroli)\n - [Lucas Astorian](https://www.kaggle.com/lucasastorian)\n - [Lucas Dixon](https://www.kaggle.com/iislucas)\n - [Lucas Erring](https://www.kaggle.com/drlucaserring)\n - [Lucas Venezian Povoa](https://www.kaggle.com/lucasvenez)\n - [Lucas Vergeest](https://www.kaggle.com/lucasvergeest)\n - [Lucas](https://www.kaggle.com/nordstjernen)\n - [LucasVinze](https://www.kaggle.com/vinchinzu)\n - [Lucio L\xc3\x83\xc2\xb3pez Lecube](https://www.kaggle.com/lucio1)\n - [Ludovic benistant](https://www.kaggle.com/ludobenistant)\n - [Lugark](https://www.kaggle.com/lugark)\n - [Luigi](https://www.kaggle.com/luigimersico)\n - [Luis Andre Dutra e Silva](https://www.kaggle.com/mindcool)\n - [Luis Bronchal](https://www.kaggle.com/lbronchal)\n - [Luis Moneda](https://www.kaggle.com/lgmoneda)\n - [LuisaAPF](https://www.kaggle.com/luisaapf)\n - [luistelmocosta](https://www.kaggle.com/luistelmocosta)\n - [Luiz Gerosa](https://www.kaggle.com/gerosa)\n - [Luiz Gustavo Schiller](https://www.kaggle.com/schiller)\n - [Luiz Henrique Amorim](https://www.kaggle.com/luizoamorim)\n - [Luiza Fontana](https://www.kaggle.com/zafontana)\n - [Luke Bunge](https://www.kaggle.com/lukebunge14)\n - [Luke Godwin-Jones](https://www.kaggle.com/lagodw)\n - [lukebyrne](https://www.kaggle.com/lukebyrne)\n - [LukeLee](https://www.kaggle.com/infgeoax)\n - [Lumin](https://www.kaggle.com/lumins)\n - [LunarLlama](https://www.kaggle.com/lunarllama)\n - [Luu](https://www.kaggle.com/namluu)\n - [LyAhmedTidiane](https://www.kaggle.com/tizezie)\n - [lyh19970409](https://www.kaggle.com/lyuyanhan)\n - [Lynn dai](https://www.kaggle.com/lynndai)\n - [LynnPan](https://www.kaggle.com/lynnpan168)\n - [M Baddar](https://www.kaggle.com/baddar)\n - [M Ganiyu](https://www.kaggle.com/mascotinme)\n - [M.F.](https://www.kaggle.com/mfrincu)\n - [maarten](https://www.kaggle.com/maartenko)\n - [Mabs](https://www.kaggle.com/mabs003)\n - [MACHINE LEARNING DATASETS](https://www.kaggle.com/pitasr)\n - [Maciej Witkowiak](https://www.kaggle.com/ytmytm)\n - [Mad Hab](https://www.kaggle.com/madhab)\n - [Madhan Varadhodiyil](https://www.kaggle.com/varadhodiyil)\n - [Madhav Iyengar](https://www.kaggle.com/madhavthegod)\n - [Madhavi  Burra](https://www.kaggle.com/madhaviburra)\n - [Madhur Inani](https://www.kaggle.com/madhurinani)\n - [Madis_Lemsalu](https://www.kaggle.com/madislemsalu)\n - [Madison Curtis](https://www.kaggle.com/mfc5300)\n - [MadScientist](https://www.kaggle.com/keremt)\n - [Maghilnan](https://www.kaggle.com/maghilnan)\n - [MagicK](https://www.kaggle.com/katedubbs)\n - [Magsgiust ](https://www.kaggle.com/magsgiust)\n - [Mahadevan](https://www.kaggle.com/mahadevansv)\n - [MahdiJavid](https://www.kaggle.com/mahdijavid)\n - [Mahdy Nabaee](https://www.kaggle.com/mnabaee)\n - [Mahek Hooda](https://www.kaggle.com/mahekhooda)\n - [Mahesh Sinha](https://www.kaggle.com/maheshsinha)\n - [Mahesh_PRS](https://www.kaggle.com/maheshprs)\n - [MahirKukreja](https://www.kaggle.com/mahirkukreja)\n - [Mahmoud Aljabary](https://www.kaggle.com/maljabary)\n - [MahreenAhmed](https://www.kaggle.com/mahreen)\n - [maik3141](https://www.kaggle.com/maik3141)\n - [Mainak kUNDU](https://www.kaggle.com/mainakdatageek)\n - [Maitree Priyadarsini](https://www.kaggle.com/maitree)\n - [MakarandVelankar](https://www.kaggle.com/makvel)\n - [Maksim Mikhotov](https://www.kaggle.com/mmikhotov)\n - [Maksym](https://www.kaggle.com/intell)\n - [Malathi Arumugam](https://www.kaggle.com/malathiarumugam)\n - [Malek Trabelsi](https://www.kaggle.com/malektrabelsi)\n - [Malinee Fawcett](https://www.kaggle.com/malineef)\n - [Malini](https://www.kaggle.com/malinikocheri)\n - [Mamun](https://www.kaggle.com/mdmahmudulalam)\n - [Manan Jain](https://www.kaggle.com/mananjain)\n - [Manan Manwani](https://www.kaggle.com/manan904)\n - [Manas](https://www.kaggle.com/manasgarg)\n - [Manav Sehgal](https://www.kaggle.com/startupsci)\n - [mancml](https://www.kaggle.com/hhmanlee)\n - [Manfredi Federico Pivetta ](https://www.kaggle.com/manfredipivetta)\n - [Mani](https://www.kaggle.com/dmvreddy91)\n - [MANIKANTA](https://www.kaggle.com/mani443)\n - [ManikHossain](https://www.kaggle.com/manik500)\n - [Manimala](https://www.kaggle.com/vikrishnan)\n - [Manish jain](https://www.kaggle.com/manishjain15051982)\n - [Manish Kumar](https://www.kaggle.com/mkagenius)\n - [Manjeet Singh](https://www.kaggle.com/manjeetsingh)\n - [Manoj Kumar](https://www.kaggle.com/sumanoj23)\n - [manoj2891](https://www.kaggle.com/manoj2891)\n - [ManojHariharan](https://www.kaggle.com/manojhariharan)\n - [MANOJKUMAR PARMAR](https://www.kaggle.com/parmarmanojkumar)\n - [MANOJKUMAR](https://www.kaggle.com/manojk15)\n - [Manqiong](https://www.kaggle.com/manqiong)\n - [Manshubh Singh Rihal](https://www.kaggle.com/manshubh)\n - [Mansoor Iqbal](https://www.kaggle.com/mansoordaku)\n - [Mansour Movahhedinia](https://www.kaggle.com/mmovahhedinia)\n - [Mantas Zimnickas](https://www.kaggle.com/sirexo)\n - [Manuel Barrena](https://www.kaggle.com/mbarrenag)\n - [Mapik88](https://www.kaggle.com/mapik88)\n - [Mar\xc3\x83\xc2\xada Otero](https://www.kaggle.com/maotero)\n - [Marc Kossa](https://www.kaggle.com/marckossa)\n - [marc moreaux](https://www.kaggle.com/mmoreaux)\n - [Marc Robert](https://www.kaggle.com/vluijpen)\n - [Marc Slaughter](https://www.kaggle.com/marcslaughter)\n - [Marc Velmer](https://www.kaggle.com/marcvelmer)\n - [Marc](https://www.kaggle.com/marc45773)\n - [Marcel](https://www.kaggle.com/mkempers)\n - [Marcell ""Mazuh"" Guilherme Costa da Silva](https://www.kaggle.com/mazuh69)\n - [Marcelo Santos](https://www.kaggle.com/mefsantos)\n - [Marco Boaretto](https://www.kaggle.com/mboaretto)\n - [Marco De Nadai](https://www.kaggle.com/marcodena)\n - [Marco Molina](https://www.kaggle.com/marcomolina)\n - [Marco Zanchi](https://www.kaggle.com/inquisitivecrow)\n - [MarcoCarnini](https://www.kaggle.com/marcocarnini)\n - [Marcos Boaglio](https://www.kaggle.com/mboaglio)\n - [MarcSchroeder](https://www.kaggle.com/marcschroeder)\n - [MarcTorrellas](https://www.kaggle.com/marctorsoc)\n - [Marcus Lin](https://www.kaggle.com/marcuslin)\n - [Maria Bile](https://www.kaggle.com/mariabile)\n - [Maria Luiza](https://www.kaggle.com/marialuiza07)\n - [mariakatosvich](https://www.kaggle.com/qwikfix)\n - [Mariehane](https://www.kaggle.com/mariehane)\n - [Marielen Ferreira](https://www.kaggle.com/mferreira)\n - [Mario Navas](https://www.kaggle.com/mnavas)\n - [Mario Pasquato](https://www.kaggle.com/mariopasquato)\n - [Marius](https://www.kaggle.com/titamarius)\n - [Mark DiMarco](https://www.kaggle.com/markmarkoh)\n - [Mark Eldridge](https://www.kaggle.com/mkeldridge)\n - [Mark](https://www.kaggle.com/baileymm)\n - [MarkArchieGamayan](https://www.kaggle.com/markarchie)\n - [Marketing As Is](https://www.kaggle.com/bnguye05)\n - [Marko K](https://www.kaggle.com/knelle87)\n - [MarkSchultz](https://www.kaggle.com/schulm3)\n - [Markus Lang](https://www.kaggle.com/markuslang)\n - [Marlesson](https://www.kaggle.com/marlesson)\n - [Marouane Benmeida](https://www.kaggle.com/atmarouane)\n - [Martin Enzinger](https://www.kaggle.com/enzinger)\n - [Martin Pereira](https://www.kaggle.com/pera21)\n - [MartinBoyanov](https://www.kaggle.com/mboyanov)\n - [MartJ](https://www.kaggle.com/martj42)\n - [Marty](https://www.kaggle.com/mboren)\n - [marvin](https://www.kaggle.com/marvinlsj)\n - [Marwa Saied](https://www.kaggle.com/marwaf)\n - [masahito429](https://www.kaggle.com/masahito429)\n - [masakt](https://www.kaggle.com/masakt)\n - [Masato Hagiwara](https://www.kaggle.com/mhagiwara)\n - [Masato](https://www.kaggle.com/giwada)\n - [Masood Hussain](https://www.kaggle.com/masoodhussain)\n - [Massachusetts Institute of Technology](https://www.kaggle.com/mit)\n - [Masseycre](https://www.kaggle.com/masseyratings)\n - [Mateus](https://www.kaggle.com/mateus51)\n - [Mathew Savage](https://www.kaggle.com/mathewsavage)\n - [Mathias Meldgaard Pedersen](https://www.kaggle.com/mattidk)\n - [MathiasEdman](https://www.kaggle.com/skeletor)\n - [Mathieu Goutay](https://www.kaggle.com/mgoutay)\n - [Mathijs Waegemakers](https://www.kaggle.com/mathijs)\n - [mathishammel](https://www.kaggle.com/mathishammel)\n - [Mathurin Ach\xc3\x83\xc2\xa9](https://www.kaggle.com/mathurinache)\n - [matiasfeld](https://www.kaggle.com/feldmatias)\n - [matsueushi](https://www.kaggle.com/matsueushi)\n - [Matt Hixon](https://www.kaggle.com/mhixon)\n - [Matt Rose](https://www.kaggle.com/mattrose3)\n - [Matt Snell](https://www.kaggle.com/mattsnellaai)\n - [Matt](https://www.kaggle.com/mssilver)\n - [Matteo Casadei](https://www.kaggle.com/matteocasadei)\n - [Matteo_Mazzola](https://www.kaggle.com/ciotolaaaa)\n - [Matthew Allbee](https://www.kaggle.com/grafs50)\n - [Matthew Anderson](https://www.kaggle.com/matthewa313)\n - [Matthew Carter](https://www.kaggle.com/mattcarter865)\n - [matthew](https://www.kaggle.com/matthewweb)\n - [MatthewHonnibal](https://www.kaggle.com/honnibal)\n - [Matthieu C](https://www.kaggle.com/theognosis)\n - [Mattia Gigliotti](https://www.kaggle.com/gigliotti)\n - [mattilgale](https://www.kaggle.com/mattilgale)\n - [maurice_f](https://www.kaggle.com/mauricefreund)\n - [Mauro Reverter](https://www.kaggle.com/mreverter)\n - [mavez DABAS](https://www.kaggle.com/mavezdabas)\n - [Max Candocia](https://www.kaggle.com/mcandocia)\n - [Max Halford](https://www.kaggle.com/maxhalford)\n - [Max Horowitz](https://www.kaggle.com/maxhorowitz)\n - [Max Mind](https://www.kaggle.com/max-mind)\n - [Max Stanford-Taylor](https://www.kaggle.com/m0ongg)\n - [Max.liu](https://www.kaggle.com/madmaxliu)\n - [Maxime Fuccellaro](https://www.kaggle.com/blackbee2016)\n - [Maximilian Hahn](https://www.kaggle.com/maximilianhahn)\n - [Maximilian Kapsecker](https://www.kaggle.com/maxkapsecker)\n - [Mayank Singla](https://www.kaggle.com/mayanksingla)\n - [MayankSiddharth](https://www.kaggle.com/mayanksiddharth)\n - [MayankTiwari](https://www.kaggle.com/mayanktiwari09)\n - [Maykon Ravy](https://www.kaggle.com/maykonravy)\n - [McDonald\'s](https://www.kaggle.com/mcdonalds)\n - [MCrescenzo](https://www.kaggle.com/crescenzo)\n - [Md Irfan Ali](https://www.kaggle.com/irfanalidv)\n - [Mearafat](https://www.kaggle.com/fuckbitch)\n - [Medicare](https://www.kaggle.com/medicare)\n - [meep](https://www.kaggle.com/meepbobeep)\n - [Meetika Sharma](https://www.kaggle.com/meetika)\n - [Meg Shields](https://www.kaggle.com/meghshields)\n - [Megan Risdal](https://www.kaggle.com/mrisdal)\n - [Mehdi](https://www.kaggle.com/mnoori)\n - [Mehedi Shafi](https://www.kaggle.com/exilour)\n - [mehrdad](https://www.kaggle.com/mehrdat)\n - [mehrdadz007](https://www.kaggle.com/mehrdadz007)\n - [Mehta](https://www.kaggle.com/fm4023)\n - [Meigang Gu](https://www.kaggle.com/vradore)\n - [Meinertsen](https://www.kaggle.com/meinertsen)\n - [Melody Z](https://www.kaggle.com/melodyxyz)\n - [melvincheung](https://www.kaggle.com/melvincheung)\n - [Melvyn Drag](https://www.kaggle.com/juliancienfuegos)\n - [Mengfei Li](https://www.kaggle.com/meli19)\n - [mengmengyong](https://www.kaggle.com/mengmengyong)\n - [mengyan](https://www.kaggle.com/mengyanli)\n - [MengYe](https://www.kaggle.com/konohayui)\n - [meow](https://www.kaggle.com/nguyentp)\n - [mepotts](https://www.kaggle.com/mepotts)\n - [Merilin K\xc3\x83\xc2\xb5rnas](https://www.kaggle.com/merilink)\n - [Mesum Raza Hemani](https://www.kaggle.com/mesumraza)\n - [mgkmgk](https://www.kaggle.com/mgkmgk)\n - [MGN](https://www.kaggle.com/mguzmann)\n - [mharrys](https://www.kaggle.com/mharrys)\n - [MHouellemont](https://www.kaggle.com/mhouellemont)\n - [Miaomiao](https://www.kaggle.com/jinmm1992)\n - [Micha\xc3\x85\xe2\x80\x9a Jamry](https://www.kaggle.com/abecadel)\n - [Micha\xc3\x85\xe2\x80\x9aPuchalski](https://www.kaggle.com/zeniott13)\n - [Michael Clouting](https://www.kaggle.com/mclouts91)\n - [Michael Ibrahim](https://www.kaggle.com/michaelibrahim)\n - [Michael KS](https://www.kaggle.com/ashurali)\n - [Michael Nation](https://www.kaggle.com/michaelnation)\n - [Michael Pang](https://www.kaggle.com/akababa)\n - [Michael Pavlukhin](https://www.kaggle.com/archelunch)\n - [Michael Plohhotnichenko](https://www.kaggle.com/mixanikk)\n - [Michael Skrzypiec](https://www.kaggle.com/skrzym)\n - [Michael](https://www.kaggle.com/aenimaxoxo)\n - [Michael](https://www.kaggle.com/mdquigg)\n - [MichaelKirk](https://www.kaggle.com/heliodata)\n - [MichaelKlear](https://www.kaggle.com/alliedtoasters)\n - [MichaelStone](https://www.kaggle.com/stoney71)\n - [Michal Januszewski](https://www.kaggle.com/meehau)\n - [Michelle HY](https://www.kaggle.com/hyyeoh)\n - [MieMie Kurisu](https://www.kaggle.com/miemiekurisu)\n - [Miguel Llad\xc3\x83\xc2\xb3](https://www.kaggle.com/mlladocunyat)\n - [Miguel](https://www.kaggle.com/miguel2523)\n - [Miguel](https://www.kaggle.com/miguelgvieira)\n - [MiguelSalazar](https://www.kaggle.com/migue1284)\n - [Mihai Oltean](https://www.kaggle.com/moltean)\n - [Mihir Garg](https://www.kaggle.com/mihirgarg)\n - [Mihkel Gering](https://www.kaggle.com/airtton)\n - [MihwaHan](https://www.kaggle.com/hanriver0618)\n - [miinooo](https://www.kaggle.com/miinoooo)\n - [mijim](https://www.kaggle.com/jimgoh)\n - [Mike Chirico](https://www.kaggle.com/mchirico)\n - [Mike Johnson Jr](https://www.kaggle.com/mikejohnsonjr)\n - [Mike Kim](https://www.kaggle.com/mikeskim)\n - [Mike Mekilo](https://www.kaggle.com/mmek31)\n - [Mike Pastore](https://www.kaggle.com/mpastore)\n - [mike sebel](https://www.kaggle.com/mykcbel)\n - [Mikhail Chesnokov](https://www.kaggle.com/chesnokov)\n - [miki112](https://www.kaggle.com/miki112)\n - [MikioKubo](https://www.kaggle.com/logopt)\n - [mikr](https://www.kaggle.com/milankryl)\n - [MilindParadkar](https://www.kaggle.com/milind81)\n - [Miljenko Bartulovic](https://www.kaggle.com/bartulovic)\n - [mimic1](https://www.kaggle.com/mimic1)\n - [Mina](https://www.kaggle.com/mnanlch)\n - [Minat Verma](https://www.kaggle.com/minatverma)\n - [MindaugasMejeras](https://www.kaggle.com/mindaugasm)\n - [Minerwa Min](https://www.kaggle.com/minerva666)\n - [mingming](https://www.kaggle.com/billy8399)\n - [minmind](https://www.kaggle.com/minmind)\n - [Minso](https://www.kaggle.com/wjeong)\n - [Minx](https://www.kaggle.com/songbm524)\n - [Minxuan](https://www.kaggle.com/minxuanchen)\n - [minyao](https://www.kaggle.com/minyao)\n - [Mir Ali](https://www.kaggle.com/mirbaig)\n - [Miranda](https://www.kaggle.com/miiranda)\n - [Mircea Stanciu](https://www.kaggle.com/baiazid)\n - [Mirko M\xc3\x83\xc2\xa4licke](https://www.kaggle.com/mmaelicke)\n - [Miro Karpis](https://www.kaggle.com/kam1ro)\n - [Miroslav Sabo](https://www.kaggle.com/miroslavsabo)\n - [Miroslav Zoricak](https://www.kaggle.com/mirosval)\n - [MiroslavTyurin](https://www.kaggle.com/miroslavtyurin)\n - [MirrorLu](https://www.kaggle.com/mirrorlu)\n - [Mission San Jose AI Club](https://www.kaggle.com/msjaiclub)\n - [MistyMoo](https://www.kaggle.com/alisonp)\n - [Mitchell J](https://www.kaggle.com/datasnaek)\n - [mithileshwaribhade](https://www.kaggle.com/varsha97)\n - [mitillo](https://www.kaggle.com/mitillo)\n - [mitsu](https://www.kaggle.com/mitsuru1)\n - [Mitusha](https://www.kaggle.com/mitusha)\n - [Miza\'](https://www.kaggle.com/miza203)\n - [mizosalah](https://www.kaggle.com/mizosalah)\n - [MKMK](https://www.kaggle.com/koogle)\n - [ML Coder](https://www.kaggle.com/rsaiml)\n - [ML_CX](https://www.kaggle.com/chenmingml)\n - [mlagunas](https://www.kaggle.com/mlagunas)\n - [MLane](https://www.kaggle.com/skyrmion)\n - [MLS](https://www.kaggle.com/sushanta)\n - [mlxd](https://www.kaggle.com/loriordan)\n - [mnakajima](https://www.kaggle.com/mnakajima75)\n - [Modeling Online Auctions](https://www.kaggle.com/onlineauctions)\n - [Moghazy](https://www.kaggle.com/moghazy)\n - [Mohamed Abul Danish](https://www.kaggle.com/danish1998)\n - [Mohamed Elsayed](https://www.kaggle.com/sayedovic)\n - [Mohamed Loey](https://www.kaggle.com/mloey1)\n - [Mohamed Ramadan](https://www.kaggle.com/mramadan85)\n - [Mohamed Shawky DG](https://www.kaggle.com/darkgeekms)\n - [MohamedSaidDaw](https://www.kaggle.com/kito96)\n - [MohamedShawky](https://www.kaggle.com/mohshawky)\n - [MohamedWasim](https://www.kaggle.com/uchihaaitachi)\n - [Mohammad Ali](https://www.kaggle.com/mohalikhan)\n - [Mohammad Ghahramani](https://www.kaggle.com/analystmasters)\n - [Mohammad Kachuee](https://www.kaggle.com/mkachuee)\n - [MohammadAmir](https://www.kaggle.com/amirkhn33)\n - [MohammadAseemUrRehman](https://www.kaggle.com/aseem1981)\n - [Mohammed Alnemari](https://www.kaggle.com/alnemari)\n - [Mohit Balani](https://www.kaggle.com/mohit770)\n - [Mohit Sainani](https://www.kaggle.com/msainani)\n - [Moi](https://www.kaggle.com/francismoi)\n - [Moko Sharma](https://www.kaggle.com/mokosan)\n - [Monika Munjal](https://www.kaggle.com/monika11)\n - [MonishC](https://www.kaggle.com/monishc)\n - [monkeyking](https://www.kaggle.com/supersp1234)\n - [moon soo Lee](https://www.kaggle.com/leemoonsoo)\n - [morcinim](https://www.kaggle.com/morcinim)\n - [MorganMazer](https://www.kaggle.com/socialmedianews)\n - [Moses Salifu](https://www.kaggle.com/moses87)\n - [Moshfiqur Rahman](https://www.kaggle.com/moshfiqur)\n - [Motaz Saad](https://www.kaggle.com/mksaad)\n - [Moufid](https://www.kaggle.com/moufid)\n - [Mouli](https://www.kaggle.com/crmouli)\n - [moxious](https://www.kaggle.com/moxious)\n - [Mozilla](https://www.kaggle.com/mozillaorg)\n - [MphoGodfreyNkadimeng](https://www.kaggle.com/gnkadimeng)\n - [Mr. Analytics](https://www.kaggle.com/emoneyanalytics)\n - [mrdeeds](https://www.kaggle.com/mrdeeds)\n - [MridulSharma](https://www.kaggle.com/midzsh98)\n - [MritunjayMohitesh](https://www.kaggle.com/latentheat)\n - [mrjazz](https://www.kaggle.com/mrjazz)\n - [MrNasalHazel](https://www.kaggle.com/zwarner)\n - [mrpantherson](https://www.kaggle.com/mrpantherson)\n - [mrsantos](https://www.kaggle.com/mrsantos)\n - [Mrverde](https://www.kaggle.com/mrverde)\n - [mrzzheng](https://www.kaggle.com/mrzzheng)\n - [Ms Brown](https://www.kaggle.com/msbrown)\n - [msiebold](https://www.kaggle.com/msiebold)\n - [msjass](https://www.kaggle.com/msjass)\n - [MsZombie](https://www.kaggle.com/zombie)\n - [MT](https://www.kaggle.com/mtinti)\n - [Mudit Choraria](https://www.kaggle.com/muditchoraria)\n - [Mufti Mubarak](https://www.kaggle.com/muftimm)\n - [Muhamad Nady](https://www.kaggle.com/muhamadnady)\n - [Muhammad Abdul Rehman](https://www.kaggle.com/rehmanm)\n - [Muhammad Alfiansyah](https://www.kaggle.com/muhammadalfiansyah)\n - [Muhammad Ali](https://www.kaggle.com/alisubhan)\n - [Muhammad Aseem Ur Rehman](https://www.kaggle.com/maseemurrehman)\n - [Muhammad Asif khan](https://www.kaggle.com/engrasifkhan)\n - [Muhammad Jamil Moughal](https://www.kaggle.com/mjamilmoughal)\n - [MuhammadMahadTariq](https://www.kaggle.com/mmahadt)\n - [MuhammadYasirAdnan](https://www.kaggle.com/yasiradnan)\n - [Mukarram Pasha](https://www.kaggle.com/mpasha96)\n - [Mukesh Kumar](https://www.kaggle.com/mukesh2626)\n - [Muneeb ul Hassan](https://www.kaggle.com/muneeb2405)\n - [MuonNeutrino](https://www.kaggle.com/muonneutrino)\n - [Murali_Munna](https://www.kaggle.com/muralimunna18)\n - [MURALIDHAR ANUMULA](https://www.kaggle.com/anumulamuralidhar)\n - [Murder Accountability Project](https://www.kaggle.com/murderaccountability)\n - [mureren](https://www.kaggle.com/mureren)\n - [Murilo Siqueira](https://www.kaggle.com/murilosiqueira)\n - [Murilo Viviani](https://www.kaggle.com/mviviani)\n - [MuskanBararia](https://www.kaggle.com/muskanbararia)\n - [Mustakim](https://www.kaggle.com/abdaatif)\n - [Muthukumar.J](https://www.kaggle.com/muthuj7)\n - [Muttaqi Ismail](https://www.kaggle.com/muttaqi)\n - [My Khe Nguyen](https://www.kaggle.com/mykhe1097)\n - [Myles O\'Neill](https://www.kaggle.com/mylesoneill)\n - [mypapit](https://www.kaggle.com/mypapit)\n - [n&n student](https://www.kaggle.com/nnstudent)\n - [n01z3](https://www.kaggle.com/drn01z3)\n - [Nabeel Raza](https://www.kaggle.com/nabeel965)\n - [Nada Fathallah](https://www.kaggle.com/nadafathallah)\n - [Nadin Tamer](https://www.kaggle.com/nadintamer)\n - [Nagabhushan S B](https://www.kaggle.com/nagabhushan1995)\n - [NAGARAJ RAMAKRISHNA](https://www.kaggle.com/nagarajh)\n - [Nagendra Yadav](https://www.kaggle.com/nagendrayadav)\n - [nailo](https://www.kaggle.com/nailo2c)\n - [nami](https://www.kaggle.com/nami0917)\n - [Namory Koulibaly](https://www.kaggle.com/sonamkoul2)\n - [Namsraijav Dugersuren](https://www.kaggle.com/namsraijavd)\n - [NAN JI](https://www.kaggle.com/frupaul)\n - [Nancy Lubalo](https://www.kaggle.com/nlubalo)\n - [Nandagopal M](https://www.kaggle.com/nandum)\n - [NaomiNguyen](https://www.kaggle.com/naominguyen7)\n - [narmeen ](https://www.kaggle.com/narmeen29)\n - [NASA](https://www.kaggle.com/nasa)\n - [Nasir Mushtaq](https://www.kaggle.com/nasirmushtaq773384)\n - [Naszy](https://www.kaggle.com/nasma1)\n - [Nat T](https://www.kaggle.com/natalieytan)\n - [Natalia](https://www.kaggle.com/natt77)\n - [Natalia](https://www.kaggle.com/nlyubova)\n - [Natalie Ha](https://www.kaggle.com/natalieh)\n - [Natasha Zope](https://www.kaggle.com/nata009)\n - [Natasha](https://www.kaggle.com/natashaevpak)\n - [Natasha](https://www.kaggle.com/natashasavc)\n - [Nate](https://www.kaggle.com/natehenderson)\n - [Nathan Burns](https://www.kaggle.com/nateofspades)\n - [Nathan Cohen](https://www.kaggle.com/propanon)\n - [Nathan Zhang](https://www.kaggle.com/oneespresso)\n - [Nathan](https://www.kaggle.com/nathanto)\n - [NathanGeorge](https://www.kaggle.com/wordsforthewise)\n - [Nathaniel See](https://www.kaggle.com/nathanielysee)\n - [National Archives](https://www.kaggle.com/nationalarchives)\n - [National Health Service](https://www.kaggle.com/nhs)\n - [National Institutes of Health Chest X-Ray Dataset](https://www.kaggle.com/nih-chest-xrays)\n - [National Library of Medicine](https://www.kaggle.com/nlm-nih)\n - [National Park Service](https://www.kaggle.com/nationalparkservice)\n - [National Snow and Ice Data Center](https://www.kaggle.com/nsidcorg)\n - [National UFO Reporting Center (NUFORC)](https://www.kaggle.com/NUFORC)\n - [Navdeep Pal](https://www.kaggle.com/navdeeppal)\n - [naveen holla](https://www.kaggle.com/naveenholla)\n - [Naveen Kumar](https://www.kaggle.com/naveenbanda)\n - [Naveen Pandian](https://www.kaggle.com/naveenpandianv)\n - [navneethc](https://www.kaggle.com/navneethc)\n - [NavyashreeS](https://www.kaggle.com/navyasudhakar)\n - [Nayan Bhattacharya](https://www.kaggle.com/nayan7631)\n - [Nayan solanki](https://www.kaggle.com/nayansolanki2411)\n - [Nazimamzz](https://www.kaggle.com/nazimamzz)\n - [NCAA](https://www.kaggle.com/ncaa)\n - [Ncls byr](https://www.kaggle.com/n3k0l6s)\n - [Neel Shah](https://www.kaggle.com/neelshah18)\n - [Neeraj Kasturi](https://www.kaggle.com/neerajkasturi)\n - [Neerav Kharche](https://www.kaggle.com/nkharche)\n - [neha singh](https://www.kaggle.com/n05011996)\n - [Neha](https://www.kaggle.com/neha1703)\n - [NeilS](https://www.kaggle.com/neilslab)\n - [neinei](https://www.kaggle.com/neinei)\n - [neKsdrawkcaB](https://www.kaggle.com/isbs39083)\n - [Nelson Chu](https://www.kaggle.com/nelsonchu)\n - [Nelson](https://www.kaggle.com/mu202199)\n - [Nema](https://www.kaggle.com/nemanema)\n - [Nerdiholic](https://www.kaggle.com/jnnerd)\n - [NetanelMalka](https://www.kaggle.com/netanel246)\n - [Netflix](https://www.kaggle.com/netflix-inc)\n - [NeuroGuy](https://www.kaggle.com/neuroguy)\n - [Never_die](https://www.kaggle.com/bahoury)\n - [New America](https://www.kaggle.com/newamerica)\n - [New York Philharmonic](https://www.kaggle.com/nyphil)\n - [New York Public Library](https://www.kaggle.com/nypl)\n - [newman](https://www.kaggle.com/newman123)\n - [Nguyen Tang Tri Duc](https://www.kaggle.com/mathormad)\n - [NHTSA](https://www.kaggle.com/nhtsa)\n - [nic](https://www.kaggle.com/nicw102168)\n - [Nicholas Zufelt](https://www.kaggle.com/zufelt)\n - [Nick DiGiulio](https://www.kaggle.com/ndigiulio)\n - [Nick Rose](https://www.kaggle.com/nsrose7224)\n - [Nick Schroeder](https://www.kaggle.com/imnickschroeder)\n - [Nick Spadafora](https://www.kaggle.com/spaddy08)\n - [Nick Torsky](https://www.kaggle.com/ntorsky)\n - [Nick Wagner](https://www.kaggle.com/monsieurwagner)\n - [Nick Wong](https://www.kaggle.com/nickwong64)\n - [NickAchin](https://www.kaggle.com/nja1019)\n - [NickSehy](https://www.kaggle.com/nicksehy)\n - [Niclas Kj\xc3\x83\xc2\xa4ll-Ohlsson](https://www.kaggle.com/niclasko)\n - [Nico Belov](https://www.kaggle.com/travelerspb)\n - [Nicol\xc3\x83\xc2\xa1s](https://www.kaggle.com/nidafra92)\n - [NicolaBernini](https://www.kaggle.com/nicolabernini)\n - [Nicolas P](https://www.kaggle.com/nepuerto)\n - [Nigel Dalziel](https://www.kaggle.com/ndalziel)\n - [nihal88](https://www.kaggle.com/nihal88)\n - [Nika Ioramishvili](https://www.kaggle.com/ioramishvili)\n - [Nikhil Akki](https://www.kaggle.com/akkithetechie)\n - [Nikhil Gargeya](https://www.kaggle.com/nikhil27gargeya)\n - [Nikhil Gupta](https://www.kaggle.com/nikhil04)\n - [Nikhil Jain](https://www.kaggle.com/jainnikhil)\n - [Nikhil Parihar](https://www.kaggle.com/nikhilparihar)\n - [Nikhil Reddy](https://www.kaggle.com/nikhi264)\n - [Nikhil](https://www.kaggle.com/nikhack16)\n - [nikhil](https://www.kaggle.com/nikhil5642)\n - [Nikita Malyshev](https://www.kaggle.com/mlshff)\n - [Nikunj](https://www.kaggle.com/nikunjm88)\n - [Nilesh Sakpal](https://www.kaggle.com/neiljs)\n - [Nilesh](https://www.kaggle.com/nacharya)\n - [Nils Ponomarchuk](https://www.kaggle.com/nils86)\n - [Nilzone](https://www.kaggle.com/nilzone)\n - [Ning Zhou](https://www.kaggle.com/edgedislocation)\n - [niniyan](https://www.kaggle.com/ni00ni)\n - [Nirajk18](https://www.kaggle.com/nirajkalantri99)\n - [Niranjan Nakkala](https://www.kaggle.com/niranjanmudhiraj)\n - [NiranjanDeshpande](https://www.kaggle.com/niranjan0272)\n - [Nirav Nikunj Patel](https://www.kaggle.com/niravdito)\n - [nirmalelumalai](https://www.kaggle.com/nirmalelumalai)\n - [NirmalyaKumarMohanty](https://www.kaggle.com/nkmlt31)\n - [Nishant ](https://www.kaggle.com/nishant88y)\n - [Nishant Arora](https://www.kaggle.com/nishanta)\n - [Nishant Bhadauria](https://www.kaggle.com/nishantbhadauria)\n - [Nishant K](https://www.kaggle.com/nishant4k)\n - [Nishant Kumar](https://www.kaggle.com/nishkgp)\n - [nishantjain](https://www.kaggle.com/nishantjain91)\n - [NISHIO Hirokazu](https://www.kaggle.com/nishio)\n - [Nishit Sehgal](https://www.kaggle.com/sehgalfuture)\n - [Nitesh Tiwari](https://www.kaggle.com/niteeshtiwari)\n - [NItesh Yadav](https://www.kaggle.com/niteshyadav)\n - [NiteshSurana](https://www.kaggle.com/nykebarz)\n - [Nitin Bisht](https://www.kaggle.com/nitsbat)\n - [Nitin Venkateswaran](https://www.kaggle.com/tundraman)\n - [nitishaadhikari](https://www.kaggle.com/nitishaadhikari)\n - [Niwech Harnkham](https://www.kaggle.com/niwech)\n - [Niyamat Ullah](https://www.kaggle.com/niyamatalmass)\n - [NLSpdX](https://www.kaggle.com/sport16dx)\n - [NLTK Data](https://www.kaggle.com/nltkdata)\n - [NMIN](https://www.kaggle.com/nicolasmin)\n - [No more overfitting ](https://www.kaggle.com/ngoquochung)\n - [No Re](https://www.kaggle.com/bearenon0743)\n - [NOAA](https://www.kaggle.com/noaa)\n - [Noah Gift](https://www.kaggle.com/noahgift)\n - [Noah Schwartz](https://www.kaggle.com/noahlumos)\n - [Noah Wang](https://www.kaggle.com/sunnywhj)\n - [Nodes](https://www.kaggle.com/uiuxwebdesign)\n - [Noel Yoo](https://www.kaggle.com/noelyoo)\n - [Nolan Conaway](https://www.kaggle.com/nolanbconaway)\n - [Nooh](https://www.kaggle.com/nuhsikander)\n - [NorbertBudincsevity](https://www.kaggle.com/budincsevity)\n - [NORC.org](https://www.kaggle.com/norc)\n - [Nosbielcs](https://www.kaggle.com/nosbielcs)\n - [Nowshin Nawar Arony](https://www.kaggle.com/nowshin01)\n - [NPO 2799](https://www.kaggle.com/npo2799)\n - [Nuggs](https://www.kaggle.com/ahmedelnaggar)\n - [Numerai](https://www.kaggle.com/numerai)\n - [Nupur Warke](https://www.kaggle.com/nupurw)\n - [Nuraddin](https://www.kaggle.com/sti18214046)\n - [Nur\xc3\x85\xc5\xb8en\xc3\x83\xe2\x80\x93\xc3\x84\xc5\xb8\xc3\x83\xc2\xbctveren](https://www.kaggle.com/nursen)\n - [NV27](https://www.kaggle.com/nvarganov)\n - [NYC Open Data](https://www.kaggle.com/nycopendata)\n - [NYC Parks and Recreation](https://www.kaggle.com/nycparks)\n - [NYPD](https://www.kaggle.com/nypd)\n - [\xc3\x98\xc2\xb9\xc3\x98\xc2\xa8\xc3\x98\xc2\xaf\xc3\x98\xc2\xa7\xc3\x99\xe2\x80\x9e\xc3\x99\xe2\x80\x9e\xc3\x98\xc2\xb7\xc3\x99\xc5\xa0\xc3\x99\xc2\x81\xc3\x98\xc2\xa3\xc3\x98\xc2\xad\xc3\x99\xe2\x80\xa6\xc3\x98\xc2\xaf\xc3\x98\xc2\xba\xc3\x99\xe2\x80\x9e\xc3\x98\xc2\xa7\xc3\x98\xc2\xa8](https://www.kaggle.com/ghallab1984)\n - [ObadiahJeshurenNaidoo](https://www.kaggle.com/acevanoj)\n - [obandoruben](https://www.kaggle.com/obandoruben)\n - [obey ismael](https://www.kaggle.com/obismey)\n - [Ocelot](https://www.kaggle.com/foxeared)\n - [OctavioG](https://www.kaggle.com/octaviog)\n - [OfayMailey](https://www.kaggle.com/nisi01)\n - [Oh InQueue](https://www.kaggle.com/gomjellie)\n - [Ohhm Prakash K I](https://www.kaggle.com/ohhmprakashki)\n - [Okus](https://www.kaggle.com/okuspokus)\n - [Ole Kr\xc3\x83\xc2\xb6ger](https://www.kaggle.com/wikunia)\n - [Oleg Brizhatiy](https://www.kaggle.com/brizol)\n - [Oleg O](https://www.kaggle.com/smeilz)\n - [OlegSolomka](https://www.kaggle.com/legomushroom)\n - [Oleksii Nidzelskyi](https://www.kaggle.com/onidzelskyi)\n - [Olga Belitskaya](https://www.kaggle.com/olgabelitskaya)\n - [Olga Ivanova ](https://www.kaggle.com/olgaiv39)\n - [Oliveira, L. O. V. B.](https://www.kaggle.com/oliveiralovb)\n - [Oliver Collins](https://www.kaggle.com/olivercollins)\n - [OliverMoralesLopez](https://www.kaggle.com/tivelos)\n - [olivia](https://www.kaggle.com/lsd0304hh)\n - [Olivier Richard](https://www.kaggle.com/olivri)\n - [olivier](https://www.kaggle.com/ogrellier)\n - [ololo](https://www.kaggle.com/agrigorev)\n - [Omajaykarthik](https://www.kaggle.com/omajaykarthik)\n - [Omar](https://www.kaggle.com/oxanderv)\n - [Omer Gozuacik](https://www.kaggle.com/ogozuacik)\n - [Omicron](https://www.kaggle.com/andromi)\n - [OmkarP](https://www.kaggle.com/omkar24)\n - [OnkarKadam](https://www.kaggle.com/onkarkadam)\n - [Onno Eberhard](https://www.kaggle.com/onnoeberhard)\n - [Onofrio_BIScience](https://www.kaggle.com/biaiscience)\n - [Open Food Facts](https://www.kaggle.com/openfoodfacts)\n - [Open Knowledge International](https://www.kaggle.com/okfn)\n - [Open Source Sports](https://www.kaggle.com/open-source-sports)\n - [Open Sourcing Mental Illness, LTD](https://www.kaggle.com/osmi)\n - [OpenAddresses](https://www.kaggle.com/openaddresses)\n - [OpenFlights](https://www.kaggle.com/open-flights)\n - [ophelia1234](https://www.kaggle.com/jratchford)\n - [OrCo](https://www.kaggle.com/orelcoh)\n - [Orges Leka](https://www.kaggle.com/orgesleka)\n - [OrgodolDawaasuren](https://www.kaggle.com/dawaasuren)\n - [orgrimm9](https://www.kaggle.com/bashit)\n - [Oscar Takeshita](https://www.kaggle.com/pliptor)\n - [Oscar Zamora](https://www.kaggle.com/oscarzapi)\n - [oscarleo](https://www.kaggle.com/oscarleo)\n - [ostrokach](https://www.kaggle.com/ostrokach)\n - [OSUBMI](https://www.kaggle.com/osubmi)\n - [Oswin Rahadiyan Hartono](https://www.kaggle.com/oswinrh)\n - [ouissa souliman](https://www.kaggle.com/souliman)\n - [ouyangxuan](https://www.kaggle.com/oyxuan)\n - [Owais](https://www.kaggle.com/owaisraza009)\n - [Ozan Aygun](https://www.kaggle.com/dataygun)\n - [ozgur](https://www.kaggle.com/ozgurb)\n - [P111110](https://www.kaggle.com/p111110)\n - [Pablo ](https://www.kaggle.com/pablorr10)\n - [Pablo Escobar](https://www.kaggle.com/pescobar)\n - [Pablo Tabales](https://www.kaggle.com/pablotab)\n - [PabloMonleon](https://www.kaggle.com/pablomonleon)\n - [Padmavathi R](https://www.kaggle.com/padma2590)\n - [paesibassi](https://www.kaggle.com/paesibassi)\n - [painkiller](https://www.kaggle.com/allenshi820)\n - [Pakshal Jain](https://www.kaggle.com/apletin)\n - [Palak Sharma](https://www.kaggle.com/palak29)\n - [PalashShah](https://www.kaggle.com/palashio)\n - [Pallav Routh](https://www.kaggle.com/pallavr)\n - [Pallavi Ramicetty](https://www.kaggle.com/pallaviroyal)\n - [Panagiotis G. Togias](https://www.kaggle.com/ptogias)\n - [panchicore](https://www.kaggle.com/panchicore)\n - [Pancho](https://www.kaggle.com/nathantunning)\n - [Panda974](https://www.kaggle.com/xfontaine)\n - [pandataDelta](https://www.kaggle.com/pandatadelta)\n - [Pandey Nilesh Prasad](https://www.kaggle.com/npd1211)\n - [Panos Kostakos](https://www.kaggle.com/panoskostakos)\n - [panos](https://www.kaggle.com/panosa)\n - [Panos](https://www.kaggle.com/panosc)\n - [Paolo Campanelli](https://www.kaggle.com/paololol)\n - [paolo](https://www.kaggle.com/paolop)\n - [paosheng](https://www.kaggle.com/paosheng)\n - [Parallax](https://www.kaggle.com/nikhilmudholkar)\n - [Paras Jindal](https://www.kaggle.com/parasjindal96)\n - [Paresh](https://www.kaggle.com/pareshkadoo)\n - [Parichart](https://www.kaggle.com/parichartpanichpol)\n - [Parindsheel Singh](https://www.kaggle.com/psdhillon)\n - [park thirty-two](https://www.kaggle.com/parksami)\n - [Parmanand Sahu](https://www.kaggle.com/analystanand)\n - [Parole Hearing Data Project](https://www.kaggle.com/parole-hearing-data)\n - [parseltung](https://www.kaggle.com/parselt)\n - [Parth Gupta](https://www.kaggle.com/parthgupta28)\n - [Parth Iramani](https://www.kaggle.com/iramaniparth)\n - [ParthMaheshwari](https://www.kaggle.com/parthm1801)\n - [Pascal Brenner](https://www.kaggle.com/pascalbrenner)\n - [Patatae](https://www.kaggle.com/patatae)\n - [Patit Pawan Karmakar](https://www.kaggle.com/patspk)\n - [Patrick Hyland](https://www.kaggle.com/patrickhyland)\n - [Patrick J](https://www.kaggle.com/patjob)\n - [Patrick Murphy](https://www.kaggle.com/patrickmurphy)\n - [Patryk Nied\xc3\x85\xc2\xbawiedzi\xc3\x85\xe2\x80\x9eski](https://www.kaggle.com/patrykn)\n - [Paul Abramshe](https://www.kaggle.com/sonicschnooze)\n - [Paul Curry](https://www.kaggle.com/marict)\n - [Paul Larmuseau](https://www.kaggle.com/plarmuseau)\n - [Paul Magda](https://www.kaggle.com/pmagda)\n - [Paul Rossotti](https://www.kaggle.com/pablote)\n - [Paul Schale](https://www.kaggle.com/pschale)\n - [Paul Tracey](https://www.kaggle.com/ptrace02)\n - [Paul Watt](https://www.kaggle.com/paulw8)\n - [Paul Yang](https://www.kaggle.com/paulyangsz)\n - [Paul-Louis Hery](https://www.kaggle.com/plhery)\n - [paul](https://www.kaggle.com/semakulapaul)\n - [Paula Ceccon](https://www.kaggle.com/pceccon)\n - [Paulo Henrique Vasconcellos](https://www.kaggle.com/paulovasconcellos)\n - [paultimothymooney](https://www.kaggle.com/paultimothymooney)\n - [PaulZH](https://www.kaggle.com/paulzh)\n - [pavansubhash](https://www.kaggle.com/pavansubhasht)\n - [PavelTroshenkov](https://www.kaggle.com/pavetr)\n - [Pavlin Bakalov](https://www.kaggle.com/kaiserbdevios)\n - [Pavlos Zitis](https://www.kaggle.com/pavlosz)\n - [pawan](https://www.kaggle.com/pawanyalla)\n - [Pazookii](https://www.kaggle.com/pazookii)\n - [pbcquoc](https://www.kaggle.com/phamquoc94)\n - [PCMiners](https://www.kaggle.com/pcminers)\n - [Pedro Lima](https://www.kaggle.com/pvlima)\n - [Pedro Velez](https://www.kaggle.com/pdvelez)\n - [PedroFrantz](https://www.kaggle.com/pafrantz)\n - [PengM(MySaturdaySelf)](https://www.kaggle.com/pengmei83)\n - [pengzha](https://www.kaggle.com/pengzha)\n - [People HR Analytics Repository](https://www.kaggle.com/HRAnalyticRepository)\n - [peppermintshake](https://www.kaggle.com/peppermintshake)\n - [perastikos](https://www.kaggle.com/perastikos)\n - [PerfectFit](https://www.kaggle.com/perfectfit)\n - [Peter Joseph Arienza](https://www.kaggle.com/parienza)\n - [Peter Klauke](https://www.kaggle.com/pepeeee)\n - [Peter Ostroukhov](https://www.kaggle.com/twelveth)\n - [Peter Wittek](https://www.kaggle.com/peterwittek)\n - [Peter Yang](https://www.kaggle.com/pacificyang)\n - [Peter](https://www.kaggle.com/guillp)\n - [Petit Ours](https://www.kaggle.com/yeqiang0428)\n - [pguptha](https://www.kaggle.com/pyennamp)\n - [phalaris](https://www.kaggle.com/devinanzelmo)\n - [phatgamer](https://www.kaggle.com/willwetzel)\n - [Philip Corr](https://www.kaggle.com/corrphilip)\n - [PhilipHarmuth](https://www.kaggle.com/harmuth)\n - [philipjames11](https://www.kaggle.com/philipjames11)\n - [Philipp Schmidt](https://www.kaggle.com/philschmidt)\n - [PhillipChin](https://www.kaggle.com/ekkus93)\n - [PhillipLiu](https://www.kaggle.com/phillipliu)\n - [Phung Van Hoa](https://www.kaggle.com/vanhoa)\n - [pickleChu](https://www.kaggle.com/meiyizi)\n - [pickou](https://www.kaggle.com/pickou)\n - [Pierre Sardin](https://www.kaggle.com/psardin)\n - [Piks Ral](https://www.kaggle.com/princyralaivao)\n - [PiperGragg](https://www.kaggle.com/pipergragg)\n - [pistachio_overlord](https://www.kaggle.com/myqrizzo)\n - [piyushgoyal443](https://www.kaggle.com/piyushgoyal443)\n - [piyushgupta](https://www.kaggle.com/piyusamp)\n - [pjmonti](https://www.kaggle.com/prashant3912)\n - [pkugoodspeed](https://www.kaggle.com/pkugoodspeed)\n - [PKylas](https://www.kaggle.com/pkylas)\n - [pmohun](https://www.kaggle.com/philmohun)\n - [Poetri Heriningtyas](https://www.kaggle.com/poetri)\n - [Polina Vakhrusheva](https://www.kaggle.com/polyav)\n - [Poorna](https://www.kaggle.com/poornapallela)\n - [Poornima Ravishankar](https://www.kaggle.com/poornimasai)\n - [PoornimaShanbhag](https://www.kaggle.com/poornimashanbhag)\n - [poquilia](https://www.kaggle.com/ines80)\n - [portia brat](https://www.kaggle.com/hahdawg)\n - [pourmehrab](https://www.kaggle.com/pourmehrab)\n - [Pradeep.narayanan](https://www.kaggle.com/pradeepp)\n - [Pradeep](https://www.kaggle.com/lookdeepu)\n - [PradeepKumar](https://www.kaggle.com/contactprad)\n - [Pragya Goyal](https://www.kaggle.com/pragya05)\n - [Prajit Datta](https://www.kaggle.com/prajitdatta)\n - [prajwal](https://www.kaggle.com/prajwalv94)\n - [Prakash Tiwary](https://www.kaggle.com/pctiwary)\n - [PrakashGawas](https://www.kaggle.com/gunners009)\n - [Prakhar Srivastava](https://www.kaggle.com/prakharsr)\n - [Prakriti Iyengar](https://www.kaggle.com/prakriti73)\n - [Pramit](https://www.kaggle.com/pramit1)\n - [Pramod Kumar](https://www.kaggle.com/pramodkumar8)\n - [Pramud](https://www.kaggle.com/pramud)\n - [Pranav](https://www.kaggle.com/thoughtcircle)\n - [Pranay Aryal](https://www.kaggle.com/speedoheck)\n - [Pranesh Kumar Palanisamy Padmavathy](https://www.kaggle.com/pashern)\n - [PranjalGandhi](https://www.kaggle.com/pg2457)\n - [pranstar](https://www.kaggle.com/pran93)\n - [Prasanna Nadimpalli](https://www.kaggle.com/dataswimmer)\n - [Prasanna steed](https://www.kaggle.com/prasanna9417)\n - [Prashant Singh Chauhan](https://www.kaggle.com/pchauhan13)\n - [Prashanth Poojary](https://www.kaggle.com/mprashanth73)\n - [Prashanth Sekar](https://www.kaggle.com/prashanth1994)\n - [prashanthsreepuram](https://www.kaggle.com/prashanthsr)\n - [Prateek Gupta](https://www.kaggle.com/iamprateek)\n - [Prateek Joshi](https://www.kaggle.com/pjoshi15)\n - [Prateik](https://www.kaggle.com/prateikmahendra)\n - [Pratibha Sharma](https://www.kaggle.com/pratibhasharma)\n - [PratibhaSharma](https://www.kaggle.com/pratizilla)\n - [Pratik Agrawal](https://www.kaggle.com/pratiksagrawal)\n - [Pratik K](https://www.kaggle.com/pk13055)\n - [Pratik Singh](https://www.kaggle.com/impratiksingh)\n - [Pratiksha Salimath](https://www.kaggle.com/psalimat)\n - [Pratiush Prasunn](https://www.kaggle.com/pratiush309)\n - [pravallika](https://www.kaggle.com/pravallika30)\n - [Pravesh_Ghorawat](https://www.kaggle.com/pravesh97)\n - [preeth kumar](https://www.kaggle.com/preeth)\n - [PreetSinghKhalsa](https://www.kaggle.com/bazuka)\n - [Prem Patrick](https://www.kaggle.com/prempatrick007)\n - [PreMon](https://www.kaggle.com/premamonish)\n - [PremTewari](https://www.kaggle.com/premtewari)\n - [Prince Grover](https://www.kaggle.com/grroverpr)\n - [priscilla](https://www.kaggle.com/prisro)\n - [Priya_ds](https://www.kaggle.com/priya2908)\n - [PriyaChowdary](https://www.kaggle.com/poojitha21)\n - [Priyaljain](https://www.kaggle.com/priyalj)\n - [Priyank Shah](https://www.kaggle.com/czar123)\n - [priyanka gagneja](https://www.kaggle.com/datageekpriyanka)\n - [Priyanka Kolli](https://www.kaggle.com/priyak19)\n - [priyanka Kukunuru](https://www.kaggle.com/prkukunoor)\n - [PriyanshJain](https://www.kaggle.com/priyanshj72)\n - [Progress Queens](https://www.kaggle.com/progressqueens)\n - [Project Jupyter](https://www.kaggle.com/jupyter)\n - [proland](https://www.kaggle.com/rolandp)\n - [PromphongBandhuvara](https://www.kaggle.com/boocertified)\n - [PromptCloud](https://www.kaggle.com/PromptCloudHQ)\n - [Pronto Cycle Share](https://www.kaggle.com/pronto)\n - [Properati Data](https://www.kaggle.com/properati-data)\n - [prvns](https://www.kaggle.com/singhpraveen)\n - [ps](https://www.kaggle.com/ps2811)\n - [psparks](https://www.kaggle.com/psparks)\n - [Pulkit Jha](https://www.kaggle.com/pappukrjha)\n - [PULKIT KHANDELWAL](https://www.kaggle.com/pulkit8595)\n - [puneet](https://www.kaggle.com/puneetbhaya)\n - [puneeth019](https://www.kaggle.com/puneeth019)\n - [Punxsutawney Groundhog Club](https://www.kaggle.com/groundhogclub)\n - [Purvank](https://www.kaggle.com/purvank)\n - [Pushkar Jain](https://www.kaggle.com/pushkar39)\n - [PushpendraPratap](https://www.kaggle.com/pushpendra7)\n - [pylyfe](https://www.kaggle.com/pylyfe)\n - [PythonMython](https://www.kaggle.com/pythonmython)\n - [PyTorch](https://www.kaggle.com/pytorch)\n - [Q82 Capital](https://www.kaggle.com/q82capital)\n - [QadeemKhan](https://www.kaggle.com/qadeemkhan)\n - [Qishen Ha](https://www.kaggle.com/haqishen)\n - [qixiang109](https://www.kaggle.com/qixiang109)\n - [qizheng](https://www.kaggle.com/yuqizheng)\n - [Quan Do](https://www.kaggle.com/qmdo97)\n - [Quan Nguyen](https://www.kaggle.com/quanbk)\n - [Quang Nguyen](https://www.kaggle.com/nhmquang)\n - [QuantScientist](https://www.kaggle.com/solomonk)\n - [Quentin Garnier](https://www.kaggle.com/ptitmoustique)\n - [Quentin Mouton](https://www.kaggle.com/moutov)\n - [QuinnCarver](https://www.kaggle.com/qcarver)\n - [Quoc Thang Nguyen](https://www.kaggle.com/victorythang113)\n - [quoniammm](https://www.kaggle.com/quoniammm)\n - [Quora](https://www.kaggle.com/quora)\n - [R.Venkatesh](https://www.kaggle.com/rvenkatesh2020)\n - [R1q3](https://www.kaggle.com/ruanqian)\n - [R\xc3\x85\xc2\x8f\xc3\x85\xc2\xa9K\xc3\x84\xc2\xa9\xc3\x84\xe2\x80\xa6](https://www.kaggle.com/csroukia)\n - [raam](https://www.kaggle.com/raam93)\n - [Raaz](https://www.kaggle.com/raaz181)\n - [Rachael Tatman](https://www.kaggle.com/rtatman)\n - [Rachit Sapra](https://www.kaggle.com/rachit72)\n - [Rachit Srivastava](https://www.kaggle.com/rachit1307)\n - [RadociechBubuSierakowski](https://www.kaggle.com/bubu89)\n - [Radu Stoicescu](https://www.kaggle.com/radustoicescu)\n - [Rafael Novello](https://www.kaggle.com/rafanovello)\n - [Rafal Cycon (blaine)](https://www.kaggle.com/rafalcycon)\n - [RafflesiaKhan](https://www.kaggle.com/rafflesia)\n - [Raghavi](https://www.kaggle.com/raghavi9607)\n - [RaghuReddy](https://www.kaggle.com/raghu07)\n - [Rahi](https://www.kaggle.com/braintickle)\n - [Rahul Bagga](https://www.kaggle.com/rahulbagga)\n - [rahul batham](https://www.kaggle.com/rahulbthm46)\n - [Rahul Chaudhary](https://www.kaggle.com/rahulxc1)\n - [rahul kumar](https://www.kaggle.com/rahulin05)\n - [rahul patil](https://www.kaggle.com/rrp170330)\n - [Rahul Sathyajit](https://www.kaggle.com/rahulsathyajit)\n - [rahul](https://www.kaggle.com/rahul897)\n - [Rahul](https://www.kaggle.com/sroohul656)\n - [RahulBhambri](https://www.kaggle.com/rbhambri)\n - [RahulMayuranath](https://www.kaggle.com/kedi96)\n - [RahulVerma](https://www.kaggle.com/smugglaz)\n - [Raihan Kibria](https://www.kaggle.com/rkibria)\n - [Rainey](https://www.kaggle.com/rainey)\n - [Raj Sharma](https://www.kaggle.com/therajsharma)\n - [RajaGanapathy](https://www.kaggle.com/rganapathy)\n - [Rajanand Ilangovan / \xc3\xa0\xc2\xae\xe2\x80\xa1\xc3\xa0\xc2\xae\xc2\xb0\xc3\xa0\xc2\xae\xc2\xbe\xc3\xa0\xc2\xae\xc5\x93\xc3\xa0\xc2\xaf\xc2\x8d\xc3\xa0\xc2\xae\xe2\x80\xa0\xc3\xa0\xc2\xae\xc2\xa9\xc3\xa0\xc2\xae\xc2\xa8\xc3\xa0\xc2\xaf\xc2\x8d\xc3\xa0\xc2\xae\xc2\xa4\xc3\xa0\xc2\xaf\xc2\x8d \xc3\xa0\xc2\xae\xe2\x80\xa1\xc3\xa0\xc2\xae\xc2\xb3\xc3\xa0\xc2\xae\xe2\x84\xa2\xc3\xa0\xc2\xaf\xc2\x8d\xc3\xa0\xc2\xae\xe2\x80\xa2\xc3\xa0\xc2\xaf\xe2\x80\xb9\xc3\xa0\xc2\xae\xc2\xb5\xc3\xa0\xc2\xae\xc2\xa9\xc3\xa0\xc2\xaf\xc2\x8d](https://www.kaggle.com/rajanand)\n - [Rajasankar Viswanathan](https://www.kaggle.com/rajasankar)\n - [rajat arora](https://www.kaggle.com/rajatarora)\n - [Rajat Sharma](https://www.kaggle.com/rajatiitg)\n - [Rajeev kumar ](https://www.kaggle.com/john2195)\n - [Rajeev](https://www.kaggle.com/rajeevmeda)\n - [rajesh kumar](https://www.kaggle.com/kumar012)\n - [RAJESH PURWAR](https://www.kaggle.com/rajeshpurwar)\n - [RajeshM](https://www.kaggle.com/codingnirvana)\n - [Rajiv Jeeva](https://www.kaggle.com/rajivjeeva)\n - [Rajmund Mokso](https://www.kaggle.com/rajmund)\n - [Rajorshi Chaudhuri](https://www.kaggle.com/knight079)\n - [RajSekhar](https://www.kaggle.com/rajasekhardodda)\n - [Raju Alluri](https://www.kaggle.com/rajualluri)\n - [RakanNimer](https://www.kaggle.com/rakannimer)\n - [Rakesh Raushan](https://www.kaggle.com/rakeshrau)\n - [RakeshSk](https://www.kaggle.com/skrakesh5)\n - [Rakuraku](https://www.kaggle.com/rakuraku678)\n - [RalicLo](https://www.kaggle.com/raliclo)\n - [Ram Ramrakhya](https://www.kaggle.com/axel81)\n - [Ramakrishnan Srinivasan](https://www.kaggle.com/toramky)\n - [ramamet](https://www.kaggle.com/ramamet4)\n - [Ramanujam Allam](https://www.kaggle.com/anjuram25)\n - [Ramesh](https://www.kaggle.com/grameshbabu)\n - [Ramiro](https://www.kaggle.com/ramirobmar)\n - [ramirobentes](https://www.kaggle.com/ramirobentes)\n - [RamNemani](https://www.kaggle.com/ramnemani)\n - [Randy Betancourt](https://www.kaggle.com/PythonforSASUsers)\n - [Ranjan Kumar](https://www.kaggle.com/ranjan73)\n - [Ranjit kumar](https://www.kaggle.com/ranjit5600)\n - [RanjithaKorrapati](https://www.kaggle.com/ranjitha1)\n - [Ranjithkumar M](https://www.kaggle.com/rkmunusamy)\n - [Rapha\xc3\x83\xc2\xablMontaud](https://www.kaggle.com/raphboss)\n - [Raphael](https://www.kaggle.com/elraphabr)\n - [Raquel Aoki](https://www.kaggle.com/rysaoki)\n - [Rashid Ali](https://www.kaggle.com/rashidali)\n - [Rashid Khan](https://www.kaggle.com/rashidallama)\n - [Rashmi Singh Chauhan](https://www.kaggle.com/singhchauhan)\n - [RatnaChowdary](https://www.kaggle.com/ratna364)\n - [Raul](https://www.kaggle.com/racu10)\n - [Ravali](https://www.kaggle.com/ravaliraj)\n - [Ravi Rokhade](https://www.kaggle.com/ravirk66)\n - [Ravi Verma](https://www.kaggle.com/machinoai)\n - [Ravi](https://www.kaggle.com/kavinotravi)\n - [ravi](https://www.kaggle.com/ravi12344)\n - [RaviBhalala](https://www.kaggle.com/ravibhalala217)\n - [Ravichandra Malapati](https://www.kaggle.com/malapatiravi)\n - [RaviJain](https://www.kaggle.com/ravijain056)\n - [RaviKiran](https://www.kaggle.com/ravikiran378)\n - [Ravin ](https://www.kaggle.com/ravin0512)\n - [Ravindra Kompella](https://www.kaggle.com/kmsravindra)\n - [Ray](https://www.kaggle.com/raford2)\n - [rayen](https://www.kaggle.com/rayenkhayat)\n - [Raymond Delord](https://www.kaggle.com/raymos)\n - [RaymondMak](https://www.kaggle.com/makray)\n - [raysar](https://www.kaggle.com/raysar)\n - [Razib Mustafiz](https://www.kaggle.com/razibmustafiz)\n - [RBakes](https://www.kaggle.com/bakesril)\n - [Rcaer](https://www.kaggle.com/rcavelino)\n - [rdayala](https://www.kaggle.com/rdayala)\n - [RDizzl3](https://www.kaggle.com/rdizzl3)\n - [Reason Foundation](https://www.kaggle.com/reason-foundation)\n - [rechards](https://www.kaggle.com/rechards)\n - [Recruit Institute of Technology](https://www.kaggle.com/ritresearch)\n - [Reddit](https://www.kaggle.com/reddit)\n - [RedRegressor](https://www.kaggle.com/salilchitnis)\n - [REE_](https://www.kaggle.com/zhenzhouren)\n - [Regis Nunes Vargas](https://www.kaggle.com/regisnv)\n - [Reinhard](https://www.kaggle.com/reisel)\n - [Remi Myers](https://www.kaggle.com/rmyersapco)\n - [Renata Barros](https://www.kaggle.com/renatabarros)\n - [RenzoRamirez](https://www.kaggle.com/freshrenzo)\n - [Retailrocket](https://www.kaggle.com/retailrocket)\n - [Reynald Riviere](https://www.kaggle.com/reynaldriviere)\n - [Reza Agung Pambudi](https://www.kaggle.com/rezaagungpambudi)\n - [Reza Javidi](https://www.kaggle.com/javidimail)\n - [Reza Katebi](https://www.kaggle.com/rezakatebi)\n - [REZA](https://www.kaggle.com/reza2866)\n - [rhammell](https://www.kaggle.com/rhammell)\n - [rhishikesh nepal](https://www.kaggle.com/rhishikesh)\n - [RhitamjeetSaharia](https://www.kaggle.com/rhitamjeet)\n - [Rhostam](https://www.kaggle.com/rhostam)\n - [Ri_Nandiya](https://www.kaggle.com/nandiya)\n - [Ricardo Moya](https://www.kaggle.com/ricardomoya)\n - [Ricardo Suarez](https://www.kaggle.com/ricardosuarez)\n - [Ricardo Zuccolo](https://www.kaggle.com/rzuccolo)\n - [Riccardo Bongiovanni](https://www.kaggle.com/rbonjovi)\n - [Riccardo Miccini](https://www.kaggle.com/miccio)\n - [Riccardo Nizzolo](https://www.kaggle.com/riccardonizzolo)\n - [Richa Gautam](https://www.kaggle.com/gautamricha)\n - [Richard Churchill](https://www.kaggle.com/rschurchill)\n - [Richard Gu](https://www.kaggle.com/guchenghao)\n - [Richard Nagyfi](https://www.kaggle.com/sedthh)\n - [richard](https://www.kaggle.com/richardbebin)\n - [RichardBJ](https://www.kaggle.com/richardbj)\n - [RichardNguyen](https://www.kaggle.com/richardnguyen)\n - [Rick Chen](https://www.kaggle.com/ddongchen)\n - [rickvenadata](https://www.kaggle.com/rickvenadata)\n - [Ricky](https://www.kaggle.com/zurfer)\n - [RickyMak](https://www.kaggle.com/rmak230)\n - [rickysaurav](https://www.kaggle.com/rickysaurav)\n - [Ridhi Adyanthaya](https://www.kaggle.com/ridhiadyanthaya)\n - [Rini](https://www.kaggle.com/rinivabini)\n - [Rio 2016](https://www.kaggle.com/rio2016)\n - [Rippon](https://www.kaggle.com/ripponmangaraj)\n - [Riri](https://www.kaggle.com/rharrak)\n - [Rishab Gargeya](https://www.kaggle.com/rishabg)\n - [Rishabh Kumar Jha](https://www.kaggle.com/rishabhkumarjha)\n - [Rishabh Mishra](https://www.kaggle.com/soulreaper328)\n - [Rishi Anand](https://www.kaggle.com/rishianand)\n - [Rishi Sankineni](https://www.kaggle.com/rishisankineni)\n - [RishiBarath](https://www.kaggle.com/rb1181)\n - [riti ](https://www.kaggle.com/ritidata)\n - [RitikaJain](https://www.kaggle.com/nobody404)\n - [RITUSHARMA15BCE1347](https://www.kaggle.com/ritusharma8124)\n - [River](https://www.kaggle.com/rsnively)\n - [Riyas](https://www.kaggle.com/riyasvk)\n - [rjcampa](https://www.kaggle.com/rjcampa)\n - [rjl2155](https://www.kaggle.com/richardjameslopez)\n - [RM](https://www.kaggle.com/rmtest)\n - [rmsda2](https://www.kaggle.com/rmsda2)\n - [Roam Analytics](https://www.kaggle.com/roamresearch)\n - [Rob Harrand](https://www.kaggle.com/tentotheminus9)\n - [Rob Wishart](https://www.kaggle.com/robwishart)\n - [Robbert Manders](https://www.kaggle.com/robbertmanders)\n - [RobbieS](https://www.kaggle.com/robbies)\n - [Robert Hargraves](https://www.kaggle.com/dataharg)\n - [Robert Nolan](https://www.kaggle.com/robertnolan)\n - [Robert Wexler](https://www.kaggle.com/rwexler)\n - [Roberto Sousa](https://www.kaggle.com/ominivac)\n - [Roberto Spadim](https://www.kaggle.com/rspadim)\n - [Roberto Williams](https://www.kaggle.com/robbat1)\n - [Robin E. Masliah](https://www.kaggle.com/robmaslh)\n - [Robin Nicole](https://www.kaggle.com/robinnicolem)\n - [Robin Praet](https://www.kaggle.com/robinpraet)\n - [RobinReni](https://www.kaggle.com/robinreni)\n - [robotcator](https://www.kaggle.com/robotcator)\n - [rocha](https://www.kaggle.com/rochachan)\n - [Rock Pereira](https://www.kaggle.com/rockp1)\n - [RockBottom](https://www.kaggle.com/rockbottom73)\n - [Rodrigo Ancavil](https://www.kaggle.com/rancavil)\n - [Rodrigo Domingos](https://www.kaggle.com/rodrigodomingos)\n - [Rodrigo Ramele](https://www.kaggle.com/rramele)\n - [Rodrigo Salas](https://www.kaggle.com/rsalaschile)\n - [Rodrigo](https://www.kaggle.com/crdias)\n - [Roel van den Boom](https://www.kaggle.com/roelvdboom)\n - [roger](https://www.kaggle.com/roger1315)\n - [Rogerio Lopes](https://www.kaggle.com/rglopes)\n - [RogierMonshouwer](https://www.kaggle.com/rogier2012)\n - [Rohan Kale](https://www.kaggle.com/rohankale)\n - [Rohan Kayan](https://www.kaggle.com/rohankayan)\n - [Rohan Patel](https://www.kaggle.com/rohan8594)\n - [Rohit Sharma](https://www.kaggle.com/rohitx007)\n - [Rohit Singh](https://www.kaggle.com/rhtsingh)\n - [RohithRPai](https://www.kaggle.com/rohithpai)\n - [RohitMathur](https://www.kaggle.com/rohitmathur100)\n - [Rohk](https://www.kaggle.com/therohk)\n - [Roi Shikler](https://www.kaggle.com/roishik)\n - [rojour](https://www.kaggle.com/rojour)\n - [Rolandas \xc3\x85\xc2\xa0imkus](https://www.kaggle.com/rolandassimkus)\n - [Rolando P. Aguirre](https://www.kaggle.com/rpaguirre)\n - [Romain Loiseau](https://www.kaggle.com/romainloiseau)\n - [Romain LOURY](https://www.kaggle.com/rloury)\n - [romainvincent](https://www.kaggle.com/romainvincent)\n - [Roman Akhunov](https://www.kaggle.com/romanakhunov)\n - [Roman Semenyk](https://www.kaggle.com/laurlct)\n - [Roman](https://www.kaggle.com/netroman)\n - [RomitDhamija](https://www.kaggle.com/romitdhamija)\n - [Romy](https://www.kaggle.com/romy25)\n - [Ron Graf](https://www.kaggle.com/ronaldjgrafjr)\n - [Ron Leplae](https://www.kaggle.com/rleplae)\n - [Ronald Troncoso](https://www.kaggle.com/ronaldtroncoso20)\n - [rongruosong](https://www.kaggle.com/rongruosong)\n - [ronnie](https://www.kaggle.com/rohandx1996)\n - [Ronny Kimathi kaimenyi](https://www.kaggle.com/ronnykym)\n - [Rony Lussari](https://www.kaggle.com/ronylussari)\n - [RoopaliKaujalgi](https://www.kaggle.com/roopalik)\n - [Rosanaider](https://www.kaggle.com/rosado)\n - [rosegao](https://www.kaggle.com/rosegao)\n - [Roselyn Kinuthia](https://www.kaggle.com/rkinuthia)\n - [RoshaanKhan](https://www.kaggle.com/khanrm2)\n - [Roshan](https://www.kaggle.com/roshan1986)\n - [Rounak Banik](https://www.kaggle.com/rounakbanik)\n - [roundedup](https://www.kaggle.com/roundedup)\n - [rovilayjnr](https://www.kaggle.com/rovilayjnr)\n - [Roy Garrard](https://www.kaggle.com/noriuk)\n - [Roy Kiran](https://www.kaggle.com/royalrk)\n - [Roy Klaasse Bos](https://www.kaggle.com/royklaassebos)\n - [RoyWWilson](https://www.kaggle.com/smedleykagnovitch)\n - [RoyXss](https://www.kaggle.com/royxss)\n - [RpyGamer](https://www.kaggle.com/rpygamer)\n - [RShorty30](https://www.kaggle.com/rshorty30)\n - [Rudd Fawcett](https://www.kaggle.com/ruddfawcett)\n - [Ruhshan](https://www.kaggle.com/ruhshan)\n - [Rui Romanini](https://www.kaggle.com/ruiromanini)\n - [ruijie li](https://www.kaggle.com/liruijie4)\n - [Ruishen Lyu](https://www.kaggle.com/lruishen)\n - [Rumen Manev](https://www.kaggle.com/rmanev)\n - [rupali](https://www.kaggle.com/rupalish)\n - [Rush Kirubi](https://www.kaggle.com/rush4ratio)\n - [Ruslan Khalitov](https://www.kaggle.com/ruslankhalitov)\n - [Ruslan](https://www.kaggle.com/luckysturr)\n - [Rutuj Gavankar](https://www.kaggle.com/rutujsg)\n - [Ryan Bain](https://www.kaggle.com/cocowaffle)\n - [Ryan Buck](https://www.kaggle.com/stravinsky)\n - [Ryan Chang](https://www.kaggle.com/juiyangchang)\n - [Ryan Cushen](https://www.kaggle.com/rcushen)\n - [Ryan Epp](https://www.kaggle.com/reppic)\n - [Ryan Harrison](https://www.kaggle.com/rrharrison90)\n - [Ryan Li](https://www.kaggle.com/statikk)\n - [Ryan Sloot](https://www.kaggle.com/rsloot)\n - [Ryan](https://www.kaggle.com/snarfed)\n - [RyanHuang](https://www.kaggle.com/ryan88)\n - [RyanLott](https://www.kaggle.com/greygoo)\n - [RyoOgata](https://www.kaggle.com/ryoogata)\n - [RyuJiseung](https://www.kaggle.com/lsk7421)\n - [ryvolum](https://www.kaggle.com/ryvolum)\n - [S Sakarin](https://www.kaggle.com/sangcrazy4)\n - [S. Zotos](https://www.kaggle.com/szotos)\n - [s.ayadi](https://www.kaggle.com/salemayadi)\n - [S.S. Tarek](https://www.kaggle.com/heavymetalrebel)\n - [S1M0N38](https://www.kaggle.com/s1m0n38)\n - [S\xc3\x83\xc2\xa9bastien Aroulanda](https://www.kaggle.com/paladeur)\n - [S\xc3\x83\xc2\xa9bastien MATHIEU](https://www.kaggle.com/negtitep)\n - [S\xc3\x83\xc2\xa9bastien Pouilly](https://www.kaggle.com/sebwdz)\n - [saagie_anthony](https://www.kaggle.com/anthobau)\n - [sab30226](https://www.kaggle.com/sab30226)\n - [Sabber Ahamed](https://www.kaggle.com/msahamed)\n - [Sabyasachi](https://www.kaggle.com/sabysachi)\n - [SachGupta](https://www.kaggle.com/sachgupta)\n - [Sachiemon](https://www.kaggle.com/sachiemon)\n - [Sachin Kalsi](https://www.kaggle.com/sachinkalsi)\n - [Sachin Patel](https://www.kaggle.com/sachinpatel21)\n - [sachinumrao](https://www.kaggle.com/sachin1512)\n - [SadhanaSingh](https://www.kaggle.com/sadhanasingh)\n - [Safecast](https://www.kaggle.com/safecast)\n - [Sagar Sarkar](https://www.kaggle.com/sagarsarkar043)\n - [Sagarnil Das](https://www.kaggle.com/sagarnildass)\n - [SagarSen](https://www.kaggle.com/sagarsen)\n - [Sahil Gandhi](https://www.kaggle.com/sahilgandhi94)\n - [Sai C](https://www.kaggle.com/nsaikn)\n - [Sai Pranav](https://www.kaggle.com/saipranava)\n - [Saida Antonyan](https://www.kaggle.com/saidaantonyan)\n - [saigonapps](https://www.kaggle.com/saigonapps)\n - [saikiran](https://www.kaggle.com/jellasaikiran)\n - [SaiKumar](https://www.kaggle.com/sailsk)\n - [Saimagesh R](https://www.kaggle.com/saimageshr)\n - [sainath](https://www.kaggle.com/sainathreddy)\n - [Saiprasad](https://www.kaggle.com/sunmoon)\n - [Sajal](https://www.kaggle.com/sajalkumar)\n - [Sajid](https://www.kaggle.com/noobchef)\n - [SakinaDas](https://www.kaggle.com/sakinadas)\n - [SakthiSiva](https://www.kaggle.com/sakthisiva)\n - [Sakti Prasad](https://www.kaggle.com/spn007)\n - [Salil Gautam](https://www.kaggle.com/salil007)\n - [Salim Dohri](https://www.kaggle.com/cythun)\n - [SalimChouai](https://www.kaggle.com/salim94)\n - [salmanpathan](https://www.kaggle.com/salmanasylum)\n - [Salomon](https://www.kaggle.com/dollarbillio)\n - [SalvadorDali](https://www.kaggle.com/salvadordali)\n - [Sam Edelstein](https://www.kaggle.com/samedelstein)\n - [Sam Harris](https://www.kaggle.com/samharris)\n - [sam komo](https://www.kaggle.com/samson22)\n - [Sam Shideler](https://www.kaggle.com/sjshide)\n - [Sam Stonesifer](https://www.kaggle.com/sds5578)\n - [Sam Wong](https://www.kaggle.com/shwong)\n - [samael](https://www.kaggle.com/emcmii)\n - [SambitSekhar](https://www.kaggle.com/sambit7)\n - [samdeeplearning](https://www.kaggle.com/samdeeplearning)\n - [SamDotson](https://www.kaggle.com/samdotson)\n - [Sameer Mahajan](https://www.kaggle.com/sameersmahajan)\n - [Sameer](https://www.kaggle.com/sameerqayyum)\n - [Sami Rahman](https://www.kaggle.com/samirahman)\n - [SamiraKlaylat](https://www.kaggle.com/suso172)\n - [SamiTabet](https://www.kaggle.com/stabet)\n - [Sammy Klasfeld](https://www.kaggle.com/sklasfeld)\n - [sammy123](https://www.kaggle.com/sammy123)\n - [Samrat](https://www.kaggle.com/samratp)\n - [Samriddhi Sinha](https://www.kaggle.com/djokester)\n - [Samuel Longwell](https://www.kaggle.com/thebirdofhermes)\n - [Samuel](https://www.kaggle.com/slucomb)\n - [Samyak Jain](https://www.kaggle.com/samyak3098)\n - [SanD](https://www.kaggle.com/sandipdatta)\n - [Sandeep Kumar](https://www.kaggle.com/sanbelief)\n - [Sandeep](https://www.kaggle.com/sdalvi)\n - [SandeepRamesh](https://www.kaggle.com/sandeep04201988)\n - [SandeepYadav](https://www.kaggle.com/sandeepyadav007)\n - [sandhya raghavan](https://www.kaggle.com/raghavansandhya)\n - [Sandra Cristina Bustos Galvis](https://www.kaggle.com/sanbuga)\n - [sandrarivera](https://www.kaggle.com/sandrarivera)\n - [Sandro Marcelo Peirano Gozalvez](https://www.kaggle.com/ordnas)\n - [sandsp](https://www.kaggle.com/sandsp)\n - [Sandy HE](https://www.kaggle.com/sandyhe)\n - [SangamVerma](https://www.kaggle.com/vermasangam)\n - [Sangeetha Sasikumar](https://www.kaggle.com/sangeetha007)\n - [sanjay kushwah](https://www.kaggle.com/sanjaykushwah)\n - [Sanjaya Wijeratne](https://www.kaggle.com/sanjayaw)\n - [Sanjeet Kumar Yadav](https://www.kaggle.com/sanjeet41)\n - [Sanjeev Upreti](https://www.kaggle.com/sanjeevupreti)\n - [Sanket Kumar](https://www.kaggle.com/sk9000)\n - [Santa Meilisa](https://www.kaggle.com/smeilisa07)\n - [SanthoshMurali](https://www.kaggle.com/sanedhika)\n - [SantiagoVazquezGomez](https://www.kaggle.com/siryago)\n - [Santosh Boina](https://www.kaggle.com/santoshb183)\n - [Sanyam](https://www.kaggle.com/sanyammehta)\n - [Saqib Mujtaba](https://www.kaggle.com/saqibmujtaba)\n - [Sara G. Mille](https://www.kaggle.com/saramille)\n - [Sarah Adsit](https://www.kaggle.com/sea5238)\n - [Sarah VCH](https://www.kaggle.com/sarahvch)\n - [SarahZ](https://www.kaggle.com/xzhang159)\n - [Sarai Rosenberg](https://www.kaggle.com/saraislet)\n - [Saravanan B](https://www.kaggle.com/sarvasub)\n - [Saravanan Jaichandar](https://www.kaggle.com/saranchandar)\n - [sariya](https://www.kaggle.com/dssariya)\n - [sarra zammit chatti](https://www.kaggle.com/sarraz)\n - [sarthak nautiyal](https://www.kaggle.com/sarthaknautiyal)\n - [sarubhava](https://www.kaggle.com/sarukaggle)\n - [Sasan Jafarnejad](https://www.kaggle.com/sasanj)\n - [sash](https://www.kaggle.com/sashchernuh)\n - [sasi](https://www.kaggle.com/venkatakumar81)\n - [Saswata Das](https://www.kaggle.com/sasd3107)\n - [satadru5](https://www.kaggle.com/satadru5)\n - [Satavisha Mitra](https://www.kaggle.com/satavisham)\n - [satheeshperepu](https://www.kaggle.com/satheesh841)\n - [Sathu79](https://www.kaggle.com/sathutr)\n - [Satish Karivedha](https://www.kaggle.com/karivedha)\n - [Satish Tiwari](https://www.kaggle.com/satishtiwari23)\n - [Satya Patel](https://www.kaggle.com/satya05)\n - [Satyaki Banik](https://www.kaggle.com/satyakibanik)\n - [satyasai](https://www.kaggle.com/krishnasai)\n - [SaudAl-Zakwani](https://www.kaggle.com/szakwani)\n - [saurabh singh](https://www.kaggle.com/saurabh00007)\n - [Saurabh Singh](https://www.kaggle.com/saurabh13nov)\n - [Saurabh](https://www.kaggle.com/skhemka)\n - [SaurabhBhagvatula](https://www.kaggle.com/saurabhbhagvatula)\n - [saurav ghosh](https://www.kaggle.com/sauravghosh)\n - [Saurav Kumar](https://www.kaggle.com/saurabhkmr707)\n - [SAURAV SUMAN](https://www.kaggle.com/tastelesswine)\n - [Sauro Grandi](https://www.kaggle.com/saurograndi)\n - [savannahlogan](https://www.kaggle.com/savannahvi)\n - [SavasY\xc3\x84\xc2\xb1ld\xc3\x84\xc2\xb1r\xc3\x84\xc2\xb1m](https://www.kaggle.com/savasy)\n - [Savioz](https://www.kaggle.com/savioz)\n - [sawayaka](https://www.kaggle.com/sawayaka)\n - [Saxinou](https://www.kaggle.com/saxinou)\n - [SazidurRahman](https://www.kaggle.com/sazid28)\n - [SciELO](https://www.kaggle.com/scieloorg)\n - [Scott A. Miller](https://www.kaggle.com/smiller933)\n - [Scott Cole](https://www.kaggle.com/srcole)\n - [Scott](https://www.kaggle.com/pippey)\n - [Scott](https://www.kaggle.com/sfennell)\n - [Scottfree Analytics LLC](https://www.kaggle.com/scottfree)\n - [ScottHendrickson](https://www.kaggle.com/scotth64)\n - [sdorius](https://www.kaggle.com/sdorius)\n - [SeaGoat](https://www.kaggle.com/vbandaru)\n - [Seagullbird](https://www.kaggle.com/seagullbird)\n - [Sean Kelley](https://www.kaggle.com/seangtkelley)\n - [Sean Marjason](https://www.kaggle.com/mrmarjo)\n - [Sean Saito](https://www.kaggle.com/saitosean)\n - [Sean](https://www.kaggle.com/seannn)\n - [SeanKim](https://www.kaggle.com/yuzuri)\n - [SeanLahman](https://www.kaggle.com/seanlahman)\n - [Seattle Public Library](https://www.kaggle.com/seattle-public-library)\n - [Sebastian Mantey](https://www.kaggle.com/sebastianmantey)\n - [Sebastian](https://www.kaggle.com/sebastianp)\n - [sebastianmarkow](https://www.kaggle.com/sebastianmarkow)\n - [SebastianZanabria](https://www.kaggle.com/seussz)\n - [Securities and Exchange Commission](https://www.kaggle.com/securities-exchange-commission)\n - [security3test](https://www.kaggle.com/security3test)\n - [securityteamvictim4](https://www.kaggle.com/securityteamvictim4)\n - [Seetharam Indurti](https://www.kaggle.com/seetzz)\n - [Sekar M G](https://www.kaggle.com/sekarmg)\n - [Selah](https://www.kaggle.com/selahlynch)\n - [Selfish Gene](https://www.kaggle.com/selfishgene)\n - [selvakumar](https://www.kaggle.com/selvakumarvr)\n - [Semin](https://www.kaggle.com/eliotyoon)\n - [SemionKorchevskiy](https://www.kaggle.com/semioniy)\n - [Seong-Jae Chu](https://www.kaggle.com/saychuwho)\n - [SEPTA](https://www.kaggle.com/septa)\n - [Serena Chen](https://www.kaggle.com/y578chen)\n - [Sergei Fironov](https://www.kaggle.com/sergeifironov)\n - [Sergey Kosterin](https://www.kaggle.com/skosterin88)\n - [Sergey Kuznetsov](https://www.kaggle.com/mousehead)\n - [Sergey](https://www.kaggle.com/devorvant)\n - [SergeyA](https://www.kaggle.com/sergeya)\n - [Sergio GQ](https://www.kaggle.com/sergioalbertogq)\n - [SergioGonzalez](https://www.kaggle.com/sergiogq)\n - [SergioPerez](https://www.kaggle.com/sergioperez)\n - [Sergiy Chumachenko](https://www.kaggle.com/chumachenkosergiy)\n - [Serhiy Subota](https://www.kaggle.com/subota)\n - [Serigne ](https://www.kaggle.com/serigne)\n - [SeungHyun Jeon](https://www.kaggle.com/towever)\n - [sevaspb](https://www.kaggle.com/sevaspb)\n - [seyvar](https://www.kaggle.com/seyvar)\n - [SGDE](https://www.kaggle.com/adsa00sgde)\n - [sgDysregulation](https://www.kaggle.com/sophieg)\n - [SH Lee](https://www.kaggle.com/bigshushu)\n - [shabeer](https://www.kaggle.com/pshabeerm)\n - [Shabu KC](https://www.kaggle.com/shabukc)\n - [Shahebaz](https://www.kaggle.com/shaz13)\n - [SHAHUMANGKAMLESHBHAI15BCE1303](https://www.kaggle.com/umangshah97)\n - [Shaik Kamran](https://www.kaggle.com/shaikkamran3)\n - [Shakaed Subin](https://www.kaggle.com/subinshakaed)\n - [Shakti Sharma](https://www.kaggle.com/shaktisharma)\n - [Shakti](https://www.kaggle.com/shaktirajput)\n - [ShalvaRai16MCB0025](https://www.kaggle.com/shalv16mcb0025)\n - [Shams ul arfeen](https://www.kaggle.com/shamsularfeen)\n - [shan](https://www.kaggle.com/shan4224)\n - [Shan](https://www.kaggle.com/shanmugasundarammk)\n - [Shane Smith](https://www.kaggle.com/smid80)\n - [Shang Pengxu](https://www.kaggle.com/shangpx)\n - [Shanger Lin](https://www.kaggle.com/mic771112)\n - [ShaniGershtein](https://www.kaggle.com/sgershtein)\n - [Shankar](https://www.kaggle.com/shankarpandala)\n - [ShantamVijayputra](https://www.kaggle.com/vshantam)\n - [Shantanu Acharya](https://www.kaggle.com/shanwizard)\n - [Shantanu](https://www.kaggle.com/shantanuladhwe)\n - [Shanth](https://www.kaggle.com/shanth84)\n - [Sharadhi V](https://www.kaggle.com/sharadhiv)\n - [Sharan Naribole](https://www.kaggle.com/nsharan)\n - [sharddha](https://www.kaggle.com/sharddha)\n - [Sharon Lin](https://www.kaggle.com/sharonlin)\n - [Shashank ](https://www.kaggle.com/shashankpathak2015)\n - [Shashank Kumar](https://www.kaggle.com/shashank12)\n - [Shashank Shekhar Shukla](https://www.kaggle.com/shashank2011)\n - [Shashank Yadav](https://www.kaggle.com/shashank1558)\n - [ShashankNainwal](https://www.kaggle.com/clayman1)\n - [Shatiel](https://www.kaggle.com/shatiel)\n - [ShaunakChadha](https://www.kaggle.com/hanumanstark)\n - [Shaurya Munshi](https://www.kaggle.com/mshaurya)\n - [Shaurya Munshi](https://www.kaggle.com/shauryamunshi)\n - [ShauryaChawla](https://www.kaggle.com/emorres25)\n - [Shawn Tian](https://www.kaggle.com/zuckgo)\n - [Shayenne Moura](https://www.kaggle.com/shayenne)\n - [Shazad Udwadia](https://www.kaggle.com/shazadudwadia)\n - [Sheik Mohamed Imran](https://www.kaggle.com/imrandude)\n - [Sheikh Asif Imran Shouborno](https://www.kaggle.com/strawhats)\n - [Sheil Naik](https://www.kaggle.com/sheilnaik)\n - [Sheng Guo](https://www.kaggle.com/anyezijue49)\n - [shengwei](https://www.kaggle.com/syushengwei)\n - [shenjiawei](https://www.kaggle.com/shenjiawei)\n - [Sherry_CS](https://www.kaggle.com/sherrycs)\n - [Shihao](https://www.kaggle.com/pulchritudinous)\n - [Shikhar](https://www.kaggle.com/shikhar1)\n - [shilpibhattacharyya](https://www.kaggle.com/shilpibhattacharyya)\n - [shilpitha](https://www.kaggle.com/shilpitha)\n - [shiMu](https://www.kaggle.com/ddongjian0001)\n - [Shiny](https://www.kaggle.com/shinydhar)\n - [shirley](https://www.kaggle.com/shirleyw)\n - [ShiSanCD](https://www.kaggle.com/shisancd)\n - [Shishir](https://www.kaggle.com/shisnir)\n - [Shitao Zeng](https://www.kaggle.com/hjkhjk)\n - [shiv gehlot](https://www.kaggle.com/shivml89)\n - [Shiv Santosh](https://www.kaggle.com/shivsj)\n - [Shiva Manhar](https://www.kaggle.com/shivamanhar)\n - [ShivajiAlaparthi](https://www.kaggle.com/shivaji9999)\n - [Shivam Panchal](https://www.kaggle.com/shivampanchal)\n - [Shivam Patel](https://www.kaggle.com/shivamp629)\n - [Shivam Patel](https://www.kaggle.com/spatel4140)\n - [shivamagrawal](https://www.kaggle.com/shivam2503)\n - [ShivamGoel](https://www.kaggle.com/sg1791)\n - [shivamnijhawan](https://www.kaggle.com/shivamnijhawan96)\n - [ShivinderKapil](https://www.kaggle.com/shivinder)\n - [shodiq](https://www.kaggle.com/shodiqmh)\n - [ShradhaJoshi](https://www.kaggle.com/shradhapj)\n - [Shreeya Bhosale](https://www.kaggle.com/shreeyabhosale)\n - [Shreyams Jain](https://www.kaggle.com/shreyams)\n - [ShreyasSomashekara](https://www.kaggle.com/shreyas0906)\n - [shrihans giriraj meena](https://www.kaggle.com/shrihans)\n - [ShruthiShankar](https://www.kaggle.com/shruthi2512)\n - [Shruti Bhargava](https://www.kaggle.com/shrutibhargava94)\n - [Shubham ](https://www.kaggle.com/slimshady19)\n - [Shubham Barudwale](https://www.kaggle.com/barudwale20)\n - [Shubham Deshmukh](https://www.kaggle.com/shubham619)\n - [SHUBHAM KARANDE](https://www.kaggle.com/shubham17mcb1015)\n - [ShubhamAgarwal](https://www.kaggle.com/shubhamagarwal269)\n - [ShubhamMaurya](https://www.kaggle.com/mauryashubham)\n - [ShubhamPawar](https://www.kaggle.com/shubhmamp)\n - [ShubhamThakur](https://www.kaggle.com/sythakur)\n - [shubhangi](https://www.kaggle.com/shubhangi)\n - [Shuchi](https://www.kaggle.com/shuchirb)\n - [Shuhei Fujiwara](https://www.kaggle.com/sfujiwara)\n - [Shunpoco](https://www.kaggle.com/shunsuke313320)\n - [SHUNYA](https://www.kaggle.com/rahul3321)\n - [shuwenz](https://www.kaggle.com/shuwenz)\n - [Shwet Prakash](https://www.kaggle.com/shwetp)\n - [shweta](https://www.kaggle.com/sk12190n)\n - [shwetabh123](https://www.kaggle.com/shwetabh123)\n - [sibappa](https://www.kaggle.com/sibappa)\n - [sichunlam](https://www.kaggle.com/sichunlam)\n - [Sid Shetty](https://www.kaggle.com/iamsidshetty)\n - [Siddartha](https://www.kaggle.com/siddarthareddyt)\n - [Siddhanth VInay](https://www.kaggle.com/sidvin97)\n - [siddhartha sharan](https://www.kaggle.com/siddharthasharan)\n - [Siddhartha](https://www.kaggle.com/meaninglesslives)\n - [SidG](https://www.kaggle.com/cheedcheed)\n - [sidhant](https://www.kaggle.com/sidhanta)\n - [SidhantDeka](https://www.kaggle.com/sidhant09)\n - [siero](https://www.kaggle.com/siero5335)\n - [SiewKamOnn](https://www.kaggle.com/kosiew)\n - [Siim M](https://www.kaggle.com/kedokedokedo)\n - [Sijo VM](https://www.kaggle.com/sijovm)\n - [silicon99](https://www.kaggle.com/silicon99)\n - [Silogram](https://www.kaggle.com/psilogram)\n - [Silvio Santana](https://www.kaggle.com/silviosantana)\n - [Simo](https://www.kaggle.com/simn93)\n - [Simon Asiimwe](https://www.kaggle.com/asimonp)\n - [Simon Fraser University - Summit](https://www.kaggle.com/sfu-summit)\n - [Simon Gurcke](https://www.kaggle.com/itssimon)\n - [Simon Plovyt](https://www.kaggle.com/simonplovyt)\n - [Simon Tse](https://www.kaggle.com/ghostintheshell)\n - [Simon](https://www.kaggle.com/shuofxz)\n - [Simon](https://www.kaggle.com/simonprevoteaux)\n - [Simon](https://www.kaggle.com/swwintels)\n - [Simone Seregni](https://www.kaggle.com/ssersim)\n - [SimoneDalessio](https://www.kaggle.com/sdalessio)\n - [SimonRazniewski](https://www.kaggle.com/srazniewski)\n - [Sindhu Rao](https://www.kaggle.com/raosindhu)\n - [Sirish](https://www.kaggle.com/sirishamatya)\n - [Siva Kumar](https://www.kaggle.com/dsivakumar)\n - [Siva Swaminathan](https://www.kaggle.com/subraminion)\n - [SiyuanH](https://www.kaggle.com/siyuanh)\n - [SIZZLE](https://www.kaggle.com/SIZZLE)\n - [skakki](https://www.kaggle.com/skakki)\n - [Skalldihor](https://www.kaggle.com/skalldihor)\n - [SkalskiP](https://www.kaggle.com/skalskip)\n - [Skiddie](https://www.kaggle.com/deftskiddie)\n - [SkyLord](https://www.kaggle.com/skylord)\n - [sleight82](https://www.kaggle.com/sleight82)\n - [Smart Revolution](https://www.kaggle.com/cetingzhou)\n - [smeschke](https://www.kaggle.com/smeschke)\n - [smota](https://www.kaggle.com/santiagomota)\n - [sna](https://www.kaggle.com/shoaib)\n - [Snehaa Ganesan](https://www.kaggle.com/gsnehaa21)\n - [snehanshusengupta](https://www.kaggle.com/snehanshu17)\n - [SnehaReddy](https://www.kaggle.com/snehareddy5)\n - [Snow Dog](https://www.kaggle.com/snowdog)\n - [snow2011](https://www.kaggle.com/ilyaivanchenko)\n - [Sofiya](https://www.kaggle.com/sofiyag87)\n - [Sohaib Ali](https://www.kaggle.com/sohaibali)\n - [SohaibOmar](https://www.kaggle.com/sohaibomar)\n - [Soham Patel](https://www.kaggle.com/sohamshp)\n - [sohel](https://www.kaggle.com/sohelhasan)\n - [Sohier Dane](https://www.kaggle.com/sohier)\n - [SohiniBhattacharya](https://www.kaggle.com/sohinibhattacharya86)\n - [Somasundaram Sankaranaraynan](https://www.kaggle.com/somasundaram0504)\n - [somesh](https://www.kaggle.com/somesh)\n - [Sommenoob](https://www.kaggle.com/yang727)\n - [Somnath Roy](https://www.kaggle.com/roysomnath93)\n - [Son Genacrys](https://www.kaggle.com/songenacrys)\n - [Sonali Chawla](https://www.kaggle.com/sona58)\n - [SonamSrivastava](https://www.kaggle.com/sonaam1234)\n - [Song WanG](https://www.kaggle.com/swang215)\n - [soojung](https://www.kaggle.com/csjcsj7477)\n - [soorajms](https://www.kaggle.com/smsubrahmannian)\n - [soroosh](https://www.kaggle.com/sorooshnazem)\n - [Sotopia](https://www.kaggle.com/bakrianoo)\n - [Soufiane Fhiyil](https://www.kaggle.com/soufianefhy95)\n - [soufianeorama](https://www.kaggle.com/soufianeorama)\n - [souhaiel](https://www.kaggle.com/souhaiel)\n - [Souhail Toumdi](https://www.kaggle.com/soutou)\n - [Soukaina](https://www.kaggle.com/soukiii)\n - [Souman Roy](https://www.kaggle.com/souman)\n - [Soumitra Agarwal](https://www.kaggle.com/artimous)\n - [SourabhMittal](https://www.kaggle.com/srbhmitt)\n - [Sourav Nandi](https://www.kaggle.com/souravstat)\n - [Sourav Roy](https://www.kaggle.com/souravroy1)\n - [Sourav Verma](https://www.kaggle.com/srgrace)\n - [SouravMaharana](https://www.kaggle.com/srvmaharana)\n - [SovBoc2018](https://www.kaggle.com/sovannt)\n - [sowhit](https://www.kaggle.com/saisowhit)\n - [Sowmiya Nagarajan](https://www.kaggle.com/codess)\n - [soywu](https://www.kaggle.com/soywugzm)\n - [SpaceX](https://www.kaggle.com/spacex)\n - [Spencer Buja](https://www.kaggle.com/csbuja)\n - [Spider Pig](https://www.kaggle.com/apartmentguru)\n - [sprabakar](https://www.kaggle.com/sprabakar)\n - [Sreeram Reddy Kasarla (SRK16113)](https://www.kaggle.com/ksr102631)\n - [Sreyansh Jain](https://www.kaggle.com/sreyanshjain)\n - [sri charan](https://www.kaggle.com/dgscharan)\n - [Sri Kamma](https://www.kaggle.com/funnelai)\n - [SRI KANTH](https://www.kaggle.com/srikanthkon21)\n - [Sri Manjusha](https://www.kaggle.com/srimanjushatella)\n - [Sri Santhosh Hari](https://www.kaggle.com/srisanthoshhari)\n - [sridhar narasaiahgari](https://www.kaggle.com/sridharnarasaiahgari)\n - [Sridhar](https://www.kaggle.com/sridar1803)\n - [Srihari Vasudevan](https://www.kaggle.com/sriharivasu)\n - [SrihariRao](https://www.kaggle.com/sriharirao)\n - [Srilakshmi](https://www.kaggle.com/srilakshminagesh)\n - [srilakshminandamuri](https://www.kaggle.com/nandamuri)\n - [SriLBG](https://www.kaggle.com/srilbg)\n - [Srinath Sridharan](https://www.kaggle.com/srinath2648)\n - [SrinivasRao](https://www.kaggle.com/srinivas1)\n - [SriniVinnakota](https://www.kaggle.com/srinivinnakota)\n - [SRK](https://www.kaggle.com/sudalairajkumar)\n - [Ssvitian](https://www.kaggle.com/ssvitian)\n - [Stack Overflow](https://www.kaggle.com/stackoverflow)\n - [Stan](https://www.kaggle.com/stan2517)\n - [Stanford Network Analysis Project ](https://www.kaggle.com/snap)\n - [Stanford Open Policing Project](https://www.kaggle.com/stanford-open-policing)\n - [Stanford University](https://www.kaggle.com/stanfordu)\n - [Starbucks](https://www.kaggle.com/starbucks)\n - [starconf](https://www.kaggle.com/starinconf)\n - [starmine.ai](https://www.kaggle.com/biomimic)\n - [START Consortium](https://www.kaggle.com/START-UMD)\n - [Startup Policy Lab](https://www.kaggle.com/startuppolicylab)\n - [stawary](https://www.kaggle.com/stawary)\n - [steal](https://www.kaggle.com/tbsteal)\n - [SteeveHuang](https://www.kaggle.com/huangkh19951228)\n - [Stefanie04736](https://www.kaggle.com/stefanie04736)\n - [Stephan Andre](https://www.kaggle.com/sandreds)\n - [Stephan Wessels](https://www.kaggle.com/slwessels)\n - [Stephane Bernadac](https://www.kaggle.com/sbernadac)\n - [Stephanerappeneau](https://www.kaggle.com/stephanerappeneau)\n - [Stephanie Le Grange](https://www.kaggle.com/slegra78)\n - [Stephen Cranney](https://www.kaggle.com/scranney)\n - [Stephen Huan](https://www.kaggle.com/vazarum)\n - [Stephen McGlennon](https://www.kaggle.com/srmcglennon)\n - [Stephen Thompson](https://www.kaggle.com/coffeenmusic)\n - [Stephen](https://www.kaggle.com/sbrady)\n - [StephRouen](https://www.kaggle.com/stephrouen)\n - [Steve Ahn](https://www.kaggle.com/dsteveahn)\n - [Steve Joly](https://www.kaggle.com/sjoly123)\n - [Steve Palley](https://www.kaggle.com/stevepalley)\n - [Steven Venezie](https://www.kaggle.com/svenezie)\n - [SteveN](https://www.kaggle.com/sniafas)\n - [Steven](https://www.kaggle.com/stevenknguyen)\n - [Stoddy](https://www.kaggle.com/jwstodd)\n - [stonepurple](https://www.kaggle.com/stonepurple)\n - [Streichholz](https://www.kaggle.com/aihsani)\n - [Stuart Chan](https://www.kaggle.com/stuart002)\n - [Stuart Colianni](https://www.kaggle.com/scolianni)\n - [stytch](https://www.kaggle.com/stytch16)\n - [Styven Ponnusamy](https://www.kaggle.com/styven)\n - [SubarnaRana](https://www.kaggle.com/subarnarana1)\n - [Subham Das](https://www.kaggle.com/subhamdas)\n - [Subhransu Sekhar Sahoo](https://www.kaggle.com/subhransuss)\n - [Submarineering](https://www.kaggle.com/submarineering)\n - [Subra](https://www.kaggle.com/nssubramanya)\n - [Suchit Gupta](https://www.kaggle.com/suchitgupta60)\n - [Sudarshan](https://www.kaggle.com/sdevkota007)\n - [Sudeepta Kkr](https://www.kaggle.com/skr912)\n - [Sudheej Sudhakaran](https://www.kaggle.com/sudheej)\n - [Sudheer Sankar](https://www.kaggle.com/sudheersankar)\n - [Sudhir Thuppale](https://www.kaggle.com/sudhirtk)\n - [Sudip Das](https://www.kaggle.com/sudipdas)\n - [Suhel](https://www.kaggle.com/suhelm)\n - [Sujan Ghimire](https://www.kaggle.com/sujanme)\n - [sujan](https://www.kaggle.com/sujanpokharel)\n - [Sujay Khandagale](https://www.kaggle.com/sujaykhandagale)\n - [Sujith](https://www.kaggle.com/samuelsujith)\n - [sujithramkotagiri](https://www.kaggle.com/ksujithram)\n - [Sulata Patra](https://www.kaggle.com/anshilata)\n - [sultan](https://www.kaggle.com/sultanmkhan)\n - [sumanth](https://www.kaggle.com/sumanthpola)\n - [SumanthSRao](https://www.kaggle.com/sumanthrao)\n - [sumendar](https://www.kaggle.com/sumendar)\n - [Sumit Bhongale](https://www.kaggle.com/sumithbhongale)\n - [Sumit Kant](https://www.kaggle.com/sumitkant)\n - [Sumit Kothari](https://www.kaggle.com/usersumit)\n - [Sumit Kumar](https://www.kaggle.com/sirpunch)\n - [Sumit](https://www.kaggle.com/sumit9)\n - [SunDai](https://www.kaggle.com/friday20121221)\n - [SuneetSawant](https://www.kaggle.com/suneet94)\n - [Sungpil Han](https://www.kaggle.com/shanmdphd)\n - [Sunil Kumar SV](https://www.kaggle.com/sunilkumarsv)\n - [Sunil Neurgaonkar](https://www.kaggle.com/sunilneurgaonkar)\n - [Sunil Sethi](https://www.kaggle.com/sunilsethi25)\n - [sunilp](https://www.kaggle.com/sunilp)\n - [sunmarkil](https://www.kaggle.com/sunmarkil)\n - [SuperDave](https://www.kaggle.com/superdave)\n - [Suprabhat Tiwari](https://www.kaggle.com/suprabhat)\n - [Suprabhat Tiwari](https://www.kaggle.com/suprabhatt)\n - [SupriyaDubey](https://www.kaggle.com/priyasd)\n - [Surabhi](https://www.kaggle.com/surabhitomer)\n - [Suraj](https://www.kaggle.com/surajcet)\n - [SurajPathak](https://www.kaggle.com/freesuraj)\n - [Suresh Bhusare](https://www.kaggle.com/sureshbhusare)\n - [SureshSrinivas](https://www.kaggle.com/sureshsrinivas)\n - [SuryaSista](https://www.kaggle.com/sistasp)\n - [Susan Noboa](https://www.kaggle.com/snoboay)\n - [Susan Wang](https://www.kaggle.com/rabbitsusan)\n - [susanna](https://www.kaggle.com/susannayangcao)\n - [sushant ](https://www.kaggle.com/sushant120)\n - [Sushant jha](https://www.kaggle.com/sushantjha8)\n - [Susmitha](https://www.kaggle.com/susmithamanda)\n - [Sustainable Development Solutions Network](https://www.kaggle.com/unsdsn)\n - [Svidon](https://www.kaggle.com/svidon)\n - [Swami Krishnamurthy](https://www.kaggle.com/nathsri1983)\n - [Swapnil](https://www.kaggle.com/swapni1)\n - [swapnilkale](https://www.kaggle.com/swappyk)\n - [SwaroopVenigalla](https://www.kaggle.com/swaroopvenigalla)\n - [Swathi Priyadarsini ](https://www.kaggle.com/kswathipriya)\n - [swati](https://www.kaggle.com/kianswati)\n - [Swatish Swaminathan](https://www.kaggle.com/swatish)\n - [Swayam Mittal](https://www.kaggle.com/swayammittal65)\n - [Sweety ](https://www.kaggle.com/sweetyparmar1)\n - [SwetaAgrawal](https://www.kaggle.com/swetaagrawal)\n - [Sylas](https://www.kaggle.com/jsylas)\n - [Sylvia Mittal](https://www.kaggle.com/sylvia23)\n - [Szery](https://www.kaggle.com/szerus)\n - [Szkript](https://www.kaggle.com/szkript)\n - [szrlee](https://www.kaggle.com/szrlee)\n - [T Byrnes](https://www.kaggle.com/tbyrnes)\n - [T McKetterick](https://www.kaggle.com/tmcketterick)\n - [T Michaels](https://www.kaggle.com/tommichaels)\n - [T Peng](https://www.kaggle.com/tzp5165)\n - [T. Scharf](https://www.kaggle.com/scharf)\n - [T](https://www.kaggle.com/tudor9)\n - [T7 - Pokemon Challenge](https://www.kaggle.com/terminus7)\n - [TadashiNagao](https://www.kaggle.com/zanjibar)\n - [Taffey Lewis](https://www.kaggle.com/taffeylewis)\n - [Taha Zerrouki](https://www.kaggle.com/linuxscout)\n - [Tahsin Mayeesha](https://www.kaggle.com/mayeesha)\n - [TaichiWang](https://www.kaggle.com/taichi53719)\n - [Taimur Khan](https://www.kaggle.com/taimurkhan)\n - [TaiwoO.Adetiloye](https://www.kaggle.com/taiwotman)\n - [Taka](https://www.kaggle.com/taka152)\n - [takuoko](https://www.kaggle.com/takuok)\n - [Tamber](https://www.kaggle.com/tamber)\n - [Tamil Dhoni](https://www.kaggle.com/tamilarasu75)\n - [Tamilselvan Sudalai](https://www.kaggle.com/tamilsud)\n - [Tammy Rotem](https://www.kaggle.com/tammyrotem)\n - [Tan Kinh Bui](https://www.kaggle.com/tankinhbui)\n - [Tang Yiming](https://www.kaggle.com/tymatfd)\n - [tanishk parihar](https://www.kaggle.com/tan305)\n - [tankeestka](https://www.kaggle.com/tankeestka)\n - [TANYA MAKKAR ](https://www.kaggle.com/tanyamakkar123)\n - [T\xc3\x83\xc2\xba Anh Ho\xc3\x83\xc2\xa0ng](https://www.kaggle.com/hoangtuanh1805)\n - [Tara Rutkowski](https://www.kaggle.com/taradaqtal)\n - [Taraprasanna Saha Babu](https://www.kaggle.com/sahababu)\n - [Taras](https://www.kaggle.com/ustyk5)\n - [tarek benkhelif](https://www.kaggle.com/tarekbenkhelif)\n - [Tarun Khanna](https://www.kaggle.com/tennispro1213)\n - [TARUN KUMAR](https://www.kaggle.com/tarunkumar)\n - [tdougherty223](https://www.kaggle.com/tdougherty223)\n - [Team AI](https://www.kaggle.com/team-ai)\n - [Team PuppyGoGo](https://www.kaggle.com/puppygogo)\n - [techmn](https://www.kaggle.com/techmn)\n - [teck44""><](https://www.kaggle.com/teck44)\n - [tecperson](https://www.kaggle.com/datamunge)\n - [TehreemAnsari](https://www.kaggle.com/tehreem)\n - [tejasvagarwal](https://www.kaggle.com/tejasvdante)\n - [Temilade Adefioye Aina](https://www.kaggle.com/apttemi)\n - [Teng Lei](https://www.kaggle.com/nichaoku)\n - [Teodosiy](https://www.kaggle.com/openaimaniac)\n - [TeraFlops](https://www.kaggle.com/sekrier)\n - [TerenceLiu](https://www.kaggle.com/terenceliu4444)\n - [Terminal Security Agency](https://www.kaggle.com/terminal-security-agency)\n - [test ""><img src=x onerror=alert(document.domain)>](https://www.kaggle.com/buggyguy)\n - [test""><img src=x>](https://www.kaggle.com/test123654)\n - [test](https://www.kaggle.com/rajauzairabdullah)\n - [test](https://www.kaggle.com/strukt)\n - [test2""><](https://www.kaggle.com/tona9900)\n - [testaccountkagglee](https://www.kaggle.com/testaccountkagglee)\n - [testbugmasooddd](https://www.kaggle.com/testbugmasooddd)\n - [tester](https://www.kaggle.com/hkpow2)\n - [TESTIMON @ NTNU](https://www.kaggle.com/ntnu-testimon)\n - [testingshi](https://www.kaggle.com///facebook.com)\n - [TetianaMyronivska](https://www.kaggle.com/mtetiana)\n - [TetyanaLoskutova](https://www.kaggle.com/tetyanal)\n - [TetyanaYatsenko](https://www.kaggle.com/tetyanayatsenko)\n - [TEVEC Systems](https://www.kaggle.com/tevecsystems)\n - [Thais Rodrigues Neubauer](https://www.kaggle.com/thaisneubauer)\n - [thaisalmeida](https://www.kaggle.com/thaisalmeida)\n - [Thanakom Sangnetra](https://www.kaggle.com/thanakomsn)\n - [thanuj](https://www.kaggle.com/thanuj11)\n - [Thao](https://www.kaggle.com/vuthao)\n - [Tharini Padmagirisan](https://www.kaggle.com/tharini)\n - [The Bear](https://www.kaggle.com/saramahar)\n - [The BGU Cyber Security Research Center](https://www.kaggle.com/BGU-CSRC)\n - [The Fellow](https://www.kaggle.com/ardenn)\n - [The Flying Munkey](https://www.kaggle.com/theflyingmunkey)\n - [The Guardian](https://www.kaggle.com/the-guardian)\n - [The Huffington Post](https://www.kaggle.com/huffingtonpost)\n - [The Marshall Project](https://www.kaggle.com/marshallproject)\n - [The Metropolitan Museum of Art](https://www.kaggle.com/metmuseum)\n - [The Movie Database (TMDb)](https://www.kaggle.com/tmdb)\n - [The Museum of Modern Art](https://www.kaggle.com/momanyc)\n - [The Nobel Foundation](https://www.kaggle.com/nobelfoundation)\n - [The Smithsonian Institution](https://www.kaggle.com/smithsonian)\n - [The Wall Street Journal](https://www.kaggle.com/wsj)\n - [The Washington Post](https://www.kaggle.com/washingtonpost)\n - [the1owl](https://www.kaggle.com/the1owl)\n - [Theo Ioa](https://www.kaggle.com/codeteo)\n - [TheScientistBR](https://www.kaggle.com/TheScientistBR)\n - [thetraderrr](https://www.kaggle.com/thetraderrr)\n - [Theudas](https://www.kaggle.com/theudas)\n - [Thiago Balbo](https://www.kaggle.com/thibalbo)\n - [Thiago Oliveira](https://www.kaggle.com/pintowar)\n - [Thinh Uy Quang](https://www.kaggle.com/takahirotachi)\n - [THIRU MAALAVAN](https://www.kaggle.com/thirumaalavan)\n - [Thobani Hlophe](https://www.kaggle.com/thobani)\n - [Thomas De Jonghe](https://www.kaggle.com/jinxbe)\n - [Thomas Nelson](https://www.kaggle.com/thomasnelson)\n - [Thomas Pappas](https://www.kaggle.com/tpapp157)\n - [Thomas Ranvier](https://www.kaggle.com/thomasranvier)\n - [Thomas Wade Culbertson](https://www.kaggle.com/ugnix911aalc)\n - [Thomas](https://www.kaggle.com/thomasd9)\n - [ThomasLuby](https://www.kaggle.com/bluehorseshoe)\n - [ThomasVoreyer](https://www.kaggle.com/tvoreyer)\n - [THORODINOVICH](https://www.kaggle.com/thorinhood)\n - [Thought Vector](https://www.kaggle.com/thoughtvector)\n - [throne1032](https://www.kaggle.com/throne1032)\n - [ThuanHieu](https://www.kaggle.com/thuanhieu147)\n - [Thulani Tembo](https://www.kaggle.com/thulani96)\n - [Tiago V. Melo](https://www.kaggle.com/tiagovmelo)\n - [Tiago Vinhoza](https://www.kaggle.com/tiagotvv)\n - [Tiantian](https://www.kaggle.com/tiantianchen76)\n - [Tianyi Wang](https://www.kaggle.com/tianyiwang)\n - [Tigran Davtyan](https://www.kaggle.com/tigran97)\n - [Tilak](https://www.kaggle.com/tilakd)\n - [Tim Hradil](https://www.kaggle.com/timhradil)\n - [Tim Kartawijaya](https://www.kaggle.com/timkartawijaya)\n - [Tim Pearce](https://www.kaggle.com/trpearce)\n - [Time Magazine](https://www.kaggle.com/timemagazine)\n - [Timo Bozsolik](https://www.kaggle.com/timoboz)\n - [Timothy Leung](https://www.kaggle.com/timleunghk)\n - [TimRu](https://www.kaggle.com/timrus)\n - [timsyang](https://www.kaggle.com/timschutzyang)\n - [Ting Zhou](https://www.kaggle.com/ztlevi)\n - [tiredgeek](https://www.kaggle.com/tiredgeek)\n - [TirthGajjar](https://www.kaggle.com/tirthgajjar)\n - [Tito Maraca](https://www.kaggle.com/elyisu)\n - [tivoli2](https://www.kaggle.com/tivoli2)\n - [Tiziano Teso](https://www.kaggle.com/tesotiziano)\n - [Tjb5670](https://www.kaggle.com/tjb5670)\n - [TK](https://www.kaggle.com/tttkkk)\n - [tmthyjames](https://www.kaggle.com/tmthyjames)\n - [TobeyStrauch](https://www.kaggle.com/tobey1)\n - [toby jolly](https://www.kaggle.com/teajay)\n - [Tolu Toluhi](https://www.kaggle.com/toluoverscore)\n - [Tom Bombadil](https://www.kaggle.com/haixili2007)\n - [Tom Hill](https://www.kaggle.com/thomill)\n - [Tom\xc3\x83\xc2\xa1s Accini](https://www.kaggle.com/tomasaccini)\n - [Tom\xc3\x83\xc2\xa1s Bustamante](https://www.kaggle.com/bustamantejt)\n - [Tomasz Bartczak](https://www.kaggle.com/kretes)\n - [Tomato](https://www.kaggle.com/kebabdk400)\n - [Tomer Eldor](https://www.kaggle.com/tomerel)\n - [Tomi-Andre](https://www.kaggle.com/tomiandrep)\n - [tommert](https://www.kaggle.com/tommert)\n - [Tommy Pompo](https://www.kaggle.com/tpompo)\n - [TomNeeld](https://www.kaggle.com/tomneeld)\n - [Tomo](https://www.kaggle.com/dosukoi)\n - [Tony Pino](https://www.kaggle.com/anthonypino)\n - [Tony Xie](https://www.kaggle.com/tonyxie)\n - [TonyChan](https://www.kaggle.com/tonychanyt)\n - [tophatsteve](https://www.kaggle.com/tophatsteve)\n - [torr](https://www.kaggle.com/ayush01)\n - [Toshnoue](https://www.kaggle.com/toshinoue)\n - [TP](https://www.kaggle.com/tharindraparanagama)\n - [traceyvanp](https://www.kaggle.com/traceyvanp)\n - [tranndo](https://www.kaggle.com/tranndo)\n - [Transparency International](https://www.kaggle.com/transparencyint)\n - [Trent Baur](https://www.kaggle.com/trentbaur)\n - [Trey Kollmer](https://www.kaggle.com/treykollmer)\n - [TripleFireYan](https://www.kaggle.com/yansun1996)\n - [Trond Magne Lamprecht Haaland](https://www.kaggle.com/trondmagne)\n - [TruMedicines](https://www.kaggle.com/trumedicines)\n - [Truong An](https://www.kaggle.com/ancs21)\n - [Truth Lover](https://www.kaggle.com/tjtong)\n - [tsimins](https://www.kaggle.com/tsiresi)\n - [Tuhin Saha](https://www.kaggle.com/tuhinsaha84)\n - [Tung Thanh Le](https://www.kaggle.com/ttungl)\n - [tusha kutusha](https://www.kaggle.com/aradzhabov)\n - [Tushar Dhyani](https://www.kaggle.com/thanatoz)\n - [Tushar Gupta](https://www.kaggle.com/tushar987)\n - [Tushar Mahendra Patil](https://www.kaggle.com/tusharpatil15)\n - [Tushar Makkar](https://www.kaggle.com/tusharmakkar)\n - [Tushar Yadav](https://www.kaggle.com/tusharyad)\n - [tvscitechtalk](https://www.kaggle.com/tvscitechtalk)\n - [TwistFateBOY](https://www.kaggle.com/twistfateboy)\n - [TY](https://www.kaggle.com/tywangty)\n - [tyjzhong](https://www.kaggle.com/tyjzhong)\n - [tylerfuller](https://www.kaggle.com/tylerfuller)\n - [TylerTuschhoff](https://www.kaggle.com/tsquared)\n - [u_kag](https://www.kaggle.com/utkarshasthana)\n - [U.S. National Archives and Records Administration](https://www.kaggle.com/national-archives)\n - [UC San Diego](https://www.kaggle.com/ucsandiego)\n - [UCI Machine Learning](https://www.kaggle.com/uciml)\n - [Udacity](https://www.kaggle.com/udacity)\n - [UDAS](https://www.kaggle.com/k2sguard)\n - [Uday](https://www.kaggle.com/udaykp)\n - [Uddeshya Singh](https://www.kaggle.com/uds5501)\n - [Udeme Udofia](https://www.kaggle.com/udemeudofia)\n - [ugocupcic](https://www.kaggle.com/ugocupcic)\n - [Ujjwal Kr Gupta](https://www.kaggle.com/ujjwalkg)\n - [Ujjwal](https://www.kaggle.com/ujjwal9)\n - [Ujjwal](https://www.kaggle.com/ujjwalsaxena)\n - [ultra-jack](https://www.kaggle.com/ultrajack)\n - [Umakant](https://www.kaggle.com/umakantjena)\n - [Umang Dhiman](https://www.kaggle.com/umangdhiman)\n - [Umberto](https://www.kaggle.com/umbertogriffo)\n - [umut](https://www.kaggle.com/iklotho)\n - [Union of Concerned Scientists](https://www.kaggle.com/ucsusa)\n - [United Nations Development Program](https://www.kaggle.com/undp)\n - [United Nations](https://www.kaggle.com/unitednations)\n - [United States Air Force](https://www.kaggle.com/usaf)\n - [United States Department of Agriculture](https://www.kaggle.com/usdeptofag)\n - [United States Drought Monitor](https://www.kaggle.com/us-drought-monitor)\n - [University of Connecticut](https://www.kaggle.com/uconn)\n - [University of Copenhagen](https://www.kaggle.com/University-of-Copenhagen)\n - [University of Michigan](https://www.kaggle.com/umichigan)\n - [University of North Texas](https://www.kaggle.com/unt)\n - [University of Pittsburgh](https://www.kaggle.com/pitt)\n - [University of Virginia](https://www.kaggle.com/university-of-virginia)\n - [uranio255](https://www.kaggle.com/uranio255)\n - [UrvangPatel](https://www.kaggle.com/urvang)\n - [US Bureau of Labor Statistics](https://www.kaggle.com/bls)\n - [US Census Bureau](https://www.kaggle.com/census)\n - [US Customs and Border Protection](https://www.kaggle.com/cbp)\n - [US Department of Agriculture](https://www.kaggle.com/usda)\n - [US Department of Energy](https://www.kaggle.com/us-doe)\n - [US Department of Health and Human Services](https://www.kaggle.com/hhs)\n - [US Environmental Protection Agency](https://www.kaggle.com/epa)\n - [US Geological Survey](https://www.kaggle.com/usgs)\n - [US Patent and Trademark Office](https://www.kaggle.com/uspto)\n - [US Senate](https://www.kaggle.com/senate)\n - [USB](https://www.kaggle.com/utsavbanka)\n - [usfundamentals](https://www.kaggle.com/usfundamentals)\n - [ushchent](https://www.kaggle.com/ushchent)\n - [Utagh](https://www.kaggle.com/utathya)\n - [Utkarsh Aggarwal](https://www.kaggle.com/utkarshaggarwal)\n - [utmhikari](https://www.kaggle.com/utmhikari)\n - [uttahjazz](https://www.kaggle.com/ubonguttah)\n - [V.A. Freeman](https://www.kaggle.com/m3financial)\n - [V81msk](https://www.kaggle.com/v81msk)\n - [Vadim Shmelev](https://www.kaggle.com/wadims)\n - [Vahe Andonians](https://www.kaggle.com/andonians)\n - [Vahik95](https://www.kaggle.com/vahe95)\n - [vaibhav_varshney](https://www.kaggle.com/vaibhavvarshney0)\n - [vaibhavgeek](https://www.kaggle.com/vaibhavgeek)\n - [Vaibhavi Singh](https://www.kaggle.com/didi17)\n - [Vaibs](https://www.kaggle.com/vaibhao)\n - [Valentina C](https://www.kaggle.com/carusova)\n - [Valeria Bar\xc3\x83\xc2\xb3n](https://www.kaggle.com/valabaron)\n - [ValerieSalazar](https://www.kaggle.com/valsal27)\n - [Valerio Luciani](https://www.kaggle.com/valeriol93)\n - [Valerio Luzzi](https://www.kaggle.com/valluzzi)\n - [ValerioVaccaro](https://www.kaggle.com/valeriovaccaro)\n - [vanAmsen](https://www.kaggle.com/vanamsen)\n - [Vanessa ](https://www.kaggle.com/vanessaboucinha)\n - [Vardan](https://www.kaggle.com/vardan95ghazaryan)\n - [VarDial](https://www.kaggle.com/vardial)\n - [Varun Belliappa](https://www.kaggle.com/varunbelliappa)\n - [Varun Bhargava](https://www.kaggle.com/varunbhargava17)\n - [Varun Kashyap.K.S.](https://www.kaggle.com/varunkashyapks)\n - [varunagarwal](https://www.kaggle.com/aguyhasnoname)\n - [vasilisnikolaou](https://www.kaggle.com/vasilis73)\n - [VasyaVologdin](https://www.kaggle.com/dogama)\n - [Vedant Ruparelia](https://www.kaggle.com/vedantnr)\n - [VedapragnaReddy](https://www.kaggle.com/vedapragnareddy)\n - [Vein](https://www.kaggle.com/veinpy)\n - [Venkat Ramakrishnan](https://www.kaggle.com/venkatramakrishnan)\n - [VenkataDuvvuri](https://www.kaggle.com/ramanamurthy)\n - [VenkataSivaAbhishek](https://www.kaggle.com/hanumanjunction)\n - [Venkatesh Madhava](https://www.kaggle.com/venmadh)\n - [Venkateshgopal](https://www.kaggle.com/venkateshgopal)\n - [Vera Lei](https://www.kaggle.com/veralei)\n - [Vered Shwartz](https://www.kaggle.com/vered1986)\n - [verginer](https://www.kaggle.com/alucaria)\n - [Veysel Kocaman](https://www.kaggle.com/vkocaman)\n - [Vicc Alexander](https://www.kaggle.com/viccalexander)\n - [Vicky1](https://www.kaggle.com/vignesh1234)\n - [VickyLee](https://www.kaggle.com/vickylee745)\n - [Victor dos Santos](https://www.kaggle.com/m1thr4nd1r)\n - [Victor Genin](https://www.kaggle.com/victorgenin)\n - [Victor Hugo](https://www.kaggle.com/vhcg77)\n - [Victor Paslay](https://www.kaggle.com/vpaslay)\n - [Victor](https://www.kaggle.com/zhangruinan9652)\n - [victor7246](https://www.kaggle.com/victor7246)\n - [VictorElie](https://www.kaggle.com/victorelie07)\n - [VictorGrobberio](https://www.kaggle.com/victorgrobberio)\n - [Vidhu Shekhar Tripathi](https://www.kaggle.com/vidhushekhart)\n - [viditjain](https://www.kaggle.com/viditj)\n - [Vignesh Varadarajan](https://www.kaggle.com/vigneshv59)\n - [vihan](https://www.kaggle.com/vihansp)\n - [vijay dhameliya](https://www.kaggle.com/dhamvi01)\n - [vijay](https://www.kaggle.com/vijayaghanapathy)\n - [Vijaykumar Ummadisetty](https://www.kaggle.com/vijayuv)\n - [VijayN](https://www.kaggle.com/vijaychowthri)\n - [Vikas Kamath M](https://www.kaggle.com/vikasjce)\n - [Vikas Pandey](https://www.kaggle.com/vikasp)\n - [VikasSangwan](https://www.kaggle.com/trekkerthemaker)\n - [vikassrivastava](https://www.kaggle.com/onlyricks)\n - [vikrant yadav](https://www.kaggle.com/vikrant4)\n - [VikrantThakur](https://www.kaggle.com/vikrantthakur14)\n - [Viktor Malyi](https://www.kaggle.com/vmalyi)\n - [ViktoriaSuponenko](https://www.kaggle.com/vikichocolate)\n - [vinay shanbhag](https://www.kaggle.com/vinayshanbhag)\n - [Vinayagam.D.Ganesh](https://www.kaggle.com/vinaylogics)\n - [vinceallenvince](https://www.kaggle.com/vinceallenvince)\n - [Vincent Assoun](https://www.kaggle.com/vincenta1812)\n - [VincentLa](https://www.kaggle.com/vincela9)\n - [VineetKothari](https://www.kaggle.com/vineetkothari)\n - [vinodkumar](https://www.kaggle.com/vinodkumarcvk)\n - [Viraj Bhambri](https://www.kaggle.com/virajb)\n - [Virginie Do](https://www.kaggle.com/virginiedo)\n - [VirgoData](https://www.kaggle.com/virgodata)\n - [viru](https://www.kaggle.com/virugadde)\n - [Vish Chekuri](https://www.kaggle.com/chekuri1961)\n - [Vish Vishal](https://www.kaggle.com/altavish)\n - [VishakhHegde](https://www.kaggle.com/vishakhhegde)\n - [VISHAL MODAGEKAR](https://www.kaggle.com/vishalmodagekar)\n - [VishnuRaghavan](https://www.kaggle.com/vishnusraghavan)\n - [Vishwas Shrikhande](https://www.kaggle.com/vishwasshrikhande)\n - [Vishwesh S](https://www.kaggle.com/vishweshs)\n - [viswateja gajulavarthy](https://www.kaggle.com/viswatejag)\n - [Vitalii Peretiatko](https://www.kaggle.com/vitaliiperetiatko)\n - [Vitaly Burachyonok](https://www.kaggle.com/byrachonok)\n - [Vitaly Korchagin](https://www.kaggle.com/vitalykorchagin)\n - [Vitor R. F.](https://www.kaggle.com/vitorrf)\n - [Vivek Chutke](https://www.kaggle.com/vivekchutke)\n - [Vivek Kumar](https://www.kaggle.com/viveknium)\n - [Vivek Pandey](https://www.kaggle.com/thevivekpandey)\n - [Vivek Singh](https://www.kaggle.com/viv541)\n - [VivekGopinathlal](https://www.kaggle.com/vivekgopinathlal)\n - [VivekMangipudi](https://www.kaggle.com/stansilas)\n - [Vivian l](https://www.kaggle.com/vivianl0)\n - [Vivin Abraham](https://www.kaggle.com/vsa5027)\n - [vl](https://www.kaggle.com/dogedoge)\n - [Vlad Golubev](https://www.kaggle.com/golubev)\n - [vlad.pambucol](https://www.kaggle.com/pambucol)\n - [VladB](https://www.kaggle.com/vladb37)\n - [vladifidchuk](https://www.kaggle.com/vladifidchuk)\n - [Vladimir Alencar](https://www.kaggle.com/valencar)\n - [Vladimir Belyaev](https://www.kaggle.com/vbelyaev)\n - [Vladimir Gmyzin](https://www.kaggle.com/pushero)\n - [Vladimir Kiselev](https://www.kaggle.com/wikiselev)\n - [Vladimir Kuznetsov](https://www.kaggle.com/miracula)\n - [Vladislav Zavadskyy](https://www.kaggle.com/zavadskyy)\n - [Volodymyr Sadovyy](https://www.kaggle.com/vovsad)\n - [Vonage Garage](https://www.kaggle.com/vonagegarage)\n - [voronwe2007](https://www.kaggle.com/voronwe2007)\n - [VoteView](https://www.kaggle.com/voteview)\n - [Vrushali Patel](https://www.kaggle.com/vrushalipatel)\n - [vsmolyakov](https://www.kaggle.com/vsmolyakov)\n - [Vyas](https://www.kaggle.com/vedavyasv)\n - [W. Yifan](https://www.kaggle.com/evanwang1028)\n - [Wal8800](https://www.kaggle.com/wal8800)\n - [walla2ae](https://www.kaggle.com/walla2ae)\n - [Wally Atkins](https://www.kaggle.com/wallyatkins)\n - [Walter_Sam](https://www.kaggle.com/samirankundustat)\n - [wanglaiqi](https://www.kaggle.com/wanglaiqi)\n - [WangQiucheng](https://www.kaggle.com/idealmaster)\n - [wangtianju](https://www.kaggle.com/wangtianju)\n - [WanqiWang](https://www.kaggle.com/wanqwang)\n - [Waqas Malik](https://www.kaggle.com/waqasafz)\n - [Ward Bradt](https://www.kaggle.com/wardbradt)\n - [Warren Elder](https://www.kaggle.com/warrenelder)\n - [warrentnt](https://www.kaggle.com/warrentnt)\n - [Washim Ahmed](https://www.kaggle.com/washimahmed)\n - [Washington University](https://www.kaggle.com/wustl)\n - [Watts](https://www.kaggle.com/watts2)\n - [Wayne Haubner](https://www.kaggle.com/whaubner)\n - [WayneC](https://www.kaggle.com/chanfai514)\n - [Wazeed](https://www.kaggle.com/wazeed)\n - [Web IR](https://www.kaggle.com/webirlab)\n - [WebDev](https://www.kaggle.com/webdevday)\n - [weeliangng](https://www.kaggle.com/weeliangng)\n - [Wei Chun Chang](https://www.kaggle.com/justjun0321)\n - [Wei Ouyang](https://www.kaggle.com/weiouyang)\n - [weibo](https://www.kaggle.com/webber008wang)\n - [weisinhong](https://www.kaggle.com/weisinhong)\n - [wellll](https://www.kaggle.com/wellll)\n - [WENBOCAO](https://www.kaggle.com/wenbocao)\n - [wenchen](https://www.kaggle.com/wenchenkof2001)\n - [Wenchi](https://www.kaggle.com/zhangwenchi)\n - [Wendy Kan](https://www.kaggle.com/wendykan)\n - [wenlong](https://www.kaggle.com/longwade)\n - [WesDuckett](https://www.kaggle.com/wduckett)\n - [wh0801](https://www.kaggle.com/wh0801)\n - [whosonit 1](https://www.kaggle.com/whosonit1)\n - [W\xc3\x8e\xe2\x80\x9d](https://www.kaggle.com/keplersmachines)\n - [Wijdan Aljumiah](https://www.kaggle.com/wijdan)\n - [wil o c ward](https://www.kaggle.com/wilocw)\n - [WildGrok](https://www.kaggle.com/wildgrok)\n - [Wilian Osaku](https://www.kaggle.com/wosaku)\n - [Will Gao](https://www.kaggle.com/pirateshadow)\n - [will hunt](https://www.kaggle.com/glovepm)\n - [WillamGreen](https://www.kaggle.com/dskswu)\n - [William Cao](https://www.kaggle.com/williamcao)\n - [William Cukierski](https://www.kaggle.com/wcukierski)\n - [William Hyde](https://www.kaggle.com/wjhyde1)\n - [William Straus](https://www.kaggle.com/willstr)\n - [William Walter](https://www.kaggle.com/colara)\n - [williamnowak](https://www.kaggle.com/wpncrh)\n - [Willie Liao](https://www.kaggle.com/willieliao)\n - [willinghorse](https://www.kaggle.com/jiezi2004)\n - [Winastwan Gora](https://www.kaggle.com/winastwangora)\n - [Windson](https://www.kaggle.com/fengshenfeilian)\n - [Windy Torgerud](https://www.kaggle.com/windytorgerud)\n - [Winnie](https://www.kaggle.com/awenqi)\n - [WNYC](https://www.kaggle.com/wnyc)\n - [WojciechW\xc3\x85\xe2\x80\x9aodarczyk](https://www.kaggle.com/heolin)\n - [Wol4ara_Vio](https://www.kaggle.com/wol4aravio)\n - [Work1810](https://www.kaggle.com/mywork1810)\n - [World Bank](https://www.kaggle.com/theworldbank)\n - [World Bank](https://www.kaggle.com/worldbank)\n - [World Economic Forum](https://www.kaggle.com/weforum)\n - [WorldValueSurvey](https://www.kaggle.com/worldvaluesurvey)\n - [woutervh88](https://www.kaggle.com/woutervh88)\n - [WrackShipParty](https://www.kaggle.com/sdeng2)\n - [Wrong](https://www.kaggle.com/miguelllana)\n - [WU Wuhui](https://www.kaggle.com/canonwu)\n - [WUZZUF](https://www.kaggle.com/WUZZUF)\n - [xachi](https://www.kaggle.com/seniorxachi)\n - [Xai Nano](https://www.kaggle.com/xainano)\n - [xaliap](https://www.kaggle.com/xaliap)\n - [XavierBays](https://www.kaggle.com/xavierepfl)\n - [XavierMartinezBartra](https://www.kaggle.com/xavier14)\n - [Xavya](https://www.kaggle.com/xavya77)\n - [xgan](https://www.kaggle.com/xgan2010)\n - [Xiang Zhang](https://www.kaggle.com/datafreshman)\n - [xiaocongSonia](https://www.kaggle.com/xiaocongsonia)\n - [XiaojingLi](https://www.kaggle.com/xiaojingli)\n - [Xiaoxiao Wu](https://www.kaggle.com/cathywu)\n - [XIAOZHOU YANG](https://www.kaggle.com/yangxiaozhou)\n - [Ximing](https://www.kaggle.com/jackalex)\n - [Xin](https://www.kaggle.com/huxin216)\n - [xingzhangren](https://www.kaggle.com/xingzhangren)\n - [Xiong Songsong](https://www.kaggle.com/bigsomg)\n - [xjtushilei](https://www.kaggle.com/xjtushilei)\n - [xss](https://www.kaggle.com/bbbbbbbu)\n - [xtyscut](https://www.kaggle.com/xtyscut)\n - [Xuetao Shi](https://www.kaggle.com/xuetaoshi)\n - [XuleiYang](https://www.kaggle.com/yangxulei)\n - [xuseniayu](https://www.kaggle.com/xuchuanyu)\n - [xuy2](https://www.kaggle.com/constanceyoung)\n - [xWang](https://www.kaggle.com/seniorwx)\n - [xx](https://www.kaggle.com/hackxxy)\n - [Yabir Canario](https://www.kaggle.com/ycanario)\n - [YachunCheng](https://www.kaggle.com/yachuncheng)\n - [YaGana Sheriff-Hussaini](https://www.kaggle.com/sheriytm)\n - [Yagnesh Badiyani](https://www.kaggle.com/byagnesh)\n - [YahyaCivelek](https://www.kaggle.com/mylogic)\n - [yaliTsai](https://www.kaggle.com/yalitsai)\n - [yamuuu](https://www.kaggle.com/yamuuu)\n - [Yan Ramos da Silva](https://www.kaggle.com/yrdasilva)\n - [Yan Zhu](https://www.kaggle.com/vincent625)\n - [Yang Lin](https://www.kaggle.com/ljjsfe)\n - [Yang Yunfan](https://www.kaggle.com/kevinyang372)\n - [Yanir](https://www.kaggle.com/ycalisar)\n - [Yannis Pappas](https://www.kaggle.com/yannisp)\n - [YannMallegol](https://www.kaggle.com/yannmallegol)\n - [Yannsar](https://www.kaggle.com/yannsar)\n - [Yao Hu](https://www.kaggle.com/hooyao)\n - [Yao Lu](https://www.kaggle.com/bitandatom)\n - [YaoHsiao](https://www.kaggle.com/yaohsiaopid)\n - [YaoSenYou](https://www.kaggle.com/litterboy)\n - [Yaoxiang Li](https://www.kaggle.com/lzyacht)\n - [Yap Wei Yih](https://www.kaggle.com/yapweiyih)\n - [Yapi Donatien Achou](https://www.kaggle.com/rubben)\n - [Yarden Sharon](https://www.kaggle.com/yardenandchen)\n - [Yasar Kocal](https://www.kaggle.com/uyasarkocal)\n - [Yaser Ahmed](https://www.kaggle.com/codeworm)\n - [Yash Pradhan](https://www.kaggle.com/pradhan1234)\n - [Yash](https://www.kaggle.com/urstrulyyashu)\n - [yashjain](https://www.kaggle.com/yoyo1704)\n - [Yashna shravani](https://www.kaggle.com/yashnashravani)\n - [Yashu](https://www.kaggle.com/yashikabansal92)\n - [YasmeenW](https://www.kaggle.com/otto531)\n - [Yassine Marzougui](https://www.kaggle.com/ymarzougui)\n - [Yassine Morakkam](https://www.kaggle.com/ymorakkam)\n - [yassineameur](https://www.kaggle.com/yassine)\n - [yasuhiro_121](https://www.kaggle.com/yasuhiro121)\n - [Yaswanth Gosula](https://www.kaggle.com/yaswanth5)\n - [Yatishbn](https://www.kaggle.com/yatishbn)\n - [yazi](https://www.kaggle.com/wuyazi)\n - [Ye HuangJie](https://www.kaggle.com/kiet321)\n - [YeoMyungRo](https://www.kaggle.com/rymyung)\n - [yeongchan](https://www.kaggle.com/yeongchan)\n - [yeongseok](https://www.kaggle.com/yeongseokkwon)\n - [Yevgeniya Migranova](https://www.kaggle.com/migranova)\n - [Yexiaofeng](https://www.kaggle.com/stenen)\n - [Yi Cao](https://www.kaggle.com/yicao2)\n - [Yi Jingyuan-\xc3\xa9\xc2\x9d\xe2\x84\xa2\xc3\xa8\xc2\xbf\xc5\x93](https://www.kaggle.com/universeyi)\n - [Yi Su](https://www.kaggle.com/yisunext408)\n - [Yichen\xc3\xa2\xe2\x82\xac\xc5\x93Eddie\xc3\xa2\xe2\x82\xac\xc2\x9dShen](https://www.kaggle.com/shenyichen105)\n - [Yifan Xie](https://www.kaggle.com/yifanxie)\n - [YijieZhuang](https://www.kaggle.com/jes2ica)\n - [Yin  Zhang](https://www.kaggle.com/yinzhang1)\n - [YingHan](https://www.kaggle.com/hollin0620)\n - [Yingzhu](https://www.kaggle.com/zhaoyingzhu)\n - [YiqiZhang](https://www.kaggle.com/zhang17)\n - [yiweihuang](https://www.kaggle.com/yiweihuang)\n - [Yixin Sun](https://www.kaggle.com/yixinsunn)\n - [ykamikawa](https://www.kaggle.com/ykamikawa)\n - [ykatayama](https://www.kaggle.com/ykatayama)\n - [YL ](https://www.kaggle.com/yl1202)\n - [Ylan Kazi](https://www.kaggle.com/ylankazi)\n - [yliu](https://www.kaggle.com/yliu9999)\n - [ymlai87416](https://www.kaggle.com/ymlai87416)\n - [ymtoo](https://www.kaggle.com/ymtoo86)\n - [Yoann Pradat](https://www.kaggle.com/yoannpradat)\n - [Yochanan Scharf](https://www.kaggle.com/yochanan)\n - [Yogesh Gupta](https://www.kaggle.com/yogeshgupta5)\n - [yogeshsingh](https://www.kaggle.com/yogeshsinghrbt)\n - [Yogi](https://www.kaggle.com/yogalakshmi18)\n - [Yoka](https://www.kaggle.com/yoka33)\n - [Yonatan Vaizman](https://www.kaggle.com/yvaizman)\n - [Yongho Choi](https://www.kaggle.com/yongho1037)\n - [Young And Dumb](https://www.kaggle.com/ayushpaliwal2015)\n - [YourKingdomCome](https://www.kaggle.com/yourwillbedone)\n - [ysaz](https://www.kaggle.com/imanazas)\n - [Yu Sheng Lu](https://www.kaggle.com/yushenglu)\n - [YU_CHIH](https://www.kaggle.com/cutyhell)\n - [Yuanjie Li](https://www.kaggle.com/yuanjieli)\n - [yuansaijie0604](https://www.kaggle.com/yuansaijie0604)\n - [Yueming](https://www.kaggle.com/carolzhangdc)\n - [YueSu](https://www.kaggle.com/suyue715)\n - [YuhaoWang](https://www.kaggle.com/yuhaowang)\n - [YuhuaXiong](https://www.kaggle.com/yuhuaxiong)\n - [yujack](https://www.kaggle.com/yuyijack)\n - [Yukarin](https://www.kaggle.com/yukarin)\n - [Yulia G](https://www.kaggle.com/yuliag)\n - [Yuncheng Li](https://www.kaggle.com/raingo)\n - [Yunguan FU](https://www.kaggle.com/yunguanfu)\n - [yuqing01](https://www.kaggle.com/yuqing01)\n - [Yura Shakhnazaryan](https://www.kaggle.com/yuridias)\n - [Yuranan](https://www.kaggle.com/yuranan)\n - [Yurii Biurher](https://www.kaggle.com/yburger)\n - [Yury Kashnitsky](https://www.kaggle.com/kashnitsky)\n - [Yusuf](https://www.kaggle.com/rybekci)\n - [YuwenJin](https://www.kaggle.com/yuwenjin)\n - [Yuzie Yu](https://www.kaggle.com/yuyugrin)\n - [Yvon](https://www.kaggle.com/yvon123)\n - [yvonhk](https://www.kaggle.com/yvonhk)\n - [Zach Barillaro](https://www.kaggle.com/zquant)\n - [zach](https://www.kaggle.com/balloonanimal)\n - [zack](https://www.kaggle.com/mzharif88)\n - [ZackCode](https://www.kaggle.com/zackcode)\n - [ZacKentonASI](https://www.kaggle.com/zacasi)\n - [zackthoutt](https://www.kaggle.com/zynicide)\n - [ZagarsurenSukhbaatar](https://www.kaggle.com/zagarsuren)\n - [Zain Baig](https://www.kaggle.com/mzainbaig)\n - [Zain Rizvi](https://www.kaggle.com/zainrizvi)\n - [Zakar H.](https://www.kaggle.com/zakarh)\n - [Zalando Research](https://www.kaggle.com/zalando-research)\n - [Zan Huang](https://www.kaggle.com/zanhuang314)\n - [Zaruhi Avagyan](https://www.kaggle.com/zaraavagyan)\n - [Zaur Begiev](https://www.kaggle.com/zaurbegiev)\n - [zedd](https://www.kaggle.com/zeddmaxx)\n - [Zeeshan-ul-hassan Usmani](https://www.kaggle.com/zusmani)\n - [zelhassn](https://www.kaggle.com/ljlr34449)\n - [Zeta](https://www.kaggle.com/zeta2191622)\n - [zhai kun](https://www.kaggle.com/video1243)\n - [zhangchengwei](https://www.kaggle.com/zcw607)\n - [zhanglanqing](https://www.kaggle.com/zhanglanqing)\n - [ZhaofengLi](https://www.kaggle.com/lzfxxx)\n - [zhaojingnan](https://www.kaggle.com/jingnanzhao)\n - [Zhe LIN](https://www.kaggle.com/linzhe)\n - [ZheCJ](https://www.kaggle.com/markshizhe)\n - [Zhengyi Zhu](https://www.kaggle.com/zzhu56)\n - [ZhenyuBo](https://www.kaggle.com/zbi441)\n - [Zheye Yuan](https://www.kaggle.com/tet21tet)\n - [Zhijin](https://www.kaggle.com/zhijinzhai)\n - [zhiliang](https://www.kaggle.com/chenzhiliang)\n - [zhixing](https://www.kaggle.com/zhixing629)\n - [zhousheng](https://www.kaggle.com/zhouzhiguang)\n - [Zielak](https://www.kaggle.com/mczielinski)\n - [Zillow](https://www.kaggle.com/zillow)\n - [Zinuo Jia](https://www.kaggle.com/xiaojia129)\n - [ZiyuanZhong](https://www.kaggle.com/zhongzzy9)\n - [zjf](https://www.kaggle.com/zhangjuefei)\n - [zluckyH](https://www.kaggle.com/zluckyhou)\n - [ZoeRenwick](https://www.kaggle.com/zoerenwick)\n - [Zoey](https://www.kaggle.com/zoe1580)\n - [ztyh0121](https://www.kaggle.com/ztyh0121)\n - [ZuhaibAli](https://www.kaggle.com/zohaib1111)\n - [Zuoyu Miao](https://www.kaggle.com/zymiao)\n - [Zurda](https://www.kaggle.com/hakabuk)\n - [ZuSwi](https://www.kaggle.com/nidhirastogi)\n - [Zwidofhelangani Gabara](https://www.kaggle.com/gabarazwido)\n - [zyaj](https://www.kaggle.com/zyajnokid)\n'","b""['internet', 'communities', 'small', 'featured']""",https://www.kaggle.com/jessevent/all-kaggle-datasets
b'Peace Agreements Dataset',b'Text and metadata of 1500 peace agreements',"b'### Context\n\nThis dataset is a copy of the University of Edinburgh\'s PA-X Peace Agreements Database ([available and searchable here](https://www.peaceagreements.org/)).  The database is ""a repository of over 1500 peace agreements from over 140 processes from 1990 current until 1 January 2016."" \n\n### Content\n\nThe dataset includes the text of the agreement, the scenario under which it was signed, and some other metadata about the agreement.\n\n### Acknowledgements\n\nIf you use this dataset, please cite is using one or both of the following citations:\n\n&gt; PA-X (2017). Peace Agreements Database and Access Tool, Version 1. Political Settlements Research Programme, University of Edinburgh, Edinburgh. www.peaceagreements.org\n\n&gt; Bell, Christine, Sanja Badanjak, Robert Forster, Astrid Jamar, Jan Pospisil, Laura Wise (2017). PA-X Codebook, Version 1. Political Settlements Research Programme, University of Edinburgh, Edinburgh. www.peaceagrements.org\n\n[Click here](https://www.peaceagreements.org/files/Terms_of_Use.pdf) to see the Terms of Use.\n\n### Inspiration\n\nWhat can you discover by applying natural language processing to the text of the peace agreements contained in this dataset?'","b""['linguistics', 'international relations', 'war', 'peace', 'small', 'featured']""",https://www.kaggle.com/university-of-edinburgh/peace-agreements-dataset
b'ResNet-34',b'ResNet-34 Pre-trained Model for PyTorch',"b'# ResNet-34\n\n---\n\n## Deep Residual Learning for Image Recognition\nDeeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. \n\nAn ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. \n\nThe depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.<br>\n\n**Authors: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun**<br>\n**https://arxiv.org/abs/1512.03385**\n\n---\n\n\nArchitecture visualization: http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006\n\n![Resnet][1]\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/nyYh5xH.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/resnet34
b'Paradise Papers',b'Data Scientists Against Corruption',"b""## Context\n\nI've uploaded a [dataset][1] previously that contains Paradise Papers, Panama Papers, Bahamas and Offshore Leaks. I've been getting a lot of requests to upload Paradise papers alone to make it less confusing for my fellow data scientists. Here it is, the complete cache of Paradise Papers released so far. I will keep updating it.\n\nThe Paradise Papers is a cache of some 13GB of data that contains 13.4 million confidential records of offshore investment by 120,000 people and companies in 19 tax jurisdictions (Tax Heavens - [an awesome video to understand this][2]); that was published by the International Consortium of Investigative Journalists (ICIJ) on November 5, 2017. Subsequent data was released on November 20, 2017. Here is a brief [video][3] about the leak. The people include Queen Elizabeth II, the President of Columbia (Juan Manuel Santos), Former Prime Minister of Pakistan ([Shaukat Aziz][4]), U.S Secretary of Commerce (Wilbur Ross) and many more. According to an estimate by the Boston Consulting Group, the amount of money involved is around $10 trillion. The leak contains many famous companies, including Facebook, Apple, Uber, Nike, Walmart, Allianz, Siemens, McDonald\xe2\x80\x99s and Yahoo.\n\nIt also contains a lot of U. S President [Donald Trump allies][5] including Rax Tillerson, Wilbur Ross, Koch Brothers, Paul Singer, Sheldon Adelson, Stephen Schwarzman, Thomas Barrack and Steve Wynn etc. The complete list of Politicians involve is available here.\n\nI am calling all data scientists to help me stop the corruption and reveal the patterns and linkages invisible for the untrained eye.\n\n## Content\n\nThe data is the effort of more than 100 journalists from 60+ countries\n\nThe original data is available under creative common license and can be downloaded from this [link.][6]\n\nI will keep updating the datasets with more leaks and data as it\xe2\x80\x99s available\n\n## Acknowledgements\n\n[International Consortium of Investigative Journalists (ICIJ][7])\n\n## Inspiration\n\nSome ideas worth exploring:\n\n    How many companies and individuals are there in all of the leaks data\n\n    How many countries involved\n\n    Total money involved\n\n    What is the biggest best tax heaven\n\n    Can we compare the corruption with human development index and make an argument that would correlate corruption with bad conditions in that country\n\n    Who are the biggest cheaters and where they live\n\n    What role Fortune 500 companies play in this game\n\nI need your help to make this world corruption free in the age of NLP and Big Data\n\n\n  [1]: https://www.kaggle.com/zusmani/paradisepanamapapers\n  [2]: https://www.icij.org/investigations/paradise-papers/watch-snax-haven-hide-secret-sauce-save-millions/\n  [3]: https://www.icij.org/investigations/paradise-papers/watch-the-paradise-papers-secrets-of-the-global-elite/\n  [4]: https://offshoreleaks.icij.org/stories/shaukat-aziz\n  [5]: https://www.icij.org/investigations/paradise-papers/us-president-donald-trumps-influencers/\n  [6]: https://offshoreleaks.icij.org/pages/database\n  [7]: https://offshoreleaks.icij.org/""","b""['politics', 'money', 'covariance and correlation', 'small', 'featured']""",https://www.kaggle.com/zusmani/paradise-papers
b'SpaceX Launch Data',"b'Launch, payload, and outcome information for SpaceX missions'","b""### Context\n\nSpaceX designs, manufactures and launches advanced rockets and spacecraft. The company was founded in 2002 to revolutionize space technology, with the ultimate goal of enabling people to live on other planets - [SpaceX][1]\n\n### Content\n\nThe dataset contains mission information for rocket launches conducted by SpaceX (Space Exploration Technologies Corp).\n\n\n### Acknowledgements\n\nData was obtained via Wikipedia's entry for [Falcon 9 and Falcon Heavy launches][2].\n\n\n### Inspiration\n\nDo you anticipate an increase in launches with the introduction of the Falcon Heavy? How has launch rate increased over time? Do you predict a shift in payload orbits for upcoming launches? How has the customer diversity changed over the years?\n\n\n  [1]: http://www.spacex.com/about\n  [2]: https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches""","b""['space', 'spaceflight', 'small', 'featured']""",https://www.kaggle.com/scoleman/spacex-launch-data
b'Moses Sample',b'Moses sample MT models',"b'### Context\n\nNLTK redistributes the Moses machine translation models to test the `nltk.translate` functionalities, originally from http://www.statmt.org/moses/?n=Development.GetStarted\n\n### Content\n\nThe Moses sample contains the following subdirectories:\n\n - **lm**: pre-trained N-gram language models using europarl and [SRILM](http://www.speech.sri.com/projects/srilm/)\n - **phrase-model**:  pre-trained Moses phrase-based model\n - **string-to-tree**: pre-trained Moses String-to-Tree model\n - **tree-to-tree**: pre-trained Moses Tree-to-Tree model\n\n### Acknowledgements\n\nCredit goes to the Moses developers who distribute this as a regression test to check that Moses Statistical Machine Translation tool is successfully installed.'","b""['medium', 'featured']""",https://www.kaggle.com/nltkdata/moses-sample
b'International Datasets',b'International health and population metrics',"b'### Content\n\nThe United States Census Bureau\xe2\x80\x99s International Dataset provides estimates of country populations since 1950 and projections through 2050. Specifically, the data set includes midyear population figures broken down by age and gender assignment at birth. Additionally, they provide time-series data for attributes including fertility rates, birth rates, death rates, and migration rates.\n \nThe full documentation is available here. For basic field details, please see the data dictionary. \n\nNote: The U.S. Census Bureau provides estimates and projections for countries and areas that are recognized by the U.S. Department of State that have a population of at least 5,000.\n\n### Acknowledgements\n\nThis dataset was created by the [United States Census Bureau][1].\n\n### Inspiration\n\nWhich countries have made the largest improvements in life expectancy? Based on current trends, how long will it take each country to catch up to today\xe2\x80\x99s best performers?\n\n### Use this dataset with BigQuery\nYou can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the data on BigQuery, too: https://cloud.google.com/bigquery/public-data/international-census.\n\n  [1]: https://www.census.gov/'","b""['demographics', 'international relations', 'large', 'featured']""",https://www.kaggle.com/census/international-data
b'Hair Salon No-Show Dataset',b'A Dataset for Predicting Hair Salon Appointment No-Shows',"b'### Context\n\nNo-shows are a big problem for hair salons the same as airlines and medical facilities.  Excessive no-shows increase costs and wait times for businesses and all other customers alike.  A No-show prediction service would allow hair salons to select from a variety of treatment options at the time of the booking such as requiring a non-refundable deposit or scheduling the appointment at a different time, location or with a different service provider such that the potential no-show would have less business and customer experience impact.\n\n### Content\n\nThis is a dataset that can be used to predict appointment no-shows.  Datasets and models are available for predicting no-shows in healthcare but this is the first hair salon appointment dataset on Kaggle.   The data includes bookings and cancellation information to determine whether a given booking resulted in a ""no-show"" wherein the client either didn\'t show up at all or canceled the appointment within 48 hours of the planned booking (i.e., an out-of-policy cancellation). The data consists primarily of attributes of the appointment booking itself and excludes client details or details on the staff member providing the service.\n\n### Acknowledgements\n\nThe data was used with the permission of an actual hair salon in Toronto, Canada.  It covers a time series from March to July of 2018.  The name of the salon is omitted for privacy reasons.\n\n### Inspiration\n\nI was inspired by the extensive no-show analytics that has been done on Kaggle with appointment records from public hospitals in Vitoria, Espirito Santo, Brazil. The data set is provided by JoniHoppen on Kaggle: [https://www.kaggle.com/joniarroba/noshowappointments][1] . My goal is to answer the question: ""Which client bookings are most likely to either 1) no-show or 2) cancel within 48 hours of the scheduled appointment time.  False positives are okay as long as we can optimize the number of actual no shows predicted in test.\n\n\n  [1]: https://www.kaggle.com/joniarroba/noshowappointments'","b""['business', 'small', 'featured']""",https://www.kaggle.com/frederickferguson/hair-salon-no-show-data-set
b'Zillow Economics Data',b'Turning on the lights in housing research.',"b""### Context\n\nZillow's Economic Research Team collects, cleans and publishes housing and economic data from a variety of public and proprietary sources. Public property record data filed with local municipalities -- including deeds, property facts, parcel information and transactional histories -- forms the backbone of our data products, and is fleshed out with proprietary data derived from property listings and user behavior on Zillow. \n\nThe large majority of Zillow's aggregated housing market and economic data is made available for free download at zillow.com/data.\n\n\n### Content\n\n**Variable Availability:** \n\n*Zillow Home Value Index (ZHVI)*: A smoothed seasonally adjusted measure of the median estimated home value across a given region and housing type. A dollar denominated alternative to repeat-sales indices. Find a more detailed methodology here: http://www.zillow.com/research/zhvi-methodology-6032/ \n\n*Zillow Rent Index (ZRI)*: A smoothed seasonally adjusted measure of the median estimated market rate rent across a given region and housing type. A dollar denominated alternative to repeat-rent indices. Find a more detailed methodology here: http://www.zillow.com/research/zillow-rent-index-methodology-2393/\n\n*For-Sale Listing/Inventory Metrics*: Zillow provides many variables capturing current and historical for-sale listings availability, generally from 2012 to current. These variables include median list prices and inventory counts, both by various property types. Variables capturing for-sale market competitiveness including share of listings with a price cut, median price cut size, age of inventory, and the days a listing spend on Zillow before the sale is final. \n\n*Home Sales Metrics*: Zillow provides data on sold homes including median sale price by various housing types, sale counts (methodology here: http://www.zillow.com/research/home-sales-methodology-7733/), and a normalized view of sale volume referred to as turnover. The prevalence of foreclosures is also provided as ratio of the housing stock and the share of all sales in which the home was previously foreclosed upon. \n\n*For-Rent Listing Metrics*: Zillow provides median rents prices and median rent price per square foot by property type and bedroom count.\n\n**Housing type definitions:**\n\n*All Homes:* Zillow defines all homes as single-family, condominium and co-operative homes with a county record. Unless specified, all series cover this segment of the housing stock.\n\n*Condo/Co-op:* Condominium and co-operative homes.\n\n*Multifamily 5+ units*: Units in buildings with 5 or more housing units, that are not a condominiums or co-ops.\n\n*Duplex/Triplex*: Housing units in buildings with 2 or 3 housing units.\n\n*Tiers*: By metro, we determine price tier cutoffs that divide the all homes housing stock into thirds using the full distribution of estimated home values. We then estimate real estate metrics within the property sets, Bottom, Middle, and Top, defined by these cutoffs. When reported at the national level, all Bottom Tier homes defined at the metro level are pooled together to form the national bottom tier. The same holds for Middle and Top Tier homes.    \n\n**Regional Availability:**   \n\nZillow metrics are reported for common US geographies including Nation, State, Metro (2013 Census Defined CBSAs), County, City, ZIP code, and Neighborhood. \n\nWe provide a crosswalk between colloquial Zillow region names and federally defined region names and linking variables such as County FIPS codes and CBSA codes. Cities and Neighborhoods do not match standard jurisdictional boundaries. Zillow city boundaries reflect mailing address conventions and so are often visually similar to collections of ZIP codes. Zillow neighborhood boundaries can be found here. \n\nSuppression Rules: To ensure reliability of reported values the Zillow Economic Research team applies suppression rules triggered by low sample sizes and excessive volatility. These rules are customized to the metric and region type and explain most missingness found in the provided datasets. \n\n**Additional Data Products** \n\nThe following data products and more are available for free download exclusively at [Zillow.com/Data][1]:\n\n - Zillow Home Value Forecast\n - Zillow Rent Forecast\n - Negative Equity (the share of mortgaged properties worth less than\n   mortgage balance)\n - Zillow Home Price Expectations Survey\n - Zillow Housing Aspirations Report\n - Zillow Rising Sea Levels Research\n - Cash Buyers Time Series\n - Buy vs. Rent Breakeven Horizon\n - Mortgage Affordability, Rental Affordability, Price-to-Income Ratio\n - Conventional 30-year Fixed Mortgage Rate, Weekly Time Series\n - Jumbo 30-year Fixed Mortgage Rates, Weekly Time Series \n\n### Acknowledgements\n\nThe mission of the Zillow Economic Research Team is to be the most open, authoritative source for timely and accurate housing data and unbiased insight. We aim to empower consumers, industry professionals, policy makers and researchers looking to better understand the housing market.\n\nTo see more of our mission in action, we invite you to learn more about us and to check out our collection of research briefs, stories, data tools and past presentations at https://www.zillow.com/research/\n\n### Inspiration\n\nZillow, and the Zillow Economic Research Team, firmly believe that not only do data *want* to be free, data are *going* to be free. Instead of simply publishing raw data, we believe in the power of pushing data up the ladder from raw data bits, to actionable information and finally to unique insight. We aim to answer questions of all kinds, even questions our users may not have known they had before coming to us. When done right, we firmly believe this process of turning data into insight can be transformational in people's lives.\n\nPlease join us on this journey, and we're excited to see what insights you can discover hidden amongst our data!\n\n\n  [1]: https://www.zillow.com/research/data/""","b""['economics', 'demographics', 'business', 'housing', 'medium', 'featured']""",https://www.kaggle.com/zillow/zecon
b'Delpher Dutch Newspaper Archive (1618-1699)',b'Can you identify linguistic features that predict a market crash?',"b'### Context:  \n\n""Tulip mania, tulipmania, or tulipomania (Dutch names include: tulpenmanie, tulpomanie, tulpenwoede, tulpengekte and bollengekte) was a period in the Dutch Golden Age during which contract prices for bulbs of the recently introduced tulip reached extraordinarily high levels and then dramatically collapsed in February 1637. It is generally considered the first recorded speculative bubble (or economic bubble)."" -- From [Wikipedia](https://en.wikipedia.org/wiki/Tulip_mania), CC BY-SA\n\nMarket forecasting is difficult. There are many factors that may affect the market, and a high degree of uncertainty. One thing that some researchers have been investigating is whether natural language processing (NLP) of news texts can help with market forecasting. Recent publications suggest that it can be.\n\n* [Peng, Y., & Jiang, H. (2016). Leverage Financial News to Predict Stock Price Movements Using Word Embeddings and Deep Neural Networks. In Proceedings of NAACL-HLT (pp. 374-379).](http://www.aclweb.org/anthology/N16-1041)\n* [Fraiberger, S. P. (2016). News Sentiment and Cross-Country Fluctuations. NLP+ CSS 2016, 125.](http://www.aclweb.org/anthology/W16-5616)\n\nThis dataset an interesting test case for these methodologies. It contains Dutch-language newspapers from the years immediately preceding and following tulip mania. Can you use NLP techniques to model the tulip market over time?\n\n### Content: \n\nThis dataset contains the texts of 8,559 newspaper deliveries from the 17th century, from June 14th, 1618 to December 31, 1699. The text is in Dutch. Since the text was scraped from old newspapers using OCR (optical character recognition), there are some errors in the text.\n\n### Acknowledgments:\n\nThis dataset was compiled by Delpher, an archive service provided by the National Library of the Netherlands. It is provided under a [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.nl) license. For more information, and newspapers from other years, please visit their [website (in Dutch)](http://www.delpher.nl/). If you use this dataset in your work, please include this citation:\n\nDelpher open newspaper archive (1.0). Creative Commons Attribution 4.0 , The Hague, 2017 .'","b""['finance', 'linguistics', 'europe', 'languages', 'product', 'medium', 'featured']""",https://www.kaggle.com/rtatman/delpher-dutch-newspaper-archive-16181699
b'Stanford Open Policing Project - California',b'Data on Traffic and Pedestrian Stops by Police in California',"b""###Context: \n\nOn a typical day in the United States, police officers make more than 50,000 traffic stops. The Stanford Open Policing Project team is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public.\n\nIf you'd like to see data regarding other states, please go to https://www.kaggle.com/stanford-open-policing.\n\n### Content: \n\nThis dataset includes over 2gb of stop data from California, covering all of 2013 onwards. Please see the data readme for the full details of the available fields.\n\n###Acknowledgements:\n\nThis dataset was kindly made available by the [Stanford Open Policing Project][1]. If you use it for a research publication, please cite their [working paper][2]:\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, V. Ramachandran, C. Phillips, S. Goel. (2017) \xe2\x80\x9cA large-scale analysis of racial disparities in police stops across the United States\xe2\x80\x9d.\n\n###Inspiration: \n\n - How predictable are the stop rates? Are there times and places that\n   reliably generate stops?\n - Concerns have been raised about jurisdictions using civil forfeiture\n   as a funding mechanism rather than to properly fight drug\n   trafficking. Can you identify any jurisdictions that may be\n   exhibiting this behavior?\n\n  [1]: https://openpolicing.stanford.edu/\n  [2]: https://5harad.com/papers/traffic-stops.pdf""","b""['crime', 'law', 'government agencies', 'large', 'featured']""",https://www.kaggle.com/stanford-open-policing/stanford-open-policing-project-california
b'Medium Articles tagged under ML/DL/AI',"b'Articles description, title, author and other metadata'",b'### Context\n\nMedium Articles tagged under ML/DL/AI scraped using Beautifulsoup and selenium \n\nCheck out the link: \nhttps://github.com/Sangarshanan/Web-scraping-and-analysis-of-Medium-articles/blob/master/Medium%20Article%20Scraping.ipynb \n\nfor the complete code\n\n### Content\n\n1.Tag : Tagged under AI/ML or DL\n\n2.Name: Name of the author\n\n3.Title: Title of the article\n\n4.Body: Body of the article (Subject)\n\n5.Upvotes: number of upvotes recieved\n\n6.Date: Date it was published\n\n\n7.Comments: Number of comments\n\n\n8.Link: Link to the article\n\n### Acknowledgements\n\nThis work was done as a part of my internship selection process at a startup called Pucho\n\n#Inspiration\n\nWho is the most prolific publisher on medium.com?',"b""['nlp', 'education', 'artificial intelligence', 'small', 'featured']""",https://www.kaggle.com/sangarshanan/medium-articles-tagged-in-mldlai
b'Hacker News Corpus',b'A subset of all Hacker News articles',"b'### Context\n\nThis dataset contains a randomized sample of roughly one quarter of all stories and comments from Hacker News from its launch in 2006. Hacker News is a social news website focusing on computer science and entrepreneurship. It is run by Paul Graham\'s investment fund and startup incubator, Y Combinator. In general, content that can be submitted is defined as ""anything that gratifies one\'s intellectual curiosity"".\n\n### Content\n\nEach story contains a story ID, the author that made the post, when it was written, and the number of points the story received.\n\nPlease note that the text field includes profanity. All texts are the author\xe2\x80\x99s own, do not necessarily reflect the positions of Kaggle or Hacker News, and are presented without endorsement.\n\n### Acknowledgements\n\nThis dataset was kindly made publicly available by [Hacker News][1] under [the MIT license][2].\n\n### Inspiration\n\n - Recent studies have found that many forums tend to be dominated by a\n   very small fraction of users. Is this true of Hacker News?\n\n - Hacker News has received complaints that the site is biased towards Y\n   Combinator startups. Do the data support this? \n\n - Is the amount of coverage by Hacker News predictive of a startup\xe2\x80\x99s\n   success?\n\n### Use this dataset with BigQuery\n\nYou can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the data in BigQuery, too: https://cloud.google.com/bigquery/public-data/hacker-news\n\nThe BigQuery version of this dataset has roughly four times as many articles.\n\n\n\n  [1]: https://github.com/HackerNews/API\n  [2]: https://github.com/HackerNews/API/blob/master/LICENSE'","b""['internet', 'news agencies', 'large', 'featured']""",https://www.kaggle.com/hacker-news/hacker-news-corpus
b'NYC SCA Disqualified Firms',b'From New York City Open Data',"b""### Content  \n\nList of firms that are disqualified to work for the SCA. The file includes the term of the firms' disqualification. If the 'disqualified to date' is empty, the firm is disqualified indefinitely.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/y2zXlLpOU4U) by [Tim Queng](https://unsplash.com/@mothy29) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'education', 'construction', 'companies', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-sca-disqualified-firms
b'New York State Parcel Counts',b'From New York State Open Data',"b""### Content  \n\nThe Department of Taxation and Finance annually produces a report pertaining to the distribution of parcels by property class.  The data analysis involves a breakdown of property classes to nine segments of broad use, namely Agricultural, Residential, Vacant Land/Farm, Commercial, Recreation, Community Service, Industrial, Public Service, and Forest/Conservation. For more information please go to:  http://www.tax.ny.gov/research/property/default.htm  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/fyaTq-fIlro) by [chuttersnap](https://unsplash.com/@chuttersnap) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/new-york-state-parcel-counts
b'Stanford Open Policing Project - Illinois',b'Data on Traffic and Pedestrian Stops by Police in Illinois',"b""###Context: \n\nOn a typical day in the United States, police officers make more than 50,000 traffic stops. The Stanford Open Policing Project team is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public.\n\nIf you'd like to see data regarding other states, please go to https://www.kaggle.com/stanford-open-policing.\n\n### Content: \n\nThis dataset includes over 1 gb of stop data from Illinois, covering all of 2010 onwards. Please see the data readme for the full details of the available fields.\n\n###Acknowledgements:\n\nThis dataset was kindly made available by the [Stanford Open Policing Project][1]. If you use it for a research publication, please cite their [working paper][2]:\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, V. Ramachandran, C. Phillips, S. Goel. (2017) \xe2\x80\x9cA large-scale analysis of racial disparities in police stops across the United States\xe2\x80\x9d.\n\n###Inspiration: \n\n - How predictable are the stop rates? Are there times and places that\n   reliably generate stops?\n - Concerns have been raised about jurisdictions using civil forfeiture\n   as a funding mechanism rather than to properly fight drug\n   trafficking. Can you identify any jurisdictions that may be\n   exhibiting this behavior?\n\n  [1]: https://openpolicing.stanford.edu/\n  [2]: https://5harad.com/papers/traffic-stops.pdf""","b""['crime', 'law', 'medium', 'featured']""",https://www.kaggle.com/stanford-open-policing/stanford-open-policing-project-illinois
b'Metrics for Kiva',b'A look into regional economic measures & demographics',"b'### Context\n\nAdditional data collated for Kiva loans & Poverty analysis\n\n\n### Content\n\nThere are various measures that can used to understand the economic welfare of countries/regions throughout the world - Such data is published & made available publicly by various organizations, such as The World Bank, United Nations Human Development Reports, Organisation for Economic Co-operation and Development (OECD), Oxford Poverty & Human Development Initiative, to name a few\n\nHere we have collated the data from various sources to understand different factors & how these factors affects Kiva borrower situations, taking into consideration the latest available data (2016 in majority cases, & in case data for 2016 is not available in the particular dataset, have considered the data from the last year that is available)\n\nApart from understanding Kiva loans, this dataset can also be used for understanding the Poverty levels of various regions\n\n### Acknowledgements\n\nhttps://data.worldbank.org/indicator\nhttp://hdr.undp.org/\nData Tables 1.1 \xe2\x80\x93 7 as: Alkire, S. and Robles, G. (2017). \xe2\x80\x9cMultidimensional Poverty Index Summer 2017: Brief methodological note and results.\xe2\x80\x9d OPHI Methodological Note 44, University of Oxford.\n\nBanner Photo by [Olga DeLawrence on Unsplash][1]\n\n### Inspiration\n\nhttps://www.kiva.org/about/\n\n\n  [1]: https://unsplash.com/photos/1jbxXN4OkMM'","b""['finance', 'economics', 'demographics', 'small', 'featured']""",https://www.kaggle.com/rgupta09/kiva-additional-data
b'3-Month or 90-day Rates and Yields Data Collection',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/1jbxXN4OkMM) by [Olga DeLawrence](https://unsplash.com/@walkingondream) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'utility', 'small', 'featured']""",https://www.kaggle.com/oecd-org/3-month-or-90-day-rates-and-yields-data-collection
b'Ticket to Ride Games',b'Score a board game with image processing',"b'## Context\n\nTicket to Ride is a board game where players place their train figures on the board to connect cities on the map. This dataset contains pictures and some data on this game.\n\n## Content\n\nThis dataset has pictures of different board ""configurations"" (players\' city connections) taken at 4 different angles. A `CSV` file labeling each player\'s city connections is provided.\n\n## Inspiration\n\nThe challenge of this dataset is to correctly label all of the city connections in an image. Can you find a working approach to this image processing task?'","b""['image processing', 'board games', 'medium', 'featured']""",https://www.kaggle.com/lemonkoala/ticket-to-ride
b'Paradise-Panama-Papers',b'Data Scientists United Against Corruption',"b'### Context\n\nThe Paradise Papers is a cache of some 13GB of data that contains 13.4 million confidential records of offshore investment by 120,000 people and companies in 19 tax jurisdictions (Tax Heavens - an [awesome video][1] to understand this); that was published by the International Consortium of Investigative Journalists (ICIJ) on November 5, 2017. Here is a brief [video][2] about the leak. The people include Queen Elizabeth II, the President of Columbia (Juan Manuel Santos), Former Prime Minister of Pakistan ([Shaukat Aziz][3]), U.S Secretary of Commerce (Wilbur Ross) and many more. According to an estimate by the Boston Consulting Group, the amount of money involved is around $10 trillion. The leak contains many famous companies, including Facebook, Apple, Uber, Nike, Walmart, Allianz, Siemens, McDonald\xe2\x80\x99s and Yahoo. \n\nIt also contains a lot of U. S President [Donald Trump allies][4] including Rax Tillerson, Wilbur Ross, Koch Brothers, Paul Singer, Sheldon Adelson, Stephen Schwarzman, Thomas Barrack and Steve Wynn etc.  The complete list of Politicians involve is avaiable [here][5]. \n\nThe Panama Papers in the cache of 38GB of data from the national corporate registry of Bahamas. It contains world\xe2\x80\x99s top politicians and influential persons as head and director of offshore companies registered in Bahamas.\n\nOffshore Leaks details 13,000 offshore accounts in a report.\n\nI am calling all data scientists to help me stop the corruption and reveal the patterns and linkages invisible for the untrained eye.\n\n### Content\n\nThe data is the effort of more than 100 journalists from 60+ countries\n\nThe original data is available under creative common license and can be downloaded from this link.\n\nI will keep updating the datasets with more leaks and data as it\xe2\x80\x99s available\n\n### Acknowledgements\n\n[International Consortium of Investigative Journalists (ICIJ)][6]\n\n### Paradise Papers Update\n\nParadise Papers data has been uploaded as released by ICIJ on Nov 21, 2017. You can find Paradise Papers zip file and six extracted files in CSV format, all starting with a prefix of Paradise. Happy Coding!\n\n\n### Inspiration\n\n\nSome ideas worth exploring:\n\n1.\tHow many companies and individuals are there in all of the leaks data\n\n2.\tHow many countries involved\n\n3.\tTotal money involved\n\n4.\tWhat is the biggest best tax heaven\n\n5.\tCan we compare the corruption with human development index and make an argument that would correlate corruption with bad conditions in that country\n\n6.\tWho are the biggest cheaters and where they live\n\n7.\tWhat role Fortune 500 companies play in this game\n\n\nI need your help to make this world corruption free in the age of NLP and Big Data\n\n\n  [1]: https://www.icij.org/investigations/paradise-papers/watch-snax-haven-hide-secret-sauce-save-millions/\n  [2]: https://www.icij.org/investigations/paradise-papers/watch-the-paradise-papers-secrets-of-the-global-elite/\n  [3]: https://offshoreleaks.icij.org/stories/shaukat-aziz\n  [4]: https://www.icij.org/investigations/paradise-papers/us-president-donald-trumps-influencers/\n  [5]: https://www.icij.org/investigations/paradise-papers/explore-politicians-paradise-papers/\n  [6]: https://offshoreleaks.icij.org/pages/database\n  [7]: https://www.icij.org/investigations/paradise-papers/explore-politicians-paradise-papers/'","b""['banking', 'money', 'medium', 'featured']""",https://www.kaggle.com/zusmani/paradisepanamapapers
b'Arabic Natural Audio Dataset',b'Automatic Emotion Recognition',"b'Emotion expression is an essential part of human interaction. The same text can hold different meanings when expressed with different emotions. Thus understanding the text alone is not enough for getting the meaning of an utterance. Acted and natural corpora have been used to detect emotions from speech. Many speech databases for different languages including English, German, Chinese, Japanese, Russian, Italian, Swedish and Spanish exist for modeling emotion recognition. Since there is no reported reference of an available Arabic corpus, we decided to collect the first Arabic Natural Audio Dataset (ANAD) to recognize discrete emotions.\n\nEmbedding an effective emotion detection feature in speech recognition system seems a promising solution for decreasing the obstacles faced by the deaf when communicating with the outside world. There exist several applications that allow the deaf to make and receive phone calls normally, as the hearing-impaired individual can type a message and the person on the other side hears the words spoken, and as they speak, the words are received as text by the deaf individual. However, missing the emotion part still makes these systems not hundred percent reliable. Having an effective speech to text and text to speech system installed in their everyday life starting from a very young age will hopefully replace the human ear. Such systems will aid deaf people to enroll in normal schools at very young age and will help them to adapt better in classrooms and with their classmates. It will help them experience a normal childhood and hence grow up to be able to integrate within the society without external help. \n\nEight videos of live calls between an anchor and a human outside the studio were downloaded from online Arabic talk shows. Each video was then divided into turns: callers and receivers. To label each video, 18 listeners were asked to listen to each video and select whether they perceive a happy, angry or surprised emotion. Silence, laughs and noisy chunks were removed. Every chunk was then automatically divided into 1 sec speech units forming our final corpus composed of 1384 records.\n\nTwenty five acoustic features, also known as low-level descriptors, were extracted. These features are: intensity, zero crossing rates, MFCC 1-12 (Mel-frequency cepstral coefficients), F0 (Fundamental frequency) and F0 envelope, probability of voicing and, LSP frequency 0-7. On every feature nineteen statistical functions were applied. The functions are: maximum, minimum, range, absolute position of maximum, absolute position of minimum, arithmetic of mean, Linear Regression1, Linear Regression2, Linear RegressionA, Linear RegressionQ, standard Deviation, kurtosis, skewness, quartiles 1, 2, 3 and, inter-quartile ranges 1-2, 2-3, 1-3. The delta coefficient for every LLD is also computed as an estimate of the first derivative hence leading to a total of 950 features.\n\nI would have never reached that far without the help of my supervisors. I warmly thank and appreciate Dr. Rached Zantout, Dr. Lama Hamandi, and Dr. Ziad Osman for their guidance, support and constant supervision.'","b""['medium', 'featured']""",https://www.kaggle.com/suso172/arabic-natural-audio-dataset
b'Red Wine Quality',b'Simple and clean practice dataset for regression or classification modelling',"b'### Context\n\nThe two datasets are related to red and white variants of the Portuguese ""Vinho Verde"" wine. For more details, consult the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.). \n\nThese datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are much more normal wines than excellent or poor ones). \n\n---\n*This dataset is also available from the UCI machine learning repository, https://archive.ics.uci.edu/ml/datasets/wine+quality , I just shared it to kaggle for convenience. (If I am mistaken and the public license type disallowed me from doing so, I will take this down if requested.)*\n\n\n### Content\n\nFor more information, read [Cortez et al., 2009].<br>\nInput variables (based on physicochemical tests):<br>\n1 - fixed acidity <br>\n2 - volatile acidity <br>\n3 - citric acid <br>\n4 - residual sugar <br>\n5 - chlorides <br>\n6 - free sulfur dioxide <br> \n7 - total sulfur dioxide <br>\n8 - density <br>\n9 - pH <br>\n10 - sulphates <br>\n11 - alcohol <br>\nOutput variable (based on sensory data): <br>\n12 - quality (score between 0 and 10) <br>\n\n### Tips\nWhat might be an interesting thing to do, is aside from using regression modelling, is to set an arbitrary cutoff for your dependent variable (wine quality) at e.g. 7 or higher getting classified as \'good/1\' and the remainder as \'not good/0\'.\nThis allows you to practice with hyper parameter tuning on e.g. decision tree algorithms looking at the ROC curve and the AUC value.\nWithout doing any kind of feature engineering or overfitting you should be able to get an AUC of .88 (without even using random forest algorithm)\n\n**KNIME** is a great tool (GUI) that can be used for this.<br>\n1 - File Reader (for csv) to linear correlation node and to interactive histogram for basic EDA.<br>\n2- File Reader to \'Rule Engine Node\' to turn the 10 point scale to dichtome variable (good wine and rest), the code to put in the rule engine is something like this:<br>\n -  **$quality$ > 6.5 => ""good""**<br>\n -  **TRUE => ""bad""** <br>\n3- Rule Engine Node output to input of Column Filter node to filter out your original 10point feature (this prevent leaking)<br>\n4- Column Filter Node output to input of Partitioning Node (your standard train/tes split, e.g. 75%/25%, choose \'random\' or \'stratified\')<br>\n5- Partitioning Node train data split output to input of Train data split to input Decision Tree Learner node and <br>\n6- Partitioning Node test data split output to input Decision Tree predictor Node<br>\n7- Decision Tree learner Node output to input Decision Tree Node input<br>\n8- Decision Tree output to input ROC Node.. (here you can evaluate your model base on AUC value)<br>\n\n\n### Inspiration\nUse machine learning to determine which physiochemical properties make a wine \'good\'!\n\n\n\n### Acknowledgements\n\nThis dataset is also available from the UCI machine learning repository, https://archive.ics.uci.edu/ml/datasets/wine+quality , I just shared it to kaggle for convenience. *(I am mistaken and the public license type disallowed me from doing so, I will take this down at first request. I am not the owner of this dataset.*\n\n**Please include this citation if you plan to use this database: \nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \nModeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.**\n\n### Relevant publication\n\nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. \nIn Decision Support Systems, Elsevier, 47(4):547-553, 2009. '","b""['beginner', 'food and drink', 'regression analysis', 'small', 'featured']""",https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009
b'Urdu Speech Dataset',"b'2,500 Urdu audio samples'","b'### Context\n\nThis dataset presents speech files recorded for isolated words of Urdu. \nLanguage resources for Urdu language are not well developed. In this work, we summarize our work on the development of Urdu speech corpus for isolated words. The Corpus comprises of 250 isolated words of Urdu recorded by ten individuals. The speakers include both native and non-native, male and female individuals. The corpus can be used for both speech and speaker recognition tasks.\nThe sampling frequency is 16000 Hz.\n\n### Content\n\nEach folder name refers to a single speaker. \nThe folder name gives information about the characteristics of each speaker.\nEach folder contains 250 isolated files i.e. 250 isolated words.\n\n\n**Speaker Name**\nAA\nAB\nAC\n.\n.\n.\nAK\n\n\n**Gender**\nM for male \nF for female\n\n\n**Native /Non-Native**\nY for Native \nN for Non-Native\n\n\n**Age Group**\nG1, G2, G3, G4\n\n\n**Example: AAMNG1**\nSpeaker Name \t= \tAA\nGender\t\t=\tMale\nN\t\t=\tNon-Native\nG1\t\t=\tAge Group G1\n\n\n### Acknowledgements\n\nAll the volunteers community who recorded for us.\n\n'","b""['linguistics', 'medium', 'featured']""",https://www.kaggle.com/hazrat/urdu-speech-dataset
b'Ubuntu Dialogue Corpus',b'26 million turns from natural two-person dialogues',"b'### Context: \n\nBuilding dialogue systems, where a human can have a natural-feeling conversation with a virtual agent, is a difficult task in Natural Language Processing and the focus of much ongoing research. Some of the challenges include linking references to the same entity over time, tracking what\xe2\x80\x99s happened in the conversation previously, and generating appropriate responses. This corpus of naturally-occurring dialogues can be helpful for building and evaluating dialogue systems.\n\n### Content: \n\nThe new Ubuntu Dialogue Corpus consists of almost one million two-person conversations extracted from the Ubuntu chat logs, used to receive technical support for various Ubuntu-related problems. The conversations have an average of 8 turns each, with a minimum of 3 turns. All conversations are carried out in text form (not audio). \n\nThe full dataset contains 930,000 dialogues and over 100,000,000 words and is available [here](http://dataset.cs.mcgill.ca/ubuntu-corpus-1.0/). This dataset contains a sample of this dataset spread across .csv files. This dataset contains more than 269 million words of text, spread out over 26 million turns. \n\n* folder: The folder that a dialogue comes from. Each file contains dialogues from one folder .\n* dialogueID: An ID number for a specific dialogue. Dialogue ID\xe2\x80\x99s are reused across folders.\n* date: A timestamp of the time this line of dialogue was sent.\n* from: The user who sent that line of dialogue.\n* to: The user to whom they were replying. On the first turn of a dialogue, this field is blank.\n* text: The text of that turn of dialogue, separated by double quotes (\xe2\x80\x9c). Line breaks (\\n) have been removed.\n\n### Acknowledgements: \n\nThis dataset was collected by Ryan Lowe, Nissan Pow , Iulian V. Serban\xe2\x80\xa0 and Joelle Pineau. It is made available here under the Apache License,  2.0. If you use this data in your work, please include the following citation: \n\nRyan Lowe, Nissan Pow, Iulian V. Serban and Joelle Pineau, ""The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems"", SIGDial 2015. URL: http://www.sigdial.org/workshops/conference16/proceedings/pdf/SIGDIAL40.pdf\n\n### Inspiration: \n\nCan you use these chat logs to build a chatbot that offers help with Ubuntu?'","b""['linguistics', 'languages', 'computing and society', 'large', 'featured']""",https://www.kaggle.com/rtatman/ubuntu-dialogue-corpus
b'Animal Bites',"b'Data on over 9,000 bites, including rabies tests'","b'\n### Context: \n\nIn the United States, animal bites are often reported to law enforcement (such as animal control). The main concern with an animal bite is that the animal may be rabid. This dataset includes information on over 9,000 animal bites which occurred near Louisville, Kentucky from 1985 to 2017 and includes information on whether the animal was quarantined after the bite occurred and whether that animal was rabid.\n\n### Content: \n\nAttributes of animal bite incidents reported to and investigated by Louisville Metro Department of Public Health and Wellness.  Personal/identifying data has been removed. This dataset is a single .csv with the following fields.\n\n* bite_date: The date the bite occurred\n* SpeciesIDDesc: The species of animal that did the biting\n* BreedIDDesc: Breed (if known)\n* GenderIDDesc: Gender (of the animal)\n* color: color of the animal\n* vaccination_yrs: how many years had passed since the last vaccination\n* vaccination_date: the date of the last vaccination\n* victim_zip: the zipcode of the victim\n* AdvIssuedYNDesc: whether advice was issued\n* WhereBittenIDDesc: Where on the body the victim was bitten\n* quarantine_date: whether the animal was quarantined\n* DispositionIDDesc: whether the animal was released from quarantine\n* head_sent_date: the date the animal\xe2\x80\x99s head was sent to the lab\n* release_date: the date the animal was released\t\n* ResultsIDDesc: results from lab tests (for rabies)\n\n### Acknowledgements: \n\nAttributes of animal bite incidents reported to and investigated by Louisville Metro Department of Public Health and Wellness. This data is in the public domain.\n\n### Inspiration: \n\n* Which animals are most likely to bite humans?\n* Are some dog breeds more likely to bite?\n* What factors are most strongly associated with a positive rabies ID? '","b""['healthcare', 'crime', 'animals', 'violence', 'small', 'featured']""",https://www.kaggle.com/rtatman/animal-bites
b'NYS Banking Institution History: Beginning 1784',b'From New York State Open Data',"b""### Content  \n\nThis file contains a history of banking institutions that are, or were, state chartered, as well as most federally chartered institutions that have operated in the state of New York.  Events in the life cycle of institutions are listed by date.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/v9rZ3Yz6fSg) by [Aidan Bartos](https://unsplash.com/@bartos) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'history', 'banking', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-banking-institution-history-beginning-1784
b'HMO Capitation DataSet',b'Capitation Data of staff patients of a company between 2017-09-01 and 2017-10-01',"b'### Context\n\nThis dataset is a capitation list containing the list of staff of a company eligible for treatment for the specified period of time. With this dataset, One can study how much a company spends on her staff on a monthly basis, how often staffs are added to the health insurance scheme and how often staffs are withdrawn from the scheme.\n\n\n### Content\nThe datasets contains the following column with about 103385 rows which is the data of two months 2017-09-01 and 2017-10-01\n\n* ID_capitation\n* Hospital_ID\n* CapitationAmount\n* ValueDate\n* CompanyID\n* PatientUniqueID\n* CapitationType\n\n### Inspiration\n\nHow can we eradicate fraud from this system because capitation Fee are still being paid on some ghost staffs.'","b""['medium', 'featured']""",https://www.kaggle.com/kelvinkins/hmo-capitation-dataset
b'Quarterly Foreign Tourist Arrivals in India',b'Determinants of Foreign Tourism Demand and Foreign Tourist Arrivals (2005-2016)',"b'**INTRODUCTION**\n\nIn 2017, over 10 million foreign tourists arrived in India as compared to 8.89 million in 2016, recording a growth of 15.6%. Hence, in recent years, there is a rapid growth of Foreign Tourist Arrivals in India. The Data Set, contains quarterly national accounts\' data for the years starting from 2005 to 2016 and includes 41 determinants of International Tourism Demand and Quarterly Foreign Tourist Arrivals in India.  \n\n**CONTENT**\n\nThe Data-Set consists of different configurations of Gross Domestic Product across multiple sectors & Foreign Exchange Earnings as determinants of Foreign Tourism Demand and the number of Foreign Tourist Arrivals (as target variable) in India. There are 4 sub data-sets as files, \n\n    1. q1.csv (corresponding to 1st Quarter of years from 2005 to 2016)\n    2. q2.csv (corresponding to 2nd Quarter of years from 2005 to 2016)\n    3. q3.csv (corresponding to 3rd Quarter of years from 2005 to 2016)\n    4. q4.csv (corresponding to 4th Quarter of years from 2005 to 2016)\n\n**SOURCES**\n\n - The data regarding the Foreign Tourist Arrivals is acquired from Indian Tourism Statistics for the duration of 2015-2016.\n - The data regarding the Foreign Exchange Earnings is collected from **Various Issues of Indian Tourism Statistics, M/o Tourism, Market Research Division** in Indian Rupee Crores.\n - The different GDP values are extracted from the **Organisation for Economic Co-Operation and Development**  in Indian Rupee Billions.\n\n**RELATED LINKS**\n\n - https://stats.oecd.org/index.aspx?queryid=350#\n - http://tourism.gov.in/sites/default/files/Other/english%20India%20Torurism%20Statics%20020917.pdf\n - http://tourism.gov.in/sites/default/files/Other/India%20Tourism%20Statistics_English_2015%20Final.pdf\n - https://navoneel1092283.github.io/fta-dataset/\n\n**RELEVANT PAPERS**\n\nJana Vencovska, ""[The determinants of international tourism demand][1]."" (2014).\n\n\n  [1]: https://is.cuni.cz/webapps/zzp/download/130133783/?lang=en'","b""['data visualization', 'regression analysis', 'small', 'featured']""",https://www.kaggle.com/navoneel/fta-data
b'Multilingual word vectors in 78 languages',b'fastText vectors of 78 languages',"b'### Context: \nWord embeddings define the similarity between two words by the normalised inner product of their vectors. The matrices in this repository place languages in a single space, without changing any of these monolingual similarity relationships. When you use the resulting multilingual vectors for monolingual tasks, they will perform exactly the same as the original vectors. \n\nFacebook recently open-sourced word vectors in 89 languages. However these vectors are monolingual; meaning that while similar words within a language share similar vectors, translation words from different languages do not have similar vectors. In this dataset are 78 matrices, which can be used to align the majority of the fastText languages in a single space.\n\n### Contents: \n\nThis repository contains 78 matrices, which can be used to align the majority of the fastText languages in a single space.\n\nThis dataset was obtained by first getting the 10,000 most common words in the English fastText vocabulary, and then using the Google Translate API to translate these words into the 78 languages available. This vocabulary was then split in two, assigning the first 5000 words to the training dictionary, and the second 5000 to the test dictionary.\nThe alignment procedure is discribed [in this blog](https://www.samtalksml.net/aligning-vector-representations/). It takes two sets of word vectors and a small bilingual dictionary of translation pairs in two languages; and generates a matrix which aligns the source language with the target. Sometimes Google translates an English word to a non-English phrase, in these cases we average the word vectors contained in the phrase.\nTo place all 78 languages in a single space, every matrix is aligned to the English vectors (the English matrix is the identity).\nYou can find more information on this dataset in the authors\xe2\x80\x99 GitHub repository, [here](https://github.com/Babylonpartners/fastText_multilingual).\n\n### Acknowledgements: \n\nThis dataset was produced by Samuel Smith, David Turban, Steven Hamblin and Nils Hammerly. If you use this repository, please cite:\nOffline bilingual word vectors, orthogonal transformations and the inverted softmax. Samuel L. Smith, David H. P. Turban, Steven Hamblin and Nils Y. Hammerla. ICLR 2017 (conference track)\n\n### Inspiration: \n\n* Can you use the word embeddings in this dataset to cluster languages into their [families](https://en.wikipedia.org/wiki/Language_family)?\n* Can you create a visualization of the relationship between words for similar concepts across languages?'","b""['linguistics', 'languages', 'medium', 'featured']""",https://www.kaggle.com/rtatman/multilingual-word-vectors-in-78-languages
b'UK Car Accidents 2005-2015',b'Data from the UK Department for Transport',"b'# Context \n\nUK police forces collect data on every vehicle collision in the uk on a form called Stats19. Data from this form ends up at the DfT and is published at https://data.gov.uk/dataset/road-accidents-safety-data\n\n\n# Content\n\nThere are 3 CSVs in this set. Accidents is the primary one and has references by Accident_Index to the casualties and vehicles tables. This might be better done as a database.\n\n\n# Inspiration\n\nQuestions to ask of this data -\n\n - combined with population data, how do different areas compare?\n-  what trends are there for accidents involving different road users eg motorcycles, peds, cyclists\n-  are road safety campaigns effective?\n-  likelihood of accidents for different groups / vehicles\n-  many more..\n\n# Manifest\n\ndft05-15.tgz - tar of Accidents0515.csv, Casualties0515.csv and Vehicles0515.csv\ntidydata.sh - script to get and tidy data.'","b""['road transport', 'medium', 'featured']""",https://www.kaggle.com/silicon99/dft-accident-data
b'NYS Children in Foster Care Annually',b'From New York State Open Data',"b""### Content  \n\nThe purpose of this data set is to provide information on the total number of admissions, discharges, and children in foster care, the type of care, and total Child Protective Services (CPS) reports indicated during period.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/CMejBwGAdGk) by [Aaron Huber](https://unsplash.com/@aahubs) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-children-in-foster-care-annually
"b'US Traffic, 2015'","b'7.1M Daily Traffic Volume Observations, By Hour and Direction'","b'### Context: \nTraffic management is a critical concern for policymakers, and a fascinating data question. This ~2gb dataset contains daily volumes of traffic, binned by hour. Information on flow direction and sensor placement is also included.\n\n### Content: \nTwo datasets are included:\n\n**dot_traffic_2015.txt.gz**\n\n* daily observation of traffic volume, divided into 24 hourly bins\n* station_id, location information (geographical place), traffic flow direction, and type of road\n\n**dot_traffic_stations_2015.txt.gz**\n\n* deeper location and historical data on individual observation stations, cross-referenced by station_id\n\n### Acknowledgements: \nThis dataset was compiled by the [US Department of Transportation](https://www.transportation.gov/data) and available on [Google BigQuery](https://cloud.google.com/bigquery/public-data/)\n\n### Inspiration: \n* Where are the heaviest traffic volumes? By time of day? By type of road?\n* Any interesting seasonal patterns to traffic volumes?'","b""['medium', 'featured']""",https://www.kaggle.com/jboysen/us-traffic-2015
b'A millennium of macroeconomic data',b'Economic Data for the UK from 1086-2016',"b""The dataset contains a broad set of macroeconomic and financial data for the UK stretching back in some cases to the C13th and with one or two benchmark estimates available for 1086, the year of the Domesday Book. The dataset was originally called the 'Three centuries of macroeconomic data' spreadsheet but has now been renamed given its broader coverage. Version 3 of the dataset has now been updated to 2016.\n\n\n### Content\n\nThe Excel file contains the original data. It contains hundreds of time series, while the csv is an extract of several dozen headline time series.\n\nIf you would like to see more of the data made available in CSV format; please let me know what you would like extracted and I'll be happy to add it. Please see `excel_sheet_names.csv` for details of what other data has yet to be unpacked.\n\n### Acknowledgements\n\nThis dataset was kindly made available by the [Bank of England][1]. You can find [the original dataset here][2].\n\n### Inspiration\n\n- Which metrics give similar answers about when the industrial revolution began? How clear is the cutoff point?\n\n### If you like\nIf you enjoyed this dataset, you might also like the [Allen-Unger Global Commodity Prices dataset](https://www.kaggle.com/sohier/allenunger-global-commodity-prices), which provides historic commodity prices from locations around the world.\n\n  [1]: http://www.bankofengland.co.uk\n  [2]: http://www.bankofengland.co.uk/research/Pages/datasets/default.aspx#""","b""['finance', 'economics', 'history', 'banking', 'medium', 'featured']""",https://www.kaggle.com/bank-of-england/a-millennium-of-macroeconomic-data
b'Manila Traffic Incident Data',b'Incidents Reported by the Metro Manila Development Authority Twitter Page',"b""### Project Details\nLook at more details here:\nhttps://panjib.wixsite.com/blog/mmdatweet2map\n\nGet the Python code here:\nhttps://github.com/Esparko/tweet2map\n\nAny comments on the code are appreciated as well, I've still only known Python for a few months at this point.\n\n### Context\n\nI created this dataset to share traffic data with anyone who is interested. As far as I know, this does not represent all the incidents in Metro Manila. The MMDA's jurisdiction is mainly the national roads so the location bias is mainly towards the national roads (EDSA, C5, etc).\n\n\n### Content\n\nThis data is MMDA ALERT data that is parsed from the [MMDA Twitter page][1].  The data was gathered through the Twitter API and I have a Python script that parses through the tweet text to get the relevant data. At the moment the dataset only starts from August 20, 2018 due to my free tier access of the Twitter API.\n\n\n### Acknowledgements\n\nThank you to the MMDA for sharing incident reports in a structured manner.\n\n\n  [1]: https://twitter.com/MMDA""","b""['geospatial analysis', 'transport', 'small', 'featured']""",https://www.kaggle.com/esparko/mmda-traffic-incident-data
b'GeoNames database',b'Geographical database covering all countries with over eleven million placenames',"b""### Context\n\nThe GeoNames geographical database contains over 10 million geographical names and consists of over 9 million unique features with 2.8 million populated places and 5.5 million alternate names. All features are categorized into one out of nine feature classes and further subcategorized into one out of 645 feature codes. \n\n### Content\n\n\nThe main 'geoname' table has the following fields :\n\n- geonameid         : integer id of record in geonames database\n- name              : name of geographical point (utf8) varchar(200)\n- asciiname         : name of geographical point in plain ascii characters, varchar(200)\n- alternatenames    : alternatenames, comma separated, ascii names automatically transliterated, convenience attribute from alternatename table, varchar(10000)\n- latitude          : latitude in decimal degrees (wgs84)\n- longitude         : longitude in decimal degrees (wgs84)\n- feature class     : see http://www.geonames.org/export/codes.html, char(1)\n- feature code      : see http://www.geonames.org/export/codes.html, varchar(10)\n- country code      : ISO-3166 2-letter country code, 2 characters\n- cc2               : alternate country codes, comma separated, ISO-3166 2-letter country code, 200 characters\n- admin1 code       : fipscode (subject to change to iso code), see exceptions below, see file admin1Codes.txt for display names of this code; varchar(20)\n- admin2 code       : code for the second administrative division, a county in the US, see file admin2Codes.txt; varchar(80) \n- admin3 code       : code for third level administrative division, varchar(20)\n- admin4 code       : code for fourth level administrative division, varchar(20)\n- population        : bigint (8 byte int) \n- elevation         : in meters, integer\n- dem               : digital elevation model, srtm3 or gtopo30, average elevation of 3''x3'' (ca 90mx90m) or 30''x30'' (ca 900mx900m) area in meters, integer. srtm processed by cgiar/ciat.\n- timezone          : the iana timezone id (see file timeZone.txt) varchar(40)\n- modification date : date of last modification in yyyy-MM-dd format\n\n\n\n\n\n**AdminCodes:**\n\nMost adm1 are FIPS codes. ISO codes are used for US, CH, BE and ME. UK and Greece are using an additional level between country and fips code. The code '00' stands for general features where no specific adm1 code is defined.\nThe corresponding admin feature is found with the same countrycode and adminX codes and the respective feature code ADMx.\n\n**feature classes:**\n\n- A: country, state, region,...\n- H: stream, lake, ...\n- L: parks,area, ...\n- P: city, village,...\n- R: road, railroad \n- S: spot, building, farm\n- T: mountain,hill,rock,... \n- U: undersea\n- V: forest,heath,...\n\n\n\n### Acknowledgements\n- Data Sources: http://www.geonames.org/data-sources.html""","b""['geography', 'large', 'featured']""",https://www.kaggle.com/geonames/geonames-database
b'Air pollutants measured in Seoul',"b'Yellow dust,  fine dust, where and when to avoid?'","b'### Context\n\nSadly, [Seoul, South Korea has some of the most polluted air in the world](https://www.ft.com/content/b49a9878-141b-11e7-80f4-13e067d5072c ). Since Seoul also represents 25-50% of the South Korean population, the air quality is a concern to many. \n\nIt used to be that in Korea, we have bad air quality in spring (yellow wind blowing from the Chinese Yellow River), and clear air in autumn. Now with more industries in China, the air is getting worse in Korea in a different seasonality pattern. This is known as [Asian Dust](https://en.wikipedia.org/wiki/Asian_Dust).\n\n### Content\n\nHourly measurement on several air pollutants in dozens of districts in Seoul.\n\n### Acknowledgements\n\nData downloaded from here. http://data.seoul.go.kr/openinf/sheetview.jsp?infId=OA-2275&amp;tMenu=11\nWe thank Seoul Open Data Plaza for making the datasets available. http://english.seoul.go.kr/policy-information/key-policies/informatization/seoul-open-data-plaza/\n\nThe banner photos are via JEONGUK HA on Unsplash\n\n### Inspiration\n\nRecently, fine dusts are posing a big problem in Korea. \nhttps://www.ft.com/content/b49a9878-141b-11e7-80f4-13e067d5072c'","b""['cities', 'pollution', 'atmospheric sciences', 'small', 'featured']""",https://www.kaggle.com/jihyeseo/seoulairreport
b'NBA Players stats since 1950',"b'3000+ Players over 60+ Seasons, and 50+ features per player'","b'### Content\n\nThe data-set contains aggregate individual statistics for 67 NBA seasons. from basic box-score attributes such as points, assists, rebounds etc., to more advanced money-ball like features such as Value Over Replacement.\n\n\n### Acknowledgements\n\nThe data was scraped from [Basketball-reference][1]\nTake a look in their glossary for a detailed column description [Glossary][2]\n\nAlso, thanks to [AbidR][3] for the corrected dataset.\n\n\n  [1]: http://www.basketball-reference.com/\n  [2]: http://www.basketball-reference.com/about/glossary.html\n  [3]: https://www.kaggle.com/abidrahman'","b""['basketball', 'small', 'featured']""",https://www.kaggle.com/drgilermo/nba-players-stats
b'Adverse Food Events',"b'90,000 product-related user-reported adverse medical events'","b""### Context: \nThe CFSAN Adverse Event Reporting System (CAERS) is a database that contains information on adverse event and product complaint reports submitted to FDA for foods, dietary supplements, and cosmetics. The database is designed to support CFSAN's safety surveillance program. Adverse events are coded to terms in the [Medical Dictionary for Regulatory Activities (MedDRA) terminology](http://www.meddra.org/).\n\n\n### Content: \nSee the metadata description in the accompanying README.pdf below or [here](https://www.fda.gov/downloads/Food/ComplianceEnforcement/UCM494019.pdf). Approximately 90k reactions are recorded from 2004-mid 2017, with 12 columns of information regarding type of reaction and related event details.\n\n### Acknowledgements: \nThis dataset is collected by the [US Food and Drug Administration](https://www.fda.gov/Food/ComplianceEnforcement/ucm494015.htm).\n\n### Inspiration: \n* What are the most commonly reported foodstuffs?\n* What are the most commonly reported medical reactions to foods?\n* Where do people in the US most commonly report food-related conditions?""","b""['food and drink', 'healthcare', 'medicine', 'government', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/fda/adverse-food-events
b'Chicago Tax Increment Financing (TIF) Projects',b'From City of Chicago Open Data',"b""### Content  \n\nThis dataset is a comprehensive list of every project in every TIF District that has received funding from the City of Chicago via the TIF program from the inception of TIF to current. Public Infrastructure projects are not included in this dataset. For more information on the Tax Increment Financing program, please see http://cityofchicago.org/tif.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/9cx4-QowgLc) by [Avel Chuklanov](https://unsplash.com/@chuklanov) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-tax-increment-financing-tif-projects
b'VGG-19',b'VGG-19 Pre-trained Model for PyTorch',"b'# VGG-19\n\n---\n\n## Very Deep Convolutional Networks for Large-Scale Image Recognition<br>\nIn this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.\n<br>\n\n**Authors: Karen Simonyan, Andrew Zisserman**<br>\n**https://arxiv.org/abs/1409.1556**\n\n---\n\n#VGG Architectures<br>\n![VGG Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/uLXrKxe.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/vgg19
b'Fatal Police Shootings',"b""The Washington Post's Dataset of Fatal Police Shootings in the US since 2015""","b'### Context\n\nThis dataset contains information about fatal shooting of civilians by police officers in the US since Jan 1st, 2015.  The data about the shootings was collected by the Washington Post in their [fatal police shootings dataset](https://github.com/washingtonpost/data-police-shootings).  The city locations were geocoded using [OpenStreetMap Nominatim](https://wiki.openstreetmap.org/wiki/Nominatim).\n\n### Content\n\n`fatal-police-shootings-data.csv` contains information about each shooting.  Each row is a shooting, and columns contain information about\n\n- Name of the individual shot\n- Date of the shooting\n- Manner of death of the individual shot\n- If and how the individual shot was armed\n- Age of the individual shot\n- Gender of the individual shot\n- Race of the individual shot\n- Whether the individual shot displayed signs of mental illness\n- To what level the individual shot was attacking when shot\n- If and how the individual shot was fleeing from police\n- If an officer present for the shooting was wearing a body camera\n\n`CityLocations.csv` contains the latitude and longitude for each city present in `fatal-police-shootings-data.csv`.\n\n### Acknowledgements and Licenses\n\nThe data in `fatal-police-shootings-data.csv` was [collected by the Washington Post](https://github.com/washingtonpost/data-police-shootings), and is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License.\n\nThe data in `CityLocations.csv` was geocoded using [OpenStreetMap Nominatim](https://wiki.openstreetmap.org/wiki/Nominatim), and is licensed under the [Open Database License](http://opendatacommons.org/licenses/odbl/).\n\nCover image by [Spenser](https://unsplash.com/@spensewithans).'","b""['violence', 'small', 'featured']""",https://www.kaggle.com/brendanhasz/fatal-police-shootings
b'Independent Election Expenditures',b'Spending by groups other than the candidates themselves',"b'This file contains ""24-hour"" and ""48-hour"" reports of independent expenditures filed during the current election cycle and for election cycles through 2010. The file contains detailed information about independent expenditures, including who was paid, the purpose of the disbursement, date and amount of the expenditure and the candidate for or against whom the expenditure was made.\n\nIndependent expenditures represent spending by individual people, groups, political committees, corporations or unions expressly advocating the election or defeat of clearly identified federal candidates. These expenditures may not be made in concert or cooperation with or at the request or suggestion of a candidate, the candidate\'s campaign or a political party.\n\nAny time up to 20 days before an election, if these independent expenditures by a person or organization aggregate more than $10,000 in a race they must be reported to the Commission before the end of the second day after the communication is publicly distributed. If the communications are distributed within the last 19 days before the election, the expenditure must be reported within one day if they aggregate more than $1,000 in any race.\n\n\n### Acknowledgements\n\nThis data comes from the US Federal Election Commission. You can find the original dataset here.\n\n## If you like...\n\nIf you enjoyed this dataset, you might also like the [Congressional Election Disbursements][1] dataset.\n\n\n  [1]: https://www.kaggle.com/fec/congressional-election-expenditures'","b""['politics', 'medium', 'featured']""",https://www.kaggle.com/fec/independent-campaign-expenditures
"b""Where's Waldo""",b'Find Waldo with image recognition',"b""### Context\n\nWhere's Waldo is a popular children's book series where the reader is presented with a sequence of scenes. Each scene contains potentially hundreds of individuals doing different things. Exactly one of these figures is Waldo: a tall man in a striped red shirt, red beanie, and glasses, and the objective of the game is to find Waldo is the least time possible. This dataset is raw data from the books for these challenges.\n\n### Content\n\nThis dataset contains a number of cuts of Where's Waldo scenes, including scenes. See [the complimentary kernel](https://www.kaggle.com/residentmario/finding-waldo-a-primer) to learn more about the dataset contents!\n\n### Acknowledgements\n\nThis dataset was collected and published as-is by Valentino Constantinou (vc1492a) on GitHub ([here](https://github.com/vc1492a/Hey-Waldo)).\n\n### Inspiration\n\nCan you come up with a strategy better than randomly scanning the page for this task? Can you identify Waldos and not-Waldos?""","b""['image data', 'popular culture', 'object detection', 'visual arts', 'medium', 'featured']""",https://www.kaggle.com/residentmario/wheres-waldo
b'Google Project Sunroof',b'Solar Panel Power Consumption Offset Estimates',"b""### Context: \nAs the price of installing solar has gotten less expensive, more homeowners are turning to it as a possible option for decreasing their energy bill. We want to make installing solar panels easy and understandable for anyone.\nProject Sunroof puts Google's expansive data in mapping and computing resources to use, helping calculate the best solar plan for you.\n\n\n### Content: \nSee metadata for indepth description. Data is at census-tract level. Project Sunroof computes how much sunlight hits your roof in a year. It takes into account:\nGoogle's database of imagery and maps\n3D modeling of your roof\nShadows cast by nearby structures and trees\nAll possible sun positions over the course of a year\nHistorical cloud and temperature patterns that might affect solar energy production\n\n\n### Acknowledgements: \nData was compiled by [Google Project Sunroof](https://www.google.com/get/sunroof/about/). You can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the [data on BigQuery, too](https://cloud.google.com/bigquery/public-data/).\n\n### Inspiration: \n* Which tracts have the highest potential possible coverage? Carbon offsets?\n* Which tracts have the highest estimated solar panel utilization? As a percent of carbon offsets?\n\nIf you want more energy data, check out [30 Years of European Wind Generation](https://www.kaggle.com/sohier/30-years-of-european-wind-generation) and [30 Years of European Solar Generation]( https://www.kaggle.com/sohier/30-years-of-european-solar-generation).\n""","b""['medium', 'featured']""",https://www.kaggle.com/jboysen/google-project-sunroof
b'NYC Restaurant Inspections',b'~400k Rows of Restaurant Inspections Data',"b'### Context: \nRestaurant inspections for permitted food establishments in NYC. Restaurants are graded on A-F scale with regular visits by city health department. \n\n### Content: \nDataset includes address, cuisine description, inspection date, type, action, violation code and description(s). Data covers all of NYC and starts Jan 1, 2010-Aug 29, 2017. \n\n### Acknowledgements: \nData was collected by the NYC Department of Health and is available [here](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j). \n\n### Inspiration: \n* Can you predict restaurant closings?\n* Are certain violations more prominent in certain neighborhoods? By cuisine?\n* Who gets worse grades--chain restaurants or independent establishments?'","b""['food and drink', 'business', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/nyc-inspections
b'Trending YouTube Video Statistics and Comments',"b'Daily statistics (views, likes, category, comments+) for trending YouTube videos'","b""_________\nUPDATED: https://www.kaggle.com/datasnaek/youtube-new\n\nSOURCE: https://github.com/DataSnaek/Trending-YouTube-Scraper\n\n__________\n\nPlan\n====\n\nData collected from the (up to) 200 listed trending YouTube videos every day in the US and the UK.\n\nDescription\n===========\n\nThe dataset includes data gathered from videos on YouTube that are contained within the trending category each day.\n\nThere are two kinds of data files, one includes comments and one includes video statistics. They are linked by the unique video_id field.\n\n\n\nThe headers in the video file are:\n\n - video_id (Common id field to both comment and video csv files)\n - title\n - channel_title\n - category_id (Can be looked up using the included JSON files, but varies per region so use the appropriate JSON file for the CSV file's country)\n - tags (Separated by | character, [none] is displayed if there are no tags)\n - views\n - likes\n - dislikes\n - thumbnail_link\n - date (Formatted like so: [day].[month])\n\n\n\nThe headers in the comments file are:\n\n - video_id (Common id field to both comment and video csv files)\n - comment_text\n - likes\n - replies\n\nExtra info: The YouTube API is not effective at formatting comments by relevance, although it claims to do so. As a result, the most relevant comments do not align with the top comments at all, they aren't even sorted by likes or replies.\n\nInspiration\n===========\n\nPossible uses for this dataset could include:\n\n - Sentiment analysis in a variety of forms\n - Categorising YouTube videos based on their comments and statistics.\n - Training ML algorithms to generate their own YouTube comments.\n - Analysing what factors affect how popular a YouTube video will be.\n\nAlthough there are likely many more possibilities, including analysis of changes over time etc.\n""","b""['internet', 'linguistics', 'languages', 'statistics', 'popular culture', 'medium', 'featured']""",https://www.kaggle.com/datasnaek/youtube
b'AlexNet',b'AlexNet Pre-trained Model for PyTorch',"b'# AlexNet\n\n---\n\n## ImageNet Classification with Deep Convolutional Neural Networks<br>\n\nWe trained a large, deep convolutional neural network to classify the 1.2 million\nhigh-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different\nclasses. On the test data, we achieved top-1 and top-5 error rates of 37.5%\nand 17.0% which is considerably better than the previous state-of-the-art. The\nneural network, which has 60 million parameters and 650,000 neurons, consists\nof five convolutional layers, some of which are followed by max-pooling layers,\nand three fully-connected layers with a final 1000-way softmax. To make training\nfaster, we used non-saturating neurons and a very efficient GPU implementation\nof the convolution operation. To reduce overfitting in the fully-connected\nlayers we employed a recently-developed regularization method called \xe2\x80\x9cdropout\xe2\x80\x9d\nthat proved to be very effective. We also entered a variant of this model in the\nILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%,\ncompared to 26.2% achieved by the second-best entry.\n\n**Authors: Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton**<br>\n**https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks**\n\n---\n\n\n![AlexNet Architecure][1]\n*Top of the image is cut-off even in the original paper :D*\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/zgzKqHp.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/alexnet
b'SF Appeals to the Rent Board',b'From San Francisco Open Data',"b""### Content  \n\nAppeals are filed when parties are seeking review of decisions made by the Rent Board and are decided by the Rent Board Commission. Grounds for appeals include: substantive appeals, procedural problems and hardship appeals. For more information, please see: http://sfrb.org/fact-sheet-8-hearings-mediations-and-appeals.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/nrSzRUWqmoI) by [Toa Heftiba](https://unsplash.com/@heftiba) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-appeals-to-the-rent-board
b'Hazardous Air Pollutants',b'A summary of daily Hazardous Air Pollutants from 1990 to 2017',"b'###Context: \nHazardous air pollutants, also known as toxic air pollutants or air toxics, are those pollutants that are known or suspected to cause cancer or other serious health effects, such as reproductive effects or birth defects, or adverse environmental effects. The Environmental Protection Agency (EPA) tracks 187 air pollutants. See [https://www.epa.gov/haps/](https://www.epa.gov/haps/) for more information.\n\n\n###Content: \nThe daily summary file contains data for every monitor (sampled parameter) in the Environmental Protection Agency (EPA) database for each day. This file will contain a daily summary record that is:\n1. The aggregate of all sub-daily measurements taken at the monitor.\n2. The single sample value if the monitor takes a single, daily sample (e.g., there is only one sample with a 24-hour duration). In this case, the mean and max daily sample will have the same value.\n\n\n**Fields Descriptions:**\n1. State Code: The Federal Information Processing Standards (FIPS) code of the state in which the monitor resides.\n\n2. County Code: The FIPS code of the county in which the monitor resides.\n\n3. Site Num: A unique number within the county identifying the site.\n\n4. Parameter Code: The AQS code corresponding to the parameter measured by the monitor.\n\n5. POC: This is the \xe2\x80\x9cParameter Occurrence Code\xe2\x80\x9d used to distinguish different instruments that measure the same parameter at the same site.\n\n6. Latitude: The monitoring site\xe2\x80\x99s angular distance north of the equator measured in decimal degrees.\n\n7. Longitude: The monitoring site\xe2\x80\x99s angular distance east of the prime meridian measured in decimal degrees.\n\n8. Datum: The Datum associated with the Latitude and Longitude measures.\n\n9. Parameter Name: The name or description assigned in AQS to the parameter measured by the monitor. Parameters may be pollutants or non-pollutants.\n\n10. Sample Duration: The length of time that air passes through the monitoring device before it is analyzed (measured). So, it represents an averaging period in the atmosphere (for example, a 24-hour sample duration draws ambient air over a collection filter for 24 straight hours). For continuous monitors, it can represent an averaging time of many samples (for example, a 1-hour value may be the average of four one-minute samples collected during each quarter of the hour).\n\n11. Pollutant Standard: A description of the ambient air quality standard rules used to aggregate statistics. (See description at beginning of document.)\n\n12. Date Local: The calendar date for the summary. All daily summaries are for the local standard day (midnight to midnight) at the monitor.\n\n13. Units of Measure: The unit of measure for the parameter. QAD always returns data in the standard units for the parameter. Submitters are allowed to report data in any unit and EPA converts to a standard unit so that we may use the data in calculations.\n\n14. Event Type: Indicates whether data measured during exceptional events are included in the summary. A wildfire is an example of an exceptional event; it is something that affects air quality, but the local agency has no control over. No Events means no events occurred. Events Included means events occurred and the data from them is included in the summary. Events Excluded means that events occurred but data form them is excluded from the summary. Concurred Events Excluded means that events occurred but only EPA concurred exclusions are removed from the summary. If an event occurred for the parameter in question, the data will have multiple records for each monitor.\n\n15. Observation Count: The number of observations (samples) taken during the day.\n\n16. Observation Percent: The percent representing the number of observations taken with respect to the number scheduled to be taken during the day. This is only calculated for monitors where measurements are required (e.g., only certain parameters).\n\n17. Arithmetic Mean: The average (arithmetic mean) value for the day.\n\n18. 1st Max Value: The highest value for the day.\n\n19. 1st Max Hour: The hour (on a 24-hour clock) when the highest value for the day (the previous field) was taken.\n\n20. AQI: The Air Quality Index for the day for the pollutant, if applicable.\n\n21. Method Code:  An internal system code indicating the method (processes, equipment, and protocols) used in gathering and measuring the sample. The method name is in the next column.\n\n22. Method Name: A short description of the processes, equipment, and protocols used in gathering and measuring the sample.\n\n23. Local Site Name: The name of the site (if any) given by the State, local, or tribal air pollution control agency that operates it.\n\n24. Address: The approximate street address of the monitoring site.\n\n25. State Name: The name of the state where the monitoring site is located.\n\n26. County Name: The name of the county where the monitoring site is located.\n\n27. City Name: The name of the city where the monitoring site is located. This represents the legal incorporated boundaries of cities and not urban areas.\n\n28. CBSA Name: The name of the core bases statistical area (metropolitan area) where the monitoring site is located.\n\n29. Date of Last Change: The date the last time any numeric values in this record were updated in the AQS data system.\n\n\n###Acknowledgements:\nThese data came from the EPA and are current up to May 01, 2017. You can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the data on BigQuery, too: [https://cloud.google.com/bigquery/public-data/epa](https://cloud.google.com/bigquery/public-data/epa).\n\n###Inspiration: \nPeople exposed to toxic air pollutants at sufficient concentrations and durations may have an increased chance of getting cancer or experiencing other serious health effects. These health effects can include damage to the immune system, as well as neurological, reproductive (e.g., reduced fertility), developmental, respiratory and other health problems. In addition to exposure from breathing air toxics, some toxic air pollutants such as mercury can deposit onto soils or surface waters, where they are taken up by plants and ingested by animals and are eventually magnified up through the food chain. Like humans, animals may experience health problems if exposed to sufficient quantities of air toxics over time. Use this dataset to find out where the highest concentrations of hazardous air pollutants are for each state. You could also use the GPS locations to find out where the EPA has the most monitoring stations and identify places that could use more.'","b""['environment', 'pollution', 'large', 'featured']""",https://www.kaggle.com/epa/hazardous-air-pollutants
b'Los Angeles Gross Receipts by Industry',b'From Los Angeles Open Data',"b""### Content  \n\nSummary of annually reported gross receipts by NAICS Industry Code.  Update Interval: Annually.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/tfkaJQV2KCM) by [Joel Muniz](https://unsplash.com/@jmuniz) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-gross-receipts-by-industry
b'Touch Sensor Events',b'Use neuronal networks to classify touch gestures',"b'### Context\n\nA very simple dev board based on a esp32 was build. It reads 8 touch sensors arranged in a 2x4 array. The esp32 detects an inital touch on any sensor and then sends the (normalized) values of each touch sensor for the next 100 points (~one second ) to a couchdb database over a wifi connection.\nDue to the setup 8*100 values are recorded per event. The idea is to train i.e. 3 arbitrary gestures and use and ML to classifiy new events. The touch array is intended to work as a general userinterface. For the inital test, the following gestures have been used  and the \'class\' name is given.\n\nswipe right = ""r""\nswipe left = ""b""\ndouble tap = ""k""\n\nAs one can see in the overview of the three gesutes, even a human beeing would have no problem distunguishing the the profiles. The idea is not to write a algorithm that does the classification, but use a neuronal net to classify the 800 input features. \nThis work is intended to get into ML and a POC, to show that a neuronal network is able to distingush pattern. Also the idea is to give an idea of an general jupyter notebook (python) based workflow example.\n\n![enter image description here][1]\n\n![enter image description here][2]\n\n### Content\n\nThe supplied dataset may be loaded into pandas and will result in a dataframe with a datetime bases index. This is the time, when the document was created on the couchdb.\nThe ""event"" column holds the array with the touch sensor values. So there are 100x8 values. The numpy equivalent shape would be (100, 8).\nThe ""class"" holds a string which was given when recording the events. As a consequence of the inital idea of a POC, the class have been referring to thier color in the later repsentation (red, blue and black). This was not changed yet is is gore sure not the best way to have a comprehensiv dataset.\n\n### Acknowledgements\n\nAndrew Ng, for his work on coursera. And the micropython and esp-idf community for bringing python to the esp32.\n\n\n### Inspiration\n\nCan a neuronal network take away the part of writing the algorithm? Is it enough if I supply the idea and the code is written by the network?\n\n\n  [1]: https://storage.googleapis.com/kagglesdsdata/datasets/28422/36213/esp32_touch.JPG?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1527504284&Signature=a3Be8ZTbBoU36luiwe%2BRolgeIiv9i2TgDDRlSPl3QbzUu2cSyOEqGNHiZBEuTik4FRtikx9RhHgBZo3iYIUuD6mmUufLmQogGRQgLs8vEAKRgwmfnvJ8jrDp1WvS67DcQiBwN1GtjCvmx%2Fx2feO%2F6eqC%2Fl1evo1tNrJzaV9KNfsvfT0DAsMeMltJqZ5jfozhPxHbHIekqMiCdlNwqg3yGTowb5Jpral3aat4wQOCf74j5iLr3Rmg%2FJ%2B0hV5sKonq%2F%2FvEtZ056HmW4cbx%2BIzM9qWGPptxuQBrBViWtrP4aULcL%2BNtwP4z9XaoBAfoqUmkOP9e9h4K6U6jQjI9%2BSvOpA%3D%3D\n  [2]: https://storage.googleapis.com/kagglesdsdata/datasets/28422/36219/event_overview.jpg?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1527514694&Signature=OIvLKRqWNLuBUBptUx7DFNKc6Pp1KPCB2TkdCwDPerrRmJ7WObqKUqYicFU3zhgYf13Aqi%2B7DZJ5vGLCxhvZWePoNh6fb%2FqOeISrsuwkZ8Aw66Mwbnl%2BHqttjskf9qGq9O7R2jFDOUWfrrss28%2FzgxkTUayftwx1E%2FdSy32TilKgfx1XQgsyeiPgsjUPMXkgMhw9Me%2B5fr4Oxq8QriUuL1Ft0MvZynsMdHPZtj49R25NND9E3HjWRmuRmXaz7ADucVWc4Ljwj7Crxp6pRAPwx0BmHoxzrBbbKcLoz355I%2BngWqZKEIMQfkZKwpGdVkBw9j%2FKBsgi%2BBLnDCjzl8T5bA%3D%3D'","b""['classification', 'time series', 'small', 'featured']""",https://www.kaggle.com/nilsnoreyson/touch-sensor-events
b'RxNorm Drug Name Conventions',b'A normalized naming system for clinical drugs',"b'### Context\n\nRxNorm was created by the [U.S. National Library of Medicine][1] (NLM) to provide a normalized naming system for clinical drugs, defined as the combination of {ingredient + strength + dose form}. In addition to the naming system, the RxNorm dataset also provides structured information such as brand names, ingredients, drug classes, and so on, for each clinical drug. Typical uses of RxNorm include navigating between names and codes among different drug vocabularies and using information in RxNorm to assist with health information exchange/medication reconciliation, e-prescribing, drug analytics, formulary development, and other functions.\n\n### Content\n\nThe full technical documentation is available [here][2].\n\nPlease note that the NLM updates RxNorm on a regular basis; you should assume that this version is out of date.\n\n### Acknowledgements\n\nThis dataset uses publicly available data from the U.S. National Library of Medicine (NLM), National Institutes of Health, Department of Health and Human Services. Please cite this dataset as:\nRxNorm\nMETA2016AB Full Update 2017_03_06\nBethesda, MD\nNational Library of Medicine\n\n###Use this dataset with BigQuery\n\nYou can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the data on BigQuery, too: https://cloud.google.com/bigquery/public-data/rxnorm.\n\n\n  [1]: https://www.nlm.nih.gov/\n  [2]: https://www.nlm.nih.gov/research/umls/rxnorm/docs/2017/rxnorm_doco_full_2017-2.html#doc'","b""['linguistics', 'medicine', 'medium', 'featured']""",https://www.kaggle.com/nlm-nih/rxnorm-drug-name-conventions
b'Education in India',"b'District and state-wise primary & secondary school education data, 2015-16'","b'**Connect/Follow me on [LinkedIn](http://link.rajanand.org/linkedin) for more updates on interesting dataset like this. Thanks.**\n\n### Context\n\nWhen India got independence from British in 1947 the literacy rate was 12.2% and as per the recent census 2011 it is 74.0%. Although it looks an accomplishment, still many people are there without access to education. \n\nIt would be interesting to know the current status of the Indian education system.\n\n### Content\n\nThis dataset contains district and state wise Indian primary and secondary school education data for 2015-16.\n\nGranularity: Annual\n\nList of files: \n\n 1. 2015_16_Districtwise.csv ( 680 observations and 819 variables )\n 1. 2015_16_Statewise_Elementary.csv ( 36 observations and 816 variables )\n 1. 2015_16_Statewise_Secondary.csv ( 36 observations and 630 variables  )\n\n \n\n### Acknowledgements\n\nMinistry of Human Resource Development (DISE) has shared the dataset [here](http://udise.in/src.htm) and also published some [reports](http://udise.in/AR.htm).\n\nSource of Banner [image](https://unsplash.com/photos/j9jZSqfH5YI).\n\n### Inspiration\n\nThis dataset provides the complete information about primary and secondary education. There are many inferences can be made from this dataset. There are few things I would like to understand from this dataset. \n\n1. Drop out ratio in primary and secondary education. (Govt. has made law that every child under age 14 should get free compulsary education.)\n2. Various factors affecting examination results of the students.\n3. What are all the factors that makes the difference (in literacy rate) between Kerala and Bihar?\n4. What could be done to improve the female literacy rate and literacy rate in rural area?\n\n\n'","b""['education', 'india', 'small', 'featured']""",https://www.kaggle.com/rajanand/education-in-india
b'Household and Housing Inventory Estimates Data',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/VSYq9nS-fY0) by [Jonas Jacobsson](https://unsplash.com/@jonasjacobsson) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'utility', 'small', 'featured']""",https://www.kaggle.com/census/household-and-housing-inventory-estimates-data
b'Los Angeles Registered City Lobbyists',b'From Los Angeles Open Data',"b""### Content  \n\nAn individual who directly communicates with a City official for the purpose of influencing a legislative or administrative matter and is compensated to spend 30 or more hours in any consecutive three-month period engaged in lobbying activities must register with the Ethics Commission as a lobbyist. This also applies to in-house lobbyists (employees who are compensated to lobby only on behalf of their employers).  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/NDLLFxTELrU) by [Skye Studios](https://unsplash.com/@skyestudios) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'ethics', 'small', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-registered-city-lobbyists
b'Every Pub in England',b'Every pub in the UK and its address',"b""### Context: \nPubs, or public houses, are popular traditional British gathering places where alcohol and food is served.\n\n### Content: \n\nThis dataset includes information on 51,566 pubs. This dataset contains the following columns:\n\n* fsa_id\t(int): Food Standard Agency's ID for this pub.\n* name (string)L Name of the pub\n* address (string): Address fields separated by commas.\n* postcode (string): Postcode of the pub.\n* easting (int)\t\n* northing (int)\t\n* latitude (decimal)\t\n* longitude (decimal)\t\n* local_authority\t (string): Local authority this pub falls under.\n\n### Acknowledgements: \n\nThe data was derived from the Food Standard Agency's Food Hygiene Ratings and the ONS Postcode Directory. The data is licensed under the Open Government Licence. (See the included .html file.)\n\n### Inspiration: \n\nYou could use this data as the basis for a real-life travelling salesman problem and plan the world\xe2\x80\x99s longest pub crawl.""","b""['europe', 'alcohol', 'small', 'featured']""",https://www.kaggle.com/rtatman/every-pub-in-england
b'NYS County Mental Health Profiles: Beginning 2006',b'From New York State Open Data',"b""### Content  \n\nThese reports provide summary information about mental health service utilization funded through Medicaid for Local Fiscal Years, beginning in service year 2006 and updated yearly thereafter. Totals are based on date of service and data are refreshed on a monthly basis so values in the same report may change over time. Prepaid Mental Health Plan (PMHP) data are included in these reports as Recovery Services (RS); however, Medicaid Managed Care data are not included. Expenditures include Comprehensive Outpatient Program Services (COPS) and Community Support Program (CSP) add-on payments, where applicable.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/zi5vRoAP3WY) by [Nathan Dumlao](https://unsplash.com/@nate_dumlao) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-county-mental-health-profiles-beginning-2006
b'2016 U.S. Presidential Campaign Texts and Polls',b'Debate and Speech Transcripts & Voter Group Polls',"b'### Context\n\nThis is an aggregate of the data I studied for my thesis titled, ""Data Mining in Presidential Debates and Speeches: How Campaign Rhetoric Shaped Voter Opinion in the 2016 U.S. Presidential Race"". The goal of my thesis was to use NLP techniques to understand how Donald Trump\xe2\x80\x99s rhetoric impacted the opinions of various voter groups throughout his campaign. Here is a summary of my findings:\n\n 1. Trump\xe2\x80\x99s words were typically more common in an American English corpus and more extreme on both ends of the sentiment spectrum\n 2. Trump not only used rhetorical devices for persuasion but also adeptly coupled these devices with the right talking points based on the composition of his audience\n 3. Precise execution of the above strategy garnered him an unexpectedly large number of votes from the white female and Hispanic demographics\n\nI hope that others can use this dataset to answer questions of their own about the 2016 presidential campaign.\n\n\n### Content\n\nCollection of data from the 2016 U.S. Presidential Election Campaign containing:\n\n 1. Transcripts of the three presidential debates, divided into separate Trump and Clinton text files\n 2. Transcripts of Trump\'s 64 speeches delivered after the RNC and Clinton\'s 35 speeches delivered after the DNC\n 3. Transcripts of select speeches delivered by candidates during the primary campaigns\n 4. USC Dornsife/LA Times Presidential Election Poll, with daily breakdown by voter groups\n 5. Five Thirty Eight Election Poll, containing daily data from numerous pollsters\n\n\n### Acknowledgements\n\nDebate and speech texts scraped from the American Presidency Project website.'","b""['linguistics', 'demographics', 'politics', 'political science', 'small', 'featured']""",https://www.kaggle.com/alandu20/2016-us-presidential-campaign-texts-and-polls
b'Chicago Schools (deprecated 2012)',b'From City of Chicago Open Data',"b""### Content  \n\nList of schools by name, address, type and grades. Note some facilities house multiple schools.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/_M-DrbiNFa4) by [Eli Francis](https://unsplash.com/@elifrancis) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-schools-deprecated-2012
b'Housing New York Units',b'From New York City Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/N_FDXbXwQmc) by [Ivan Bandura](https://unsplash.com/@unstable_affliction) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'housing', 'small', 'featured']""",https://www.kaggle.com/new-york-city/housing-new-york-units
b'UNHCR Refugee Data',b'Data on Uprooted Populations and Asylum Processing',"b'### Context: \nThe mass movement of uprooted people is a highly charged geopolitical issue. This data, gathered by the UN High Commissioner for Refugees (UNHCR), covers movement of displaced persons (asylum seekers, refugees, internally displaced persons (IDP), stateless). Also included are destination country responses to asylum petitions.\n\n### Content: \nThis dataset includes 6 csv files covering:\n\n* Asylum monthly applications opened (asylum_seekers_monthly.csv)\n* Yearly progress through the refugee system (asylum_seekers.csv) \n* Refugee demographics (demographics.csv)\n* Yearly time series data on UNHCR\xe2\x80\x99s populations of concern (time_series.csv)\n* Yearly population statistics on refugees by residence and destination (persons_of_concern.csv)\n*  Yearly data on resettlement arrivals, with or without UNHCR assistance (resettlement.csv)\n\n### Acknowledgements: \nThis dataset was gathered from [UNHCR](http://popstats.unhcr.org/en/overview). Photo by [Ali Tareq](https://unsplash.com/@a12li0).\n\n### Inspiration: \nWhat are the most frequent destination countries for refugees? How has refugee flow changed? Any trends that could predict future refugee patterns?'","b""['demographics', 'politics', 'utility', 'medium', 'featured']""",https://www.kaggle.com/unitednations/refugee-data
b'GOSU.AI Dota 2 Game Chats',b'Anonymized chats from Dota 2 match replays',"b'## Dataset\n\nThis dataset contains chat messages from [Dota 2][1] \xe2\x80\x94 video game by Valve, one of the most popular eSport discipline. The dataset was used to train [Roflan bot][2]. It contains chats of almost 1M matches from public matchmaking (when players are selected by the game server at random with about the same skill level).\n\n## Caution and Disclaimer\n\n**Important, please read.** This dataset is completely Not Safe For Work.\n\nIn Dota 2 the players communicate with each other in a very specific way. For instance, you may found a lot of abbreviations and game-specific terms. For Dota 2 player it is typical to blame teammates and opponents for failure in the game. Unfortunately, many messages may contain coarse insults, humiliation of another player\'s family, expressions of racism and other awful things. We provide the messages ""as is"" without any filters and censorship and we are not responsible for offensive content inside the data. \n\nOur goal is to give researchers an opportunity to explore players community by diving into a real dialogs. We want to draw an attention to the problem of outstanding toxicity of the most Dota 2 players, we consider this behaviour of players unhealthy.\n\n## Usage of the dataset\n\n1. See rough explanations on how do we [learn our Roflan bot][4] intended to mirror typical player\'s chat behaviour. You can apply your own language models on this dataset and make alternative chat bot or just compare performance of learning.\n2. Look at [this arXiv paper][3] with analysis of esport spectators\' chats. You can apply similar analysis to game participants chats.\n\n\n  [1]: https://en.wikipedia.org/wiki/Dota_2\n  [2]: https://roflan.gosu.ai\n  [3]: https://arxiv.org/pdf/1801.02862.pdf\n  [4]: https://www.reddit.com/r/DotA2/comments/7xs8q6/how_we_trained_dota_2_chat_simulator_why_he_is_so/'","b""['text data', 'video games', 'medium', 'featured']""",https://www.kaggle.com/romovpa/gosuai-dota-2-game-chats
b'Income Gini Ratio Time Series Collection',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/U-yHjENTmMg) by [Gene Devine](https://unsplash.com/@devine_images) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/income-gini-ratio-time-series-collection
b'Canada National Justice Survey 2016',b'Canadian government justice system survey results',"b'### Context\n\nThis dataset is the anonymized result of responses submitted to a survey collected by the Canadian Department of Justice in 2016.  This survey ""...focuses on the criminal justice system (CJS) to inform the current criminal justice system review...[this] involved a traditional public opinion research survey, in informed choice survey and in person and online focus groups...this work was undertaken to support reforms and new initiatives in this area.""\n\nThis dataset is the survey component of this review.\n\n### Content\n\nRespondents were asked over 50 questions on their perception of how the Canadian Justice system works at large. This dataset was published in a typical survey output format, in that most questions are 1-10 rating scales or 0-1 True/False questions, with some free-text responses intermixed. To understand the fields, please see the attached data dictionary, or otherwise access it [here](http://www.justice.gc.ca/eng/trans/open-ouvert/rsd-drs/njs2016-snj2016/njs2016_dd_en.xlsx).\n\n### Acknowledgements\n\nThis data was published as-is by the Government of Canada, [here](http://canada.justice.gc.ca/eng/rp-pr/jr/index.html). It is licensed under the [Open Government License - Canada](http://open.canada.ca/en/open-government-licence-canada).\n\n### Inspiration\n\nIn a time of increasingly invective dialogue between police forces and the people they police, this dataset provides a window on the general level of satisfaction and concern that Canadian government citizens have with their country\'s justice systems. These results are mostly generalizable to the developed world as a whole.'","b""['crime', 'politics', 'government agencies', 'small', 'featured']""",https://www.kaggle.com/residentmario/national-justice-survey-2016
b'Seattle Business Districts',b'From City of Seattle Open Data',"b""### Content  \n\nContact list of business district organizations in Seattle  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ZGjbiukp_-A) by [samsonyyc](https://unsplash.com/@samsonyyc) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-business-districts
b'Births in Poland',b'Number of births in Polish regions 2002-2016',"b'### Context &amp; Inspiration\n\nThe birthrate in Poland was low for the past several years. The government is aiming to fix this situation by proposing a social program called ""500+"" - a family gets 500 PLN for  each child (2nd and more).\nThere was a lot of fuss in media how the government program affected birthrate. The government wanted to prove that their actions are the positive force to encourage people to have kids.  This is not easily proven, but what can be done is to check the birthrate change during the last years.\n\n### Content\nThis dataset contains number of births depending on the region of Poland and if it is 1st, 2nd or later child of the same mother.\nThe data will be later complimented with other useful entries such as demographic structure of polish women and age structure of age when women become mothers. Any suggestions are warmly welcomed!\n\n\n### Acknowledgements\nThe data is collected from [http://demografia.stat.gov.pl/bazademografia/][1]\n\n\n  [1]: http://demografia.stat.gov.pl/bazademografia/'","b""['demographics', 'government', 'small', 'featured']""",https://www.kaggle.com/mknorps/births
"b'US Trademark Case Files, 1870-2016'",b'Over 8 million Trademark case files and their owners',"b'### Context: \nA trademark is a brand name. A trademark or service mark includes any word, name, symbol, device, or any combination, used or intended to be used to identify and distinguish the goods/services of one seller or provider from those of others, and to indicate the source of the goods/services.\n\n### Content: \n\nThe Trademark Case Files Dataset contains detailed information on 8.6 million trademark applications filed with or registrations issued by the USPTO between January 1870 and January 2017. It is derived from the USPTO main database for administering trademarks and includes data on mark characteristics, prosecution events, ownership, classification, third-party oppositions, and renewal history.\n\nThis dataset is a partial version of the full dataset, made up of only the case files and owner information. For the full dataset and additional information, please see the [USPTO website](https://www.uspto.gov/learning-and-resources/electronic-data-products/trademark-case-files-dataset-0). \n\n### Inspiration: \n\n* Which owner has filed for multiple trademarks with the longest break in between?\n* Who is the most prolific trademarker?\n* How has the volume of trademarks changed since 1870?\n* Which US city has produced the most trademark owners?'","b""['united states', 'government agencies', 'product', 'large', 'featured']""",https://www.kaggle.com/uspto/us-trademark-case-files-18702016
b'Total Business Inventories and Sales Data',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/qE1jxYXiwOA) by [Petr Sevcovic](https://unsplash.com/@sevcovic23) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'utility', 'small', 'featured']""",https://www.kaggle.com/census/total-business-inventories-and-sales-data
b'Favicons',"b'Image data and metadata for 360,000 favicons scraped from popular websites'","b'### Context\n\nFavicons are the (usually tiny) image files that browsers may use to represent websites in tabs, in the URL bar, or for bookmarks. Kaggle, for example, uses an image of a blue lowercase ""k"" as its favicon. This dataset contains about 360,000 favicons from popular websites.\n\n### Content and Acknowledgements\n\nThese favicons were scraped in July 2016. I wrote a crawler that went through Alexa\'s top 1 million sites, and made a request for \'favicon.ico\' at the site root. If I got a 200 response code, I saved the result as `${site_url}.ico`. For domains that were identical but for the TLD (e.g. google.com, google.ca, google.jp...), I scraped only one favicon. My scraping/cleaning code is on GitHub [here](https://github.com/colinmorris/favicon-scraper).\n\nOf 1m sites crawled, 540k responded with a 200 code. The dataset has 360k images, which were the remains after filtering out:\n\n- empty files (-140k)\n- non-image files, according to the [`file`](https://en.wikipedia.org/wiki/File_(command)) command (-40k). These mostly had type HTML, ASCII, or UTF-*.\n- corrupt/malformed image files - i.e. those that were sufficiently messed up that ImageMagick failed to parse them. (-1k)\n\nThe remaining files are exactly as I received them from the site. They are mostly [ICO files](https://en.wikipedia.org/wiki/ICO_(file_format)), with the most common sizes being 16x16, 32x32, and 48x48. But there\'s a long tail of more exotic formats and sizes (there is at least one person living among us who thought that 88x31 was a fine size for a favicon).\n\nThe favicon files are divided among 6 zip files, `full-0.zip, full-1.zip... full-5.zip`. (If you wish to download the full dataset as a single tarball, you can do so from the [Internet Archive](https://archive.org/details/favicons_201708))\n\n`favicon_metadata.csv` is a csv file with one row per favicon in the dataset. The `split_index` says which of the zip files the image landed in. For an example of loading and interacting with particular favicons in a kernel context, check out the [Favicon helper functions](https://www.kaggle.com/colinmorris/favicon-helper-functions) kernel.\n\nAs mentioned above, the full dataset is a dog\'s breakfast of different file formats and dimensions. I\'ve created \'standardized\' subsets of the data that may be easier to work with (particularly for machine learning applications, where it\'s necessary to have fixed dimensions).\n\n**16_16.tar.gz** is a tarball containing all 16x16 favicons in the dataset, converted to PNG. It has 290k images. ICO is a container format, and many of the ico files in the raw dataset contain several versions of the same favicon at different resolutions. 16x16 favicons that were stuffed together in an ICO file with images of other sizes are included in this set. But I did no resizing - if a favicon has no \'native\' 16x16 version, it isn\'t in this set.\n\n**16_16_distinct.tar.gz** is identical to the above, but with 70k duplicate or near-duplicate images removed. There are a small number of commonly repeated favicons like the Blogger ""B"" that occur thousands of times, which could be an annoyance depending on the use case - e.g. a generative model might get stuck in a local maximum of spitting out Blogger Bs.\n\nAlexa\'s top 1-million list includes \'adult\' sites, so some URLs and favicons may be NSFW or offensive. (It\'s pretty hard to make a credible depiction of nudity in 256 pixels, but there are some occasional attempts.)\n\n### Inspiration\n\nI hope this dataset might be especially useful for small-scale deep learning experiments. Scaling photographs down to 16x16 would render many of them unintelligible, but these favicons were born tiny. The `16_16` fold has more instances than MNIST, and the images are even smaller! (Though, unlike MNIST, most of the images in this dataset are not grayscale.)\n\nIf you liked this, you should also check out the recently released [Large Logo Dataset](https://data.vision.ee.ethz.ch/cvl/lld/). They\'ve currently made available 550k favicons resized to 32x32. Their data was collected more recently, and their scraping process was more robust, so their dataset should probably be preferred (though you might still want to use this one if you need the raw favicon files, or if you prefer to use 16x16 non-resized images).'","b""['internet', 'image data', 'medium', 'featured']""",https://www.kaggle.com/colinmorris/favicons
b'Vietnam War Bombing Operations',b'Details on 4.8 Million Runs',"b'### Context: \nTHOR is a painstakingly cultivated database of historic aerial bombings from World War I through Vietnam. THOR has already proven useful in finding unexploded ordinance in Southeast Asia and improving Air Force combat tactics. Our goal is to see where public discourse and innovation takes this data.  Each theater of warfare has a separate data file, in addition to a [THOR Overview](http://www.data.mil/s/v2/data-stories-an-overview-of-thor/a100cd16-c2a7-453b-8ea6-45947c1bbc51/).\n\n### Content: \n4.8 million rows with 47 columns describing each run. See the data dictionary [here](https://www.dds.mil/data/thor_data_dictionary_2016.pdf).\n\n### Acknowledgements: \nTHOR is a dataset project initiated by  Lt Col Jenns Robertson and continued in partnership with Data.mil,  an experimental project, created by the [Defense Digital Service](https://www.dds.mil/) in collaboration with the [Deputy Chief Management Officer]( http://dcmo.defense.gov/) and data owners throughout the U.S. military. \n\n### Inspiration: \n* Which campaigns saw the heaviest bombings?\n* Which months saw the most runs?\n* What were the most used aircraft?\n'","b""['military', 'large', 'featured']""",https://www.kaggle.com/usaf/vietnam-war-bombing-operations
b'Los Angeles General Fund Revenue',b'From Los Angeles Open Data',"b""### Content  \n\nRevenue towards the City's general fund by department, program, and account.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/CbgXKSd3qkQ) by [Guillaume de Germain](https://unsplash.com/@guillaumedegermain) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/los-angeles-general-fund-revenue
b'Crime in Los Angeles',b'Crime data from 2010 through September 2017',"b'This dataset reflects incidents of crime in the City of Los Angeles dating back to 2010. This data is transcribed from original crime reports that are typed on paper and therefore there may be some inaccuracies within the data. Some location fields with missing data are noted as (0\xc2\xb0, 0\xc2\xb0). Address fields are only provided to the nearest hundred block in order to maintain privacy.\n\n### Reporting District Shapefile Attributes\n\nREPDIST, Number, min: 101   max: 2,199   avg: 1,162   count: 1,135\n\nPREC, Number, min: 1   max: 21   avg: 11   count: 1,135\n\nAPREC, Text, PACIFIC (74), DEVONSHIRE (70), WEST LOS ANGELES (69), NORTHEAST (64), HOLLENBECK (63), MISSION (62)... (15 more)\n\nBUREAU, Text, VALLEY BUREAU (399), WEST BUREAU (288), CENTRAL BUREAU (267), SOUTH BUREAU (181)\n\nBASICCAR, Text, 8A29 (17), 17A35 (17), 1A1 (15), 17A49 (14), 16A35 (14), 14A73 (14), 19A43 (13), 8A95 (12), 19A7 (12)... (160 more)\n\nTOOLTIP, Text, Bureau: SOUTH BUREAU\\nDistrict: 562\\nDivision: HARBOR (1)... (1134 more)\n\nOBJECTID\n\nUnique ID\n\n### Acknowledgements\n\nThis dataset was kindly released by the [City of Los Angeles][1]. You can find the original dataset, updated weekly, [here][2].\n\n### Inspiration\n\n - Some of the MO codes seem unlikely or unrelated to crime. Can you find out what would lead to the use of code `0107 God` or `1021 Repair`?\n\n\n  [1]: https://www.lacity.org/\n  [2]: https://data.lacity.org/A-Safe-City/Crime-Data-from-2010-to-Present/y8tr-7khq'","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/cityofLA/crime-in-los-angeles
b'Devanagari Character Dataset',b'Devanagari (Nepali) Handwritten Character Dataset',"b""### Context\n\nThis dataset is created as a part of my dissertation work for the fulfillment of the Master's degree in Computer Science (Tribhuvan University, Nepal, 2012).\n\n### Content\nThe dataset contains three individual categories. Samples are collected from 40 individuals (persons) from different fields and cropped for character boundary.\n\n 1. Numerals (288 samples per class, 10 classes) \n 2. Vowels (221 samples per class, 12 classes) \n 3. Consonants (205 samples per class, 36 classes)\n\n## Citation\n\nPlease cite in your publications if it helps your research:\n\n    @inproceedings{pant2012off,\n      title={Off-line Nepali handwritten character recognition using Multilayer Perceptron and Radial Basis Function neural networks},\n      author={Pant, Ashok Kumar and Panday, Sanjeeb Prasad and Joshi, Shashidhar Ram},\n      booktitle={2012 Third Asian Himalayas International Conference on Internet},\n      pages={1--5},\n      year={2012},\n      organization={IEEE}\n    }""","b""['small', 'featured']""",https://www.kaggle.com/ashokpant/devanagari-character-dataset
b'State of the Nation Addresses - Ghana',b'Annual State of the Nation Addresses',"b""### Context\nThis dataset contains Ghana's state of the nation addresses since 2008. The state of the nation address is an annual address to parliament given by the president. It typically summarizes the government's agenda and the progress made in the past year as seen by the administration in power.\n\nThis dataset is published as part of the [Citizen Data Science Project](https://ds4good.github.io/ghana-datasets/), you are welcome to join the conversation on [Slack](https://join.slack.com/t/ds4good/shared_invite/enQtNDE4NTkxMzI1NDQ2LWJkNDI0ZDEyODY5NDkyNjg3NWI1NmJkNTg0ZmM1MGI1ODUxNGY3MmNjNWVjNzBhMzNlODc3ZjE2YjVkYjFmM2Y)\n\n\n### Dataset Use-cases\n\n1. Teaching and learning Natural Language Processing (NLP):\n------------------------------------------------------------------------\nby demonstrating NLP techniques using data that learner can identify with, we improve engagement & better understanding of the concepts. We will be happy to see the community demonstrate NLP concepts with this dataset while delivery relevant applications/use-cases.  [spacy](https://spacy.io/), [nltk](https://www.nltk.org/), [gate](https://gate.ac.uk/), etc.\n\n2. Key Topics and  address uniqueness:\n--------------------------------------------------------------\nWhat are the key topics over the years? Can the state of the nation address highlight main problems/talking points in each year?.  \n\n3. Search:\n----------\nAs a journalist or an inquisitive citizen, I want to be able to search the speech and get short relevant paragraphs/sentences about my topic of interest.  \n\n4. Question and Answering:\n--------------------------\nfurther to search, can you device an algorithm that answers questions using the content of this data-set? [what are typical questions people ask of the state of the nation address? we need to find out.]. **For Learning outcome** question and answering systems are popular nlp applications. what are the key concepts? your work should highlight them. \n\n5. Promise Extraction:\n----------------------\n Are you able to extract promises/commitments made in these addresses? This will enable citizens hold their governments accountable. **For Learning outcome** this should teach the core concepts of in Information Retrieval.  \n\n6. Others\n------\nAny other application you wish to share with the community.\n\n\n \n\n\n\n### Acknowledgements\nby: [easimadi](https://www.linkedin.com/in/easimadi/)  \nsource: [Wikipedia](https://en.wikipedia.org/wiki/State_of_the_Nation_(Ghana))   \n[datanix](https://www.datanix.co.uk/blog)  \n[Institute of ICT Professionals Ghana](https://www.iipgh.org)    \n""","b""['politics', 'government', 'small', 'featured']""",https://www.kaggle.com/citizen-ds-ghana/sona-ghana
"b'Olympic Sports and Medals, 1896-2014'",b'Which countries and athletes have won the most medals at the Olympic games?',"b""# Content\n\nWhich Olympic athletes have the most gold medals? Which countries are they from and how has it changed over time? \n\nMore than 35,000 medals have been awarded at the Olympics since 1896. The first two Olympiads awarded silver medals and an olive wreath for the winner, and the IOC retrospectively awarded gold, silver, and bronze to athletes based on their rankings. This dataset includes a row for every Olympic athlete that has won a medal since the first games.\n\n\n# Acknowledgements\n\nData was provided by the IOC Research and Reference Service and published by The Guardian's Datablog.""","b""['olympic games', 'small', 'featured']""",https://www.kaggle.com/the-guardian/olympic-games
b'Brazilian Federal Legislative activity',"b'Datasets of congresspeople attendance, votes and propositions since past century'","b'[Brazilian? You can read a Portuguese version of this article here.](https://medium.com/quinhentos-e-noventa-e-quatro/entendendo-o-que-faz-um-deputado-73e46db3aaa4)\n\n### Context\n\nLast year, while I was attending a data science course in Germany, my country was impeaching its president. My colleagues asked me to explain what was happening in Brazil and the possible political outcomes in South America. Although I was able to give a general context and tell multiple arguments in favor and against the impeachment, deep inside, my answer was ""I really don\'t know"".\n\nUnderstanding what happens in Politics is something that takes a lot of effort and research. When I decided I had to use my tech skills to make myself a better citizen, I dived into government data and started [Operation Serenata de Amor](https://impact.vice.com/en_us/article/d3zxnz/scientists-are-using-twitter-to-battle-brazils-congressional-corruption).\n\nAfter [reporting hundreds of politicians](https://twitter.com/RosieDaSerenata) for small acts of corruption and learning how to encourage the population to engage in the democratic processes, my studies drove me to understand the legislative activity.\n\nBrazilians elect 594 citizens to be their representatives in the National Congress. How can we be sure that they are not defending their own interests or those who paid for their campaigns? My way, as a data scientist, is to ask the data.\n\n### Content\n\nThe National Congress of Brazil is composed of a Lower (Chamber of Deputies) and an Upper House (Federal Senate). In the first version of this dataset, you are going to find data only from the Chamber of Deputies. With 513 representatives, 86% of the congresspeople, I hope you have enough data to explore for some time.\n\nWould be impossible for me, a citizen without government ties, to collect this data without the help of public servants. I processed 9,717 fixed-width files and 73 XML\'s made officially available by the Chamber of Deputies and created 5 CSV\'s containing the same information. Multiple fields of the same file telling the same thing (e.g. `body_id`, `body_name` and `body_abbreviation`) were removed.\n\nData on session attendance, votes, and propositions since past century were collected and scripted in a reproducible manner. The data collection and pre-processing scripts are available in [a GitHub repository](https://github.com/Irio/national-congress-data), under an open source license.\n\nEverything was collected from the Chamber of Deputies website at December 27, 2017, containing the whole legislative activity of the year. Presence and votes date from 1999, propositions go as far as 1946.\n\nWhen in question about the legislative process and how the sessions work in real world, the [Internal Regulation of the Chamber of Deputies](http://livraria.camara.leg.br/regimento-interno-da-camara-dos-deputados-931.html) is the best Portuguese documentation for research. It\'s free!\n\n### Acknowledgements\n\nSince the data was collected from a government website and the Brazilian law states that access to this information is free to any citizen, I am placing my own work published here in Public Domain.\n\nI\'d like to thank the hundreds of people financially supporting the work of [Operation Serenata de Amor](https://apoia.se/serenata) and those responsible for passing the Information Access bill in 2011.\n\n### Inspiration\n\nThe legislative activity should tell the history while it\'s happening. How much has the Congress changed over the past decades? Do the congresspeople maintain the same political views or they vary on a weekly basis? Do people vote together with their state or party peers? How often? Can you model an algorithm to tell us the real parties inside Brazilian Congress?'","b""['politics', 'brazil', 'journalism', 'south america', 'medium', 'featured']""",https://www.kaggle.com/iriomk/brazilian-federal-legislative-activity
b'Elementary school admission Romania 2014',b'Show elementary school admission patterns at county level for Romania in 2014',"b""## Context\n\n[*data.gov.ro*](http://data.gov.ro) hosts datasets with public administrative data from Romania government, much like [*data.gov*](http://data.gov) for US relevant data.  \nThe main file from this datasource [http://data.gov.ro/dataset/inscrierea-in-invatamantul-primar-2014](http://data.gov.ro/dataset/inscrierea-in-invatamantul-primar-2014) originates from [*data.gov.ro*](http://data.gov.ro) and contains the anonymized information for the pupils registering in elementary school 1st grade in Romania in 2014. Starting from this data, I wanted to represent the registration data geographically, to have a sense of the geographical distribution of pupils registration in 1st grade. I therefore added few other files to this dataset, from different sources:  \n\n- school information (to be able to connect pupils information with geographical data) - 1 file;  \n- census information (in order to show the percent of the entire regional population registering in 1st grade in 2014) - 2 files.\n\n\n## Content\n\nThe dataset contains 4 sources of data:\n\n### elementary_school_registration_2014.csv\nThe original source of this data is to be found here (Romanian page): [http://data.gov.ro/dataset/inscrierea-in-invatamantul-primar-2014](http://data.gov.ro/dataset/inscrierea-in-invatamantul-primar-2014)\nThis represents the registration information for pupils in 1st grade for elementary school in Romania.\n\nThe data is anonymized and shows: \n\n- an unique code for each child;\n- sex;\n- social environment ('U' stands for Urban and 'R' for country-side); \n- the citizenship;\n- the ethnic group (similar with mother tongue);\n- the type of the registration application;\n- the admission stage (I-1, I-2, I-3),;\n- the educational alternative (traditional or different schooling options available in Romania, like special education for challenged pupils or Montessori, progressive etc.);\n- teaching language, an unique code for identifying every school (SIRUES);\n-  disability (handicap) flag;\n- orphan or institutionalized child flag;\n- single parent flag;\n- attendance of after-school option.\n\n### school_network.csv\nOrigin of this data source is [http://eprofu.ro/docs/tehnic/institutii/retea-scolara.xls](http://eprofu.ro/docs/tehnic/institutii/retea-scolara.xls). This file is used to connect SIRUES code from the main file in the datasource with the geographical information. The file contains:\n\n- the 'judet' information (is an administrative unit in Romania, larger than a municipality and smaller than a region, much like a county in US);\n- the name of the school;\n- the unique code SIRUES (this can be used to merge with the pupils registration file);\n- the type of school;\n- the school category;\n- the education form;\n- the teaching language.\n\n### ro_judete_poligon.geojson\nThis file original source is: [http://www.geo-spatial.org](http://www.geo-spatial.org) - shows geospatial information for Romanian counties (judet), in geojson format. It also includes the census information starting from 1948 until 2011 (last Romanian census). The detail of county geographical information is very high and therefore this geojson will be used only to extract the census information.\n\n### romania.geojson\nThis geojson file source is [https://github.com/codeforamerica/click_that_hood/blob/master/public/data/romania.geojson](https://github.com/codeforamerica/click_that_hood/blob/master/public/data/romania.geojson)\nIt is used to display the county borders (contains less points than ro_judete_poligon.geojson)""","b""['europe', 'education', 'medium', 'featured']""",https://www.kaggle.com/gpreda/elementary-school-admission-romania-2014
b'Movie Dialog Corpus',b'A metadata-rich collection of fictional conversations from raw movie scripts',"b'### Context\nThis corpus contains a metadata-rich collection of fictional conversations extracted from raw movie scripts:\n\n- 220,579 conversational exchanges between 10,292 pairs of movie characters\n- involves 9,035 characters from 617 movies\n- in total 304,713 utterances\n- movie metadata included:\n\t- genres\n\t- release year\n\t- IMDB rating\n\t- number of IMDB votes\n\t- IMDB rating\n- character metadata included:\n\t- gender (for 3,774 characters)\n\t- position on movie credits (3,321 characters)\n\n\n\n### Content\nIn all files the original field separator was "" +++$+++ "" and have been converted to tabs (\\t). Additionally, the original file encoding was ISO-8859-2. It\'s possible that the field separator conversion and decoding may have left some artifacts. \n\n\n- movie_titles_metadata.txt\n\t- contains information about each movie title\n\t- fields: \n\t\t- movieID, \n\t\t- movie title,\n\t\t- movie year, \n\t   \t- IMDB rating,\n\t\t- no. IMDB votes,\n \t\t- genres in the format [\'genre1\',\'genre2\',\xc3\x89,\'genreN\']\n\n- movie_characters_metadata.txt\n\t- contains information about each movie character\n\t- fields:\n\t\t- characterID\n\t\t- character name\n\t\t- movieID\n\t\t- movie title\n\t\t- gender (""?"" for unlabeled cases)\n\t\t- position in credits (""?"" for unlabeled cases) \n\n- movie_lines.txt\n\t- contains the actual text of each utterance\n\t- fields:\n\t\t- lineID\n\t\t- characterID (who uttered this phrase)\n\t\t- movieID\n\t\t- character name\n\t\t- text of the utterance\n\n- movie_conversations.txt\n\t- the structure of the conversations\n\t- fields\n\t\t- characterID of the first character involved in the conversation\n\t\t- characterID of the second character involved in the conversation\n\t\t- movieID of the movie in which the conversation occurred\n\t\t- list of the utterances that make the conversation, in chronological \n\t\t\torder: [\'lineID1\',\'lineID2\',\xc3\x89,\'lineIDN\']\n\t\t\thas to be matched with movie_lines.txt to reconstruct the actual content\n\n- raw_script_urls.txt\n\t- the urls from which the raw sources were retrieved\n\n\n### Acknowledgements\nThis corpus comes from the paper, ""Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs"" by Cristian Danescu-Niculescu-Mizil and Lillian Lee.  \n\nThe paper and up-to-date data can be found here: [http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html][1]\n\nPlease see the README for more information on the authors\' collection procedures.\n\nThe file formats were converted to TSV and may contain a few errors\n\n### Inspiration\n\n - What are all of these imaginary people talking about? Are they representative of how real people communicate?\n - Can you identify themes in movies from certain writers or directors? \n - How does the dialog change between characters?\n\n  [1]: http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html'","b""['linguistics', 'film', 'medium', 'featured']""",https://www.kaggle.com/Cornell-University/movie-dialog-corpus
b'NY Upcoming contracts to be awarded',b'From New York City Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/TRVSyEf4UEE) by [Animesh Basnet](https://unsplash.com/@hsemina) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'education', 'construction', 'design', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-upcoming-contracts-to-be-awarded
b'Emergency - 911 Calls',"b'Montgomery County, PA'","b'**Emergency (911) Calls**: Fire, Traffic, EMS for Montgomery County, PA\n\n\nYou can get a quick introduction to this Dataset with this kernel: [Dataset Walk-through][1]\n\n**Acknowledgements:** Data provided by [montcoalert.org][2]\n\n\n  [1]: https://www.kaggle.com/mchirico/d/mchirico/montcoalert/dataset-walk-through-911\n  [2]: http://montcoalert.org/gettingdata/'","b""['crime', 'law', 'medium', 'featured']""",https://www.kaggle.com/mchirico/montcoalert
b'Question-Answer Dataset',b'Can you use NLP to answer these questions?',"b'### Context: \n\nBeing able to automatically answer questions accurately remains a difficult problem in natural language processing. This dataset has everything you need to try your own hand at this task. Can you correctly generate the answer to questions given the Wikipedia article text the question was originally generated from?\n\n### Content: \n\nThere are three question files, one for each year of students: S08, S09, and S10, as well as 690,000 words worth of cleaned text from Wikipedia that was used to generate the questions.\n\nThe ""question_answer_pairs.txt"" files contain both the questions and answers. The columns in this file are as follows:                  \n\n* **ArticleTitle** is the name of the Wikipedia article from which questions and answers initially came.\n* **Question** is the question.\n* **Answer** is the answer.\n* **DifficultyFromQuestioner** is the prescribed difficulty rating for the question as given to the question-writer. \n* **DifficultyFromAnswerer** is a difficulty rating assigned by the individual who evaluated and answered the question, which may differ from the difficulty in field 4.\n* **ArticleFile** is the name of the file with the relevant article\n\nQuestions that were judged to be poor were discarded from this data set.\n\nThere are frequently multiple lines with the same question, which appear if those questions were answered by multiple individuals. \n\n### Acknowledgements: \n\nThese data were collected by Noah Smith, Michael Heilman, Rebecca Hwa, Shay Cohen, Kevin Gimpel, and many students at Carnegie Mellon University and the University of Pittsburgh between 2008 and 2010. It is released here under CC BY_SA 3.0. Please cite this paper if you write any papers involving the use of the data above:\n\nSmith, N. A., Heilman, M., & Hwa, R. (2008, September). Question generation as a competitive undergraduate course project. In Proceedings of the NSF Workshop on the Question Generation Shared Task and Evaluation Challenge.\n\n### You may also like:\n\n* [Question-Answer Jokes: Jokes of the question-answer form from Reddit\'s r/jokes](https://www.kaggle.com/jiriroz/qa-jokes)\n* [Stanford Question Answering Dataset: New Reading Comprehension Dataset on 100,000+ Question-Answer Pairs](https://www.kaggle.com/stanfordu/stanford-question-answering-dataset)\n* [Question Pairs Dataset: Can you identify duplicate questions?](https://www.kaggle.com/quora/question-pairs-dataset)'","b""['linguistics', 'languages', 'artificial intelligence', 'small', 'featured']""",https://www.kaggle.com/rtatman/questionanswer-dataset
b'Company Acquisitions Data',b'Data of Companies acquired by 7 top companies as of May 2018',"b'### Company Acquisitions Data - Top 7 Companies\n\nThis dataset contains the list of acquisitions made by the following companies:    \n\n1. Google  \n2. Microsoft    \n3. Facebook  \n4. Apple  \n5. Yahoo  \n6. Twitter  \n7. IBM  \n\n### Content  \n\nThe attributes include the date, year, month of the acquisition, name of the company acquired, value or the cost of acquisition,  business use-case of the acquisition, and the country from which the acquisition was made. \n\n### Source  \n\nSource of this dataset is Wikipedia  \n\n- https://en.wikipedia.org/wiki/List_of_mergers_and_acquisitions_by_Alphabet (/Apple/Facebook/IBM/Yahoo!/Twitter/Microsoft)   \n\n### Inspiration\n\n- Which company makes the acquisitions quickly \n- What is the trend of business use-cases among the acquired companies throughout the years  \n- What can be forecasted for upcoming years in terms of acquisitions '","b""['business', 'companies', 'small', 'featured']""",https://www.kaggle.com/shivamb/company-acquisitions-7-top-companies
b'Microdados Censo Escolar 2015',b'Parcial:  Escolas + Turmas',"b'O Censo Escolar \xc3\xa9 um levantamento de dados estat\xc3\xadstico-educacionais de \xc3\xa2mbito nacional realizado todos os anos e coordenado pelo Inep. Ele \xc3\xa9 feito com a colabora\xc3\xa7\xc3\xa3o das secretarias estaduais e municipais de Educa\xc3\xa7\xc3\xa3o e com a participa\xc3\xa7\xc3\xa3o de todas as escolas p\xc3\xbablicas e privadas do pa\xc3\xads.\n\nTrata-se do principal instrumento de coleta de informa\xc3\xa7\xc3\xb5es da educa\xc3\xa7\xc3\xa3o b\xc3\xa1sica, que abrange as suas diferentes etapas e modalidades: ensino regular (educa\xc3\xa7\xc3\xa3o Infantil e ensinos fundamental e m\xc3\xa9dio), educa\xc3\xa7\xc3\xa3o especial e educa\xc3\xa7\xc3\xa3o de jovens e adultos (EJA). O Censo Escolar coleta dados sobre estabelecimentos, matr\xc3\xadculas, fun\xc3\xa7\xc3\xb5es docentes, movimento e rendimento escolar.\n\nEssas informa\xc3\xa7\xc3\xb5es s\xc3\xa3o utilizadas para tra\xc3\xa7ar um panorama nacional da educa\xc3\xa7\xc3\xa3o b\xc3\xa1sica e servem de refer\xc3\xaancia para a formula\xc3\xa7\xc3\xa3o de pol\xc3\xadticas p\xc3\xbablicas e execu\xc3\xa7\xc3\xa3o de programas na \xc3\xa1rea da educa\xc3\xa7\xc3\xa3o, incluindo os de transfer\xc3\xaancia de recursos p\xc3\xbablicos como merenda e transporte escolar, distribui\xc3\xa7\xc3\xa3o de livros e uniformes, implanta\xc3\xa7\xc3\xa3o de bibliotecas, instala\xc3\xa7\xc3\xa3o de energia el\xc3\xa9trica, Dinheiro Direto na Escola e Fundo de Manuten\xc3\xa7\xc3\xa3o e Desenvolvimento da Educa\xc3\xa7\xc3\xa3o B\xc3\xa1sica e de Valoriza\xc3\xa7\xc3\xa3o dos Profissionais da Educa\xc3\xa7\xc3\xa3o (Fundeb).\n\nAl\xc3\xa9m disso, os resultados obtidos no Censo Escolar sobre o rendimento (aprova\xc3\xa7\xc3\xa3o e reprova\xc3\xa7\xc3\xa3o) e movimento (abandono) escolar dos alunos do ensino Fundamental e M\xc3\xa9dio, juntamente com outras avalia\xc3\xa7\xc3\xb5es do Inep (Saeb e Prova Brasil), s\xc3\xa3o utilizados para o c\xc3\xa1lculo do \xc3\x8dndice de Desenvolvimento da Educa\xc3\xa7\xc3\xa3o B\xc3\xa1sica (IDEB), indicador que serve de refer\xc3\xaancia para as metas do Plano de Desenvolvimento da Educa\xc3\xa7\xc3\xa3o (PDE), do Minist\xc3\xa9rio da Educa\xc3\xa7\xc3\xa3o.\n\nPara saber mais sobre o Censo Escolar: http://portal.inep.gov.br/basica-censo\n\nApresentados em formato ASCII, os microdados s\xc3\xa3o acompanhados de inputs, ou seja, canais de entrada para leitura dos arquivos por meio da utiliza\xc3\xa7\xc3\xa3o dos softwares SAS e SPSS.\n\nOs Microdados passaram a ser estruturados em formato CSV (Comma-Separated Values), e seus dados est\xc3\xa3o delimitados por Pipe ( | ), de modo a garantir que praticamente qualquer software estat\xc3\xadstico, inclusive open source, consiga importar e carregar as bases de dados.\n\nDevido \xc3\xa0 amplitude de nossas bases, os arquivos foram divididos por regi\xc3\xa3o geogr\xc3\xa1fica (Norte, Nordeste, Sudeste, Sul e Centro-Oeste), tanto para as vari\xc3\xa1veis de Matr\xc3\xadculas, quanto para as de Docentes. \n'","b""['education', 'medium', 'featured']""",https://www.kaggle.com/lucianakeiko/microdados-censo-escolar-2015
b'The Buildings of South East England',b'A large shapefile building outlines ',"b'This dataset is a single large shapefile of the buildings in southeast England. You can use it to make gorgeous maps or join it with other datasets for some really nice visualizations.\n\n### Acknowledgements\n\nThis dataset was kindly made available by [Alasdair Rae][1], with the underlying raw data from the [British Ordnance Survey][2]. You can find [the original shapefiles here][3], plus shapefiles for the rest of the UK.\n\n\n  [1]: https://www.sheffield.ac.uk/usp/staff/alasdair_rae\n  [2]: http://osni-spatial-ni.opendata.arcgis.com/\n  [3]: http://www.statsmapsnpix.com/2017/09/buildings-of-great-britain.html'","b""['geography', 'cities', 'medium', 'featured']""",https://www.kaggle.com/sohier/buildings-of-south-east-england
b'NYS Currently Licensed Wildlife Rehabilitators',b'From New York State Open Data',"b""### Content  \n\nThis dataset contains contact information for Wildlife Rehabilitators as well as the type of animals they handle.  These rehabilitators are licensed by the New York State Department of Environmental Conservation (DEC) Bureau of Fish and Wildlife Services.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/0toU42SB6dk) by [Vincent Van Zalinge](https://unsplash.com/@vincentvanzalinge) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-currently-licensed-wildlife-rehabilitators
b'Kepler Exoplanet Search Results',b'10000 exoplanet candidates examined by the Kepler Space Observatory',"b'### Context\n\nThe Kepler Space Observatory is a NASA-build satellite that was launched in 2009. The telescope is dedicated to searching for exoplanets in star systems besides our own, with the ultimate goal of possibly finding other habitable planets besides our own. The original mission ended in 2013 due to mechanical failures, but the telescope has nevertheless been functional since 2014 on a ""K2"" extended mission.\n\nKepler had verified 1284 new exoplanets as of May 2016. As of October 2017 there are over 3000 confirmed exoplanets total (using all detection methods, including ground-based ones). The telescope is still active and continues to collect new data on its extended mission.\n\n### Content\n\nThis dataset is a cumulative record of all observed Kepler ""objects of interest"" &mdash; basically, all of the approximately 10,000 exoplanet candidates Kepler has taken observations on.\n\nThis dataset has an extensive data dictionary, which can be accessed [here](https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html). Highlightable columns of note are:\n\n* `kepoi_name`: A KOI is a target identified by the Kepler Project that displays at least one transit-like sequence within Kepler time-series photometry that appears to be of astrophysical origin and initially consistent with a planetary transit hypothesis\n* `kepler_name`: [These names] are intended to clearly indicate a class of objects that have been confirmed or validated as planets\xe2\x80\x94a step up from the planet candidate designation.\n* `koi_disposition`: The disposition in the literature towards this exoplanet candidate. One of CANDIDATE, FALSE POSITIVE, NOT DISPOSITIONED or CONFIRMED.\n* `koi_pdisposition`: The disposition Kepler data analysis has towards this exoplanet candidate. One of FALSE POSITIVE, NOT DISPOSITIONED, and CANDIDATE.\n* `koi_score `: A value between 0 and 1 that indicates the confidence in the KOI disposition. For CANDIDATEs, a higher value indicates more confidence in its disposition, while for FALSE POSITIVEs, a higher value indicates less confidence in that disposition.\n\n### Acknowledgements\n\nThis dataset was published as-is by NASA. You can access the original table [here](https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=koi). More data from the Kepler mission is available from the same source [here](https://exoplanetarchive.ipac.caltech.edu/docs/data.html).\n\n### Inspiration\n\n* How often are exoplanets confirmed in the existing literature disconfirmed by measurements from Kepler? How about the other way round?\n* What general characteristics about exoplanets (that we can find) can you derive from this dataset?\n* What exoplanets get assigned names in the literature? What is the distribution of confidence scores?\n\nSee also: the [Kepler Labeled Time Series](https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data) and [Open Exoplanets Catalogue](https://www.kaggle.com/mrisdal/open-exoplanet-catalogue) datasets.'","b""['astronomy', 'space', 'small', 'featured']""",https://www.kaggle.com/nasa/kepler-exoplanet-search-results
b'NYS Law Enforcement Personnel by Agency',b'From New York State Open Data',"b""### Content  \n\nThe Division of Criminal Justice Services (DCJS) collects personnel statistics from more than 500 New York State police and sheriffs\xe2\x80\x99 departments. In New York State, law enforcement agencies use the Uniform Crime Reporting (UCR) system to report their annual personnel counts to DCJS.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/VUHfQD3u7ow) by [Zac Ong](https://unsplash.com/@zacong) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-law-enforcement-personnel-by-agency
b'Total Private Construction Spending Data',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/-VgFfyVwjT8) by [Samuel Zeller](https://unsplash.com/@samuelzeller) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/total-private-construction-spending-data
b'Indian Prison Statistics  (2001 - 2013)',b'Details of Inmates are classified according to 35+ factors. (35+ csv files)',"b'**Connect/Follow me on [LinkedIn](http://link.rajanand.org/linkedin) for more updates on interesting dataset like this. Thanks.**\n\n### Context\n\nThis dataset contains the complete detail about the Prison and various characteristics of inmates. This will help to understand better about prison system in India.\n\n### Content\n\n1. Details of Jail wise population of prison inmates\n1. Details about the list of jails in India at the end of year 2015.\n1. Jail category wise population of inmates. \n1. Capacity of jails by inmate population. \n1. Age group, nationality and gender wise population of inmates.  \n1. Religion and gender wise population of inmates.\n1. Caste and gender wise population of inmates. \n1. Education standards of inmates.  \n1. Domicile of inmates.  \n1. Incidence of recidivism.\n1. Rehabilitation of prisoners.\n1. Distribution of sentence periods of convicts in various jails by sex and age-groups. \n1. Details of under trial prisoners by the type of IPC (Indian Penal Code) offences.\n1. Details of convicts by the type of IPC (Indian Penal Code) offences.\n1. Details of SLL (special & local law) Crime headwise distribution of inmates who convicted\n1. Details of SLL (special & local law) Crime head wise distribution of inmates under trial\n1. Details of educational facilities provided to prisoners. \n1. Details of Jail breaks, group clashes and firing in jail (Tranquility).\n1. Details of wages per day to convicts. \n1. Details of Prison inmates trained under different vocational training.\n1. Details of capital punishment (death sentence) and life imprisonment. \n1. Details of prison inmates escaped. \n1. Details of prison inmates released. \n1. Details of Strength of officials\n1. Details of Total Budget and Actual Expenditure during the year 2015-16.\n1. Details of Budget\n1. Details of Expenditure\n1. Details of Expenditure on inmates\n1. Details of Inmates suffering from mental ilness\n1. Details of Period of detention of undertrials\n1. Details of Number of women prisoners with children\n1. Details of Details of inmates parole during the year\n1. Details of Value of goods produced by inmates\n1. Details of Number of vehicles available\n1. Details of Training of Jail Officers\n1. Details of Movements outside jail premises\n1. Details of Details of electronic equipment used in prison\n\n### Inspiration\n\nThere are many questions about Indian prison with this dataset. Some of the interesting questions are\n\n1. Percentage of jails over crowded. Is there any change in percentage over time?\n1. How many percentage of inmates re-arrested?\n1. Which state/u.t pay more wages to the inmates?\n1. Which state/u.t has more capital punishment/life imprisonment inmates?\n1. Inmates gender ratio per state \n\n\n### Acknowledgements\n\nNational Crime Records Bureau (NCRB), Govt of India has shared this [dataset](https://data.gov.in/dataset-group-name/prison-statistics) under [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).\nNCRB has also shared prison data on their [website](http://ncrb.nic.in/StatPublications/PSI/PrevPublications.htm).'","b""['crime', 'india', 'small', 'featured']""",https://www.kaggle.com/rajanand/prison-in-india
b'Missing people in Russia',b'Records for 2014-2017',"b'### Context\n\nThis is official open data from [The Ministry of Internal Affairs of the Russian Federation][1] on missing and wanted people, identified and unindentified corpses. Original data available here [source][2]. \n\n\n### Content\n\nFile `meta.csv` - contain information about data source and contact information of original owners in Russian.\n\nFile `structure-20140727.csv` - describe datastructure in Russian. Main things that you need to know about data columns are here:\n\n 1. ""Subject""  - The official name of the subject of statistical reporting. That\'s Russian regions, note that Crimean Federal District and city \xe2\x80\x8b\xe2\x80\x8bof Sevastopol are included.\n 2. ""Point FPSR"" - Item of the Federal Statistical Work Plan. You don\'t need to know this.\n 3. ""Name of the statistical factor"" - this one speaks for itself. Available factors:\n\n -- Identified persons from among those who were wanted, including those who disappeared from the bodies of inquiry, investigation, court.\n\n -- Total cases on the identification of citizens on unidentified corpses that were on the register. \n\n -- Total wanted persons, including those who disappeared from the bodies of inquiry, investigation, court. \n\n -- Identified persons from among the wanted persons, including those missing. \n\n -- Total wanted persons. \n\n -- Number (balance) of unreturned missing persons in relation to 2011 (%) \n\n -- Number (balance) of unresolved criminals against 2011 (%) \n\n -- Total discontinued cases in connection with the identification of the person \n\n -- Total wanted persons, including those missing \n\n -- Identified persons from the number of wanted persons \n\n 4. ""Importance of the statistical factor"" - value of correspondent statistical factor.\n\nFiles `data-%Y%m%d-structure-20140727.csv` contain actual data. Names of the files contain release date. Data aggregated by quarters of each year, for example \ndata-20150127-structure-20140727.csv - data for whole 2014 year \ndata-20150627-structure-20140727.csv - data for Q1 and Q2 of 2015\n\nFile `translate.csv` is used to simplify translation from Russian to English. See usage in the kernel.\n\n\n### Acknowledgements\n\nThanks to newspaper [Komsomolskaya Pravda][3] for bringing up the issue of missing kids in Russia.\n\nThanks to [Liza Alert][4] - Volunteer Search and Rescue Squad for efforts in rescue of missing people in Russia. \n\n [Photo by Alessio Lin on Unsplash][5]\n\n### Inspiration\n\nMissing people, especially kids, is a serious problem. However there is not much detailed information about it. Russian officials provide overall information without detalisation of victim\'s age. As a result many speculations appear in media on this topic: \n\n - [Last year about 200,000 reports of missing people were filed with\n   police in Russia.][6]\n - [45,000 kids lost every year][7]\n - [More than 15,000 kids lost every year][8]\n - [Radio interview][9] - starting from minute 7:55 main point: ""More\n   than 15K kids lost completely, i.e. was not ever found""\n\nSome insights to official data can be found here [interview, year 2012][10]: ""Annually in Russia about 20 thousand minors disappear, in 90% of cases the police find children"".\n\nStill there is no information about kids in recent years. If you have any reliable sources, please share.\n\n\n  [1]: https://en.mvd.ru/\n  [2]: https://xn--b1aew.xn--p1ai/%D0%BE%D1%82%D0%BA%D1%80%D1%8B%D1%82%D1%8B%D0%B5-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5/7727739372-MVD_GIAC_3.11\n  [3]: https://www.kp.ru/\n  [4]: http://lizaalert.org/\n  [5]: https://unsplash.com/@lin_alessio\n  [6]: https://www.rbth.com/multimedia/pictures/2017/07/26/when-police-are-powerless-how-volunteers-search-and-find-missing-persons_811700\n  [7]: https://life.ru/t/%D0%BD%D0%BE%D0%B2%D0%BE%D1%81%D1%82%D0%B8/1039505/v_rossii_iezhieghodno_propadaiet_45_tysiach_dietiei\n  [8]: https://www.kp.ru/daily/26683.4/3706104/\n  [9]: https://www.kp.ru/radio/26683.4/3706095/\n  [10]: https://xn--b1aew.xn--p1ai/mvd/structure1/Glavnie_upravlenija/Glavnoe_upravlenie_ugolovnogo_roziska/Publikacii_i_vistuplenija/item/154272'","b""['crime', 'russia', 'small', 'featured']""",https://www.kaggle.com/miniushkin/missing-people-in-russia
b'Stanford Open Policing Project - Florida',b'Data on Traffic and Pedestrian Stops by Police in Florida',"b""###Context: \n\nOn a typical day in the United States, police officers make more than 50,000 traffic stops. The Stanford Open Policing Project team is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public.\n\nIf you'd like to see data regarding other states, please go to https://www.kaggle.com/stanford-open-policing.\n\n### Content: \n\nThis dataset includes over 1 gb of stop data from Florida. Please see the data readme for the full details of the available fields.\n\n###Acknowledgements:\n\nThis dataset was kindly made available by the [Stanford Open Policing Project][1]. If you use it for a research publication, please cite their [working paper][2]:\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, V. Ramachandran, C. Phillips, S. Goel. (2017) \xe2\x80\x9cA large-scale analysis of racial disparities in police stops across the United States\xe2\x80\x9d.\n\n###Inspiration: \n\n - How predictable are the stop rates? Are there times and places that\n   reliably generate stops?\n - Concerns have been raised about jurisdictions using civil forfeiture\n   as a funding mechanism rather than to properly fight drug\n   trafficking. Can you identify any jurisdictions that may be\n   exhibiting this behavior?\n\n  [1]: https://openpolicing.stanford.edu/\n  [2]: https://5harad.com/papers/traffic-stops.pdf""","b""['crime', 'law', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/stanford-open-policing/stanford-open-policing-project-florida
b'Global Terrorism Database',"b'More than 180,000 terrorist attacks worldwide, 1970-2017'","b'# Context \n\nInformation on more than 180,000 Terrorist Attacks\n\nThe Global Terrorism Database (GTD) is an open-source database including information on terrorist attacks around the world from 1970 through 2017. The GTD includes systematic data on domestic as well as international terrorist incidents that have occurred during this time period and now includes more than 180,000 attacks. The database is maintained by researchers at the National Consortium for the Study of Terrorism and Responses to Terrorism (START), headquartered at the University of Maryland.\n[More Information][1]\n\n\n# Content\n\nGeography: Worldwide\n\nTime period: 1970-2017, *except 1993*\n\nUnit of analysis: Attack\n\nVariables: &gt;100 variables on location, tactics, perpetrators, targets, and outcomes\n\nSources: Unclassified media articles (Note: Please interpret changes over time with caution. Global patterns are driven by diverse trends in particular regions, and data collection is influenced by fluctuations in access to media coverage over both time and place.)\n\nDefinition of terrorism:\n\n""The threatened or actual use of illegal force and violence by a non-state actor to attain a political, economic, religious, or social goal through fear, coercion, or intimidation.""\n\nSee the [GTD Codebook][2] for important details on data collection methodology, definitions, and coding schema.\n\n\n# Acknowledgements\n\nThe Global Terrorism Database is funded through START, by the US Department of State (Contract Number: SAQMMA12M1292) and the US Department of Homeland Security Science and Technology Directorate\xe2\x80\x99s Office of University Programs (Award Number 2012-ST-061-CS0001, CSTAB 3.1). The coding decisions and classifications contained in the database are determined independently by START researchers and should not be interpreted as necessarily representing the official views or policies of the United States Government.\n\n[GTD Team][3]\n\n#Publications\n\nThe GTD has been leveraged extensively in [scholarly publications][4], [reports][5], and [media articles][6]. *[Putting Terrorism in Context: Lessons from the Global Terrorism Database][7]*, by GTD principal investigators LaFree, Dugan, and Miller investigates patterns of terrorism and provides perspective on the challenges of data collection and analysis. The GTD\'s data collection manager, Michael Jensen, discusses important [Benefits and Drawbacks of Methodological Advancements in Data Collection and Coding][8].\n\n\n# Terms of Use\n\nUse of the data signifies your agreement to the following [terms and conditions][9].\n\nEND USER LICENSE AGREEMENT WITH UNIVERSITY OF MARYLAND\n\nIMPORTANT \xe2\x80\x93 THIS IS A LEGAL AGREEMENT BETWEEN YOU (""You"") AND THE UNIVERSITY OF MARYLAND, a public agency and instrumentality of the State of Maryland, by and through the National Consortium for the Study of Terrorism and Responses to Terrorism (\xe2\x80\x9cSTART,\xe2\x80\x9d \xe2\x80\x9cUS,\xe2\x80\x9d \xe2\x80\x9cWE\xe2\x80\x9d or \xe2\x80\x9cUniversity\xe2\x80\x9d). PLEASE READ THIS END USER LICENSE AGREEMENT (\xe2\x80\x9cEULA\xe2\x80\x9d) BEFORE ACCESSING THE Global Terrorism Database (\xe2\x80\x9cGTD\xe2\x80\x9d). THE TERMS OF THIS EULA GOVERN YOUR ACCESS TO AND USE OF THE GTD WEBSITE, THE DATA, THE CODEBOOK, AND ANY AUXILIARY MATERIALS. BY ACCESSING THE GTD, YOU SIGNIFY THAT YOU HAVE READ, UNDERSTAND, ACCEPT, AND AGREE TO ABIDE BY THESE TERMS AND CONDITIONS.  IF YOU DO NOT ACCEPT THE TERMS OF THIS EULA, DO NOT ACCESS THE GTD. \n\nTERMS AND CONDITIONS\n\n1. \tGTD means Global Terrorism Database data and the online user interface (www.start.umd.edu/gtd) produced and maintained by the National Consortium for the Study of Terrorism and Responses to Terrorism (START). This includes the data and codebook, any auxiliary materials present, and the user interface by which the data are presented.\n \n2.\tLICENSE GRANT. University hereby grants You a revocable, non-exclusive, non-transferable right and license to access the GTD and use the data, the codebook, and any auxiliary materials solely for non-commercial research and analysis.\n\n3.\tRESTRICTIONS.  You agree to NOT:\na. \tpublicly post or display the data, the codebook, or any auxiliary materials without express written permission by University of Maryland (this excludes publication of analysis or visualization of the data for non-commercial purposes);\nb.\tsell, license, sublicense, or otherwise distribute the data, the codebook, or any auxiliary materials to third parties for cash or other considerations;\nc. \tmodify, hide, delete or interfere with any notices that are included on the GTD or the codebook, or any auxiliary materials;\nd.\tuse the GTD to draw conclusions about the official legal status or criminal record of an individual, or the status of a criminal or civil investigation;\ne.\tinterfere with or disrupt the GTD website or servers and networks connected to the GTD website; or\nf. \tuse robots, spiders, crawlers, automated devices and similar technologies to screen-scrape the site or to engage in data aggregation or indexing of the data, the codebook, or any auxiliary materials other than in accordance with the site\xe2\x80\x99s robots.txt file.\n\n4. YOUR RESPONSIBILITIES:\na.\tAll information sourced from the GTD should be acknowledged and cited as follows: ""National Consortium for the Study of Terrorism and Responses to Terrorism (START), University of Maryland. (2018). The Global Terrorism Database (GTD) [Data file]. Retrieved from https://www.start.umd.edu/gtd"" \nb.\tYou agree to acknowledge any copyrightable materials with a copyright notice \xe2\x80\x9cCopyright University of Maryland 2018.\xe2\x80\x9d\nc.\tAny modifications You make to the GTD for published analysis must be clearly documented and must not misrepresent analytical decisions made by START.\nd. \tYou agree to seek out an additional agreement in order to use the GTD, the data, the codebook or auxiliary materials for commercial purposes, or to create commercial product or services based on the GTD, the data, the codebook or auxiliary materials.\n\n5.  \tINTELLECTUAL PROPERTY.  The University owns all rights, title, and interest in the GTD, the data and codebook, and all auxiliary materials.  This EULA does not grant You any rights, title, or interests in the GTD or the data, the codebook, user interface, or any auxiliary materials other than those expressly granted to you under this EULA.\n\n6.\tDISCLAIMER AND LIMITATION ON LIABILITY.\na.\tTHE GTD, THE CODEBOOK, USER INTERFACE, OR ANY AUXILIARY MATERIALS ARE MADE AVAILABLE ON AN ""AS IS"" BASIS. UNIVERSITY DISCLAIMS ANY AND ALL REPRESENTATIONS AND WARRANTIES \xe2\x80\x93 WHETHER EXPRESS OR IMPLIED, ORAL OR WRITTEN, IN FACT OR ARISING BY OPERATION OF LAW \xe2\x80\x93 WITH RESPECT TO THE GTD, THE CODEBOOK, AND ANY AUXILIARY MATERIALS INCLUDING, BUT NOT LIMITED TO, WARRANTIES OF MERCHANTABILITY, SATISFACTORY QUALITY, FITNESS FOR A PARTICULAR PURPOSE, AND NONINFRINGEMENT OF THE INTELLECTUAL PROPERTY OR PROPRIETARY RIGHTS OF ANY THIRD PARTY. UNIVERSITY MAKES NO REPRESENTATION OR WARRANTY THAT THE GTD, THE CODEBOOK, ANY AUXILIARY MATERIALS, OR USER INTERFACE WILL OPERATE ERROR FREE OR IN AN UNINTERRUPTED FASHION.\nb. \tIn no event will the University be liable to You for any incidental, special, punitive, exemplary or consequential damages of any kind, including lost profits or business interruption, even if advised of the possibility of such claims or demands, whether in contract, tort, or otherwise, arising in connection with Your access to and use of the GTD, the codebook, user interface, or any auxiliary materials or other dealings.  This limitation upon damages and claims is intended to apply without regard to whether other provisions of this EULA have been breached or proven ineffective. In no event will University\xe2\x80\x99s total liability for the breach or nonperformance of this EULA exceed the fees paid to University within the current billing cycle.\nc.\tEvery reasonable effort has been made to check sources and verify facts in the GTD; however, START cannot guarantee that accounts reported in the open literature are complete and accurate. START shall not be held liable for any loss or damage caused by errors or omissions or resulting from any use, misuse, or alteration of GTD data by the USER. The USER should not infer any additional actions or results beyond what is presented in a GTD entry and specifically, the USER should not infer an individual referenced in the GTD was charged, tried, or convicted of terrorism or any other criminal offense. If new documentation about an event becomes available, START may modify the data as necessary and appropriate.\nd. \tUniversity is under no obligation to update the GTD, the codebook, user interface, or any auxiliary materials.  \n\n7.\tINDEMNITY. You hereby agree to defend, indemnify, and hold harmless the University and its employees, agents, directors, and officers from and against any and all claims, proceedings, damages, injuries, liabilities, losses, costs, and expenses (including reasonable attorneys\xe2\x80\x99 fees and litigation expenses) relating to or arising out of Your use of the GTD, the codebook, or any auxiliary materials or Your breach of any term in this EULA.  \n\n8.\tTERM AND TERMINATION\na.\tThis EULA and your right to access the GTD website and use the data, the codebook, and any auxiliary materials will take effect when you access the GTD.\nb.\tUniversity reserves the right, at any time and without prior notice, to modify, discontinue or suspend, temporarily or permanently, Your access to the GTD website (or any part thereof) without liability to You. \n\n9.\tMISCELLANEOUS \na.\tThe University may modify this EULA at any time. Check the GTD website for modifications. \nb.\tNo term of this Agreement can be waived except by the written consent of the party waiving compliance.\nc.\tIf any provision of this EULA is determined by a court of competent jurisdiction to be void, invalid, or otherwise unenforceable, such determination shall not affect the remaining provisions of this Agreement.\nd.\tThis Agreement does not create a joint venture, partnership, employment, or agency relationship between the Parties.\ne.\tThere are no third party beneficiaries to this agreement. You may not assign this agreement without the University\xe2\x80\x99s prior written approval.\nf.\tThis EULA shall be governed by and interpreted in accordance with United States copyright law and the laws of the State of Maryland without reference to its conflicts of laws rules. Nothing in this EULA is or shall be deemed to be a waiver by the University of any of its rights or status as an agency and instrumentality of the State of Maryland. The parties mutually agree to opt out of application of the Maryland Uniform Computer Information Transactions Act (MUCITA), Maryland Code Annotated [Commercial Law] 21-101 through 21-816 to the greatest extent authorized under MUCITA.  \ng.\tThis EULA represents the entire agreement between You and the University regarding the subject matter of paragraphs 1-10. There are no other understandings, written or oral, that are not included in this Agreement. \n\n10.\tREPRESENTATION.  You represent that You are at least 18 years of age.\n\n\n#Training\nSTART has released the first in a series of [training modules][10] designed to equip GTD users with the knowledge and tools to best leverage the database. This training module provides a general overview of the GTD, including the data collection process, uses of the GTD, and patterns of global terrorism. Participants will learn basic data handling and how to generate summary statistics from the GTD using PivotTables in Microsoft Excel.\n\n\n#Questions?\n\nFind answers to [Frequently Asked Questions][11].\n\nContact the GTD staff at gtd@start.umd.edu.\n\n\n  [1]: http://start.umd.edu/gtd\n  [2]: http://start.umd.edu/gtd/downloads/Codebook.pdf\n  [3]: http://start.umd.edu/gtd/about/GTDTeam.aspx\n  [4]: https://scholar.google.com/scholar?hl=en&q=%22Global%20Terrorism%20Database%22&btnG=&as_sdt=1%2C21&as_sdtp=\n  [5]: http://www.start.umd.edu/publications?combine=&author%5B%5D=13781&year%5Bvalue%5D%5Byear%5D=\n  [6]: http://www.start.umd.edu/start-in-the-news?combine=Global%20Terrorism%20Database\n  [7]: http://www.start.umd.edu/publication/putting-terrorism-context-lessons-global-terrorism-database-contemporary-terrorism\n  [8]: http://www.start.umd.edu/news/discussion-point-benefits-and-drawbacks-methodological-advancements-data-collection-and-coding\n  [9]: http://start.umd.edu/gtd/terms-of-use/\n  [10]: http://www.start.umd.edu/training/using-global-terrorism-database-introduction-module-1\n  [11]: http://www.start.umd.edu/gtd/faq/'","b""['crime', 'terrorism', 'international relations', 'medium', 'featured']""",https://www.kaggle.com/START-UMD/gtd
b'InceptionV3',b'InceptionV3 Pre-trained Model for PyTorch',"b'# InceptionV3\n\n---\n\n## Rethinking the Inception Architecture for Computer Vision\nConvolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5% top-5 error on the validation set (3.6% error on the test set) and 17.3% top-1 error on the validation set.\n<br>\n\n**Authors: Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna**<br>\n**https://arxiv.org/abs/1512.00567**\n\n---\n\n#InceptionV3 Architecture<br>\n![InceptionV3 Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n  [1]: https://4.bp.blogspot.com/-TMOLlkJBxms/Vt3HQXpE2cI/AAAAAAAAA8E/7X7XRFOY6Xo/s1600/image03.png'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/inceptionv3
b'LA EBEWE Program (Energy & Water Efficiency)',b'From Los Angeles Open Data',"b""### Content  \n\nThe City's Existing Buildings Energy & Water Efficiency (EBEWE) Program was established in 2016 (LA Municipal Code Section 91.9701, Ordinance No. 184674) and is administered by the Department of Building and Safety (LADBS).  It requires that owners of buildings subject to the ordinance file an annual benchmark report of energy and water usage for their buildings.  The EBEWE dataset includes the compliance year, building address, compliance status, and various energy and water use benchmark data.  For a complete explanation of the Program, including reporting requirements, please visit LADBS' EBEWE site at http://www.ladbs.org/services/green-building-sustainability/existing-buildings-energy-water-efficiency-program.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/7kg-KHohJqI) by [Tim Vanderhoydonck](https://unsplash.com/@_vdhd) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/la-ebewe-program-energy-water-efficiency
b'OECD Business Tendency Surveys for Manufacturing',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/F0TfU0S5Yhw) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'utility', 'small', 'featured']""",https://www.kaggle.com/oecd-org/oecd-business-tendency-surveys-for-manufacturing
b'NYC Financial Empowerment Centers',b'From New York City Open Data',"b""### Content  \n\nThis is a list of the Department of Consumer Affairs, Office of Financial Empowerment Financial Empowerment Centers includes information on the provider, host site, address, hours of operations, languages spoken on-site, and more specific data about the location.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/twoahjAsoO4) by [Haley Phelps](https://unsplash.com/@haleyephelps) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'banking', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-financial-empowerment-centers
b'Clothing Item Detection for E-Commerce',"b'Images from E-commerce with bounding boxes drawn around shirts, jackets etc.'","b'### Context\n\n**Images from E-commerce sites with bounding boxes drawn around shirts, jackets, sunglasses etc.**\n\n**Visualize and see the dataset:**\n\nhttps://dataturks.com/projects/devika.mishra/E-commerce%20Tagging%20for%20clothing\n\n\n### Content\n\nThe dataset has 907 items of which 504 items have been manually labeled.\n\n**Examples:**\n\n![enter image description here][1]\n\n![enter image description here][2]\n\n![enter image description here][3]\n\nThe labels are divided into following 9 categories:\n\nJackets\nJeans\nShirts\nShoes\nSkirts\nsunglasses\nTops\nTrousers\nTshirts\n\n![enter image description here][4]\n\n\nKey Features\n\n907 items\n9 categories\nHuman labeled dataset\n\nDistribution:\n\n![enter image description here][5]\n\n\n### Acknowledgements\n\nOriginal Location: https://dataturks.com/projects/devika.mishra/E-commerce%20Tagging%20for%20clothing\n\n\n  [1]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/clothing_2.png\n  [2]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/clothing_3.png\n  [3]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/clothing_4.png\n  [4]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/clothing_1.png\n  [5]: https://storage.googleapis.com/bonsai-b808c.appspot.com/dataturks/extras/clothing_5.png'","b""['image data', 'multiclass classification', 'object detection', 'object recognition', 'object labeling', 'small', 'featured']""",https://www.kaggle.com/dataturks/clothing-item-detection-for-ecommerce
b'2015 American Community Survey',b'Detailed information about the American people and workforce',"b'# The 2015 American Community Survey Public Use Microdata Sample\n\n## Context\n\nThe American Community Survey (ACS) is an ongoing survey that provides vital information on a yearly basis about our nation and its people. Information from the survey generates data that help determine how more than $400 billion in federal and state funds are distributed each year.\n\n* **Frequency**: Annual\n* **Period**: 2015\n\n## PWGTP (Weights)\n\nPlease note. Each record is weighted with **PWGTP**.  For accurate analysis, these weights need to be applied.  Reference [Getting Started \'Python\'][1] for a simple kernel on how this field gets used.  Or, click on the\nimage below to see how this can be done in R (see code in this kernel).\n\n<a href=""https://www.kaggle.com/mchirico/d/census/2015-american-community-survey/2015-population-by-age-and-race""><img src=""https://storage.googleapis.com/montco-stats/imagesUploaded/Screenshot2017-01-3020.34.26.png"" width=""700""></a>\n\nThe Data Dictionary can be found [here](http://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/PUMSDataDict15.txt), but you\'ll need to scroll down to\nthe *PERSON RECORD* section. \n\n## Content\n\nThrough the ACS, we know more about jobs and occupations, educational attainment, veterans, whether people own or rent their home, and other topics. Public officials, planners, and entrepreneurs use this information to assess the past and plan the future. When you respond to the ACS, you are doing your part to help your community plan hospitals and schools, support school lunch programs, improve emergency services, build bridges, and inform businesses looking to add jobs and expand to new markets, and more. The data dictionary can be found [here][2].\n\n### Inspiration\n\nKernels created using the [2014 ACS][3] and  [2013 ACS][4] can serve as excellent starting points for working with the 2015 ACS. For example, the following analyses were created using ACS data:\n\n* [Work arrival times and earnings in the USA][5]\n* [Inequality in STEM careers][6]\n\n## Acknowledgements\n\nThe American Community Survey (ACS) is administered, processed, researched and disseminated by the U.S. Census Bureau within the U.S. Department of Commerce.\n\n\n  [1]: https://www.kaggle.com/mchirico/d/census/2015-american-community-survey/getting-started-with-2015-acs\n  [2]: http://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/PUMSDataDict14.pdf\n  [3]: https://www.kaggle.com/census/2014-american-community-survey/kernels\n  [4]: https://www.kaggle.com/census/2013-american-community-survey/kernels\n  [5]: https://www.kaggle.com/romanpopat/d/census/2013-american-community-survey/wake-me-up-before-you-go-go/run/40491/notebook\n  [6]: https://www.kaggle.com/minkles/d/census/2013-american-community-survey/inequality-in-stem\n  [7]: https://www.kaggle.io/svf/40491/67ea0531d5c3084d7f211732d8150afc/output_files/figure-html/unnamed-chunk-6-1.png'","b""['demographics', 'employment', 'sociology', 'large', 'featured']""",https://www.kaggle.com/census/2015-american-community-survey
b'World Telecom Subscriptions',b'Mobile cell subscription rates by country',"b'### Context\n\n\xe2\x80\x9c[International Telecommunication Union][1]\xe2\x80\x99s ICT Facts and Figures 2017 shows that great strides are being made in expanding Internet access through the increased availability of broadband networks. Digital connectivity plays a critical role in bettering lives, as it opens the door to unprecedented knowledge, employment and financial opportunities for billions of people worldwide,\xe2\x80\x9d said ITU Secretary-General Houlin Zhao.\n\nThe [ITU][1] estimates that there were about 6 billion mobile subscriptions globally in the early 2010s. No technology has ever spread faster around the world. Mobile communications have a particularly important impact in rural areas. The mobility, ease of use, flexible deployment, and relatively low and declining rollout costs of wireless technologies enable them to reach rural populations with low levels of income and literacy. \n\n### Content\n\nThe data provides the number of fixed telephone, fixed broadband and mobile cellular subsctipions per 100 people, covering 264 countries between 1960 (where applicable) and 2015. \n\n\n### Acknowledgements\n\nThe data is provided by the [World Bank][2], from the [ITU][1] World Telecommunication/ICT Development Report and database.\n\nThe [International Telecommunication Union][1] is the United Nations specialized agency for information and communication technologies \xe2\x80\x93 ICTs. is the United Nations specialized agency for information and communication technologies \xe2\x80\x93 ICTs.\n\n\n  [1]: https://www.itu.int\n  [2]: https://data.worldbank.org'","b""['internet', 'world', 'telecommunications', 'small', 'featured']""",https://www.kaggle.com/taniaj/world-telecommunications-data
b'NYS Youth Admission and Discharge Demographics',b'From New York State Open Data',"b""### Content  \n\nThis dataset provides county-level demographic data (sex, adjudication, age, race/ethnicity, and service setting) for youth admitted to and discharged from the care and custody of the Office of Children and Family Services (OCFS) each year. Data are counted using a youth\xe2\x80\x99s first admission or discharge in a calendar year. Admissions data are aggregate based on the responsible (court) county. Discharges data are aggregate based on the county of residence.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/yl1wEVqEY8k) by [Caroline Hernandez](https://unsplash.com/@carolinehdz) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'utility', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-youth-admission-and-discharge-demographics
b'Reddit r/Place History',b'All 16 million moves in the r/place collaborative art project',"b'### Context\n\nr/Place was a wildly successful April Fool\'s joke perpetrated by Reddit over the course of 72 hours April 1-3, 2017. The rules of Place, quoting u/Drunken_Economist were:\n\n* There is an empty canvas.\n* You may place a tile upon it, but you must wait to place another.\n* Individually you can create something.\n* Together you can create something more.\n\n1.2 million redditors used these premises to build the largest collaborative art project in history, painting (and often re-painting) a million-pixel canvas with 16.5 million tiles in 16 colors.\n\nThe canvas started out completely blank, and ended looking like this:\n\n![](https://www.kaggle.io/svf/1524078/9f348000571338d18ca84afa042957f7/__results___files/__results___18_1.png)\n\nHow did *that* happen?\n\n### Content\n\nThis dataset is a full time placement history for r/place over time. Each record is a single move: one user changing one pixel to one of 15 different colors.\n\n### Acknowledgements\n\n[This data was published as-is by Reddit](https://www.reddit.com/r/redditdata/comments/6640ru/place_datasets_april_fools_2017/).\n\n### Inspiration\n\nUsers were heavily rate-limited in their ability to place pixels, so this dataset shows what happens when users of similar stripes ""band together"" to build something greater than themselves. With a pixel-by-pixel history, what can you tell about the relative popularity of different regions in the figure? Can you use image analysis techniques to segment the image into different regions, and measure what happens to them over time?'","b""['internet', 'popular culture', 'medium', 'featured']""",https://www.kaggle.com/residentmario/reddit-rplace-history
b'NYC Greenthumb Community Gardens',b'From New York City Open Data',"b""### Content  \n\nListing of NYC Greenthumb community gardens  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/6bKpHAun4d8) by [Toa Heftiba](https://unsplash.com/@heftiba) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-greenthumb-community-gardens
b'Chocolate Bar Ratings',"b'Expert ratings of over 1,700 chocolate bars'","b'### Context\nChocolate is one of the most popular candies in the world. Each year, residents of the United States collectively eat more than 2.8 billions pounds. However, not all chocolate bars are created equal! This dataset contains expert ratings of over 1,700 individual chocolate bars, along with information on their regional origin, percentage of cocoa, the variety of chocolate bean used and where the beans were grown.\n\n### Flavors of Cacao Rating System:\n\n* 5= Elite (Transcending beyond the ordinary limits)\n* 4= Premium (Superior flavor development, character and style)\n* 3= Satisfactory(3.0) to praiseworthy(3.75) (well made with special qualities)\n* 2= Disappointing (Passable but contains at least one significant flaw)\n* 1= Unpleasant (mostly unpalatable)\n\nEach chocolate is evaluated from a combination of both objective qualities and subjective interpretation. A rating here only represents an experience with one bar from one batch. Batch numbers, vintages and review dates are included in the database when known. \n\nThe database is narrowly focused on plain dark chocolate with an aim of appreciating the flavors of the cacao when made into chocolate. The ratings do not reflect health benefits, social missions, or organic status.\n\n**Flavor** is the most important component of the Flavors of Cacao ratings. Diversity, balance, intensity and purity of flavors are all considered. It is possible for a straight forward single note chocolate to rate as high as a complex flavor profile that changes throughout. Genetics, terroir, post harvest techniques, processing and storage can all be discussed when considering the flavor component. \n\n**Texture** has a great impact on the overall experience and it is also possible for texture related issues to impact flavor. It is a good way to evaluate the makers vision, attention to detail and level of proficiency.\n\n**Aftermelt** is the experience after the chocolate has melted. Higher quality chocolate will linger and be long lasting and enjoyable. Since the aftermelt is the last impression you get from the chocolate, it receives equal importance in the overall rating.\n\n**Overall** Opinion is really where the ratings reflect a subjective opinion. Ideally it is my evaluation of whether or not the components above worked together and an opinion on the flavor development, character and style. It is also here where each chocolate can usually be summarized by the most prominent impressions that you would remember about each chocolate.\n\n### Acknowledgements\n\nThese ratings were compiled by Brady Brelinski, Founding Member of the Manhattan Chocolate Society. For up-to-date information, as well as additional content (including interviews with craft chocolate makers), please see his website: [Flavors of Cacao](http://flavorsofcacao.com/index.html)\n\n### Inspiration\n\n* Where are the best cocoa beans grown?\n* Which countries produce the highest-rated bars?\n* What\xe2\x80\x99s the relationship between cocoa solids percentage and rating?'","b""['food and drink', 'critical theory', 'small', 'featured']""",https://www.kaggle.com/rtatman/chocolate-bar-ratings
b'WUZZUF Job Posts (2014-2016)',b'Explore jobs and job seekers applications on WUZZUF (2014-2016)',"b'# Context \n\nOne of the main challenges in any marketplace business is achieving the balance between demand and supply. At **WUZZUF** we optimize for demand, relevance and quality while connecting employers with the matching applicants, and recommending relevant jobs to the job seekers. \n\n\n# Content\n\nThe dataset includes:\n\n-  **Wuzzuf_Job_Posts_Sample** : a sample of jobs posted on **WUZZUF** during 2014-2016.\n\n-  **Wuzzuf_Applications_Sample** : the corresponding applications  (Excluding some entries). \n\n**Note**:  The jobs are mainly in Egypt but other locations are included.\n\n\n# Exploration Ideas\n\nThere are several areas to explore, including, but not limited to: \n\n - Correlations between different features\n \n - Salaries trends\n\n - Insights about supply/demand\n\n - Growth opportunities\n\n - Data quality\n'","b""['employment', 'medium', 'featured']""",https://www.kaggle.com/WUZZUF/wuzzuf-job-posts
b'Seattle Rent and Income Restricted Housing',b'From City of Seattle Open Data',"b""### Content  \n\nHousing with Rent and Income Restricted Units in Seattle\n\nSome homes are in buildings where other units are market-rate. Excludes locations with fewer than four income-restricted affordable homes (except for those in the Rainier Vista, New Holly, High Point, and Yesler Terrace neighborhoods) and locations that are confidential to protect the safety of residents. Information current as of 3/31/2018 and subject to change.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/7o-DzXL6nlY) by [Tyler Nix](https://unsplash.com/@jtylernix) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-rent-and-income-restricted-housing
b'DenseNet-169',b'DenseNet-169 Pre-trained Model for Pytorch',"b'\n# DenseNet-169\n\n---\n\n## Densely Connected Convolutional Networks<br>\n\nRecent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and models are available at this [https URL][1].\n\n**Authors: Gao Huang, Zhuang Liu, Kilian Q. Weinberger, Laurens van der Maaten**<br>\n**https://arxiv.org/abs/1608.06993**\n\n---\n\n\n![DenseNet][2]\n\n## DenseNet Architectures\n![DenseNet Architectures][3]\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://github.com/liuzhuang13/DenseNet\n  [2]: https://imgur.com/wWHWbQt.jpg\n  [3]: https://imgur.com/oiTdqJL.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/densenet169
b'Tarantino Scripts',"b'Scripts of Django Unchained, Reservoir Dogs, Inglorious Basterds & Pulp Fiction'","b""### Context\n\nI am a bit of a fan of Tarantino's work, and so I collected the scripts of 4 of his movies- Django Unchained, Inglorious Basterds, Pulp Fiction and Reservoir Dogs. The main aim was to create a Tarantino script generator using LSTMs in this kernel. Just as a disclaimer, since this is Tarantino, there is a bit of cussing in the scripts itself and I have not censored them.\n\n\n### Content\n\nThe files have not been categorized into  specific rows or columns- these are just raw scripts. The file tarantino_scripts.txt basically has all 4 scripts concatenated one after the other, for the text generator's input.\n\n\n### Acknowledgements\n\nI used this site to get the scripts- [IMSDb][1]\n\n\n### Inspiration\n\nA script generator, better than the one I made (mine isn't that great), or for text mining or some visual representation of the data.\n\nCover Photo by [Chris Murray on Unsplash][2]\n\n\n\n  [1]: http://www.imsdb.com\n  [2]: https://unsplash.com/photos/qtKVfAdF3_s""","b""['text data', 'popular culture', 'small', 'featured']""",https://www.kaggle.com/aadityanaik/shakespeareworks
b'Stanford Open Policing Project - Washington State',b'Data on Traffic and Pedestrian Stops by Police in Washington',"b""###Context: \n\nOn a typical day in the United States, police officers make more than 50,000 traffic stops. The Stanford Open Policing Project team is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public.\n\nIf you'd like to see data regarding other states, please go to https://www.kaggle.com/stanford-open-policing.\n\n### Content: \n\nThis dataset includes 2gb of stop data from Washington state. Please see the data readme for the full details of the available fields.\n\n###Acknowledgements:\n\nThis dataset was kindly made available by the [Stanford Open Policing Project][1]. If you use it for a research publication, please cite their [working paper][2]:\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, V. Ramachandran, C. Phillips, S. Goel. (2017) \xe2\x80\x9cA large-scale analysis of racial disparities in police stops across the United States\xe2\x80\x9d.\n\n###Inspiration: \n\n - How predictable are the stop rates? Are there times and places that\n   reliably generate stops?\n - Concerns have been raised about jurisdictions using civil forfeiture\n   as a funding mechanism rather than to properly fight drug\n   trafficking. Can you identify any jurisdictions that may be\n   exhibiting this behavior?\n\n  [1]: https://openpolicing.stanford.edu/\n  [2]: https://5harad.com/papers/traffic-stops.pdf""","b""['crime', 'law', 'large', 'featured']""",https://www.kaggle.com/stanford-open-policing/stanford-open-policing-project-washington-state
b'Agriculture Crop Production In India',b'Various Crops Cultivation/Production',"b'### Context\nAgricuture Production in India from 2001-2014\n\n### Content\n\nThis Dataset Describes the Agricuture Crops Cultivation/Production in india. This is from https://data.gov.in/ fully Licensed\n\n### Acknowledgements\n\nThis Dataset can solves the problems of various crops Cultivation/production in india.\n\n###Columns\ncrop:string, crop name\nVariety:string,crop subsidary name\nstate: string,Crops Cultivation/production Place\nQuantity:Integer,no of Quintals/Hectars\nproduction:Integer,no of years Production\nSeason:DateTime,medium(no of days),long(no of days)\nUnit:String , Tons\nCost:Integer, cost of cutivation and Production\nRecommended Zone:String ,place(State,Mandal,Village)\n\n\n\n### Inspiration\nAcross The Globe India Is The Second Largest Country having People more than 1.3 Billion.\nMany People Are Dependent On The Agricuture And it is the Main Resource.\nIn Agricuturce Cultivation/Production Having More Problems. \nI want to solve the Big problem in india and usefull to  many more people'","b""['business', 'india', 'agriculture', 'small', 'featured']""",https://www.kaggle.com/srinivas1/agricuture-crops-production-in-india
b'NEWS SUMMARY',b'Generating short length descriptions of news articles.',"b""### Context\n\nI am currently working on summarizing chat context where it helps an agent in understanding previous context quickly. It interests me to apply the deep learning models to existing datasets and how they perform on them. I believe news articles are rich in grammar and vocabulary which allows us to gain greater insights.\n\n\n### Content\n\nThe dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. I gathered the summarized news from Inshorts and only scraped the news articles from Hindu, Indian times and Guardian.  Time period ranges from febrauary to august 2017.\n\n### Acknowledgements\n\nI would like to thank the authors of Inshorts for their amazing work\n\n### Inspiration\n\n* Generating short length descriptions(headlines) from text(news articles).\n* Summarizing large amount of information which can be represented in compressed space\n\n###Purpose\n\nWhen I was working on the summarization task I didn't find any open source data-sets to work on, I believe there are people just like me who are working on these tasks and I hope it helps them.\n\n###Contributions\n\nIt will be really helpful if anyone found nice insights from this data and can share their work. Thankyou...!!!\n\nFor those who are interested here is the link for the github code which includes the scripts for scraping.\nhttps://github.com/sunnysai12345/News_Summary""","b""['linguistics', 'india', 'journalism', 'medium', 'featured']""",https://www.kaggle.com/sunnysai12345/news-summary
b'Travian Troops',b'Details about troops from 5 races in the browser-based game Travian',"b'These two files contain the same information about all troops of all races available in Travian game (EN - english, SP - spanish). Travian game is a game about war, so the kind of troops you have in your army can be critical for victory in a single battle. You must grow a efficient army as fast as you can, and then maximize its value.\nIn this game, in order to deffend a village, you can be helped by other players, so your def army would be a combination of all troops and races. But in order to attack a village, you can not be helped, you just can manage your own army, and available troops will depend on the race you have chosen. The files contain the following clomuns:\n\n- Name: name of the troop.\n\n- Race: chosen race of the player (gauls, romans, teutons, egyptians or huns).\n\n- Class: infantry, cavalry, assault or nothing( for troops used for village expansion).\n\n- Wood, Clay, Iron, Crop: cost of each resource to train a troop.\n\n- Attack: attack value of the troop.\n\n- Definf: deffence value of the troop against infantry.\n\n- Delcav: deffence value of the troop against cavalry.\n\n- Speed: movement speed of the troop.\n\n- Loot: amount of resources that the troop can steal.\n\n- Cons: amount of crop per hour that the troop needs to survive (like food).\n\n- Time: minutes needed for the troop to be trained.\n\nThe most important thing to know here is the consume of the troops (Cons). When you have a big army, you will need a lot of crop per hour. Your crop production is limited by your croplands, so you will have something like -23.545 crop per hour. This problem is solved by having high capacity granaries with available crops in them.\nTime period is not important, and you can always have this data in Travian official web (https://t4.answers.travian.com/).\nFinally, you can use this dataset with the Travian Buildings dataset if you want to think about the fact that attack and defence values can be upgraded in the Smithy building. Troops start with the values in the dataset (level o), and can be upgraded to level 20, increasing 1,5% per each level, so at maximum level, it would be: (initial value)*(1,015^20).\n\nAll this data can answer questions like:\nWhich troops are cheapest and more expensive?\nWhich ones are better for attack and deffend?\nWhich combination in each race is the best for a consume of crop of 50.000 per hour for an attack?\nIf the developers of the game create new troops, how much they should cost, depending on the other stats?\nHow far is it profitable to upgrade the troops in the smithy?\n'","b""['video games', 'war', 'small', 'featured']""",https://www.kaggle.com/cblesa/travian-troops
b'Seattle Use of Force',b'From City of Seattle Open Data',"b""### Content  \n\nRecords representing Use of Force (UOF) by sworn law enforcement officers of the Seattle Police Department.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/IxooIwnNjCA) by [Spenser](https://unsplash.com/@spensewithans) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-use-of-force
b'Colonia Corpus of Historical Portuguese',b'A 5.1 million word corpus of historical Portuguese',"b'### Context: \nPortuguese is a romance language that is the native language of over 215 million speakers worldwide. Like Spanish, English and French, it was the language of both its country of origin and also that country\xe2\x80\x99s colonial possessions. This corpus contains examples of historical Portuguese  written between 1500 and 1936, both in Portugal and Brazil.\n\n### Content: \nThe corpus contains complete Portuguese manuscripts published from 1500 to 1936 divided into 5 sub-corpora per century (summarized in the table below). The part of speech (POS) of words in this corpus was tagged using [TreeTagger](http://www.ims.uni-stuttgart.de/forschung/ressourcen/werkzeuge/treetagger.html). You can find more information on this corpus on the [Colonia homepage](http://corporavm.uni-koeln.de/colonia/index.html).\n\nCentury\tTexts\tTokens\n16th\t13\t399,245\n17th\t18\t709,646\n18th\t14\t425,624\n19th\t38\t2,490,771\n20th\t17\t1,132,696\nTotal\t100\t5,157,982\n\nTexts are balanced in terms of the variety, consisting of 48 European Portuguese texts and 52 Brazilian Portuguese texts. You can find more information in the paper that describes the corpus. The complete inventory of texts is here and more detail regarding annotation can be found here.\n\n### Part of Speech (POS) Tags\n\nThe works in this corpus have been automatically tagged for their part of speech (POS). The tagset used to annotate the corpus is presented in the table below. It contains not only the classic POS tags (e.g. V, DET, N) but also a couple of compound tags, such as the combination of preposition plus determiner as (PREP+DET) or verb plus pronoun (V+P). The tool used to annotate the corpus was TreeTagger.\n\nCategory\tPOS\tExample\nAdjective\tADJ\tbonita\nAdverb\tADV\tmuita\nDeterminer\tDET\tos\nCardinal\tCARD\tprimeiro\nNoun\tNOM\tmesa\nPronoun\tP\teles\nPreposition\tPRP\tde\nVerb\tV\tfazer\nInterjection\tI\tOh!\nCommas\tVIRG\t,\nPunctuation\tSENT\t.\n\nStudies report that TreeTagger achieves performance higher than 95% accuracy in attributing the correct POS tag and lemma of a token.\n\n### Acknowledgements: \nIf you use this corpus in your work, please cite this paper:\n\nZampieri, M. and Becker, M. (2013) Colonia: Corpus of Historical Portuguese. In: ZSM Studien, Special Volume on Non-Standard Data Sources in Corpus-Based Research. Volume 5. Shaker. \n\n### Inspiration: \n\n* What changes have occurred in Portuguese over time? Have words changed? Syntactic structures? How grammatical agreement is expressed?\n* Can you create a classifier which can classify the era and unseen work is from?\n* Using the part of speech tags in this tagger, can you train a new tagger and run it over the Brazilian Portuguese Literature Corpus linked below?\n\n### You may also like:\n\n[A 3.7 million word literary corpus of Brazilian Portugese](https://www.kaggle.com/rtatman/brazilian-portuguese-literature-corpus)'","b""['linguistics', 'languages', 'history', 'brazil', 'literature', 'medium', 'featured']""",https://www.kaggle.com/rtatman/colonia-corpus-of-historical-portuguese
b'Pulse of the Nation',"b""Cards Against Humanity's Pulse of the Nation""","b'### THE POLL\nAs part of Cards Against Humanity Saves America, this poll is funded for one year of monthly public opinion polls. Cards Against Humanity is asking the American people about their social and political views, what they think of the president, and their pee-pee habits.\n\nTo conduct their polls in a scientifically rigorous manner, they partnered with Survey Sampling International \xe2\x80\x94 a professional research firm \xe2\x80\x94 to contact a nationally representative sample of the American public. For the first three polls, they interrupted people\xe2\x80\x99s dinners on both their cell phones and landlines, and a total of about 3,000 adults didn\xe2\x80\x99t hang up immediately. They examined the data for statistically significant correlations which can be found here: [https://thepulseofthenation.com/][1]\n\n\n\n### Content\n\n- Polls are released each month (they are still polling so this will be updated each month)<br>\n- Row one is the header and contains the questions<br>\n- Each row is one respondent\'s answers<br>\n\n---\n\n### Questions in the Sep 2017 poll:<br>\n\n- Income\n- Gender\n- Age\n- Age Range\n- Political Affiliation\n- Do you approve or disapprove of how Donald Trump is handling his job as president?\n- What is your highest level of education? \n- What is your race?\n- What is your marital status?\n- What would you say is the likelihood that your current job will be entirely performed by robots or computers within the next decade?\n- Do you believe that climate change is real and caused by people, real but not caused by people, or not real at all?""\n- How many Transformers movies have you seen? \n- Do you agree or disagree with the following statement: scientists are generally honest and are serving the public good. \n- Do you agree or disagree with the following statement: vaccines are safe and protect children from disease.\n- ""How many books,  if any have you read in the past year?""\n- Do you believe in ghosts?\n- What percentage of the federal budget would you estimate is spent on scientific research?\n- ""Is federal funding of scientific research too high too low  or about right?""\n- True or false: the earth is always farther away from the sun in the winter than in the summer.\n- ""If you had to choose: would you rather be smart and sad or dumb and happy?""\n- Do you think it is acceptable or unacceptable to urinate in the shower?\n\n---\n\n\n### Questions from Oct 2017 poll\n\n- Income\n- Gender\n- Age\n- Age Range\n- Political Affiliation \n- Do you approve or disapprove of how Donald Trump is handling his job as president?\n- What is your highest level of education?\n- What is your race?\n- From what you have heard or seen do you mostly agree or mostly disagree with the beliefs of White Nationalists?\n- If you had to guess what percentage of Republicans would say that they mostly agree with the beliefs of White Nationalists?\n- Would you say that you love America?\n- If you had to guess,  what percentage of Democrats would say that they love America?\n- Do you think that government policies should help those who are poor and struggling in America?\n- If you had to guess, what percentage of Republicans would say yes to that question?\n- Do you think that most white people in America are racist?\n- If you had to guess, what percentage of Democrats would say yes to that question?\n- Have you lost any friendships or other relationships as a result of the 2016 presidential election?\n- Do you think it is likely or unlikely that there will be a Civil War in the United States within the next decade?\n- Have you ever gone hunting?\n- Have you ever eaten a kale salad?\n- If Dwayne ""The Rock"" Johnson ran for president as a candidate for your political party, would you vote for him?\n- Who would you prefer as president of the United States, Darth Vader or Donald Trump?\n\n---\n\n### Questions from Nov 2017 poll\n\n- Income\n- Gender\n- Age\n- Age Range\n- In politics today,  do you consider yourself a Democrat,  a Republican  or Independent? \n- Would you say you are liberal, conservative, or moderate?\n- What is your highest level of education? (High school or less,  Some college,  College degree, Graduate degree)\n- What is your race? (white, black, latino, asian, other)\n- Do you live in a city, suburb, or small town?\n- Do you approve, disapprove, or neither approve nor disapprove of how Donald Trump is handling his job as president?\n- Do you think federal funding for welfare programs in America should be increased, decreased, or kept the same?\n- Do you think poor black people are more likely to benefit from welfare programs than poor white people?\n- Do you think poor people in cities are more likely to benefit from welfare programs than poor people in small towns?\n- If you had to choose, would you rather live in a more equal society or a more unequal society?\n\n---\n\n### Acknowledgements\n\nThese polls are from Cards Against Humanity Saves America and the raw data can be found here: [https://thepulseofthenation.com/#future][2]\n\n\n  [1]: https://thepulseofthenation.com/\n  [2]: https://thepulseofthenation.com/#future'","b""['demographics', 'utility', 'social sciences', 'small', 'featured']""",https://www.kaggle.com/cardsagainsthumanity/pulse-of-the-nation
b'Severely Injured Workers',"b'~22k Injury Reports for US Workers, 2015-2017'","b'### Context: \nOccupational Safety and Health Administration aka [OSHA](https://www.osha.gov/) requires employers to report all severe work-related injuries, defined as an amputation, in-patient hospitalization, or loss of an eye. The requirement began on January 1, 2015. \n\n### Content: \nThis dataset provides information from those reports, including a description of the incident and the name and address of the establishment where it happened. Injuries are coded using the[ Occupational Injury and Illness Classification System](https://www.bls.gov/iif/oshoiics.htm). Data covers ~22k incidents Jan 1 2015-Feb 28 2017. 26 columns describe incident, parties involved, employer, injury sustained, and final outcome.\n\n\n### Acknowledgements: \nThis dataset was created by [OSHA](https://www.osha.gov/severeinjury/index.html\n) and released to the public.\n\n### Inspiration: \n* Which industries have the highest rate of worker injuries? Most severe injuries?\n* Can you predict injuries for 2016 based on 2015 data?\n* In which regions are injuries most common?'","b""['healthcare', 'employment', 'medium', 'featured']""",https://www.kaggle.com/jboysen/injured-workers
b'EmojiNet',b'A machine-readable dictionary of emoji meanings',"b'### Content\n\nEmojiNet is the largest machine-readable emoji sense inventory that links Unicode emoji representations to their English meanings extracted from the Web. EmojiNet is a dataset consisting of: \n\n* 12,904 sense labels over 2,389 emoji, which were extracted from the web and linked to machine-readable sense definitions seen in [BabelNet](http://babelnet.org/)\n* context words associated with each emoji sense, which are inferred through word embedding models trained over Google News corpus and a Twitter message corpus for each emoji sense definition\n* specification of the most likely platform-based emoji sense for a selected set of emoji (since emoji presentation is different on different platforms)\n\n### Acknowledgements: \n\nEmojiNet was developed by Sanjaya Wijeratne, Lakshika Balasuriya, Amit Sheth and Derek Doran. EmojiNet is licensed under a[Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported (CC BY-NC-SA 3.0) license.](https://creativecommons.org/licenses/by-nc-sa/3.0/). Please cite the following paper when using EmojiNet dataset(s):\n\n  Sanjaya Wijeratne, Lakshika Balasuriya, Amit Sheth, Derek Doran. EmojiNet: An Open Service and API for Emoji Sense Discovery. In 11th International AAAI Conference on Web and Social Media (ICWSM 2017). Montreal, Canada; 2017.\n\nYou can also find more information about the dataset on the [project website](http://emojinet.knoesis.org/home.php).\n\nThe banner photo is by [Frank Behrens](https://www.flickr.com/photos/frank_behrens/) and is licensed under a [CC BY-SA 2.0 license](https://creativecommons.org/licenses/by-sa/2.0/).\n\n### Inspiration: \n\n* Can you use these senses to create a sentiment lexicon for emoji?\n* Can you cluster emoji based on their sense?\n* Which emoji are the most different across platforms?\n'","b""['internet', 'linguistics', 'popular culture', 'small', 'featured']""",https://www.kaggle.com/rtatman/emojinet
b'Computer Parts (CPUs and GPUs)',b'How did computer specifications and performance evolve over time?',"b'### Contents\nThis dataset contains detailed specifications, release dates, and release prices of computer parts.\n\nThe dataset contains two CSV files: `gpus.csv` for Graphics Processing Units (GPUs), and `cpus.csv` for Central Processing Units (CPUs). Each table has its own list of unique entries, but the list of features includes: clock speeds, maximum temperatures, display resolutions, power draws, number of threads, release dates, release prices, die size, virtualization support, and many other similar fields. For more specific column-level metadata refer to the [Column Metadata](https://www.kaggle.com/iliassekkaf/computerparts/data).\n\nLooking for inspiration? Try starting by reading [""Using regression to predict the GPUs of the future""](https://www.kaggle.com/skalskip/using-regression-to-predict-gpus-of-the-future).\n\n### Inspiration\n\n* How did performance over price ratio evolve over time? \n* How about general computing power?  \n* Are there any manufacturers that are known for some specific range of performance &amp; price? \n\n### Acknowledgements\n\nThe data given here belongs mainly to Intel, Game-Debate, and the companies involved in producing the part. I do not own the data I uploaded it solely for informative purposes, under their original license.\n\n\n  [1]: http://www.futureelectronics.com/en/Microprocessors/embedded-processors.aspx'","b""['internet', 'computers', 'computer architecture', 'small', 'featured']""",https://www.kaggle.com/iliassekkaf/computerparts
b'Multidimensional Poverty Measures',b'Indexing different types of simultaneous deprivation ',"b'### Context\n\nMost countries of the world define poverty as a lack of money. Yet poor people themselves consider their experience of poverty much more broadly. A person who is poor can suffer from multiple disadvantages at the same time \xe2\x80\x93 for example they may have poor health or malnutrition, a lack of clean water or electricity, poor quality of work or little schooling. Focusing on one factor alone, such as income, is not enough to capture the true reality of poverty.\n\nMultidimensional poverty measures can be used to create a more comprehensive picture. They reveal who is poor and how they are poor \xe2\x80\x93 the range of different disadvantages they experience. As well as providing a headline measure of poverty, multidimensional measures can be broken down to reveal the poverty level in different areas of a country, and among different sub-groups of people.\n\n\n### Content\n\nOPHI researchers apply the AF method and related multidimensional measures to a range of different countries and contexts. Their analyses span a number of different topics, such as changes in multidimensional poverty over time, comparisons in rural and urban poverty, and inequality among the poor. For more information on OPHI\xe2\x80\x99s research, see our [working paper series](http://www.ophi.org.uk/resources/ophi-working-papers/) and [research briefings](http://www.ophi.org.uk/resources/briefing-documents/).\n\nOPHI also calculates the Global Multidimensional Poverty Index [MPI](http://www.ophi.org.uk/multidimensional-poverty-index/), which has been published since 2010 in the United Nations Development Programme\xe2\x80\x99s Human Development Report. The Global MPI is an internationally-comparable measure of acute poverty covering more than 100 developing countries. It is updated by OPHI twice a year and constructed using the AF method.\n\nThe Alkire Foster (AF) method is a way of measuring multidimensional poverty developed by OPHI\xe2\x80\x99s Sabina Alkire and James Foster. Building on the Foster-Greer-Thorbecke poverty measures, it involves counting the different types of deprivation that individuals experience at the same time, such as a lack of education or employment, or poor health or living standards. These deprivation profiles are analysed to identify who is poor, and then used to construct a multidimensional index of poverty (MPI). For free online video guides on how to use the AF method, see [OPHI\xe2\x80\x99s online training portal](http://www.ophi.org.uk/teaching/online-training-portal/).\n\nTo identify the poor, the AF method counts the overlapping or simultaneous deprivations that a person or household experiences in different indicators of poverty. The indicators may be equally weighted or take different weights. People are identified as multidimensionally poor if the weighted sum of their deprivations is greater than or equal to a poverty cut off \xe2\x80\x93 such as 20%, 30% or 50% of all deprivations.\n\nIt is a flexible approach which can be tailored to a variety of situations by selecting different dimensions (e.g. education), indicators of poverty within each dimension (e.g. how many years schooling a person has) and poverty cut offs (e.g. a person with fewer than five years of education is considered deprived).\n\nThe most common way of measuring poverty is to calculate the percentage of the population who are poor, known as the headcount ratio (H). Having identified who is poor, the AF method generates a unique class of poverty measures (M\xce\xb1) that goes beyond the simple headcount ratio. Three measures in this class are of high importance:\n\nAdjusted headcount ratio (M0), otherwise known as the MPI: This measure reflects both the incidence of poverty (the percentage of the population who are poor) and the intensity of poverty (the percentage of deprivations suffered by each person or household on average). M0 is calculated by multiplying the incidence (H) by the intensity (A). M0 = H x A.\n\nFind out about other ways the AF method is used in [research and policy](http://www.ophi.org.uk/research/multidimensional-poverty/research-applications/).\n\nAdditional data [here](http://ophi.org.uk/multidimensional-poverty-index/global-mpi-2017/mpi-data/).\n\n\n### Acknowledgements\n\nAlkire, S. and Robles, G. (2017). \xe2\x80\x9cMultidimensional Poverty Index Summer 2017: Brief methodological note and results.\xe2\x80\x9d OPHI Methodological Note 44, University of Oxford.\n\nAlkire, S. and Santos, M. E. (2010). \xe2\x80\x9cAcute multidimensional poverty: A new index for developing countries.\xe2\x80\x9d OPHI Working Papers 38, University of Oxford.\n\nAlkire, S. Jindra, C. Robles, G. and Vaz, A. (2017). \xe2\x80\x98Multidimensional Poverty Index \xe2\x80\x93 Summer 2017: brief methodological note and results\xe2\x80\x99. OPHI MPI Methodological Notes No. 44, Oxford Poverty and Human Development Initiative, University of Oxford.\n\n\n\n### Inspiration\n\n* Which countries exhibit the largest subnational disparities in MPI?\n* Which countries have high per-capita incomes yet still rank highly in MPI?'","b""['finance', 'demographics', 'government', 'public health', 'government agencies', 'small', 'featured']""",https://www.kaggle.com/ophi/mpi
b'Audio Cats and Dogs',b'Classify raw sound events',"b'### Context\n\nWith this dataset we hope to do a nice cheeky wink to the ""cats and dogs"" image dataset.\nIn fact, this dataset is aimed to be the audio counterpart of the famous ""cats and dogs"" image classification task, here available on Kaggle.\n\n\n### Content\n\nThe dataset consists in many ""wav"" files for both the cat and dog classes : \n\n- cat has 164 WAV files to which corresponds 1323 sec of audio\n- dog has 113 WAV files to which corresponds 598 sec of audio\n\nYou can have an visual description of the Wav here : [Visualizing woofs &amp; meows \xf0\x9f\x90\xb1][1]. In [Accessing the Dataset 2][2] we propose a train / test split which can be used.\n\nAll the WAV files contains 16KHz audio and have variable length.\n\n### Acknowledgements\n\nWe have not much credit in proposing the dataset here. Much of the work have been done by the [AE-Dataset][3] creator (From which we extracted the two classes) and by the humans behind [FreeSound][4] From which was extracted the AE-Dataset.\n\n### Inspiration\n\nYou might use this dataset to test raw audio classification challenge ;)  \nA more challenging dataset is available [here][5]\n\n\n  [1]: https://www.kaggle.com/rtatman/visualizing-woofs-meows\n  [2]: https://www.kaggle.com/mmoreaux/accessing-the-data-2/\n  [3]: https://data.vision.ee.ethz.ch/cvl/ae_dataset/\n  [4]: https://freesound.org/\n  [5]: https://www.kaggle.com/mmoreaux/environmental-sound-classification-50'","b""['animals', 'acoustics', 'medium', 'featured']""",https://www.kaggle.com/mmoreaux/audio-cats-and-dogs
b'Silicon Valley Diversity Data',b'What\xe2\x80\x99s diversity like for 23 top tech companies?',"b'### Context\n\nThere has been a lot of discussion of the ways in which the workforce for Silicon Valley tech companies differs from that of the United States as a whole. In particular, a lot of evidence suggests that tech workers (who tend to be more highly paid than workers in many other professions) are more likely to be white and male. This dataset will allow you to investigate the demographics for 23 Silicon Valley tech companies for yourself.\n\n## Updates!\n\n**NEW June 2018:**\nThe spreadsheet `Distributions_data_2016.csv` contains workforce distributions by job category and race for 177 of the largest tech companies headquartered in Silicon Valley.\n\nEach figure in the dataset represents the percentage of each job category that is made up of employees with a given race/gender combination, and are based on each company\'s EEO-1 report.\n\nThis dataset was created through a unique collaboration with the [Center for Employment Equity](https://www.umass.edu/eeodatanet/about-us) and [Reveal](https://www.revealnews.org/?p=47103). The equity center provided Reveal with anonymized data for 177 large companies, and Reveal identified companies that have publicly released their data in this anonymized dataset. The equity center and Reveal analyzed the data independently. \n\nFor more information on the data, read our post [here.](https://www.revealnews.org/blog/how-we-created-a-baseline-for-silicon-valleys-diversity-problem)\n\nThe spreadsheet `Reveal_EEO1_for_2016.csv` has been updated to include EEO-1s from companies PayPal, NetApp and Sanmina for 2016. The race and job categories have been modified to ensure consistency across all the datasets.\n\n**NEW April 2018:** The spreadsheet `Tech_sector_diversity_demographics_2016.csv` contains aggregated diversity data for 177 large Silicon Valley tech companies. We calculated averages for the largest race and gender groups across job categories. For information on the aggregated data, read our post [here.](https://www.revealnews.org/blog/the-sound-of-disparity-data-directed-silicon-valley-diversity-choir/)\n\nThis repository also contains EEO-1 reports filed by Silicon Valley tech companies. Please [read our complete methodology](https://www.revealnews.org/article/how-we-analyzed-silicon-valley-tech-companies-diversity-data) for details on this data.\n\nThe data was compiled by Reveal from The Center for Investigative Reporting.\n\n### Contents\n\nThis database contains EEO-1 reports filed by Silicon Valley tech companies. It was compiled by [Reveal from The Center for Investigative Reporting](https://www.revealnews.org/svdiversity).\n\nThere are six columns in this dataset:\n\n* company: Company name\n* year: For now, 2016 only\n* race: Possible values: ""American_Indian_Alaskan_Native"", ""Asian"", ""Black_or_African_American"", ""Latino"", ""Native_Hawaiian_or_Pacific_Islander"", ""Two_or_more_races"", ""White"", ""Overall_totals""\n* gender:  Possible values: ""male"", ""female"". Non-binary gender is not counted in EEO-1 reports.\n* job_category: Possible values: ""Administrative support"", ""Craft workers"", ""Executive/Senior officials & Mgrs"", ""First/Mid officials & Mgrs"", ""laborers and helpers"", ""operatives"", ""Professionals"", ""Sales workers"", ""Service workers"", ""Technicians"", ""Previous_totals"", ""Totals""\n* count: Mostly integer values, but contains ""na"" for a no-data variable.\n\n### Acknowledgements: \n\nThe EEO-1 database is licensed under the [Open Database License (ODbL)](https://opendatacommons.org/licenses/odbl/1.0/) by [Reveal from The Center for Investigative Reporting](https://www.revealnews.org/svdiversity).\n\nYou are free to copy, distribute, transmit and adapt the spreadsheet, so long as you:\n\n* credit Reveal (including [this link](https://www.revealnews.org/svdiversity) if it\xe2\x80\x99s distributed online);\n* inform Reveal that you are using the data in your work by emailing Sinduja Rangarajan at srangarajan@revealnews.org; and\n* offer any new work under the same license.\n\n### Inspiration: \n\n* How does each company\xe2\x80\x99s workforce compare to the United States population as a whole? You can find [county level diversity information here](https://www.kaggle.com/mikejohnsonjr/us-counties-diversity-index).\n* Which company is the most diverse? Least diverse?'","b""['demographics', 'united states', 'employment', 'small', 'featured']""",https://www.kaggle.com/rtatman/silicon-valley-diversity-data
b'20 Newsgroups',"b'A collection of ~18,000 newsgroup documents from 20 different newsgroups'","b'### Context\n\nThis dataset is a collection newsgroup documents. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n\n\n### Content\n\nThere is file (list.csv) that contains a reference to the document_id number and the newsgroup it is associated with.\nThere are also 20 files that contain all of the documents, one document per newsgroup.\n\nIn this dataset, duplicate messages have been removed and the original messages only contain ""From"" and ""Subject"" headers (18828 messages total).\n\nEach new message in the bundled file begins with these four headers:\n\nNewsgroup: alt.newsgroup\n\nDocument_id: xxxxxx\n\nFrom:  Cat\n\nSubject:  Meow Meow Meow\n\nThe Newsgroup and Document_id can be referenced against list.csv\n\n\nOrganization\n- Each newsgroup file in the bundle represents a single newsgroup\n- Each message in a file is the text of some newsgroup document that was posted to that newsgroup.\n\nThis is a list of the 20 newsgroups:\n\n- comp.graphics\n- comp.os.ms-windows.misc\n- comp.sys.ibm.pc.hardware\n- comp.sys.mac.hardware\n- comp.windows.x\trec.autos\n- rec.motorcycles\n- rec.sport.baseball\n- rec.sport.hockey\tsci.crypt\n- sci.electronics\n- sci.med\n- sci.space\n- misc.forsale\ttalk.politics.misc\n- talk.politics.guns\n- talk.politics.mideast\ttalk.religion.misc\n- alt.atheism\n- soc.religion.christian\n\n\n### Acknowledgements\n\nKen Lang is credited by the source for collecting this data. The source of the data files is here:  \nhttp://qwone.com/~jason/20Newsgroups/\n\n### Inspiration\n\n- This dataset text can be used to classify text documents'","b""['internet', 'linguistics', 'medium', 'featured']""",https://www.kaggle.com/crawford/20-newsgroups
b'Blog Authorship Corpus',"b'Over 600,000 posts from more than 19 thousand bloggers'","b'### Context:\n\xe2\x80\x9cA blog (a truncation of the expression ""weblog"") is a discussion or informational website published on the World Wide Web consisting of discrete, often informal diary-style text entries (""posts""). Posts are typically displayed in reverse chronological order, so that the most recent post appears first, at the top of the web page. Until 2009, blogs were usually the work of a single individual, occasionally of a small group, and often covered a single subject or topic.\xe2\x80\x9d -- Wikipedia article \xe2\x80\x9c[Blog](https://en.wikipedia.org/wiki/Blog)\xe2\x80\x9d\n\nThis dataset contains text from blogs written on or before 2004, with each blog being the work of a single user.\n\n### Content: \n\nThe Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person.  \n\nEach blog is presented as a separate file, the name of which indicates a blogger id# and the blogger\xe2\x80\x99s self-provided gender, age, industry and astrological sign. (All are labeled for gender and age but for many, industry and/or sign is marked as unknown.)\n\nAll bloggers included in the corpus fall into one of three age groups:\n\n* 8240 ""10s"" blogs (ages 13-17),\n* 8086 ""20s"" blogs(ages 23-27)\n* 2994 ""30s"" blogs (ages 33-47).\n\nFor each age group there are an equal number of male and female bloggers.   \n\nEach blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label urllink.\n\n### Acknowledgements\n\nThe corpus may be freely used for non-commercial research purposes. Any resulting publications should cite the following:\n\nJ. Schler, M. Koppel, S. Argamon and J. Pennebaker (2006). Effects of Age and Gender on Blogging in Proceedings of 2006 AAAI Spring Symposium on Computational Approaches for Analyzing Weblogs. URL: http://www.cs.biu.ac.il/~schlerj/schler_springsymp06.pdf\n\n### Inspiration: \n\n* This dataset contains information on writers demographics, including their age, gender and zodiac sign. Can you build a classifier to guess someone\xe2\x80\x99s zodiac sign from blog posts they\xe2\x80\x99ve written?\n* Which are bigger: differences between demographic groups or differences between blogs on different topics?\n\n### You may also like:\n\n* [News and Blog Data Crawl: Content section from over 160,000 news and blog articles](https://www.kaggle.com/patjob/articlescrape)\n* [20 Newsgroups: A collection of ~18,000 newsgroup documents from 20 different newsgroups](https://www.kaggle.com/crawford/20-newsgroups)'","b""['internet', 'linguistics', 'languages', 'medium', 'featured']""",https://www.kaggle.com/rtatman/blog-authorship-corpus
b'InceptionV3',b'InceptionV3 Pre-trained Model for Keras',"b'# InceptionV3\n\n---\n\n## Rethinking the Inception Architecture for Computer Vision\nConvolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5% top-5 error on the validation set (3.6% error on the test set) and 17.3% top-1 error on the validation set.\n<br>\n\n**Authors: Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna**<br>\n**https://arxiv.org/abs/1512.00567**\n\n---\n\n#InceptionV3 Architecture<br>\n![InceptionV3 Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n  [1]: https://4.bp.blogspot.com/-TMOLlkJBxms/Vt3HQXpE2cI/AAAAAAAAA8E/7X7XRFOY6Xo/s1600/image03.png'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/keras/inceptionv3
b'InceptionV3',b'InceptionV3 Pre-trained Model for Keras',"b'# InceptionV3\n\n---\n\n## Rethinking the Inception Architecture for Computer Vision\nConvolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5% top-5 error on the validation set (3.6% error on the test set) and 17.3% top-1 error on the validation set.\n<br>\n\n**Authors: Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna**<br>\n**https://arxiv.org/abs/1512.00567**\n\n---\n\n#InceptionV3 Architecture<br>\n![InceptionV3 Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n  [1]: https://4.bp.blogspot.com/-TMOLlkJBxms/Vt3HQXpE2cI/AAAAAAAAA8E/7X7XRFOY6Xo/s1600/image03.png'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/'charmap' codec can't encode characters in position 34-44: character maps to <undefined>
b'NYS Mined Land Permits: Beginning 1974',b'From New York State Open Data',"b""### Content  \n\nThis coverage contains data from the Division of Mineral Resources Mined Lands permit files.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/A3AMRHgC9PY) by [Mariusz Prusaczyk](https://unsplash.com/@curioso) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'utility', 'minerals', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-mined-land-permits-beginning-1974
"b'Disadv Business Enterprises, NYS Unified Cert Prog'",b'From New York State Open Data',"b""### Content  \n\nThis dataset is a combined directory of the New York State Unified Certification Program (NYSUCP).  Firms certified as Disadvantaged Business Enterprises (DBEs) by the New York State Department of Transportation, Metropolitan Transportation Authority, Niagara Frontier Transportation Authority and Port Authority of New York New Jersey are included in this dataset.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/a2VqhP3d4Vg) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""","https://www.kaggle.com/new-york-state/disadv-business-enterprises,-nys-unified-cert-prog"
b'Movie Scripts',b'Text scripts written in russian',"b'### Context\n\nOne fine day the team ZAVOD announced a film written by neural network. 40 hours later the rendering finished, and the first [neurofilm in russian][1] was published.\n\nThis dataset contains a bunch of clean `.txt` files with movie scripts in Russian used for training.\n\n### Acknowledgements\n\nThe data is mostly from *kinomania.ru* and *kinodramaturg.ru*.\n\n## Inspiration\n\nIt would be nice if you help me to continue filling out the dataset.\n\n  [1]: https://youtu.be/L3WV0G_zut8'","b""['text data', 'film', 'russia', 'small', 'featured']""",https://www.kaggle.com/lisovskey/moviescripts
b'Chicago Restaurant Inspections',b'~154k Rows of Inspections Data',"b""### Context: \nRestaurant inspections ensure that food served to the public at licensed food establishments follows food safety guidelines. The Food Protection Division of the Chicago Department of Public Health (CDPH) is committed to maintaining the safety of food bought, sold, or prepared for public consumption in Chicago by carrying out science-based inspections of all retail food establishments. These inspections promote public health in areas of food safety and sanitation and prevent the occurrence of food-borne illness. CDPH's licensed, accredited sanitarians inspect retail food establishments such as restaurants, grocery stores, bakeries, convenience stores, hospitals, nursing homes, day care facilities, shelters, schools, and temporary food service events. Inspections focus on food handling practices, product temperatures, personal hygiene, facility maintenance, and pest control.\nAll restaurants are subject to certain recurring inspections. Each year a restaurant is subject to annual inspections to ensure continued compliance with City ordinances and regulations. In addition to recurring inspections, restaurants may also be inspected in response to a complaint. Some of these recurring inspections, such as the inspection by the Buildings Department, will be scheduled, while others will not.\n\nGenerally inspections are conducted by the Health Department for sanitation and safe food handling practices, the Buildings Department to ensure the safety of the structure, and the Fire Department to ensure safe fire exits.The City's Dumpster Task Force, a collaborative effort between the Health Department and Streets and Sanitation Department, also inspects restaurants to ensure compliance with sanitation regulations.\n\n\n### Content: \nData includes inspection date, results, violations noted, business name and lat/lon, license# and risk. Data covers 01/02/2013-08/28/17.\n\n### Acknowledgements: \nData was collected by [City of Chicago Department of Health](https://www.cityofchicago.org/city/en/depts/cdph/provdrs/inspections_and_permitting/svcs/restaurant_food_inspection.html).\n\n### Inspiration: \n* Can you predict restaurant closings? \n* Do restaurants in certain neighborhoods gather more/less violations?\n* Any seasonal or time anomalies in the data?""","b""['food and drink', 'medium', 'featured']""",https://www.kaggle.com/chicago/chi-restaurant-inspections
b'Multispectral Image Classification',b'Handwritten numbers (0-9) from six different people and two different pens',"b'# Introduction\n\nWith multispectral images,  we can capture more data per pixel, and understand objects based on their chemical composition or the variation of composition that encompasses an object. \n\nFor example, is the image you see an apple or an orange? Further, is the apple or the orange real?  If it is plastic, was it made in Mexico or India?\n\nReal life impacts of using spectral data as part of object detection in images could one day save a life, if a self driving car could not only detect faces, but also the difference between skin and plastic, a lone pedestrian could avoid being if it was a choice between them or a group of three manikins.\n\nThis sample data contains a series of multispectral images of handwritten numbers between 0 and 9, from six different peoples, using two different pens.  And here I am asking the great kagglers to explore and build models to tell each of the numbers from one another and with what ink each was written in. \n\n# Data\n\nEach csv file contains pixels for 10 grayscale images (350 * 350) that represent 10 channels for the multispectral image, where X, Y represent the location of the pixel, and channel0 - channel9 represent channels.\n\nAnd we also have a labels csv that contains labels for each pixel csv file.\n\n\n# Licence\n\nYou can do whatever you want with the data.'","b""['image data', 'multiclass classification', 'artificial intelligence', 'writing', 'large', 'featured']""",https://www.kaggle.com/xiaozhouwang/multispectralimages
b'The Global Avian Invasions Atlas',b'A database of alien bird distributions worldwide',"b'This comma-separated text file contains the 27,723 alien bird records that form the core of the Global AVian Invasions Atlas (GAVIA) project. These records represent 971 species, introduced to 230 countries and administrative areas across all eight biogeographical realms, spanning the period 6000 BCE \xe2\x80\x93 AD 2014. The data comprises taxonomic (species-level), spatial (geographic location, realm, land type) and temporal (dates of introduction and spread) components, as well as details relating to the introduction event (how and why the species was introduced, whether or not it is established). Each line of data consists of an individual record concerning a specific alien bird species introduced to a specific location. The data derives from both published and unpublished sources, including atlases, country species lists, peer-reviewed articles, websites and via correspondence with in-country experts.\n\n### Acknowledgements\n\nDyer, Ellie; Redding, David; Blackburn, Tim (2016): Data from: The Global Avian Invasions Atlas - A database of alien bird distributions worldwide. [figshare][1].\n\n\n  [1]: https://figshare.com/articles/Data_from_The_Global_Avian_Invasions_Atlas_-_A_database_of_alien_bird_distributions_worldwide/4234850'","b""['animals', 'medium', 'featured']""",https://www.kaggle.com/figshare/the-global-avian-invasions-atlas
b'Food Images (Food-101)',b'Labeled food images in 101 categories from apple pies to waffles',"b'# Overview \nThe dataset contains a number of different subsets of the full food-101 data. The idea is to make a more exciting simple training set for image analysis than CIFAR10 or MNIST. For this reason the data includes massively downscaled versions of the images to enable quick tests. The data has been reformatted as HDF5 and specifically Keras HDF5Matrix which allows them to be easily read in. The file names indicate the contents of the file. For example\n\n - food_c101_n1000_r384x384x3.h5 means there are 101 categories represented, with n=1000 images, that have a resolution of 384x384x3 (RGB, uint8)\n\n - food_test_c101_n1000_r32x32x1.h5 means the data is part of the validation set, has 101 categories represented, with n=1000 images, that have a resolution of 32x32x1 (float32 from -1 to 1)\n\n\n\n\n# Challenge\nThe first goal is to be able to automatically classify an unknown image using the dataset, but beyond this there are a number of possibilities for looking at what regions / image components are important for making classifications, identify new types of food as combinations of existing tags, build object detectors which can find similar objects in a full scene.\n\n# Data Acknowledgement\nThe data was repackaged from the original source (gzip) available at https://www.vision.ee.ethz.ch/datasets_extra/food-101/\n\n# License\n\n - The Food-101 data set consists of images from Foodspotting [1]. Any use beyond scientific fair use must be negotiated with the respective picture owners according to the Foodspotting terms of use [2].\n\n[1] http://www.foodspotting.com/\n[2] http://www.foodspotting.com/terms/'","b""['food and drink', 'image data', 'multiclass classification', 'popular culture', 'large', 'featured']""",https://www.kaggle.com/kmader/food41
"b""Medicare's Doctor Comparison Scores""",b'The 2017 Physican Compare Database',"b'The [Physician Compare][1] website was created by the Centers for Medicare & Medicaid Services (CMS) in December 2010 as required by the Affordable Care Act (ACA) of 2010 to help patients assess and find doctors and hospitals. This dataset contains the information supplied to patients via that website, including patient satisfaction surveys and performance scores across over 100 metrics.\n\n### Acknowledgements\n\nThis dataset was kindly released by the Centers for Medicare & Medicaid Services. You can find [the original copy of the dataset here][2].\n\n\n  [1]: https://www.medicare.gov/physiciancompare/#about/aboutphysiciancompare\n  [2]: https://data.medicare.gov/data/physician-compare'","b""['healthcare', 'public health', 'medium', 'featured']""",https://www.kaggle.com/cms/medicares-doctor-comparison-scores
b'Agricultural Land Values (1997-2017)',b'How have farm real estate values changed over the past two decades? ',"b'#Context\n\nThe National Agricultural Statics Service (NASS) publishes data about varying aspects of the agricultural industry. Since 1997, the service has compiled data regarding the value per acre of farmland in each state/region in the United States. \n\n#Content\n\nThe data were acquired from the NASS website through published annual reports.  At first, the data were combined into a common Excel file. I decided to use Excel for the preliminary data compiling because the report formats changed relatively often; however, the reports were still easy to compile by simply copying and pasting yearly columns. From this, I then tidied the data in R. \n\n**The final cleaned dataset is titled Combined_Clean.csv**\n\n#Acknowledgements\n\nThe data were acquired from the NASS website through published annual reports. \n\nThank you to the NASS (and USDA) for collecting this data. Here is the link containing the annual reports: [NASS/USDA][1]\n\nThe link to the wonderful banner image: [Banner][2]\n\n#Inspiration\n\nI was inspired to gather this data to gain insight into how agricultural land values have changed over the past two decades, especially in different states and regions across the United States. \n- Which states have had the greatest increases in land value? \n- Which regions have the most expensive land per acre? \n- What are some possible reasons for changes in values in certain states/regions?\n- How do prices vary across type of land (Overall farmland, pasture, and cropland)?\n\nThanks!\n\nPlease feel free to view my kernel regarding the cleaning/tidying of the data! Here is the link to my Github: [Github][3]\n\n\n  [1]: http://usda.mannlib.cornell.edu/MannUsda/viewDocumentInfo.do;jsessionid=F154BA78C7C50C021C8CA924EDB72FD5?documentID=1446\n  [2]: http://www.freedomworks.org/content/agriculture-committees-farm-bill-proposal-mixed-bag\n  [3]: https://github.com/TarHeel45/Agricultural-Land-Value'","b""['beginner', 'eda', 'economics', 'agriculture', 'real estate', 'small', 'featured']""",https://www.kaggle.com/jmullan/agricultural-land-values-19972017
b'The ExtraSensory Dataset',b'Behavioral Context Recognition In-the-Wild',"b'### Context \n\nBehavioral Context refers to a wide range of attributes describing what is going on with you: where you are (home, school, work, at the beach, at a restaurant), what you are doing (sleeping, eating, in a meeting, computer work, exercising, shower), who you are with (family, friends, co-workers), your body posture state (sitting, standing, walking, running), and so on.\nThe ability to automatically (effortlessly, frequently, objectively) recognize behavioral context can serve many domains. Medical applications can monitor physical activity or eating habits; aging-at-home programs can log older adults\' physical, social, and mental behavior; personal assistant systems can better server the user if they are aware of the context.\nIn-the-wild (in real life), natural behavior is complex, composed of different aspects, and has high variability. You can run outside at the beach, with friends with your phone in the pocket; you can also run indoors, at the gym, on a treadmill, with your phone motionless next to you. This high variability makes context-recognition a hard task to perform **in-the-wild**.\n\n### Content\n\nThe ExtraSensory Dataset was collected from 60 participants where each person participated approximately 7 days. We installed our data-collection mobile app on their *personal phone* and it was used to collect both sensor-measurements and context-labels. The sensor-measurements were recorded automatically for a window of 20-seconds every minute. This included accelerometer, gyroscope, magnetometer, audio, location, and phone-state from the person\'s phone, as well as accelerometer and compass from an additional smartwatch that we provided. In addition, the app\'s interface had many mechanisms for self-reporting the relevant context-labels, including reporting past context, near future, responding to notifications, and more. The flexible interface allowed to collect many labels with minimal effort and interaction-time, to avoid interfering with the natural behavior. The data was collected in-the-wild: participants used their phone in any way that was convenient to them, they engaged in their regular behavior and reported an combinations of labels that fit their context.\n\nFor every participant (or ""user""), the dataset has a CSV file with pre-computed features that we extracted from the sensors and with labels.  Each row has a separate example (representing 1 minute) and is indexed by the timestamp (seconds since the epoch). There are columns for the sensor-features, with the prefix of the column name indicating the sensor it came from (e.g. prefix ""raw_acc:"" indicating a feature came from the raw phone accelerometer measurements). There are columns for 51 diverse context-labels and the value for an example-label pair is either 1 (the label is relevant for the example), 0 (the label is not relevant), or \'NaN\' (missing information).\n\nHere, we provide data for 2 of the 60 participants. You can use this partial data to get familiar with the data and practice algorithms. The full dataset is publicly available at http://extrasensory.ucsd.edu. The website has additional parts of the data (such as a wider range of the original reported labels, location coordinates, mood labels from part of the participants). If you use the data for your publications, you are required to cite our original paper\nVaizman, Y., Ellis, K., and Lanckriet, G. ""Recognizing Detailed Human Context In-the-Wild from Smartphones and Smartwatches"". IEEE Pervasive Computing, vol. 16, no. 4, October-December 2017, pp. 62-74.\nRead the information at http://extrasensory.ucsd.edu and the original paper for more details.\n\n### Acknowledgements\n\nThe dataset was collected by Yonatan Vaizman and Katherine Ellis, under the supervision of prof. Gert Lanckriet, all from the department of Electrical and Computer Engineering, University of California, San Diego.\n\n### Inspiration\n\nThe ExtraSensory Dataset can serve as a benchmark to compare methods for context-recognition (or context-awareness, activity recognition, daily activity detection). You can focus on specific sensors or on specific context-labels. You can suggest new models and classifiers, train them on the data and evaluate their performance on the data.'","b""['psychology', 'medium', 'featured']""",https://www.kaggle.com/yvaizman/the-extrasensory-dataset
b'EveryPolitician',b'Open data on politicians from 10 countries',"b'### Context\n\nEveryPolitician is a project with the goal of providing data about every politician in the world. They collect open data on as many politicians as they can find and these datasets are just a small sample of the data available at http://www.everypolitician.org. \n\n### Content\n\nEach country has their own governmental structure and EveryPolitician provides data for as many countries as possible. At the time of publishing, there was information on politicians from 233 countries. I chose to publish JSON files for these 10 countries:\n\n- Australia\n- Brazil\n- China\n- France\n- India\n- Nigeria\n- Russia\n- South_Africa\n- UK\n- US\n \nThese JSON files follow the [POPOLO][1] format \n\n### Acknowledgements\n\nThese data were collected from [http://everypolitician.org/][2]. Their website has more data than I have published here - this is a small sample.\n\n\n  [1]: http://www.popoloproject.com/\n  [2]: http://everypolitician.org/'","b""['medium', 'featured']""",https://www.kaggle.com/everypolitician/everypoliticiansample
b'Flight Revenue Simulator',b'Code for in the August 2 Micro-Challenge',b'',"b""['optimization', 'small', 'featured']""",https://www.kaggle.com/dansbecker/flight-revenue-simulator
b'NYS Registered Pesticide Businesses and Agencies',b'From New York State Open Data',"b""### Content  \n\nThis file contains information on Pesticide Businesses and Agencies currently registered by New York State Department of Environmental Conservation (DEC) in the various categories of operation (6NYCRR Part 325).  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/rHbob_bEsSs) by [Matt Benson](https://unsplash.com/@mattgyver) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-registered-pesticide-businesses-and-agencies
b'Chicago Red Light Violations',b'309k Records of Violations in Safety Zones',"b'### Context: \nThis dataset reflects the daily volume of violations created by the City of Chicago Red Light Program for each camera. The data reflects violations that occurred from July 1, 2014 until present, minus the most recent 14 days. This data may change due to occasional time lags between the capturing of a potential violation and the processing and determination of a violation. The most recent 14 days are not shown due to revised data being submitted to the City of Chicago during this period. The reported violations are those that have been collected by the camera system and reviewed by two separate City contractors. In some instances, due to the inability the registered owner of the offending vehicle, the violation may not be issued as a citation. However, this dataset contains all violations regardless of whether a citation was actually issued, which provides an accurate view into the Red Light Program. Because of occasional time lags between the capturing of a potential violation and the processing and determination of a violation, as well as the occasional revision of the determination of a violation, this data may change. \n\n\n### Content: \nMore information on the Red Light Program can be found [here](http://www.cityofchicago.org/city/en/depts/cdot/supp_info/red-light_cameraenforcement.html).\n\nData covers July 1, 2014 to Sept 7, 2017. Rows include:\n\n* Intersection: Intersection of the location of the red light enforcement camera(s). There may be more than one camera at each intersection.\n* Camera ID: A unique ID for each physical camera at an intersection, which may contain more than one camera.\n* Address: The address of the physical camera (CAMERA ID). The address may be the same for all cameras or different, based on the physical installation of each camera.\n* Violation Date: The date of when the violations occurred. NOTE: The citation may be issued on a different date.\n* Violations: Number of violations for each camera on a particular day.\n*  X Coordinate: The X Coordinate, measured in feet, of the location of the camera. Geocoded using Illinois State Plane East (ESRI:102671).\n* Y Coordinate: The Y Coordinate, measured in feet, of the location of the camera. Geocoded using Illinois State Plane East (ESRI:102671).\n* Latitude: The latitude of the physical location of the camera(s) based on the ADDRESS column. Geocoded using the WGS84.\n* Longitutde: The longitude of the physical location of the camera(s) based on the ADDRESS column. Geocoded using the WGS84.\n* Location: The coordinates of the camera(s) based on the LATITUDE and LONGITUDE columns. Geocoded using the WGS84.\n\n\n\n### Acknowledgements: \nDataset compiled by City of Chicago [here](https://data.cityofchicago.org/Transportation/Red-Light-Camera-Violations/spqx-js37). \n\n### Inspiration: \n* Which intersections have the most violations?\n* When do most violations occur?\n'","b""['government', 'law', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/chicagopolice/chicago-red-light-violations
b'General Practice Prescribing Data',b'One year of British National Health Service Prescription data',"b""### Context\n\nThe British National Health Service releases data covering every public sector prescription made in the country. This covers a single year of that data.\n\n\n### Content\n\nCovering all general practices in England, the data includes figures on the number of prescription items that are dispensed each month and information relating to costs.\n\nFor each GP practice, the total number of items that were prescribed and then dispensed is shown.\nThe total Net Ingredient Cost and the total Actual Cost of these items is shown.\n\n\nChemical level\n\nAll prescribed and dispensed medicines (by chemical name), dressings and appliances (at section level) are listed for each GP practice.\n\n\nPresentation level\n\nAll prescribed and dispensed medicines, dressings and appliances are listed at presentation level, for each GP practice. (Presentation level gives the individual drug name, the form, and strength or size accordingly).\nThe total quantity of drugs dispensed (in terms of number of tablets or millilitres, for example) is shown.\nThis data does not list each individual prescription and does not contain any patient identifiable data.\n\nThe data have been edited from their original version. During the data preparation process I:\n\n- Dropped obsolete and redundant columns.\n- Normalized the BNF (British National Formulary) codes, BNF names, and practice codes.\nThese steps reduced the total file size by roughly 75%, at the cost of requiring one table join to access some of the data.\n\nFor further details, please see:\n\n- [FAQ](http://content.digital.nhs.uk/media/10048/FAQs-Practice-Level-Prescribingpdf/pdf/PLP_FAQs_April_2015.pdf)\n- [Glossary of Terms](http://content.digital.nhs.uk/media/10686/Download-glossary-of-terms-for-GP-prescribing---presentation-level/pdf/PLP_Presentation_Level_Glossary_April_2015.pdf)\n\n### Acknowledgements\n\nThis dataset was kindly released by the [United Kingdom's National Health Service][1] under their [government open data license v3.][2] You can find this and other datasets at their open data site.\n\n### Inspiration\n\n- What trends can you see in the data? For example, can you identify the onset of winter based on the types of drugs being prescribed?\n- The BNF Name entries contain dosage data that I haven't yet cleaned and extracted. Can you unpack that field into item dispensed, units, and dosage? If so, let me know in the forums and I'll add it to the dataset!\n- Per [this blog from Oxford](https://ebmdatalab.net/prescribing-data-bnf-codes/), the raw BNF codes contain quite a bit of information about a drug's function. Can you find a source of open data for translating these codes? It's probable that one exists somewhere at https://www.nhsbsa.nhs.uk/nhs-prescription-services.\n\n\n  [1]: http://content.digital.nhs.uk/gpprescribingdata\n  [2]: http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/""","b""['healthcare', 'government', 'pharmaceutical industry', 'pharmaceuticals policy', 'pharmacy', 'large', 'featured']""",https://www.kaggle.com/nhs/general-practice-prescribing-data
b'Short Jokes',"b'Collection of over 200,000 short jokes for humour research'","b'**Context**\n\nGenerating humor is a complex task in the domain of machine learning, and it requires the models to understand the deep semantic meaning of a joke in order to generate new ones. Such problems, however, are difficult to solve due to a number of reasons, one of which is the lack of a database that gives an elaborate list of jokes. Thus, a large corpus of over 0.2 million jokes has been collected by scraping several websites containing funny and short jokes.\n\nVisit my [Github repository](https://github.com/amoudgl/short-jokes-dataset) for more information regarding collection of data and the scripts used. \n\n**Content**\n\nThis dataset is in the form of a csv file containing 231,657 jokes. Length of jokes ranges from 10 to 200 characters. Each line in the file contains a unique ID and joke. \n\n**Disclaimer**\n\nIt has been attempted to keep the jokes as clean as possible. Since the data has been collected by scraping websites, it is possible that there may be a few jokes that are inappropriate or offensive to some people.'","b""['linguistics', 'humor', 'medium', 'featured']""",https://www.kaggle.com/abhinavmoudgil95/short-jokes
b'Weather in Szeged 2006-2016',"b'Hourly/daily summary with temperature, pressure, wind speed and more'","b'# Context \n\nThis is a dataset for a larger project I have been working on. My idea is to analyze and compare real historical weather with weather folklore.\n\n# Content\n\nThe CSV file includes a hourly/daily summary for [Szeged, Hungary][1] area, between 2006 and 2016.\n\nData available in the hourly response:\n\n- time\n- summary\n- precipType\n- temperature\n- apparentTemperature\n- humidity\n- windSpeed\n- windBearing\n- visibility\n- loudCover\n- pressure\n\n# Acknowledgements\n\nMany thanks to [Darksky.net][2] team for their awesome API.\n\n [1]: https://en.wikipedia.org/wiki/Szeged?oldformat=true\n [2]: http://darksky.net/dev/'","b""['climate', 'utility', 'medium', 'featured']""",https://www.kaggle.com/budincsevity/szeged-weather
b'Chicago Population by 2010 Census Block',b'From City of Chicago Open Data',"b""### Content  \n\nPopulation estimates by the U.S. Census Bureau by U.S. Census Block.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-population-by-2010-census-block
b'SF Web Analytics for SFGov Sites',b'From San Francisco Open Data',"b""### Content  \n\nWeb analytics data for SFGov sites  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is not updated.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/dBI_My696Rk) by [Chris Liverani](https://unsplash.com/@chrisliverani) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-web-analytics-for-sfgov-sites
b'Food searches on Google since 2004',b'How do we search for food? Google search interest can reveal key food trends over the years.',"b'This is the data behind the Rhythm of Food visualisation by Moritz Stefaner. It shows seasonal food searches in different food types around the world since 2004. The data is indexed, with 0 being the least and 100 being the highest search interest.\n\nFind out more here: http://rhythm-of-food.net/'","b""['internet', 'food and drink', 'journalism', 'small', 'featured']""",https://www.kaggle.com/GoogleNewsLab/food-searches-on-google-since-2004
b'NYC Medical Assistance Program Medicaid Offices',b'From New York City Open Data',"b""### Content  \n\nThis table represents the list of different types of organizations where individuals and families can get help determining their eligibility for public health insurance as well as assistance with completing the application process.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/aF99M98c_uk) by [John Jason](https://unsplash.com/@_johnjase) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-medical-assistance-program-medicaid-offices
b'VGG-13 with batch normalization',b'VGG-13 Pre-trained model with batch normalization for PyTorch',"b'# VGG-13\n\n---\n\n## Very Deep Convolutional Networks for Large-Scale Image Recognition<br>\nIn this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.\n<br>\n\n**Authors: Karen Simonyan, Andrew Zisserman**<br>\n**https://arxiv.org/abs/1409.1556**\n\n---\n\n#VGG Architectures<br>\n![VGG Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/uLXrKxe.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/vgg13bn
b'NYC DHS Daily Report',b'From New York City Open Data',"b""### Content  \n\nThis dataset includes the daily number of families and individuals residing in the Department of Homeless Services (DHS) shelter system and the daily number of families applying to the DHS shelter system.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/8UG90AYPDW4) by [Matt Collamer](https://unsplash.com/@breakyourboundaries4) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-dhs-daily-report
b'Facial Expression of Emotion',b'Frame-by-frame analysis of facial expressions in a video interview',"b'# Context \n\nIt is a database with 9 patients with BPD. Not all patients covered the 12 therapeutic interviews. All patients are women. The duration of the therapeutic intervention varies according to the interview.\n\n\n# Content\n\nWe analyzed the 7 facial expressions of emotion according to the theory of Paul Ekman and David Matsumoto. These expressions were analyzed from video recordings of each therapeutic interviews of each patient, analyzed every 0.04 seconds, that is, there are 25 measurements per second. Not all patients cover all 12 interviews, But the chronology of the sessions appears in order of assistance to the therapy. So what we want to see is resilience or emotional regulation in these patients.\n\nThe emotions of Neutral to Contemp are valued in intensities from 0 to 1. The emotional valence is evaluated from 0 to 1 being positive emotion and 0 to -1 being negative emotion. The arousal is evaluated from 0 to 1.\n\n\n# Acknowledgements\n\nAcknowledgements to Borderline Personality Disorder Clinic for contributing the material, also to the Chronoecology and Human Ethology Laboratory from National Institute Psychiatric Ram\xc3\xb3n de la Fuente Mu\xc3\xb1iz, M\xc3\xa9xico.'","b""['emotion', 'medium', 'featured']""",https://www.kaggle.com/sivlemx/facial-expression-of-emotion
b'NYS New York State Budget and Actuals',b'From New York State Open Data',"b""### Content  \n\nThis data includes disbursement information for the budget year and prior years going back to 1994 for all governmental funds.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/QiESeyAOOyA) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-new-york-state-budget-and-actuals
b'Filipino Family Income and Expenditure',b'Annual Household Income and Expenses in the Philippines',"b""### Context\n\nThe Philippine Statistics Authority (PSA) spearheads the conduct of the Family Income and Expenditure Survey (FIES) nationwide. The survey, which is undertaken every three (3) years, is aimed at providing data on family income and expenditure, including, among others, levels of consumption by item of expenditure, sources of income in cash, and related information affecting income and expenditure levels and patterns in the Philippines.\n\n\n### Content\n\nInside this data set is some selected variables from the latest Family Income and Expenditure Survey (FIES) in the Philippines. It contains more than 40k observations and 60 variables which is primarily comprised of the household income and expenditures of that specific household\n\n### Acknowledgements\n\nThe Philippine Statistics Authority for providing the publisher with their raw data\n\n\n### Inspiration\n\nSocio-economic classification models in the Philippines has been very problematic. In fact, not one SEC model has been widely accepted. Government bodies uses their own SEC models and private research entities uses their own. We all know that household income is the greatest indicator of one's socio-economic classification that's why the publisher would like to find out the following:\n\n1) Best model in predicting household income\n2) Key drivers of household income, we want to make the model as sparse as possible\n3) Some exploratory analysis in the data would also be useful""","b""['finance', 'demographics', 'income', 'medium', 'featured']""",https://www.kaggle.com/grosvenpaul/family-income-and-expenditure
b'The Simpsons Characters Data',b'Image dataset of 20 characters from The Simpsons',"b'### Context\n\nAs a big Simpsons fan, I have watched a lot (and still watching) of The Simpson episodes -multiple times each- over the years. I wanted to build a neural network which can recognize characters.  Feel free to check and recommend my Medium post [Part 1 on a classification model][1]  and [Part 2 on a detection model][2]  (Faster R-CNN) about this dataset and what I am doing with it.  You can also find the related [GitHub repo here][3] .\n\n### Content\n\nI am still building this dataset (labeling pictures), I will upload new versions of this dataset. Please check the files there are descriptions and explanations.\n\nFile simpson-set.tar.gz : This is an image dataset: 20 folders (one for each character) with 400-2000 pictures in each folder.\n\nFile simpson-test-set.zip. : Preview of the image dataset\n\nFile weights.best.h5 : Weights computed, in order to predict in Kernels.\n\nFile annotation.txt : Annotation file for bounding boxes for each character\n\n![The 20 characters][4]\n\n### Acknowledgements\n\nIf someone wants to contribute and make this dataset bigger and more relevant, any help will be appreciated.\n\nData is directly taken and labeled from TV show episodes.\n\nFeel free to check and recommend my Medium post [Part 1 on a classification model][1]  and [Part 2 on a detection model][2]  (Faster R-CNN) about this dataset and what I am doing with it.  You can also find the related [GitHub repo here][3] .\n\n# Inspiration\n\nCan you tell the difference between Maggie Simpson and Lisa Simpson?  Was that Lenny Leonard or was that Carl Carlson?\n\n  [1]: https://medium.com/alex-attia-blog/the-simpsons-character-recognition-using-keras-d8e1796eae36\n  [2]: https://medium.com/alex-attia-blog/the-simpsons-characters-recognition-and-detection-part-2-c44f9d5abf37\n  [3]: https://github.com/alexattia/SimpsonRecognition\n  [4]: https://cdn-images-1.medium.com/max/800/1*64laQlCh-57A6AyTXAeRWQ.png'","b""['image data', 'popular culture', 'object detection', 'large', 'featured']""",https://www.kaggle.com/alexattia/the-simpsons-characters-dataset
b'UK fleet and foreign fleet landings by port',b'Data from 2008-2015 on fishing vessels either from the UK or landing in the UK',"b""### Context\n\nData taken from the Marine Management Organisation on all UK vessels landing in ports, or foreign vessels landing in UK ports. This dataset contains data on the catch, also the weight and value (\xc2\xa3) of the catch.\n\n\n### Content\n\n - **Year** year of landing, 2008-2015\n - **Month** calendar months, 1-12\n - **Port of Landing** name of port\n - **Port Nationality** nationality of the port of landing\n - **Vessel Nationality** nationality of the vessel\n - **Length Group** length of the vessel, 10m or under/Over 10m\n - **Gear Category** gear carried by the vessel\n - **Species Code** three letter code of the catch\n - **Species Name** name of the catch\n - **Species as shown in publication** name of the catch with fewer subcategories\n - **Species Group** catch species\n - **Live Weight (tonnes)** weight of live catch\n - **Landed Weight (tonnes)** landed weight of catch\n - **Value (\xc2\xa3)** the value of the catch in GBP, most likely without any inflation adjustment\n\nPoints to note\n\n 1. Data on **Port Nationality** and **Vessel Nationality** for 2008 were supplied as 3 letter codes, not all of which matched standard country codes. I've tried to clean these up as best I can to match with standard country codes but ones that couldn't be matched have been left as-is.\n 2. **Species Code** and **Species Name** were not supplied for 2008. You may be able to infer some from the 2009-2015 data.\n\n### Inspiration\n * Which UK ports see the greatest activity?\n * Which foreign ports see the greatest number of UK vessels?\n * Has the price-paid per tonne of goods varied during the data collection period?\n * Has there been any major changes in activity for particular species?\n\n### Acknowledgements\n\nData taken from the Office of National Statistics [and is part of the UK Sea Fisheries Annual Statistics][1].\nData are available under a Open Government Licence v3.0.\n\n  [1]: https://www.gov.uk/government/statistical-data-sets/uk-fleet-landings-and-foreign-fleet-landings-into-the-uk-by-port""","b""['business', 'government agencies', 'fishing', 'medium', 'featured']""",https://www.kaggle.com/theflyingmunkey/uk-fleet-landings
b'Cuff-Less Blood Pressure Estimation',b'Pre-processed and cleaned vital signals for cuff-less BP estimation',"b""#Data Set Information:\n\nThe main goal of this data set is providing clean and valid signals for designing cuff-less blood pressure estimation algorithms. The raw electrocardiogram (ECG), photoplethysmograph (PPG), and arterial blood pressure (ABP) signals are originally collected from the physionet.org and then some preprocessing and validation performed on them. (For more information about the process please refer to our paper)\n\n\n#Attribute Information:\n\nThis database consists of a cell array of matrices, each cell is one record part. \nIn each matrix each row corresponds to one signal channel:\n\n1: PPG signal, FS=125Hz; photoplethysmograph from fingertip\n\n2: ABP signal, FS=125Hz; invasive arterial blood pressure (mmHg)\n\n3: ECG signal, FS=125Hz; electrocardiogram from channel II\n\n**Note**: dataset is splitted to multiple parts to make it easier to load on machines with low memory. Each cell is a record. There might be more than one record per patient (which is not possible to distinguish). However, records of the same patient appear next to each other. N-fold cross test and train is suggested to reduce the chance of trainset being contaminated by test patients.\n\n#Relevant Papers:\n\nM. Kachuee, M. M. Kiani, H. Mohammadzade, M. Shabany, Cuff-Less High-Accuracy Calibration-Free Blood Pressure Estimation Using Pulse Transit Time, IEEE International Symposium on Circuits and Systems (ISCAS'15), 2015. \n\nA. Goldberger, L. Amaral, L. Glass, J. Hausdorff, P. Ivanov, R. Mark, J.Mietus, G. Moody, C. Peng and H. Stanley, \xc3\xa2\xe2\x82\xac\xc5\x93Physiobank, physiotoolkit, and physionet components of a new research resource for complex physiologic signals,\xc3\xa2\xe2\x82\xac\xc2\x9d Circulation, vol. 101, no. 23, pp. 215\xc3\xa2\xe2\x82\xac\xe2\x80\x9c220, 2000. \n\n\n\n#Citation Request:\n\nIf you found this data set useful please cite the following: \n\nM. Kachuee, M. M. Kiani, H. Mohammadzade, M. Shabany, Cuff-Less High-Accuracy Calibration-Free Blood Pressure Estimation Using Pulse Transit Time, IEEE International Symposium on Circuits and Systems (ISCAS'15), 2015.\n\nM. Kachuee, M. M. Kiani, H. Mohammadzadeh, M. Shabany, Cuff-Less Blood Pressure Estimation Algorithms for Continuous Health-Care Monitoring, IEEE Transactions on Biomedical Engineering, 2016.""","b""['healthcare', 'health', 'large', 'featured']""",https://www.kaggle.com/mkachuee/BloodPressureDataset
b'Overwatch Game Records',"b'One player, thousands of games, stats meticulously recorded!'","b'Overwatch is a team-based multiplayer online first-person shooter video game developed and published by Blizzard Entertainment. It was released in May 2016 for Windows, PlayStation 4, and Xbox One. Overwatch assigns players into two teams of six, with each player selecting from a roster of over 20 characters, known in-game as ""heroes"", each with a unique style of play, whose roles are divided into four general categories: Offense, Defense, Tank, and Support. Players on a team work together to secure and defend control points on a map or escort a payload across the map in a limited amount of time. \n\nI discovered this dataset on the Overwatch Subreddit here: https://www.reddit.com/r/Overwatch/comments/7o8hmg/my_friend_has_recorded_every_game_hes_played/\n\nIt represents a ridiculous amount of effort in terms of manually recording game results. This data, whilst in some places incomplete, gives an unprecedented view into the experience of a single overwatch player over the course of years of gameplay. From it you can track the ups and downs, shifts in hero preference and all sorts of other exciting in game trends.\n\nThanks to JustWingIt for their amazing collecting this data.\n\nI cleaned the data a little and put it into a single CSV.'","b""['video games', 'games and toys', 'small', 'featured']""",https://www.kaggle.com/mylesoneill/overwatch-game-records
b'FDA Enforcement Actions',"b'Food, drug, and medical device enforcements'","b'The objective of FDA regulatory programs is to assure compliance with the Federal Food, Drug, and Cosmetic Act (the Act). Specific enforcement activities include actions to correct and prevent violations, remove violative products or goods from the market, and punish offenders. The type of enforcement activity FDA uses will depend on the nature of the violation. The range of enforcement activities include issuing a letter notifying the individual or firm of a violation and requesting correction, to criminal prosecution of the individual or firm. Adulteration or misbranding is usually the result of an individual failing to take steps to assure compliance with the law. Such an individual may be liable for a violation of the Act and, if found guilty, be subject to the penalties specified by the law.\n\n### Acknowledgements\n\nThis dataset was kindly made available by the United States Food and Drug Administration. You can find [the most current version of the dataset here][1].\n\n### Inspiration\n\n- All but two out of every thousand drug enforcement actions were voluntary recalls. Does this hold for food and medical devices as well? Was there anything special about the non-voluntary enforcement actions that leads the industry to largely self-police?\n\n  [1]: https://open.fda.gov/downloads/'","b""['public health', 'health law', 'large', 'featured']""",https://www.kaggle.com/fda/fda-enforcement-actions
b'Arabic - Egyptian comparable Wikipedia corpus',b'Arabic (Modern Standard) and Egyptian Arabic dialect comparable documents',"b'### Context\n\nEgyptian is an Arabic dialect, and it is the only Arabic dialect that has articles on Wikipedia. That is why I decided to extract Arabic-Egyptian comparable corpus from Wikipedia to make these resources available for linguists and computational linguists. \n\n\n### Content\n\nThe dataset is composed of a set of text documents in both Arabic (Modern Standard) and Egyptian dialect aligned at document level. comparable documents share the same document ID. \n\n### Acknowledgements\n\nThanks to Wikipedia and Wikipedia contributors who make these resource available. This corpus was collected by:\nM. Saad and B. O. Alijla, ""WikiDocsAligner: An Off-the-Shelf Wikipedia Documents Alignment Tool,"" 2017 Palestinian International Conference on Information and Communication Technology (PICICT), Gaza, Palestine, 2017, pp. 34-39.\ndoi: 10.1109/PICICT.2017.27\n\n\n\n### Inspiration\n\nWhat are the most common words in Egyptian and Arabic?\nWhat are the most frequent words in Egyptian and Arabic?\nWhat are the least frequent (rare) words in Egyptian and Arabic?'","b""['linguistics', 'languages', 'medium', 'featured']""",https://www.kaggle.com/mksaad/arb-egy-cmp-corpus
b'Street Network of New York in GraphML',b'Analyse the New York City Street Network!',"b'### Context\nHaving such a task as predicting the travel time of taxis, it can be insightful to have a deeper look at the underlying street network of the city. Network Analysis can enable us to get insights for why certain taxi trips take longer than others given some basic network properties. Examples for the analysis can be: calculate the shortest path, measure the influence of specific streets on the robustness of the network or find out which streets are key points in the network when it comes to traffic flow.\n\n### Content\nThis dataset contains one large Graph for the Street Network of New York City in GraphML format and a subgraph for the area of Manhattan for fast testing of your Analysis. \nEach Graph was created with the awesome python package https://github.com/gboeing/osmnx which is not available on Kaggle. The Graphs nodes attributes are taken from OSM and contain information to which other nodes they are connected, how long the connection is, which speed limit it has etc.\n\n### Acknowledgements\nhttps://github.com/gboeing/osmnx\n\n\n### Inspiration\nExplore the New York Street Network, gain a deeper understanding for network analysis and craft some useful Features for the Taxi Trip Prediction Competition!'","b""['networks', 'medium', 'featured']""",https://www.kaggle.com/crailtap/street-network-of-new-york-in-graphml
b'30 Years of European Solar Generation',b'Hourly energy potential for 1986-2015',"b""This dataset contains hourly estimates of an area's energy potential for 1986-2015 as a percentage of a power plant's maximum output.\n\nThe overall scope of EMHIRES is to allow users to assess the impact of meteorological\nand climate variability on the generation of solar power in Europe and not to mime the\nactual evolution of solar power production in the latest decades. For this reason, the\nhourly solar power generation time series are released for meteorological conditions of\nthe years 1986-2015 (30 years) without considering any changes in the solar installed\ncapacity. Thus, the installed capacity considered is fixed as the one installed at the end of\n2015. For this reason, data from EMHIRES should not be compared with actual power\ngeneration data other than referring to the reference year 2015. \n\n### Content\n\n- The data is available at both the national level and the NUTS 2 level. [The NUTS 2 system][1] divides the EU into 276 statistical units.\n- Please see the manual for the technical details of how these estimates were generated. \n- This product is intended for policy analysis over a wide area and is not the best for estimating the output from a single system. Please don't use it commercially.\n\n### Acknowledgements\n\nThis dataset was kindly made available by the [European Commission's STETIS program][2]. You can find the original dataset here.\n\n### Inspiration\n\n- How clean is the dataset? Older solar estimates used to contain impossible values around sunset (ie more energy than the sun releases) or negative sunlight.\n- What does a typical year look like? One common approach is to stitch together 12 months of raw data, using the 12 most typical months per this ISO standard.\n\n\n## If you like\nIf you like this dataset, you might also enjoy: \n- 30 years of European wind \n- Google's Project Sunroof \n\n  [1]: https://en.wikipedia.org/wiki/Nomenclature_of_Territorial_Units_for_Statistics\n  [2]: https://setis.ec.europa.eu/about-setis""","b""['energy', 'medium', 'featured']""",https://www.kaggle.com/sohier/30-years-of-european-solar-generation
"b'ACLED African Conflicts, 1997-2017'",b'Details on 165k Conflicts Across Africa Over Twenty Years',"b'### Context: \nThe [Armed Conflict Location and Event Data Project](https://www.acleddata.com/about-acled/) is designed for disaggregated conflict analysis and crisis mapping. This dataset codes the dates and locations of all reported political violence and protest events in dozens of developing countries in Africa. Political violence and protest includes events that occur within civil wars and periods of instability, public protest and regime breakdown. The project covers all African countries from 1997 to the present.\n\n### Content: \nThese data contain information on:\n\n- Dates and locations of conflict events;\n- Specific types of events including battles, civilian killings, riots, protests and recruitment activities;\n- Events by a range of actors, including rebels, governments, militias, armed groups, protesters and civilians;\n- Changes in territorial control; and\n- Reported fatalities.\n\nEvent data are derived from a variety of sources including reports from developing countries and local media, humanitarian agencies, and research publications. Please review the [codebook](http://www.acleddata.com/wp-content/uploads/2017/01/ACLED_Codebook_2017.pdf) and [user guide](http://www.acleddata.com/wp-content/uploads/2017/01/ACLED_User-Guide_2017.pdf) for additional information: the codebook is for coders and users of ACLED, whereas the brief guide for users reviews important information for downloading, reviewing and using ACLED data. A specific [user guide for development and humanitarian practitioners](http://www.acleddata.com/wp-content/uploads/2017/01/ACLED_User-Guide-for-Humanitarians_2017.pdf) is also available, as is a guide to our sourcing materials.\n\n\n### Acknowledgements: \nACLED is directed by Prof. Clionadh Raleigh (University of Sussex). It is operated by senior research manager Andrea Carboni (University of Sussex) for Africa and Hillary Tanoff for South and South-East Asia. The data collection involves several research analysts, including Charles Vannice, James Moody, Daniel Wigmore-Shepherd, Andrea Carboni, Matt Batten-Carew, Margaux Pinaud, Roudabeh Kishi, Helen Morris, Braden Fuller, Daniel Moody and others. Please cite:\n\nRaleigh, Clionadh, Andrew Linke, H\xc3\xa5vard Hegre and Joakim Karlsen. 2010. Introducing ACLED-Armed Conflict Location and Event Data. Journal of Peace Research 47(5) 651-660.\n\n### Inspiration: \nDo conflicts in one region predict future flare-ups? How do the individual actors interact across time? Do some sources report more often on certain actors?'","b""['politics', 'war', 'africa', 'medium', 'featured']""",https://www.kaggle.com/jboysen/african-conflicts
b'Taiwan PTT stock topics and intraday trading chats',b'Find out the relationship of BBS user activity/texts and stock prices',"b'### Context\nPTT is the biggest BBS in Taiwan, it contained lots of news and discussion in different boards. PTT stock board is really popular because many of the users would give their opinions on trends of the market. Most of them tried to predict the trend of the  index(^TWII). It would be interesting to know if the users activities or texts was correlated with index price or trend.\n\n### Content\nThere are 3 csv files.\n\n""PTT_stock_p3000_p3718.csv""\n\nIt contains about 2 years of the stock discussion topic name, topic_URL, author ID,  number of people liked it or not(push type).\n\n""daychat_push_60d_1006.csv""\n\nIt contains 60 days of instant intraday trading chats texts (2017/7/17~2017/10/06)\n\n""TWII_20151001_20171006.csv""\n\nDaily OHLC , volume, up or down, %changes and volatility level of ^TWII historical prices between 2015/10/01 and 2017/10/06\n\n*** Data has been updated to 2018/05/03.\n\n1. PTT_stock_p3718_p4245.csv\n\n2. daychat_push_60d_20180503.csv\n\n3. TWII_20171006_20180503\n\n### Acknowledgements\nAll of the text data could be found on: https://www.ptt.cc/bbs/Stock/index.html.\n\nThe historical price data of Taiwan stock market index (^TWII) was from Yahoo Finance.\n\n### Inspiration\n1. There are few NLP data presented in Mandarin. It would be a new challenge to interpret texts not written in English.\n2. Since the text data were all about stock or index going up or down, so it would be interesting to know which ID predicts accurate or misleading the others about the market trend.\n3. Is volatility level correlated with intraday trading chat amounts or topic amounts of the day?\n4. Can you tell which is the most popular stock they are observing, and the trend is going up or down?'","b""['finance', 'linguistics', 'languages', 'small', 'featured']""",https://www.kaggle.com/randyrose2017/pttstock
b'High-Content Screening with C.Elegans',"b'A small, fully annotated dataset for getting starting with HCS analysis'","b'# About\nThis selection of images are controls selected from a screen to find novel anti-infectives using the roundworm C.elegans . The animals were exposed to the pathogen Enterococcus faecalis and either untreated or treated with ampicillin, a known antibiotic against the pathogen. The untreated (negative control) worms display predominantly the ""dead"" phenotype: worms appear rod-like in shape and slightly uneven in texture. The treated (ampicillin, positive control) worms display predominantly the ""live"" phenotype: worms appear curved in shape and smooth in texture. For more information, please see Moy et al. (ACS Chem Biol, 2009) [http://dx.doi.org/10.1021/cb900084v]\n\n# Images\n\nOne image per channel (Channel 1 = brightfield; channel 2 = GFP) was acquired at MGH on a Discovery-1 automated microscope (Molecular Devices). Original image size is 696 x 520 pixels. Images are available in 16-bit TIF.\n\n# Ground Truth\n\t\nThe 384 images are from a plate of positive and negative controls. The images are named using this format: \n```\n<plate>_<wellrow>_<wellcolumn>_<wavelength>_<fileid>.tif\n```\n Columns 1-12 are positive controls treated with ampicillin. Columns 13-24 are untreated negative controls.\n\nWe also provide human-corrected binary images of foreground/background segmentation. To address the problem of correctly segmenting individual worms also when they overlap or cluster, we provide one binary foreground/background segmentation ground truth image for each worm:\n\n# Acknowledgements\nThe data have been reposted from the original data taken from the Broad Institute. Please acknowledge the original source if this is used in other works. The original data can be found and downloaded here:\nhttps://data.broadinstitute.org/bbbc/BBBC010/ \n\nThese images were originally acquired for a screen in Fred Ausubel\'s lab at MGH. Please contact aconery AT molbio.mgh.harvard.edu for more information.\n\nOriginal Publication: http://dx.doi.org/10.1038/nmeth.1984\n\n# Inspiration'","b""['healthcare', 'diseases', 'microtechnology', 'medium', 'featured']""",https://www.kaggle.com/kmader/high-content-screening-celegans
b'Natural Stories Corpus',b'A corpus of stories with human reading times (by word)',"b""### Context: \n\nIt is now a common practice to compare models of human language processing by predicting participant reactions (such as reading times) to corpora consisting of rich naturalistic linguistic materials. However, many of the corpora used in these studies are based on naturalistic text and thus do not contain many of the low-frequency syntactic constructions that are often required to distinguish processing theories. The corpus includes self-paced reading time data for ten naturalistic stories.\n\n### Content: \n\nThis is a corpus of naturalistic stories meant to contain varied, low-frequency syntactic constructions. There are a variety of annotations and psycholinguistic measures available for the stories.\nThe stories in with their various annotations are coordinated around the file words.tsv, which specifies a unique code for each token in the story under a variety of different tokenization schemes. For example, the following lines in words.tsv cover the phrase the long-bearded mill owners.:\n\n1.54.whole      the\n\n1.54.word       the\n\n1.54.1  the\n\n1.55.whole      long - bearded\n\n1.55.word       long - bearded\n\n1.55.1  long\n\n1.55.2  -\n\n1.55.3  bearded\n\n1.56.whole      mill\n\n1.56.word       mill\n\n1.56.1  mill\n\n1.57.whole      owners .\n\n1.57.word       owners\n\n1.57.1  owners\n\n1.57.2  .\n\n\nThe first column is the token code; the second is the token itself. For example, 1.57.whole represents the token owners.and 1.57.word represents the token owners. The token code consists of three fields:\n\n 1. The id of the story the token is found in,\n 2. The number of the token in the story,\n 3.  An additional field whose value is whole for the entire token including punctuation, word for the token stripped of punctuation to the left and right, and then 1 through n for each sub-token in whole as segmented by NLTK's TreebankWordTokenizer.\n\nThe various annotations (frequencies, parses, RTs, etc.) should reference these codes so that we can track tokens uniformly.\n\nThis dataset contains reading time data collected for 10 naturalistic stories. Participants typically read 5 stories each. The data is contained in batch1_pro.csv and batch2_pro.csv\n\nall_stories.tok contains the 10 stories, with one word per row. Item is the story number, zone is the region where the word falls within the story. Note that some wordforms in all_stories.tok differ from those in words.tsv, reflecting typos in the SPR experiment as run.\n\n### Acknowledgements: \n\n If you use this dataset in your work, please cite the following paper:\n\nFutrell, R., Gibson, E., Tily, H., Blank, I., Vishnevetsky, A., Piantadosi, S. T., & Fedorenko, E. (2017). The Natural Stories Corpus. arXiv preprint arXiv:1708.05763.\n\nA more complete version of this dataset, with additional supporting files, can be found in this [GitHub repository](https://github.com/languageMIT/naturalstories) maintained by  by Richard Futrell at Massachusetts Institute of Technology, Titus von der Malsburg at the University of Potsdam and Cory Shain at The Ohio State University.\n\n### Inspiration: \n\n* What words do participants tend to read more slowly or quickly?\n* Are certain parts of speech read more quickly or slowly?\n* How much variation in reading speed is there between individuals?\n* What\xe2\x80\x99s the relationship between word length & reading speed?""","b""['linguistics', 'languages', 'literature', 'reading', 'medium', 'featured']""",https://www.kaggle.com/rtatman/natural-stories-corpus
b'Who Dies? Physics Puzzle Dataset',b'Who can predict the outcome of a physics puzzle better - human or machine?',"b'## The Game ##\n""Who Dies?"" is a simple physics puzzle available for [Android][1]. Randomly, a world full of stones, monsters, coil springs, slingshots and other objects is created. The user has to guess, which monster will get hit by a stone or falls of the platform when gravity is turned on. He gets point for every right guess, the more points he collects, the more complex the worlds will get.\n![Game][2]\n\n\n## The Development ##\nFor development, [Phaser][3] was used, the game map is a 35x20 grid. Each tile in this grid can contain different blockers or objects. \n![Who Dies Grid][4]\n\n## The Data ##\nEvery time a user is playing the game, the position of all objects is recorded as well as the selection the user has made and the final set of monsters who died. The dataset consists of 5 columns: DATETIME is a timestamp of when a user played the game. COMPLEXITY is a parameter that measures the difficulty of the game (1 = easy, 100 = hard). MAP is a JSON array containing 3 arrays: The **first** array contains **immobile foreground objects** described by a ""type"" property including x and y coordinates. The following list gives an overview about the the most commonly used types:\n\n![enter image description here][5]\n\nThe **second** array contains immobile background objects that don\'t interact with the game objects and are therefore not relevant. The **third** array contains movable foreground objects. These could be: monsters (""guys""), balls (""smallball"", ""ball"" and ""bigball"" with or without an initial rotation to the left or right), spring (catapults boxes and balls up in the air but not monsters), box, chain, seesaw, spin, switch and switchwall (if a ball touches a switch, all switchwalls with the same color as the switch change their visibility and become transparent to foreground objects or vice versa).\nColumn ""MONSTERS_SELECTED"" contains all the monsters a player thought will get hit by a ball (ordered by the selection time)\n""MONSTERS_HIT"" contains all monsters that were actually killed by balls or fell of the platform (ordered by time)\n\n## The Goal ##\nThere are several interesting outcomes, for example:\n\n - Creating a ML algorithm that is able to correctly predict the outcome of the game (which monster will die)\n - Creating a ML algorithm that is able to correctly predict which monsters a user will most likely pick \n - Creating a ML algorithm that is able to create new (better?) game worlds\n\n\n  [1]: https://play.google.com/store/apps/details?id=io.cordova.myappb8aefb\n  [2]: http://wissenkompakt.bplaced.com/whodies/Who_Dies_gif.gif\n  [3]: https://phaser.io\n  [4]: http://wissenkompakt.bplaced.com/whodies/wd_grid.png\n  [5]: http://wissenkompakt.bplaced.com/whodies/types.png'","b""['video games', 'artificial intelligence', 'medium', 'featured']""",https://www.kaggle.com/christianvorhemus/physicspuzzlewhodies
b'Total Merchant Wholesalers Inventory and Sales',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/SLIFI67jv5k) by [Ant Rozetsky](https://unsplash.com/@rozetsky) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'utility', 'small', 'featured']""",https://www.kaggle.com/census/total-merchant-wholesalers-inventory-and-sales
b'AWS Spot Pricing Market',"b'This includes price, region, instance size, and OS for AWS Spot Instances'","b'# Context \n\nAWS spot Instances allow users to bid on spare server capacity. You set a bid threshold for an instance that is usually upwards of 30% cheaper than standard on-demand AWS instances. You can save a lot of money with AWS spot instances.\n\n# Data Content\n\nI pulled this data from the AWS CLI with the `describe-spot-price-history` command. I took a lot of time to acquire and transform, which is why I decided to provide it here. \n\nThere are various time periods per region (I acquired all that I could). The columns are all fairly self-evident. Please comment if you have any questions about the data or columns.\n\nThe data includes the following column fields:\n\n- **price**:  the current Spot price \n- **datetime**: the date and time\n- **instance_type**: the Spot instance type \n- **os**: the Spot instance operating system \n- **region**: the region and availability zone (AZ) for the Spot instance\n\n# Inspiration\n\nWhile AWS spot instances are significantly cheaper than on-demand instances, there is only one problem with spot instances: once the spot market price of an instance exceeds the bid threshold you purchased an instance for, the instance is terminated and given to others with higher bids. So while hourly server costs are cheaper, your server is liable to terminate without notice. But, there is a difference between regions and spot pricing. Sometimes there is an arbitrage between regions, and some regions have more stable prices than others (fewer price spikes). If you can find which region/AZ is most stable, you can worry less about your instance terminating without notice. \n\nI started collecting this data because I wanted answers to two questions:\n\n1. Which region/AZ is historically cheapest for instance X \n2. Which region/AZ is historically most stable for instance X\n\nWe could also use this data to predict which regions are likely to stay under a certain $ Spot price, which would allow you to say with some amount of certainty whether a SPOT instance lasts the next [6,12,18]+ hours.'","b""['business', 'computing', 'large', 'featured']""",https://www.kaggle.com/noqcks/aws-spot-pricing-market
b'Handwritten Mathematical Expressions',b'Can you use computer vision to recognize handwritten mathematical expressions?',"b""### Context\n\nIf you've ever had to typeset mathematical expressions, you might have thought:  wouldn\xe2\x80\x99t it be great if I could just take a picture of a handwritten expression and have it be recognized automatically? This dataset has all the data you\xe2\x80\x99ll need to build a system to do just that.\n\n###Description\n\nThe dataset provide more than 11,000 expressions handwritten by hundreds of writers from different countries, merging the data sets from 4 CROHME competitions. Writers were asked to copy printed expressions from a corpus of expressions. The corpus has been designed to cover the diversity proposed by the different tasks and chosen from an existing math corpus and from expressions embedded in Wikipedia pages. Different devices have been used (different digital pen technologies, white-board input device, tablet with sensible screen), thus different scales and resolutions are used. The dataset provides only the on-line signal.\n \nIn the last competition CROHME 2013 the test part is completely original and the train part is using 5 existing data sets:\n \n* MathBrush  (University  of  Waterloo), \n* HAMEX  (University  of  Nantes), \n* MfrDB  (Czech Technical  University), \n* ExpressMatch  (University  of Sao Paulo),\n* the KAIST data set.\n\nIn CROHME 2014 a new test set has been created with 987 new expressions and 2 new tasks has been added: isolated symbol recognition and matrix recognition. Train and test files as the evaluation scripts for these new tasks are provided. For the isolated symbol datasets, elements are extracted from full expression using the existing datasets, which also includes segmentation errors. For the matrix recognition task, 380 new expressions have been labelled and split into training and test sets.\n \nFurthermore, 6 participants of the 2012 competition provide their recognized expressions for the 2012 test part. This data allows research on decision fusion or evaluation metrics.\n\n### Technical Details\n\nThe ink corresponding to each expression is stored in an InkML file. An InkML file mainly contains three kinds of information:\n \n* The  ink: a set of traces made of points;\n* The  symbol level ground truth: the segmentation and label information of each symbol in the expression;\n* The  expression level ground truth: the MathML structure of the expression.\n \nThe  two levels of ground truth information (at the symbol as well  as at  the expression level) are entered manually.  Furthermore, some  general information is added in the file:\n \n* The channels (here, X and Y);\n* The writer   information (identification, handedness (left/right), age, gender, etc.), if available;  \n* The LaTeX ground truth (without any reference to the ink and hence, easy to render);  \n* The unique identification code of the ink (UI), etc.\n\nThe InkML format makes references between the digital ink of the expression, its segmentation into symbols and its  MathML representation. Thus, the stroke segmentation of a symbol can be linked to its MathML representation.\n \nThe recognized expressions are the outputs of the recognition competitors' systems. It uses the same InkML format, but without the ink information (only segmentation, label and MathML structure).\n \nMore details available on [CROHME website](http://www.isical.ac.in/~crohme/index.html).\n\n### Acknowledgements\n\nThis dataset was compiled by Harold Mouch\xc3\xa8re and is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License. If you use this dataset in your work, please include the following citation:\n\nHarold Mouch\xc3\xa8re, ICFHR 2014 CROHME: Fourth International Competition on Recognition of Online Handwritten Mathematical Expressions (CROHME-2014) ,2,ID:CROHME-2014_2,URL:http://tc11.cvc.uab.es/datasets/CROHME-2014_2\n\n### You might also like:\n\n* [Handwritten math symbols dataset: Over 100 000 image samples](https://www.kaggle.com/xainano/handwrittenmathsymbols)\n* [Arabic Handwritten Digits Dataset](https://www.kaggle.com/mloey1/ahdd1)""","b""['artificial intelligence', 'writing', 'mathematics', 'medium', 'featured']""",https://www.kaggle.com/rtatman/handwritten-mathematical-expressions
b'The Bank of England\xe2\x80\x99s balance sheet',b'Annual data from 1696 to 2014',"b""This dataset contains an annual summary of the assets and liabilities from the bank's founding in 1696 through 2014.\n\n### Content\n\nThe csv is a condensed version of the original spreadsheet. Some notes, disclaimers, and a small portion of the data have been discarded to enable the format conversion.\n\n### Acknowledgements\n\nThis dataset was kindly made available by the [Bank of England][1]. You can find [the original dataset here][2].\n\n### Inspiration\n\n- Can you back out key moments in history from this dataset using time series analysis?\n\n\n  [1]: http://www.bankofengland.co.uk/Pages/home.aspx\n  [2]: http://www.bankofengland.co.uk/research/Pages/datasets/default.aspx#""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/sohier/the-bank-of-englands-balance-sheet
b'ResNet-152',b'ResNet-152 Pre-trained Model for PyTorch',"b'# ResNet-152\n\n---\n\n## Deep Residual Learning for Image Recognition\nDeeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. \n\nAn ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. \n\nThe depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.<br>\n\n**Authors: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun**<br>\n**https://arxiv.org/abs/1512.03385**\n\n---\n\n\nArchitecture visualization: http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006\n\n![Resnet][1]\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/nyYh5xH.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/resnet152
b'Road Accidents Incidence',b'Road Accidents Data Great Britain 1979-2015',b'# Context \n\nRoad Accidents\n\n\n# Content\n\nDataset has been fetched from [here][1] and the files have been merged and cleaned to reach the final data attached.\nPrimarily Captures Road Accidents in UK between 1979 and 2015 and has 70 features/columns and about 250K rows.\nAlso attached with it is an excel file with Multiple Tabs that can help one to understand the Data.\n\n\n# Acknowledgements\n\nData has been fetched from Open Data Platform UK and is being shared under Open Government Licence.\nFor more details refer to [Open Data UK][2]\n\n\n  [1]: http://Data.gov.uk\n  [2]: https://data.gov.uk/dataset/road-accidents-safety-data/resource/6d253c0f-caa4-4eaf-aa85-464dc48252da',"b""['road transport', 'medium', 'featured']""",https://www.kaggle.com/akshay4/road-accidents-incidence
b'Unimorph',b'Morphological annotation for 352 languages',"b""### Context: \nThe fact that some languages extensively use suffixes and prefixes to convey grammatical meaning(e.g.  subject-verb agreement) poses a challenge to most current human language technology (HLT). Suffixes and prefixes in such languages can more generally be called morphemes, which are defined as the meaningful subparts of words.  The rules that languages use to combine morphemes, together with the actual morphemes that they use (i.e. suffixes and prefixes themselves), are both referred to as a language's morphology.  Languages which make extensive use of morphemes to build words are said to be morphologically-rich.  These include languages such as Turkish and can be contrasted with so-called analytic languages such as Mandarin Chinese, which does not use suffixes or prefixes all.\n\nThe  goal  of  the  Universal  Morphological  Feature  Schema  is  to  allow  an  inflected  word  from any language to be dened by its lexical meaning (typically carried in the root or stem) and by a  rendering  of  its  inflectional  morphemes  in  terms  of  features  from  the  schema  (i.e.  a  vector  of universal  morphological  features).   When  an  inflected  word  is  defined in  this  way,  it  can  then  be translated  into  any  other  language  since  all  other  inflected  words  from  all  other  languages  can also  be  defined  in  terms  of  the  Universal  Morphological  Feature  Schema.   Although  building  an interlingual representation for the semantic content of human language as a whole is typically seen as prohibitively difficult, the comparatively small extent of grammatical meanings that are conveyed by overt, affixal inflectional morphology places a natural bound on the range of meaning that must be expressed by an interlingua for inflectional morphology.\n\n### Content: \nThis dataset contains Unimorph morphological annotations for 352 languages. Each language\xe2\x80\x99s annotations are in a separate file, and each file has a different number of words.\n\nMany cells in each file are empty. This is because not every feature that is annotated applies to every part of speech. Nouns, for example, do not have a tense. In addition, not every language makes use of every possible morphological marking. For instance, English does not have an evidentiality inflection, while other languages, like Mongolian and Eastern Pomo, do.\n\n### Acknowledgments: \n\nThe Unimorph framework was developed by John Sylak-Glassman. If you use this framework in your work, please cite the following paper:\n\nSylak-Glassman, J. (2016). The composition and use of the universal morphological feature schema (unimorph schema). Technical report, Department of Computer Science, Johns Hopkins University.\n\n### You may also like:\n\n* [Extinct Languages: Number of endangered languages in the world, and their likelihood of extinc](https://www.kaggle.com/the-guardian/extinct-languages)\n* [Stopword Lists for 19 Languages: Lists of high-frequency words usually removed during NLP analysis](https://www.kaggle.com/rtatman/stopword-lists-for-19-languages)\n* [Atlas of Pidgin and Creole Language Structures: Information on 76 Creole and Pidgin Languages](https://www.kaggle.com/rtatman/atlas-of-pidgin-and-creole-language-structures)""","b""['linguistics', 'large', 'featured']""",https://www.kaggle.com/rtatman/unimorph
b'UK Housing Prices Paid',b'Records of all individual transactions in England and Wales since 1995',"b'The Price Paid Data includes information on all registered property sales in England and Wales that are sold for full market value. Address details have been truncated to the town/city level. \n\nYou might also find the HM Land Registry transaction records to be a useful supplement to this dataset: https://www.kaggle.com/hm-land-registry/uk-land-registry-transactions\n\nThe available fields are as follows:\n\nTransaction unique identifier\tA reference number which is generated automatically recording each published sale. The number is unique and will change each time a sale is recorded.\n\nPrice\tSale price stated on the transfer deed.\n\nDate of Transfer\tDate when the sale was completed, as stated on the transfer deed.\n\nProperty Type\tD = Detached, S = Semi-Detached, T = Terraced, F = Flats/Maisonettes, O = Other \nNote that: \n- we only record the above categories to describe property type, we do not separately identify bungalows. \n- end-of-terrace properties are included in the Terraced category above. \n- \xe2\x80\x98Other\xe2\x80\x99 is only valid where the transaction relates to a property type that is not covered by existing values.\n\nOld/New\tIndicates the age of the property and applies to all price paid transactions, residential and non-residential.\nY = a newly built property, N = an established residential building\n\nDuration\tRelates to the tenure: F = Freehold, L= Leasehold etc.\nNote that HM Land Registry does not record leases of 7 years or less in the Price Paid Dataset.\n\nTown/City\t \n\nDistrict\t \n\nCounty\t \n\nPPD Category Type\tIndicates the type of Price Paid transaction.\nA = Standard Price Paid entry, includes single residential property sold for full market value.\nB = Additional Price Paid entry including transfers under a power of sale/repossessions, buy-to-lets (where they can be identified by a Mortgage) and transfers to non-private individuals. Note that category B does not separately identify the transaction types stated. HM Land Registry has been collecting information on Category A transactions from January 1995. Category B transactions were identified from October 2013. \n\nRecord Status - monthly file only\tIndicates additions, changes and deletions to the records.(see guide below).\nA = Addition\nC = Change\nD = Delete.\n\nNote that where a transaction changes category type due to misallocation (as above) it will be deleted from the original category type and added to the correct category with a new transaction unique identifier.\n\n\nThis data was kindly released by [HM Land Registry][1] under [the Open Government License 3.0][2]. You can find their current release [here](https://www.gov.uk/government/statistical-data-sets/price-paid-data-downloads).\n\nData produced by HM Land Registry \xc2\xa9 Crown copyright 2017.\n\n\n  [1]: https://www.gov.uk/government/organisations/land-registry/about\n  [2]: https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/'","b""['finance', 'government', 'housing', 'large', 'featured']""",https://www.kaggle.com/hm-land-registry/uk-housing-prices-paid
b'CoMNIST',b'Cyrillic-oriented MNIST: A dataset of Latin and Cyrillic letter images',"b'## Cyrillic-oriented MNIST\n\n### CoMNIST services\n<b>A repository of images of hand-written Cyrillic and Latin alphabet letters for machine learning applications.</b>\n\nThe repository currently consists of 28,000+ 278x278 png images representing all 33 letters of the Russian alphabet and the 26 letters of the English alphabet. Find original source on my [github](https://github.com/GregVial/CoMNIST)\nThese images have been hand-written on touch screen through crowd-sourcing.\n\n*The dataset will be regularly extended with more data as the collection progresses*\n\n<b> An API that reads words in images</b>\n\nCoMNIST also makes available a web service that reads drawing and identifies the word/letter you have drawn.\nOn top of an image you can submit an expected word and get back the original image with mismtaches highlighted (for educational purposes)\n\nThe API is available at this address: http://35.187.34.5:5002/api/word\nIt is accessible via a POST request with following input expected:\n```\n{\n    \'img\': Mandatory b64 encoded image, with letters in black on a white background\n    \'word\': Optional string, the expected word to be read\n    \'lang\': Mandatory string, either \'en\' or \'ru\', respectively for Latin or Cyrillic (russian) alphabets\n    \'nb_output\': Mandatory integer, the ""tolerance"" of the engine\n}\n```\n\nThe return information is the following:\n```\n{\n    \'img\': b64 encoded image, if a word was supplied as an input, then modified version of that image highlighting mismatches\n    \'word\': string, the word that was read by the API\n}\n```\n\n### Participate\nThe objective is to gather at least 1000 images of each class, therefore your contribution is more that welcome! One minute of your time is enough, and don\'t hesitate to ask your friends and family to participate as well.\n\n[English version](http://comnist.gregvi.al) - Draw Latin only + common to cyrillic and latin\n\n[French version](http://comnist.gregvi.al/?fr) - Draw Latin only + common to cyrillic and latin\n\n[Russian version](http://comnist.gregvi.al/?ru) - Draw Cyrillic only\n\nFind out more about CoMNIST on my [blog](http://ds.gregvi.al/2017/02/28/CoMNIST/)\n\n### Credits and license\n\nA big thanks to all the [contributors](https://github.com/GregVial/CoMNIST/blob/master/misc/contributors.md)!\n\nThese images have been crowd-sourced thanks to the great web-design by Anna Migushina available on her [github](https://github.com/migusta/coMNIST).\n\nCoMNIST logo by [Sophie Valenina](http://www.facebook.com/pg/catandtonicdesigns)'","b""['image data', 'linguistics', 'multiclass classification', 'writing', 'russia', 'medium', 'featured']""",https://www.kaggle.com/gregvial/comnist
b'Chinese Characters Generator',"b'Chinese fonts dataset, which can be used for Chinese text OCR'",b'About This Dataset\n=====\nYou can use this fonts file to generate some Chinese character.\nUse this image can train a machine learning model to recognize text.\n\nDataset is updating\n=====\n\n## Tell me if you have other font file or anything related to this topic.',"b""['linguistics', 'writing', 'medium', 'featured']""",https://www.kaggle.com/dylanli/chinesecharacter
b'OECD Current Account Balance: Total Trade of Goods',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/LaHgrqo1ZRk) by [Karl Magnuson](https://unsplash.com/@kmagnuson) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'utility', 'small', 'featured']""",https://www.kaggle.com/oecd-org/oecd-current-account-balance-total-trade-of-goods
b'Retail Data Analytics',b'Historical sales data from 45 stores',"b'### Context \n\nThe Challenge - One challenge of modeling retail data is the need to make decisions based on limited history. Holidays and select major events come once a year, and so does the chance to see how strategic decisions impacted the bottom line. In addition, markdowns are known to affect sales \xe2\x80\x93 the challenge is to predict which departments will be affected and to what extent.  \n\n### Content\n\nYou are provided with historical sales data for 45 stores located in different regions - each store contains a number of departments.  The company also runs several promotional markdown events throughout the year. These markdowns precede prominent holidays, the four largest of which are the\xc2\xa0Super Bowl, Labor Day, Thanksgiving, and Christmas. The weeks including these holidays are weighted five times higher in the evaluation than non-holiday weeks.\n\nWithin the Excel Sheet, there are 3 Tabs \xe2\x80\x93 Stores, Features and Sales \n\n### Stores \n\nAnonymized information about the 45 stores, indicating the type and size of store\n\n### Features\n\nContains additional data related to the store, department, and regional activity for the given dates. \n\n* Store - the store number\n* Date - the week\n* Temperature - average temperature in the region\n* Fuel_Price - cost of fuel in the region\n* MarkDown1-5 - anonymized data related to promotional markdowns. MarkDown data is only available after Nov 2011, and is not available for all stores all the time. Any missing value is marked with an NA\n* CPI - the consumer price index\n* Unemployment - the unemployment rate\n* IsHoliday -\xc2\xa0whether the week is a special holiday week\n\n### Sales \n\nHistorical sales data, which covers to 2010-02-05 to 2012-11-01. Within this tab you will find the following fields:\n\n* Store - the store number\n* Dept - the department number\n* Date - the week\n* Weekly_Sales - \xc2\xa0sales for the given department in the given store\n* IsHoliday - whether the week is a special holiday week\n\n\n### The Task\n\n1. Predict the department-wide sales for each store for the following year\n2. Model the effects of markdowns on holiday weeks\n3. Provide recommended actions based on the insights drawn, with prioritization placed on largest business impact'","b""['medium', 'featured']""",https://www.kaggle.com/manjeetsingh/retaildataset
b'US Veteran Suicides',b'2005-2011 veteran deaths outside of combat by state',"b""![](https://i.imgur.com/Vrs6apv.png)\n\n### Context\n\nThere is a well-documented phenomenon of increased suicide rates among United States military veterans. One recent analysis, published in 2016, found the suicide rate amongst veterans to be around 20 per day. The widespread nature of the problem has resulted in efforts by and pressure on the United States military services to combat and address mental health issues in and after service in the country's armed forces.\n\nIn 2013 News21 published [a sequence of reports](https://backhome.news21.com/interactive/suicide-interactive/) on the phenomenon, aggregating and using data provided by individual states to typify the nationwide pattern. This dataset is the underlying data used in that report, as collected by the News21 team.\n\n### Content\n\nThe data consists of six files, one for each year between 2005 and 2011. Each year's worth of data includes the general population of each US state, a count of suicides, a count of state veterans, and a count of veteran suicides.\n\n### Acknowledgements\n\nThis data was originally published by News21. It has been converted from an XLS to a CSV format for publication on Kaggle. The original data, visualizations, and stories can be found [at the source](https://backhome.news21.com/interactive/suicide-interactive/).\n\n### Inspiration\n\nWhat is the geospatial pattern of veterans in the United States? How much more vulnerable is the average veteran to suicide than the average citizen? Is the problem increasing or decreasing over time?""","b""['mental health', 'military', 'small', 'featured']""",https://www.kaggle.com/residentmario/us-veteran-suicides
b'Stanford Open Policing Project - South Carolina',b'Data on Traffic and Pedestrian Stops by Police in South Carolina',"b""###Context: \n\nOn a typical day in the United States, police officers make more than 50,000 traffic stops. The Stanford Open Policing Project team is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public.\n\nIf you'd like to see data regarding other states, please go to https://www.kaggle.com/stanford-open-policing.\n\n### Content: \n\nThis dataset includes 1.7 gb of stop data from South Carolina, covering all of 2010 onwards. Please see the data readme for the full details of the available fields.\n\n###Acknowledgements:\n\nThis dataset was kindly made available by the [Stanford Open Policing Project][1]. If you use it for a research publication, please cite their [working paper][2]:\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, V. Ramachandran, C. Phillips, S. Goel. (2017) \xe2\x80\x9cA large-scale analysis of racial disparities in police stops across the United States\xe2\x80\x9d.\n\n###Inspiration: \n\n - How predictable are the stop rates? Are there times and places that\n   reliably generate stops?\n - Concerns have been raised about jurisdictions using civil forfeiture\n   as a funding mechanism rather than to properly fight drug\n   trafficking. Can you identify any jurisdictions that may be\n   exhibiting this behavior?\n\n  [1]: https://openpolicing.stanford.edu/\n  [2]: https://5harad.com/papers/traffic-stops.pdf""","b""['crime', 'law', 'government agencies', 'violence', 'large', 'featured']""",https://www.kaggle.com/stanford-open-policing/stanford-open-policing-project-south-carolina
b'NYS Political Consultant Filings: Beginning 2016',b'From New York State Open Data',"b""### Content  \n\nThis dataset contains Political Consultant Disclosure Statements and Correction Filings, as well as an agency-generated final records for each political consultant.  Each line contains the Political Consultant\xe2\x80\x99s name, business address and telephone as well as the public official/candidate and client names, business address, telephone number, the office held or sought by each public official/candidate where applicable and a brief description of the services provided to each.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Qc6vnbE4JQs) by [Jerry Kiesewetter](https://unsplash.com/@jerryinocmd) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-political-consultant-filings-beginning-2016
b'FiveThirtyEight Bob Ross Dataset',b'Explore Data from FiveThirtyEight',"b""### Content  \n\n# Bob Ross\n\nThis folder contains data behind the story [A Statistical Analysis of the Work of Bob Ross](https://fivethirtyeight.com/features/a-statistical-analysis-of-the-work-of-bob-ross/).\n  \n\n### Context  \n\nThis is a dataset from [FiveThirtyEight](https://fivethirtyeight.com/) hosted on their [GitHub](https://github.com/fivethirtyeight/data). Explore FiveThirtyEight data using Kaggle and all of the data sources available through the FiveThirtyEight [organization page](https://www.kaggle.com/fivethirtyeight)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using GitHub's [API](https://developer.github.com/v3/?) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) license.  \n\n[Cover photo](https://unsplash.com/photos/pCgQBi-wvTU) by [Alex Kotomanov](https://unsplash.com/@kotomanov) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['weather', 'climate', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/fivethirtyeight-bob-ross-dataset
b'Stanford Mass Shootings in America (MSA)',"b'A high quality dataset from 1966-2016 with method, definitions and references'","b'https://www.youtube.com/watch?v=A8syQeFtBKc\n\n\n----------\n\n\n# Context\n\nThe Stanford Mass Shootings in America (MSA) is a dataset released under [Creative Commons Attribution 4.0 international license](https://creativecommons.org/licenses/by/4.0/) by the Stanford Geospatial Center. While not an exhaustive collection of mass shootings, it is a high-quality dataset ranging from 1966 to 2016 with well-defined methodology, definitions and source URLs for user validation. \n\nThis dataset can be used to validate other datasets, such as [us-mass-shootings-last-50-years](https://www.kaggle.com/zusmani/us-mass-shootings-last-50-years), which contains more recent data, or conduct other analysis, as more information is provided. \n\n# Content\n\nThis dataset contains data by the MSA project both from it\'s [website](https://library.stanford.edu/projects/mass-shootings-america) and from it\'s [Github account](https://github.com/StanfordGeospatialCenter/MSA). The difference between the two sources is only on the data format (i.e. .csv versus .geojson for the data, or .csv versus .pdf for the dictionary).\n\n- **mass_shooting_events**_stanford_msa_release_06142016\n   - Contains a nonexaustive list of US Mass Shootings from 1966 to 2016 in both .csv and .geojson formats.\n- **dictionary**_stanford_msa_release_06142016\n   - Contains the data dictionary in .csv and .pdf formats. Note the .pdf format provides an easier way to visualize sub-fields.\n\n**Note the data was reproduced here without any modifications other than file renaming for clarity, the content is the same as in the source.**\n\nThe following sections are reproduced from the dataset creators [website](https://library.stanford.edu/projects/mass-shootings-america). For more details, please see the source.\n\n## Project background\n\nThe Stanford Mass Shootings of America (MSA) data project began in 2012, in reaction to the mass shooting in Sandy Hook, CT. In our initial attempts to map this phenomena it was determined that no comprehensive collection of these incidents existed online. The Stanford Geospatial Center set out to create, as best we could, a single point repository for as many mass shooting events as could be collected via online media. The result was the Stanford MSA.\n\n## What the Stanford MSA is\n\nThe Stanford MSA is a data aggregation effort. It is a curated set of spatial and temporal data about mass shootings in America, taken from online media sources. It is an attempt to facilitate research on gun violence in the US by making raw data more accessible.\n\n## What the Stanford MSA is not\n\nThe Stanford MSA is not a comprehensive, longitudinal research project. The data collected in the MSA are not investigated past the assessment for inclusion in the database. The MSA is not an attempt to answer specific questions about gun violence or gun laws.\n\nThe Stanford Geospatial Center does not provide analysis or commentary on the contents of this database or any derivatives produced with it.\n\n## Data collection methodology\n\nThe information collected for the Stanford MSA is limited to online resources. An initial intensive investigation was completed looking back over existing online reports to fill in the historic record going back to 1966. Contemporary records come in as new events occur and are cross referenced against a number of online reporting sources. In general a minimum of three corroborating sources are required to add the full record into the MSA (as many as 6 or 7 sources may have been consulted in many cases). All sources for each event are listed in the database.\n\nDue to the time involved in vetting the details of any new incident, there is often a 2 to 4 week lag between a mass shooting event and its inclusion in the public release database.\n\nIt is important to note the records in the Stanford MSA span a time from well before the advent of online media reporting, through its infancy, to the modern era of web based news and information resources. Researchers using this database need to be aware of the reporting bias these changes in technology present. A spike in incidents for recent years is likely due to increased online reporting and not necessarily indicative of the rate of mass shootings alone. Researchers should look at this database as a curated collection of quality checked data regarding mass shootings, and not an exhaustive research data set itself. Independent verification and analysis will be required to use this data in examining trends in mass shootings over time.\n\n## Definition of Mass Shooting\n\nThe definition of mass shooting used for the Stanford database is 3 or more shooting victims (not necessarily fatalities), not including the shooter. The shooting must not be identifiably gang, drug, or organized crime related.\n\n# Acknowledgements\n\nThe Stanford Mass Shootings in America (MSA) is a dataset released under [Creative Commons Attribution 4.0 international license](https://creativecommons.org/licenses/by/4.0/) by the Stanford Geospatial Center.\n\n## How to cite the MSA\n\nThe Stanford MSA is released under a Creative Commons Attribution 4.0 international license. Please cite the MSA as \xe2\x80\x9cStanford Mass Shootings in America, courtesy of the Stanford Geospatial Center and Stanford Libraries\xe2\x80\x9d.\n\n# Inspiration\n\nThere is already a great number of interesting datasets in Kaggle surrounding the subject of Mass Shootings, however, little has been done leveraging information from multiple sources. Can you see a story among them? Can we learn anything, for example, comparing the different sources by city or state? \n\n**From a bigger picture**\n\n - Leading Causes of Death in US: https://www.kaggle.com/cdc/mortality\n - Gun Violence Database:\n   https://www.kaggle.com/gunviolencearchive/gun-violence-database\n - Gun Deaths in US: https://www.kaggle.com/hakabuk/gun-deaths-in-the-us\n - Homicide Reports:\n   https://www.kaggle.com/murderaccountability/homicide-reports\n - Global Terrorism Database: https://www.kaggle.com/START-UMD/gtd\n - Crime Rates in America:\n   https://www.kaggle.com/marshallproject/crime-rates\n\n**""Prevention?**\n\n - Firearms Provisions in US States: https://www.kaggle.com/jboysen/state-firearms\n - Trial and Terror: https://www.kaggle.com/jboysen/trial-and-terror\n - Connecticut Inmates Waiting trial: https://www.kaggle.com/Connecticut-open-data/connecticut-inmates-awaiting-trial\n\n\n**Are there warning signs?**\n\n  - Mental Health in Tech Survey: https://www.kaggle.com/osmi/mental-health-in-tech-2016/data (Not directly related but can be used to make a parenthesis about mental health being an issue in our surroundings).\n'","b""['crime', 'united states', 'terrorism', 'violence', 'small', 'featured']""",https://www.kaggle.com/carlosparadis/stanford-msa
b'Chicago Relocated Vehicles',b'From City of Chicago Open Data',"b""### Content  \n\nThis dataset presents current and former locations of vehicles that have been relocated by the City of Chicago within the last 90 days. Vehicles may be relocated, but not impounded, due to inoperability, accident, severe weather, special events, construction or other work being performed in a thoroughfare where the vehicle was previously located.\r\n\r\nRelated Applications: Find Your Vehicle (http://j.mp/iZiX0B).  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/nw6xREmkXkg) by [Nicolai Berntsen](https://unsplash.com/@nicolaiberntsen) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'vehicles', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-relocated-vehicles
b'World of Warcraft Battlegrounds',b'Details of some battlegrounds in World of warcraft',"b'### Context\n\nWorld of Warcraft is a MMORPG ([massively multiplayer online role-playing game](https://en.wikipedia.org/wiki/Massively_multiplayer_online_role-playing_game)) video game created by Blizzard. It has a lot of content, but in this dataset we are just focusing in player vs player content.\n\nBattlegrounds are scenarios where the two playable factions of the game (Horde and Alliance) fight against each other to win. Some of them are capture the flag them, others are take control points them, some of them are gain resources them, and some of them are a mixture of several themes. Playing battlegrounds means a lot of fun, but you we will get a currency in game called ""Honor"", which can be traded for powerful gear of our characters. If you wish to know more about this, you can visit the [official website][1].\n\n### Content\n\nIn this dataset you will find five files with the statistics at the end of each battleground. Common statistics (columns) in all files are:\n\n- Code: code for the battleground (not needed for analysis).\n- Faction: faction of the player (Horde or Alliance).\n- Class: class of the player (warrior, paladin, hunter, rogue, priest, death knight, shaman, mage, warlock, monk, druid, demon hunter).\n- KB: number of mortal kills given by the player.\n- D: number of times that the player died.\n- HK: number of killings where the player or his/her group contributed.\n- DD: damage done by the player.\n- HD: healing done by the player.\n- Honor: honor awarded to the player.\n- Win: 1 if the player won.\n- Lose: 1 if the player lost.\n- Rol: dps if the player is a damage dealer; heal if the player is focused in healing allies. Note that not all classes can be healers, just shaman, paladin, priest, monk and druid, but all classes can be damage dealers.\n- BE: some weeks there is a bonus event, when the honor gained is increased. 1 if the battleground happened during that week.\n\nThese columns, plus the ""battleground"" column are in wowbgs.csv file. Battleground column represent the kind of battleground:\n- AB: Arathi basin.\n- BG: Battle for Gilneas.\n- DG: Deepwind gorge.\n- ES: Eye of the storm.\n- SA: Strand of the ancients.\n- SM: Silvershard mines.\n- SS: Seething shore.\n- TK: Temple of Kotmogu.\n- TP: Twin peaks.\n- WG: Warsong gulch.\n\nThe other files have statistics for just one kind of bg, and have additional columns:\n- wowgil.csv: statistics for Battle for Gilneas battleground. BA: number of bases assaulted by the player. BD: number of bases defended by the player.\n- wowsm.csv: statistics for Silvershard mines battleground. CC: number of carts controlled by the player.\n- wowtk.csv: statistics for Temple of Kotmogu battleground: OP: number of orb controlled by the player. VP: victory points earned by the player.\n- wowwg.csv: statistics for Warsong gulch battleground: FC: number of flag captured by the player. FR: number of flags defended by the player.\n\nIn Version 2, files are the same but with a ""2"" in the name. You can find 1657 aditional rows and one new battleground, called Seething shore (SS). Next version will come with the new expansion of the game, Battle for Azeroth (14-8-2018), where Strand of the Ancients battleground will be no longer available and damage and healing will be reduce for all players.\n\nTime is not important in this dataset, but the rows are ordered by the moment I collected the data, from March 2017 to January 2018. Players can improve their gear, so maybe there is a increasing factor in Damage done and Healing done over the time. \n\n### Acknowledgements\n\nAll data was collected by me playing battlegrounds, and the name of the players will remain anonymous. \n\n### Inspiration\n\nWith this dataset you can check which class is the lethalest, which one dies more often, which faction win more scenarios, how capturing one flag can affect the honor awarded, which class are the best at doing damage or healing, which classes have better combination in order to win each battleground and what is the chance of winning for every class, for example.\n\n [1]: https://worldofwarcraft.com/en-gb/'","b""['video games', 'future prediction', 'small', 'featured']""",https://www.kaggle.com/cblesa/world-of-warcraft-battlegrounds
b'BIXI Montreal (public bicycle sharing system)',"b""Data on North America's first large-scale bike sharing system""","b""### Context\n\xc2\xab **BIXI** Montr\xc3\xa9al is a public bicycle sharing system serving Montr\xc3\xa9al, Quebec, Canada.\n\nLaunched in May 2009, it is North America's first large-scale bike sharing system and the original BIXI brand of systems. \n\nThe location of a BIXI bike station is determined by several parameters, including population density, points of interest and activities (universities, bike paths, other transportation networks, and data on travel patterns of the general public. In 2009, 5,000 bikes were deployed in Montreal through a network of pay stations located mainly in the boroughs of Rosemont\xe2\x80\x93La Petite-Patrie, the Plateau-Mont-Royal and Ville-Marie, spilling over into parts of Outremont and the South West. As of 2011, the system has spread to Hochelaga-Maisonneuve, Villeray\xe2\x80\x93Saint-Michel\xe2\x80\x93Parc-Extension, Ahuntsic, C\xc3\xb4te-des-Neiges\xe2\x80\x93Notre-Dame-de-Gr\xc3\xa2ce, Westmount and Verdun. \xc2\xbb [1] \n\n\n### Content\n\n**1. BIXI - Movements history** \n\n- Datasets containing the details of the travels made via the BIXI Montr\xc3\xa9al self-service bike network. Each year is a .zip file (ex. BixiMontrealRentals2014.zip) containing several .CSV files (ex. OD_2014-04.csv) for each months. <br><br> **Version 2 : All .csv are merged per year (OD-year.csv).**  <br><br>\n\n- The data is extracted from the BIXI Montr\xc3\xa9al station and bike management system. Trips of less than 1 minute or more than 2 hours are excluded. The station identifiers used correspond to those of the station status data set\n\n***Data Sructure***\n\n- start_date: Date and time of the start of the trip ( AAAA-MM-JJ hh:mm )\n- start_station_code: Start station ID\n- end_date: Date and time of the start of the trip ( AAAA-MM-JJ hh:mm )\n- end_station_code : End station ID\n- is_member : Type users. (1 : Suscriber, 0 : Non-suscriber)\n- duration_sec: Total travel time in seconds\n<br><br>\n\n---\n**2. BIXI - The condition of stations**\n\n- This dataset presents the list of stations in the BIXI Montr\xc3\xa9al self-service bicycle network, including the geographic position, the number of bicycles available and the number of terminals available. It is a .json file, which corresponds to a dictionary. \n\n- The data is produced by the BIXI Montr\xc3\xa9al station management system with a refresh rate of 5 minutes. Station locations are generally stable over time, but may be subject to change during the season, particularly when the City of Montreal is carrying out work or as part of special events. Temporary storage stations are not included in station status. The data is automatically generated on the BIXI servers, so the date of last update of this dataset does not represent the actual date of update. Information about bikes and bad terminals is available in the JSON format file.\n\n***Data Sructure***\n\n- id: Unique station ID\n- s: Name of the station\n- n: Station terminal ID\n- st: Station status\n- b: Boolean value (true or false) specifying whether the station is blocked\n- su: Boolean value (true or false) specifying whether the station is suspended\n- m: Boolean value (true or false) specifying whether the station is displayed as out of service\n- read: timestamp of the last update of the data in milliseconds since January 1, 1970.\n- lc: timestamp of the last communication with the server in milliseconds since January 1, 1970.\n- bk: (For future use)\n- bl: (For future use)\n- la: latitude of the station according to the geodesic datum WGS84\n- lo: longitude of the station according to the WGS84 datum\n- da: Number of available terminals at this station\n- dx: Number of unavailable terminals at this station\n- ba: Number of available bikes at this station\n- bx: Number of unavailable bicycles at this station\n\n---\n**3. Geographical boundaries of Montreal (Borough and related city)**\n\n- This dataset is optional and will be useful mostly for ploting data and doing some choropleth maps. \n\n\n### Acknowledgements\n\nCreative Commons Attribution 4.0 International\n\nFor more details :\n<br>http://donnees.ville.montreal.qc.ca/dataset/bixi-historique-des-deplacements\n<br>http://donnees.ville.montreal.qc.ca/dataset/bixi-etat-des-stations\n<br>http://donnees.ville.montreal.qc.ca/dataset/polygones-arrondissements\n\n\n\n\n### Inspiration\n\nCan you find pattern in the behavior of Bixi users? <br>\nAre there any inefficient stations ? <br>\nWhat insights can we use from this data for decision making ? \n\n\n\n----------\n[1] https://en.wikipedia.org/wiki/BIXI_Montr%C3%A9al""","b""['road transport', 'cycling', 'medium', 'featured']""",https://www.kaggle.com/aubertsigouin/biximtl
"b'World Bank GNI Ranking, Atlas method and PPP based'",b'From World Bank Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](https://databank.worldbank.org/) and they update their information according the amount of data that is brought in. Explore the World Bank using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using the World Bank's [APIs](data.worldbank.org/developers) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/RN4w8LzsaqQ) by [Daniel Corneschi](https://unsplash.com/@corneschi) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['world', 'small', 'featured']""","https://www.kaggle.com/theworldbank/world-bank-gni-ranking,-atlas-method-and-ppp-based"
b'Crimes in Chicago',"b'An extensive dataset of crimes in Chicago (2001-2017), by City of Chicago'","b'# Context \n\nThis dataset reflects reported incidents of crime (with the exception of murders where data exists for each victim) that occurred in the City of Chicago from 2001 to present, minus the most recent seven days. Data is extracted from the Chicago Police Department\'s CLEAR (Citizen Law Enforcement Analysis and Reporting) system. In order to protect the privacy of crime victims, addresses are shown at the block level only and specific locations are not identified. Should you have questions about this dataset, you may contact the Research & Development Division of the Chicago Police Department at 312.745.6071 or RDAnalysis@chicagopolice.org. Disclaimer: These crimes may be based upon preliminary information supplied to the Police Department by the reporting parties that have not been verified. The preliminary crime classifications may be changed at a later date based upon additional investigation and there is always the possibility of mechanical or human error. Therefore, the Chicago Police Department does not guarantee (either expressed or implied) the accuracy, completeness, timeliness, or correct sequencing of the information and the information should not be used for comparison purposes over time. The Chicago Police Department will not be responsible for any error or omission, or for the use of, or the results obtained from the use of this information. All data visualizations on maps should be considered approximate and attempts to derive specific addresses are strictly prohibited. The Chicago Police Department is not responsible for the content of any off-site pages that are referenced by or that reference this web page other than an official City of Chicago or Chicago Police Department web page. The user specifically acknowledges that the Chicago Police Department is not responsible for any defamatory, offensive, misleading, or illegal conduct of other users, links, or third parties and that the risk of injury from the foregoing rests entirely with the user. The unauthorized use of the words ""Chicago Police Department,"" ""Chicago Police,"" or any colorable imitation of these words or the unauthorized use of the Chicago Police Department logo is unlawful. This web page does not, in any way, authorize such use. Data are updated daily. The dataset contains more than 6,000,000 records/rows of data and cannot be viewed in full in Microsoft Excel.  To access a list of Chicago Police Department - Illinois Uniform Crime Reporting (IUCR) codes, go to http://data.cityofchicago.org/Public-Safety/Chicago-Police-Department-Illinois-Uniform-Crime-R/c7ck-438e\n\n\n# Content\n\n**ID -** Unique identifier for the record.\n\n**Case Number -** The Chicago Police Department RD Number (Records Division Number), which is unique to the incident.\n\n**Date -** Date when the incident occurred. this is sometimes a best estimate.\n\n**Block -** The partially redacted address where the incident occurred, placing it on the same block as the actual address.\n\n**IUCR -** The Illinois Unifrom Crime Reporting code. This is directly linked to the Primary Type and Description. See the list of IUCR codes at https://data.cityofchicago.org/d/c7ck-438e.\n\n**Primary Type -** The primary description of the IUCR code.\n\n**Description -** The secondary description of the IUCR code, a subcategory of the primary description.\n\n**Location Description -** Description of the location where the incident occurred.\n\n**Arrest -** Indicates whether an arrest was made.\n\n**Domestic -** Indicates whether the incident was domestic-related as defined by the Illinois Domestic Violence Act.\n\n**Beat -** Indicates the beat where the incident occurred. A beat is the smallest police geographic area \xe2\x80\x93 each beat has a dedicated police beat car. Three to five beats make up a police sector, and three sectors make up a police district. The Chicago Police Department has 22 police districts. See the beats at https://data.cityofchicago.org/d/aerh-rz74.\n\n**District -** Indicates the police district where the incident occurred. See the districts at https://data.cityofchicago.org/d/fthy-xz3r.\n\n**Ward -** The ward (City Council district) where the incident occurred. See the wards at https://data.cityofchicago.org/d/sp34-6z76.\n\n**Community Area -** Indicates the community area where the incident occurred. Chicago has 77 community areas. See the community areas at https://data.cityofchicago.org/d/cauq-8yn6.\n\n**FBI Code -** Indicates the crime classification as outlined in the FBI\'s National Incident-Based Reporting System (NIBRS). See the Chicago Police Department listing of these classifications at http://gis.chicagopolice.org/clearmap_crime_sums/crime_types.html.\n\n**X Coordinate -** The x coordinate of the location where the incident occurred in State Plane Illinois East NAD 1983 projection. This location is shifted from the actual location for partial redaction but falls on the same block.\n\n**Y Coordinate -** The y coordinate of the location where the incident occurred in State Plane Illinois East NAD 1983 projection. This location is shifted from the actual location for partial redaction but falls on the same block.\n\n**Year -** Year the incident occurred.\n\n**Updated On -** Date and time the record was last updated.\n\n**Latitude -** The latitude of the location where the incident occurred. This location is shifted from the actual location for partial redaction but falls on the same block.\n\n**Longitude -** The longitude of the location where the incident occurred. This location is shifted from the actual location for partial redaction but falls on the same block.\n\n**Location -** The location where the incident occurred in a format that allows for creation of maps and other geographic operations on this data portal. This location is shifted from the actual location for partial redaction but falls on the same block.\n\n\n# Acknowledgements\n\nI really want to say thank you to the City of Chicago and the Chicago Police Department for making this comprehensive data set available to everyone! \n\n\n# Inspiration\n\nHow has crime changed over the years? Is it possible to predict where or when a crime will be committed? Which areas of the city have evolved over this time span?'","b""['crime', 'large', 'featured']""",https://www.kaggle.com/currie32/crimes-in-chicago
"b'Health searches by US Metropolitan Area, 2005-2017'",b'Data from Google trends showing who searches for what and where',"b""This is the Google Search interest data that powers the Visualisation [Searching For Health][1]. Google Trends data allows us to see what people are searching for at a very local level. This visualization tracks the top searches for common health issues in the United States, from Cancer to Diabetes, and compares them with the actual location of occurrences for those same health conditions to understand how search data reflects life for millions of Americans.\n\nHow does search interest for top health issues change over time? From 2004\xe2\x80\x932017, the data shows that search interest gradually increased over the past few years. Certain regions show a more significant increase in search interest than others. The increase in search activity is greatest in the Midwest and Northeast, while the changes are noticeably less dramatic in California, Texas, and Idaho. Are people generally becoming more aware of health conditions and health risks?\n\nThe search interest data was collected using the Google Trends API. The visualisation also brings in incidences of each condition so they can be compared. The health conditions were hand-selected from the Community Health Status Indicators (CHSI) which provides key indicators for local communities in the United States. The CHSI dataset includes more than 200 measures for each of the 3,141 United States counties. More information about the CHSI can be found on healthdata.gov. \n\nMany striking similarities exist between searches and actual conditions\xe2\x80\x94but the relationship between the Obesity and Diabetes maps stands out the most.\n\xe2\x80\x9cThere are many risk factors for type 2 diabetes such as age, race, pregnancy, stress, certain medications, genetics or family history, high cholesterol and obesity. However, the single best predictor of type 2 diabetes is overweight or obesity. Almost 90% of people living with type 2 diabetes are overweight or have obesity. People who are overweight or have obesity have added pressure on their body's ability to use insulin to properly control blood sugar levels, and are therefore more likely to develop diabetes.\xe2\x80\x9d \n\xe2\x80\x94Obesity Society via obesity.org\n\n\n  [1]: http://www.searching-for-health.com/""","b""['internet', 'healthcare', 'health', 'journalism', 'diseases', 'small', 'featured']""",https://www.kaggle.com/GoogleNewsLab/health-searches-us-county
b'BRFSS 2001-2010',b'Behavioral Risk Factor Surveillance System for 2001-2010',"b""The objective of the BRFSS is to collect uniform, state-specific data on preventive health practices and risk\nbehaviors that are linked to chronic diseases, injuries, and preventable infectious diseases in the adult population.\nFactors assessed by the BRFSS include tobacco use, health care coverage, HIV/AIDS knowledge or prevention,\nphysical activity, and fruit and vegetable consumption. Data are collected from a random sample of adults (one per\nhousehold) through a telephone survey.\n\nThe Behavioral Risk Factor Surveillance System (BRFSS) is the nation's premier system of health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. Established in 1984 with 15 states, BRFSS now collects data in all 50 states as well as the District of Columbia and three U.S. territories. BRFSS completes more than 400,000 adult interviews each year, making it the largest continuously conducted health survey system in the world.\n\n### Content\n\n - Each year contains a few hundred columns. Please see one of the\n   [annual code books][1] for complete details.\n - These CSV files were converted from a SAS data format using pandas; there may be some data artifacts as a result.\n - If you like this data, you might also enjoy [the 2011-2015 batch][2]. Please note that those years use a different format.\n\n### Acknowledgements\n\nThis dataset was released by the CDC. You can find the original dataset, manuals, and [additional years of data here][3].\n\n\n  [1]: https://www.cdc.gov/brfss/annual_data/2001/pdf/codebook_01.pdf\n  [2]: https://www.kaggle.com/cdc/behavioral-risk-factor-surveillance-system\n  [3]: https://www.cdc.gov/brfss/annual_data/annual_data.htm""","b""['public health', 'mental health', 'large', 'featured']""",https://www.kaggle.com/cdc/brfss-20012010
b'Old Newspapers',b'A cleaned subset of HC Corpora newspapers',"b'### Context\n\nThe [HC Corpora](https://web.archive.org/web/20161021044006/http://corpora.heliohost.org/) was a great resource that contains natural language text from various newspapers, social media posts and blog pages in multiple languages. This is a cleaned version of the raw data from newspaper subset of the HC corpus. \n\nOriginally, this subset was created for a [language identification task for similar languages](http://corporavm.uni-koeln.de/vardial/sharedtask.html)\n\n### Content\n\nThe columns of each row in the `.tsv` file are:\n\n - **Langauge**: Language of the text.\n - **Source**: Newspaper from which the text is from.\n - **Date**: Date of the article that contains the text.\n - **Text**: Sentence/paragraph from the newspaper\n\nThe corpus contains 16,806,041 sentences/paragraphs in 67 languages:\n\n - Afrikaans\n - Albanian\n - Amharic\n - Arabic\n - Armenian\n - Azerbaijan\n - Bengali\n - Bosnian\n - Catalan\n - Chinese (Simplified)\n - Chinese (Traditional)\n - Croatian\n - Welsh\n - Czech\n - German\n - Danish\n - Danish\n - English\n - Spanish\n - Spanish (South America)\n - Finnish\n - French\n - Georgian\n - Galician\n - Greek\n - Hebrew\n - Hindi\n - Hungarian\n - Icelandic\n - Indonesian\n - Italian\n - Japanese\n - Khmer\n - Kannada\n - Korean\n - Kazakh\n - Lithuanian\n - Latvian\n - Macedonian\n - Malayalam\n - Mongolian\n - Malay\n - Nepali\n - Dutch\n - Norwegian (Bokmal)\n - Punjabi\n - Farsi\n - Polish\n - Portuguese (Brazil)\n - Portuguese (EU)\n - Romanian\n - Russian\n - Serbian\n - Sinhalese\n - Slovak\n - Slovenian\n - Swahili\n - Swedish\n - Tamil\n - Telugu\n - Tagalog\n - Thai\n - Turkish\n - Ukranian\n - Urdu\n - Uzbek\n - Vietnamese\n\nLanguages in HC Corpora but not in this (yet):\n\n - Estonian\n - Greenlandic\n - Gujarati \n\n### Acknowledge\n\nAll credits goes to Hans Christensen, the creator of HC Corpora.\n\nDataset image is from [Philip Strong](https://unsplash.com/search/photos/newspaper?photo=gZaj16Ztu2Y).\n\n\n### Inspire\n\nUse this dataset to:\n\n - create a language identifier / detector\n - exploratory corpus linguistics (It\xe2\x80\x99s one capstone project from [Coursera\xe2\x80\x99s data science specialization](https://www.coursera.org/learn/data-science-project) )'","b""['internet', 'linguistics', 'history', 'news agencies', 'large', 'featured']""",https://www.kaggle.com/alvations/old-newspapers
b'CartolaFC',b'Data from the popular Brazilian Fantasy Football (2014 to 2017) \xe2\x9a\xbd\xef\xb8\x8f',"b'### Context\n\nCartolaFC is the most popular fantasy football in Brazil. Before each round of the Brazilian Football League, players choose which athletes they want for their teams, and they score points based on their real-life performances. \n\n\n### Content\n\nData is divided in 7 kinds of files:\n\n\n**Athletes (atletas)**\n\n- ""atleta_id"": id,\n\n- ""nome"": athlete\'s full name,\n\n- ""apelido"": athlete\'s nickname\n\n\n**Clubs (clubes)**\n\n- ""id"": id,\n\n- ""nome"": club\'s name,\n\n- ""abreviacao"": name abbreviation,\n\n- ""slug"": used for some API calls\n\n\n\n**Matches (partidas)**\n\n- ""rodada_id"": current round,\n\n- ""clube_casa_id"": home team id,\n\n- ""clube_visitante_id"": away team id,\n\n- ""clube_casa_posicao"": home team\'s position on the league,\n\n- ""clube_visitante_posicao"": away team\'s position on the league,\n\n- ""aproveitamento_mandante"": home team\'s outcome on the last five matches (d: loss, e: draw, v: victory),\n\n- ""aproveitamento_visitante"": away team\'s outcome on the last five matches (d: loss, e: draw, v: victory),\n\n- ""placar_oficial_mandante"": home team\'s score,\n\n- ""placar_oficial_visitante"": away team\'s score,\n\n- ""partida_data"": match date,\n\n- ""local"": stadium,\n\n- ""valida"": match valid for scoring\n\n\n\n**Scouts**\n\n- ""atleta_id"": reference to athlete,\n\n- ""rodada_id"": current round,\n\n- ""clube_id"": reference to club,\n\n- ""posicao_id"": reference to position,\n\n- ""status_id"": reference to status,\n\n- ""pontos_num"": points scored on current round,\n\n- ""preco_num"": current price,\n\n- ""variacao_num"": price variation from previous round,\n\n- ""media_num"": average points per played round,\n\n- ""jogos_num"": number of matches played,\n\n- ""FS"": suffered fouls,\n\n- ""PE"": missed passes,\n\n- ""A"": assistances,\n\n- ""FT"": shots on the post,\n\n- ""FD"": defended shots,\n\n- ""FF"": shots off target,\n\n- ""G"": goals,\n\n- ""I"": offsides,\n\n- ""PP"": missed penalties,\n\n- ""RB"": successful tackes,\n\n- ""FC"": fouls commited,\n\n- ""GC"": own goals,\n\n- ""CA"": yellow cards,\n\n- ""CV"": red cards,\n\n- ""SG"": clean sheets (only defenders),\n\n- ""DD"": difficult defenses (only goalies),\n\n- ""DP"": defended penalties (only goalies),\n\n- ""GS"": suffered goals (only goalies)\n\n\n\n**Positions (posicoes)**\n\n- ""id"": id,\n\n- ""nome"": name,\n\n- ""abreviacao"": abbreviation\n\n\n\n**Status**\n\n- ""id"": id,\n\n- ""nome"": name\n\n\n\n**Points (pontuacao)**\n\n- ""abreviacao"": abbreviation,\n\n- ""nome"": name,\n\n- ""pontuacao"": points earned for respective scout\n\n\n\n### Acknowledgements\n\nThe datasets from 2014 to 2016 were taken from here: https://github.com/thevtm/CartolaFCDados.\n\nData from 2017 until round 11 was taken from this repo: https://github.com/henriquepgomide/caRtola.\n\nFrom 2017 round 12 and on, I\'ve been extracting the data from CartolaFC\'s API (which is not officially public).\n\n\n\n### Inspiration\n\nIt would be interesting to see analyses on which factors make an athlete or team more likely to score points, and also predictive models for future scores.'","b""['sports', 'association football', 'brazil', 'small', 'featured']""",https://www.kaggle.com/schiller/cartolafc
b'Daily Happiness & Employee Turnover',b'Is There a Relationship Between Employee Happiness and Job Turnover?',"b'![enter image description here][4]\n![enter image description here][5]\n\n\n### Can Happiness Predict Employee Turnover, or is it the Other Way Around?\nIt is the summer of 2016. I am in Barcelona and it is hot and humid. By chance I go to a talk where  Alex Rios - the ceo of myhappyforce.com explains his product. He has built an app where employees report daily happiness levels at work. This app is used by companies to track happiness of the workforce. After the talk I ask him if he would opensource the (anonymized data) so we can better understad the phenomenon of employee turnover. Here is what we did, we developed a model that predicts which employees will churn. Then we looked at the features (used by the model) that are common to employees that churn. The top feautures of employees that churn are:\n\n- low ratio of likes received (likeability)\n- low posting frequency (engagement), \n- low relative happiness (employee happiness normalized by company mean). \n\nSurprisingly, a priori expected explanatory features such as mean happiness level and the ratio of likes (positivity), were not significant. Precision@50 = 80% out of a test set with 116 churns, sample size N=2k. Another surprise was that raw happiness is a bad predictor of churn. But, the question is, What did we miss? Can you find more insights?\n### Starter script\nR starter script https://www.kaggle.com/harriken/how-many-unlikes-it-takes-to-get-fired\n\n\n### Content\nThe data consists of four tables: votes, comments, interactions and churn. A vote was obtained when an employee opened the app and answered the question: How happy are you at work today? To vote the employee indicates their feeling by touching one of four icons that appeared on the screen. After the employee indicates their happiness level, a second screen appears where they can input a text explanation (usually a complaint, suggestion or comment), this is the comments table. Out of 4,356 employees, 2,638 employees commented at least once. Finally, in a third screen the employee can see their peers\xe2\x80\x99 comments and like or dislike them, this data is stored in the interactions table. 3,516 employees liked or disliked at least one of their peers\xe2\x80\x99 comments. The churn table contains when an employee churned (quit or was fired).\n\n\n### Acknowledgements\n\n- Python script version with social graph features: http://bit.ly/2v2sEZg\n- More detailed R scripts: https://github.com/orioli/e3\n- The [paper][2] which was presented at [ASONAM][3] 2017 Sydney\n- Slides https://www.slideshare.net/harriken/ieee-happiness-an-inside-job-asoman-2017\n\n### Inspiration\n\nThe cost of employee turnover has been pointed out extensively in the literature. A high turnover rate not only increases human resource costs, which can reach up to 150% of the annual salary per replaced employee, but it also has social costs, as it is correlated with lower wages, lower productivity per employee, and not surprisingly, a less loyal workforce [1]. For reference, in 2006, turnover at Walmart\xe2\x80\x99s Sam\xe2\x80\x99s Club was 44% with an average hourly pay of $10.11, while at Costco it was a much lower 17% with a higher $17.0 hourly wage [2]. In addition, a more recent study correlated companies with low turnover with a series of socially positive characteristics dubbed high-involvement work practices [3]. On the other hand, research on employee turnover (churn) is not a prolific topic in the engineering community. In IEEE publications, one can find just over 278 publications with titles containing the keyword churn, and the bulk of those focus on customer churn, and specifically churn in the telecommunications industry, while on the topic of employee churn there is just one title indexed [4]. ***The goal is to clarify the characteristics of employees that will churn (or that are at risk of churning), to help companies understand the causes so they can reduce the turnover rate***. \n\n\n  [1]: https://2.bp.blogspot.com/-Y6Q_Q2oovXc/WeYX63w_DUI/AAAAAAAACpE/qTzUqLYVPyks5HWS4qIq0ErAwDiRbdskQCLcBGAs/s1600/Screen%2BShot%2B2017-10-17%2Bat%2B6.44.41%2BPM.png\n  [2]: https://www.dropbox.com/s/g4qz7c3bccu8z41/ASONAM_BERENGUERES_55.pdf?dl=0\n  [3]: http://asonam.cpsc.ucalgary.ca/2017/\n  [4]: https://3.bp.blogspot.com/-QRTDK8rDq08/WeYX8Pih1zI/AAAAAAAACpI/wa_rSEOoJT4xFmr-_5sIf2JCjVtOo_D9QCLcBGAs/s1600/Screen%2BShot%2B2017-10-17%2Bat%2B6.45.17%2BPM.png\n   [5]: https://2.bp.blogspot.com/-Y6Q_Q2oovXc/WeYX63w_DUI/AAAAAAAACpE/qTzUqLYVPyks5HWS4qIq0ErAwDiRbdskQCLcBGAs/s1600/Screen%2BShot%2B2017-10-17%2Bat%2B6.44.41%2BPM.png\n\n'","b""['economics', 'medium', 'featured']""",https://www.kaggle.com/harriken/employeeturnover
b'Contributions to Financial Intermediary Funds',b'From World Bank Financial Open Data',"b""### Content  \n\nFinancial Intermediary Funds (FIFs) are multilateral financing arrangements for which the World Bank provides Trustee services that include committing and transferring funds to project       implementers (generally international organizations such as multilateral development banks or UN agencies).  In all cases the World Bank as Trustee is required to act in accordance with instructions of independent governing bodies.\r\n\r\nIn fulfilling its responsibilities, the World Bank as Trustee complies with all sanctions applicable to  World Bank transactions.\r\n\r\n\r\nThe innovative financing and governance arrangements of FIFs enable funds to be raised from multiple sources, including from sovereign and private sources. FIF structures are customizable. For instance FIFs have been customized to receive contributions in the form of concessional loans in addition to traditional grant funds, and can provide funding to recipients using customized financial products.\r\n\r\nData is provided as of 12/31/2013. No further updates are planned for this particular dataset.  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](finances.worldbank.org) and they update their information according the amount of data that is brought in. Explore World Bank's Financial Data using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.\n\nThis dataset is distributed under a [Creative Commons Attribution 3.0 IGO](https://creativecommons.org/licenses/by/3.0/igo/) license.  \n\n[Cover photo](https://unsplash.com/photos/wVMBn5sPQt0) by [Jared Erondu](https://unsplash.com/@erondu) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under Creative Commons Attribution 3.0 IGO""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/theworldbank/contributions-to-financial-intermediary-funds
b'SF Community Resiliency Indicator System',b'From San Francisco Open Data',"b""### Content  \n\nThe Community Resiliency Indicator System was developed by  San Francisco's Climate and Health Program and is part of San Francisco's Climate and Health Profile. The system includes 40 indicators and an additive index which is a compilation of all of the indicators. See attached methods and project description documents for more details, you can also visit San Francisco's Climate and Health Profile website - www.sfclimatehealth.org (available Feb-2015)  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/apz-nFR0NlQ) by [Jens Johnsson](https://unsplash.com/@jens_johnsson) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-community-resiliency-indicator-system
b'United States Trademark Applications',b'Information on individual trademark applications',"b'### Context: \n\nThis dataset contains pending and registered trademark text data (no drawings/images) to include word mark, serial number, registration number, filing date, registration date, goods and services, classification number(s), status code(s), design search code(s), pseudo mark(s) from the April 7, 1884 - Present. The file format .json, converted from eXtensible Markup Language (XML) in accordance with the [U.S. Trademark Applications Version 2.0 Document Type Definition (DTD)](https://www.uspto.gov/sites/default/files/products/applications-documentation.pdf). \n\n### Content: \n\nThis dataset is made up of one .json file with the following fields. (Note that the documentation was written for an XML file, which was subsequently converted into .json). The following is a description of some of the fields; full documentation can be found in the applications-documentation.pdf file.\n\n* The **trademark-applications-daily** element is mandatory and will occur one time identifying the beginning of a daily application process. The trademark applications daily element will contain one occurrence of the version and data processed indicator elements, and zero or more occurrences of the file segments element between the **trademark-applications-daily** start and **trademark-applications-daily** end tags.\n* The **version** element is mandatory and will occur one time between the **version** start and **version** end tags identifying the version number and version date of the Trademark Applications DTD. The version element will contain one occurrence of the version number and version date elements.\n* The **version-no** element is mandatory and will occur one time between the **version-no** start and **version-no** end tags containing the version number of the Trademark Applications DTD. Example: the first production version will be 1.0\n* The **version-date** element is mandatory and will occur one time between the **version-date** start and **version-date** end tags containing the date of the Trademark Applications DTD, an 8-position numeric in the format YYYYMMDD.\n\n**Application Information Section**\n\n* The **application-information** element is optional and will occur zero or one times between the **application-information** start and **application-information** end tags containing the daily trademark applications data.\n* The **data-available-code** element is optional and will occur zero or one times when trademark data is NOT present. The **data-available-code** start tag and the **data-available-code** end tag will be present and contain a one-position \xe2\x80\x9cN\xe2\x80\x9d indicating that trademark data is Not present. This element will not be present when data is available.\n* The **file-segments** element is optional and will occur zero or more times between the **file-segments** start and **file- segments** end tags identifying the beginning of the Trademark Applications file. The **file-segments** element will contain zero or more occurrences of the file segment and action keys elements.\n* The **file-segment** element is optional and will occur zero or more times between the **file-segment** start and **file-segment** end tags containing the File Segment text data, a four-position alphabetic field identifying the type of data in the Trademark Daily XML Process. The Trademark Applications **file-segment** will always have a constant of \xe2\x80\x9cTRMK\xe2\x80\x9d. The\xe2\x80\x9dTRMK\xe2\x80\x9d file segment contains new trademark data and modifications made to existing Trademark data.\n* The **action-keys** element is optional and will occur zero or more times between the **action-keys** start and **action-keys** end tags. The action keys element will contain zero or more occurrences of the action key and case file elements.\n* The **action-key** element is optional and will occur zero or more times between the **action-key** start and **action-key** end tags containing the KEY ACTION, a two-position alphanumeric field. The contents of the action key will be one of the following values for marks appearing in the Trademark Official Gazette (OG).\n\n**Case file section**\n\nThe **Case file section** and **case-file** end tags containing the following elements in the sequence as follows:\n\n* The **serial-number** element is mandatory and will occur one time between the **serial-number** start and **serial-number** end tags containing the SERIAL NUMBER, an eight-position numeric field consisting of the following:\n    * **Serial number**\n        * Position 1-2 will contain a series code:\n        * SERIES CODE, FILING DATE\n        * 70, 1881 \xe2\x80\x93 03/31/05\n        * 71, 04/01/05 \xe2\x80\x93 12/31/55\n        * 72, 01/01/56 \xe2\x80\x93 08/31/73\n        * 73, 09/01/73 \xe2\x80\x93 11/15/89\n        * 74, 11/16/89 \xe2\x80\x93 09/30/95\n        * 75, 10/01/95 \xe2\x80\x93 03/19/2000\n        * 76, 03/20/2000 \xe2\x80\x93 Present - (76 - Will be used for all paper filed applications.)\n        * 78, 03/20/2000 \xe2\x80\x93 Present - (78 - Will be used for electronically filed (e-TEAS) applications.)\n        * Position 3-8 will be a six-position serial number right justified with leading zeros.\n  * NOTE: When the **serial-number** begins with 80, 81 or 82, the actual serial number is unknown and the serial number is created by placing an \xe2\x80\x9c8\xe2\x80\x9d before the seven-digit registration number. If the registration number is less than seven digits in length, it is preceded by zeros.\n  * When the **serial-number** begins with 89, non-registration data consists of information entered in the database because of treaty obligations, U.S. Statutes, or other requirements.\n* The **registration-number** element is optional and will occur zero or one times between the **registration-number** start and **registration-number** end tags containing the REGISTRATION NUMBER, a seven-position numeric field right justified with leading zeros. NOTE: If a mark does not contain a registration number, the **registration number** element will contain zeros.\n* The **transaction-date** element is optional and will occur zero or one times between the **transaction-date** start and **transaction-date** end tags containing the TRANSACTION DATE, an eight position date in the format YYYYMMDD. The transaction date is the date of the Trademark Daily XML Process for Action Key entries.\n\n**Case File Header Section** \n\n* The **case-file-header** element is optional and occurs zero or one times between the **case-file-header** start and **case-file-header** end tags identifying the first record sequence of a trademark application document, which contains the equivalent of a TWTF/GENX record. Each case file header element will contain the following optional elements. NOTE: Any of the following elements that do not have the required date will contain zeros.\n* The **filing-date** element is optional and occurs zero or one times between the **filing-date** start and **filing-date** end tags containing the FILING DATE, an eight position date in the format YYYYMMDD, which is the date on which a statutorily complete trademark application is filed at the USPTO.\n* The **registration date** element is optional and occurs zero or one times between the **registration-date** start and **registration-date** end tags containing the REGISTRATION DATE, an eight-position date in the format YYYYMMDD that identifies the date the mark was registered.\n* The **status-code** element is optional and occurs zero or one times between the **status-code** start and **status-code** end tags containing the STATUS CODE, a three position numeric field which identifies the status of the mark.\n   * The status codes can be found in the trademark-status-codes file.\n* The **status-date** element is optional and occurs zero or one times between the **status-date** start and **status-date** end tags containing the STATUS DATE, an eight-position date in the format YYYYMMDD, which is the date on which the current status was reported to the system.\n* The **mark-identification** element is optional and occurs zero or one times between the **mark-identification** start and **mark-identification** end tags containing the MARK-1-LIN, a variable length alphanumeric field containing the characters of the actual mark.\n* The **mark-drawing-code** element is optional and occurs zero or one times between the **mark-drawing-code** start and **mark-drawing-code** end tags containing the MARK DRAWING CODE, a four-position alphanumeric field. The first position identifies the physical characteristics of the mark.\n* The **published-for-opposition-date** element is optional and occurs zero or one times between the **published-for-opposition-date** start and **published-for-opposition-date** end tags containing the DATE PUBLISHED FOR OPPOSITION, an eight-position date in the format YYYYMMDD, which is the date that the mark published for opposition in the Official Gazette.\n* The **amend-to-register-date** element is optional and occurs zero or one times between the **amend-to-register-date** start and **amend-to-register** end tags containing the AMENDED TO REGISTER DATE, an eight-position date in the format of YYYYMMDD. This element contains the date on which a case is entered as an amendment to a register.\n* The **abandonment-date** element is optional and occurs zero or one times between the **abandonment-date** start and **abandonment-date** end tags containing the DATE ABANDONED, an eight-position date in the format YYYYMMDD, which is the date that the mark is abandoned.\n* The **cancellation-code** element is a optional and occurs zero or one times between the **cancellation-code** start and **cancellation-code** end tags containing the CANCELLATION CODE, a one-position alphanumeric which identifies the section of the statute under which an entire registration is being cancelled or under which some classes in a multiple class registration are being cancelled.\n    * CC, Definition\n    * 0, No entry\n    * 1, Section 7(d) Entire Registration\n    * 2, Section 8 Entire Registration\n    * 3, Section 18 Entire Registration\n    * 4, Section 24 Entire Registration\n    * 5, Section 37 Entire Registration\n    * 6, Entire Registration inadvertently Issued\n    * 7, Inadvertently issued-entire Registration restored to pendency\n    * A, Section 7 (d ) - Class(es) in multiple class Registration\n    * B, Section 8 - Class(es) in multiple class Registration\n    * C, Section 18 - Class(es) in multiple class Registration\n    * D, Section 24 - Class(es) in multiple class Registration\n    * E, Section 37 - Class(es) in multiple class Registration\n* The **cancellation-date** element is optional and occurs zero or one times between the **cancellation-date** start and **cancellation-date** end tags containing the CANCELLATION DATE, an eight-position date in the format YYYYMMDD, which is the date that the cancellation of the entire registration was recorded.\n* The **republished 12c-date** element is optional and occurs zero or one times between the **republished-12c-date** start and **republished-12c-date** end tags containing the DATE PUBLISHED UNDER SECTION 12(C), an eight-position date in the format YYYYMMDD, which is the date of publication under Section 12(c).\n* The **domestic-representative-name** element is optional and occurs zero or one times between the **domestic-representative-name** start and **domestic-representative-name** end tags and contains the DOMESTIC REPRESENTATIVE information for the application.\n* The **attorney-docket-number** element is optional and occurs zero or one times between the **attorney-docket-number** start and **attorney-docket-number** end tags containing the ATTORNEY DOCKET NUMBER, a twelve-position number containing the reference or identification number of a case as assigned and used in the office of the attorney filing the application.\n* The **attorney-name** element is optional and occurs zero or one times between the **attorney-name** start and **attorney-name** end tags and contains the ATTORNEY information from the OWNX record.\n* The **principal-register-amended-indicator** element is optional and occurs zero or one times between the **principal-register-amended-in** start and **principal-register-amended-in** end tags containing the FLAG AMENDED TO THE PRINCIPAL REGISTER, a one-position alphabetic indicating the register has been amended for an application on the Supplemental Register. A \xe2\x80\x9cT\xe2\x80\x9d in this field indicates an amendment to the Principal Register. An \xe2\x80\x9cF\xe2\x80\x9d in this field indicates no amendment to the Principal Register.\n* The **supplemental-register-amended-indicator** element is optional and occurs zero or one times between the **supplemental-register-amended-in** start and **supplemental-register-amended-in** end tags containing the FLAG AMENDED TO THE SUPPLEMENTAL REGISTER, a one-position field indicating the register has been amended for an application on the Principal Register. A \xe2\x80\x9cT\xe2\x80\x9d in this field indicates an amendment to the Supplemental Register. An \xe2\x80\x9cF\xe2\x80\x9d in this field indicates no amendment to the supplemental Register.\n\n**Prior Registration Applications Section**\n\n* The **prior-registration-applications** element is optional and occurs zero or one times between the **prior-registration-applications** start and **prior-registration-applications** end tags, which contains the equivalent of all TWTF/PRUS records. Each prior registration applications element will contain the optional other related in and prior registration application elements.\n* The **other-related-indicator** element is optional and occurs zero or more times between the **other-related-in** start and **other-related-in** end tags containing the AND OTHERS, a one-position alphabetic field. A \xe2\x80\x9cT\xe2\x80\x9d in this field would indicate that the words \xe2\x80\x9cand others\xe2\x80\x9d appears in conjunction with a list of prior registrations that are claimed as being related to this mark. An \xe2\x80\x9cF\xe2\x80\x9d would indicate that the statement is not present.\n\n\n### Acknowledgements: \n\nThis dataset is provided by the United States Government and is in the public domain. Daily uploads of this dataset are available online [here](https://bulkdata.uspto.gov/). '","b""['united states', 'government agencies', 'product', 'medium', 'featured']""",https://www.kaggle.com/rtatman/trademark-application
b'Numeral Gestures recorded on iOS',b'The numbers 0-9 drawn by 257 people',"b'### Context\nThis dataset was recorded as part of an investigation into machine learning algorithms for iOS. 20,136 glyphs were drawn by 257 subjects on the touch screen of an iPhone 6.\n\nAn iOS app was developed to record the dataset. Firstly, subjects entered their age, sex, nationality and handedness. Each subject was then instructed to draw the digits 0 to 9 on the touchscreen using their index finger and thumb. This was repeated four times for each subject resulting in 80 glyphs drawn per subject, 40 using index finger and 40 using thumb. The sequence of glyph entry was random. Instructions to the user were provided using voice synthesis to avoid suggesting a specific glyph rendering. \n\nThe index finger and thumb were both used to account for situations in which the subject may only have one hand free. The aim here was to train a model that could accurately classify the glyph drawn in as many real life scenarios as possible. \n\nCubic interpolation of touches during gesture input was rendered on the screen to provide visual feedback to the subject and to compute arclengths. The screen was initially blank (white) and the gestures were displayed in black. \nThe subject could use most of screen to draw with small areas at the top and bottom reserved for instructions/interactions/guidance.\nThe subject was permitted to erase and repeat the entry, if desired.\n\n### Content\n\n![Database Schema][1]\n\nThe database consists of 4 tables as seen in the schema. The tables are Subject, Glyph, Stroke and Touch. This is a logical structure as each subject draws 80 glyphs, each glyph consists of a number of strokes and each stroke consists of a number of touches. The four tables are presented in csv format and sqlite format. \n\nNote that, in the files below, all columns start with a capital Z. This is automatically prepended to column names by Core Data, apples database framework. Column names which start with Z_ were automatically created by Core Data and hence, do not appear in the schema above.\n\nThe tables are connected through the first column in each table (Z_PK). This primary key links to the relevant column name in the next table. For example,  the subject that entered any given glyph can be found by taking the value from the ZSUBJECT column in the glyph table and finding the matching Z_PK value in the subject table.\n\n### Some questions to get you started...\n\n* What is the best model for classifying glyphs?\n* What is the best model for classifying sequences of these glyphs?\n* What is the best model to predict what number a glyph is before completion?\n* How much of the glyph needs to be completed before a prediction can be made?\n* What is the best method for interpolating between the touches in the dataset?\n* How can a trained model be integrated into iOS apps?\n\n### CITATION REQUEST\n\nPlease cite the following paper in any publications reporting on use of this dataset:\n\nPhilip J. Corr, Guenole C. Silvestre, Chris J. Bleakley\nOpen Source Dataset and Deep Learning Models for Online Digit Gesture Recognition on Touchscreens\nIrish Machine Vision and Image Processing Conference (IMVIP) 2017\nMaynooth, Ireland, 30 August-1 September 2017\nhttp://arxiv.org/abs/1709.06871\n\n  [1]: https://raw.githubusercontent.com/PhilipCorr/numeral-gesture-dataset/master/database.png'","b""['medium', 'featured']""",https://www.kaggle.com/corrphilip/numeral-gestures
b'Kwici Welsh Wikipedia Corpus',b'A 4 million word corpus of contemporary Welsh',"b'### Content: \n\nKwici is a 4m-word corpus drawn from the Welsh Wikipedia as it was on 30 December 2013. \n\nThe final pages and articles dump for 2013 was downloaded from the Wikimedia dump page. The WikiExtractor tool written by Giuseppe Attardi and Antonio Fuschetto was then used to extract plain text (discarding markup etc) from the 165Mb dump, resulting in a 33Mb output file. This was tidied by removing remaining XML, blank lines, and blocks of English text.\n\nThe text was then split to give into a total of 360,477 sentences, and these were imported into a PostgreSQL database table. The sentences were pruned by removing all items\n less than 50 characters long, all items containing numbers only (eg timelines), and all duplicates, to give a final total of 204,789 sentences in the corpus. \n\nThe file contains the following fields:\n\n* id: unique identifier for the sentence;\n* welsh: the sentence in Welsh;\n* word_w: the number of words in the Welsh sentence.\n\n### Acknowledgements: \n\nThis dictionary was created by  Kevin Donnell. If using Kwici in research, please use the following citation\n\nKevin Donnelly (2014). ""Kwici: a 4m-word corpus drawn from the Welsh Wikipedia."" http://cymraeg.org.uk/kwici. (BibTeX)\n\n### Inspiration: \n\n* Can you use this corpus to add frequency information to [this Welsh dictionary](https://www.kaggle.com/rtatman/eurfa-welsh-dictionary)?\n* Can you use this corpus to create a stemmer for Welsh?'","b""['linguistics', 'europe', 'languages', 'medium', 'featured']""",https://www.kaggle.com/rtatman/kwici-welsh-wikipedia-corpus
b'Dengue Cases in the Philippines',"b'Monthly and Regional Cases of Dengue per 100,000 Population from 2008 to 2016'","b'### Context\n\nData set contains the recorded number of dengue cases per 100,000 population per region of the Philippines from 2008 to 2016\n\n\n### Content\n\nThis is a small data set that is a good starting point for beginners that wants to play around with small scale temporal and spatial data set \n\n\n### Acknowledgements\n\nPublisher would like to thank the Department of Health of the Philippines for providing the raw data\n\n\n### Inspiration\n\nWhat is the trend of dengue cases in the Philippines?\nWhat region/s recorded the highest prevalence of dengue cases?\nIn what specific years do we observe the highest dengue cases?\nWhen and where will a possible dengue outbreak occur?'","b""['healthcare', 'demographics', 'public health', 'diseases', 'small', 'featured']""",https://www.kaggle.com/grosvenpaul/dengue-cases-in-the-philippines
b'Alcohol and Drug Consumption of German Teens',b'Do modern teens prefer weed over cigarettes?',"b""### Context\n\nThe data was collected by social science research institutes:\n\n1973 bis 1993: Institut f\xc3\xbcr Jugendforschung GmbH (IJF), M\xc3\xbcnchen;\n1997: GfM-GETAS/WBA GmbH, Hamburg\n2001 bis 2015: forsa Gesellschaft f\xc3\xbcr Sozialforschung und statistische Analysen mbH, Dortmund und Berlin. \n\nLong term studies regarding the alcohol and (illegal) drug consumption habits of 12 to 25 year old German teens were taken. The motivations and influences in drug consumption were studied. The aim was to develop preventional means and ways of communication with drug consuming teenagers.\n\n### Content\n\nYoung Germans between 12 and 25 years were asked about their drug consumptions in the last 12 months. The survey was taken from the 70's until today. Different datasets were provided and for some years features are missing.\n\n### Acknowledgements\nThe data is provided by German Bundeszentrale f\xc3\xbcr gesundheitliche Aufkl\xc3\xa4rung (Ministry of Health Education) and can be accessed at http://www.gbe-bund.de.\n\nPhoto by Stas Svechnikov on Unsplash.\n\n### Inspiration\n\nWhile growing up in the late 2000's in Germany I had the impression that teenagers smoke less cigarettes and drink less alcohol than they used to in the 90's. Instead, they consumed more cannabis. I wonder if I was right ...""","b""['health', 'public health', 'alcohol', 'children', 'illegal drugs', 'small', 'featured']""",https://www.kaggle.com/fabiolabusch/alcohol-and-drug-consumption-of-german-teens
b'H-1B Visa Petitions 2011-2016',b'3 million petitions for H-1B visas',"b""# Context \n\nH-1B visas are a category of employment-based, non-immigrant visas for temporary foreign workers in the United States. For a foreign national to apply for H1-B visa, a US employer must offer them a job and submit a petition for a H-1B visa to the US immigration department. This is also the most common visa status applied for and held by international students once they complete college or higher education and begin working in a full-time position.\n\nThe following articles contain more information about the H-1B visa process:\n\n* [What is H1B LCA ? Why file it ? Salary, Processing times \xe2\x80\x93 DOL](https://redbus2us.com/what-is-h1b-lca-why-file-it-salary-processing-times-dol/)\n* [H1B Application Process: Step by Step Guide](http://www.immi-usa.com/h1b-application-process-step-by-step-guide/)\n\n# Content\n\nThis dataset contains five year's worth of H-1B petition data, with approximately 3 million records overall. The columns in the dataset include case status, employer name, worksite coordinates, job title, prevailing wage, occupation code, and year filed.\n\nFor more information on individual columns, refer to the column metadata. A detailed description of the underlying raw dataset is available in [an official data dictionary](https://www.foreignlaborcert.doleta.gov/docs/Performance_Data/Disclosure/FY15-FY16/H-1B_FY16_Record_Layout.pdf).\n\n# Acknowledgements\n\nThe Office of Foreign Labor Certification (OFLC) generates program data, including data about H1-B visas. The disclosure data updated annually and is available [online](https://www.foreignlaborcert.doleta.gov/performancedata.cfm).\n\nThe raw data available is messy and not immediately suitable analysis. A set of data transformations were performed making the data more accessible for quick exploration. To learn more, refer to [this blog post](https://sharan-naribole.github.io/2017/02/24/h1b-eda-part-I.html) and to the complimentary [R Notebook](https://github.com/sharan-naribole/H1B_visa_eda/blob/master/data_processing.Rmd).\n\n# Inspiration\n\n* Is the number of petitions with Data Engineer job title increasing over time?\n* Which part of the US has the most Hardware Engineer jobs?\n* Which industry has the most number of Data Scientist positions?\n* Which employers file the most petitions each year?""","b""['law', 'international relations', 'medium', 'featured']""",https://www.kaggle.com/nsharan/h-1b-visa
b'MRI and Alzheimers',b'Magnetic Resonance Imaging Comparisons of Demented and Nondemented Adults',"b'### Context: \nThe [Open Access Series of Imaging Studies (OASIS)](http://www.oasis-brains.org/) is a project aimed at making MRI data sets of the brain freely available to the scientific community. By compiling and freely distributing MRI data sets, we hope to facilitate future discoveries in basic and clinical neuroscience. OASIS is made available by the Washington University Alzheimer\xe2\x80\x99s Disease Research Center, Dr. Randy Buckner at the [Howard Hughes Medical Institute (HHMI)](http://www.hhmi.org/)( at Harvard University, the [Neuroinformatics Research Group (NRG)](http://nrg.wustl.edu/) at Washington University School of Medicine, and the [Biomedical Informatics Research Network (BIRN)](http://www.nbirn.net/).\n\n\n### Content: \n* **Cross-sectional MRI Data in Young, Middle Aged, Nondemented and Demented Older Adults**: This set consists of a cross-sectional collection of 416 subjects aged 18 to 96.  For each subject, 3 or 4 individual T1-weighted MRI scans obtained in single scan sessions are included.  The subjects are all right-handed and include both men and women.  100 of the included subjects over the age of 60 have been clinically diagnosed with very mild to moderate Alzheimer\xe2\x80\x99s disease (AD).  Additionally, a reliability data set is included containing 20 nondemented subjects imaged on a subsequent visit within 90 days of their initial session.\n* **Longitudinal MRI Data in Nondemented and Demented Older Adults**:  This set consists of a longitudinal collection of 150 subjects aged 60 to 96. Each subject was scanned on two or more visits, separated by at least one year for a total of 373 imaging sessions. For each subject, 3 or 4 individual T1-weighted MRI scans obtained in single scan sessions are included. The subjects are all right-handed and include both men and women. 72 of the subjects were characterized as nondemented throughout the study. 64 of the included subjects were characterized as demented at the time of their initial visits and remained so for subsequent scans, including 51 individuals with mild to moderate Alzheimer\xe2\x80\x99s disease. Another 14 subjects were characterized as nondemented at the time of their initial visit and were subsequently characterized as demented at a later visit.\n\n\n### Acknowledgements: \nWhen publishing findings that benefit from OASIS data, please include the following grant numbers in the acknowledgements section and in the associated Pubmed Central submission: P50 AG05681, P01 AG03991, R01 AG021910, P20 MH071616, U24 RR0213\n\n### Inspiration: \nCan you predict dementia? Alzheimer\xe2\x80\x99s?'","b""['image data', 'healthcare', 'health sciences', 'neuroscience', 'neurology', 'small', 'featured']""",https://www.kaggle.com/jboysen/mri-and-alzheimers
b'Last Words of Death Row Inmates',b'Text Mining with Farewell Words',"b'**1. Context**\n\nCapital punishment is one of the controversial human rights issues in the United States. While surfing the Internet for an interesting dataset, I came across this database by Texas Department of Criminal Justice, which comprises of the offenders\' last words before execution. Some of the statements are:   \n\n""...Young people, listen to your parents; always do what they tell you to do, go to school, learn from your mistakes. Be careful before you sign anything with your name. Never, despite what other people say..."" (Ramiro Hernandez, executed on April 9th, 2014)  \n\n""First and foremost I\'d like to say, ""Justice has never advanced by taking a life"" by Coretta Scott King. Lastly, to my wife and to my kids, I love y\'all forever and always. That\'s it."" (Taichin Preyor, executed on July 27th, 2017)   \n\nAs I skimmed these lines, I decided to create this dataset. \n\n\n**2. Content**\n\nThis dataset includes information on criminals executed by Texas Department of Criminal Justice from 1982 to November 8th, 2017. In *Furman v Georgia* in 1972, the Supreme Court considered a group of consolidated cases, whereby it severely restricted the death penalty. However, like other states, Texas adjusted its legislation to address the Court\'s concern and once again allow for capital punishment in 1973. Texas adopted execution by lethal injection in 1977 and in 1982, the starting year of this dataset, the first offender was executed by this method.    \n\nThe dataset consists of 545 observations with 21 variables. They are:   \n- **Execution**: The order of execution, numeric.   \n- **LastName**: Last name of the offender, character.   \n- **FirstName**: First name of the offender, character.   \n- **TDCJNumber**: TDCJ Number of the offender, numeric.  \n- **Age**: Age of the offender, numeric.   \n- **Race**: Race of the offender, categorical : Black, Hispanic, White, Other.   \n- **CountyOfConviction**: County of conviction, character.   \n- **AgeWhenReceived**: Age of offender when received, numeric.   \n- **EducationLevel**: Education level of offender, numeric.    \n- **Native County**: Native county of offender, categorical : 0 = Within Texas, 1= Outside Texas.   \n- **PreviousCrime** : Whether the offender committed any crime before, categorical: 0= No, 1= Yes.  \n- **Codefendants**: Number of co-defendants, numeric.  \n- **NumberVictim**: Number of victims, numeric.  \n- **WhiteVictim**, **HispanicVictim**, **BlackVictim**, **VictimOtherRace**. **FemaleVictim**, **MaleVictim**: Number of victims with specified demographic features, numeric.   \n- **LastStatement**: Last statement of offender, character.   \n\n**3. Acknowledgement** \n  \nThis dataset is derived from the database by Texas Department of Criminal Justice which can be found in this link: http://www.tdcj.state.tx.us/death_row/dr_executed_offenders.html . It can be seen that the original one has fewer than 10 variables and is embedded with some links to sub-datasets, so I manually inputted more variables based on those links.    \n\nThere are some complications with this dataset. Firstly, the dataset was manually created so mistakes are inevitable, though I have tried my best to minimize them. Secondly, the recording of offender information is not complete and consistent. For example, sometimes the education level of GED is interpreted as 11 years, at other times as 9 or 10 years. ""None"" and ""NA"" are used interchangeably, making it hard to distinguish between 0 and NA in the coded variable. The victim\'s information is often omitted, so I rely on the description of the crime for the names and pronouns to make a judgement of the number of victims and their gender. Finally, the last statements are sometimes recorded in the first person and sometimes in the third, so the word choice might not be original.  That being said, I find this dataset meaningful and worth sharing.\n  \n**4. Inspiration**   \n\nWhat are the demographics of the death row inmates? What are the patterns of their last statements? What is the relationship between the two? '","b""['demographics', 'crime', 'small', 'featured']""",https://www.kaggle.com/mykhe1097/last-words-of-death-row-inmates
b'All Lending Club loan data',b'2007 through current Lending Club accepted and rejected loan data',"b'# Update:\nThe URL column is now in the dataset for completeness, as of 2018 Q2.\n\n# Context \n\nI wanted an easy way to share all the lending club data with others.  Unfortunately, the [data on their site][1] is fragmented into many smaller files.  There is another lending club [dataset on Kaggle][2], but it hasn\'t been updated in years.  It also doesn\'t include the rejected loans, which I put in here.\n\nI created a git repo for the code to create this data: https://github.com/nateGeorge/preprocess_lending_club_data\n\n\n# Content\n\nThe definitions for the fields are here, at the bottom of the page.\n\nUnfortunately, there is (maybe ""was"" now?) a limit of 500MB for dataset files, so I had to compress the files with gzip in the Python pandas package.  \n\nI cleaned the data a tiny bit:  I removed %s from int_rate and revol_util, and deleted the url column.\n\nTo load the data in Python:\n\n    import pandas as pd\n    \n    accept_df = pd.read_csv(\'../input/accepted_2007_to_2016.csv.gz\', compression=\'gzip\')\n    reject_df = pd.read_csv(\'../input/rejected_2007_to_2016.csv.gz\', compression=\'gzip\')\n    \n    # too many columns to print the info summary out, so we need to force it\n    print(accept_df.info(verbose=True, null_counts=True))\n\nIn R:\n\n    library(data.table)\n    \n    accepted_def &lt;- read.csv(gzfile(\'rejected_2007_to_2016.csv.gz\'), na.strings=\'\')\n    acc_dt &lt;- as.data.table(accepted_def)\n    rejected_def &lt;- read.csv(gzfile(\'accepted_2007_to_2016.csv.gz\'), na.strings=\'\')\n    rej_dt &lt;- as.data.table(accepted_def)\n\n\nThere are also separate csvs in the main input folder, but the only advantage over the lending club site is that the 2016 year is joined into one file instead of 4.\n\n\n# Inspiration\n\nI wanted to make this dataset easily available for others to use.\n\n\n  [1]: https://www.lendingclub.com/info/download-data.action\n  [2]: https://www.kaggle.com/wendykan/lending-club-loan-data\n  [3]: https://blog.rstudio.org/2016/03/29/feather/'","b""['finance', 'business', 'lending', 'medium', 'featured']""",https://www.kaggle.com/wordsforthewise/lending-club
b'Chicago Grocery Stores - 2013',b'From City of Chicago Open Data',"b""### Content  \n\nContains a list of grocery stores which was used by the city to calculate the estimates of Chicagoans living in food deserts in 2013. Data in this file can be cross-referenced with the city's business license data (http://bit.ly/sMFZdN).  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/7hlOjB5VVb0) by [Elli O.](https://unsplash.com/@oelli) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-grocery-stores-2013
b'Canadian Disaster Database',b'Over 1000 Disasters Affecting Canadians At-Home or Abroad Since 1900',"b'### Context\n\nThe Canadian Disaster Database\nThe Canadian Disaster Database (CDD) contains detailed disaster information on more than 1000 natural, technological and conflict events (excluding war) that have happened since 1900 at home or abroad and that have directly affected Canadians. \n\n\n### Content\n\nData description copied from: [https://www.publicsafety.gc.ca/cnt/rsrcs/cndn-dsstr-dtbs/index-en.aspx](https://www.publicsafety.gc.ca/cnt/rsrcs/cndn-dsstr-dtbs/index-en.aspx)\n\nDataset date range: 1900 - present\n\n\nThe CDD tracks ""significant disaster events"" which conform to the Emergency Management Framework for Canada definition of a ""disaster"" and meet one or more of the following criteria:\n\n\n* 10 or more people killed  \n* 100 or more people affected/injured/infected/evacuated or homeless  \n* an appeal for national/international assistance  \n* historical significance  \n* significant damage/interruption of normal processes such that the community affected cannot recover on its own  \n\nThe database describes where and when a disaster occurred, the number of injuries, evacuations, and fatalities, as well as a rough estimate of the costs.  As much as possible, the CDD contains primary data that is valid, current and supported by reliable and traceable sources, including federal institutions, provincial/territorial governments, non-governmental organizations and media sources.  \n\nData is updated and reviewed on a semi-annual basis.\n \n\n   \n```Data Field``` Description    \n\n----------\n\n\n``` Disaster Type                        ``` The type of disaster (e.g. flood, earthquake, etc.) that occurred.    \n``` Date of Event                        ``` The date a specific event took place.    \n``` Specific Location                    ``` The city, town or region where a specific event took place.    \n``` Description of Event                 ``` A brief description of a specific event, including pertinent details that may not be captured in other data fields (e.g. amount of precipitation, temperatures, neighbourhoods, etc.)    \n``` Fatalities                           ``` The number of people killed due to a specific event.    \n``` Injured/Infected                     ``` The number of people injured or infected due to a specific event.    \n``` Evacuees                             ``` The number of individuals evacuated by the government of Canada due to a specific event.    \n``` Latitude & Longitude                 ``` The exact geographic location of a specific event.    \n``` Province/Territory                   ``` The province or territory where a specific event took place.    \n``` Estimated Total Cost                 ``` A roll-up of all the costs listed within the financial data fields for a specific event.    \n``` DFAA Payments                        ``` The amount, in dollars, paid out by Disaster Financial Assistance Arrangements (Public Safety Canada) due to a specific event.    \n``` Insurance Payments                   ``` The amount, in dollars, paid out by insurance companies due to a specific event.    \n``` Provincial/Territorial Costs/Payments``` The amount, in dollars, paid out by a Province or Territory due to a specific event.    \n``` Utility Costs/Losses                 ``` The amount of people whose utility services (power, water, etc.) were interrupted/affected by a specific event.    \n``` Magnitude                            ``` A measure of the size of an earthquake, related to the amount of energy released.    \n``` Other Federal Institution Costs      ``` The amount, in dollars, paid out by other federal institutions.    \n  \n\t  \n### Acknowledgements\n\nData gathered from: http://cdd.publicsafety.gc.ca\nTerms of use for commercial and non-comerical reproduction: https://www.publicsafety.gc.ca/cnt/ntcs/trms-en.aspx\n\n\n### Inspiration\nThis dataset provides valuable insight to natural and non-natrual disasters which have affected Canada. \n\nPossible explorations:\n* Where do different types of disasters occur more frequently? \n* Which Province / Location in Canada has been hit the hardest in terms of fatalities, number of injuries, estimated total cost, etc.?\n \n Spatial-temporal correlations between natural/artifical distasters\n* \n\nI think that this can be used to produce some interesting data visualizations. Some of the questions I look forward to answering include:\n\n* Can any spatial-temporal correlations between disasters be found in this dataset?\n* Which locations in Canada have been hit the hardest, in terms of people injured, fatalities, financial impact, etc.\n'","b""['time series', 'geography', 'north america', 'small', 'featured']""",https://www.kaggle.com/criticalhits/canadian-disaster-database
b'Cervical Cancer Risk Classification',b'prediction of  cancer indicators; Please download; run kernel & upvote',"b'Cervical Cancer Risk Factors for Biopsy: This Dataset is Obtained from UCI Repository and kindly acknowledged!\n\nThis file contains a List of Risk Factors for Cervical Cancer leading to a Biopsy Examination!\n\nAbout 11,000 new cases of invasive cervical cancer are diagnosed each year in the U.S. However, the number of new cervical cancer cases has been declining steadily over the past decades. Although it is the most preventable type of cancer, each year cervical cancer kills about 4,000 women in the U.S. and about 300,000 women worldwide. In the United States, cervical cancer mortality rates plunged by 74% from 1955 - 1992 thanks to increased screening and early detection with the Pap test. AGE Fifty percent of cervical cancer diagnoses occur in women ages 35 - 54, and about 20% occur in women over 65 years of age. The median age of diagnosis is 48 years. About 15% of women develop cervical cancer between the ages of 20 - 30. Cervical cancer is extremely rare in women younger than age 20. However, many young women become infected with multiple types of human papilloma virus, which then can increase their risk of getting cervical cancer in the future. Young women with early abnormal changes who do not have regular examinations are at high risk for localized cancer by the time they are age 40, and for invasive cancer by age 50. SOCIOECONOMIC AND ETHNIC FACTORS Although the rate of cervical cancer has declined among both Caucasian and African-American women over the past decades, it remains much more prevalent in African-Americans -- whose death rates are twice as high as Caucasian women. Hispanic American women have more than twice the risk of invasive cervical cancer as Caucasian women, also due to a lower rate of screening. These differences, however, are almost certainly due to social and economic differences. Numerous studies report that high poverty levels are linked with low screening rates. In addition, lack of health insurance, limited transportation, and language difficulties hinder a poor woman\xe2\x80\x99s access to screening services. HIGH SEXUAL ACTIVITY Human papilloma virus (HPV) is the main risk factor for cervical cancer. In adults, the most important risk factor for HPV is sexual activity with an infected person. Women most at risk for cervical cancer are those with a history of multiple sexual partners, sexual intercourse at age 17 years or younger, or both. A woman who has never been sexually active has a very low risk for developing cervical cancer. Sexual activity with multiple partners increases the likelihood of many other sexually transmitted infections (chlamydia, gonorrhea, syphilis).Studies have found an association between chlamydia and cervical cancer risk, including the possibility that chlamydia may prolong HPV infection. FAMILY HISTORY Women have a higher risk of cervical cancer if they have a first-degree relative (mother, sister) who has had cervical cancer. USE OF ORAL CONTRACEPTIVES Studies have reported a strong association between cervical cancer and long-term use of oral contraception (OC). Women who take birth control pills for more than 5 - 10 years appear to have a much higher risk HPV infection (up to four times higher) than those who do not use OCs. (Women taking OCs for fewer than 5 years do not have a significantly higher risk.) The reasons for this risk from OC use are not entirely clear. Women who use OCs may be less likely to use a diaphragm, condoms, or other methods that offer some protection against sexual transmitted diseases, including HPV. Some research also suggests that the hormones in OCs might help the virus enter the genetic material of cervical cells. HAVING MANY CHILDREN Studies indicate that having many children increases the risk for developing cervical cancer, particularly in women infected with HPV. SMOKING Smoking is associated with a higher risk for precancerous changes (dysplasia) in the cervix and for progression to invasive cervical cancer, especially for women infected with HPV. IMMUNOSUPPRESSION Women with weak immune systems, (such as those with HIV / AIDS), are more susceptible to acquiring HPV. Immunocompromised patients are also at higher risk for having cervical precancer develop rapidly into invasive cancer. DIETHYLSTILBESTROL (DES) From 1938 - 1971, diethylstilbestrol (DES), an estrogen-related drug, was widely prescribed to pregnant women to help prevent miscarriages. The daughters of these women face a higher risk for cervical cancer. DES is no longer prsecribed.'","b""['healthcare', 'human genetics', 'small', 'featured']""",https://www.kaggle.com/loveall/cervical-cancer-risk-classification
b'NSE India stocks (Indices)',b'1 minute intraday datasets',"b""Context\n-------\n\n**nifty50.csv**\nThe NIFTY 50 index is National Stock Exchange of India's benchmark stock market index for Indian equity market. It is a well diversified 50 stock index accounting for 22 sectors of the economy. It is used for a variety of purposes such as bench-marking fund portfolios, index based derivatives and index funds.\n\n**banknifty.csv**\nBank Nifty represents the 12 most liquid and large capitalized stocks from the banking sector which trade on the National Stock Exchange (NSE). It provides investors and market intermediaries a benchmark that captures the capital market performance of Indian banking sector.\n\nContent\n-------\n\nA data frame with 8 variables: index, date, time, open, high, low, close and id. For each year from 2013 to 2016, the number of trading data of each minute of given each date. The currency of the price is Indian Rupee (INR).\n\n - index : market id\n - date: numerical value (Ex. 20121203- to be converted to 2012/12/03)\n - time: factor (Ex. 09:16)\n - open: numeric (opening price)\n - high: numeric (high price)\n - low: numeric (low price)\n - close: numeric (closing price)\n\nInspiration\n-----------\n\nInitial raw data sets are very complex and mixed datatypes. These are processed properly using R libraries like dplyr, stringr and other data munging packages. The desired outputs are then converted into a CSV format to use for further analysis.""","b""['finance', 'medium', 'featured']""",https://www.kaggle.com/ramamet4/nse-stocks-database
b'NYS Child and Dependent Care Credit',b'From New York State Open Data',"b""### Content  \n\nThe Department of Taxation and Finance annually publishes statistical information on the New York State child and dependent care credit (NYS CDCC).  Summary data are presented for all taxpayers, including full-year New York state residents, part-year residents and nonresidents (where applicable).  Data are presented on a statewide and county-level basis for numbers and amounts of credit claims based on filing status and number of qualifying dependents.  Taxpayers filing \xe2\x80\x9cmarried separate\xe2\x80\x9d generally are not allowed to take the child and dependent care credit.\n\nThe tables also include summary information for the New York City child and dependent care credit (NYC CDCC).  The data are presented on a county-level basis for numbers and amounts of credit claims at the aggregate level only.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/p0hDztR46cw) by [li tzuni](https://unsplash.com/@itshoobastank) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-child-and-dependent-care-credit
b'Current Properati Listing Information',b'Property attributes of 1.5 million Latin American listings',"b'Properati is a competitive marketplace for Latin American real estate that strives to assist consumers in purchasing and renting homes, while simultaneously providing location-specific property databases for the public. \n \nProperati currently lists over 1.5 million properties through hubs in Argentina, Mexico, and Brazil. Listings include property name, type, price, listing date, surface area, coordinates, description, and photos. Most of these premises are located in urban settings, with few straying into suburban or rural areas. Innovators at Properati understand that a house is usually the most important and costly purchase an individual makes in his or her lifetime. Properati has developed tools, such as Preci\xc3\xb3metro, to help people make well-educated property investments. \n \nProperati also creates data analyses based on over 1.5 million properties to better understand the real estate market. Through these reports, Properati uncovers social trends and urban processes that help characterize current and future listings. Visit Properati\xe2\x80\x99s blog and website to join them in their advanced market knowledge. \n \nProperati invites you to utilize their location based datasets from current and past listings in Big Query \nhttps://bigquery.cloud.google.com/dataset/properati-data-public:properties_ar\nhttps://bigquery.cloud.google.com/dataset/properati-data-public:properties_br\nhttps://bigquery.cloud.google.com/dataset/properati-data-public:properties_mx'","b""['home', 'medium', 'featured']""",https://www.kaggle.com/properati-data/properties
b'NYS Roswell Park Cancer Institute - Publications',b'From New York State Open Data',"b""### Content  \n\nList of existing publications from Roswell Park Cancer Institute authors, including:  year published; publication type and title; journal name, volume, issue and page range; author list; ISSN; and peer reviewed information  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/iWI0KPkmcZA) by [Charles Deluvio](https://unsplash.com/@charlesdeluvio) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-roswell-park-cancer-institute-publications
b'NYS Meals Served by the Office for the Aging',b'From New York State Open Data',"b""### Content  \n\nThis dataset is a listing of congregate and home delivered meals served 1974 to the present by the network of Area Agencies on Aging (AAAs).  AAAs - local offices for the Aging - provide services at senior center locations either directly or through subcontracts. Services may include but are not limited to congregate meals, health promotion, educational programs, recreation, etc.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/-YHSwy6uqvk) by [Lily Banse](https://unsplash.com/@lvnatikk) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-meals-served-by-the-office-for-the-aging
b'Tusbic Santander ',b'Santander bike sharing system',"b'# Description\n\nThis is a collection of the Santander (Spain) bike-sharing open data facility, named [Tusbic][1], operated by JCDecaux.\n\nI will be updating this dataset form time to time, added new data as I collect it.\n\n# Format\n\n## Bike sharing system data\n\nThe `bikes.csv` file contains the information from the bike sharing system. Data is structured as follows:\n\n* `number` number of the station\n* `contract_name` name of the contract of the station\n* `name` name of the station\n* `address` address of the station (raw)\n* `lat` latitude of the station in WGS84 format\n* `lng` latitude of the station in WGS84 format\n* `banking` indicates whether this station has a payment terminal\n* `bonus` indicates whether this is a bonus station\n* `status` indicates whether this station is CLOSEDor OPEN\n* `bike_stands` the number of operational bike stands at this station\n* `available_bike_stands` the number of available bike stands at this station\n* `available_bikes` the number of available and operational bikes at this station\n* `last_update` timestamp indicating the last update time in milliseconds since Epoch\n\n## Bike lane geometries\nThe `bike_lanes.csv` file contains the geometries of bike lanes in Santander city, as published by the Santander City Council in its [open data platform][2].\n\n* `ayto:WKT` contains the geometry in WKT format, using ED50 UTM coordinates (zone 30N).\n* `wkt_wsg84` contains the geometry in WKT format, using WGS84 coordinates.\n* `ayto:Estado` shows the status of the bike lane. EJECUTADO means that is has been built and it is operative.\n\n# License\n\nThe bike sharing data is being collected from the [JCDecaux Developer][3] Open Data platform and is licensed under the [Etalab Open License][4], compatbile with the standards of Open Data licenses (ODC-BY, CC-BY 2.0).\n\nThe bike lane geometry is being collected form the [Santander Open Data Platform][5] and is licensed under a CC BY 4.0 license.\n\nDataste Kaggle logo is a photo licensed under a CC-BY-SA 3.0, authored by [Tiia Monto][6].\n\n\n  [1]: http://www.tusbic.es/\n  [2]: http://datos.santander.es/dataset/?id=carril-bici\n  [3]: https://developer.jcdecaux.com/\n  [4]: https://developer.jcdecaux.com/#/opendata/license\n  [5]: http://datos.santander.es\n  [6]: https://commons.wikimedia.org/wiki/File:Tusbic.jpg'","b""['cities', 'cycling', 'small', 'featured']""",https://www.kaggle.com/alvarolopez/tusbic
b'NY Taxi Improvement Fund (TIF) Medallion Payments',b'From New York City Open Data',"b""### Content  \n\nThis is a list of monthly payments made to owners of Wheelchair Accessible Vehicles (WAVs) from the Taxi Improvement Fund (TIF). Information is listed by medallion and agent number, and is updated after each payment is distributed from the Taxi Improvement Fund, approximately once per month. For more information see the TIF Owner page (http://www.nyc.gov/html/tlc/html/industry/taxi_improvement_fund_owner.shtml).\r\n\r\nIf you have questions or comments on this data set, please contact the Taxi Improvement Fund Project Team at TIF@TLC.NYC.GOV or visit the TIF Frequently Asked Questions page: http://www.nyc.gov/html/tlc/html/industry/taxi_improvement_fund_faq.shtml.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/yAqUJCQS8f8) by [Rohit Tandon](https://unsplash.com/@rohittandon) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-taxi-improvement-fund-tif-medallion-payments
b'One Week of Global News Feeds',b'7 days of tracking 20k news feeds worldwide',"b'# Context\n\nThis dataset is a snapshot of most of the new news content published online over one week (August 24 through August 30). \n\nYear 2017: 1,398,431 ; Year 2018: 1,912,873\n\nPrepared by **Rohit Kulkarni**\n\nIt includes approximately **3.3 million** articles, with **20,000 news sources** and **20+ languages**.\n\nThis dataset has just four fields (as per the [column metadata](https://www.kaggle.com/therohk/global-news-week/data)):\n\n - **publish_time** - earliest known time of the url appearing online in yyyyMMddHHmm format, IST timezone\n\n - **feed_code** - unique identifier for the publisher or domain\n\n - **source_url** - url of the article\n\n - **headline_text** - Headline of the article (UTF8, 20+ possible languages)\n\nSee the [""Basic Data Exploration""](https://www.kaggle.com/residentmario/basic-data-exploration) notebook for a quick look at the dataset contents.\n\n# Inspiration\n\nThe sources include news feeds, news websites, government agencies, tech journals, company websites, blogs and wikipedia updates. The data has been collected by polling RSS feeds and by crawling other large news aggregators. \n\nAs of 2017, this 7 day slice was selected as there wasn\'t any downtime or internet outage during the interval. New news content is produced at this rate by publishers everyday, throughout the year. \n\nFeed code: w3-event-ijsstream ; Si.gh.rank: GNV\n\n# Acknowledgements\n\nThis dataset is free to use with the following citation: \n\nRohit Kulkarni (2017), One Week of Global Feeds [News CSV Dataset], doi:10.7910/DVN/ILAT5B, Retrieved from: [this url]\n\nRemodelling from raw IJS news feed: http://newsfeed.ijs.si/\n\nOriginal paper by M Trampus, B Novak: Internals of An Aggregated Web News Feed\n\nHosted By: Josef Stefan Institute, Slovenia : http://ailab.ijs.si/people/\n\nLieve News: http://eventregistry.org/'","b""['internet', 'linguistics', 'news agencies', 'historiography', 'medium', 'featured']""",https://www.kaggle.com/therohk/global-news-week
b'Path of exile game statistic',"b'Statistic of 59000 players, lets analyze it!'","b""### Path of Exile League statistic \n\nData contains stats of 59000 players, from 4th August of 2017 and before now.\n\n### Content\n\nOne file with 12 data sections. One league - Harbinger, but 4 different types of divisions: \n\n* Harbinger\n* Hardcore Harbinger\n* SSF Harbinger\n* SSF Harbinger HC\n\nEach division has own ladder with leaders\n\n### Acknowledgements\n\nI found this data at the pathofstats.com as a JSON format and exported at CVS.  Data have been collecting by this API, and free to use for interested people. If GGG or pathofstats.com don't want to share it here, please contact me and it will be removed.  \nAs I could understand, it is simple data for people, who are new at data science and want to have practice. \n\n### Questions for participants\n\n\n1. A total number of players in each division, usage of each class in descending order.\n2. Some of the players streaming their game (twitch colum). Do they play better than people, who does not? \n3. Predict chance to be at top 30 in each division, if we are Necromancer. With and without stream.\n4. Average number of finished challanges for each division, show division with highest and lowest average challanges.\n5. Show dependency between level and class of died characters. Only for HC divisions.\n\n""","b""['video games', 'small', 'featured']""",https://www.kaggle.com/gagazet/path-of-exile-league-statistic
b'Honorees in the B Corp Best for the World Lists',b'Analyse the impact of certified B Corps chosen for Best for the World Lists',"b'### Context\n\nTo explore the impact data of Certified B Corps that have been selected for the Best for the World Lists\n\n\n### Content\n\nEvery year, B Lab highlights the Certified B Corporations that go above and beyond in their pursuit of positive impact. All B Corporations take the B Impact Assessment and meet verified score requirements to become certified. In the assessment, companies are evaluated on their impact on the environment, their workers, their customers, and their communities; they also all meet the highest standards of accountability and transparency. Companies featured on the Best for the World lists scored in the top 10% of the B Corp community in each of seven categories\xe2\x80\x94they are the top performers in an already exceptional group of businesses. The datasets provided mainly accounts for the B Corp nominees for Best for the World and the eventual honorees this year and the various different areas of work these B Corps mostly focus on.\n\n\n### Acknowledgements\n\nThe dataset published here can be found at ""data.world/blab"" so a big thanks to B Lab for making the data publicly available for everyone\n\n### Inspiration\nWhat companies are best for the world?'","b""['eda', 'demographics', 'business', 'small', 'featured']""",https://www.kaggle.com/ol0fmeister/honorees-in-the-b-corp-best-for-the-world-lists
b'Baltimore 911 Calls',b'Records of 2.8 million calls from 2015 onwards',"b'This dataset records the time, location, priority, and reason for calls to 911 in the city of Baltimore.\n \n## Acknowledgements\nThis dataset was kindly made available by the City of Baltimore. They update the data daily; you can find [the original version here][1].\n\n## Inspiration\n\n - The study discussed in [this Atlantic article][2] reviewing 911 calls in Milwaukuee found that that incidents of police violence lead to large drops in the number of 911 calls. Does this hold true for Baltimore as well?\n\n\n  [1]: https://data.baltimorecity.gov/Public-Safety/911-Calls-for-Service/xviu-ezkt\n  [2]: https://www.theatlantic.com/politics/archive/2016/09/police-violence-lowers-911-calls-in-black-neighborhoods/501908/'","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/sohier/baltimore-911-calls
"b'380,000+ lyrics from MetroLyrics'","b'Lyrics, Artist , Genre, Year'","b'# Context \n\nI tried to gather as many lyrics as I could. I ran my code on a a free ec2 instance and ran out of storage space. I have attached the code below so if any one wants to try out it and get all lyrics, please do.\n\n\n# Content\n\nThere are around 380,000+ lyrics in the data set from a lot of different artists from a lot of different genres arranged by year. Structure is artist/year/song. Every artist folder has a genre.txt that tells what is the genre of the musician. Find the crawler [here][1].\n\n\n# Acknowledgements\n\nI would like to thank Shruti Jasoria, [SJasoria][2] on GitHub for writing the multi-threaded version.\n\n\n# Inspiration\n\nI wanted to find out what genre and what artist abuses what substance. Do rapstars like cocaine or liquor? If liquor then what Liquor? Does Eminem prefer Hennesy over Jack Daniels? Do Rockstars love pot?\n\n\n  [1]: https://github.com/h4ck3rk3y/lyrics_substance\n  [2]: https://github.com/SJasoria'","b""['linguistics', 'music', 'writing', 'medium', 'featured']""",https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics
b'Eurovision 2018 Voting Results',b'Explore voting patterns in the 2018 Eurovision song contest',"b""This dataset comes from: https://eurovision.tv/event/lisbon-2018/grand-final/voting-details\n\nIt contains the extended voting information for countries in the 2018 eurovision song contest.\n\nKaggle's first competition was based on Eurovision, check it out here: \nhttps://www.kaggle.com/c/Eurovision2010""","b""['europe', 'music', 'small', 'featured']""",https://www.kaggle.com/mylesoneill/eurovision-2018-voting-results
b'Funding Successful Projects on Kickstarter',b'Predict if a project will get successfully funded or not using labeled data',"b'### Problem Statement\n\nKickstarter is a community of more than 10 million people comprising of creative, tech enthusiasts who help in bringing creative project to life. Till now, more than $3 billion dollars have been contributed by the members in fueling creative projects. The projects can be literally anything \xe2\x80\x93 a device, a game, an app, a film etc.\n\nKickstarter works on all or nothing basis i.e if a project doesn\xe2\x80\x99t meet it goal, the project owner gets nothing. For example: if a projects\xe2\x80\x99s goal is $500. Even if it gets funded till $499, the project won\xe2\x80\x99t be a success.\n\nRecently, Kickstarter released its public data repository to allow researchers and enthusiasts like us to help them solve a problem. Will a project get fully funded ?\n\nIn this challenge, you have to predict if a project will get successfully funded or not.\n\n###Data Description\n\nThere are three files given to download: train.csv, test.csv and sample_submission.csv The train data consists of sample projects from the May 2009 to May 2015. The test data consists of projects from June 2015 to March 2017.'","b""['finance', 'business', 'medium', 'featured']""",https://www.kaggle.com/codename007/funding-successful-projects
b'NFL Statistics',"b'Basic NFL statistics, career statistics, and game logs'","b'# NFL-Statistics-Scrape\nHere are the basic statistics, career statistics and game logs provided by the NFL on their website (http://www.nfl.com) for all players past and present. \n\n## Summary\nThe data was scraped using a Python code.  The code can be located at Github: https://github.com/kendallgillies/NFL-Statistics-Scrape\n\n## Explanation of Data\n1. The first main group of statistics is the basic statistics provided for each player.  This data is stored in the CSV file titled Basic_Stats.csv along with the player\xe2\x80\x99s name and URL identifier.  If available the data pulled for each player is as follows:\n    1. Number\n    2. Position\n    3. Current Team\n    4. Height\n    5. Weight\n    6. Age\n    7. Birthday\n    8. Birth Place\n    9. College Attended\n    10. High School Attended\n    11. High School Location\n    12. Experience\n2. The second main group of statistics gathered for each player are their career statistics.  While each player has a main position they play, they will have statistics in other areas; therefore, the career statistics are divided into statistics types.  The statistics are then stored in CSV files based on statistic type along with the player name, URL identifier and position (if available).  The following are the career statistics types and accompanying CSV file names:\n    1. Defensive Statistics \xe2\x80\x93 Career_Stats_Defensive.csv\n    2. Field Goal Kickers - Career_Stats_Field_Goal_Kickers.csv\n    3. Fumbles - Career_Stats_Fumbles.csv\n    4. Kick Return - Career_Stats_Kick_Return.csv\n    5. Kickoff - Career_Stats_Kickoff.csv\n    6. Offensive Line - Career_Stats_Offensive_Line.csv\n    7. Passing - Career_Stats_Passing.csv\n    8. Punt Return - Career_Stats_Punt_Return.csv\n    9. Punting - Career_Stats_Punting.csv\n    10. Receiving - Career_Stats_Receiving.csv\n    11. Rushing - Career_Stats_Rushing.csv\n3. The final group of statistics is the game logs for each player.  The game logs are stored by position and have the player name, URL identifier and position (if available).  The following are the game log types and accompanying CSV file names:\n    1. Quarterback \xe2\x80\x93 Game_Logs_Quarterback.csv\n    2. Running back \xe2\x80\x93 Game_Logs_Runningback.csv\n    3. Wide Receiver and Tight End \xe2\x80\x93 Game_Logs_Wide_Receiver_and_Tight_End.csv\n    4. Offensive Line \xe2\x80\x93 Game_Logs_Offensive_Line.csv\n    5. Defensive Lineman \xe2\x80\x93 Game_Logs_Defensive_Lineman.csv\n    6. Kickers \xe2\x80\x93 Game_Logs_Kickers.csv\n    7. Punters \xe2\x80\x93 Game_Logs_Punters.csv\n\n## Glossary\nWhile most of the abbreviations used by the NFL have been translated in the table headers in the data files, there are still a couple of abbreviations used.\n\n * FG: Field Goal\n * TD: Touchdown\n * Int: Interception'","b""['american football', 'medium', 'featured']""",https://www.kaggle.com/kendallgillies/nflstatistics
b'Audio features of songs ranging from 1922 to 2011',b'A subset of the Million Song Database',"b""### Context\n\nThe Million Song Dataset (MSD) is a freely-available collection of audio features and metadata for a million contemporary popular music tracks. This is a subset of the MSD and contains audio features of songs with the year of the song. The purpose being to predict the release year of a song from audio features. \n\n### Content\n\nThe owners recommend that you split the data like this to avoid the 'producer effect' by making sure no song from a given artist ends up in both the train and test set.\n\n- train: first 463,715 examples \n- test: last 51,630 examples \n\nField descriptions:\n\n- The first value is the year (target), ranging from 1922 to 2011. \n- Then there are 90 attributes \n  - TimbreAverage[1-12]\n  - TimbreCovariance[1-78]\n\nThese features were extracted from the 'timbre' features from The Echo Nest API.  The authors took the average and covariance over all 'segments' and each segment was described by a 12-dimensional timbre vector.\n\n### Acknowledgements\n\nOriginal dataset: Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere. The Million Song Dataset. In Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR 2011), 2\n\nSubset downloaded from: https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd\n\n### Inspiration\n\nUse this dataset to predict the years that each song was released based on it's audio features""","b""['music', 'sound technology', 'medium', 'featured']""",https://www.kaggle.com/uciml/msd-audio-features
b'NYS Short-term Occupation and Industry Projections',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/tZw3fcjUIpM) by [Solomon Hsu](https://unsplash.com/@solimonster) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'employment', 'industry', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-short-term-occupation-and-industry-projections
b'Retailrocket recommender system dataset',"b'Ecommerce data: web events, item properties (with texts), category tree'","b'# Context \n\nThe dataset consists of three files: a file with behaviour data (events.csv), a file with item properties (item_properties.\xd1\x81sv) and a file, which describes category tree (category_tree.\xd1\x81sv). The data has been collected from a real-world ecommerce website. It is raw data, i.e. without any content transformations, however, all values are hashed due to confidential issues. The purpose of publishing is to motivate researches in the field of recommender systems with implicit feedback.\n\n# Content\n\nThe behaviour data, i.e. events like clicks, add to carts, transactions, represent interactions that were collected over a period of 4.5 months. A visitor can make three types of events, namely \xe2\x80\x9cview\xe2\x80\x9d, \xe2\x80\x9caddtocart\xe2\x80\x9d or \xe2\x80\x9ctransaction\xe2\x80\x9d. In total there are 2 756 101 events including 2 664 312 views, 69 332 add to carts and 22 457 transactions produced by  1 407 580 unique visitors. For about 90% of events corresponding properties can be found in the \xe2\x80\x9citem_properties.csv\xe2\x80\x9d file. \n\nFor example:\n\n -  \xe2\x80\x9c1439694000000,1,view,100,\xe2\x80\x9d means visitorId = 1, clicked the item with id = 100 at 1439694000000 (Unix timestamp)\n -   \xe2\x80\x9c1439694000000,2,transaction,1000,234\xe2\x80\x9d means visitorId  = 2 purchased the item with id = 1000 in transaction with id = 234 at 1439694000000 (Unix timestamp)\n\nThe file with item properties (item_properties.csv) includes 20 275 902 rows, i.e. different properties, describing 417 053 unique items. File is divided into 2 files due to file size limitations. Since the property of an item can vary in time (e.g., price changes over time), every row in the file has corresponding timestamp. In other words, the file consists of concatenated snapshots for every week in the file with the behaviour data. However, if a property of an item is constant over the observed period, only a single snapshot value will be present in the file.\nFor example, we have three properties for single item and 4 weekly snapshots, like below:\n\n    timestamp,itemid,property,value\n    1439694000000,1,100,1000\n    1439695000000,1,100,1000\n    1439696000000,1,100,1000\n    1439697000000,1,100,1000\n    1439694000000,1,200,1000\n    1439695000000,1,200,1100\n    1439696000000,1,200,1200\n    1439697000000,1,200,1300\n    1439694000000,1,300,1000\n    1439695000000,1,300,1000\n    1439696000000,1,300,1100\n    1439697000000,1,300,1100\nAfter snapshot merge it would looks like:\n\n    1439694000000,1,100,1000\n    1439694000000,1,200,1000\n    1439695000000,1,200,1100\n    1439696000000,1,200,1200\n    1439697000000,1,200,1300\n    1439694000000,1,300,1000\n    1439696000000,1,300,1100\nBecause property=100 is constant over time, property=200 has different values for all snapshots, property=300 has been changed once.\n\nItem properties file contain timestamp column because all of them are time dependent, since properties may change over time, e.g. price, category, etc. Initially, this file consisted of snapshots for every week in the events file and contained over 200 millions rows. We have merged consecutive constant  property values, so it\'s changed from snapshot form to change log form. Thus,  constant  values would appear only once in the file. This action has significantly reduced the number of rows in 10 times.\n\n All values in the \xe2\x80\x9citem_properties.csv\xe2\x80\x9d file excluding ""categoryid"" and ""available"" properties were hashed.  Value of the ""categoryid"" property contains item category identifier. Value of the ""available"" property contains availability of the item, i.e. 1 means the item was available, otherwise 0. All numerical values were marked with ""n"" char at the beginning, and have 3 digits precision after decimal point, e.g.,  ""5"" will become ""n5.000"", ""-3.67584"" will become ""n-3.675"". All words in text values were normalized (stemming procedure: https://en.wikipedia.org/wiki/Stemming) and hashed, numbers were processed as above, e.g. text ""Hello world 2017!"" will become ""24214 44214 n2017.000""\n\nThe category tree file has 1669 rows. Every row in the file specifies a child categoryId and the corresponding parent.\nFor example:\n\n - Line \xe2\x80\x9c100,200\xe2\x80\x9d means that categoryid=1 has parent with categoryid=200\n - Line \xe2\x80\x9c300,\xe2\x80\x9d means that categoryid hasn\xe2\x80\x99t parent in the tree\n\n# Acknowledgements\n\nRetail Rocket (retailrocket.io) helps web shoppers make better shopping decisions by providing personalized real-time recommendations through multiple channels with over 100MM unique monthly users and 1000+ retail partners over the world.\n\n# Inspiration\n\n - How to use item properties and category tree data to improve collaborative filtering model?\n - Recurrent Neural Networks with Top-k Gains for Session-based Recommendations https://github.com/hidasib/GRU4Rec  and paper https://arxiv.org/abs/1706.03847\n - https://www.researchgate.net/publication/280538158_Application_of_Kullback-Leibler_divergence_for_short-term_user_interest_detection\n - https://pdfs.semanticscholar.org/66dc/1724c4ed1e74fe6b22e636b52031a33c8ebe.pdf https://www.slideshare.net/LukasLerche/adaptation-and-evaluation-of-recommendationsfor-shortterm-shopping-goals   Adaptation and Evaluation of Recommendations for Short-term Shopping Goals\n\n# Tasks\n\n## Task 1\nWhen a customer comes to an e-commerce site, he looks for a product with particular properties: price range, vendor, product type and etc. These properties are implicit, so it\'s hard to determine them through clicks log. \n\nTry to create an algorithm which predicts properties of items in ""addtocart"" event by using data from ""view"" events for any visitor in the published log.\n\n## Task 2\n###Description: \n\nProcess of analyzing ecommerce data include very important part of data cleaning. Researchers noticed that in some cases browsing data include up to 40% of abnormal traffic.\n\nFirstly, abnormal users add a lot of noise into data and make recommendation system less effective. In order to increase efficiency of recommendation system, abnormal users should be removed from the raw data.\n\nSecondly, abnormal users add bias to results of split tests, so this type of users should be removed also from split test data.\n\n###Goals:\n - The main goal is to find abnormal users of e-shop.\n\n###Subgoals:\n - Generate features\n - Build a model\n - Create a metric that helps to evaluate quality of the model'","b""['internet', 'business', 'medium', 'featured']""",https://www.kaggle.com/retailrocket/ecommerce-dataset
b'NYS ZIP Codes-County FIPS Cross-Reference',b'From New York State Open Data',"b""### Content  \n\nA listing of NYS counties with accompanying Federal Information Processing System (FIPS) and US Postal Service ZIP codes sourced from the NYS GIS Clearinghouse.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/sPpe2D7VbpM) by [Maximillian Conacher](https://unsplash.com/@maxconacher) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-zip-codes-county-fips-cross-reference
b'OpenAddresses - U.S. Midwest',b'Addresses and geo locations for the U.S. Midwest',"b""### Context\n\nOpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates, street names, house numbers and postal codes. \n\n### Content\n\nThis dataset contains one datafile for each state in the U.S. Midwest region (although some are arguably not in the Midwest).\n\nStates included in this dataset:\n\n* Iowa - ia.csv\n* Illinois - il.csv\n* Indiana - in.csv\n* Kansas - ks.csv\n* Michigan - mi.csv\n* Minnesota - mn.csv\n* Missouri - mo.csv\n* North Dakota - nd.csv\n* Nebraska - ne.csv\n* Ohio - oh.csv\n* South Dakota - sd.csv\n* Wisconsin  -wi.csv\n\n\n\nField descriptions:\n\n* LON - Longitude\n* LAT - Latitude\n* NUMBER - Street number\n* STREET - Street name\n* UNIT - Unit or apartment number\n* CITY - City name\n* DISTRICT - ?\n* REGION - ?\n* POSTCODE - Postcode or zipcode\n* ID - ?\n* HASH - ?\n\n\n### Acknowledgements\n\nData collected around 2017-07-25 by OpenAddresses (http://openaddresses.io).\n\nAddress data is essential infrastructure. Street names, house numbers and\npostal codes, when combined with geographic coordinates, are the hub that\nconnects digital to physical places.\n\nData licenses can be found in LICENSE.txt.\n\nData source information can be found at\nhttps://github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources\n\n\n### Inspiration\n\nUse this dataset to create maps in conjunction with other datasets for housing prices, crime, or weather!""","b""['large', 'featured']""",https://www.kaggle.com/openaddresses/openaddresses-us-midwest
b'United States Code',b'The general and permanent laws of the United States',"b'The United States Code (""Code"") contains the general and permanent laws of the United States, arranged into 54 broad titles according to subject matter. The organization of the Code was originally established by Congress in 1926 with the enactment of the act of June 30, 1926, chapter 712. Since then, 27 of the titles, referred to as positive law titles, have been restated and enacted into law by Congress as titles of the Code. The remaining titles, referred to as non-positive law titles, are made up of sections from many acts of Congress that were either included in the original Code or subsequently added by the editors of the Code, i.e., the Office of the Law Revision Counsel, and its predecessors in the House of Representatives. Positive law titles are identified by an asterisk on the Search & Browse page. For an explanation of the meaning of positive law, see the Positive Law Codification page.\n\nEach title of the Code is subdivided into a combination of smaller units such as subtitles, chapters, subchapters, parts, subparts, and sections, not necessarily in that order. Sections are often subdivided into a combination of smaller units such as subsections, paragraphs, subparagraphs, clauses, subclauses, and items. In the case of a positive law title, the units are determined by Congress in the laws that enact and later amend the title. In the case of a non-positive law title, the organization of the title since 1926 has been determined by the editors of the Code and has generally followed the organization of the underlying acts [1] as much as possible. For example, chapter 7 of title 42 sets out the titles, parts, and sections of the Social Security Act as corresponding subchapters, parts, and sections of the chapter.\n\nIn addition to the sections themselves, the Code includes statutory provisions set out as statutory notes, the Constitution, several sets of Federal court rules, and certain Presidential documents, such as Executive orders, determinations, notices, and proclamations, that implement or relate to statutory provisions in the Code. The Code does not include treaties, agency regulations, State or District of Columbia laws, or most acts that are temporary or special, such as those that appropriate money for specific years or that apply to only a limited number of people or a specific place. For an explanation of the process of determining which new acts are included in the Code, see the About Classification page.\n\nThe Code also contains editorially created source credits, notes, and tables that provide information about the source of Code sections, their arrangement, the references they contain, and their history.\n\nThe law contained in the Code is the product of over 200 years of legislating. Drafting styles have changed over the years, and the resulting differences in laws are reflected in the Code. Similarly, Code editorial styles and policies have evolved over the 80-plus years since the Code was first adopted. As a result, not all acts have been handled in a consistent manner in the Code over time. This guide explains the editorial styles and policies currently used to produce the Code, but the reader should be aware that some things may have been done differently in the past. However, despite the evolution of style over the years, the accuracy of the information presented in the Code has always been, and will always remain, a top priority.\n\n### Content\n\nThis dataset is a snapshot of the XML version of the United States Code. It is not a suitable for any form of legal work and is intended for research purposes only. \n\nThe data are stored in a large json dictionary, indexed by the title of the code.\n\n### Acknowledgements\n\nThis dataset was released by the [United States Government Publishing Office][1]. You can find [the original dataset here][2]. \n\n\n  [1]: https://www.gpo.gov/\n  [2]: http://uscode.house.gov/download/download.shtml'","b""['government', 'law', 'medium', 'featured']""",https://www.kaggle.com/us-gpo/united-states-code
b'SF Commercial Wireless Telecom Facilities',b'From San Francisco Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Open Data Commons Public Domain Dedication and License""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/san-francisco/sf-commercial-wireless-telecom-facilities
b'World Language Family Map',b'Where are the world\xe2\x80\x99s language families used?',"b""### Context: \nGlottolog (http://glottolog.org) provides a comprehensive catalogue of the world's languages, language families and dialects. It assigns a unique and stable identifier (the Glottocode) to (in principle) all languoids, i.e. all families, languages, and dialects.\n\n### Content: \nThis dataset contains information on 1) the geographic location of languages and dialects, 2) their familial relationships and 3) a list of scholarly sources where information on languages was found.\n\n### Acknowledgements: \n\nThis dataset was the current version of Glottolog as of July 20, 2017. If you publish work using this dataset, please use the following citation:\n\nHammarstr\xc3\xb6m, Harald & Haspelmath, Martin & Forkel, Robert. 2017.\nGlottolog 3.0. Jena: Max Planck Institute for the Science of Human History.\n(Available online at http://glottolog.org, Accessed on 2017-03-23.)\n\n### Inspiration: \n\n* Can you plot the geographic location of each language family or langoid?\n* Where are most extinct languages found?\n* Can you find which language was documented in what decade? Which areas of the focus of more or less documentation?\n\n### You may also be interested in: \n\n* [Atlas of Pidgin and Creole Language Structures](https://www.kaggle.com/rtatman/atlas-of-pidgin-and-creole-language-structures)\n* [The Sign Language Analyses (SLAY) Database](https://www.kaggle.com/rtatman/sign-language-analyses)\n* [World Atlas of Language Structures: Information on the linguistic structures in 2,679 languages](https://www.kaggle.com/rtatman/world-atlas-of-language-structures)""","b""['linguistics', 'languages', 'geography', 'medium', 'featured']""",https://www.kaggle.com/rtatman/world-language-family-map
b'NYS State Park Annual Attendance Figures',b'From New York State Open Data',"b""### Content  \n\nThis data set contains the annual attendance figures for facilities operated by the New York State Office for Parks, Recreation and Historic Preservation (OPRHP).  The data is organized by OPRHP region and county.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/2x6vURol6cM) by [Hector Arguello Canals](https://unsplash.com/@harguello) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-state-park-annual-attendance-figures
b'NY School Districts',b'Geodata for NY School Districts',"b""### History\nAdditional geodata can be very useful in many directions of the data analysis, and New York City has a lot of open information to make this work much easier.\n\nI've created this dataset about NYC School Districts for combining with educational and demographical information.\n\n### Content\nThe data about areas, shapes, and coordinates of NYC School Districts can be found in the next five files:\n\n- nysd.dbf\n- nysd.prj\n- nysd.shp\n- nysd.shp.xml\n- nysd.shx\n\nThe files were downloaded from the official site [NYC Department of City Planning. Open Data](https://www1.nyc.gov/site/planning/data-maps/open-data/districts-download-metadata.page)\n\nHere the Lambert conformal conic projection (LCC) has the Earth Geodetic Parameter Set (EPSG) = 2263.\nThe World Geodetic System 1984, used in GPS, has EPSG = 4326.\n\n### Acknowledgements\nThis information was received from the official and free source and it is possible to download other shapefiles and to view the metadata for New York City Political, Administrative and Census geographies.\n\n### Usage\nThis dataset can be used to visualize data in the form of geographic maps and charts.\n\n### Improvement\nThe data could be transformed into a wider information system with statistics about education in NYC.""","b""['demographics', 'geography', 'small', 'featured']""",https://www.kaggle.com/olgabelitskaya/ny-school-districts
b'FIFA 18 Complete Player Dataset',"b'17k+ players, 70+ attributes extracted from the latest edition of FIFA'","b""**The Dataset you can play with.** \n\n\n----------\n\n\n### Context\n\nDataset for people who love data science and have grown up playing FIFA.\n\n\n----------\n\n\n### Content\n\n - Every player featuring in FIFA 18\n - 70+ attributes \n - Player and Flag Images\n - Playing Position Data\n - Attributes based on actual data of the latest  EA's FIFA 18 game\n - Attributes include on all player style statistics like Dribbling, Aggression, GK Skills etc.\n - Player personal data like Nationality, Photo, Club, Age, Wage, Salary etc.\n\n----------\n\n\n**Upcoming Update will Include :**\n\n - Team (National and Club) Data\n - Player Images in Zip folder\n - Betting Odds\n\nThe dataset contains all the statistics and playing attributes of all the players in the Full version of FIFA 18.\n\n\n----------\n\n\n### Data Source\n\nThe data is scraped from the website [https://sofifa.com][1] by extracting the Player personal data and Player Ids and then the playing and style statistics.\n\n\n----------\n![][2]\n\n----------\n\n\n### [Github Project][3]\n\n\n----------\n\n\n### Possible Explorations\n\n - Make your dream team\n - Analyse which Club or National Team has the best-rated players\n - Assess the strength of a team at a particular position\n - Analyse the team with the best dribbling speed\n - Co-relate between Age and Overall rating\n - Co-relate between Age and Nationality \n - Co-relate between Age and Potential \n\n*Could prove of immense value to Fantasy Premier League enthusiasts.*\n\nThese are just basic examples, sky is the limit. \n\n\n----------\n\n\n### Acknowledgements\n\nThe data has been crawled from the [https://sofifa.com][4] website.\n\n\n----------\n\n\n### Inspiration\n\nSeveral insights and correlations between player value, wage, age, and performance can be derived from the dataset. Furthermore, how do the players in this dataset compare against themselves in [last year's dataset](https://www.kaggle.com/artimous/complete-fifa-2017-player-dataset-global/data)?\n\n\n----------\n\n### Contributing\n\nChanges and Improvement suggestions are welcome. Feel free to comment new additions that you think are useful or drop a PR on the [github][5] project.\n\n\n  [1]: https://sofifa.com\n  [2]: https://wallpapershome.com/images/wallpapers/fifa-18-5120x2880-4k-screenshot-poster-e3-2017-13691.jpg\n  [3]: https://github.com/amanthedorkknight/fifa18-all-player-statistics\n  [4]: https://sofifa.com\n  [5]: https://github.com/amanthedorkknight/fifa18-all-player-statistics\n  [6]: https://www.paypal.me/AShrivastava961""","b""['video games', 'association football', 'popular culture', 'medium', 'featured']""",https://www.kaggle.com/thec03u5/fifa-18-demo-player-dataset
b'NYS Nursery Growers and Greenhouse',b'From New York State Open Data',"b""### Content  \n\nA listing of all certified nursery growers and greenhouses which are licensed by the Department of Agriculture and Markets. Licensing of nursery growers and greenhouses is intended to prevent the introduction of injurious insects, noxious weeds, and plant diseases into the state.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/B5PcDNbMu0M) by [Annie Spratt](https://unsplash.com/@anniespratt) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-nursery-growers-and-greenhouse
b'Vienna subway network',b'All subway stations and lines',"b""### Context\n\nI was reading articles about network analysis and wanted to get hands on experience. But coding alone is not as much fun as getting feedback and inspiration of the great Kaggle community. That's why I decided to publicly share this dataset about the metro stations and lines of the city I currently live - Austria's capital city of Vienna.\n\n### Content\n\nIt is a very simple graph data set to kick-start one's network analysis skills. Columns contain the stations, the lines and their color. In the rows, the connections between stations are recorded.\n\n### Inspiration\n\nI am eager to learn more about network analysis and in particular what kind of opportunities you have in this are of machine larning:\n* What kind of metrics are suitable to assess a transportation network, single stations or lines?\n* What kind of algorithms are out there to work with network analysis?\n\n### Acknowledgements\n\nThis is only a very small part of the Open Data Vienna efforts. Besides other topics, the platform provides  lots of data about public transportation, e.g. realtime subway data, spatial data of stations or statistical data about stations and lines. Tell me, if you are interested in more data about public transportation in vienna. I can help with translating the german website or get relevant data! Or go by yourself and see:  https://open.wien.gv.at/site/""","b""['cities', 'network analysis', 'transport', 'public transport', 'networks', 'small', 'featured']""",https://www.kaggle.com/lenapiter/vienna-subway-network
b'NYS Jail Population By County: Beginning  1997',b'From New York State Open Data',"b""### Content  \n\nA file containing the average daily census for county for each year displayed (e.g., daily counts are averaged and then divided by the number of days reported for that year).  The population report categorizes inmates by type of offender and includes:  Sentenced, Civil, Federal, Technical Parole Violators, State Readies and Other Unsentenced.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Bc_fvQNxmOc) by [Cole Patrick](https://unsplash.com/@colepatrick) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-jail-population-by-county-beginning-1997
b'NYS NYS Liquor Authority New Applications Received',b'From New York State Open Data',"b""### Content  \n\nLiquor License applications received  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/AaTZZqlZCww) by [Alex Holyoake](https://unsplash.com/@stairhopper) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'alcohol', 'manufacturing', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-nys-liquor-authority-new-applications-received
b'Geographically Annotated Civil War Corpus',b'Texts from the War of The Rebellion American Civil War archives',"b""WarOfTheRebellion is an annotated corpus of data from War of The Rebellion (a large set of American Civil War archives). It was built using [GeoAnnotate](https://github.com/utcompling/GeoAnnotate/).\n\nIt consists of two parts: a toponym corpus and a document-geolocation corpus.\n\n## Document geolocation corpus\n\nThe document geolocation corpus is found in two JSON files.\n\n* `wotr-docgeo-jan-5-2016-625pm-by-vol.json` gives the spans by volume.\n* `wotr-docgeo-jan-5-2016-625pm-80-0-20-by-split.json` gives the spans by split, with an 80-20 training/test split.\n\nIn both cases, the JSON data for an individual span consists of the following information:\n\n* The volume number, from War of the Rebellion.\n* The span character offsets, from corrected OCR'd text.\n* The text of the span in question.\n* The counts of individual words, using the tokenization algorithm followed in the paper (FIXME, name of paper). They are stored in a string, with a space separating word-count pairs and a colon separating the word from the count. The word itself is URL-encoded, i.e. a colon is represented as `%3A` and a percent character as `%25`.\n* The date (if available), extracted from the text using regular expressions.\n* The full [GeoJSON](http://geojson.org/) of the points and polygons annotated for the span.\n* The centroid of the points and polygons, computed first by taking the centroid of each polygon and then taking the centroid of the resulting set of annotated points and polygon-centroid points. The centroid is in the form of a size-2 array of longitude and latitude (the same as how points are stored in GeoJSON).\n\n## Toponym corpus\n\nThe Toponym corpus, otherwise known as WoTR-Topo, is given in two different formats. The first format is JSON format files, split into train and test. Geographic information for toponyms is given by the geojson standard, with annotations done in a stand-off style. \n\nNot everything that has been annotated is guaranteed to be correct. The creators encourage others to correct errors that they find in a branched repository and submit pull requests when corrections are made. \n\nFor questions regarding the corpus, please contact its creators Ben Wing (ben@benwing.com) and Grant DeLozier (grantdelozier@gmail.com). This data is reproduced here under the MIT license. Please see the file \xe2\x80\x9cLICENSE\xe2\x80\x9d for more information.\n\n[The ACL LAW paper describing the corpus and performing benchmark evaluation](http://aclanthology.info/papers/creating-a-novel-geolocation-corpus-from-historical-texts)""","b""['linguistics', 'united states', 'history', 'geography', 'war', 'medium', 'featured']""",https://www.kaggle.com/rtatman/geographically-annotated-civil-war-corpus
b'Individual Income Tax Statistics',b'Summaries of individual income tax returns by zip code',"b""ZIP Code data show selected income and tax items classified by State, ZIP Code, and size of adjusted gross income. Data are based on individual income tax returns filed with the IRS. The data include items, such as:\n\n- Number of returns, which approximates the number of households\n- Number of personal exemptions, which approximates the population\n- Adjusted gross income \n- Wages and salaries\n- Dividends before exclusion\n- Interest received  \n\n### Content\nFor details of the exact fields available, please see the field_definitions.csv. Please note that the exact fields available can change from year to year, this definitions file was generated by retaining only the most recent year's entry from the years which had pdf manuals. The associated IRS form numbers are the most likely to change over time. \n\n### Acknowledgements\n\nThis data was generated by the [Internal Revenue Service][1].\n\n\n  [1]: https://www.irs.gov/uac/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi""","b""['finance', 'government', 'medium', 'featured']""",https://www.kaggle.com/irs/individual-income-tax-statistics
"b'Taxi Routes of Mexico City, Quito and more'","b'Data collected from Taxi, Cabify and Uber trips, using EC Taximeter'","b""### Context\n\nThis dataset was collected using our App EC Taximeter. \n\nAn easy to use tool developed to compare fees, giving the user an accurate fee based on GPS to calculate a cost of the taxi ride. Due to the ability to verify that you are charged fairly, our App is very popular in several cities. We encourage our users to send us URLs with the taxi/transportation fees in their cities to keep growing our database.\n\n\xe2\x98\x85 Our App gets the available fares for your location based on your GPS, perfect when traveling and not getting scammed.\n\n\xe2\x98\x85 Users can start a taximeter in their own phone and check they are charged fairly\n\n\xe2\x98\x85 Several useful information is displayed to the user during the ride: Speed, Wait time, Distance, GPS update, GPS precision, Range of error.\n\n\xe2\x98\x85 Each fare has information available for reference like: Schedule, Minimum fee, Source, Last update.\n\n\xe2\x98\x85 It\xe2\x80\x99s possible to surf through several cities and countries which fares are available for use. If a fare is not in the app, now it\xe2\x80\x99s easier than ever to let us know thanks to Questbee Apps.\n\nWe invite users to contribute to our project and expect this data set to be useful, please don't hesitate to contact us to info@ashkadata.com to add your city or to contribute with this project.\n\n### Content\n\nThe data is collected from June 2016 until July 20th 2017. The data is not completely clean, many users forget to turn off the taximeter when done with the route. Hence, we encourage data scientist to explore it and trim the data a little bit\n\n\n### Acknowledgements\n\nWe have to acknowledge the valuable help of our users, who have contributed to generate this dataset and have push our growth by mouth to mouth recommendation.\n\n### Inspiration\n\nOur first inspiration for the App was after being scammed in our home city Quito. We started it as a tool for people to be fairly charged when riding a taxi. Currently with other transportation options available, we also help user to compare fares in their cities or the cities which they are visiting.\n\n###File descriptions\n\n    mex_clean.csv - the dataset contains information of routes in Mexico City\n    uio_clean.csv - the dataset contains information of routes in Quito Ecuador\n    bog_clean.csv - the dataset contains information of routes in Bogota\n    all-data_clean.csv - the dataset contains information of routes in different cities""","b""['road transport', 'telecommunications', 'medium', 'featured']""",https://www.kaggle.com/mnavas/taxi-routes-for-mexico-city-and-quito
b'NYS Active Sporting License Issuing Agents',b'From New York State Open Data',"b""### Content  \n\nThe name, mailing address and telephone number for the retail establishments and municipalities that sell hunting, fishing, and trapping licenses and associated privileges and permits.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/NSf27dNSCA0) by [Carl Heyerdahl](https://unsplash.com/@carlheyerdahl) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-active-sporting-license-issuing-agents
b'Mobile phone activity in a city',"b'Hourly phone calls, SMS and Internet communication of an entire city'","b'##Introduction\n\nThe Mobile phone activity dataset is composed by one week of Call Details Records (CDRs) from the city of Milan and the Province of Trentino (Italy). \n\n## Description of the dataset\nEvery time a user engages a telecommunication interaction, a Radio Base Station (RBS) is assigned by the operator and delivers the communication through the network. Then, a new CDR is created recording the time of the interaction and the RBS which handled it. The following activities are present in the dataset: \n\n - received SMS\n - sent SMS\n - incoming calls\n - outgoing calls\n - Internet activity\n\nIn particular, Internet activity is generated each time a user starts an Internet connection or ends an Internet connection. Moreover, during the same connection a CDR is generated if the connection lasts for more than 15\xe2\x80\x89min or the user transferred more than 5\xe2\x80\x89MB. \n\nThe datasets is spatially aggregated in a square cells grid. The area of Milan is composed of a grid overlay of 1,000 (squares with size of about 235\xc3\x97235\xe2\x80\x89meters. This grid is projected with the WGS84 (EPSG:4326) standard. For more details we link the original paper http://go.nature.com/2fcOX5E\n\nThe data provides CellID, CountryCode and all the aforementioned telecommunication activities aggregated every 60 minutes.\n\n\n## Original datasource\nThe Mobile phone activity dataset is a part of the Telecom Italia Big Data Challenge 2014, which is a rich and open multi-source aggregation of telecommunications, weather, news, social networks and electricity data from the city of Milan and the Province of Trentino (Italy).  The original dataset has been created by Telecom Italia in association with EIT ICT Labs, SpazioDati, MIT Media Lab, Northeastern University, Polytechnic University of Milan, Fondazione Bruno Kessler, University of Trento and Trento RISE.\nIn order to make it easy-to-use, here we provide a subset of telecommunications data that allows researchers to design algorithms able to exploit an enormous number of behavioral and social indicators. The complete version of the dataset is available at the following link: http://go.nature.com/2fz4AFr\n\n\n## Relevant, external, data sources\nThe presented datasets can be enriched by using census data provided by the Italian National Institute of Statistics (ISTAT) (http://www.istat.it/en/), a public research organization and the main provider of official statistics in Italy. The census data have been released for 1999, 2001 and 2011. \nThe dataset (http://www.istat.it/it/archivio/104317), released in Italian, is composed of four parts: Territorial Bases (Basi Territoriali), Administrative Boundaries (Confini Amministrativi), Census Variables (Variabili Censuarie) and data about Toponymy (Dati Toponomastici).\n\nMotivational video: https://www.youtube.com/watch?v=_d2_RWMsUKc\n\n\n## Relevant papers\nBlondel, Vincent D., Adeline Decuyper, and Gautier Krings. ""A survey of results on mobile phone datasets analysis."" *EPJ Data Science 4*, no. 1 (2015): 1.\n\nFrancesco Calabrese, Laura Ferrari, and Vincent D. Blondel. 2014. Urban Sensing Using Mobile Phone Network Data: A Survey of Research. *ACM Comput. Surv.* 47, 2, Article 25 (November 2014), 20 pages.\n\nEagle, Nathan, Michael Macy, and Rob Claxton. ""Network diversity and economic development."" *Science* 328, no. 5981 (2010): 1029-1031.\n\nLenormand, Maxime, Miguel Picornell, Oliva G. Cant\xc3\xba-Ros, Thomas Louail, Ricardo Herranz, Marc Barthelemy, Enrique Fr\xc3\xadas-Mart\xc3\xadnez, Maxi San Miguel, and Jos\xc3\xa9 J. Ramasco. ""Comparing and modelling land use organization in cities."" *Royal Society open science* 2, no. 12 (2015): 150449.\n\nLouail, Thomas, Maxime Lenormand, Oliva G. Cantu Ros, Miguel Picornell, Ricardo Herranz, Enrique Frias-Martinez, Jos\xc3\xa9 J. Ramasco, and Marc Barthelemy. ""From mobile phone data to the spatial structure of cities."" *Scientific reports* 4 (2014).\n\nDe Nadai, Marco, Jacopo Staiano, Roberto Larcher, Nicu Sebe, Daniele Quercia, and Bruno Lepri. ""The Death and Life of Great Italian Cities: A Mobile Phone Data Perspective."" *WWW*, 2016.\n\n\n## Citation\n**We** kindly **ask** people who use this dataset **to cite the following paper**, where this aggregation comes from:\n\nBarlacchi, Gianni, Marco De Nadai, Roberto Larcher, Antonio Casella, Cristiana Chitic, Giovanni Torrisi, Fabrizio Antonelli, Alessandro Vespignani, Alex Pentland, and Bruno Lepri. ""A multi-source dataset of urban life in the city of Milan and the Province of Trentino."" *Scientific data* 2 (2015).\n\n\n  [1]: http://'","b""['internet', 'cities', 'telecommunications', 'large', 'featured']""",https://www.kaggle.com/marcodena/mobile-phone-activity
b'Mr Donald Trump Speeches',b'Psychological profile of Donald Trump based on his spoken language',"b'**Context:**\n\nYoutube has introduced automatic generation of subtitles based on speech recognition of uploaded video. This dataset provides collection of subtitles Donald Trump\'s uploaded speeches. It serves as database for an introduction to algorithmic analysis of spoken language.\n\n**Content:**\n\nMr Donald Trump speeches dataset consists of 836 subtitles (sets of words) retrieved from Youtube playlists:\n""Donald Trump Speeches & Events"",\n""DONALD TRUMP SPEECHES & PRESS CONFERENCE"",\n""President Donald Trump Weekly Address 2017"",\n""President Donald Trump\'s First 100 Days | NBC News"",\n""Donald Trump Rally Speech Events Press Conference Rallies Playlist"".\n\nThis dataset consists of a single CSV file MrTrumpSpeeches.csv. The columns are: \'id\', \'playlist\', \'upload_date\', \'title\', \'view_count\', \'average_rating\', \'like_count\', \'dislike_count\', \'subtitles\', which are delimited with tilde character \'~\'.\n\nText data in columns \'subtitles\' is not sentence based, there are not commas or dots. It is only stream of words being translated from speech into text by GoogleVoice (more here https://googleblog.blogspot.com.au/2009/11/automatic-captions-in-youtube.html).\n\n**Acknowledgements:**\n\nThe data was downloaded using youtube-dl package. \n\n**Inspiration:**\n\nI\'m interested in psychological profiles of people speaking based on language used.\n(For example see https://medium.com/@TSchnoebelen/trump-does-not-talk-like-a-woman-breaking-news-gender-continues-to-be-complicated-and-confusing-4c0d28b41d7)'","b""['linguistics', 'politics', 'languages', 'psychology', 'presidents', 'medium', 'featured']""",https://www.kaggle.com/binksbiz/mrtrump
b'Mushroom Classification',b'Safe to eat or deadly poison?',"b'### Context\n\nAlthough this dataset was originally contributed to the UCI Machine Learning repository nearly 30 years ago, mushroom hunting (otherwise known as ""shrooming"") is enjoying new peaks in popularity. Learn which features spell certain death and which are most palatable in this dataset of mushroom characteristics. And how certain can your model be?\n\n### Content \n\nThis dataset includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family Mushroom drawn from The Audubon Society Field Guide to North American Mushrooms (1981). Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ""leaflets three, let it be\'\' for Poisonous Oak and Ivy.\n\n- **Time period**: Donated to UCI ML 27 April 1987\n\n### Inspiration\n\n- What types of machine learning models perform best on this dataset?\n\n- Which features are most indicative of a poisonous mushroom?\n\n### Acknowledgements\n\nThis dataset was originally donated to the UCI Machine Learning repository. You can learn more about past research using the data [here][1]. \n\n#[Start a new kernel][2]\n\n\n  [1]: https://archive.ics.uci.edu/ml/datasets/Mushroom\n  [2]: https://www.kaggle.com/uciml/mushroom-classification/kernels?modal=true'","b""['food and drink', 'small', 'featured']""",https://www.kaggle.com/uciml/mushroom-classification
b'ENEM 2015',"b'Data from ENEM 2015, the Brazilian High School National Exam.'","b'### Context\n\nThis dataset was downloaded from INEP, a department from the Brazilian Education Ministry. It contains data from the applicants for the 2015 National High School Exam.\n\n\n### Content\n\nInside this dataset there are not only the exam results, but the social and economic context of the applicants.\n\n\n### Acknowledgements\n\nThe original dataset is provided by INEP (http://portal.inep.gov.br/microdados). I removed some information from original files to fit the file size into the Kaggle constraints.\n\n\n### Inspiration\n\nThe objective is to explore the dataset to achieve a better understanding of the social and economic context of the applicants in the exams results.'","b""['education', 'large', 'featured']""",https://www.kaggle.com/gbonesso/enem2015
b'Crop Residue Cover Measurement',b'On the ground or in the air? ',"b'### Context\nIn commercial agriculture it is common practice to retain so-called crop residue (agricultural product left on the field after a harvest) on planting fields. This is a commonly recommended practice in [conservation agriculture](https://en.wikipedia.org/wiki/Conservation_agriculture).  \n\nThis dataset is a measurement of the adoption and impact of the methodology for a selection of agricultural fields. Six different crop residue coverage measurement methods are included: i) interviewee (respondent) estimation; ii) enumerator estimation visiting the field; iii) interviewee with visual-aid without visiting the field; iv) enumerator with visual-aid visiting the field; v) field picture collected with a drone and analyzed with image-processing methods and vi) satellite picture of the field analyzed with remote sensing methods. \n\n### Content\n\nThis dataset is a `CSV` file with a selection of characteristics about fields included in the sample.\n\n### Acknowledgements\n\nThis dataset was created as part of the following study: [""On the Ground or in the Air? A Methodological Experiment on\nCrop Residue Cover Measurement in Ethiopia""](https://link.springer.com/content/pdf/10.1007%2Fs00267-017-0898-0.pdf).\n\n### Inspiration\n\nWhat are the characteristics of the Ethiopian farmers sampled in this dataset? How well do they follow conservation practices?'","b""['survey analysis', 'agriculture', 'africa', 'small', 'featured']""",https://www.kaggle.com/fkosmowski/crop-residue-cover-measurement
b'Stack Overflow Tag Network',b'Network (links and nodes) of Stack Overflow tags based on Developer Stories',"b""### Context\n\nOn the data team at Stack Overflow, we spend a lot of time and energy thinking about tech ecosystems and how technologies are related to each other.  One way to get at this idea of relationships between technologies is **tag correlations**, how often technology tags at Stack Overflow appear together relative to how often they appear separately. One place we see developers using tags at Stack Overflow is on their [Developer Stories](https://stackoverflow.com/users/story/join), or professional profiles/CVs/resumes. If we are interested in how technologies are connected and how they are used together, developers' own descriptions of their work and careers is a great place to get that.\n\n### Content\n\nA network of technology tags from [Developer Stories](https://stackoverflow.com/users/story/join) on the Stack Overflow online developer community website.\n\nThis is organized as two tables:\n  \n**stack_network_links** contains links of the network, the source and target tech tags plus the value of the the link between each pair\n**stack_network_nodes** contains nodes of the network, the name of each node, which group that node belongs to (calculated via a cluster walktrap), and a node size based on how often that technology tag is used\n\n\n### Acknowledgements\n\nAll Stack Overflow user contributions are licensed under [CC-BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/) with [attribution required](http://blog.stackoverflow.com/2009/06/attribution-required/).\n""","b""['internet', 'programming languages', 'networks', 'small', 'featured']""",https://www.kaggle.com/stackoverflow/stack-overflow-tag-network
b'Swedish NER corpus',"b'~8000 sentences annotated for Swedish NER (PER, LOC, ORG, MISC)'","b'### Context\n\nBootstrapped and manually annotated NER Swedish web news from 2012. NER stands for Named entity recognition, and its used to describe entities in a text such as organisations, locations and people for instance. \n\nIts a very common operation in general NLP pipeline, and several algorithms can be used to train a model. Traditionally many NER systems were trained using some kind of CRF (conditionally random fields) approach, but nowadays many people successfully uses LSTM:s or other sequence based deep learning techniques.  \n\nA tutorial on how to use this dataset to train an NER for Stanford CoreNLP is available here https://medium.com/@klintcho/training-a-swedish-ner-model-for-stanford-corenlp-part-2-20a0cfd801dd\n\n### Content\n\nThe dataset is very simple and can easily be adapted into other formats, it is specifically adapted to CoreNLP NER. Thus the first column is a word. Second column (tab separated) is either the NER category (ORG, PER, LOC, MISC) or a 0 if it does not belong to any category (not an entity). Each word is separated by a new line, and each sentence is separated by an empty new line.\n\nSample structure (of two sentences, one three word sentence, and another 4 word sentence):\nApple     ORG\nis            0\nnice        0\n.              0\n\nPer         PER\nis            0\nnot         0\nsad        0\n\n\n### Acknowledgements\n\nText is annotated from http://spraakbanken.gu.se/eng/resource/webbnyheter2012. Thanks Norah Klintberg Sakal for helping out with the annotation and reviewing all annotations as well.\n\n### Inspiration\n\nFeel free to use this for whatever you like. As most datasets it would definitely benefit from becoming larger, feel free to create a pull request https://github.com/klintan/swedish-ner-corpus/ or update it here on Kaggle.'","b""['languages', 'small', 'featured']""",https://www.kaggle.com/andreasklintberg/swedish-ner-corpus
b'EEG-Alcohol',b'This data contains EEG correlates of genetic predisposition to alcoholism',"b""**Data Set Information:**\nThis data arises from a large study to examine EEG correlates of genetic predisposition to alcoholism. It contains measurements from 64 electrodes placed on subject's scalps which were sampled at 256 Hz (3.9-msec epoch) for 1 second. \n\nThere were two groups of subjects: alcoholic and control. Each subject was exposed to either a single stimulus (S1) or to two stimuli (S1 and S2) which were pictures of objects chosen from the 1980 Snodgrass and Vanderwart picture set. When two stimuli were shown, they were presented in either a matched condition where S1 was identical to S2 or in a non-matched condition where S1 differed from S2. \n\n\n**Attribute Information**\n\nEach trial is stored in its own file and will appear in the following format. \n\ntrial number\tsensor position  sample num    sensor value   subject identifier   matching condition   channel   name\t            time\n\n\n0\t                    FP1\t                     0\t                      -8.921\t              a\t                 S1 obj\t                   0\t co2a0000364\t0\n\n\n0\t                    AF8\t                    87\t               4.14\t                      a\t                 S1 obj\t                 33\t co2a0000364    0.33\n\n\nThe columns of data are: \n\nthe trial number, \n\nsensor position, \n\nsample number (0-255),\n\nsensor value (in micro volts), \n\nsubject identifier(Alcoholic(a) or Control (c)),\n\nmatching condition(a single object shown (S1 obj), object 2 shown in a matching condition (S2 match), and object 2 shown in non matching condition (S2 nomatch)), \n\nchannel number(0-63), \n\nname(a serial code assigned to each subject), \n\ntime(inverse of sample num measured in seconds)) \n\n\n**Acknowledgements**\n\nThere are no usage restrictions on this data. \n\nAcknowledgments for this data should made to Henri Begleiter at the Neurodynamics Laboratory at the State University of New York Health Center at Brooklyn. \n\n\nYou can check out more info about it on: https://archive.ics.uci.edu/ml/datasets/eeg+database""","b""['alcohol', 'neuroscience', 'signal processing', 'signal data', 'neurology', 'medium', 'featured']""",https://www.kaggle.com/nnair25/Alcoholics
b'NYC Property Sales',"b""A year's worth of properties sold on the NYC real estate market""","b""### Context\n\nThis dataset is a record of every building or building unit (apartment, etc.) sold in the New York City property market over a 12-month period.\n\n### Content\n\nThis dataset contains the location, address, type, sale price, and sale date of building units sold. A reference on the trickier fields:\n\n* `BOROUGH`: A digit code for the borough the property is located in; in order these are Manhattan (1), Bronx (2), Brooklyn (3), Queens (4), and Staten Island (5).\n* `BLOCK`; `LOT`: The combination of borough, block, and lot forms a unique key for property in New York City. Commonly called a `BBL`.\n* `BUILDING CLASS AT PRESENT` and `BUILDING CLASS AT TIME OF SALE`: The type of building at various points in time. See the glossary linked to below.\n\nFor further reference on individual fields see the [Glossary of Terms](http://www1.nyc.gov/assets/finance/downloads/pdf/07pdf/glossary_rsf071607.pdf). For the building classification codes see the [Building Classifications Glossary](http://www1.nyc.gov/assets/finance/jump/hlpbldgcode.html).\n\nNote that because this is a financial transaction dataset, there are some points that need to be kept in mind:\n\n* Many sales occur with a nonsensically small dollar amount: $0 most commonly. These sales are actually transfers of deeds between parties: for example, parents transferring ownership to their home to a child after moving out for retirement.\n* This dataset uses the financial definition of a building/building unit, for tax purposes. In case a single entity owns the building in question, a sale covers the value of the entire building. In case a building is owned piecemeal by its residents (a condominium), a sale refers to a single apartment (or group of apartments) owned by some individual.\n\n### Acknowledgements\n\nThis dataset is a concatenated and slightly cleaned-up version of the New York City Department of Finance's [Rolling Sales dataset](http://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page).\n\n### Inspiration\n\nWhat can you discover about New York City real estate by looking at a year's worth of raw transaction records? Can you spot trends in the market, or build a model that predicts sale value in the future?""","b""['cities', 'real estate', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/nyc-property-sales
b'Chicago Life Safety Evaluations (Deprecated 2015)',b'From City of Chicago Open Data',"b""### Content  \n\nOUTDATED. This dataset will not be updated further due to changes in how the source data are maintained. For more information on the City\xe2\x80\x99s life safety ordinance, see https://www.cityofchicago.org/city/en/depts/bldgs/provdrs/inspect/svcs/life_safety_high-riseordinance.html and the contact information on that page. --  This dataset is a listing of the report status of all residential buildings required to submit a Life Safety Evaluation under city ordinance. Because the Chicago building code has since 1975 required new high-rise residential buildings to be constructed with sprinkler systems, the Life Safety Ordinance mostly impacted high-rise residential buildings constructed prior to 1975.  This dataset does not describe the overall safety of a building, only whether or not the life safety evaluation was submitted and approved by the City of Chicago. Please note that the majority of reports \xe2\x80\x9cfailed\xe2\x80\x9d initially as a result of a new reporting process and changes to building standards.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is no longer updated.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/zZza888FSKg) by [Clem Onojeghuo](https://unsplash.com/@clemono2) on [Unsplash](https://unsplash.com/)\n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'safety', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-life-safety-evaluations-deprecated-2015
b'Library of Southern Literature',b'The full text of 115 influential works of Southern literature',"b'The goal of the ""Library of Southern Literature"" is to make one hundred of the most important works of Southern literature published before 1920 available world-wide for teaching and research. Currently, this collection includes over eighty titles that were digitized with special funding from the Chancellor and the University Library of the University of North Carolina at Chapel Hill.\nThe Southern United States has been a distinct region since the colonial period, and its literature has developed in connection with, but also divergently from American literature as a whole. The South claims prominent and world-renowned authors, including Edgar Allan Poe and Mark Twain, but also lesser known authors who created works that reflected Southern attitudes and experiences. Teachers of literature as well as historians and other scholars of Southern culture need access to literary texts that illustrate these differences, and many of these important Southern works are no longer in print and are not widely held in libraries.\nNoting this lack of available titles, the late Dr. Robert Bain volunteered to help Documenting the American South by developing the bibliography for it. Dr. Bain was a faculty member at the University of North Carolina at Chapel Hill and taught American and Southern literature from 1964 until 1995. He also co-edited five scholarly works on Southern writers. To prepare this bibliography of Southern Literature, Dr. Bain wrote to some fifty scholars throughout the United States who specialize in Southern and American literature requesting that they nominate what they considered to be the ten most important works of Southern literature published before 1920. From their responses, Dr. Bain compiled the bibliography on which this collection is based. He completed the list three months before his death in July 1996.\nWith additional funding from the University Library, this collection continues to grow. Dr. Joe Flora, professor of English at UNC-Chapel Hill, guides the expansion of this collection beyond Dr. Bain\'s original bibliography.\nThe original texts for the ""Library of Southern Literature"" come from the University Library of the University of North Carolina at Chapel Hill, which includes the Southern Historical Collection, one of the largest collections of Southern manuscripts in the country and the North Carolina Collection, the most complete printed documentation of a single state anywhere. The DocSouth Editorial Board, composed of faculty and librarians at UNC and staff from the UNC Press, oversees this collection and all other collections on Documenting the American South.\n\n### Context\n\nThe North American Slave Narratives collection at the University of North Carolina contains 344 items and is the most extensive collection of such documents in the world.\n\nThe physical collection was digitized and transcribed by students and library employees. This means that the text is far more reliable than uncorrected OCR output which is common in digitized archives.\n\nMore information about the collection and access to individual page images can be be found here: http://docsouth.unc.edu/neh\n\nThe plain text files have been optimized for use in Voyant and can also be used in text mining projects such as topic modeling, sentiment analysis and natural language processing. Please note that the full text contains paratextual elements such as title pages and appendices which will be included in any word counts you perform. You may wish to delete these in order to focus your analysis on just the narratives.\n\nThe .csv file acts as a table of contents for the collection and includes Title, Author, Publication Date a url pointing to the digitized version of the text and a unique url pointing to a version of the text in plain text (this is particularly useful for use with Voyant: http://voyant-tools.org/). \n\n### Copyright Statement and Acknowledgements\n\nWith the exception of ""Fields\'s Observation: The Slave Narrative of a Nineteenth-Century Virginian,"" which has no known rights, the texts, encoding, and metadata available in Open DocSouth are made available for use under the terms of a Creative Commons Attribution License (CC BY 4.0:http://creativecommons.org/licenses/by/4.0/). Users are free to copy, share, adapt, and re-publish any of the content in Open DocSouth as long as they credit the University Library at the University of North Carolina at Chapel Hill for making this material available.\n\nIf you make use of this data, considering letting the holder of the original collection know how you are using the data and if you have any suggestions for making it even more useful. Send any feedback to wilsonlibrary@unc.edu.\n\n### About the DocSouth Data Project\n\nDoc South Data provides access to some of the Documenting The American South collections in formats that work well with common text mining and data analysis tools.\n\nDocumenting the American South is one of the longest running digital publishing initiatives at the University of North Carolina. It was designed to give researchers digital access to some of the library\xe2\x80\x99s unique collections in the form of high quality page scans as well as structured, corrected and machine readable text.\n\nDoc South Data is an extension of this original goal and has been designed for researchers who want to use emerging technology to look for patterns across entire texts or compare patterns found in multiple texts. We have made it easy to use tools such as Voyant (http://voyant-tools.org/) to conduct simple word counts and frequency visualizations (such as word clouds) or to use other tools to perform more complex processes such as topic modeling, named-entity recognition or sentiment analysis.'","b""['linguistics', 'united states', 'history', 'literature', 'medium', 'featured']""",https://www.kaggle.com/docsouth-data/library-of-southern-literature
b'8a.nu Climbing Logbook',"b""Analyze the world's largest rock climbing logbook!""","b'### Context\n\nAnalyze the world\'s largest rock climbing logbook!\n\nWho\'s the biggest downgrader? Is it better to be short, tall, or average height? How many years does it take the average climber to send her first 5.12? After countless crag debates over these and similar topics, I set out to find the answers. Now you can prove statistically why that dude who tagged your multi-year project ""Soft"" is wrong. (Sorry, he might actually be right.)\n\n\n### Content\n\nI used Python3 to build a web-scraper to collect all of the user and ascent information from the world\'s largest rock climbing logbook, https://www.8a.nu/. I actually ended up scraping their beta site, https://beta.8a.nu/, as it provided well-formed JSON objects. The scraper dumps all of the data into an SQLite database. Check out https://github.com/dcohen21/8a.nu-Scraper for more information about the project. This dataset was collected on 9/13/2017.\n\nThe database consists of four tables: User, Ascent, Method, and Grade. \n\n\n### Acknowledgements\n\nThanks to Andrew Cassidy (https://github.com/andrewcassidy) for the idea and mentorship. Thanks to Jens Larssen and 8a.nu for creating the logbook and maintaining a thriving community.\n\n\n### Inspiration\n\nThe sky\'s the limit!'","b""['internet', 'sports', 'medium', 'featured']""",https://www.kaggle.com/dcohen21/8anu-climbing-logbook
b'OpenAddresses - U.S. West',b'Addresses and geo-locations for the U.S. West',"b""### Context\n\nOpenAddresses's goal is to connect the digital and physical worlds by sharing geographic coordinates, street names, house numbers and postal codes. \n\n### Content\n\nThis dataset contains one datafile for each state in the U.S. West region.\n\nStates included in this dataset:\n\n* Alaska - ak.csv\n* Arizona - az.csv\n* California - ca.csv\n* Colorado - co.csv\n* Hawaii - hi.csv\n* Idaho - id.csv\n* Montana - mt.csv\n* New Mexico - nm.csv\n* Nevada - nv.csv\n* Oregon - or.csv\n* Utah - ut.csv\n* Washington - wa.csv\n* Wyoming - wy.csv\n\nField descriptions:\n\n* LON - Longitude\n* LAT - Latitude\n* NUMBER - Street number\n* STREET - Street name\n* UNIT - Unit or apartment number\n* CITY - City name\n* DISTRICT - ?\n* REGION - ?\n* POSTCODE - Postcode or zipcode\n* ID - ?\n* HASH - ?\n\n\n### Acknowledgements\n\nData collected around 2017-07-25 by OpenAddresses (http://openaddresses.io).\n\nAddress data is essential infrastructure. Street names, house numbers and\npostal codes, when combined with geographic coordinates, are the hub that\nconnects digital to physical places.\n\nData licenses can be found in LICENSE.txt.\n\nData source information can be found at\nhttps://github.com/openaddresses/openaddresses/tree/9ea72b079aaff7d322349e4b812eb43eb94d6d93/sources\n\n\n### Inspiration\n\nUse this dataset to create maps in conjunction with other datasets for crime or weather""","b""['large', 'featured']""",https://www.kaggle.com/openaddresses/openaddresses-us-west
b'New York Stock Exchange',b'S&P 500 companies historical prices with fundamental data',"b""# Context \n\nThis dataset is a playground for fundamental and  technical analysis. It is said that 30% of traffic on stocks is already generated by machines, can trading be fully automated? If not, there is still a lot to learn from historical data.    \n\n# Content\n\nDataset consists of following files:\n\n - **prices.csv**: raw, as-is daily prices. Most of data spans from 2010 to the end 2016, for companies new on stock market date range is shorter. There have been approx. 140 stock splits in that time, this set doesn't account for that.\n - **prices-split-adjusted.csv**: same as prices, but there have been added adjustments for splits.\n - **securities.csv**: general description of each company with division on sectors\n - **fundamentals.csv**: metrics extracted from annual SEC 10K fillings (2012-2016), should be enough to derive most of popular fundamental indicators.\n\n# Acknowledgements\n\nPrices were fetched from Yahoo Finance, fundamentals are from Nasdaq Financials, extended by some fields from EDGAR SEC databases.\n\n# Inspiration\n\nHere is couple of things one could try out with this data:\n\n - One day ahead prediction: Rolling Linear Regression, ARIMA, Neural Networks, LSTM\n - Momentum/Mean-Reversion Strategies\n - Security clustering, portfolio construction/hedging\n\nWhich company has biggest chance of being bankrupt? Which one is undervalued (how prices behaved afterwards), what is Return on Investment?\n\n\n""","b""['finance', 'medium', 'featured']""",https://www.kaggle.com/dgawlik/nyse
b'chABSA dataset',b'Aspect Based Sentiment Analysis dataset in Japanese',"b'### Context\n\n[Aspect based sentiment analysis (ABSA)](http://alt.qcri.org/semeval2016/task5/) is important for understanding a sentence polarity and its ground. In spite of its significance, the dataset is available in few language and domain. \n\nWe provide the ABSA dataset in Japanese (chABSA-dataset). chABSA-dataset is built on the corporate analysis domain and it is the first ABSA dataset in Japanese to the best of our knowledge.  \n\n[Please refer our GitHub page!](https://github.com/chakki-works/chABSA-dataset)\n\n### Content\n\nThe annotation is based on the financial reports of companies in Japan in 2016 fiscal year. The number of report is 230 (10% of all listed companies). Each annotation contains the pair of entity (e.g., business, product) and the attribute (e.g., sales, profit, cost), and its sentiment (positive, negative, neutral). This dataset includes 6,119 sentences and 3,215 of these have one or more entities. The total number of entities is 7,723.\n\n### Inspiration\n\nThis dataset is inspired by [SemEval Shared Task](http://alt.qcri.org/semeval2016/task5/).\n'","b""['classification', 'business', 'small', 'featured']""",https://www.kaggle.com/takahirokubo0/chabsa
"b'English Premier League Players Dataset, 2017/18'","b'A unique dataset containing FPL data, popularity and market values'","b""### Context\n\nFor most football fans, May - July represents a lull period due to the lack of club football. What makes up for it, is the intense transfer speculation that surrounds all major player transfers today. Their market valuations also lead to a few raised eyebrows, lately more than ever.  I was curious to see how good a proxy **popularity** could be for **ability**, and the predictive power it would have in a model estimating a player's market value. \n\n\n### Content\n\n**name**: Name of the player\n   \n**club**: Club of the player\n  \n**age** : Age of the player\n  \n**position** : The usual position on the pitch  \n\n**position_cat** :  \n   \n+ 1 for attackers  \n\n+ 2 for midfielders  \n\n+ 3 for defenders  \n\n+ 4 for goalkeepers   \n\n**market_value** : As on transfermrkt.com on July 20th, 2017  \n\n**page_views** : Average daily Wikipedia page views from September 1, 2016 to May 1, 2017  \n\n**fpl_value** : Value in Fantasy Premier League as on July 20th, 2017  \n\n**fpl_sel** : % of FPL players who have selected that player in their team  \n\n**fpl_points** : FPL points accumulated over the previous season  \n\n**region**:  \n \n+ 1 for England  \n\n+ 2 for EU  \n\n+ 3 for Americas  \n\n+ 4 for Rest of World   \n\n**nationality**   \n\n**new_foreign** : Whether a new signing from a different league, for 2017/18 (till 20th July)  \n\n**age_cat**  \n\n**club_id**  \n\n**big_club**: Whether one of the Top 6 clubs  \n\n**new_signing**: Whether a new signing for 2017/18 (till 20th July)  \n\n\n\n### Inspiration\n\nTo statistically analyse the beautiful game.""","b""['sports', 'popular culture', 'association football', 'small', 'featured']""",https://www.kaggle.com/mauryashubham/english-premier-league-players-dataset
b'Sentiment Lexicons for 81 Languages',b'Sentiment Polarity Lexicons (Positive vs. Negative)',"b'### Context: \n\nSentiment analysis, the task of automatically detecting whether a piece of text is positive or negative, generally relies on a hand-curated list of words with positive sentiment (good, great, awesome) and negative sentiment (bad, gross, awful). This dataset contains both positive and negative sentiment lexicons for 81 languages.\n\n### Content: \n\nThe sentiment lexicons in this dataset were generated via graph propagation based on a knowledge graph--a graphical representation of real-world entities and the links between them. The general intuition is that words which are closely linked on a  knowledge graph probably have similar sentiment polarities. For this project, sentiments were generated based on English sentiment lexicons. \n\nThis dataset contains sentiment lexicons for the following languages:\n\n* Afrikaans\n* Albanian\n* Arabic\n* Aragonese\n* Armenian\n* Azerbaijani\n* Basque\n* Belarusian\n* Bengali\n* Bosnian\n* Breton\n* Bulgarian\n* Catalan\n* Chinese\n* Croatian\n* Czech\n* Danish\n* Dutch\n* Esperanto\n* Estonian\n* Faroese\n* Finnish\n* French\n* Galician\n* Georgian\n* German\n* Greek\n* Gujarati\n* Haitian Creole\n* Hebrew\n* Hindi\n* Hungarian\n* Icelandic\n* Ido\n* Indonesian\n* Interlingua\n* Irish\n* Italian\n* Kannada\n* Khmer\n* Kirghiz\n* Korean\n* Kurdish\n* Latin\n* Latvian\n* Lithuanian\n* Luxembourgish\n* Macedonian\n* Malay\n* Maltese\n* Marathi\n* Norwegian\n* Norwegian\n* Persian\n* Polish\n* Portuguese\n* Romanian\n* Romansh\n* Russian\n* Scottish\n* Serbian\n* Slovak\n* Slovene\n* Spanish\n* Swahili\n* Swedish\n* Tagalog\n* Tamil\n* Telugu\n* Thai\n* Turkish\n* Turkmen\n* Ukrainian\n* Urdu\n* Uzbek\n* Vietnamese\n* Volap\xc3\xbck\n* Walloon\n* Welsh\n* Western Frisian\n* Yiddish\n\n For more information and additional sentiment lexicons, please visit [the project\xe2\x80\x99s website](https://sites.google.com/site/datascienceslab/projects/multilingualsentiment). \n\n### Acknowledgements: \n\nThis dataset was collected by Yanqing Chen and Steven Skiena. If you use it in your work, please cite the following paper:\n\nChen, Y., & Skiena, S. (2014). Building Sentiment Lexicons for All Major Languages. In ACL (2) (pp. 383-389).\n\nIt is distributed here under the [GNU General Public License](http://www.gnu.org/licenses/gpl-3.0.html). Note that this is the full GPL, which allows many free uses, but does not allow its incorporation into any type of distributed proprietary software, even in part or in translation. For commercial applications please contact the dataset creators.\n\n### Inspiration:\n\n* These word lists contain many words with similar meanings. Can you automatically detect which words are [cognates](https://en.wikipedia.org/wiki/Cognate)?\n* Can you use these sentiment lexicons to reverse-engineer the knowledge graphs that generated them?'","b""['linguistics', 'languages', 'small', 'featured']""",https://www.kaggle.com/rtatman/sentiment-lexicons-for-81-languages
b'NYC Oil Usage (Select City Owned Buildings)',b'From New York City Open Data',"b""### Content  \n\nOil Usage (select City Owned Buildings), oil, city, data, statistics,heating, energy,heat  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.""","b""['socrata', 'statistics', 'energy', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-oil-usage-select-city-owned-buildings
b'California Kindergarten Immunization Rates',b'How many new students contributed to \xe2\x80\x9cherd immunity\xe2\x80\x9d between 2000 and 2015?',"b'### Context\n\nVaccinations provide people the ability to develop immunity to particular diseases.  When the majority of a population is vaccinated, \xe2\x80\x9cherd immunity\xe2\x80\x9d protects those who have not been vaccinated by blocking the spread of these diseases.  A medical research paper published by The Lancet in 1998 suggested an association between the Measles/Mumps/Rubella (MMR) vaccine and Autism spectrum disorders.  The paper was later fully-retracted due controversy surrounding the lead author, who had financial conflicts of interest and allegedly manipulated the study data.  However, it generated worldwide concern over the safety of MMR and other types of vaccines, including Diphtheria/Tetanus/Pertussis (DTP).\n\nIn California by 2010, the growing trend for parents to opt out of having their children receive vaccines over the following decade coincided with the largest Pertussis outbreak in more than 60 years.  Reduced vaccination frequency was also linked to a high-profile measles outbreak in 2014 that began at Disneyland.  The resulting California state legislation (Senate Bill 277), signed June 2015, made it much more difficult for parents to opt out of vaccinations for their children.  The data set will allow you to explore individual public and private school vaccination rates of incoming Kindergarten students for the 2000 to 2014 school years.\n\n\n### Content\n\nThe data are records for every school with ten or more students reporting the number of incoming Kindergarteners who provided either proof of immunization, personal beliefs exemption (PBE), or permanent medical exemption (PME).  Annual records for the 2000-2001 through 2014-2015 school years have been formatted and combined.  Common variables in these annual data sets included in the merged file are the number of students, school name, school county, the number of PBEs, PMEs, and number of students vaccinated for:\n\n - Diphtheria/Tetanus/Pertussis (DTP)  \n - Polio \n - Measles/Mumps/Rubella (MMR)\n\nOne additional file contains 5 years of county-level Pertussis case numbers and rates.  Another additional data file contains the number of infant Pertussis cases for infants under three months old for each county in California between 2014-2015.\n\nGeographic data are available in a file based on scripted geocode calls using the ggmap R package to find latitude and longitude data using the school names and county names.  Not all calls returned a valid coordinate, so additional indicator variables in this file indicate the quality of the match.  The isSchool indicator variable is 1 if the geocode search meta data included ""school"" and the countyMatch indicator is 1 if the latitude and longitude coordinates are contained within the appropriate county in CA.\n\n----------\n\nReferences:\n\n 1. [Retracted Lancet Research Article][1] \n 2. [Report on 2010 Pertussis Outbreak][2]\n\n### Acknowledgements\n\nIndividual data files and detailed annual reports for every school year in this data set are provided by the California Department of Public Health (CDPH).  Individual schools and licensed child care facilities are required to report immunization information to CDPH every year to maintain compliance with the California Health and Safety Code.  Additional details as well as child care and 7th grade data files can be found on the CDPH website:\nhttps://www.cdph.ca.gov/programs/immunize/Pages/ImmunizationLevels.aspx\n\nCounty level case data were pulled from the following report:\nhttps://archive.cdph.ca.gov/programs/immunize/Documents/Pertussis_Report_1-7-2015.pdf\n\nInfant Pertussis data were reported to CDPH as of 2/10/2016.  Additional Pertussis reports can be found here:\nhttps://www.cdph.ca.gov/programs/immunize/Pages/PertussisSummaryReports.aspx\n\n\n### Inspiration\n\nWhile the Disneyland measles outbreak received much media attention, Pertussis outbreaks in California present great health risks to infants and the elderly.  Can you predict which counties and schools are at greatest risk for outbreaks and/or quantify the association between vaccination rates and the number infant Pertussis cases?\n\n\n  [1]: http://www.thelancet.com/journals/lancet/article/PIIS0140-6736(97)11096-0/abstract\n  [2]: http://www.jpeds.com/article/S0022-3476(12)00558-6/abstract'","b""['public health', 'diseases', 'small', 'featured']""",https://www.kaggle.com/broach/california-kindergarten-immunization-rates
b'Spy Plane Finder',b'Identify Candidate US Government Spy Planes',"b'### Context: \nBuzzFeed had [previously reported](https://www.buzzfeed.com/peteraldhous/spies-in-the-skies) on flights of spy planes operated by the FBI and the Department of Homeland Security (DHS), and reasoned that it should be possible to train a machine learning algorthim to identify other aircraft performing similar surveillance, based on characteristics of the aircraft and their flight patterns. You can read the story [here](https://www.buzzfeed.com/peteraldhous/hidden-spy-planes), and additional analysis and code by [Peter Aldhous](https://github.com/paldhous) can be found [here](https://github.com/BuzzFeedNews/2017-08-spy-plane-finder).\n\n### Content: \nBuzzFeed News obtained more than four months of aircraft transponder detections from the plane tracking website [Flightradar24](https://www.flightradar24.com), covering August 17 to December 31, 2015 [UTC](http://www.timeanddate.com/time/aboututc.html), containing all data displayed on the site within a bounding box encompassing the continental United States, Alaska, Hawaii, and Puerto Rico.\n\nFlightradar24 receives data from its network of ground-based receivers, supplemented by a feed from ground radars provided by the Federal Aviation Administration (FAA) with a five-minute delay.\n\nAfter parsing from the raw files supplied by Flightradar24, the data included the following fields, for each transponder detection:\n\n- `adshex` Unique identifier for each aircraft, corresponding to its ""[Mode-S](http://www.skybrary.aero/index.php/Mode_S)"" code, in hexademical format.\n- `flight_id` Unique identifier for each ""flight segment,"" in hexadecimal format. A flight segment is a continuous series of transponder detections for one aircraft. There may be more than one segment per flight, if a plane disappears from Flightradar24\'s coverage for a period --- for example when flying over rural areas with sparse receiver coverage. While being tracked by Fightradar24, planes were typically detected several times per minute.\n- `latitude`, `longitude` Geographic location in digital degrees.\n- `altitude` Altitude in feet.\n- `speed` Ground speed in knots.\n- `squawk` Four-digit code transmitted by the transponder.\n- `type` Aircraft manufacter and model, if identified.\n- `timestamp` Full UTC timestamp.\n- `track` Compass bearing in degrees, with 0 corresponding to north.\n\nWe also calculated:\n\n- `steer` Change in compass bearing from the previous transponder detection for that aircraft; negative values indicate a turn to the left, positive values a turn to the right.\n\n## Feature engineering\n\nFirst we filtered the data to remove planes registered abroad, based on their `adshex` code, common commercial airliners, based on their `type`, and aircraft with fewer than 500 transponder detections.\n\nThen we took a random sample of 500 aircraft and calculated the following for each one:\n\n- `duration` of each flight segment recorded by Flightradar24, in minutes.\n- `boxes` Area of a rectangular bounding box drawn around each flight segment, in square kilometers.\n\nFinally, we calculated the following variables for each of the aircraft in the larger filtered dataset:\n\n- `duration1`,`duration2`,`duration3`,`duration4`,`duration5` Proportion of flight segment durations for each plane falling into each of five quantiles calculated from `duration` for the sample of 500 planes. The proportions for each aircraft must add up to 1; if the durations of flight segments for a plane closely matched those for a typical plane from the sample, these numbers would all approximate to 0.2; a plane that mostly flew very long flights would have large decimal fraction for `duration5`.\n- `boxes1`,`boxes2`,`boxes3`,`boxes4`,`boxes5` Proportion of bounding box areas for each plane falling into each of five quantiles calculated from `boxes` for the sample of 500 planes.\n- `speed1`,`speed2`,`speed3`,`speed4`,`speed5` Proportion of `speed` values recorded for the aircraft falling into each of five quantiles recorded for `speed` for the sample of 500 planes.\n- `altitude1`,`altitude2`,`altitude3`,`altitude4`,`altitude5` Proportion of `altitude` values recorded for the aircraft falling into each of five quantiles recorded for `altitude` for the sample of 500 planes.\n- `steer1`,`steer2`,`steer3`,`steer4`,`steer5`,`steer6`,`steer7`,`steer8` Proportion of `steer` values for each aircraft falling into bins set manually, after observing the distribution for the sample of 500 planes, using the breaks: -180, -25, -10, -1, 0, 1, 22, 45, 180.\n- `flights` Total number of flight segments for each plane.\n- `squawk_1` Squawk code used most commonly by the aircraft.\n- `observations` Total number of transponder detections for each plane.\n- `type` Aircraft manufacter and model, if identified, else `unknown`.\n\nThe resulting data for 19,799 aircraft are in the file `planes_features.csv`.\n\n\n### Acknowledgements: \nThis dataset was created by [Peter Aldhous](https://github.com/BuzzFeedNews/2017-08-spy-plane-finder) from raw [Flightradar24](https://github.com/BuzzFeedNews/2017-08-spy-plane-finder) data, as well as [FAA](http://registry.faa.gov/aircraftinquiry/) data.\n\n### Inspiration: \n* Peter used a Random Forest classifier--would another approach be better? Worse?\n* Compare your list of candidates to his [here](https://github.com/BuzzFeedNews/2017-08-spy-plane-finder/tree/master/data).\n* This data is from 2015--can you grab up to date data from [ADS-B Exchange](https://www.adsbexchange.com/) and find any new candidate planes?'","b""['government', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/jboysen/spy-plane-finder
b'Social Power NBA',"b'NBA on the court performance with Social Influence, Popularity and Power'","b'### Context\n\nThis data set contains combined on-court performance data for NBA players in the 2016-2017 season, alongside salary, Twitter engagement, and Wikipedia traffic data.\n\nFurther information can be found in a series of articles for IBM Developerworks: [""Explore valuation and attendance using data science and machine learning""](https://www.ibm.com/developerworks/library/ba-social-influence-python-pandas-machine-learning-r-1/) and [""Exploring the individual NBA players""](https://www.ibm.com/developerworks/analytics/library/ba-social-influence-python-pandas-machine-learning-r-2/). \n\nA talk about this dataset has slides from March, 2018, Strata:\n\nhttps://www.slideshare.net/noahgift/social-power-andinfluenceinthenba-89807740?qid=3f9f835a-f3d7-4174-8a8c-c97f9c82e614&v=&b=&from_search=1\n\nFurther reading on this dataset is in the book [Pragmatic AI, in Chapter 6][1] or full book, [Pragmatic AI:  An introduction to Cloud-based Machine Learning][2] and watch lesson 9 in [Essential Machine Learning and AI with Python and Jupyter Notebook][3]\n\n### Acknowledgement\n\nData sources include ESPN, Basketball-Reference, Twitter, Five-ThirtyEight, and Wikipedia. The source code for this dataset (in Python and R) can be found [on GitHub](https://github.com/noahgift/socialpowernba). Links to more writing can be found at [noahgift.com](http://noahgift.com).\n\n### Inspiration\n\n* Do NBA fans know more about who the best players are, or do owners?  \n* What is the true worth of the social media presence of athletes in the NBA?\n\n\n  [1]: https://www.safaribooksonline.com/library/view/pragmatic-ai-an/9780134863924/ch06.xhtml#ch06\n  [2]: https://www.amazon.com/gp/product/0134863860/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0134863860&linkCode=as2&tag=pragmaticai-20&linkId=a467451d9cd0205e8d5eee595c6f9f47\n[3]:  https://www.safaribooksonline.com/videos/essential-machine-learning/9780135261118'","b""['sports', 'twitter', 'basketball', 'income', 'social groups', 'small', 'featured']""",https://www.kaggle.com/noahgift/social-power-nba
b'Mathematicians of Wikipedia',"b""A Dataset of the World's Most Famous Mathematicians""","b'### Context\n\nWhat distinguishes the great from the good, the remembered from the accomplished, and the genius from the merely brilliant? Scrapping English Wikipedia, Joseph Philleo has cleaned and compiled a database of more than 8,500 famous mathematicians for the Kaggle data science community to analyze and better understand.\n\n### Inspiration\n\n - What are the common characteristics of famous mathematicians?\n - How old do they live, which fields do they work in, where are they born, and where do they live?\n - Can you predict which mathematicians will win a Fields Medal, join the Royal Society, or secure tenure at Harvard?'","b""['internet', 'demographics', 'mathematics', 'people', 'medium', 'featured']""",https://www.kaggle.com/joephilleo/mathematicians-on-wikipedia
b'A Year of Pumpkin Prices',b'Pumpkin Prices in 13 US Cities: 2016-2017',"b'### Context: \n\nOver 1.5 billions pounds of pumpkin are grown annually in the United States. Where are they sold, and for how much?\n\nThis dataset contains prices for which pumpkins were sold at selected U.S. cities\xe2\x80\x99 terminal markets. Prices are differentiated by the commodities\xe2\x80\x99 growing origin, variety, size, package and grade.\n\n### Content: \n\nThis dataset contains terminal market prices for different pumpkin crops in 13 cities in the United States from September 24, 2016 to September 30, 2017. In keeping with the structure of the original source data, information on each city has been uploaded as a separate file.\n\n* Atlanta, GA\n* Baltimore, MD\n* Boston, MA\n* Chicago, IL\n* Columbia, SC\n* Dallas, TX\n* Detroit, MI\n* Los Angeles, CA\n* Miami, FL\n* New York, NY\n* Philadelphia, PA\n* San Francisco, CA\n* Saint Louis, MO\n\nData for each city includes the following columns (although not all information is available for every city) \n\n* Commodity Name: Always pumpkin, since this is a pumpkin-only dataset\n* City Name: City where the pumpkin was sold\n* Type\n* Package\n* Variety\n* Sub Variety\n* Grade: In the US, usually only canned pumpkin is graded\n* Date: Date of sale (rounded up to the nearest Saturday)\n* Low Price\n* High Price\n* Mostly Low\n* Mostly High\n* Origin: Where the pumpkins were grown\n* Origin District\n* Item Size\n* Color\n* Environment\n* Unit of Sale\n* Quality\n* Condition\n* Appearance\n* Storage\n* Crop\n* Repack: Whether the pumpkin has been repackaged before sale\n* Trans Mode\n\n### Acknowledgements: \n\nThis dataset is based on Specialty Crops Terminal Markets Standard Reports distributed by the United States Department of Agriculture. Up-to-date reports can be generated [here](https://www.marketnews.usda.gov/mnp/fv-report-config-step1?type=termPrice). This data is in the public domain.\n\n### Inspiration: \n\n* Which states produce the most pumpkin?\n* Where are pumpkin prices highest?\n* How does pumpkin size relate to price?\n* Which pumpkin variety is the most expensive? Least expensive?\n'","b""['finance', 'food and drink', 'united states', 'agriculture', 'small', 'featured']""",https://www.kaggle.com/usda/a-year-of-pumpkin-prices
b'Upvoted Kaggle Kernels',b'Metadata on more than 900 of the most upvoted Kaggle kernels',"b""### Context\n\nBeside datasets, kernels in Kaggle are interesting features. We can learn, share, and furthermore, contribute to others. I collected metadata from highly voted kernels in Kaggle so that people can explore many things.\n\n\n### Content\n\nThis dataset contains 971 most favorited kernels in 12 columns:  \n* Votes (number of votes)    \n* Owner  \n* Kernel (name of the kernel)    \n* Dataset  \n* Version History  \n* Tags  \n* Output  \n* Code type (script/notebook)    \n* Language (Python/R)  \n* Comments (number of comments)    \n* Views (number of views)    \n* Forks (number of forks)    \n\n\n### Acknowledgements\n\nAll data were taken from Kaggle's website on 26 Feb 2018.\n\n\n### Inspiration\n\nWhat makes people vote your kernel? What are the trends of highly voted kernels? Who has the biggest number of accumulated votes? etc""","b""['databases', 'information', 'small', 'featured']""",https://www.kaggle.com/canggih/upvoted-kaggle-kernels
b'Crop Nutrient Database',b'USDA data about crop nutrients in the U.S.',"b""### Context\n\nThe PLANTS Database provides standardized information about the vascular plants, mosses, liverworts, hornworts, and lichens of the U.S. and its territories. It includes names, plant symbols, checklists, distributional data, species abstracts, characteristics, images, plant links, references, and crop information, and automated tools.\n\nThis particular dataset is the Crop Nutrient Database.\n\n### Content\n \nThese are the fields included in the dataset. I'll be honest, I have no idea what some of them mean:\n\n- Crop\n- ScientificName\n- Symbol\n- NuContAvailable\n- PlantPartHarvested\n- CropCategory\n- YieldUnit\n- AvYieldUnitWeight(lb)\n- AvMoisture%\n- AvN%(dry)\n- AvP%(dry)\n- AvK%(dry)\n- YieldUnitWeight(lb)_set\n- YieldUnitWeight(lb)_Bau\n- YieldUnitWeight(lb)_Joh\n- YieldUnitWeight(lb)_Roberts\n- YieldUnitWeight(lb)_WEEP\n- YieldUnitWeight(lb)_Men\n- YieldUnitWeight(lb)_Guy\n- YieldUnitWeight(lb)_Mc\n- YieldUnitWeight(lb)_Mah\n- YieldUnitWeight(lb)_Sha\n- YieldUnitWeight(lb)_Sch\n- YieldUnitWeight(lb)_Atu\n- YieldUnitWeight(lb)_Zim\n- YieldUnitWeight(lb)_Scu\n- YieldUnitWeight(lb)_John\n- YieldUnitWeight(lb)_Arc\n- DryMatter%_M-FF\n- DryMatter%_NAS\n- DryMatter%_F&L\n- DryMatter%_F&N\n- DryMatter%_Alb\n- DryMatter%_Est1\n- DryMatter%_Est2\n- DryMatter%_Est3\n- DryMatter%_Est4\n- DryMatter%_Est5\n- DryMatter%_Est6\n- DryMatter%_M&R\n- DryMatter%_M&L\n- DryMatter%_Sun\n- DryMatter%_Gro\n- DryMatter%_AgH8-9\n- DryMatter%_AgH8-12\n- DryMatter%_B788\n- AvDryMatter%\n- N%(dry)_NAS\n- N%(dry)_F&L\n- N%(dry)_F&N\n- N%(dry)_Swa\n- N%(dry)_Chapko\n- N%(dry)_Hill\n- N%(dry)_Bru\n- N%(dry)_AgH8-9\n- N%(dry)_AgH8-12\n- N%(dry)_B788\n- N%(dry)_M&L\n- N%(dry)_M-FF\n- N%(dry)_M&R\n- N%(dry)_Foster\n- N%(dry)_Rob1\n- N%(dry)_Rob2\n- N%(dry)_Coa\n- N%(dry)_And\n- N%(dry)_Gol1\n- N%(dry)_Gol2\n- N%(dry)_Wol\n- N%(dry)_Pete\n- N%(dry)_Col\n- N%(dry)_Alb\n- N%(dry)_Arc\n- N%(dry)_Bis\n- N%(dry)_Gar\n- N%(dry)_Heg\n- N%(dry)_Flo\n- N%(dry)_Feil\n- N%(dry)_Bre\n- N%(dry)_Burns\n- N%(dry)_Coc\n- P%(dry)_M-FF\n- P%(dry)_NAS\n- P%(dry)_F&L\n- P%(dry)_F&N\n- P%(dry)_AgH8-9\n- P%(dry)_AgH8-12\n- P%(dry)_B788\n- P%(dry)_M&L\n- P%(dry)_L&V\n- P%(dry)_Foster\n- P%(dry)_Rob1\n- P%(dry)_Rob2\n- P%(dry)_Coa\n- P%(dry)_And\n- P%(dry)_Gol1\n- P%(dry)_Gol2\n- P%(dry)_Sims\n- P%(dry)_Wol\n- P%(dry)_Pete\n- P%(dry)_Col\n- P%(dry)_Alb\n- P%(dry)_Arc\n- P%(dry)_Swa\n- P%(dry)_Rei\n- K%(dry)_M-FF\n- K%(dry)_NAS\n- K%(dry)_F&L\n- K%(dry)_F&N\n- K%(dry)_AgH8-9\n- K%(dry)_AgH8-12\n- K%(dry)_B788\n- K%(dry)_Foster\n- K%(dry)_Rob1\n- K%(dry)_Rob2\n- K%(dry)_Coa\n- K%(dry)_And\n- K%(dry)_Gol1\n- K%(dry)_Gol2\n- K%(dry)_Sims\n- K%(dry)_Wol\n- K%(dry)_Pete\n- K%(dry)_Col\n- K%(dry)_Alb\n- K%(dry)_Arc\n- K%(dry)_Swa\n- K%(dry)_Rei\n- Moisture%_M&R\n- Moisture%_M&L\n- Moisture%_Sun\n- Moisture%_Gro\n- gWater/100g_AgH8-9\n- gWater/100g_AgH8-12\n- gWater/100g_B788\n- Protein%(dry)_NAS\n- Protein%(dry)_F&L\n- Protein%(dry)_F&N\n- Protein%(dry)_Swa\n- Protein%(dry)_Chapko\n- Protein%(dry)_Hill\n- Protein%(dry)_Bru\n- Protein%(dry)_Bis\n- Protein%(dry)_Gar\n- Protein%(dry)_Heg\n- Protein%(dry)_Flo\n- Protein%(dry)_Feil\n- Protein%(dry)_Bre\n- Protein%(dry)_Burns\n- gProtein/100g(wet)_AgH8-9\n- gProtein/100g(wet)_AgH8-12\n- gProtein/100g(wet)_B788\n- Protein%(wet)_M&L\n- N%(wet)_M-FF\n- P%(wet)_M-FF\n- gP/100g(wet)_AgH8-9\n- gP/100g(wet)_AgH8-12\n- gP/100g(wet)_B788\n- P%(wet)_M&L\n- K%(wet)_M-FF\n- gK/100g(wet)_AgH8-9\n- gK/100g(wet)_AgH8-12\n- gK/100g(wet)_B788\n\n""","b""['food and drink', 'united states', 'health', 'plants', 'science and culture', 'small', 'featured']""",https://www.kaggle.com/crawford/crop-nutrient-database
b'History of Hearthstone',"b'346,242 decks representing more than 3 years of gameplay!'","b'## Context\n\n[Hearthstone](http://eu.battle.net/hearthstone/en/) is a very popular collectible card game published by [Blizzard Entertainment](http://blizzard.com) in 2014. The goal of the game consists in building a 30 cards deck in order to beat your opponent. A few weeks ago, I decided to download all the decks posted by players at [Hearthpwn](http://www.hearthpwn.com/). The code to download the data is available [here](https://github.com/rmnvncnt/pystone/tree/master).\n\n## Content\n\nThis upload is composed of two files :\n\n### `data.json` / `data.csv`\nContains the actual Hearthstone deck records. Each record features :\n\n * **date (str)** : the date of publication (or last update) of the deck.\n * **user (str)** : the user who uploaded the deck.\n * **deck_class (str)** : one of the nine character class in Hearthstone (`Druid`, `Priest`, ...).\n * **deck_archetype (str)** : the theme of deck labelled by the user (`Aggro Druid`, `Dragon Priest`, ...).\n * **deck_format (str)** : the game format of the deck on the day data was recorded (`W` for ""Wild"" or `S` for ""Standard"").\n * **deck_set (str)** : the latest expansion published prior the deck publication (`Naxxramas`, `TGT Launch`, ...).\n * **deck_id (int)** : the ID of the deck.\n * **deck_type (str)** : the type of the deck labelled by the user :\n    - *Ranked Deck* : a deck played on ladder.\n    - *Theorycraft* : a deck built with unreleased cards to get a gist of the future metagame.\n    - *PvE Adventure* : a deck built to beat the bosses in adventure mode.\n    - *Arena* : a deck built in arena mode.\n    - *Tavern Brawl* : a deck built for the weekly tavern brawl mode.\n    - *Tournament* : a deck brought at tournament by a pro-player.\n    - *None* : the game type was not mentioned.\n    \n * **rating (int)** : the number of upvotes received by that deck.\n * **title (str)** : the name of the deck.\n * **craft_cost (int)** : the amount of dust (in-game craft material) required to craft the deck.\n * **cards (list)** : a list of 30 card ids. Each ID can be mapped to the card description using the reference file.\n\n### `refs.json` \nContains the reference to the cards played in Hearthstone. This file was originally proposed on [HearthstoneJSON](https://hearthstonejson.com/). Each record features a lot of informations about the cards, I\'ll list the most important :\n\n* **dbfId (int)** : the id of the card (the one used in `data.json`).\n* **rarity (str)** : the rarity of the card (`EPIC`, `RARE`, ...).\n* **cardClass (str)** : the character class (`WARLOCK`, `PRIEST`, ...).\n* **artist (str)** : the artist behind the card\'s art.\n* **collectible (bool)** : whether or not the card can be collected.\n* **cost (int)** : the card play cost.\n* **health (int)** : the card health (if it\'s a minion).\n* **attack (int)** : the card attack (if it\'s a minion).\n* **name (str)** : the card name.\n* **flavor (str)** : the card\'s flavor text.\n* **set (str)** : the set / expansion which featured this card.\n* **text (int)** : the card\'s text.\n* **type (str)** : the card\'s type (`MINION`, `SPELL`, ...).\n* **race (str)** : the card\'s race (if it\'s a minion).\n* **set (str)** : the set / expansion which featured this card.\n* ...\n\nIf you need help cleaning the data take a look at my [start over kernel](https://www.kaggle.com/romainvincent/exploration-classification/)!\n\n## What you could do :\n\n* Try to predict the deck archetype based on the cards features in the deck.\n* Seek relationships between the cost of the deck and it\'s popularity.\n* Describe the evolution of the meta-game over-time.\n* Find out unbalanced (overplayed) cards'","b""['video games', 'medium', 'featured']""",https://www.kaggle.com/romainvincent/history-of-hearthstone
b'Airbnb Property Data from Texas',"b'Dataset of 18,000+ properties'","b""### Context\n\nSharing economy and vacation rentals are among the hottest topics that has touched millions of lives across the globe. Airbnb has been instrumental in this space and currently operating in more than 191 countries. Hence, it'd be good idea to analyze this data and uncover insights.\n\n### Content\n\nDataset contains more than 18,000 property listings from Texas, United Staes. Given below are the data fields:\n\nRate per night\nNumber of bedrooms\nCity\nJoining month and year\nLongitude\nLatitude\nProperty description\nProperty title\nProperty URL\n\nThe Airbnb data was extracted by [PromptCloud\xe2\x80\x99s][1] Data-as-a-Service solution.\n\n### Initial Analysis\n\nThe following article covers spatial data visualization and topic modelling of the description text:\nhttp://www.kdnuggets.com/2017/08/insights-data-mining-airbnb.html\n\n### Inspiration\n\nSome of the interesting analysis are related to spatial mapping and text mining of the description text apart from the exploratory analysis.\n\n  [1]: https://promptcloud.com/?utm_source=kaggle""","b""['united states', 'hotels', 'small', 'featured']""",https://www.kaggle.com/PromptCloudHQ/airbnb-property-data-from-texas
b'Deep Sea Corals',b'Coral Records from NOAA\xe2\x80\x99s Deep-Sea Coral Research and Technology Program',"b'### Context\n\nThis dataset contains information about deep sea corals and sponges collected by NOAA and NOAA\xe2\x80\x99s partners. Amongst the data are geo locations of deep sea corals and sponges and the whole thing is tailored to the occurrences of **azooxanthellates** - a subset of all corals and all sponge species (i.e. they don\'t have symbiotic relationships with certain microbes).  Additionally, these records only consists of observations deeper than 50 meters to truly focus on the *deep sea* corals and sponges.\n\n### Content:\n\nColumn descriptions:\n\n- CatalogNumber: Unique record identifier assigned by the Deep-Sea Coral Research and Technology Program.\n- DataProvider: The institution, publication, or individual who ultimately deserves credit for acquiring or aggregating the data and making it available.\n- ScientificName: Taxonomic identification of the sample as a Latin binomial.\n- VernacularNameCategory: Common (vernacular) name category of the organism.\n- TaxonRank: Identifies the level in the taxonomic hierarchy of the ScientificName term.\n- ObservationDate: Time as hh:mm:ss when the sample/observation occurred (UTC).\n- Latitude (degrees North): Latitude in decimal degrees where the sample or observation was collected.\n- Longitude (degrees East): Longitude in decimal degrees where the sample or observation was collected.\n- DepthInMeters: Best single depth value for sample as a positive value in meters.\n- DepthMethod: Method by which best singular depth in meters (DepthInMeters) was determined. ""Averaged"" when start and stop depths were averaged. ""Assigned"" when depth was derived from bathymetry at the location. ""Reported"" when depth was reported based on instrumentation or described in literature.\n- Locality: A specific named place or named feature of origin for the specimen or observation (e.g., Dixon Entrance, Diaphus Bank, or Sur Ridge). Multiple locality names can be separated by a semicolon, arranged in a list from largest to smallest area (e.g., Gulf of Mexico; West Florida Shelf, Pulley Ridge).\n- IdentificationQualifier: Taxonomic identification method and level of expertise. Examples: \xe2\x80\x9cgenetic ID\xe2\x80\x9d; \xe2\x80\x9cmorphological ID from sample by taxonomic expert\xe2\x80\x9d; \xe2\x80\x9cID by expert from image\xe2\x80\x9d; \xe2\x80\x9cID by non-expert from video\xe2\x80\x9d; etc. \n- SamplingEquipment: Method of data collection. Examples: ROV, submersible, towed camera, SCUBA, etc.\n- RecordType: Denotes the origin and type of record. published literature (""literature""); a collected specimen (""specimen""); observation from a still image (""still image""); observation from video (""video observation""); notation without a specimen or image (""notation""); or observation from trawl surveys, longline surveys, and/or observer records (""catch record"").\n\n### Acknowledgements\n\nBig shout out to NOAA and it\'s partners. Thank you for being scientists! \nThe original and probably more up-to-date dataset can be found here: [https://deepseacoraldata.noaa.gov/website/AGSViewers/DeepSeaCorals/mapSites.htm][1]\n\nThis dataset hasn\'t been changed in anyway.\n\nNOAA (2015) National Database for Deep-Sea Corals and Sponges (version 20170324-0). https://deepseacoraldata.noaa.gov/; NOAA Deep Sea Coral Research & Technology Program.\n\n### Inspiration\n\nWho doesn\'t love coral and sponges?!  I challenge you to find the best algorithm that successfully SAVES the world\'s corals 100% of the time! \n\n  [1]: https://deepseacoraldata.noaa.gov/website/AGSViewers/DeepSeaCorals/mapSites.htm'","b""['biology', 'oceans', 'fishing', 'science and culture', 'oceanography', 'medium', 'featured']""",https://www.kaggle.com/noaa/deep-sea-corals
b'NYS Key Credit Collection: Beginning 2010',b'From New York State Open Data',"b""### Content  \n\nQuarterly snapshot of residential collection data submitted by New York State\xe2\x80\x99s ten largest distribution utility companies.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/UnPhQSAVbdk) by [rawpixel](https://unsplash.com/@rawpixel) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'utility', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-key-credit-collection-beginning-2010
b'Zuckerberg Testimony',b'Transcript of Testimony given to Congress',"b'### Context\n\nOn April 10 and April 11, 2018, Zuckerberg began testifying before the&nbsp;United States Senate Committee on Commerce, Science, and Transportation&nbsp;regarding the usage of personal data by Facebook in relation to the&nbsp;Facebook\xe2\x80\x93Cambridge Analytica data breach.  Source: https://en.wikipedia.org/wiki/Mark_Zuckerberg#Testimony_before_U.S._Congress\n\n### Content\n\nText of congressional testimony in the form of a CSV file with columns ""Person"" and ""Text"".\n\n### Acknowledgements\n\nWe wouldn\'t be here without the help of others.\n\n### Inspiration\n\nNLP analysis'","b""['internet', 'politics', 'united states', 'small', 'featured']""",https://www.kaggle.com/gunnvant/zuckerberg-testimony
b'Boatos de WhatsApp e outros do BoatosOrg (pt + es)',b'1900 boatos (pt) + 130 rumores (es) desmentidos por boatos.org',"b'### Contexto\n\nBoatos s\xc3\xa3o compartilhados em milhares de grupos todos os dias no WhatsApp, enganando muitos brasileiros. Para tentar combater esses boatos, eu imaginei que possa ter algum padr\xc3\xa3o nesses textos, para tentar identific\xc3\xa1-los automaticamente e combater esse problema usando Machine Learning.\n\nPara isso, eu precisava de datos, ent\xc3\xa3o criei esse dataset fazendo scrapping de todos os boatos falsos dos sites [boatos.org](http://www.boatos.org/) e [hablillas.org](http://hablillas.org/), que est\xc3\xa3o nesses CSVs para que voc\xc3\xaa possa explorar \xc3\xa0 vontade.\n\nSe quiser saber mais sobre o que fiz com esses dados, d\xc3\xaa uma olhada no projeto [Fake News Detector](https://fakenewsdetector.org/).\n\n### Conte\xc3\xbado\n\nO dataset cont\xc3\xa9m o texto do boato em si, o link desmentindo o boato e a data que ele foi dementido pelo boatos.org, ou pelo hablillas.org para os rumores em espanhol.\n\nO c\xc3\xb3digo usado para fazer scrapping desses dados est\xc3\xa1 no [reposit\xc3\xb3rio do github](https://github.com/fake-news-detector/scrappers).\n\n### Ideias para explorar\n\n- Existe algum padr\xc3\xa3o de escrita nos boatos?\n- Boatos costumam ter mais emojis que conversas comuns?\n- Quem s\xc3\xa3o as pessoas que mais aparecem nos boatos? Dilma? Temer? Pabllo Vittar?\n- Olhando as datas, est\xc3\xa3o surgindo boatos cada vez mais r\xc3\xa1pido?\n- Podemos identificar e bloquear um boato no whatsapp antes que ele se espalhe?\n\n### Agradecimentos\n\nMuito obrigado \xc3\xa0 equipe do boatos.org que me permitiu publicar este dataset para experimentos fututos'","b""['internet', 'small', 'featured']""",https://www.kaggle.com/rogeriochaves/boatos-de-whatsapp-boatosorg
b'NYC Queens Library Branches',b'From New York City Open Data',"b""### Content  \n\nHours and locations of Queens Library Branches  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/-_eCaEXMSqg) by [Vidar Nordli-Mathisen](https://unsplash.com/@vidarnm) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'libraries', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-queens-library-branches
b'Hard Drive Test Data',b'Daily Snapshot of Each Operational Hard Drive in 2016',"b""## Context\n\nEach day, Backblaze takes a snapshot of each operational hard drive that includes basic hard drive information (e.g., capacity, failure) and S.M.A.R.T. statistics reported by each drive. This dataset contains data from the first two quarters in 2016.\n\n## Content \n\nThis dataset contains basic hard drive information and 90 columns or raw and normalized values of 45 different S.M.A.R.T. statistics. Each row represents a daily snapshot of one hard drive.\n\n* **date**: Date in yyyy-mm-dd format\n\n* **serial_number**: Manufacturer-assigned serial number of the drive\n\n* **model**: Manufacturer-assigned model number of the drive\n\n* **capacity_bytes**: Drive capacity in bytes\n\n* **failure**: Contains a \xe2\x80\x9c0\xe2\x80\x9d if the drive is OK. Contains a \xe2\x80\x9c1\xe2\x80\x9d if this is the last day the drive was operational before failing.\n\n* **90 variables that begin with 'smart'**: Raw and Normalized values for 45 different SMART stats as reported by the given drive\n\n## Inspiration\n\nSome items to keep in mind as you process the data:\n\n* S.M.A.R.T. statistic can vary in meaning based on the manufacturer and model. It may be more informative to compare drives that are similar in model and manufacturer\n\n* Some S.M.A.R.T. columns can have out-of-bound values\n\n* When a drive fails, the 'failure' column is set to 1 on the day of failure, and starting the day after, the drive will be removed from the dataset. Each day, new drives are also added. This means that total number of drives each day may vary. \n\n* S.M.A.R.T. 9 is the number of hours a drive has been in service. To calculate a drive's age in days, divide this number by 24.\n\nGiven the hints above, below are a couple of questions to help you explore the dataset:\n\n1. What is the median survival time of a hard drive? How does this differ by model/manufacturer?\n\n2. Can you calculate the probability that a hard drive will fail given the hard drive information and statistics in the dataset?\n\n## Acknowledgement\n\nThe original collection of data can be found [here](https://www.backblaze.com/b2/hard-drive-test-data.html). When using this data, Backblaze asks that you cite Backblaze as the source; you accept that you are solely responsible for how you use the data; and you do not sell this data to anyone.""","b""['computer science', 'electrical components', 'large', 'featured']""",https://www.kaggle.com/backblaze/hard-drive-test-data
"b'Landslides After Rainfall, 2007-2016'",b'Location and cause of landslide events around the world',"b'# Context\n\nLandslides are one of the most pervasive hazards in the world, causing more than 11,500 fatalities in 70 countries since 2007. Saturating the soil on vulnerable slopes, intense and prolonged rainfall is the most frequent landslide trigger.\n\n\n# Content\n\nThe Global Landslide Catalog (GLC) was developed with the goal of identifying rainfall-triggered landslide events around the world, regardless of size, impacts, or location. The GLC considers all types of mass movements triggered by rainfall, which have been reported in the media, disaster databases, scientific reports, or other sources.\n\n\n# Acknowledgements\n\nThe GLC has been compiled since 2007 at NASA Goddard Space Flight Center.'","b""['climate', 'geology', 'mountains', 'small', 'featured']""",https://www.kaggle.com/nasa/landslide-events
b'Stanford Open Policing Project - Bundle 2',b'Data on Traffic and Pedestrian Stops by Police in many states',"b""###Context: \n\nOn a typical day in the United States, police officers make more than 50,000 traffic stops. The Stanford Open Policing Project team is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public.\n\nIf you'd like to see data regarding other states, please go to https://www.kaggle.com/stanford-open-policing.\n\n### Content: \n\nThis dataset includes stop data from MS, MT, ND, NH, NJ, NV, OR, RI, SD, TN,  VA, V, WI, and WY. Please see the data readme for the full details of the available fields.\n\n###Acknowledgements:\n\nThis dataset was kindly made available by the [Stanford Open Policing Project][1]. If you use it for a research publication, please cite their [working paper][2]:\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, V. Ramachandran, C. Phillips, S. Goel. (2017) \xe2\x80\x9cA large-scale analysis of racial disparities in police stops across the United States\xe2\x80\x9d.\n\n###Inspiration: \n\n - How predictable are the stop rates? Are there times and places that\n   reliably generate stops?\n - Concerns have been raised about jurisdictions using civil forfeiture\n   as a funding mechanism rather than to properly fight drug\n   trafficking. Can you identify any jurisdictions that may be\n   exhibiting this behavior?\n\n  [1]: https://openpolicing.stanford.edu/\n  [2]: https://5harad.com/papers/traffic-stops.pdf""","b""['crime', 'law', 'government agencies', 'large', 'featured']""",https://www.kaggle.com/stanford-open-policing/stanford-open-policing-project-bundle-2
b'NY DCAS Managed Building Energy Usage',b'From New York City Open Data',"b""### Content  \n\nCity Building Energy Usage Data.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/S1326piyGBE) by [Johny Goerend](https://unsplash.com/@johnygoerend) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'energy', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-dcas-managed-building-energy-usage
"b'Primetime Emmy Awards, 1949-2017'",b'Which television show has won the most Emmy Awards?',"b""### Context\nWe are working on a project relating to predicting and voting for Academy Award. With the Primetime Emmy Awards coming up this week, I thought it would be interesting to see if I could integrated those. I couldn't find too many well organized datasets relating to those awards.  I decided to spend the afternoon and build my own.  We probably won't use this information this year,  but it might be something we could use in the future. \n\n### Content\nI created a simple web parser in Go, and parsed the data from the [Emmy Awards Website][1]. The data is a representation of Primetime Emmy Nominees from the first Emmy Awards (1949)... to the current ones that will air Sunday September 17th, 2017.  After this date, the winner will have to be updated. \nIn work we've done with Academy Awards, we used movie title and name as the main structure for the data. I kind of felt this was a little inconsistent as certain awards focus on one or the other. With the Emmy Nominees, I made it more general with nominee and additional detail, I believe this will make the data more consistent and easier to manipulate.\n\n### Acknowledgements\nI based the structure of the data from the Kaggle dataset of the [Academy Awards][2] . I would also like to acknowledge the Academy of Television Arts & Sciences for providing the data on their [website][1].\n\n\n### Inspiration\nWho won the most Emmys for Outstanding Comedy Series?\nI think it would be cool, if we could answer:\nWho will win the Emmy for Outstanding Comedy Series in 2018? \nBut, I think we more than just historical data. \n\n  [1]: https://www.emmys.com/\n  [2]: https://www.kaggle.com/theacademy/academy-awards""","b""['entertainment', 'telecommunications', 'actors', 'small', 'featured']""",https://www.kaggle.com/pmagda/primetime-emmy-awards
b'UFC Rankings',b'Historical UFC rankings',"b""### Content\n\nThis dataset contains the historical rankings of UFC fighters. From their inception in 2013 up until now. The rankings are published weekly, more or less, by the UFC and compiled via a vote by media members. God bless.\n\nIn each weight class, the fighters are listed by the ranking, except for the belt holder who is ranked at 0.\n\nThe dataset isn't 100% complete, there are weeks missing here and there but I'd say it's over 90% complete. Rankings are published only after UFC events so every 2-3 week period without new rankings does not necessarily mean missing data.\n\n\n### Acknowledgements\n\nThe data was pulled from The Internet Archive's records of ufc.com.""","b""['sports', 'ranking', 'small', 'featured']""",https://www.kaggle.com/martj42/ufc-rankings
b'Annotated Corpus for Named Entity Recognition',b'Feature Engineered Corpus annotated with IOB and POS tags',"b'**Context**:\nAnnotated Corpus for Named Entity Recognition using GMB(Groningen Meaning Bank) corpus for entity classification with enhanced and popular features by Natural Language Processing applied to the data set.\n\n> Tip: Use Pandas Dataframe to load dataset if using Python for convenience.\n\n**Content**:\nThis is the extract from GMB corpus which is tagged, annotated and built specifically to train the classifier to predict named entities such as name, location, etc.\n\n----------\n*Number of tagged entities*:\n\n```\n\'O\': 1146068\', geo-nam\': 58388, \'org-nam\': 48034, \'per-nam\': 23790, \'gpe-nam\': 20680, \'tim-dat\': 12786, \'tim-dow\': 11404, \'per-tit\': 9800, \'per-fam\': 8152, \'tim-yoc\': 5290, \'tim-moy\': 4262, \'per-giv\': 2413, \'tim-clo\': 891, \'art-nam\': 866, \'eve-nam\': 602, \'nat-nam\': 300, \'tim-nam\': 146, \'eve-ord\': 107, \'per-ini\': 60, \'org-leg\': 60, \'per-ord\': 38, \'tim-dom\': 10, \'per-mid\': 1, \'art-add\': 1\n```\n\n*Essential info about entities*:\n\n- geo = Geographical Entity\n- org = Organization\n- per = Person\n- gpe = Geopolitical Entity\n- tim = Time indicator\n- art = Artifact\n- eve = Event\n- nat = Natural Phenomenon\n\n\nTotal Words Count = 1354149\nTarget Data Column: ""tag""\n\n**Inspiration**: This dataset is getting more interested because of more features added to the recent version of this dataset. Also, it helps to create a broad view of **Feature Engineering** with respect to this dataset.\n\nWhy this dataset is helpful or playful?\n\nIt might not sound so interested for earlier versions, but when you are able to pick intent and custom named entities from your own sentence with more features then, it is getting interested and helps you solve real business problems(like picking entities from Electronic Medical Records, etc)\n\nPlease, feel free to ask questions, do variations and let\'s play together!\n'","b""['linguistics', 'medium', 'featured']""",https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus
b'London Fire Brigade Calls',b'32k Calls to London Fire Brigade',"b""### Context: \nLondon's fire and rescue service is the busiest in England and one of the largest firefighting and rescue organisations in the world. In the aftermath of the Grenfell Tower fire, it is critical that firefighting resources are accurately and appropriately deployed.\n\n### Content: \nThis data covers Jan 01-April 30 2017, consisting of 32 columns containing information on time, type, and address of call, as well the home station, stay duration, and arrival time of attending pumps.\n\n### Acknowledgements: \nThis dataset was compiled by the [City of London](http://www.london-fire.gov.uk/). You can use Kernels to analyze, share, and discuss this data on Kaggle, but if you\xe2\x80\x99re looking for real-time updates and bigger data, check out the [data on BigQuery, too](https://cloud.google.com/bigquery/public-data/).\n\n### Inspiration: \n* Which boroughs have the shortest average call response? Longest?\n* Which boroughs have the greatest volume of calls?""","b""['government', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/jboysen/london-fire
b'SkillCraft-StarCraft',b'Classifying Starcraft 2 league-level performance',"b'### Context\nDataset of Starcraft 2 games, played in different leagues/levels. \n\n### Content\nScreen movements aggregated into screen-fixations. \n-- Time is recorded in terms of timestamps in the StarCraft 2 replay file. When the game is played on \'faster\', 1 real-time second is equivalent to roughly 88.5 timestamps. \n\nAttribute Information:\n\n1. GameID: Unique ID number for each game (integer) \n2. LeagueIndex: Bronze, Silver, Gold, Platinum, Diamond, Master, GrandMaster, and Professional leagues coded 1-8 (Ordinal) \n3. Age: Age of each player (integer) \n4. HoursPerWeek: Reported hours spent playing per week (integer) \n5. TotalHours: Reported total hours spent playing (integer) \n6. APM: Action per minute (continuous) \n7. SelectByHotkeys: Number of unit or building selections made using hotkeys per timestamp (continuous) \n8. AssignToHotkeys: Number of units or buildings assigned to hotkeys per timestamp (continuous) \n9. UniqueHotkeys: Number of unique hotkeys used per timestamp (continuous) \n10. MinimapAttacks: Number of attack actions on minimap per timestamp (continuous) \n11. MinimapRightClicks: number of right-clicks on minimap per timestamp (continuous) \n12. NumberOfPACs: Number of PACs per timestamp (continuous) \n13. GapBetweenPACs: Mean duration in milliseconds between PACs (continuous) \n14. ActionLatency: Mean latency from the onset of a PACs to their first action in milliseconds (continuous) \n15. ActionsInPAC: Mean number of actions within each PAC (continuous) \n16. TotalMapExplored: The number of 24x24 game coordinate grids viewed by the player per timestamp (continuous) \n17. WorkersMade: Number of SCVs, drones, and probes trained per timestamp (continuous) \n18. UniqueUnitsMade: Unique unites made per timestamp (continuous) \n19. ComplexUnitsMade: Number of ghosts, infestors, and high templars trained per timestamp (continuous) \n20. ComplexAbilitiesUsed: Abilities requiring specific targeting instructions used per timestamp (continuous)\n\n\n\n### Acknowledgements\n\nSource:\n1. Thompson JJ, Blair MR, Chen L, Henrey AJ (2013) Video Game Telemetry as a Critical Tool in the Study of Complex Skill Learning. PLoS ONE 8(9): e75129. [Web Link] \n-- Results: \n-- Skip league conditional inference forest classification (Bronze-Gold;Silver-Platinum;Gold-Diamond;Platinum-Masters;Diamond-Professional) showed changing patterns of variable importance with skill. \n\n[http://archive.ics.uci.edu/ml/datasets/SkillCraft1+Master+Table+Dataset][1]\n\n### Inspiration\n\n - Ordinal Classification / regression model to determine League Index  (""**LeagueIndex**"")\n - Suggest additional features to gather and analyze for predicting leagues/performance.\n - Are there features which do not increase/decrease linearly as we go up in the leagues? \n\n\n  [1]: http://archive.ics.uci.edu/ml/datasets/SkillCraft1+Master+Table+Dataset'","b""['internet', 'video games', 'sports', 'games and toys', 'small', 'featured']""",https://www.kaggle.com/danofer/skillcraft
b'Connecticut inmates awaiting trial',b'Inmates being held in correcitonal facilities until trial',"b""### Context\n\nSince July 1, 2016, Connecticut has updated this nightly dataset of every inmate held in jail while awaiting trial.  At the time of download, this dataset contains just over one year of data with 1132352 rows of data, where one row is one inmate.\n\n### Content\n\nField Descriptions:\n* DOWNLOAD DATE: Date in which the data were extracted and reflecting the population for that day.\n\n* IDENITIFIER: Individual Inmate Identifier\n\n* LATEST ADMISSION DATE: Most recent date in which the inmate has been admitted. In some instances, this may reflect an original date of admission to a correctional facility. Generally, if a date is more than one year old, an inmate should not be considered to have been held for the entire duration of that time.\n\n* RACE: Race of inmate\n\n* AGE: Age of inmate\n\n* BOND AMOUNT: Amount of bond for which the inmate is being held. In some instances, for particularly low (less than $100), this bond amount may be considered a place holder value\n\n* OFFENSE: Controlling offense for which the bond amount has been set.\n\n* FACILITY: Department of Correction facility where the inmate is currently held.\n\n* DETAINER: Denotes whether inmate is being held at the request of another criminal justice agency, or if another agency is to be notified upon release.\n\n### Acknowledgements\n\nThanks to [http://dataispluralc.om] for the tip on this dataset! \nThis dataset was downloaded on July 26, 2017 - Chekc the original source for more up-to-date data (updated nightly)\n[https://data.ct.gov/Public-Safety/Accused-Pre-Trial-Inmates-in-Correctional-Faciliti/b674-jy6w]\n\n### Inspiration\n\nThis dataset contains information about inmate's race and the nature of the crimes. The Minority Report is a sci-fi story pretty well known for predicting crimes and arresting people before they happen. Can you do the same? Would you *dare* do the same?""","b""['medium', 'featured']""",https://www.kaggle.com/Connecticut-open-data/connecticut-inmates-awaiting-trial
b'Historical Military Battles',b'Conditions and results from over 600 battles fought in 1600 - 1973 AD',"b'### Context\n\nThis dataset is a cleaned-up and modernized version of ""CAA Database of Battles, Version 1990"", shortnamed ""CDB90"". It contains information on over 600 battles that were fought between 1600 AD and 1973 AD. Descriptive data include battle name, date, and location; the strengths and losses on each side; identification of the victor; temporal duration of the battle; and selected environmental and tactical environment descriptors (such as type of fortifications, type of tactical scheme, weather conditions, width of front, etc.).\n\n### Content\n\nThe data contained therein is split across several files. The most important of these is `battles.csv`, which is lists and gives information about the battles themselves. Files marked `enum` describe the keys used by specific fields. Other files provide additional context.\n\n### Acknowledgements\n\nThe original version of this database was distributed by the U.S. Army Concepts Analysis Agency. The version of this dataset you see here is a cleaned-up version created by Jeffrey Arnold. This dataset, cleanup code, and source data are all available [here](https://github.com/jrnold/CDB90).\n\n### Inspiration\n\n* How often were battles fought in various weather conditions?\n* How often did an attacker or defender achieve the element of surprise? Did it have a significant effect on the outcome?\n* Did prepared fortifications have a significant effect on outcomes?'","b""['history', 'military', 'military science', 'small', 'featured']""",https://www.kaggle.com/residentmario/database-of-battles
b'Python Questions from Stack Overflow',b'Full text of Stack Overflow Q&A about the Python programming language',"b'### Context\n\nFull text of all questions and answers from Stack Overflow that are tagged with the [python tag](http://stackoverflow.com/questions/tagged/python). Useful for natural language processing and community analysis. See also the dataset of [R questions](https://www.kaggle.com/stackoverflow/rquestions).\n\n### Content\n\nThis dataset is organized as three tables:\n\n* **Questions** contains the title, body, creation date, score, and owner ID for each Python question.\n* **Answers** contains the body, creation date, score, and owner ID for each of the answers to these questions. The ParentId column links back to the Questions table.\n* **Tags** contains the tags on each question *besides* the Python tag.\n\nQuestions may be deleted by the user who posted them. They can also be closed by community vote, if the question is deemed off-topic for instance. Such questions are not included in this dataset. \n\nThe dataset contains questions all questions asked between August 2, 2008 and Ocotober 19, 2016.\n\n### License\n\nAll Stack Overflow user contributions are licensed under [CC-BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/) with [attribution required](http://blog.stackoverflow.com/2009/06/attribution-required/).'","b""['internet', 'programming languages', 'large', 'featured']""",https://www.kaggle.com/stackoverflow/pythonquestions
b'CAT Scan Localization',b'384 features extracted from CT images',"b'### Context\n\nThis dataset consists of 384 features extracted from CT images. The class variable is numeric and denotes the relative location of the CT slice on the axial axis of the human body. The data was retrieved from a set of 53500 CT images from 74 different \npatients (43 male, 31 female).  \n\n\n### Content\n\nEach CT slice is described by two histograms in polar space. The first histogram describes the location of bone structures in the image, the second the location of air inclusions inside of the body. Both histograms are concatenated to form the final feature vector. Bins that are outside of the image are marked with the value -0.25. \n\nThe class variable (relative location of an image on the axial axis) was constructed by manually annotating up to 10 different distinct landmarks in each CT Volume with known location. The location of slices in between landmarks was interpolated.\n\nField Descriptions:\n\n- patientId: Each ID identifies a different patient \n- value[1-241]: Histogram describing bone structures \n- value[242 - 385]: Histogram describing air inclusions \n- 386: Relative location of the image on the axial axis (class value). \n\nValues are in the range [0; 180] where 0 denotes the top of the head and 180 the soles of the feet.\n\n### Acknowledgements\n\nOriginal dataset was downloaded from UCI Machine learning Repository\n\n*Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.*\n\nBanner image acknowledgement: \n\n- Self Portre on cat scan, 1997\n- Title: ""Soon I will be there""\n- Date: 8 April 1997\n- Author:\tS\xc3\xa9rgio Valle Duarte\n- License: CC BY 3.0\n- Source: [Wikipedia][1]\n\n### Inspiration\n\nPredict the relative location of CT slices on the axial axis\n\n\n  [1]: https://commons.wikimedia.org/wiki/File:Portrait_of_Sergio_Valle_Duarte.jpg#/media/File:A_Self_porte_on_cat_scan_1997.jpg:'","b""['image data', 'healthcare', 'image processing', 'health', 'biology', 'medium', 'featured']""",https://www.kaggle.com/uciml/ct-slice-localization
b'Chicago Condom Distribution Sites',b'From City of Chicago Open Data',"b""### Content  \n\nThe Chicago Department of Public Health is distributing condoms at several locations across the City.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/H8iwZwVBjXo) by [Pedro de Sousa](https://unsplash.com/@petrussousa) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-condom-distribution-sites
b'NYS Currently Licensed Real Estate Appraisers',b'From New York State Open Data',"b""### Content  \n\nThis data contains information for all currently active Real Estate Appraiser licensees.  Each record will be for an individual licensee, and will contain their Name, Unique Identification Number, License Type, Original Certification Date, Current Certification and Expiration Dates, Reciprocal State (if any), the Name of the Business they are associated with, and the Business\xe2\x80\x99s Address.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/8Z2ChynkzYs) by [Lachlan Gowen](https://unsplash.com/@lachlangowen) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'real estate', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-currently-licensed-real-estate-appraisers
b'Faulty Steel Plates',b'Steel plate faults classified into seven types',"b'### Context\n\nThis dataset comes from research by Semeion, Research Center of Sciences of Communication. The original aim of the research was to correctly classify the type of surface defects in stainless steel plates, with six types of possible defects (plus ""other"").  The  Input  vector  was  made  up  of  27  indicators  that  approximately [describe] the geometric shape of the defect and its outline. According to the research paper, Semeion was commissioned by the Centro Sviluppo Materiali (Italy) for this task and therefore it is not possible to provide details on the nature of the 27 indicators used as Input vectors or the types of the 6 classes of defects. \n\n\n### Content\n\nThere are 34 fields. The first 27 fields describe some kind of steel plate faults seen in images.  Unfortunately, there is no other information that I know of to describe these columns. \n\n - X_Minimum\n - X_Maximum\n - Y_Minimum\n - Y_Maximum\n - Pixels_Areas\n - X_Perimeter\n - Y_Perimeter\n - Sum_of_Luminosity\n - Minimum_of_Luminosity\n - Maximum_of_Luminosity\n - Length_of_Conveyer\n - TypeOfSteel_A300\n - TypeOfSteel_A400\n - Steel_Plate_Thickness\n - Edges_Index\n - Empty_Index\n - Square_Index\n - Outside_X_Index\n - Edges_X_Index\n - Edges_Y_Index\n - Outside_Global_Index\n - LogOfAreas\n - Log_X_Index\n - Log_Y_Index\n - Orientation_Index\n - Luminosity_Index\n - SigmoidOfAreas\n\n\nThe last seven columns are one hot encoded classes, i.e. if the plate fault is classified as ""Stains"" there will be a 1 in that column and 0\'s in the other columns. If you are unfamiliar with one hot encoding, just know that the last seven columns are your class labels. \n\n - Pastry\n - Z_Scratch\n - K_Scatch\n - Stains\n - Dirtiness\n - Bumps\n - Other_Faults\n\n\n### Acknowledgements\n\nMetaNet: The Theory of Independent Judges (PDF Download Available). Available from: https://www.researchgate.net/publication/13731626_MetaNet_The_Theory_of_Independent_Judges [accessed Sep 6, 2017].\n\nDataset provided by Semeion, Research Center of Sciences of Communication, Via Sersale 117, 00128, Rome, Italy. \nwww.semeion.it\n\nLichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n'","b""['business', 'civil engineering', 'engineering', 'mechanical engineering', 'materials science', 'small', 'featured']""",https://www.kaggle.com/uciml/faulty-steel-plates
b'NIPS 2017: Adversarial Learning Development Set',b'Development images used in the NIPS 2017 Adversarial Learning challenges',"b""Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake.\n\nAdversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model.\n\nTo accelerate research on adversarial examples, [Google Brain](http://g.co/brain) is organizing **Competition on Adversarial Examples and Defenses** within the [NIPS 2017 competition track](https://nips.cc/Conferences/2017/CompetitionTrack). This dataset contains the development images for this competition.\n\nThe competition on Adversarial Examples and Defenses consist of three sub-competitions:\n\n- [Non-targeted Adversarial Attack](https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack). The goal of the non-targeted attack is to slightly modify source image in a way that image will be classified incorrectly by generally unknown machine learning classifier.\n- [Targeted Adversarial Attack](https://www.kaggle.com/c/nips-2017-targeted-adversarial-attack). The goal of the targeted attack is to slightly modify source image in a way that image will be classified as specified target class by generally unknown machine learning classifier.\n- [Defense Against Adversarial Attack](https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack). The goal of the defense is to build machine learning classifier which is robust to adversarial example, i.e. can classify adversarial images correctly.\n\nIn each of the sub-competitions you're invited to make and submit a program which solves the corresponding task. In the end of the competition we will run all attacks against all defenses to evaluate how each of the attacks performs against each of the defenses.""","b""['artificial intelligence', 'medium', 'featured']""",https://www.kaggle.com/google-brain/nips-2017-adversarial-learning-development-set
b'US Candy Production by Month',b'From January 1972 to August 2017',"b'### Context: \n\nHalloween begins frenetic candy consumption that continues into the Christmas holidays and New Year\xe2\x80\x99s Day, when people often make (usually short-lived) resolutions to lose weight. But all this consumption first needs production. The graph shows the relevant data from the industrial production index and its stunning seasonality\n\n### Content: \n\nThe industrial production (IP) index measures the real output of all relevant establishments located in the United States, regardless of their ownership, but not those located in U.S. territories. This dataset tracks industrial production every month from January 1972 to August 2017. \n\n### Acknowledgements: \n\nBoard of Governors of the Federal Reserve System (US), Industrial Production: Nondurable Goods: Sugar and confectionery product [IPG3113N], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/IPG3113N, October 13, 2017.\n\n### Inspiration: \n\n* Can you correct for the seasonality in this data?\n* Which months have the highest candy production?\n* Can you predict production for September through December 2017?\n'","b""['food and drink', 'time series', 'product', 'manufacturing', 'product management', 'small', 'featured']""",https://www.kaggle.com/rtatman/us-candy-production-by-month
b'Pizza Restaurants and the Pizza They Sell',"b'A list of pizza restaurants,  3,500 pizzas, and their menu prices.'","b""# About this Data\nThis is a list of over 3,500 pizzas from multiple restaurants provided by [Datafiniti's Business Database][1]. The dataset includes the category, name, address, city, state, menu information, price range, and more for each pizza restaurant. \n\n*Note that this is a sample of a large data set. The full data set is available through Datafiniti.*\n\n# What You Can Do with this Data\nYou can use this data to discover how much [you can expect to pay for pizza across the country][2]. E.g.:\n\n - What are the least and most expensive cities for pizza?\n - What is the number of restaurants serving pizza per capita (100,000 residents) across the U.S.?\n - What is the median price of a large plain pizza across the U.S.?\n - Which cities have the most restaurants serving pizza per capita (100,000 residents)?\n\n# Data Schema\nA full schema for the data is available in our [support documentation][3].\n\n# About Datafiniti\nDatafiniti provides instant access to web data. We compile data from thousands of websites to create standardized databases of business, product, and property information. [Learn more][4].\n\n# Want More?\nYou can get more data like this by [joining Datafiniti][5] or [requesting a demo][6].\n\n  [1]: http://datafiniti.co/products/business-data/\n  [2]: https://datafiniti.co/price-slice-pizza-across-america/\n  [3]: https://datafiniti-api.readme.io/docs/business-data-schema\n  [4]: https://datafiniti.co\n  [5]: https://portal.datafiniti.co/login\n  [6]: https://datafiniti.co/request-a-demo/""","b""['internet', 'food and drink', 'business', 'databases', 'small', 'featured']""",https://www.kaggle.com/datafiniti/pizza-restaurants-and-the-pizza-they-sell
b'New York City Medicaid Offices',b'From New York City Open Data',"b""### Content  \n\nThis table represents the details of the Medicaid Offices distributed by Borough along with their address and phone number detail.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ggcmoi5J5Fw) by [Rick L](https://unsplash.com/@rickyyyl) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/new-york-city-medicaid-offices
b'NY Current Reservoir Levels',b'From New York City Open Data',"b""### Content  \n\nThe daily capacity and percent of capacity filled for each of the City's reservoirs.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/HlQf_iNy9ug) by [John Peters](https://unsplash.com/@johnphiker) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'health', 'environment', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-current-reservoir-levels
"b""Women's Tennis Association Matches""",b'WTA matches from 2000 to 2016',"b""# Context \n\nA dataset of WTA matches including individual statistics.\n\n\n# Content\n\nIn these datasets there are individual csv files for WTA tournament from 2000 to 2016.\n\nThe numbers in the last columns are absolute values, using them you can calculate percentages.\n\n# Acknowledgement\n\nThanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile\n\nhttps://github.com/JeffSackmann/tennis_wta\n\n\n# Inspiration\n\nThis dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.""","b""['tennis', 'small', 'featured']""",https://www.kaggle.com/gmadevs/wta-matches
b'Seattle Traffic Cameras',b'From City of Seattle Open Data',"b""### Content  \n\nTraffic caneras in Seattle owned by SDOT and WSDOT  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.\n  \n\n[Cover photo](https://unsplash.com/photos/UR7RzFRXcrU) by [Mark Jefferson Paraan](https://unsplash.com/@markjparaan) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-traffic-cameras
b'Scientific Researcher Migrations',b'Movement of ~742k Scientists',"b'### Context: \nORCID provides a persistent digital identifier that distinguishes you from every other researcher and, through integration in key research workflows such as manuscript and grant submission, supports automated linkages between you and your professional activities ensuring that your work is recognized. [Find out more.](https://orcid.org/about/what-is-orcid/mission)\n\n### Content: \nThis data is a subset of the entire ORCID collection. The subset here was produced by [John Bohannon](http://www.johnbohannon.org/). You can see his excellent Ipython notebook and the entire (300GB!) ORCID archives [here](http://datadryad.org/resource/doi:10.5061/dryad.48s16).\n\nThe data covers ~742k unique researchers and includes:\n\n* orcid_id\n* phd_year\n* country_2016\n* earliest_year\n* earliest_country\n* has_phd\n* phd_country\n* has_migrated\n\n### Acknowledgements: \nBohannon J, Doran K (2017) Introducing ORCID. Science 356(6339) 691-692. http://dx.doi.org/10.1126/science.356.6339.691\n\nAdditionally, please cite the Dryad data package:\n\nBohannon J, Doran K (2017) Data from: Introducing ORCID. Dryad Digital Repository. http://dx.doi.org/10.5061/dryad.48s16\n\n\n### Inspiration: \n* Where do most researchers move to?\n* What countries experience the largest \xe2\x80\x98brain drain\xe2\x80\x99? As a % of population?\n* Can you predict researcher migration?'","b""['demographics', 'utility', 'medium', 'featured']""",https://www.kaggle.com/jboysen/scientist-migrations
b'Google Text Normalization Challenge',"b'Text-to-speech synthesis text normalization data, from Sproat & Jaitly 2016'","b'### Challenge Description \n\nThis dataset and [accompanying paper](https://arxiv.org/abs/1611.00068) present a challenge to the community: given a large corpus of *written* text aligned to its normalized *spoken* form, train an RNN to learn the correct normalization function. That is, a date written ""31 May 2014"" is spoken as ""the thirty first of may twenty fourteen."" We present a dataset of general text where the normalizations were generated using an existing text normalization component of a text-to-speech (TTS) system. This dataset was originally released open-source [here](https://github.com/rwsproat/text-normalization-data/blob/master/README.md) and is reproduced on Kaggle for the community.\n\n### The Data\n\nThe data in this directory are the English language training, development and test data used in Sproat and Jaitly (2016).\n\nThe following divisions of data were used:\n\n* Training:      `output_1` through `output_21` (corresponding to output-000[0-8]?-of-00100 in the original dataset)\n\n* Runtime eval:  `output_91` (corresponding to output-0009[0-4]-of-00100 in the original dataset)\n\n* Test data:     `output_96` (corresponding to output-0009[5-9]-of-00100 in the original dataset)\n\nIn practice for the results reported in the paper only the first 100,002 lines of output-00099-of-00100 were used (for English).\n\nLines with ""<eos>"" in two columns are the end of sentence marker, otherwise there are three columns, the first of which is the ""semiotic class"" (Taylor, 2009), the second is the input token and the third is the output, following the paper cited above.\n\nAll text is from Wikipedia. All data were extracted on 2016/04/08, and run through the Google Kestrel TTS text normalization system (Ebden and Sproat, 2015), so that the notion of ""token"", ""semiotic class"" and reference output are all Kestrel\'s notion.\n\n### Our Research\n\n[In this paper](https://arxiv.org/abs/1611.00068), we present our own experiments with this data set with a variety of different RNN architectures. While some of the architectures do in fact produce very good results when measured in terms of overall accuracy, the errors that are produced are problematic, since they would convey completely the wrong message if such a system were deployed in a speech application. On the other hand, we show that a simple FST-based filter can mitigate those errors, and achieve a level of accuracy not achievable by the RNN alone. \n\nThough our conclusions are largely negative on this point, we are actually not arguing that the text normalization problem is intractable using an pure RNN approach, merely that it is not going to be something that can be solved merely by having huge amounts of annotated text data and feeding that to a general RNN model. And with open-source data, we provide a novel data set for sequence-to-sequence modeling in the hopes that the the community can find better solutions. \n\n### Disclaimer\n\nThis is not an official Google product.\n\n### References\n\nEbden, Peter and Sproat, Richard. 2015. The Kestrel TTS text normalization system. Natural Language Engineering. 21(3).\n\nRichard Sproat and Navdeep Jaitly. 2016. RNN Approaches to Text Normalization: A Challenge. Released on arXiv.org: https://arxiv.org/abs/1611.00068\n\nTaylor, Paul. 2009. Text-to-Speech Synthesis. Cambridge University Press, Cambridge.'","b""['linguistics', 'languages', 'large', 'featured']""",https://www.kaggle.com/google-nlu/text-normalization
b'School Shootings US 1990-present',b'Record of all school shooting incidents since 1990',"b'### Context\n\nAnother week, sadly another school shooting.  \n\nTo better understand the facts I went looking for data and found it difficult to come by - often embedded in other datasets or fragmented and unusable.  I decided to create my own compilation based on a mashup of the [Pah/Amaral/Hagan research][1] on school shootings with the [Wikipedia article][2] from 1990 to present.\n\n\n### Content\npah_wikp file: A list of all school shooting incidents from 1990 to present.\n\nFields: \n\n - Date: date of incident \n - City: location of incident \n - State: location of incident \n - Area Type: urban or suburban (only in Pah dataset) \n - School: C = college, HS = high school, MS = middle school, ES = elementary school, - = unknown \n - Fatalities: # killed \n - Wounded: # wounded (only in Wikipedia dataset) \n - Dupe: whether this incident appears in both datasets. Note: only the ""Pah"" version of the incident is marked. \n - Source: Pah or Wikp \n - Desc: text description of incident (only in Wikipedia dataset)\n\ncps file: US census data on school populations.  Fields should be fairly self explanatory.\n\n### Acknowledgements\n\nThanks to the authors referenced above as well as the Wikipedia contributors!\n\n\n### Inspiration\n\n- Why are school shootings (and death counts) increasing over time?\n- How does the risk of being killed in a school shooting compare with other risks?\n- Are some schools / cities / states at higher risk?\n- Is there a correlation between countermeasures and a decrease in fatalities?\n- What else correlates with school shooting risks?  In addition to firearms and the people who wield them, is there any clear causality?\n\n### github version\nNote: the master version of these datasets can be found at [https://github.com/ecodan/school-shooting-data.git][3] and is open for community contributions.  I\'ll try to keep this data up-to-date with the github version on at least a monthly basis.\n\n\n  [1]: https://news.northwestern.edu/stories/2017/01/shootings-us-schools-link-unemployment\n  [2]: https://en.wikipedia.org/wiki/School_shootings_in_the_United_States\n  [3]: https://github.com/ecodan/school-shooting-data.git'","b""['politics', 'public health', 'violence', 'death', 'small', 'featured']""",https://www.kaggle.com/ecodan/school-shootings-us-1990present
b'PM2.5 Data of Five Chinese Cities',"b'Measurements for Shenyang, Chengdu, Beijing, Guangzhou, and Shanghai'","b""### Context\n\nPM2.5 readings are often included in air quality reports from environmental authorities and companies. PM2.5 refers to atmospheric particulate matter (PM) that have a diameter less than 2.5 micrometers. In other words, it's used as a measure of pollution. \n\n### Content\n\nThe time period for this data is between Jan 1st, 2010 to Dec 31st, 2015. Missing data are denoted as NA. \n\n- No: row number \n- year: year of data in this row \n- month: month of data in this row \n- day: day of data in this row \n- hour: hour of data in this row \n- season: season of data in this row \n- PM: PM2.5 concentration (ug/m^3) \n- DEWP: Dew Point (Celsius Degree) \n- TEMP: Temperature (Celsius Degree) \n- HUMI: Humidity (%) \n- PRES: Pressure (hPa) \n- cbwd: Combined wind direction \n- Iws: Cumulated wind speed (m/s) \n- precipitation: hourly precipitation (mm) \n- Iprec: Cumulated precipitation (mm)\n\n### Acknowledgements\n\nLiang, X., S. Li, S. Zhang, H. Huang, and S. X. Chen (2016), PM2.5 data reliability, consistency, and air quality assessment in five Chinese cities, J. Geophys. Res. Atmos., 121, 10220\xc3\xa2\xe2\x82\xac\xe2\x80\x9c10236.\n\nThe files were downloaded from the UCI Machine Learning Repository and have not been modified. https://archive.ics.uci.edu/ml/datasets/PM2.5+Data+of+Five+Chinese+Cities#""","b""['cities', 'pollution', 'medium', 'featured']""",https://www.kaggle.com/uciml/pm25-data-for-five-chinese-cities
b'Port Phillip Bay Weather',b'Watersport enthusiasts can build their own forecasts. Dataset updates daily. ',"b'### Context\n\nI am a kitefoiler so plan my days around when the wind is blowing. Having this dataset helps me figure out the best time of day and year to go kitefoiling in Melbourne. It also tells me which is the most reliable location. \n\nI hope to eventually to try and use machine learning to forecast the wind. \n\n### Content\n\nEach file contains wind speed, wind gust, wind direction and temperature data. The data is collected at 10 minute internals. Each day and location is a different CSV.  This dataset updates once per day. \n\nThis dataset has data for seven locations around Victoria \n\n - Cerberus (which is actually in Westernport Bay)\n - Fawkner Beacon\n - Frankston\n - Melbourne (Olympic Park)\n - Point Wilson\n - South Channel Island\n - St Kilda\n\n### Acknowledgements\n\nThis date comes from the Australia\'s Bureau of Meteorology. The raw data comes from:\n[ftp.bom.gov.au/anon/gen/fwo/IDV60920.xml][1]\n\n### Inspiration\n\nWould love to see somebody else use this data to forecast the wind at different locations. Kitefoilers say things like ""a southerly in South Channel Island arrives at Fawkner Beacon one hour later"". It\'d be interesting to dis/prove these myths. \n\n  [1]: http://ftp.bom.gov.au/anon/gen/fwo/IDV60920.xml'","b""['weather', 'utility', 'water sports', 'small', 'featured']""",https://www.kaggle.com/antgoldbloom/port-phillip-bay-wind
b'North American Slave Narratives',b'First-hand Accounts of Slaves from the United States',"b'""North American Slave Narratives"" collects books and articles that document the individual and collective story of African Americans struggling for freedom and human rights in the eighteenth, nineteenth, and early twentieth centuries. This collection includes all the existing autobiographical narratives of fugitive and former slaves published as broadsides, pamphlets, or books in English up to 1920. Also included are many of the biographies of fugitive and former slaves and some significant fictionalized slave narratives published in English before 1920.\n\n### Context\n\nThe North American Slave Narratives collection at the University of North Carolina contains 344 items and is the most extensive collection of such documents in the world.\n\nThe physical collection was digitized and transcribed by students and library employees. This means that the text is far more reliable than uncorrected OCR output which is common in digitized archives.\n\nMore information about the collection and access to individual page images can be be found here: http://docsouth.unc.edu/neh\n\nThe plain text files have been optimized for use in Voyant and can also be used in text mining projects such as topic modeling, sentiment analysis and natural language processing. Please note that the full text contains paratextual elements such as title pages and appendices which will be included in any word counts you perform. You may wish to delete these in order to focus your analysis on just the narratives.\n\nThe .csv file acts as a table of contents for the collection and includes Title, Author, Publication Date a url pointing to the digitized version of the text and a unique url pointing to a version of the text in plain text (this is particularly useful for use with Voyant: http://voyant-tools.org/). \n\n### Copyright Statement and Acknowledgements\n\nWith the exception of ""Fields\'s Observation: The Slave Narrative of a Nineteenth-Century Virginian,"" which has no known rights, the texts, encoding, and metadata available in Open DocSouth are made available for use under the terms of a Creative Commons Attribution License (CC BY 4.0:http://creativecommons.org/licenses/by/4.0/). Users are free to copy, share, adapt, and re-publish any of the content in Open DocSouth as long as they credit the University Library at the University of North Carolina at Chapel Hill for making this material available.\n\nIf you make use of this data, considering letting the holder of the original collection know how you are using the data and if you have any suggestions for making it even more useful. Send any feedback to wilsonlibrary@unc.edu.\n\n### About the DocSouth Data Project\n\nDoc South Data provides access to some of the Documenting The American South collections in formats that work well with common text mining and data analysis tools.\n\nDocumenting the American South is one of the longest running digital publishing initiatives at the University of North Carolina. It was designed to give researchers digital access to some of the library\xe2\x80\x99s unique collections in the form of high quality page scans as well as structured, corrected and machine readable text.\n\nDoc South Data is an extension of this original goal and has been designed for researchers who want to use emerging technology to look for patterns across entire texts or compare patterns found in multiple texts. We have made it easy to use tools such as Voyant (http://voyant-tools.org/) to conduct simple word counts and frequency visualizations (such as word clouds) or to use other tools to perform more complex processes such as topic modeling, named-entity recognition or sentiment analysis.'","b""['linguistics', 'united states', 'history', 'north america', 'slaves', 'medium', 'featured']""",https://www.kaggle.com/docsouth-data/north-american-slave-narratives
b'NYS Substance Use Disorder Data',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'mental health', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-substance-use-disorder-data
b'US Gross Rent ACS Statistics',"b'+40,000 Samples: Real Estate Application (Mean, Median, Standard Deviation)'","b""### What you get:\n*Upvote!* The database contains +40,000 records on US Gross Rent & Geo Locations. The field description of the database is documented in the attached pdf file. **To access, all 325,272 records on a scale roughly equivalent to a neighborhood (census tract) see link below** and *make sure to upvote*. Upvote right now, please. *Enjoy*!\n\n\n**Get the full free database with coupon code: FreeDatabase**, *See directions at the bottom of the description... And make sure to upvote* :)  coupon ends at 2:00 pm 8-23-2017\n\n\n###Gross Rent & Geographic Statistics:\n\n\n - Mean Gross Rent (double)\n - Median Gross Rent (double)\n - Standard Deviation of Gross Rent (double)\n - Number of Samples (double) \n - Square area of land at location (double) \n - Square area of water at location (double) \n\n\n###Geographic Location:\n\n - Longitude (double)\n - Latitude (double)\n - State Name (character)\n - State abbreviated (character) \n - State_Code (character) \n - County Name (character)\n - City Name (character)\n - Name of city, town, village or CPD  (character)\n - Primary, Defines if the location is a track and block group.\n - Zip Code (character)\n - Area Code (character)                      \n\n\n### Abstract\nThe data set originally developed for real estate and business investment research. Income is a vital element when determining both quality and socioeconomic features of a given geographic location. The following data was derived from over **+36,000 files** and covers 348,893 location records.\n\n### License\nOnly proper citing is required please see the documentation for details.\nHave Fun!!!\n\nGolden Oak Research Group, LLC. \xe2\x80\x9cU.S. Income Database Kaggle\xe2\x80\x9d. Publication: 5, August 2017. Accessed, day, month year.\n\n\nFor any questions, you may reach us at  research_development@goldenoakresearch.com. For immediate assistance, you may reach me on at 585-626-2965\n\n*please note: it is my personal number and email is preferred*\n\nCheck our data's accuracy:\n[Census Fact Checker][1]\n\n\n###Access all 325,272 location for Free Database Coupon Code:\nDon't settle. Go big and win big.  Optimize your potential**. *Access all gross rent records and more on a scale roughly equivalent to a neighborhood, see link below*:\n\n\n - **Website**: [Golden Oak Research][2]  *make sure to upvote*\n\n\nA small startup with big dreams, giving the every day, up and coming data scientist professional grade data at affordable prices It's what we do. \n\n  [1]: https://factfinder.census.gov/\n  [2]: https://www.goldenoakresearch.com/product-page/store""","b""['finance', 'demographics', 'real estate', 'small', 'featured']""",https://www.kaggle.com/goldenoakresearch/acs-gross-rent-us-statistics
b'DenseNet-121',b'DenseNet-121 Pre-trained Model for PyTorch',"b'\n# DenseNet-121\n\n---\n\n## Densely Connected Convolutional Networks<br>\n\nRecent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and models are available at this [https URL][1].\n\n**Authors: Gao Huang, Zhuang Liu, Kilian Q. Weinberger, Laurens van der Maaten**<br>\n**https://arxiv.org/abs/1608.06993**\n\n---\n\n\n![DenseNet][2]\n\n## DenseNet Architectures\n![DenseNet Architectures][3]\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://github.com/liuzhuang13/DenseNet\n  [2]: https://imgur.com/wWHWbQt.jpg\n  [3]: https://imgur.com/oiTdqJL.jpg'","b""['machine learning', 'pre-trained model', 'medium', 'featured']""",https://www.kaggle.com/pytorch/densenet121
b'Chicago Street Sweeping Schedule',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Xf5aySvYSb4) by [Chris Barbalis](https://unsplash.com/@cbarbalis) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-street-sweeping-schedule
b'The Ultimate Halloween Candy Power Ranking',b'What\xe2\x80\x99s the best Halloween candy?',"b'# Context\n\nWhat\xe2\x80\x99s the best (or at least the most popular) Halloween candy? That was the question this dataset was collected to answer. Data was collected by creating a website where participants were shown [presenting two fun-sized candies and asked to click on the one they would prefer to receive](http://walthickey.com/2017/10/18/whats-the-best-halloween-candy/). In total, more than 269 thousand votes were collected from 8,371 different IP addresses.\n\n# Content\n\n`candy-data.csv` includes attributes for each candy along with its ranking. For binary variables, 1 means yes, 0 means no. The data contains the following fields: \n\n* chocolate: Does it contain chocolate?\n* fruity: Is it fruit flavored?\n* caramel: Is there caramel in the candy?\n* peanutalmondy: Does it contain peanuts, peanut butter or almonds?\n* nougat: Does it contain nougat?\n* crispedricewafer: Does it contain crisped rice, wafers, or a cookie component?\n* hard: Is it a hard candy?\n* bar: Is it a candy bar?\n* pluribus: Is it one of many candies in a bag or box?\n* sugarpercent: The percentile of sugar it falls under within the data set.\n* pricepercent: The unit price percentile compared to the rest of the set.\n* winpercent: The overall win percentage according to 269,000 matchups.\n\n\n### Acknowledgements: \n\nThis dataset is Copyright (c) 2014 ESPN Internet Ventures and distributed under an [MIT license](https://github.com/fivethirtyeight/data/blob/master/LICENSE). Check out the analysis and write-up here: [The Ultimate Halloween Candy Power Ranking](http://fivethirtyeight.com/features/the-ultimate-halloween-candy-power-ranking/). Thanks to [Walt Hickey](http://walthickey.com/) for making the data available.\n\n### Inspiration: \n\n* Which qualities are associated with higher rankings?\n* What\xe2\x80\x99s the most popular candy? Least popular?\n* Can you recreate the [538 analysis](http://fivethirtyeight.com/features/the-ultimate-halloween-candy-power-ranking/) of this dataset?'","b""['food and drink', 'popular culture', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/the-ultimate-halloween-candy-power-ranking
b'Freight Analysis Framework',b'Flows of goods among US regions for all modes of transportation',"b'The Freight Analysis Framework (FAF) integrates data from a variety of sources to create a comprehensive picture of freight movement among states and major metropolitan areas by all modes of transportation. Starting with data from the 2012 Commodity Flow Survey (CFS) and international trade data from the Census Bureau, FAF incorporates data from agriculture, extraction, utility, construction, service, and other sectors.\nFAF version 4 (FAF4) provides estimates for tonnage (in thousand tons) and value (in million dollars) by regions of origin and destination, commodity type, and mode. Data are available for the base year of 2012, the recent years of 2013 - 2015, and forecasts from 2020 through 2045 in 5-year intervals.\n\n### Inspiration\n\nThis dataset should be great for map-based visualizations.'","b""['industry', 'rail transport', 'shipping', 'medium', 'featured']""",https://www.kaggle.com/usdot/freight-analysis-framework
b'Chicago Alternative Fuel Locations',b'From City of Chicago Open Data',"b""### Content  \n\nList of locations in NE Illinois, NW Indiana, and SE Wisconsin where alternative vehicle fuels are available.  For a Chicago-only filtered view, see https://data.cityofchicago.org/d/fi3z-jc3f. For more detailed descriptions of fields, see http://developer.nrel.gov/docs/transportation/alt-fuel-stations-v1 or https://data.cityofchicago.org/developers/docs/alternative-fuel-locations.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Zxs4tMZzdS8) by [Thomas Jarrand](https://unsplash.com/@tom32i) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-alternative-fuel-locations
b'NYS Artificial Reef Aerial Survey Boat Count',b'From New York State Open Data',"b""### Content  \n\nThis file provides the boat count information resulting from the Artificial Reef Aerial Survey including the date of flight, reef observed, number of small boats observed, and number of large boats observed. Large boats are defined as party and charter boats.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/5iiI5wVXY8M) by [Craig Lovelidge](https://unsplash.com/@_craigology) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'fishing', 'boating', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-artificial-reef-aerial-survey-boat-count
b'OECD Consumer Price Index: Total All Items',b'Explore Time Series from the OECD',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [Organization for Economic Co-operation and Development (OECD)](http://www.oecd.org/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the OECD using Kaggle and all of the data sources available through the OECD [organization page](https://www.kaggle.com/oecd)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).\n\nThis dataset is distributed under the [Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/) license. If you would like to use a dataset for commercial use, submit a request to the Copyright Clearance Centre, Inc. (CCC), www.copyright.com. If you are not able to find the publication on the CCC website, You may contact rights@oecd.org.\n\t  \n\n[Cover photo](https://unsplash.com/photos/t6iXAZLeHJE) by [Giulia Bertelli](https://unsplash.com/@giulia_bertelli) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'utility', 'small', 'featured']""",https://www.kaggle.com/oecd-org/oecd-consumer-price-index-total-all-items
b'NYC Rat Sightings',b'~102k Observations Around New York',"b""### Context: \nRats in New York City are prevalent, as in many densely populated areas. For a long time, the exact number of rats in New York City was unknown, and a common urban legend was that there were up to four times as many rats as people. In 2014, however, scientists more accurately measured the entire city's rat population to be approximately only 25% of the number of humans; i.e., there were approximately 2 million rats to New York's 8.4 million people at the time of the study.[1][2]\n\n### Content: \nNew York City rodent complaints can be made online, or by dialing 3-1-1, and the New York City guide Preventing Rats on Your Property discusses how the New York City Health Department inspects private and public properties for rats. Property owners that fail inspections receive a Commissioner's Order and have five days to correct the problem. If after five days the property fails a second inspection, the owner receives a Notice of Violation and can be fined. The property owner is billed for any clean-up or extermination carried out by the Health Department.\n\nData is from 2010-Sept 16th, 2017 and includes date, location (lat/lon), type of structure, borough, and community board.\n\n### Acknowledgements: \nData was produced by the [City of New York via their 311 portal](https://data.cityofnewyork.us/Social-Services/Rat-Sightings/3q43-55fe).\n\n### Inspiration: \n* Where and when are rats most seen?\n* Can you predict rat sightings from previous data?\n* Are there any trends in rat sightings?\n""","b""['animals', 'government', 'government agencies', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/nyc-rat-sightings
b'Heartbeat Sounds',b'Classifying heartbeat anomalies from stethoscope audio',"b'## Context\n\nThis dataset was originally for a machine learning challenge to classify heart beat sounds. The data was gathered from two sources: (A) from the general public via the iStethoscope Pro iPhone app, and (B) from a clinic trial in hospitals using the digital stethoscope DigiScope. There were two challenges associated with this competition: \n\n**1. Heart Sound Segmentation**<br>\nThe first challenge is to produce a method that can locate S1(lub) and S2(dub) sounds within audio data, segmenting the Normal audio files in both datasets. \n\n**2. Heart Sound Classification**<br>\nThe task is to produce a method that can classify real heart audio (also known as \xe2\x80\x9cbeat classification\xe2\x80\x9d) into one of four categories.\n\n\n## Content\n\nThe dataset is split into two sources, **A** and **B**: \n\n**set_a.csv** - Labels and metadata for heart beats collected from the general public via an iPhone app\n\n**set_a_timing.csv** - contains gold-standard timing information for the ""normal"" recordings from Set A.\n  \n**set_b.csv** - Labels and metadata for heart beats collected from a clinical trial in hospitals using a digital stethoscope\n\n**audio files** -  Varying lengths, between 1 second and 30 seconds. (some have been clipped to reduce excessive noise and provide the salient fragment of the sound).\n\n## Acknowledgements\n\n```@misc{pascal-chsc-2011,\n       author = ""Bentley, P. and Nordehn, G. and Coimbra, M. and Mannor, S."",\n       title = ""The {PASCAL} {C}lassifying {H}eart {S}ounds {C}hallenge 2011 {(CHSC2011)} {R}esults"",\n       howpublished = ""http://www.peterjbentley.com/heartchallenge/index.html""} ```\n\n## Inspiration\n\nTry your hand at automatically separating normal heartbeats from abnormal heartbeats and heart murmur with this machine learning challenge by [Peter Bentley et al](http://www.peterjbentley.com/heartchallenge/)\n\nThe goal of the task was to first (1) identify the locations of heart sounds from the audio, and (2) to classify the heart sounds into one of several categories (normal v. various non-normal heartbeat sounds).\n\n\n'","b""['classification', 'healthcare', 'sound technology', 'medium', 'featured']""",https://www.kaggle.com/kinguistics/heartbeat-sounds
b'Solar generation and demand Italy 2015-2016',b'Two-years hourly-recorded data of solar power generation and electricity demand',"b'### Context\n\nThis dataset summarizes valuable data about recent total solar power generation and total electricity demand in a specific european country like Italy. Data are time series with hourly resolution, and values represent average of real-time power (generated and used) per market time unit (*). \nData correspond to years 2015 and 2016. They are useful to analyze, for instance, the variation of solar generation with time in the four seasons of the year, the change of electricity demand depending on the day of the week, or in summer/winter holidays. Use of historical weather data could help to visualize the variation of solar power generation with climate conditions, extremely useful excercise for solar power generation forecasting. Studies of load forecasting could be also conducted by making use of the present dataset.\n\n(*) [Detailed data descriptions](https://www.entsoe.eu/fileadmin/user_upload/_library/resources/Transparency/MoP%20Ref02%20-%20EMFIP-Detailed%20Data%20Descriptions%20V1R4-2014-02-24.pdf)\n\n### Content\n\nThe two files include time series data of solar generation and total electricity consumption in Italy during the years 2015 and 2016, with hourly resolution. CSV files are structured in three columns: \n 1. Date and Time\n 2. Load\n 3. Solar Generation\nThe time is expressed in Coordinated Universal Time (UTC), and the format of Date and Time is ""%Y-%m-%dT%H%M%SZ"". Solar generation and load are floating point numbers, which represent power expressed in MW (Mega Watts) units. \nSolar generation is the total solar power generated in Italy in 2015 and 2016, calculated by adding the generation in the different italian bidding zones (6 geographical regions: Nord, Centro Nord, Centro Sud, Sud, Sardegna and Sicilia, and 4 poles: Brindisi, Foggia, Priolo and Rossano). Load represents the total demand of power in the same periods.\nNote: the 2015 file presents a few missing data.\n\n### Acknowledgements\n\nData has been extracted from ""Open Power System Data. 2017. Data Package Time series. Version 2017-07-09 (https://data.open-power-system-data.org/time_series/2017-07-09).""\n\nThe primary data source is ENTSO-E Transparency, the central data platform of the European transmission system operators (https://transparency.entsoe.eu).\n\n### Inspiration\n\nDo you think we could improve the Day-ahead load forecasting? Navigate for instance the ENTSO-E Transparency website, it shows up-to-date comparisons between Day ahead total load forecast and Actual total load, by bidding zones or countries. As you will see, sometimes the differences may be significant.\n\nImportant: The ENTSO-E Platform is a great repository of energy data. Measured data and forecasts are provided to the Platform by the Primary Data Owners (see Terms and Conditions at https://transparency.entsoe.eu).'","b""['time series', 'renewable energy', 'small', 'featured']""",https://www.kaggle.com/arielcedola/solar-generation-and-demand-italy-20152016
b'Predict Molecular Properties',b'Help computational alchemy with machine learning!',"b""# Predict molecular properties\n\n## Context\nThis dataset contains molecular properties scraped from the [PubChem database](http://pubchem.ncbi.nlm.nih.gov).\nEach file contains properties for thousands of molecules , made up of the elements H, C, N, O, F, Si, P, S, Cl, Br, and I.\nThe dataset is related to a [previous one](https://www.kaggle.com/burakhmmtgl/energy-molecule) which had fewer number of molecules, where the features were preconstructed. \n\nInstead, this dataset is a challenging case for feature engineering and is subject of active research (see references below). \n\n## Data Description\n\nThe utilities used to download and process the data can be accessed from my Github [repo](https://github.com/bhimmetoglu/RoboBohr/tree/master/utils).\n\nEach JSON file contains a list of molecular data. An example molecule is given below:\n\n{\n\n'En': 37.801,\n\n 'atoms': [\n\n{'type': 'O', 'xyz': [0.3387, 0.9262, 0.46]},\n\n  {'type': 'O', 'xyz': [3.4786, -1.7069, -0.3119]},\n\n  {'type': 'O', 'xyz': [1.8428, -1.4073, 1.2523]},\n\n  {'type': 'O', 'xyz': [0.4166, 2.5213, -1.2091]},\n\n  {'type': 'N', 'xyz': [-2.2359, -0.7251, 0.027]},\n\n  {'type': 'C', 'xyz': [-0.7783, -1.1579, 0.0914]},\n\n  {'type': 'C', 'xyz': [0.1368, -0.0961, -0.5161]},\n\n  {'type': 'C', 'xyz': [-3.1119, -1.7972, 0.659]},\n\n  {'type': 'C', 'xyz': [-2.4103, 0.5837, 0.784]},\n\n  {'type': 'C', 'xyz': [-2.6433, -0.5289, -1.426]},\n\n  {'type': 'C', 'xyz': [1.4879, -0.6438, -0.9795]},\n\n  {'type': 'C', 'xyz': [2.3478, -1.3163, 0.1002]},\n\n  {'type': 'C', 'xyz': [0.4627, 2.1935, -0.0312]},\n\n  {'type': 'C', 'xyz': [0.6678, 3.1549, 1.1001]},\n\n  {'type': 'H', 'xyz': [-0.7073, -2.1051, -0.4563]},\n\n  {'type': 'H', 'xyz': [-0.5669, -1.3392, 1.1503]},\n\n  {'type': 'H', 'xyz': [-0.3089, 0.3239, -1.4193]},\n\n  {'type': 'H', 'xyz': [-2.9705, -2.7295, 0.1044]},\n\n  {'type': 'H', 'xyz': [-2.8083, -1.921, 1.7028]},\n\n  {'type': 'H', 'xyz': [-4.1563, -1.4762, 0.6031]},\n\n  {'type': 'H', 'xyz': [-2.0398, 1.417, 0.1863]},\n\n  {'type': 'H', 'xyz': [-3.4837, 0.7378, 0.9384]},\n\n  {'type': 'H', 'xyz': [-1.9129, 0.5071, 1.7551]},\n\n  {'type': 'H', 'xyz': [-2.245, 0.4089, -1.819]},\n\n  {'type': 'H', 'xyz': [-2.3, -1.3879, -2.01]},\n\n  {'type': 'H', 'xyz': [-3.7365, -0.4723, -1.463]},\n\n  {'type': 'H', 'xyz': [1.3299, -1.3744, -1.7823]},\n\n  {'type': 'H', 'xyz': [2.09, 0.1756, -1.3923]},\n\n  {'type': 'H', 'xyz': [-0.1953, 3.128, 1.7699]},\n\n  {'type': 'H', 'xyz': [0.7681, 4.1684, 0.7012]},\n\n  {'type': 'H', 'xyz': [1.5832, 2.901, 1.6404]}\n\n],\n\n 'id': 1,\n\n 'shapeM': [259.66,  4.28,  3.04,  1.21,  1.75,  2.55,  0.16,  -3.13,  -0.22,  -2.18,  -0.56,  0.21,  0.17,  0.09]\n\n}\n\n\n1. **En**: This field is the molecular energy calculated using a force-field method. See references [1,2] for details. This is the target variable which is being predicted.\n2. **atoms**: This field contains the name of the element and the position (x,y,z coordinates) and needs to be used for feature engineering.\n3. **id** : This field is the PubChem Id \n4. **shapeM** : This field contains the shape multipoles and can be used for feature engineering. For definition of shape multipoles, see reference [3].\n\nNotice that each molecule contains different number and types of atoms, so it is challenging to come up with features that can describe every molecule in \na unique way. There are several approaches taken in the literature (see the references), one of which is to use the Coulomb Matrix for a given molecule\ndefined by\n\n$$\nC_{IJ} = \\frac{Z_I  Z_J}{\\vert R_I - R_J \\vert}, \\quad  ({\\rm I \\neq J}) \\qquad\nC_{IJ} = Z_I^{2.4}, \\quad (I=J)\n$$\n\nwhere $Z_I$ are atomic numbers (can be looked up from the periodic table for each element), and ${\\vert R_I - R_J \\vert}$ is the distance between two atoms I and J. \nThe previous [dataset](https://www.kaggle.com/burakhmmtgl/energy-molecule) used these features for a subset of molecules given here, where the maximum number of\nelements in a given molecules was limited by 50.\n\nThere are around 100,000,000 molecules in the whole database. As more files are scraped, new data will be added in time. \n\nNote: In the previous [dataset](https://www.kaggle.com/burakhmmtgl/energy-molecule), the molecular energies were computed by quantum mechanical simulations. Here, the given energies are computed using another method, so their values are different. \n\n## Inspiration\nSimulations of molecular properties are computationally expensive. The purpose of this project is to use machine learning methods to come up with a model that can predict molecular properties from a database. In the PubChem database, there are around 100,000,000 molecules. It could take years to do simulations on all \nof these molecules, however machine learning can be used to predict their properties much faster. As a result, this could open up many possibilities in computational design and discovery of molecules, compounds and new drugs.\n\nThis is a regression problem so mean squared error is minimized during training.\n\nI am looking for Kagglers to find the best model and reduce mean squared error as much as possible!\n\n\n## References\n[1] Halgren TA. Merck Molecular Force Field: I. Basis, Form, Scope, Parameterization and Performance of MMFF94.  J. Comp. Chem. 1996;17:490-519.\n\n[2] Halgren TA. Merck Molecular Force Field: VI. MMFF94s Option for Energy Minimization Studies.  J. Comp. Chem. 1999;20:720-729.\n\n[3] Kim, Sunghwan, Evan E Bolton, and Stephen H Bryant. \xe2\x80\x9cPubChem3D: Shape Compatibility Filtering Using Molecular Shape Quadrupoles.\xe2\x80\x9d J. Cheminf. 3 (2011): 25.\n\n[4] Himmetoglu B.: Tree based machine learning framework for predicting ground state energies of molecules, J. Chem. Phys 145, 134101 (2016)\n\n[5] Rupp M., Ramakrishnan R., von Lilienfeld OA.: Machine Learning for Quantum Mechanical Properties of Atoms in Molecules, \nJ. Phys. Chem. Lett. , 6(16): 3309\xe2\x80\x933313 (2015)\n\n[6] Montavon G., Rupp M., Gobre V., Vazquez-Mayagoitia A., Hansen K., Tkatchenko A., M\xc3\xbcller K-R., von Lilienfeld OA.: Machine learning of molecular electronic properties in chemical compound space, New J. Phys., 15(9): 095003 (2013)\n\n[7] Hansen K., Montavon G., Biegler F., Fazli S., Rupp M., Scheffler M., von Lilienfeld OA., Tkatchenko A., M\xc3\xbcller K-P.: Assessment and Validation of Machine Learning Methods for Predicting Molecular Atomization Energies, J. Chem. Theory Comput. , 9(8): 3543\xe2\x80\x933556 (2013)""","b""['physics', 'chemistry', 'physical sciences', 'large', 'featured']""",https://www.kaggle.com/burakhmmtgl/predict-molecular-properties
b'Raw Twitter Timelines w/ No Retweets',b'These are complete twitter timelines of various popular celebs with no retweets',"b'This is a dataset of tweets from various active scientists and personalities ranging from Donald Trump and Hillary Clinton to Neil deGrasse Tyson. More are forthcoming.\n\nThey were obtained through javascript scraping of the browser twitter timeline rather than a Tweepy python API or the twitter timeline API.\n\nThe inspiration for this twitter dataset is comparing tweets in my own twitter analysis to find who tweets like whom, e.g. does Trump or Hillary tweet more like Kim Kardashian than one another?\n\nThus, this goes further back in time than anything directly available from Twitter.\n\nThe data is in JSON format rather than CSV, which will be forthcoming as well.\n\nKim Kardashian, Adam Savage, BillNye, Neil deGrasse Tyson, Donald Trump, and Hillary Clinton have been collected up to 2016-10-14\nRichard Dawkins, Commander Scott Kelly, Barack Obama, NASA, and The Onion, tweets up to 2016-10-15.\n\nFor your own pleasure, with special thanks to the Trump Twitter Archive for providing some of the code, here is the JavaScript used to scrape tweets off of a timeline and output the results to the clipboard in JSON format:\n\n1) Construct the query with from:TWITTERHANDLE since:DATE until:DATE\n\n2) In the browser console set up automatic scrolling with: \nsetInterval(function(){ scrollTo(0, document.body.scrollHeight) }, 2500)\n\n3) Scrape the resulting timeline with:\nvar allTweets = []; var tweetElements = document.querySelectorAll(\'li.stream-item\'); \n\nfor (var i = 0; i < tweetElements.length; i++) { try {\n    var el = tweetElements[i]; var text = el.querySelector(\'.tweet-text\').textContent; allTweets.push({ id: el.getAttribute(\'data-item-id\'), date: el.querySelector(\'.time a\').textContent, text: text, link: el.querySelector(\'div.tweet\').getAttribute(\'data-permalink-path\'), retweet: text.indexOf(\'\\""@\') == 0 && text.includes(\':\') ? true : false }); } catch(err) {}\n};\ncopy(allTweets);\n\nHave fun!'","b""['internet', 'linguistics', 'celebrity', 'medium', 'featured']""",https://www.kaggle.com/speckledpingu/RawTwitterFeeds
b'National Health and Nutrition Examination Survey',b'NHANES datasets from 2013-2014',"b'# Context \n\nThe [National Health and Nutrition Examination Survey (NHANES)](https://www.cdc.gov/Nchs/Nhanes/about_nhanes.htm) is a program of studies designed to assess the health and nutritional status of adults and children in the United States. The survey is unique in that it combines interviews and physical examinations. NHANES is a major program of the National Center for Health Statistics (NCHS). NCHS is part of the Centers for Disease Control and Prevention (CDC) and has the responsibility for producing vital and health statistics for the Nation.\n\nThe NHANES program began in the early 1960s and has been conducted as a series of surveys focusing on different population groups or health topics. In 1999, the survey became a continuous program that has a changing focus on a variety of health and nutrition measurements to meet emerging needs. The survey examines a nationally representative sample of about 5,000 persons each year. These persons are located in counties across the country, 15 of which are visited each year.\n\nThe NHANES interview includes demographic, socioeconomic, dietary, and health-related questions. The examination component consists of medical, dental, and physiological measurements, as well as laboratory tests administered by highly trained medical personnel.\n\nTo date, [thousands of research findings have been published using the NHANES data](https://www.ncbi.nlm.nih.gov/pubmed?orig_db=PubMed&term=NHANES&cmd=search).\n\n\n# Content\n\nThe [2013-2014 NHANES](https://wwwn.cdc.gov/Nchs/Nhanes/Search/Nhanes13_14.aspx) datasets include the following components:\n\n1. **Demographics dataset**: \n\n* A complete variable dictionary can be found [here](https://wwwn.cdc.gov/Nchs/Nhanes/Search/variablelist.aspx?Component=Demographics&CycleBeginYear=2013)\n\n2. **Examinations dataset**, which contains: \n\n* Blood pressure\n\n* Body measures\n\n* Muscle strength - grip test\n\n* Oral health - dentition\n\n* Taste & smell\n\n* A complete variable dictionary can be found [here](https://wwwn.cdc.gov/Nchs/Nhanes/Search/variablelist.aspx?Component=Examination&CycleBeginYear=2013)\n\n3. **Dietary data - total nutrient intake, first day**:  \n\n* A complete variable dictionary can be found [here](https://wwwn.cdc.gov/Nchs/Nhanes/Search/variablelist.aspx?Component=Dietary&CycleBeginYear=2013)\n\n4. **Laboratory dataset**, which includes: \n\n* Albumin & Creatinine - Urine\n\n* Apolipoprotein B\n\n* Blood Lead, Cadmium, Total Mercury, Selenium, and Manganese\n\n* Blood mercury: inorganic, ethyl and methyl\n\n* Cholesterol - HDL\n\n* Cholesterol - LDL & Triglycerides\n\n* Cholesterol - Total\n\n* Complete Blood Count with 5-part Differential - Whole Blood\n\n* Copper, Selenium & Zinc - Serum\n\n* Fasting Questionnaire\n\n* Fluoride - Plasma\n\n* Fluoride - Water\n\n* Glycohemoglobin\n\n* Hepatitis A\n\n* Hepatitis B Surface Antibody\n\n* Hepatitis B: core antibody, surface antigen, and Hepatitis D antibody\n\n* Hepatitis C RNA (HCV-RNA) and Hepatitis C Genotype\n\n* Hepatitis E: IgG & IgM Antibodies\n\n* Herpes Simplex Virus Type-1 & Type-2\n\n* HIV Antibody Test\n\n* Human Papillomavirus (HPV) - Oral Rinse\n\n* Human Papillomavirus (HPV) DNA - Vaginal Swab: Roche Cobas & Roche Linear Array\n\n* Human Papillomavirus (HPV) DNA Results from Penile Swab Samples: Roche Linear Array\n\n* Insulin\n\n* Iodine - Urine\n\n* Perchlorate, Nitrate & Thiocyanate - Urine\n\n* Perfluoroalkyl and Polyfluoroalkyl Substances (formerly Polyfluoroalkyl Chemicals - PFC)\n\n* Personal Care and Consumer Product Chemicals and Metabolites\n\n* Phthalates and Plasticizers Metabolites - Urine\n\n* Plasma Fasting Glucose\n\n* Polycyclic Aromatic Hydrocarbons (PAH) - Urine\n\n* Standard Biochemistry Profile\n\n* Tissue Transglutaminase Assay (IgA-TTG) & IgA Endomyseal Antibody Assay (IgA EMA)\n\n* Trichomonas - Urine\n\n* Two-hour Oral Glucose Tolerance Test\n\n* Urinary Chlamydia\n\n* Urinary Mercury\n\n* Urinary Speciated Arsenics\n\n* Urinary Total Arsenic\n\n* Urine Flow Rate\n\n* Urine Metals\n\n* Urine Pregnancy Test\n\n* Vitamin B12 \n\n* A complete data dictionary can be found [here](https://wwwn.cdc.gov/Nchs/Nhanes/Search/variablelist.aspx?Component=Laboratory&CycleBeginYear=2013)\n\n5. **Questionnaire dataset**, which includes information on:\n\n* Acculturation\n\n* Alcohol Use\n\n* Blood Pressure & Cholesterol\n\n* Cardiovascular Health\n\n* Consumer Behavior\n\n* Current Health Status\n\n* Dermatology\n\n* Diabetes\n\n* Diet Behavior & Nutrition\n\n* Disability\n\n* Drug Use\n\n* Early Childhood\n\n* Food Security\n\n* Health Insurance\n\n* Hepatitis\n\n* Hospital Utilization & Access to Care\n\n* Housing Characteristics\n\n* Immunization\n\n* Income\n\n* Medical Conditions\n\n* Mental Health - Depression Screener\n\n* Occupation\n\n* Oral Health\n\n* Osteoporosis\n\n* Pesticide Use\n\n* Physical Activity\n\n* Physical Functioning\n\n* Preventive Aspirin Use\n\n* Reproductive Health\n\n* Sexual Behavior\n\n* Sleep Disorders\n\n* Smoking - Cigarette Use\n\n* Smoking - Household Smokers\n\n* Smoking - Recent Tobacco Use\n\n* Smoking - Secondhand Smoke Exposure\n\n* Taste & Smell\n\n* Weight History\n\n* Weight History - Youth\n\n* A complete variable dictionary can be found [here](https://wwwn.cdc.gov/Nchs/Nhanes/Search/variablelist.aspx?Component=Questionnaire&CycleBeginYear=2013)\n\n6. **Medication dataset**, which includes prescription medications:\n\n* A complete variable dictionary can be found [here](https://wwwn.cdc.gov/Nchs/Nhanes/Search/variablelist.aspx?Component=Questionnaire&CycleBeginYear=2013)\n\n# Acknowledgements\n\nOriginal data and additional documents related to the datasets or NHANES can be found [here](https://wwwn.cdc.gov/Nchs/Nhanes/Default.aspx).'","b""['healthcare', 'health', 'medium', 'featured']""",https://www.kaggle.com/cdc/national-health-and-nutrition-examination-survey
b'FourSquare - NYC and Tokyo Check-ins',b'Check-ins in NYC and Tokyo collected for about 10 months',"b""# Context \n\nThis dataset contains check-ins in NYC and Tokyo collected for about 10 month (from 12 April 2012 to 16 February 2013). It contains 227,428 check-ins in New York city and 573,703 check-ins in Tokyo. Each check-in is associated with its time stamp, its GPS coordinates and its semantic meaning (represented by fine-grained venue-categories). This dataset is originally used for studying the spatial-temporal regularity of user activity in LBSNs.\n\n\n# Content\n\nThis dataset includes long-term (about 10 months) check-in data in New York city and Tokyo collected from Foursquare from 12 April 2012 to 16 February 2013.\nIt contains two files in tsv format. Each file contains 8 columns, which are:\n\n1. User ID (anonymized)\n2. Venue ID (Foursquare)\n3. Venue category ID (Foursquare)\n4. Venue category name (Fousquare)\n5. Latitude\n6. Longitude\n7. Timezone offset in minutes (The offset in minutes between when this check-in occurred and the same time in UTC)\n8. UTC time\n\nThe file dataset_TSMC2014_NYC.txt contains 227428 check-ins in New York city.\nThe file dataset_TSMC2014_TKY.txt contains 537703 check-ins in Tokyo.\n\n\n# Acknowledgements\nThis dataset is acquired from [here][1]\n\nFollowing is the citation of the dataset author's paper:\n\nDingqi Yang, Daqing Zhang, Vincent W. Zheng, Zhiyong Yu. Modeling User Activity Preference by Leveraging User Spatial Temporal Characteristics in LBSNs. IEEE Trans. on Systems, Man, and Cybernetics: Systems, (TSMC), 45(1), 129-142, 2015. [PDF][2]\n\n# Inspiration\nOne of the questions that I am trying to answer is if there is a pattern in users' checkin behaviour. For example, if it's a Friday evening, what all places they might be interested to visit.\n\n\n  [1]: https://sites.google.com/site/yangdingqi/home/foursquare-dataset\n  [2]: http://www-public.it-sudparis.eu/~zhang_da/pub/TSMC_YANG_2014.pdf""","b""['internet', 'geography', 'cities', 'medium', 'featured']""",https://www.kaggle.com/chetanism/foursquare-nyc-and-tokyo-checkin-dataset
b'CMS State Summary of Outpatient Charge Data',b'Explore open data from the CMS',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the Centers for Medicare & Medicaid Services (CMS). The organization has an open data platform found [here](https://data.cms.gov/) and they update their information according the amount of data that is brought in. Explore CMS's Data using Kaggle and all of the data sources available through the CMS [organization page](https://www.kaggle.com/cms)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: NA, Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cms/cms-state-summary-of-outpatient-charge-data
b'Human Activity Recognition with Smartphones',b'Recordings of 30 study participants performing activities of daily living',"b'The Human Activity Recognition database was built from the recordings of 30 study participants performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors. *The objective is to classify activities into one of the six activities performed*.\n\n## Description of experiment\n\nThe experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. \n\nThe sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.\n\n## Attribute information\n\nFor each record in the dataset the following is provided: \n\n- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration. \n\n- Triaxial Angular velocity from the gyroscope. \n\n- A 561-feature vector with time and frequency domain variables. \n\n- Its activity label. \n\n- An identifier of the subject who carried out the experiment.\n\n## Relevant papers\n\nDavide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. *International Workshop of Ambient Assisted Living (IWAAL 2012)*. Vitoria-Gasteiz, Spain. Dec 2012 \n\nDavide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge L. Reyes-Ortiz. Energy Efficient Smartphone-Based Activity Recognition using Fixed-Point Arithmetic. *Journal of Universal Computer Science. Special Issue in Ambient Assisted Living: Home Care*. Volume 19, Issue 9. May 2013\n\nDavide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. 4th International Workshop of Ambient Assited Living, IWAAL 2012, Vitoria-Gasteiz, Spain, December 3-5, 2012. *Proceedings. Lecture Notes in Computer Science* 2012, pp 216-223. \n\nJorge Luis Reyes-Ortiz, Alessandro Ghio, Xavier Parra-Llanas, Davide Anguita, Joan Cabestany, Andreu Catal\xc3\xa0. Human Activity and Motion Disorder Recognition: Towards Smarter Interactive Cognitive Environments. *21st European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN* 2013. Bruges, Belgium 24-26 April 2013.\n\n## Citation\n\nDavide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. *21st European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN* 2013. Bruges, Belgium 24-26 April 2013.'","b""['sociology', 'telecommunications', 'human-computer interaction', 'medium', 'featured']""",https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones
b'NYS SPDES Multi-Sector General Permitted Facility',b'From New York State Open Data',"b""### Content  \n\nThe SPDES Multi-Sector General Permit (MSGP), which is administered by the Department of Environmental Conservation (the Department), regulates stormwater discharges associated with industrial activity from a point source.  The MSGP covers thirty one different industrial sectors which include activities such as mining, land transportation, and scrap recycling.  The dataset displays information on facilities that have active MSGP coverage in New York State.   Information included in the data set include the facility\xe2\x80\x99s name, address, contact information, industrial sector(s), discharging waterbody, and location of the facility\xe2\x80\x99s Stormwater Pollution Prevention Plan.  For more information, please go to http://www.dec.ny.gov/chemical/62803.html.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/UwBrS-qRMHo) by [veeterzy](https://unsplash.com/@veeterzy) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-spdes-multi-sector-general-permitted-facility
b'Stanford Open Policing Project - North Carolina',b'Data on Traffic and Pedestrian Stops by Police in North Carolina',"b""###Context: \n\nOn a typical day in the United States, police officers make more than 50,000 traffic stops. The Stanford Open Policing Project team is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public.\n\nIf you'd like to see data regarding other states, please go to https://www.kaggle.com/stanford-open-policing.\n\n### Content: \n\nThis dataset includes 1.6 gb of stop data from North Carolina, covering all of 2010 onwards. Please see the data readme for the full details of the available fields.\n\n###Acknowledgements:\n\nThis dataset was kindly made available by the [Stanford Open Policing Project][1]. If you use it for a research publication, please cite their [working paper][2]:\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, V. Ramachandran, C. Phillips, S. Goel. (2017) \xe2\x80\x9cA large-scale analysis of racial disparities in police stops across the United States\xe2\x80\x9d.\n\n###Inspiration: \n\n - How predictable are the stop rates? Are there times and places that\n   reliably generate stops?\n - Concerns have been raised about jurisdictions using civil forfeiture\n   as a funding mechanism rather than to properly fight drug\n   trafficking. Can you identify any jurisdictions that may be\n   exhibiting this behavior?\n\n  [1]: https://openpolicing.stanford.edu/\n  [2]: https://5harad.com/papers/traffic-stops.pdf""","b""['crime', 'law', 'large', 'featured']""",https://www.kaggle.com/stanford-open-policing/stanford-open-policing-project-north-carolina
b'Analysis about crypto currencies and Stock Index',b'Relation and patterns between movements of stock exchange indexes and cryptocurrency',"b""\xc2\xabDatasets per la comparaci\xc3\xb3 de moviments i patrons entre els principals \xc3\xadndexs borsatils espanyols i les crypto-monedes\xc2\xbb\n\n### Context\n\nEn aquest cas el context \xc3\xa9s detectar o preveure els diferents moviments que es produeixen per una serie factors, tant de moviment interns (compra-venda), com externs (moviments pol\xc3\xadtics, econ\xc3\xb2mics, etc...), en els principals \xc3\xadndexs borsatils espanyols i de les crypto-monedes.\n\nHem seleccionat diferents fonts de dades per generar fitxers \xc2\xabcsv\xc2\xbb, guardar diferents valors en el mateix per\xc3\xadode de temps. \xc3\x89s important destacar que ens interessa m\xc3\xa9s les tend\xc3\xa8ncies alcistes o baixes, que podem calcular o recuperar en aquests per\xc3\xadodes de temps.\n\n### Content\n\nEn aquest cas el contingut est\xc3\xa0 format per diferents csv, especialment tenim els fitxers de moviments de cryptomoneda, els quals s\xe2\x80\x99ha generat un fitxer per dia del per\xc3\xadode de temps estudiat.\n\nPel que fa als moviments del principals \xc3\xadndexs borsatils s\xe2\x80\x99ha generat una carpeta per dia del per\xc3\xadode, en cada directori un fitxer amb cadascun del noms dels \xc3\xadndexs. Degut aix\xc3\xb2 s\xe2\x80\x99han comprimit aquests \xc3\xbaltims abans de publicar-los en el directori de \xc2\xabopen data\xc2\xbb kaggle.com.\n\nPel que fa als camps, ens interess\xc3\xa0 detectar els moviments alcistes i baixistes, o almenys aquelles que tenen un patr\xc3\xb3 similar en les cryptomonedes i els \xc3\xadndexs. Els camps especialment destacats s\xc3\xb3n:\n\n    \xe2\x80\xa2 Data: Data de la observaci\xc3\xb3\n    \xe2\x80\xa2 Nom: Nom empresa o cryptomoneda, per identificar de quina moneda o index estem representant.\n    \xe2\x80\xa2 S\xc3\xadmbol: S\xc3\xadmbol de la moneda o del index borsatil, per realitzar gr\xc3\xa0fic posteriorment d\xe2\x80\x99una forma mes senzilla que el nom.\n    \xe2\x80\xa2 Preu: Valor en euros d\xe2\x80\x99una acci\xc3\xb3 o una cryptomoneda (transformarem la moneda a euros en el cas de estigui en d\xc3\xb2lars amb l'\xc3\xbaltima cotitzaci\xc3\xb3 (un dollar a 0,8501 euro)\n    \xe2\x80\xa2 Tipus_cotitzacio: Valor nou que agregarem per discretitzar entre la cotitzaci\xc3\xb3: baix (0 i 1), normal (1 i 100), alt (100 i 1000), molt_alt (&gt;1000)\n\n# Script R\n\n* An\xc3\xa0lisis de les observacions i el domini de les dades\n* An\xc3\xa0lisis en especial de Bitcoin i la IOTA.\n* Test de Levene per veure la homogeneitat\n* Kmeans per creaci\xc3\xb3 de cluster per veure la homegeneitat\n* Freq\xc3\xbc\xc3\xa8ncies de les distribucions\n* Test de contrast d'hip\xc3\xb2tesis de variables dependents (Wilcoxon)\n* Test de Shapiro-Wilk per veure la normalitat de les dades, per normalitzar-les o no\n* Correlaci\xc3\xb3 d'\xc3\xadndexs borsatils, per eliminar complexitat dels \xc3\xadndexs amb grau m\xc3\xa9s alt de correlaci\xc3\xb3\n* Iteraci\xc3\xb3 de Regressions lineals per obtenir el model amb m\xc3\xa9s qualitat, observa'n el p-valor i l'\xc3\xadndex de correlaci\xc3\xb3\n* Validaci\xc3\xb3 de la qualitat del model\n* Representaci\xc3\xb3 grafica\n\n### Acknowledgements\n\nEn aquest cas les fonts de dades que s\xe2\x80\x99han utilitzat per a la realitzaci\xc3\xb3 dels datasets corresponent a:\n\n - http://www.eleconomista.es\n - https://coinmarketcap.com\n\nPer aquest fet, les dades de borsa i crypto-moneda estan en \xc3\xbaltima inst\xc3\xa0ncia sota llic\xc3\xa8ncia de les webs respectivament.\nPel que fa a la terminologia financera podem veure vocabulari en renta4banco.  \n[https://www.r4.com/que-necesitas/formacion/diccionario]\n\n### Inspiration\n\nHi ha un estudi anterior on poder tenir prim\xc3\xadcies de com han enfocat els algoritmes:     \n\n - https://arxiv.org/pdf/1410.1231v1.pdf\n\nEn aquest cas el \xc2\xabtrading\xc2\xbb en cryptomoneda \xc3\xa9s relativament nou, for\xc3\xa7a popular per la seva formulaci\xc3\xb3 com a mitja digital d\xe2\x80\x99intercanvi, utilitzant un protocol que garanteix la seguretat, integritat i equilibri del seu estat de compte per mitj\xc3\xa0 d\xe2\x80\x99un entramat d\xe2\x80\x99agents.\n\nLa comunitat podr\xc3\xa0 respondre, entre altres preguntes, a:\n\n - Est\xc3\xa0 afectant o hi ha patrons comuns en les cotitzacions de cryptomonedes i el mercat de valors principals del pa\xc3\xads d'Espanya?\n - Els efectes o agents externs afecten per igual a les accions o cryptomonedes? \n - Hi ha relacions cause efecte entre les acciones i cryptomonedes?\n\n### Project repository\nhttps://github.com/acostasg/scraping\n\n### Datasets\nEls fitxers csv generats que componen el dataset s\xe2\x80\x99han publicat en el repositori kaggle.com:\n\n* https://www.kaggle.com/acostasg/stock-index/ \n* https://www.kaggle.com/acostasg/crypto-currencies\n\nPer una banda, els fitxers els \xc2\xabstock-index\xc2\xbb estan comprimits per carpetes amb la data d\xe2\x80\x99extracci\xc3\xb3 i cada fitxer amb el nom dels \xc3\xadndexs borsatil.  De forma diferent, les cryptomonedes aquestes estan dividides per fitxer on s\xc3\xb3n totes les monedes amb la data d\xe2\x80\x99extracci\xc3\xb3.""","b""['economics', 'time series', 'money', 'small', 'featured']""",https://www.kaggle.com/acostasg/cryptocurrenciesvsstockindex
b'Football Matches of Spanish League',b'Soccer matches of 1st and 2nd division from season 1970-71 to 2016-17',"b""### Context\n\nData Set with the football matches of the Spanish league of the 1st and 2nd division from the 1970-71 to 2016-17 season, has been created with the aim of opening a line of research in the Machine Learning, for the prediction of results (1X2) of football matches.\n\n\n### Content\n\nThis file contains information about a football matches with the follow features:\n\n```\n4808,1977-78,1,8,Rayo Vallecano,Real Madrid,3,2,30/10/1977,247014000\n```\n\n- id (4808): Unique identifier of football match\n- season (1977-78): Season in which the match was played\n- division (1): Divisi\xc3\xb3n in which the match was played (1st '1', 2nd '2')\n- round (8): round in which the match was played\n- localTeam (Rayo Vallecano): Local Team name\n- visitorTeam (Real Madrid): Visitor Team name\n- localGoals (3): Goals scored by the local team\n- visitorGoals (2): Goals scored by the visitor team\n- fecha (30/10/1977): Date in which the match was played\n- date (247014000): Timestamp in which the match was played\n\n### Acknowledgements\n\nScraping made from:\n\n 1. http://www.bdfutbol.com\n 2. http://www.resultados-futbol.com""","b""['sports', 'association football', 'american football', 'small', 'featured']""",https://www.kaggle.com/ricardomoya/football-matches-of-spanish-league
b'New York City Bus Data',"b'Live data recorded from NYC Buses - Location, Time, Schedule & more'","b""### Context\n\nI wanted to find a better way to provide live traffic updates. We dont all have access to the data from traffic monitoring sensors or whatever gets uploaded from people's smart phones to Apple, Google etc plus I question how accurate the traffic congestion is on Google Maps or other apps. So I figured that since buses are also in the same traffic and many buses stream their GPS location and other data live, that would be an ideal source for traffic data. I investigated the data streams available from many bus companies around the world and found MTA in NYC to be very reliable. \n\n\n### Content\n\nThis dataset is from the NYC MTA buses data stream service. In roughly 10 minute increments the bus location, route, bus stop and more is included in each row. The scheduled arrival time from the bus schedule is also included, to give an indication of where the bus should be (how much behind schedule, or on time, or even ahead of schedule).\n\n\n\n### Acknowledgements\n\nData is recorded from the MTA SIRI Real Time data feed and the MTA GTFS Schedule data.\n\n\n### Inspiration\n\nI want to see what exploratory & discovery people come up with from this data. Feel free to download this dataset for your own use however I would appreciate as many Kernals included on Kaggle as we can get. \n\nBased on the interest this generates I plan to collect more data for subsequent months down the track.""","b""['transport', 'public transport', 'large', 'featured']""",https://www.kaggle.com/stoney71/new-york-city-transport-statistics
b'U.S. Charities and Non-profits',b'All of the charities and non-profits registered with the IRS',"b'### Context\n\nThis dataset comes from ""The Exempt Organization Business Master File Extract"" (EO BMF) which includes cumulative information on tax-exempt organizations. \n\n\n### Content\n\nData is current up to: 8/14/2017\n\n- EIN: Employer Identification Number (EIN)\n- NAME: Primary Name of Organization\n- ICO: In Care of Name\n- STREET: Street Address\n- CITY: City\n- STATE: State\n- ZIP: Zip Code\n- GROUP: Group Exemption Number\n- SUBSECTION: Subsection Code\n- AFFILIATION: Affiliation Code\n- CLASSIFICATION: Classification Code(s)\n- RULING: Ruling Date\n- DEDUCTIBILITY: Deductibility Code\n- FOUNDATION: Foundation Code\n- ACTIVITY: Activity Codes\n- ORGANIZATION: Organization Code\n- STATUS: Exempt Organization Status Code\n- TAX_PERIOD: Tax Period\n- ASSET_CD: Asset Code\n- INCOME_CD: Income Code\n- FILING_REQ_CD: Filing Requirement Code\n- PF_FILING_REQ_CD: PF Filing Requirement Code\n- ACCT_PD: Accounting Period\n- ASSET_AMT: Asset Amount\n- INCOME_AMT: Income Amount (includes negative sign if amount is negative)\n- REVENUE_AMT: Form 990 Revenue Amount (includes negative sign if amount is negative)\n- NTEE_CD: National Taxonomy of Exempt Entities (NTEE) Code\n- SORT_NAME: Sort Name (Secondary Name Line)\n\n\nThere are six data files separated by regions\n\n### eo1:\n- CT\n- MA\n- ME\n- NH\n- NJ\n- NY\n- RI\n- VT\n\n### eo2:\n\n- DC\n- DE\n- IA\n- IL\n- IN\n- KY\n- MD\n- MI\n- MN\n- NC\n- ND\n- NE\n- OH\n- PA\n- SC\n- SD\n- VA\n- WI\n- WV\n\n### eo3:\n\n- AK\n- AL\n- AR\n- AZ\n- CA\n- CO\n- FL\n- GA\n- HI\n- ID\n- KS\n- LA\n- MO\n- MS\n- MT\n- NM\n- NV\n- OK\n- OR\n- TN\n- TX\n- UT\n- WA\n- WY\n\n### eo4:\n\n- AA\n- AE\n- AP\n- AS\n- FM\n- GU\n- MH\n- MP\n- PR\n- PW\n- VI\n\n### eo_pr:\n\n- Puerto Rico\n\n### eo_xx:\n\nVarious international non-profits (too many countries to list). See columns 5 and 6.\n\n\n### Acknowledgements\n\nMore information and updated data an be found [here][1]\n\n  [1]: https://www.irs.gov/charities-non-profits/exempt-organizations-business-master-file-extract-eo-bmf'","b""['medium', 'featured']""",https://www.kaggle.com/crawford/us-charities-and-nonprofits
b'Chicago Energy Benchmarking',b'From City of Chicago Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/Zxs4tMZzdS8) by [Thomas Jarrand](https://unsplash.com/@tom32i) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'energy', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-energy-benchmarking
b'2015 Flight Delays and Cancellations',b'Which airline should you fly on to avoid significant delays?',"b""# Context \n\nThe U.S. Department of Transportation's (DOT) Bureau of Transportation Statistics tracks the on-time performance of domestic flights operated by large air carriers. Summary information on the number of on-time, delayed, canceled, and diverted flights is published in DOT's monthly Air Travel Consumer Report and in this dataset of 2015 flight delays and cancellations.\n\n\n# Acknowledgements\n\nThe flight delay and cancellation data was collected and published by the DOT's Bureau of Transportation Statistics.""","b""['aviation', 'medium', 'featured']""",https://www.kaggle.com/usdot/flight-delays
b'Chicago Early Learning Programs',b'From City of Chicago Open Data',"b""### Content  \n\nThis is a list of all early learning programs funded by the City of Chicago.  For more information, please see http://chicagoearlylearning.org.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/us5m1-uOLfc) by [Cel Lisboa](https://unsplash.com/@cellisboa) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'education', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-early-learning-programs
b'World Atlas of Language Structures',"b'Information on the linguistic structures in 2,679  languages'","b""### Context: \nThere are over 7,000 human languages in the world. The World Atlas of Language Structures (WALS) contains information on the structure of 2,679 of them. It also includes information about where languages are used. WALS is widely-cited and used in the linguistics research community.\n### Content:\nThe World Atlas of Language Structures (WALS) is a large database of structural (phonological, grammatical, lexical) properties of languages gathered from descriptive materials (such as reference grammars) by a team of 55 authors. The atlas provides information on the location, linguistic affiliation and basic [typological](https://en.wikipedia.org/wiki/Language_typology) features of a great number of the world's languages\n\nWALS Online is a publication of the (Max Planck Institute for Evolutionary Anthropology)[http://www.eva.mpg.de/]. It is a separate publication, edited by Dryer, Matthew S. & Haspelmath, Martin (Leipzig: Max Planck Institute for Evolutionary Anthropology, 2013) The main programmer is Robert Forkel.\n\nThis dataset includes three files:\n\n* **source.bib**: A BibTex file with all of the sources cited in the dataset in it\n* **language.csv**: A file with a list of all the languages included in WALS\n* **wals-data.csv**: A file containing information on the features associated with each individual language\n \n### Acknowledgements: \n\nThis dataset is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/) .\n\nThe World Atlas of Language Structures was edited by Matthew Dryer and Martin Haspelmath. If you use this data in your work, please include the following citation: \n\nDryer, Matthew S. & Haspelmath, Martin (eds.) 2013. The World Atlas of Language Structures Online. Leipzig: Max Planck Institute for Evolutionary Anthropology. (Available online at http://wals.info, Accessed on September 7, 2017.)\n\n### Inspiration: \n\n* This dataset was designed to make interactive maps of language features. Can you make an interactive map that shows different linguistic features? You might find it helpful to use Leaflet (for R) or Plotly (for Python). [This blog post](http://blog.kaggle.com/2016/11/30/seventeen-ways-to-map-data-in-kaggle-kernels/) is a great resource to help you get started.\n* There\xe2\x80\x99s a lot of discussion of \xe2\x80\x9c[linguistic universals](https://en.wikipedia.org/wiki/Linguistic_universal)\xe2\x80\x9d in linguistics. These are specific features that every language (should) have. Can you identify any features that you think may be universals from this dataset?\n\n### You may also like:\n\n* [Atlas of Pidgin and Creole Language Structures: Information on 76 Creole and Pidgin Languages](https://www.kaggle.com/rtatman/atlas-of-pidgin-and-creole-language-structures)\n* [World Language Family Map](https://www.kaggle.com/rtatman/world-language-family-map)\n* [The Sign Language Analyses (SLAY) Database](https://www.kaggle.com/rtatman/sign-language-analyses)""","b""['linguistics', 'languages', 'medium', 'featured']""",https://www.kaggle.com/rtatman/world-atlas-of-language-structures
b'NYS Commercial Nuisance Wildlife Control Operators',b'From New York State Open Data',"b""### Content  \n\nThis dataset contains contact information for commercial Nuisance Wildlife Control Operators (NWCO) currently licensed in New York State. These control operators are licensed by the New York State Department of Environmental Conservation (DEC) Bureau of Fish and Wildlife Services.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/0pDUGYuDYWw) by [Bhargava Srivari](https://unsplash.com/@srivarib) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-commercial-nuisance-wildlife-control-operators
b'SqueezeNet 1.0',b'SqueezeNet 1.0 Pre-trained Model for PyTorch',"b'# SqueezeNet 1.0\n\n---\n\n## SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size<br>\nRecent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). \n<br>\n\n**Authors: Forrest N. Iandola, Song Han, Matthew W. Moskewicz, Khalid Ashraf, William J. Dally, Kurt Keutzer**<br>\n**https://arxiv.org/abs/1602.07360**\n\n---\n\n#SqueezeNet Architectures<br>\n![SqueezeNet Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/WV7Ru4Q.jpg'","b""['machine learning', 'pre-trained model', 'small', 'featured']""",https://www.kaggle.com/pytorch/squeezenet1
b'Candidate list for 2018 election (Pakistan)',b'Predict the next PM of Pakistan',"b'### Predict winner of next election\n\nWe have compiled the list of candidates for 2018 election along with following details: District, Seat, Constituency_title, Candidate_Name, Party. This dataset coupled with the 2002, 2008 and 2013 datasets(https://www.kaggle.com/zusmani/predict-pakistan-elections-2018/home) can be used for analyzing the coming elections (2018) of Pakistan\n\n\n### Acknowledgements\nABDUL BASIT, ARSALAN, ASAD ALI KHAN, AYAZ QURESHI, HAMZA MOTAN, INDAH KHOKHAR, MUHAMMAD ABDULLAH, MUHAMMAD NIBRAS NASIR, MUHAMMAD RAFAY BANGASH, MUSTANSIR BILLAH ASAD ABBASI, MUZAMMIL SHABBIR, RABI AHMED, RASHID RAHIM, SAAD ULLAH, SHAHZHOB AHMED KHAN, SHAIKH WALEED, SHARIF TAQI, SYED ZAIN UDDIN, SYEDA SABIKA RAZA, TALHA SAJJAD , UMAIR PERVEZ , USMAN KHAN , ZAIN QURESHI\n\n### What you can do?\n\nAnalyze the winner of coming election. Visualize in different ways the candidates based on their party, provinces etc.'","b""['data visualization', 'classification', 'regression analysis', 'small', 'featured']""",https://www.kaggle.com/nomanislam/candidate-list-for-2018-election-pakistan
b'Subtitles of The Eleventh House podcast',b'Find out hidden meaning behind current affairs',"b""Context:\n\nYoutube has introduced automatic generation of subtitles based on speech recognition of uploaded video. This dataset provides collection of subtitles Robert Phoenix The 11th House uploaded podcasts. It serves as database for an introduction to algorithmic analysis of spoken language.\n\nFrom the podcasts author description: \xe2\x80\x9cThe Eleventh House is the home of Robert Phoenix, a journalist, blogger, interviewer, astrologer and psychic medium with over 30 years experience in personal readings and coaching, and has been a media personality in TV and radio. The 11th house delves into the supernatural, geopolitics, exopolitics, conspiracy theories, and pop culture.\xe2\x80\x9d \n\n\nContent:\n\nThe 11th House speeches dataset consists of 543 subtitles (sets of words) retrieved from Youtube playlists: \nhttps://www.youtube.com/user/FreeAssociationRadio/videos\n\nThis dataset consists of a single CSV file RobertPhoenixThe11thHouse.csv. The columns are: 'id', 'playlist', 'upload_date', 'title', 'view_count', 'average_rating', 'like_count', 'dislike_count', 'subtitles', which are delimited with a comma.\n\nText data in columns 'subtitles' is not sentence based, there are not commas or dots. It is only stream of words being translated from speech into text by GoogleVoice (more here https://googleblog.blogspot.com.au/2009/11/automatic-captions-in-youtube.html).\n\nAcknowledgements:\n\nThe data was downloaded using youtube-dl package.\n\nInspiration:\n\nI'm interested in a deeper meaning behind current affairs. (For example see http://www.blogtalkradio.com/freeassociationradio)""","b""['linguistics', 'politics', 'popular culture', 'storytelling', 'psychology', 'medium', 'featured']""",https://www.kaggle.com/binksbiz/robert
"b'Country Socioeconomic Status Scores, Part II'",b'Country-weighted measures of SES',"b'This dataset contains estimates of the socioeconomic status (SES) position of each of 149 countries covering the period 1880-2010. Measures of SES, which are in decades, allow for a 130 year time-series analysis of the changing position of countries in the global status hierarchy. SES scores are the average of each country\xe2\x80\x99s income and education ranking and are reported as percentile rankings ranging from 1-99. As such, they can be interpreted similarly to other percentile rankings, such has high school standardized test scores. If country A has an SES score of 55, for example, it indicates that 55 percent of the countries in this dataset have a lower average income and education ranking than country A. ISO alpha and numeric country codes are included to allow users to merge these data with other variables, such as those found in the World Bank\xe2\x80\x99s World Development Indicators Database and the United Nations Common Database.\n\nSee here for a working example of how the data might be used to better understand how the world came to look the way it does, at least in terms of status position of countries. \n\nVARIABLE DESCRIPTIONS: \n\nunid: ISO numeric country code (used by the United Nations) \n\nwbid: ISO alpha country code (used by the World Bank) \n\nSES: Country socioeconomic status score (percentile) based on GDP per capita and educational attainment (n=174) \n\ncountry: Short country name \n\nyear: Survey year \n\ngdppc: GDP per capita: Single time-series (imputed) \n\nyrseduc: Completed years of education in the adult (15+) population \n\nregion5: Five category regional coding schema\n\nregionUN: United Nations regional coding schema\n\nDATA SOURCES: \n\nThe dataset was compiled by Shawn Dorius (sdorius@iastate.edu) from a large number of data sources, listed below. GDP per Capita: \n\n1. Maddison, Angus. 2004. \'The World Economy: Historical Statistics\'. Organization for Economic Co-operation and Development: Paris. GDP & GDP per capita data in (1990 Geary-Khamis dollars, PPPs of currencies and average prices of commodities). Maddison data collected from: http://www.ggdc.net/MADDISON/Historical_Statistics/horizontal-file_02-2010.xls. \n\n2. World Development Indicators Database Years of Education 1. Morrisson and Murtin.2009. \'The Century of Education\'. Journal of Human Capital(3)1:1-42. Data downloaded from http://www.fabricemurtin.com/ 2. Cohen, Daniel & Marcelo Cohen. 2007. \'Growth and human capital: Good data, good results\' Journal of economic growth 12(1):51-76. Data downloaded from http://soto.iae-csic.org/Data.htm \n\n3. Barro, Robert and Jong-Wha Lee, 2013, ""A New Data Set of Educational Attainment in the World, 1950-2010."" Journal of Development Economics, vol 104, pp.184-198. Data downloaded from http://www.barrolee.com/ \n\n1. Maddison, Angus. 2004. \'The World Economy: Historical Statistics\'. Organization for Economic Co-operation and Development: Paris. 13. \n\n2. United Nations Population Division. 2009.'","b""['economics', 'demographics', 'sociology', 'small', 'featured']""",https://www.kaggle.com/sdorius/countryses
b'Online Job Postings',"b'Dataset of 19,000 online job posts from 2004 to 2015'","b'# Job Posts dataset\n\nThe dataset consists of 19,000 job postings that were posted through the Armenian human resource portal CareerCenter. The data was extracted from the Yahoo! mailing group https://groups.yahoo.com/neo/groups/careercenter-am. This was the only online human resource portal in the early 2000s. \nA job posting usually has some structure, although some fields of the posting are not necessarily filled out by the client (poster). The data was cleaned by removing posts that were not job related or had no structure.\nThe data consists of job posts from 2004-2015    \n# Content\njobpost \xe2\x80\x93 The original job post  \ndate \xe2\x80\x93 Date it was posted in the group              \nTitle \xe2\x80\x93 Job title  \nCompany - employer          \nAnnouncementCode \xe2\x80\x93 Announcement code (some internal code, is usually missing)  \nTerm \xe2\x80\x93 Full-Time, Part-time, etc                \nEligibility -- Eligibility of the candidates  \nAudience  --- Who can apply?        \nStartDate \xe2\x80\x93 Start date of work   \nDuration  - Duration of the employment        \nLocation \xe2\x80\x93 Employment location  \nJobDescription \xe2\x80\x93 Job Description   \nJobRequirment  - Job requirements  \nRequiredQual   -Required Qualification   \nSalary      - Salary  \nApplicationP \xe2\x80\x93 Application Procedure  \nOpeningDate \xe2\x80\x93 Opening date of the job announcement  \nDeadline \xe2\x80\x93 Deadline for the job announcement          \nNotes   - Additional Notes  \nAboutC  - About the company          \nAttach  - Attachments  \nYear -  Year of the announcement (derived from the field date)              \nMonth - Month of the announcement (derived from the field date)  \nIT \xe2\x80\x93 TRUE if the job is an IT job. This variable is created by a simple \tsearch of IT job titles within column \xe2\x80\x9cTitle\xe2\x80\x9d   \n\n# Acknowledgements\nThe data collection and initial research was funded by the American University of Armenia\xe2\x80\x99s research grant (2015). \n# Inspiration\nThe online job market is a good indicator of overall demand for labor in the local economy. In addition, online job postings data are easier and quicker to collect, and they can be a richer source of information than more traditional job postings, such as those found in printed newspapers. \nThe data can be used in the following ways: \n-Understand the demand for certain professions, job titles, or industries\n-Help universities with curriculum development\n-Identify skills that are most frequently required by employers, and how the distribution of \tnecessary skills changes over time\n-Make recommendations to job seekers and employers\n\n#Past research\nWe have used association rules mining and simple text mining techniques to analyze the data. Some results can be found here (https://www.slideshare.net/HabetMadoyan/it-skills-analysis-63686238).'","b""['linguistics', 'employment', 'medium', 'featured']""",https://www.kaggle.com/madhab/jobposts
b'Nutrition facts for Starbucks Menu',"b'Nutrition information for Starbucks menu items, including food and drinks'","b""### Context: \nStarbucks is an American coffee chain founded in Seattle. It serves both beverages and food. \n\n### Content: \nThis dataset includes the nutritional information for Starbucks\xe2\x80\x99 food and drink menu items. All nutritional information for drinks are for a 12oz serving size.\n\n### Acknowledgements: \nFood composition data is in the public domain, but product names marked with \xc2\xae or \xe2\x84\xa2 remain the registered trademarks of Starbucks.\n\n### Inspiration: \n\n* Can you train a Markov Chain to generate new Starbucks drink or food items?\n* Can you design an easy-to-interpret visualization for the nutrition of each item?\n* How to Starbucks menu items compare to McDonald\xe2\x80\x99s menu items (see link to dataset below) in terms of nutrition?\n\n### You may also like:\n\n* [Nutrition Facts for McDonald's Menu][1] \n* [Starbucks Locations Worldwide][2]  \n\n[1]: https://www.kaggle.com/mcdonalds/nutrition-facts\n[2]: https://www.kaggle.com/starbucks/store-locations""","b""['food and drink', 'nutrition', 'small', 'featured']""",https://www.kaggle.com/starbucks/starbucks-menu
b'Getting Real about Fake News',b'Text & metadata from fake & biased news sources around the web',"b'The latest hot topic in the news is fake news and many are wondering what data scientists can do to detect it and stymie its viral spread. This dataset is only a first step in understanding and tackling this problem. It contains text and metadata scraped from 244 websites tagged as ""bullshit"" by the [BS Detector][2] Chrome Extension by [Daniel Sieradski][3]. \n\n**Warning**: I did not modify the list of news sources from the BS Detector so as not to introduce my (useless) layer of bias; I\'m not an authority on fake news. There may be sources whose inclusion you disagree with. It\'s up to you to decide how to work with the data and how you might contribute to ""improving it"". The labels of ""bs"" and ""junksci"", etc. do not constitute capital ""t"" Truth. If there are other sources you would like to include, start a discussion. If there are sources you believe should not be included, start a discussion or write a kernel analyzing the data. Or take the data and do something else productive with it. Kaggle\'s choice to host this dataset is not meant to express any particular political affiliation or intent.\n\n## Contents\n\nThe dataset contains text and metadata from 244 websites and represents 12,999 posts in total from the past 30 days. The data was pulled using the [webhose.io][4] API; because it\'s coming from their crawler, not all websites identified by the BS Detector are present in this dataset. Each website was labeled according to the BS Detector as documented here. Data sources that were missing a label were simply assigned a label of ""bs"". There are (ostensibly) no genuine, reliable, or trustworthy news sources represented in this dataset (so far), so don\'t trust anything you read.\n\n## Fake news in the news\n\nFor inspiration, I\'ve included some (presumably non-fake) recent stories covering fake news in the news. This is a sensitive, nuanced topic and if there are other resources you\'d like to see included here, please leave a suggestion. From defining fake, biased, and misleading news in the first place to deciding how to take action (a blacklist is not a good answer), there\'s a lot of information to consider beyond what can be neatly arranged in a CSV file.\n\n* [How Fake News Spreads (NYT)][6]\n\n* [We Tracked Down A Fake-News Creator In The Suburbs. Here\'s What We Learned (NPR)][7]\n\n* [Does Facebook Generate Over Half of its Revenue from Fake News? (Forbes)][8]\n\n* [Fake News is Not the Only Problem (Points - Medium)][9]\n\n* [Washington Post Disgracefully Promotes a McCarthyite Blacklist From a New, Hidden, and Very Shady Group (The Intercept)][10]\n\n## Improvements\n\nIf you have suggestions for improvements or would like to contribute, please let me know. The most obvious extensions are to include data from ""real"" news sites and to address the bias in the current list. I\'d be happy to include any contributions in future versions of the dataset.\n\n## Acknowledgements\n\nThanks to [Anthony][11] for pointing me to [Daniel Sieradski\'s BS Detector][12]. Thank you to Daniel Nouri for encouraging me to add a disclaimer to the dataset\'s page.\n\n\n  [2]: https://github.com/selfagency/bs-detector\n  [3]: https://github.com/selfagency\n  [4]: https://webhose.io/api\n  [5]: https://github.com/selfagency/bs-detector/blob/master/chrome/data/data.json\n  [6]: http://www.nytimes.com/2016/11/20/business/media/how-fake-news-spreads.html\n  [7]: http://www.npr.org/sections/alltechconsidered/2016/11/23/503146770/npr-finds-the-head-of-a-covert-fake-news-operation-in-the-suburbs\n  [8]: http://www.forbes.com/forbes/welcome/?toURL=http://www.forbes.com/sites/petercohan/2016/11/25/does-facebook-generate-over-half-its-revenue-from-fake-news\n  [9]: https://points.datasociety.net/fake-news-is-not-the-problem-f00ec8cdfcb#.577yk6s8a\n  [10]: https://theintercept.com/2016/11/26/washington-post-disgracefully-promotes-a-mccarthyite-blacklist-from-a-new-hidden-and-very-shady-group/\n  [11]: https://www.kaggle.com/antgoldbloom\n  [12]: https://github.com/selfagency/bs-detector'","b""['politics', 'languages', 'news agencies', 'medium', 'featured']""",https://www.kaggle.com/mrisdal/fake-news
b'California Wire Tapping',b'Investigate ~$30M dollars of wiretapping in the Electronic Interceptions Reports',"b""## Context\n\nIn 2016, California investigators used state wiretapping laws 563 times to capture 7.8 million communications from 181,000 people, and only 19% of these communications were incriminating.  The year's wiretaps cost nearly $30 million. \n\nWe know this, and much more, now that the California Department of Justice (CADOJ) for the first time has released to EFF the dataset underlying its annual wiretap report to the state legislature. \n\n## Content\n\nThe yearly \xe2\x80\x9cElectronic Interceptions Report\xe2\x80\x9d includes county-by-county granular data on wiretaps on landlines, cell phones, computers, pagers1, and other devices.  Each interception is accompanied by information on the number of communications captured and the number of people those communications involved, as well as what percentage of the messages were incriminating. The report also discloses the criminal justice outcomes of the wiretaps (e.g. drugs seized, arrests made) and the costs to the public for running each surveillance operation. \n\nUnder California\xe2\x80\x99s sunshine law, government agencies must provide public records to requesters in whatever electronic format they may exist. And yet, for the last three years, CADOJ officials resisted releasing the data in a machine-readable format. In fact, in 2015, CADOJ [initially attempted to only release the \xe2\x80\x9clocked\xe2\x80\x9d version of a PDF of the report][1] until [EFF publicly called out the agency][2] for ignoring these provisions of the California Public Records Act.\n\nEFF sought the dataset because the formatting of the paper version of the report was extremely difficult to scrape or export in a way that would result in reliable and accurate data. Tables in the reports have sometimes spanned more than 70 pages.  \n\nThis year, EFF has scored a major victory for open data: in response to our latest request, CADOJ has released not only an unlocked PDF, but a spreadsheet containing all the data. \n\nWhat\xe2\x80\x99s especially interesting about the data is that it includes data not previously disclosed in the formal report, including information on when wiretaps targeted multiple locations, devices, and websites, such as Facebook. At the same time, the data does not include some information included in the official report, such as the narrative summary of the outcome of each wiretap.\n\n## Inspiration\n\nSome of the highlights contained in the data.\n\n* Wiretap application in Riverside County dropped from 620 wiretap applications in 2015 to 106 in 2016. This is likely due to reforms in the Riverside County District Attorney\xe2\x80\x99s office [following a series of investigative reports from USA Today][3] that showed many wiretaps were likely illegal.\n\n* As in previous years, many of the wiretaps captured voluminous amounts of communications from large groups of people. The largest in terms of communications was a wiretap in a Los Angeles narcotics case in which 559,000 communications were captured from cell phones over 30 days. The largest in terms of number of people were caught up in a wiretap was a Riverside narcotics case in which 91,000 people each had a single piece of communication captured over 120 days.\n\n* The most expensive wiretap cost $1 million, mostly in personnel costs, to target a single person\xe2\x80\x99s text message in a Los Angeles murder case. The most expensive wiretap in terms of non-personnel resources (i.e. equipment) cost $193,000. Two arrests were made in the associated narcotics case. \n\nExplore the 2016 data (reproduced here as a CSV file) and the full report. Previous years\xe2\x80\x99 reports are also made available here in a ZIP archive (PDFs). **Let EFF know if you discover something interesting in the data by emailing dm@eff.org**.\n\n## Acknowledgments\n\n*This description is reproduced with slight changes from [the original blog post introducing the dataset published by Dave Maass on June 9, 2017][4]. The dataset and contents from EFF are released under a CC-BY license and redistributed here in accordance with EFF's [Copyright Policy.][5]*\n\n#[Start an Analysis][6]\n\n\n  [1]: https://www.eff.org/document/cadoj-response-regarding-california-electronic-interceptions-report-data-2015\n  [2]: https://www.eff.org/deeplinks/2015/05/california-attorney-general-locks-down-wiretap-and-other-criminal-justice-data\n  [3]: https://www.usatoday.com/story/news/2016/02/25/dea-riverside-wiretaps-scaled-back/80891460/\n  [4]: https://www.eff.org/deeplinks/2017/06/california-finally-releases-wiretap-dataset\n  [5]: https://www.eff.org/copyright\n  [6]: https://www.kaggle.com/eff/california-wire-tapping/kernels?modal=true""","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/eff/california-wire-tapping
b'Indian Premier League (Cricket)',b'Ball-By-Ball Cricket Data',"b'### Context\n\nCricket&nbsp;is a&nbsp;bat-and-ball game&nbsp;played between two teams of eleven players each on a&nbsp;cricket field, at the centre of which is a rectangular 20-metre (22-yard)&nbsp;pitch&nbsp;with a target at each end called the&nbsp;wicket&nbsp;(a set of three wooden&nbsp;stumps&nbsp;upon which two&nbsp;bails&nbsp;sit). Each phase of play is called an&nbsp;innings, during which one team&nbsp;bats, attempting to score as many&nbsp;runs&nbsp;as possible, whilst their opponents&nbsp;bowl&nbsp;and&nbsp;field, attempting to minimise the number of runs scored. When each innings ends, the teams usually swap roles for the next innings (i.e. the team that previously batted will bowl/field, and vice versa). The teams each bat for one or two innings, depending on the type of match. The winning team is the one that&nbsp;scores&nbsp;the most runs, including any&nbsp;extras&nbsp;gained (except when the&nbsp;result&nbsp;is not a win/loss result). Source: https://en.wikipedia.org/wiki/Cricket\n\n### Content\n\nAll Indian Premier League Cricket matches between 2008 and 2016.\n\nThis is the ball by ball data of all the IPL cricket matches till season 9. \n\nThe dataset contains 2 files: deliveries.csv and matches.csv. \n\nmatches.csv contains details related to the match such as location, contesting teams, umpires, results, etc. \n\ndeliveries.csv is the ball-by-ball data of all the IPL matches including data of the batting team, batsman, bowler, non-striker, runs scored, etc.\n\n### Acknowledgements\n\nSource:&nbsp;http://cricsheet.org/&nbsp;(data is available on this website in the YAML format. This is converted to CSV format by the contributors)\n\n### Inspiration\n\nResearch scope: Predicting the winner of the next season of IPL based on past data, Visualizations, Perspectives, etc.'","b""['india', 'cricket', 'small', 'featured']""",https://www.kaggle.com/manasgarg/ipl
b'French presidential election',b'Extract from Twitter about the French election (with a taste of Google Trends)',"b'# Context \n\nThis dataset is born from a test with the twitter streaming api to filter and collect data from this flow on a specific topic, in this case the [French election][1].The script used to make this data collection is available on this [Github repository][2].\n\nSince the 18th of March, the [French election][3] enter in the final straight line until the first poll the 23 April 2017 , the candidates for the position are:\n\n - M. Nicolas DUPONT-AIGNAN\n - Mme Marine LE PEN\n - M. Emmanuel MACRON\n - M. Beno\xc3\xaet HAMON\n - Mme Nathalie ARTHAUD\n - M. Philippe POUTOU\n - M. Jacques CHEMINADE\n - M. Jean LASSALLE\n - M. Jean-Luc M\xc3\x89LENCHON\n - M. Fran\xc3\xa7ois ASSELINEAU\n - M. Fran\xc3\xa7ois FILLON\n\nThe idea was to collect the data from the Twitter API periodically. The acquisition process evolved as follows: \n\n - Versions 1, 2 and 3\nEvery hour a python script listens to the twitter api stream for 10 minutes during 3 weeks.\n - Version 4+\nThe new versions will be based on a new data structure, and start after the validation by the French constitutional council on 18 March 2017 of the candidates.\n\nThe data will be stored in a dbsqlite files(database_number of the week_number_block_weekday.sqlite format)  and will be updated as often as I can (at least every week).\n\nAfter the first round (version 18+) i had to readjust the number of files per week and the 20 files kaggle limitation push me to reduce the number of files to upload (but you can join for your local analytics the version 17 + version 18+)\n\n**Example : Illustration of the number of mentions of the different candidates**\n![illustration of the mention of the different candidates][4]\n\nI add to these databases a sqlite database that contains the informations from the google trends about the top 5 candidates.In thid database there is :\n\n - A table that contains the overall interests by region\n - A table that contains the interests by region for each candidate\n - A table with the top25 associated queries for each candidate in top and rising ranking\n\n# Content\n\nIn this dbsqlite file, you will find a data table that contains for every row:\n\n===============Common===============\n\n - the index of the line\n - the language of the tweet\n - for each candidate\n:mention_candidatename, if the candidate or his associated account has been called (0 or 1)\n - the tweet\n - the timestamp in milliseconds\n\n===============Version 4+===============\n\n - the day\n - the hour (London timezone)\n - the username of the user that made the tweet\n - the username location (that he gives with his profile)\n - if the tweet is a retweet or a quote (0 or 1)\n - the username that has been retweeted\n - the original tweet (the one retweeted or quoted)\n\n\n# Acknowledgements\nThis election is gonna be intense.\n \n# Inspiration\nThe first version of the dataset was just a test to collect the data and see the first pieces of work  that the community can do with this dataset.The new versions are (I think and hope) adapted to do deep text analytics. \n\n\n  [1]: https://en.wikipedia.org/wiki/French_presidential_election,_2017\n  [2]: https://github.com/jeanmidevacc/french-presidential-election-twitter-pov.git\n  [3]: https://en.wikipedia.org/wiki/French_presidential_election,_2017\n  [4]: https://www.kaggle.io/svf/1039441/a6d419b95420d7c28bd3e9a4437a6370/__results___files/__results___8_2.png\n  [5]: https://trends.google.co.uk/trends/explore?date=today%201-m&geo=FR&q=%2Fm%2F011ncr8c,%2Fm%2F0fqmlm,%2Fm%2F02rdgs,%2Fm%2F04zzm99,%2Fm%2F0551nw\n  [6]: https://www.kaggle.io/svf/1049376/e54172fcff84c97fff6583431eaf9567/__results___files/__results___16_1.png'","b""['politics', 'large', 'featured']""",https://www.kaggle.com/jeanmidev/french-presidential-election
b'Exchange Rates',b'Exchange rates as far back as 1971 between the USA and 23 countries',"b""The Federal Reserve's H.10 statistical release provides data on exchange rates between the US dollar, 23 other currencies, and three benchmark indexes. The data extend back to 1971 for several of these.\n\nPlease note that the csv has six header rows. The first contains the \n\n## Acknowledgements\nThis dataset was provided by the [US Federal Reserve][1]. If you need the current version, you can find their weekly updates [here][2].\n\n## Inspiration\n\n - Venezuela is both unusually dependent on oil revenues and experiencing unusual degrees of political upheaval. Can you determine which movements in their currency were driven by changes in the oil price and which were driven by political events?\n\n  [1]: https://www.federalreserve.gov/aboutthefed.htm\n  [2]: https://www.federalreserve.gov/releases/h10/Hist/""","b""['finance', 'economics', 'small', 'featured']""",https://www.kaggle.com/federalreserve/exchange-rates
b'A Tribuna',b'Journalistic documents published on the Internet',"b'# Context \n\nThe newspaper publications on the Internet increases every day. There are many news agencies, newspapers and magazines with digital publications on the big network. Published documents made available to users who, in turn, use search engines to find them. To deliver the closest searched documents, these documents must be previously indexed and classified. With the huge volume of documents published every day, many researches have been carried out in order to find a way of dealing with the automatic document classification. \n\n\n# Content\n\nThe ""Tribuna"" database is of journalistic origin with its digital publication, a factor that may be important for professionals of the area, also serving to understand other similar datasets.\nIn order to carry out the experiment, we adopted the ""A Tribuna"" database, whose main characteristics presented previously, show that the collection is a good source of research, since it is already classified by specialists and has 21 classes that can be Displayed in the table below.\n\n# Acknowledgements\n\nMy thanks to the company ""A Tribuna"" that gave all these text files for experiment at the Federal University of Esp\xc3\xadrito Santo. To the High Desermpenho Computation Laboratory (LCAD) for all the help in the experiments. Thanks also to Prof. PhD Oliveira, Elias for all the knowledge shared.\n\n# Inspiration\n\nThere are two issues involving this dataset: \n\nWhat is the best algorithm for sorting these documents?\n\nWhat are the elements that describe each of the 21 classes in the collection?'","b""['internet', 'news agencies', 'medium', 'featured']""",https://www.kaggle.com/TheScientistBR/atribuna
b'Lord Of The Rings Data',b'Character and Movie Data',"b""### Context\n\nAs a huge LOTR fan, I was excited to have acquired this character data from the Lord of the Rings [Wiki][1]. I scraped this data using F#; the repository can be found here: https://github.com/MokoSan/FSharpAdvent. \n\n### Content\n\nData consists of character names, the url in the wiki and the respective race. \n\n\n### Acknowledgements\n\nWouldn't have been able to publish this data set unless it was for the work done by the great people of the wiki page.\n\n\n  [1]: http://lotr.wikia.com/wiki/Category:Characters""","b""['classification', 'literature', 'small', 'featured']""",https://www.kaggle.com/mokosan/lord-of-the-rings-character-data
b'Bible Corpus',b'English Bible Translations Dataset for Text Mining and NLP',"b""### Context \n\nBible (or Biblia in Greek) is a collection of sacred texts or scriptures that Jews and Christians consider to be a product of divine inspiration and a record of the relationship between God and humans ([Wiki][1]). And for data mining purpose, we could do many things using Bible scriptures as for NLP, Classification, Sentiment Analysis and other particular topics between Data Science and Theology perspective.\n\n### Content\n\nHere you will find the following bible versions in **sql, sqlite, xml, csv,** and **json** format:\n\n- American Standard-ASV1901 (ASV)\n\n- Bible in Basic English (BBE)\n\n- Darby English Bible (DARBY)\n\n- King James Version (KJV)\n\n- Webster's Bible (WBT)\n\n- World English Bible (WEB)\n\n- Young's Literal Translation (YLT)\n\nEach verse is accessed by a unique key, the combination of the BOOK+CHAPTER+VERSE id.\n\n**Example:**\n\n- Genesis 1:1 (Genesis chapter 1, verse 1) = 01001001 (01 001 001)\n\n- Exodus 2:3 (Exodus chapter 2, verse 3) = 02002003 (02 002 003)\n\n- The verse-id system is used for faster, simplified queries.\n\n- For instance: 01001001 - 02001005 would capture all verses between Genesis 1:1 through Exodus 1:5.\n\nWritten simply:\n \n`SELECT * FROM bible.t_asv WHERE id BETWEEN 01001001 AND 02001005`\n\n**Coordinating Tables**\n\nThere is also a number-to-book key (key_english table), a cross-reference list (cross_reference table), and a bible key containing meta information about the included translations (bible_version_key table). See below SQL table layout. These tables work together providing you a great basis for a bible-reading and cross-referencing app. In addition, each book is marked with a particular genre, mapping in the number-to-genre key (key_genre_english table) and common abbreviations for each book can be looked up in the abbreviations list (key_abbreviations_english table).\nWhile its expected that your programs would use the verse-id system, book #, chapter #, and verse # columns have been included in the bible versions tables.\n\n**A Valuable Cross-Reference Table**\n\nA very special and valuable addition to these databases is the extensive cross-reference table. It was created from the project at http://www.openbible.info/labs/cross-references/. See .txt version included from http://www.openbible.info website. Its extremely useful in bible study for discovering related scriptures. For any given verse, you simply query vid (verse id), and a list of rows will be returned. Each of those rows has a rank (r) for relevance, start-verse (sv), and end verse (ev) if there is one.\n\n**Basic Web Interaction**\n\nThe web folder contains two php files. Edit the first few lines of index.php to match your server's settings. Place these in a folder on your webserver.\nThe references search box can be multiple comma separated values. (i.e. John 3:16, Rom 3:23, 1 Jn 1:9, Romans 10:9-10) You can also directly link to a verse by altering the URI: [http://localhost/index.php?b=John 3:16, Rom 3:23, 1 Jn 1:9, Romans 10:9-10](http://localhost/index.php?b=John 3:16, Rom 3:23, 1 Jn 1:9, Romans 10:9-10)\n\n - bible-mysql.sql (MySQL) is the main database and most feature-oriented due to contributions from developers. It is suggested you use that for most things, or at least convert the information from it.\n - cross_references-mysql.sql (MySQL) is the cross-reference table. It has been separated to become an optional feature. This is converted from the project at http://www.openbible.info/labs/cross-references/.\n - bible-sqlite.db (SQLite) is a basic simplified database for simpler applications (includes cross-references too).\n - cross_references.txt is the source cross-reference file obtained from http://www.openbible.info/labs/cross-references/\n\nIn CSV folder, you will find (same list order with the other formats):\n\n - bible_version_key.csv\n\n![bible_version_key][2]\n\n - key_abbreviations_english.csv\n\n![key_abbreviations_english][3]\n\n - key_english.csv\n\n![key_english][4]\n\n - key_genre_english.csv\n\n![key_genre_english][5]\n\n - t_asv.csv, t_bbe.csv, t_dby.csv, t_wbt.csv, t_web.csv, t_ylt.csv\n\n![t_version][6]\n \n### Acknowledgements\n\nIn behalf of the original contributors ([Github][7])\n\n### Inspirations\n\n[WordNet][8] as an additional semantic resource for NLP\n\n\n  [1]: https://en.wikipedia.org/wiki/Bible\n  [2]: http://i.imgur.com/S9JialN.png\n  [3]: http://i.imgur.com/v59SpQs.png\n  [4]: http://i.imgur.com/BbKMQgF.png\n  [5]: http://i.imgur.com/lJVVW2C.png\n  [6]: http://i.imgur.com/jJ4cf4q.png\n  [7]: https://github.com/scrollmapper/bible_databases\n  [8]: https://wordnet.princeton.edu/""","b""['linguistics', 'faith and traditions', 'medium', 'featured']""",https://www.kaggle.com/oswinrh/bible
b'U.S. Pollution Data',b'Pollution in the U.S. since 2000',"b""### Context\nThis dataset deals with pollution in the U.S. Pollution in the U.S. has been well documented by the U.S. EPA but it is a pain to download all the data and arrange them in a format that interests data scientists. Hence I gathered four major pollutants (Nitrogen Dioxide, Sulphur Dioxide, Carbon Monoxide and Ozone) for every day from 2000 - 2016 and place them neatly in a `CSV` file. \n\n### Content\n\nThere is a total of 28 fields. The four pollutants (NO2, O3, SO2 and O3) each has 5 specific columns. Observations totaled to over 1.4 million. [This kernel](https://www.kaggle.com/jaeyoonpark/animation-basemap-plotly-for-air-quality-index) provides a good introduction to this dataset!\n\nFor observations on specific columns visit the Column Metadata on the `Data` tab.\n\n### Acknowledgements\n\nAll the data is scraped from the database of U.S. EPA : [https://aqsdr1.epa.gov/aqsweb/aqstmp/airdata/download_files.html][1] \n\n### Inspiration\nI did a related project with some of my friends in college, and decided to open source our dataset so that data scientists don't need to re-scrape the U.S. EPA site for historical pollution data.\n\n  [1]: https://aqsdr1.epa.gov/aqsweb/aqstmp/airdata/download_files.html""","b""['environment', 'pollution', 'medium', 'featured']""",https://www.kaggle.com/sogun3/uspollution
b'OSMI Mental Health in Tech Survey 2016',b'Data on prevalence and attitudes towards mental health among tech workers',"b'## OSMI Mental Health in Tech Survey 2016\n\nCurrently over 1400 responses, the ongoing 2016 survey aims to measure attitudes towards mental health in the tech workplace, and examine the frequency of mental health disorders among tech workers.\n\n### How Will This Data Be Used?\n\nWe are interested in gauging how mental health is viewed within the tech/IT workplace, and the prevalence of certain mental health disorders within the tech industry. The Open Sourcing Mental Illness team of volunteers will use this data to drive our work in raising awareness and improving conditions for those with mental health disorders in the IT workplace.'","b""['employment', 'mental health', 'medium', 'featured']""",https://www.kaggle.com/osmi/mental-health-in-tech-2016
b'Daikon (Diachronic Corpus)',b'Historic texts from the British Spector news magazine',"b'### Context\n\nThe Daikon Corpus was created during the [Diachronic Text Evaluation task in SemEval-2015](http://alt.qcri.org/semeval2015/task7/). The task was to create a system that can date a piece of text. \n\nFor example, given a text snippet:\n\n> \xe2\x80\x9cDictator **Saddam Hussein** ordered his troops to march into Kuwait.\n> After the invasion is condemned by the **UN Security Council**, the US has\n> forged a coalition with allies. **Today** American troops are sent to\n> Saudi Arabia in **Operation Desert Shield**, protecting Saudi Arabia from\n> possible attack.\xe2\x80\x9d\n\n\nThe text has clear **temporal evidence with reference** to a\n\n - historical figure (\xe2\x80\x9cSaddam Hussein\xe2\x80\x9d), \n - notable organization (\xe2\x80\x9cUN Security Council\xe2\x80\x9d) \n - factual event (\xe2\x80\x9cOperation Desert Shield\xe2\x80\x9d).\n\nHistorically, we know that \n\n - Saddam Hussein lived between 1937 to 2006, \n - UN Security Council has existed since 1946 \n - Operation Desert Shield (i.e. the Gulf War) occurred between 1990-1991\n\nGiven the specific chronic deicticity (\xe2\x80\x9ctoday\xe2\x80\x9d) that indicates that the text is published during the Gulf War, we can conceive that the **text snippet should be dated 1990-1991**.\n\n\n### Content\n\nThe Daikon Corpus is made up of articles from the British Spectator news magazine from year 828 to 2008.\n\nThe corpus contains 24,280 articles with 19 million tokens; the token count is calculated by summing the number of whitespaces plus 1 for each paragraph.\n\nThe Daikon corpus is saved in the JSON format, where the outer most-structure is a list and the inner data structure is a key-value dictionary/hashmap that contains the:\n\n - **url**: URL where the original article resides\n - **date**: Date of the article\n - **body**: A list of paragraphs\n - **title**: Title of the text \n\n**Note:** If the url is broken, try **removing the `.html`** suffix of the url. e.g. change \n\n    http://archive.spectator.co.uk/article/24th-september-2005/57/doctor-in-the-house.html \n\nto \n\n    http://archive.spectator.co.uk/article/24th-september-2005/57/doctor-in-the-house\n\n \n### Citations\n\n    Liling Tan and Noam Ordan. 2015. \n    USAAR-CHRONOS:  Crawling the Web for Temporal Annotations. \n    In Proceedings of Ninth International Workshop on \n    Semantic Evaluation (SemEval 2015). Denver, USA.\n\nTask reference:\n\n    Octavian Popescu and Carlo Strapparava. \n    SemEval 2015, Task 7: Diachronic Text Evaluation. \n    In Proceedings of Ninth International Workshop on \n    Semantic Evaluation (SemEval 2015). Denver, USA.\n\nDataset image comes from [Jonathan Pielmayer](https://unsplash.com/search/photos/white-carrot?photo=eFFnKMiDMGc)\n\n\n### Inspiration\n\nLet\'s make an artificially intelligent ""[Flynn Carsen](http://www.imdb.com/character/ch0046866/)"" !!'","b""['medium', 'featured']""",https://www.kaggle.com/alvations/daikon
b'New York State Taxes and Fees Collected',b'From New York State Open Data',"b""### Content  \n\nThe Department of Taxation and Finance monthly produces a compilation of those state and local and local purpose taxes and fees collected by the Department.  The taxes and fees information provided in this data set are primarily taxes imposed by the Tax Law, but also includes fees that are imposed by other state laws but are administered and collected by the Department.  Collections are net of refunds and other processing and accounting adjustments.  The data set provides a history of these collections by month beginning with April 1996.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/TELAb4duebI) by [Kyle Glenn](https://unsplash.com/@kylejglenn) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/new-york-state-taxes-and-fees-collected
b'Indirect Food Additives',b'Chemicals indirectly added during processing regulated by the FDA',"b'### Context\n\nThe vast majority of food and food ingredients eaten today is processed in some way before they arrived at the kitchen or dinner table. Food processing equipment may leave trace amounts of various industrial chemical compounds in the foods we eat, and these chemicals, classed **indirect food additives**, are regulated by the United States Food and Drug Administration. This dataset is a list of indirect food additives approved by the FDA.\n\n### Content\n\nThis dataset contains the names of chemical compounds and references to the federal government regulatory code approving and controlling their usage.\n\n### Acknowledgements\n\nThis dataset is published by the FDA and available [online](https://www.accessdata.fda.gov/scripts/fdcc/?set=IndirectAdditives) as a for-Excel `CSV` file. A few errant header columns have been cleaned up prior to upload to Kaggle, but otherwise the dataset is published as-is.\n\n### Inspiration\n\n* What tokens most commonly appear amongst the names contained in this list?\n* Any identifiable elements or compounds?'","b""['food and drink', 'small', 'featured']""",https://www.kaggle.com/fda/indirect-food-additives
b'The fight against malaria',b'Who is dying and being saved from this destructive disease?',"b""### Context\n\nThe data here is from the Global Health Observatory (GHO) who provide data on malaria incidence, death and prevention from around the world.\nI have also included malaria net distribution data the Against Malaria Foundation (AMF). The AMF has consistently been ranked as the most cost effective charity by charity evaluators Give Well - http://www.givewell.org/charities/top-charities\n\n### Content\n\nGHO data is all in narrow format, with variables for a country in a given year being found on different rows. \n\nGHO data (there are a number or superfluous columns):\n\n - GHO (CODE)\n - GHO (DISPLAY) - this is the variable being measured\n - GHO (URL)\n - PUBLISHSTATE (CODE)\n - PUBLISHSTATE (DISPLAY)\n - PUBLISHSTATE (URL)\n - YEAR (CODE)\n - YEAR (DISPLAY)\n - YEAR (URL)\n - REGION (CODE)\n - REGION (DISPLAY)\n - REGION (URL)\n - COUNTRY (CODE) - can be used to join this data with the AMF data\n - COUNTRY (DISPLAY)\n - COUNTRY (URL)\n - Display Value - this is the measured value\n - Low - lower confidence interval\n - High - higher confidence interval\n - Comments\n\nAMF distribution data:\n\n - #_llins - total number of malaria nets distributed\n - location - the specific area that received the nets, within the target country\n - country - the country in which the nets were distributed\n - when - the period the distribution \n - by_whom - the organisation(s) which partnered with the AMF to perform the distribution\n - country_code - the country's GHO country code (this will allow joining with the GHO data)\n\nFor the current version all data was downloaded 20-08-17\nThe GHO data covers the years from 2000 to 2015 (not all files have data in all years)\nThe AMF data runs from 2006 - the present.\n\nThe GHO data is taken as is from the csv (lists) available here: http://apps.who.int/gho/data/node.main.A1362?lang=en\nThe source of the AMF's distribution data is here: https://www.againstmalaria.com/distributions.aspx - it was assembled into a single csv using Excel (mea culpa)\n\n### Inspiration\nMalaria is one of the world's most devastating diseases, not least because it largely affects some of the poorest people. Over the past 15 years malaria rates and mortality have dropped (http://www.who.int/malaria/media/world-malaria-report-2016/en/), but there is still a long way to go. Understanding the data is generally one of the most important steps in solving any large problem. I'm excited to see what the Kaggle community can find out about the global trends in malaria over this period, and if we can find out anything about the impact of organisations such as the AMF.""","b""['public health', 'small', 'featured']""",https://www.kaggle.com/teajay/the-fight-against-malaria
b'Salt Lake City Crime Reports',"b'Includes latitude and longitudes, offence descriptions, and city council numbers'","b""# Context \n\nA collection of SLC End-of-Year Crime Reports geocoded to standard GPS coordinates.\n\n# Content\n\n2016 Crime Statistics for Salt Lake City, UT. Includes:\n\n  * Case Numbers\n  * Offence Codes for categorization\n  * Descriptions for context\n  * [IBR](https://ucr.fbi.gov/nibrs/nibrs-user-manual) (National Incident-Based Reporting System Number)\n  * Occurrence Date\n  * Report Date\n  * Day of the Week (1 = Monday, 7 = Sunday)\n  * Location (Addresses in SLC)\n  * City Council District\n  * SLCPD Police Zones\n  * SLCPD Grid\n  * x_coordinate: note that this is based on `epsg:32043` projections\n  * y_coordinate: note that this is based on `epsg:32043` projections\n  * x_gps_coords (added by yours truly, converted to `epsg:4326`)\n  * y_gps_coords (added by yours truly, converted to `epsg:4326`)\n\n## Data Accuracy Notes\n\n* Some data wrangling will still likely be required to clean up null columns. \n* I went ahead and lowercased column names (and corrected a spelling mistake in the y-coordinate column).\n* `epsg:32043` projections were converted to `epsg:4326` projections using `pyplot` with distances preserved.\n* Multiple year munging performed here: https://github.com/octaflop/slcpd/blob/master/develop/2017-08-16-crunch.ipynb\n* Still awaiting dataset owner clarification of Calls vs Cases\n\n# Acknowledgements\n\nTaken from the [SLC Open Data Web Site](https://opendata.utah.gov/Public-Safety/SALT-LAKE-CITY-POLICE-CASES-2016/trgz-4r9d). \n\nThank you Dean Larson, the original dataset owner.\n\nThank you to the City of Salt Lake government and the Utah.gov catalog for providing this data for public use.\n\nThanks to the DAT Science EdEx course for inspiring me to take a look at my own city's crime stats.\n\nThank you to the SLCPD for keeping Salt Lake City citizens safe and enforcing an internal discipline of open data-collection.\n\n# Inspiration\n\n* Crime report locations by season? \n* Cross Reference of city council districts\n* Time of day\n* Offence descriptions\n* Moving centroids based on time of day / season?\n* Holiday rowdiness?\n\n# Coming Soon\n\n* Full 2016 reports (eta Spring 2017) \xe2\x9c\x94\n* 3-year combined reports (eta Summer 2017) \xe2\x9c\x94\n* 3-year combined cases vs calls (eta Summer 2017)\n* year-by-year files (eta Fall 2017)""","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/foenix/slc-crime
b'HanziDB',b'List of simplified Chinese characters ordered by frequency rank.',"b""### Content\n\nA ranked list (by frequency) of over 9k simplified Chinese characters. \n\n\n### Acknowledgements\n\nAll data scraped from [HanziDB.org][1], which is based on Jun Da's Modern Chinese Character Frequency List.\n\n\n### Inspiration\n\nSome possible questions:\n\n - What is the distribution of radicals through the 100 most popular characters? 500? 1,000?\n - Does stroke count affect usage?\n - Is there an association between the number of strokes and the HSK level of characters?\n\n  [1]: http://hanzidb.org/character-list/by-frequency""","b""['linguistics', 'languages', 'china ', 'small', 'featured']""",https://www.kaggle.com/ruddfawcett/hanzidb
b'Expanded HR Analytics Data Lab',b'To use for various exercises including multivariate analysis.',"b""### Context\n\nWe are building an HR analytics data set that can be used for building useful reports,  understanding the difference between data and information, and multivariate analysis. The data set we are building is similar to that used in several academic reports and what may be found in ERP HR subsystems.\n\nWe will update the sample data set as we gain a better understanding of the data elements using the calculations that exist in scholarly journals. Specifically, we will use the correlation tables to rebuild the data sets.\n\n### Content\n\nThe fields represent a fictitious data set where a survey was taken and actual employee metrics exist for a particular organization. None of this data is real.\n\n### Acknowledgements\n\nWe wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research. \n\nPrabhjot Singh contributed a portion of the data (the columns on the right before the survey data was added).\nhttps://www.kaggle.com/prabhjotindia\nhttps://www.kaggle.com/prabhjotindia/visualizing-employee-data/data\n\nAbout this Dataset\nWhy are our best and most experienced employees leaving prematurely? Have fun with this database and try to predict which valuable employees will leave next. Fields in the dataset include:\n\nSatisfaction Level\nLast evaluation\nNumber of projects\nAverage monthly hours\nTime spent at the company\nWhether they have had a work accident\nWhether they have had a promotion in the last 5 years\nDepartments\nSalary\n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?""","b""['small', 'featured']""",https://www.kaggle.com/krismurphy01/data-lab
b'The Church in the Southern Black Community',b'144 primary texts about the Church in the Southern Black Community',"b'""The Church in the Southern Black Community"" collects autobiographies, biographies, church documents, sermons, histories, encyclopedias, and other published materials. These texts present a collected history of the way Southern African Americans experienced and transformed Protestant Christianity into the central institution of community life. Coverage begins with white churches\' conversion efforts, especially in the post-Revolutionary period, and depicts the tensions and contradictions between the egalitarian potential of evangelical Christianity and the realities of slavery. It focuses, through slave narratives and observations by other African American authors, on how the black community adapted evangelical Christianity, making it a metaphor for freedom, community, and personal survival.\n\n### Context\n\nThe North American Slave Narratives collection at the University of North Carolina contains 344 items and is the most extensive collection of such documents in the world.\n\nThe physical collection was digitized and transcribed by students and library employees. This means that the text is far more reliable than uncorrected OCR output which is common in digitized archives.\n\nMore information about the collection and access to individual page images can be be found here: http://docsouth.unc.edu/neh\n\nThe plain text files have been optimized for use in Voyant and can also be used in text mining projects such as topic modeling, sentiment analysis and natural language processing. Please note that the full text contains paratextual elements such as title pages and appendices which will be included in any word counts you perform. You may wish to delete these in order to focus your analysis on just the narratives.\n\nThe .csv file acts as a table of contents for the collection and includes Title, Author, Publication Date a url pointing to the digitized version of the text and a unique url pointing to a version of the text in plain text (this is particularly useful for use with Voyant: http://voyant-tools.org/). \n\n### Copyright Statement and Acknowledgements\n\nWith the exception of ""Fields\'s Observation: The Slave Narrative of a Nineteenth-Century Virginian,"" which has no known rights, the texts, encoding, and metadata available in Open DocSouth are made available for use under the terms of a Creative Commons Attribution License (CC BY 4.0:http://creativecommons.org/licenses/by/4.0/). Users are free to copy, share, adapt, and re-publish any of the content in Open DocSouth as long as they credit the University Library at the University of North Carolina at Chapel Hill for making this material available.\n\nIf you make use of this data, considering letting the holder of the original collection know how you are using the data and if you have any suggestions for making it even more useful. Send any feedback to wilsonlibrary@unc.edu.\n\n### About the DocSouth Data Project\n\nDoc South Data provides access to some of the Documenting The American South collections in formats that work well with common text mining and data analysis tools.\n\nDocumenting the American South is one of the longest running digital publishing initiatives at the University of North Carolina. It was designed to give researchers digital access to some of the library\xe2\x80\x99s unique collections in the form of high quality page scans as well as structured, corrected and machine readable text.\n\nDoc South Data is an extension of this original goal and has been designed for researchers who want to use emerging technology to look for patterns across entire texts or compare patterns found in multiple texts. We have made it easy to use tools such as Voyant (http://voyant-tools.org/) to conduct simple word counts and frequency visualizations (such as word clouds) or to use other tools to perform more complex processes such as topic modeling, named-entity recognition or sentiment analysis.'","b""['linguistics', 'united states', 'history', 'faith and traditions', 'medium', 'featured']""",https://www.kaggle.com/docsouth-data/the-church-in-the-southern-black-community
b'Google Product Taxonomy',b'Product categories for Google Shopping',"b'### Google Taxonomy \n\nThis product taxonomy lists seemed to be used by merchants in tagging their products on [Google Shopping](https://www.google.com/shopping?hl=en), see https://support.google.com/merchants/answer/6324436?hl=en\n\nThese lists were also used in the SemEval Taxonomy Evaluation tasks:\n\n - http://alt.qcri.org/semeval2015/task17/\n - http://alt.qcri.org/semeval2016/task13/\n\n### Content\n\nContains the product category lists for:\n\n - Czech\n - Danish\n - German (Swiss /  Germany)\n - English (Australian /  British / American)\n - Spanish (Spanish)\n - French (Swiss / France)\n - Italian (Swiss / Italy)\n - Japanese \n - Dutch\n - Norwegian\n - Polish\n - Portuguese (Brazillian)\n - Russian\n - Swedish\n - Turkish\n - Chinese\n\nThis post might be helpful for others too: https://www.en.advertisercommunity.com/t5/Google-Shopping-and-Merchant/Taxonomy-List-Countries-Some-missing/td-p/599656\n\n\n### Acknowledgements\n\nThe individual Google product taxonomy files came from \n\n\n    http://www.google.com/basepages/producttype/taxonomy-with-ids.<language_code>-<country_code>.txt\n\nDataset image comes from [Edho Pratama](https://unsplash.com/search/photos/google?photo=yeB9jDmHm6M)\n\n### Disclaimer\n\nI am not affiliated to Google or own these product categories lists. If this offends any copyrights/licenses, please request for me to remove it.'","b""['medium', 'featured']""",https://www.kaggle.com/alvations/google-product-taxonomy
b'Stanford Natural Language Inference Corpus',b'A collection of 570k labeled human-written English sentence pairs',"b'The SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels *entailment*, *contradiction*, and *neutral*, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE). We aim for it to serve both as a benchmark for evaluating representational systems for text, especially including those induced by representation learning methods, as well as a resource for developing NLP models of any kind.\n\n### Acknowledgements\n\nThis dataset was kindly made available bye the [Stanford Natural Language Processing Group](https://nlp.stanford.edu/). Please cite it as:\n\n[Samuel R. Bowman](https://www.nyu.edu/projects/bowman/), [Gabor Angeli](http://cs.stanford.edu/~angeli/), [Christopher Potts](http://www.stanford.edu/~cgpotts/), and [Christopher D. Manning](http://nlp.stanford.edu/~manning/). 2015. *A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)*\n\n\n### Inspiration\n\nThis dataset has been used to evaluate academic work on sentence encoding-based models for 3 way classification, with previous scores tabulated at https://nlp.stanford.edu/projects/snli/. Most of the entries use deep learning. How close to those scores (peak of 88.8% test accuracy) can you get with less computationally intensive methods?'","b""['linguistics', 'languages', 'medium', 'featured']""",https://www.kaggle.com/stanfordu/stanford-natural-language-inference-corpus
b'Roman emperors from 26 BC to 395 AD',"b'Life, death and reign of Roman emperors'","b""### Context\n\nWe all know of the Roman empire, but what about its emperors specifically?\n\n### Content\n\nHere, you will find information on each of the emperors of the Roman empire, which lasted between 26 BC and 395 AD.\nSpecifically, you can use data on their:\n\n - Names\n - Date of birth\n - City and Province of birth\n - Date of death\n - Method of accession to power\n - Date of accession to power\n - Date of end of reign\n - Cause of death\n - Identity of killer\n - Dynasty\n - Era\n - Photo\n\n### Acknowledgements\n\nThis dataset was provided by Zonination, who made it available on Wikipedia.\nSee his repository on [Github][1]\n\n\n### Inspiration\n\nWhat kind of trend can you find in these emperors' lives and reigns?\nWhat aspects of them allowed them to live longer?\n\n  [1]: https://github.com/zonination/emperors/blob/master/README.md""","b""['politics', 'history', 'death', 'politicians', 'life', 'small', 'featured']""",https://www.kaggle.com/lberder/roman-emperors-from-26-bc-to-395-ad
b'Discourse Acts on Reddit',"b'Annotated discourse acts fom 10,000 posts and replies'","b""## Context/background\n\nDiscourse acts are the different types of things you can do in a conversation, like agreeing, disagreeing or elaborating. This dataset contains annotations of the discourse acts of different Twitter comments. The discourse acts labeled here are \xe2\x80\x9ccoarse\xe2\x80\x9d in the sense that they\xe2\x80\x99re labelled broadly (for the whole Reddit comment) rather than for individual sentences or phrases, not in the sense of being vulgar. The discourse act of each post has been annotated by multiple annotators.\n\n## Content\nA large corpus of discourse annotations and relations on ~10K forum threads. Please refer to the following paper for an in depth analysis and explanation of the data: [*Characterizing Online Discussion Using Coarse Discourse Sequences (ICWSM '17)*](https://research.google.com/pubs/pub46055.html). \n\n## Explanation of fields\n\n### Thread fields\n * URL - reddit URL of the thread\n* title - title of the thread, as written by the first poster\n* is_self_post - True if the first post in the thread is a self-post (text addressed to the reddit community as opposed to an external link)\n* subreddit - the subreddit of the thread\n* posts - a list of all posts in the thread\n \n### Post fields\n* id - post ID, reddit ID of the current post\n* in_reply_to - parent ID, reddit ID of the parent post, or the post that the current post is in reply to\n* post_depth - the number of replies the current post is from the initial post\n* is_first_post - True if the current post is the initial post\n* annotations - a list of all annotations made to this post (see below)\n* majority_type - the majority annotated type, if there is a majority type between the annotators, when considering only the main_type field\n* majority_link - the majority annotated link, if there is a majority link between the annotators\n \n### Annotation fields\n* annotator - an unique ID for the annotator\n* main_type - the main discourse act that describes this post\n* secondary_type - if a post contains more than one discourse act in sequence, this is the second discourse act in the post\n* link_to_post - the post that this post is linked to\n \n## Data sampling and pre-processing\n\n### Selecting Reddit threads\n\t\t\t\nThis data was randomly sampled from the full Reddit dataset starting from its inception to the end of May 2016, which is made available publicly as a dump on [Google BigQuery](https://bigquery.cloud.google.com/table/fh-bigquery:reddit_comments.2016_05).  This dataset was subsampled from the larger dataset and does not include posts with fewer than two comments, not in English, which contain pornographic material or from Subreddits focused on trading. Further, the number of replies to a single thread was limited to 40.\n\n### Annotation\n\t\t \t \t \t\t\nThree annotators were assigned to each thread and were instructed to annotate each comment in the thread with its discourse act (main_type) as well as the relation of each comment to a prior comment (link_to_post), if it existed. Annotators were instructed to consider the content at the comment level as opposed to sentence or paragraph level to make the task simpler.\n\n\n## Authors\n**Amy X. Zhang**, MIT CSAIL, Cambridge, MA, USA. axz@mit.edu\n\n**Ka Wong**, Google, Mountain View, CA, USA. kawong@google.com\n \n**Bryan Culbertson**, Calthorpe Analytics, Berkeley, CA, USA. bryan.culbertson@gmail.com\n \n**Praveen Paritosh**, Google, Mountain View, CA, USA. pkp@google.com\n \n## Citation Guidelines\n\nIf you are using this data towards a research publication, please cite the following paper.\n \nAmy X. Zhang, Bryan Culbertson, Praveen Paritosh. *Characterizing Online Discussion Using Coarse Discourse Sequences. In Proceedings of the International AAAI Conference on Weblogs and Social Media (ICWSM '17)*. Montreal, Canada. 2017. \n \nBibtex:\n@inproceedings{coarsediscourse,\n  title={Characterizing Online Discussion Using Coarse Discourse Sequences},\n  author={Zhang, Amy X. and Culbertson, Bryan and Paritosh, Praveen},\n  booktitle={Proceedings of the 11th International AAAI Conference on Weblogs and Social Media},\n  series={ICWSM '17},\n  year={2017},\n  location = {Montreal, Canada}\n}\n\n## License\nCC-by\n\n## Inspiration\n\n* Can you visualize which discourse acts are used to in replies to each kind of discourse act?\n* Are threads more likely to be made up of a single type of discourse act or multiple discourse acts?\n* Are certain discourse acts more closely associated with specific subreddits?""","b""['linguistics', 'languages', 'medium', 'featured']""",https://www.kaggle.com/rtatman/discourse-acts-on-reddit
b'Delhi Weather Data',b'Delhi Weather Data from 1997 to 2016 december',"b""# Context \n\nThis dataset contains weather data for New Delhi, India.\n\n# Content\n\nThis data was taken out from wunderground with the help of their easy to use api.\nIt contains various features such as temperature, pressure, humidity, rain, precipitation,etc.\n\n\n# Acknowledgements\n\nThis data is owned by wunderground and although I ended up using noaa's data for my research, i thought that i'd share this data here as I haven't worked on hourly data yet and this might be of huge importance.\n\n\n# Inspiration\n\nThe main target is to develop a prediction model accurate enough for predicting the weather. We can try something like predicting the weather in the next 24 hours like microsoft tried some time back.\n\n\n\n  https://blogs.microsoft.com/next/2015/08/10/hows-the-weather-using-artificial-intelligence-for-better-answers/#sm.018l60051a9neka10is1m5qpi6u5y""","b""['climate', 'utility', 'small', 'featured']""",https://www.kaggle.com/mahirkukreja/delhi-weather-data
b'2017 March ML Mania Predictions',b'Forecasting the 2017 NCAA Basketball Tournament',"b""Kaggle\xe2\x80\x99s [March Machine Learning Mania](https://www.kaggle.com/c/march-machine-learning-mania-2017) competition challenged data scientists to predict winners and losers of the men's 2017 NCAA basketball tournament. This dataset contains the selected predictions of all Kaggle participants. These predictions were collected and locked in prior to the start of the tournament.\n\nThe NCAA tournament is a single-elimination tournament that begins with 68 teams. There are four games, usually called the \xe2\x80\x9cplay-in round,\xe2\x80\x9d before the traditional bracket action starts. Due to competition timing, these games are included in the prediction files but should not be used in analysis, as it\xe2\x80\x99s possible that the prediction was submitted after the play-in round games were over.\n\n## Data Description\n\nEach Kaggle team could submit up to two prediction files. The prediction files in the dataset are in the 'predictions' folder. You can map the files to the teams by team_submission_key.csv.\n\nThe submission format contains a probability prediction for every possible game between the 68 teams. Refer to the competition documentation for data details. For convenience, we have included the data files from the competition dataset in the dataset (you may find TourneySlots.csv and TourneySeeds.csv useful for determining matchups). However, the focus of this dataset is on Kagglers' predictions.""","b""['artificial intelligence', 'basketball', 'medium', 'featured']""",https://www.kaggle.com/wcukierski/2017-march-ml-mania-predictions
b'Devanagari Character Set',b'Over 92 thousand images of characters from devanagari script',"b'# Context \nThis is a dataset of Devanagari Script Characters. It comprises of 92000 images [32x32 px] corresponding to 46 characters, consonants ""ka"" to ""gya"", and the digits 0 to 9. The vowels are missing.\n\n\n# Content\nThe CSV file is of the dimension 92000 * 1025. There are 1024 input features of pixel values in grayscale (0 to 255). The column ""character"" represents the Devanagari Character Name corresponding to each image.\n\n\n# Acknowledgements\nThis dataset was originally created by Computer Vision Research Group, Nepal. [website archive] (https://web.archive.org/web/20160105230017/http://cvresearchnepal.com/wordpress/dhcd/)\n\n# Example Script\nhttps://nbviewer.jupyter.org/github/rishianand9/devanagari-character-recognition/blob/master/DCRS.ipynb'","b""['image data', 'linguistics', 'multiclass classification', 'languages', 'medium', 'featured']""",https://www.kaggle.com/rishianand/devanagari-character-set
b'Fraudulent E-mail Corpus',"b'CLAIR collection of ""Nigerian"" fraud emails'","b'### Context: \nFraudulent e-mails contain criminally deceptive information, usually with the intent of convincing the recipient to give the sender a large amount of money. Perhaps the best known type of fraudulent e-mails is the [Nigerian Letter or \xe2\x80\x9c419\xe2\x80\x9d](https://www.fbi.gov/scams-and-safety/common-fraud-schemes/nigerian-letter-or-419-fraud) Fraud.\n\n### Content: \nThis dataset is a collection of more than 2,500 ""Nigerian"" Fraud Letters, dating from 1998 to 2007. \n\nThese emails are in a single text file. Each e-mail has a header which includes the following information: \n\t \t \t\n* Return-Path: address the email was sent from\n* X-Sieve: the X-Sieve host (always cmu-sieve 2.0)\n* Message-Id: a unique identifier for each message\n* From: the message sender (sometimes blank)\n* Reply-To: the email address to which replies will be sent\n* To: the email address to which the e-mail was originally set (some are truncated for anonymity)\n* Date: Date e-mail was sent\n* Subject: Subject line of e-mail\n* X-Mailer: The platform the e-mail was sent from\n* MIME-Version: The Multipurpose Internet Mail Extension version\n* Content-Type: type of content & character encoding\n* Content-Transfer-Encoding: encoding in bits\n* X-MIME-Autoconverted: the type of autoconversion done\n* Status: r (read) and o (opened)\n\n### Acknowledgements: \nIf you use this collection of fraud email in your research, please include the following citation in any resulting papers:\n\n> Radev, D. (2008), CLAIR collection of fraud email, ACL Data and Code Repository, ADCR2008T001, http://aclweb.org/aclwiki\n\n### Inspiration: \n\n* This dataset contains fraudulent e-mails sent over a period of years. Has the language used in fraudulent E-mails changed over time? \n* Are there any words or phrases that are particularly common in this type of e-mail? (You might compare it with the Enron email corpus, linked below)\n\n### Related datasets:\n\n* https://www.kaggle.com/wcukierski/enron-email-dataset\n* https://www.kaggle.com/uciml/sms-spam-collection-dataset'","b""['internet', 'linguistics', 'crime', 'medium', 'featured']""",https://www.kaggle.com/rtatman/fraudulent-email-corpus
b'NBA Players Stats - 2014-2015',"b'Points, Assists, Height, Weight and other personal details and stats'","b'# Context \n\nThis data set can be paired with the [shot logs][1] data set from the same season.\n\n\n# Content\n\nFull players stats from the 2014-2015 season + personal details such as height. weight, etc.\n\nThe data was scraped and copied from:\n[http://www.basketball-reference.com/teams/][2]\nand\n [http://stats.nba.com/leaders#!?Season=2014-15&SeasonType=Regular%20Season&StatCategory=MIN&CF=MIN*G*2&PerMode=Totals][3]\n\n\n\n  [1]: https://www.kaggle.com/dansbecker/nba-shot-logs\n  [2]: http://www.basketball-reference.com/teams/\n  [3]: http://stats.nba.com/leaders#!?Season=2014-15&SeasonType=Regular%20Season&StatCategory=MIN&CF=MIN*G*2&PerMode=Totals'","b""['basketball', 'small', 'featured']""",https://www.kaggle.com/drgilermo/nba-players-stats-20142015
b'Seattle Public Information of Open Meal Sites',b'From City of Seattle Open Data',"b""### Content  \n\nPublic meal programs in Seattle  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/NCbPd-WpuTs) by [Mariana Medvedeva](https://unsplash.com/@nobiteuntilphoto) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-public-information-of-open-meal-sites
b'Chicago Problem Landlord List',b'From City of Chicago Open Data',"b'### Content  \n\nThis list describes landlords and property owners who are designated  ""problem landlords"". Landlords on this list have had two or more administrative hearing causes brought against them and were found liable or defaulted to one or more serious building violations.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata\'s API and Kaggle\'s API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/AM1pNoCnJZc) by [Martin Grincevschi](https://unsplash.com/@martingrin) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._'","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-problem-landlord-list
b'Paid In Contributions to IBRD/IDA/IFC Trust Funds',b'From World Bank Financial Open Data',"b""### Content  \n\nA Recipient-executed Grant is a Trust Fund Grant that is provided to a third party under a grant agreement, and for which the Bank plays an operational role - i.e., the Bank normally appraises and supervises activities financed by these funds. This dataset provides data on the amount of grant funds committed in the course of a fiscal year and payments made out of a Trust Fund account to eligible recipients, in accordance with the legal agreements. In fulfilling its responsibilities, the World Bank as Trustee complies with all sanctions applicable to World Bank transactions. All definitions should be regarded at present as provisional and not final, and are subject to revision at any time. \r\nData is provided at the individual Trust Fund level and is updated as of 04/02/2015. No further updates are planned for this particular dataset, please visit the Global Partnership and Trust Fund Operations website for more details: http://go.worldbank.org/GABMG2YEI0  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](finances.worldbank.org) and they update their information according the amount of data that is brought in. Explore World Bank's Financial Data using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.\n\nThis dataset is distributed under a [Creative Commons Attribution 3.0 IGO](https://creativecommons.org/licenses/by/3.0/igo/) license.  \n\n[Cover photo](https://unsplash.com/photos/wNeuMUuGiPM) by [Joseph Gonzalez](https://unsplash.com/@miracletwentyone) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under Creative Commons Attribution 3.0 IGO""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/theworldbank/paid-in-contributions-to-ibrd-ida-ifc-trust-funds
b'Identifying Interesting Web Pages',b'Automatically Extracting Features for Concept Learning from the Web',"b'### Context\n\n\nThe problem is to predict user ratings for web pages (within a subject category). The HTML source of a web page is given. Users looked at each web page and indicated on a 3 point scale (hot medium cold) 50-100 pages per domain.\n\n\n### Content\n\nThis database contains HTML source of web pages plus the ratings of a single user on these web pages. Web pages are on four separate subjects (Bands- recording artists; Goats; Sheep; and BioMedical).\n\n### Acknowledgement\nData originally from the [UCI ML Repository](http://archive.ics.uci.edu/ml/datasets/syskill+and+webert+web+page+ratings). Donated by:\n\nMichael Pazzani\nDepartment of Information and Computer Science,\nUniversity of California, Irvine\nIrvine, CA 92697-3425\npazzani@ics.uci.edu\n\nConcept based Information Access with Google for Personalized Information Retrieval'","b""['internet', 'web sites', 'small', 'featured']""",https://www.kaggle.com/uciml/identifying-interesting-web-pages
b'Synchronized Brainwave Dataset',b'Brainwave recordings from a group presented with a shared audio-visual stimulus',"b'### Context\n\nEEG devices are becoming cheaper and more inconspicuous, but few applications leverage EEG data effectively, in part because there are few large repositories of EEG data. The MIDS class at the UC Berkeley School of Information is sharing a dataset collected using consumer-grade brainwave-sensing headsets, along with the software code and visual stimulus used to collect the data. The dataset includes all subjects\' readings during the stimulus presentation, as well as readings from before the start and after the end of the stimulus.\n\n### Content\n\nWe presented two slightly different stimuli to two different groups. [Stimuli 1 is available here](https://youtu.be/zkGoPdpRvaU), and [stimuli 2 is available here](https://youtu.be/sxqlOoBBjvc). \n\nFor both stimuli, a group of about 15 people saw the stimuli at the same time, while EEG data was being collected. The stimuli each person saw is available in the `session` field of `subject-metadata.csv`. (Subjects who saw stimulus 2 left the room during stimulus 1, and vice versa).\n\nFind the synchronized times for both stimuli in `stimulus-timing.csv`.\n\nFor each participant, we also anonymously collected some other metadata: (1) whether or not they had previously seen the video displayed during the stimulus (a superbowl ad), (2) gender, (3) whether or not they saw hidden icons displayed during the color counting exercise, and (4) their chosen color during the color counting exercise. All of these can be found in `subject-metadata.csv`.\n\nWe also collected the timing (in `indra_time`) of all stimulus events for both session 1 and session 2. These times are included in `stimulus-times.csv`.\n\nThe server receives one data packet every second from each Mindwave Mobile device, and stores the data in one row entry.\n\n### Acknowledgements\n\nPlease use the following citation if you publish your research results using this dataset or software code or stimulus file:\n\n**John Chuang, Nick Merrill, Thomas Maillart, and Students of the UC Berkeley Spring 2015 MIDS Immersion Class. ""Synchronized Brainwave Recordings from a Group Presented with a Common Audio-Visual Stimulus (May 9, 2015)."" May 2015.**'","b""['healthcare', 'human-computer interaction', 'medium', 'featured']""",https://www.kaggle.com/berkeley-biosense/synchronized-brainwave-dataset
b'The Examiner - SpamClickBait News Dataset',b'VI Years of Crowd-Sourced-Journalism',"b""### Context\n\nPresenting a compendium of crowdsourced journalism from the psuedo-news site **The Examiner**. \n\nThis dataset contains the headlines of **3 million articles** written by **21000+ authors** over **6 years**. \n\nWhile The Examiner was never praised for its quality, it consistently churned out 1000s of articles per day over several years. \n\nAt their height in 2011, The Examiner was ranked highly in google search and had enormous shares on social media.\nAt one point it was the 10th largest site on mobile and was attracting 20 M unique visitors a month.\n\nAs a platform driven towards advert revenue, most of their content was rushed, unsourced and factually sparse. \nIt still manages to paint a colourful picture about the trending topics over a long period of time.\n\nPrepared by Rohit Kulkarni\n\n### Content\n\nFormat: CSV Rows: 3,089,781\n\n - **publish_date**: Date when the article was published on the site in yyyyMMdd format\n - **headline_text**: Text of the headline in English with rare utf8 chars (&lt;1k)\n\nStart Date: 2010-01-01   End Date: 2015-21-31\n\nAnother copy of the file with headlines tokenised to lowercase ascii only is included.\n\n### Acknowledgements\n\nCreated using Jsoup, Java and Bash.\n\nSimilar news datasets exploring other attributes, countries and topics can be seen on my profile.\n\nThis dataset is free to use with citation:\n\nRohit Kulkarni (2017), The Examiner - Spam ClickBait News 2010-2015 [CSV data files], doi:10.7910/DVN/I4HKOO, Retrieved from [this url]\n\n### Inspiration\n\nThe Examiner had emerged as an early winner in the digital content landscape of the 2000's using catchy headlines. \n\nIt changed many roles over the years, from leftist citizen news to a multiuser blogging platform to a content farm.\n\nWith falling views its operations were absorbed by AXS in 2014 and the website was finally shut down in June 2016.\n\nThe original site and content no longer exists: http://www.examiner.com\n\nThis is the last surviving record of its existence.""","b""['linguistics', 'news agencies', 'journalism', 'sociology', 'historiography', 'medium', 'featured']""",https://www.kaggle.com/therohk/examine-the-examiner
b'Board Game Data',b'Data is a collection of board game information from Board Game Geek',"b'# Context \n\nBeing a fan of board games, I wanted to see if there was any correlation with a games rating and any particular quality, the first step was to collect of this data.\n\n# Content\n\nThe data was collected in March of 2017 from the website https://boardgamegeek.com/, this site has an API to retrieve game information (though sadly XML not JSON).\n\n\n# Acknowledgements\n\nMainly I want to thank the people who run the board game geek website for maintaining such a great resource for those of us in the hobby.\n\n\n# Inspiration\n\nI wish I had some better questions to ask of the data, perhaps somebody else can think of some good ways to get some insight of this dataset.'","b""['board games', 'small', 'featured']""",https://www.kaggle.com/mrpantherson/board-game-data
b'Stopword Lists for African Languages',b'Stopword Lists & Frequency Information for 9 African Languages',"b'### Context: \nSome words, like \xe2\x80\x9cthe\xe2\x80\x9d or \xe2\x80\x9cand\xe2\x80\x9d in English, are used a lot in speech and writing. For most Natural Language Processing applications, you will want to remove these very frequent words. This is usually done using a list of \xe2\x80\x9cstopwords\xe2\x80\x9d which has been complied by hand.\n\n### Content: \nThis project uses the source texts provided by the African Storybook Project as a corpus and provides a number of tools to extract frequency lists and lists of stopwords from this corpus for the 60+ languages covered by ASP.\n\nIncluded in this dataset are the following languages:\n\n* Afrikaans: stoplist and word frequency\n* Hausa: stoplist and word frequency\n* Lugbarati: word frequency only\n* Lugbarati (Official): word frequency only\n* Somali: stoplist and word frequency\n* Sesotho: stoplist and word frequency\n* Kiswahili: stoplist and word frequency\n* Yoruba: stoplist and word frequency\n* isiZulu: stoplist and word frequency\n\nFiles are named using the language\xe2\x80\x99s ISO code. For each language, code.txt is the list of stopwords, and code_frequency_list.txt is word frequency information. A list of ISO codes the the languages associated with them may be found in ISO_codes.csv.\n\n### Acknowledgements: \nThis project therefore attempts to fill in the gap in language coverage for African language stoplists by using the freely-available and open-licensed ASP Source project as a corpus.\nDual-licensed under CC-BY and Apache-2.0 license. Compiled by Liam Doherty. More information and the scripts used to generate these files are available [here](https://github.com/dohliam/more-stoplists).\n\n### Inspiration: \nThis dataset is mainly helpful for use during NLP analysis, however there may some interesting insights in the data.\n\n* What qualities do stopwords share across languages? Given a novel language, could you predict what its stopwords should be?\n* What stopwords are shared across languages?\n* Often, related languages will have words with the same meaning and similar spellings. Can you automatically identify any of these pairs of words?\n\n### You may also like:\n\n* [Stopword Lists for 19 Languages (mainly European and South Asian)](https://www.kaggle.com/rtatman/stopword-lists-for-19-languages)'","b""['linguistics', 'languages', 'africa', 'small', 'featured']""",https://www.kaggle.com/rtatman/stopword-lists-for-african-languages
b'Chicago Towing Records',"b'5800 Violation Records, July 7- Sept 7 2017'","b'### Context: \nThis dataset displays location for vehicles that have been towed and impounded by the City of Chicago within the last 90 days. Illegally parked vehicles, abandoned vehicles and vehicles used for illegal activities may be towed by the Chicago Police Department, the Department of Streets and Sanitation, the Department of Revenue, Aviation and the office of the City Clerk. After a tow request is issued, an inventory number is assigned by the Department of Streets and Sanitation and a truck is dispatched to tow the requested vehicle to a City auto pound. Disclaimer: This dataset includes vehicles towed or relocated by the City of Chicago; it does not include vehicles towed by a private towing company. \n\n\n### Content: \nCollected July 7-Sept 7. Updated data can be found [here](https://data.cityofchicago.org/Transportation/Towed-Vehicles/ygr5-vcbg) for past 90 days.\n\nColumns include:\n\n* TowDate\n* Make\n* Style\n* Model\n* Color\n* Plate\n* State\n* TowedToAddress\n* TowFacilityPhone\n* InventoryNumber\n\n### Acknowledgements: \nDataset was compiled by the City of Chicago [here](https://data.cityofchicago.org/Transportation/Towed-Vehicles/ygr5-vcbg).\n\n### Inspiration: \n* When do most tows occur?\n* What are the most commonly towed cars?\n* Where are most tows occurring?\n'","b""['government', 'government agencies', 'small', 'featured']""",https://www.kaggle.com/chicagopolice/chicago-towing
b'Museum of Modern Art Collection',"b'Title, artist, date, and medium of every artwork in the MoMA collection'","b""# Context \n\nThe Museum of Modern Art (MoMA) acquired its first artworks in 1929, the year it was established. Today, the Museum\xe2\x80\x99s evolving collection contains almost 200,000 works from around the world spanning the last 150 years. The collection includes an ever-expanding range of visual expression, including painting, sculpture, printmaking, drawing, photography, architecture, design, film, and media and performance art.\n\n\n# Content\n\nMoMA is committed to helping everyone understand, enjoy, and use our collection. The Museum\xe2\x80\x99s website features 72,706 artworks from 20,956 artists. The artworks dataset contains 130,262 records, representing all of the works that have been accessioned into MoMA\xe2\x80\x99s collection and cataloged in our database. It includes basic metadata for each work, including title, artist, date, medium, dimensions, and date acquired by the Museum. Some of these records have incomplete information and are noted as \xe2\x80\x9cnot curator approved.\xe2\x80\x9d The artists dataset contains 15,091 records, representing all the artists who have work in MoMA's collection and have been cataloged in our database. It includes basic metadata for each artist, including name, nationality, gender, birth year, and death year.\n\n\n# Inspiration\n\nWhich artist has the most works in the museum collection or on display? What is the largest work of art in the collection? How many pieces in the collection were made during your birth year? What gift or donation is responsible for the most artwork in the collection?""","b""['visual arts', 'museums', 'medium', 'featured']""",https://www.kaggle.com/momanyc/museum-collection
b'National Institute of the Korean Language Corpus',b'Korean frequency lists for NLP',"b'### Context: \n\nHow frequently a word occurs in a language is an important piece of information for natural language processing and linguists. In natural language processing, very frequent words tend to be less informative than less frequent one and are often removed during preprocessing. \n\nThis dataset contains frequency information on Korean, which is spoken by 80 million people. For each item, both the frequency (number of times it occurs in the corpus) and its relative rank to other lemmas is provided.\n\n### Content: \n\nThis dataset contains six sub-files with frequency information. The files have been renamed in English, but no changes have been made to the file contents. The files and their headers are listed below. \nThe text in this dataset is UTF-8.\n\n* Frequency by Jamo (letter)\n    * \xec\x88\x9c\xec\x9c\x84: Rank\n    * \xeb\xb9\x88\xeb\x8f\x84: Frequency\n    * \xec\x9c\x84\xec\xb9\x98: Location\n    * \xec\x9e\x90\xeb\xaa\xa8: Jamo (Hangul letter)\n* Frequency\n    * \xec\x88\x9c\xec\x9c\x84: Rank\n    * \xeb\xb9\x88\xeb\x8f\x84: Frequency \n    * \xed\x95\xad\xeb\xaa\xa9: Location\n    * \xeb\xb2\x94\xec\xa3\xbc: Category\n* Frequency by Syllable\n    * \xec\x88\x9c\xec\x9c\x84: Rank\n    * \xeb\xb9\x88\xeb\x8f\x84: Frequency\n    * \xec\x9d\x8c\xec\xa0\x88: Syllable\n* Borrowings\n    * \xec\x88\x9c\xec\x9c\x84: Rank\n    * \xeb\xb9\x88\xeb\x8f\x84: Frequency\n    * \xed\x95\xad\xeb\xaa\xa9: Item\n    * \xed\x92\x80\xec\x9d\xb4: Root\n* Non Standard Words\n    * \xec\x88\x9c\xec\x9c\x84: Rank\n    * \xeb\xb9\x88\xeb\x8f\x84: Frequency\n    * \xec\x96\xb4\xed\x9c\x98: Vocabulary\n    * \xed\x92\x80\xec\x9d\xb4: Notes\t\n    * \xed\x92\x88\xec\x82\xac: Part of Speech\n* Frequency (Longer version)\n    * \xec\x88\x9c\xec\x9c\x84: Rank\n    * \xeb\xb9\x88\xeb\x8f\x84: Frequency \n    * \xed\x95\xad\xeb\xaa\xa9: Location\n    * \xeb\xb2\x94\xec\xa3\xbc: Category\n\n### Acknowledgements: \n\nThis dataset was collected and made available by the [National Institute of Korean Language](http://www.korean.go.kr/front_eng/main.do;front=C773F763B50B426BC61AC2D79AABA3C2). The dataset and additional documentation (in Korean) can be found [here](http://korean.go.kr/front/reportData/reportDataView.do?mn_id=45&report_seq=1&pageIndex=1). \n\nThis dataset is distributed under a [Korean Open Government Liscence, type 4](https://en.wikipedia.org/wiki/Korea_Open_Government_License). It may be redistributed with attribution, without derivatives and not for commercial purposes.\n \n### Inspiration: \n\n* What are the most frequent jamo (Hangul characters) in Korean? Least frequent?\n* What qualities do borrowed words have?\n* Is there a relationship between word length and frequency?\n\n### You may also like:\n\n* [English word frequency](https://www.kaggle.com/rtatman/english-word-frequency)\n* [Japanese lemma frequency](https://www.kaggle.com/rtatman/japanese-lemma-frequency)\n* [List of simplified Chinese characters ordered by frequency rank](https://www.kaggle.com/ruddfawcett/hanzidb)\n* [Stopword lists for African languages](https://www.kaggle.com/rtatman/stopword-lists-for-african-languages)'","b""['linguistics', 'languages', 'asia', 'small', 'featured']""",https://www.kaggle.com/rtatman/national-institute-of-the-korean-language-corpus
b'Article Titles from TechCrunch and VentureBeat',"b'Titles of 22,000+ article published on two of the top media websites'","b""### Context\n\nWeb data extraction or web scraping can be a great business tool for trend spotting via media monitoring. Essentially, leading media outlets can be tracked to unveil the top buzzwords and the number of mentions companies (including their products) garner over specific time period. We wanted to apply this method to understand the tech landscape and its coverage in 2017. Hence, we deployed PromptCloud\xe2\x80\x99s in-house web crawler to extract the article titles from two popular outlets (TechCrunch and VentureBeat) and performed text mining on the dataset to uncover the top buzzwords, companies and products.\n\n\n### Content\n\nThe dataset contains following 3 fields:\n\n 1. URL\n 2. Title\n 3. Date of publication\n\n### Acknowledgements\n\nThis dataset was created by using PromptCloud's in-house web scraping service.\n\n\n### Inspiration\n\nInitial Analysis can be [found here][1].\nIt includes the following findings:\n\n 1. Top companies/products that were covered by media over the year\n 2. Top tech trends over the year\n\n  [1]: https://www.promptcloud.com/blog/web-scraping-reveals-top-tech-trends-2017?utm_source=rb-kaggle&utm_medium=referral&utm_campaign=kaggle""","b""['internet', 'journalism', 'mass media', 'small', 'featured']""",https://www.kaggle.com/PromptCloudHQ/titles-by-techcrunch-and-venturebeat-in-2017
b'SF Beaches Water Quality',"b'Contaminant Sampling Across 15 Beaches, Summer 2017'","b'### Context: \nShoreline bacteria are routinely monitored at fifteen stations around the perimeter of San Francisco where water contact recreation may occur. These include three stations within the Candlestick Point State Recreation Area, one station at Islais Creek, two stations at Aquatic Park, two stations along Crissy Field Beach, three stations at Baker Beach, one station at China Beach, and three stations along Ocean Beach.\n\n\n### Content: \nDataset represents 552 samples taken across 15 locations over summer of 2017. Additional monitoring is conducted whenever a treated discharge from the City\xe2\x80\x99s Combined sewer system occurs that affects a monitored beach.\n\n\n### Acknowledgements: \nThe beach monitoring program is a cooperative effort between the San Francisco Public Utilities Commission and the San Francisco Department of Public Health. Samples are collected weekly year round.  [READ MORE](http://sfwater.org/index.aspx?page=87#CSD) about the combined sewer system and a detailed explanation of the Beach Monitoring Program.\n\n### Inspiration: \n\n* Are there any patterns in beach water quality?'","b""['safety', 'bodies of water', 'small', 'featured']""",https://www.kaggle.com/jboysen/sf-beaches-water
b'Codechef Competitive Programming',b'Problem statements and solutions provided by people on the codechef site',"b""In the pursuit of any goal, the first step is invariably data collection. As put up on the [OpenAI](https://openai.com/blog/special-projects/) blog, writing a program which can write other programs is an incredibly important problem.\n\nThis dataset collects publicly available information from the [Codechef](http://codechef.com) site's practice section to provide about 1000 problem statements and a little over 1 million solutions in total to these problems in various languages.\n\nThe ultimate aim is to allow a program to learn program generation in any language to satisfy a given problem statement.""","b""['programming', 'large', 'featured']""",https://www.kaggle.com/arjoonn/codechef-competitive-programming
b'Iris Species',b'Classify iris plants into three species in this classic dataset',"b""The Iris dataset was used in R.A. Fisher's classic 1936 paper, [The Use of Multiple Measurements in Taxonomic Problems](http://rcs.chemometrics.ru/Tutorials/classification/Fisher.pdf), and can also be found on the [UCI Machine Learning Repository][1].\n\nIt includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n\nThe columns in this dataset are:\n\n - Id\n - SepalLengthCm\n - SepalWidthCm\n - PetalLengthCm\n - PetalWidthCm\n - Species\n\n[![Sepal Width vs. Sepal Length](https://www.kaggle.io/svf/138327/e401fb2cc596451b1e4d025aaacda95f/sepalWidthvsLength.png)](https://www.kaggle.com/benhamner/d/uciml/iris/sepal-width-vs-length)\n\n\n  [1]: http://archive.ics.uci.edu/ml/""","b""['botany', 'small', 'featured']""",https://www.kaggle.com/uciml/iris
b'Shanghai Car License Plate Auction Price',b'Time-series data set (2012-2018)',"b'### Context\n\nShanghai uses an auction system to sell a limited number of license plates to fossil-fuel car buyers every month. The average price of this license plate is about $13,000 and it is often referred to as ""the most expensive piece of metal in the world."" So, our goal is to predict the avg price or the lowest price for the next month. This Data set will be updated every month constantly. Have fun!\n\n### Content\n\nThis data set is gathered by myself with the aid of search engine. \n\n### Inspiration\n\nThis data set could be used in your first toy example project. Learning algorithms like RNN+LSTM are well fitted into this time-series prediction problem. So, just have fun!'","b""['time series', 'china ', 'small', 'featured']""",https://www.kaggle.com/bogof666/shanghai-car-license-plate-auction-price
b'Weekly Corn Price',b'Weekly corn close price from 2015 to 2017 (2017-10-01)',"b'### Context\n\nAs I am trying to learn and build an LSTM prediction model for equity prices, I have tried Gold and then want to try crops which may have strong trends in times, so I prepared the dataset for the weekly corn prices.\n\n\n### Content\n\nThe file composed of simply 2 columns. One is the date (weekend) and the other is corn close price. The period is from 2015-01-04 to 2017-10-01. The original data is downloaded from Quantopian corn futures price.\n\n\n### Acknowledgements\n\nThanks to Jason of his tutorial about LSTM forecast: https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n\n\n### Inspiration\n\nWilliam Gann: Time is the most important factor in determining market movements and by studying past price records you will be able to prove to yourself history does repeat and by knowing the past you can tell the future. There is a definite relation between price and time.'","b""['finance', 'agriculture', 'small', 'featured']""",https://www.kaggle.com/nickwong64/corn2015-2017
b'Las Vegas TripAdvisor Reviews',b'500 reviews from hotels on the Las Vegas Strip',"b'### Context\n\nThis dataset includes quantitative and categorical features from online reviews from 21 hotels located in Las Vegas Strip, extracted from TripAdvisor. All the 504 reviews were collected between January and August of 2015.\n\n### Content\n\nThe dataset contains 504 records and 20 tuned features,  24 per hotel (two per each month, randomly selected), regarding the year of 2015.  The CSV contains a header, with the names of the columns corresponding to the features.\n\n### Acknowledgements\n\nLichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml][1]. Irvine, CA: University of California, School of Information and Computer Science\n\n[Downloaded form UCI Machine Learning Repository][1]\n\n### Inspiration\n\nDo machine learning algorithms take into account what happens in Vegas stays in Vegas?\n\n\n  [1]: https://archive.ics.uci.edu/ml/datasets/Las+Vegas+Strip#'","b""['cities', 'hotels', 'small', 'featured']""",https://www.kaggle.com/crawford/las-vegas-tripadvisor-reviews
b'Seattle SDOT Construction List',b'From City of Seattle Open Data',"b""### Content  \n\nGives a snapshot of planned construction and events in Seattle that may impact traffic.  \n\n### Context  \n\nThis is a dataset hosted by the City of Seattle. The city has an open data platform found [here](https://data.seattle.gov/) and they update their information according the amount of data that is brought in. Explore the City of Seattle using Kaggle and all of the data sources available through the City of Seattle [organization page](https://www.kaggle.com/city-of-seattle)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/SvMlXH_eW6o) by [Volkan Olmez](https://unsplash.com/@volkanolmez) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'construction', 'small', 'featured']""",https://www.kaggle.com/city-of-seattle/seattle-sdot-construction-list
b'Aerial Bombing Operations in World War II',"b'Target, aircraft used, and bombs deployed for every mission in WWII'","b'# Content\n\nThis dataset consists of digitized paper mission reports from WWII. Each record includes the date, conflict, geographic location, and other data elements to form a live-action sequence of air warfare from 1939 to 1945. The records include U.S. and Royal Air Force data, in addition to some Australian, New Zealand and South African air force missions.\n\n\n# Acknowledgements\n\nLt Col Jenns Robertson of the US Air Force developed the Theater History of Operations Reports (THOR) and posted them online after receiving Department of Defense approval.'","b""['history', 'war', 'medium', 'featured']""",https://www.kaggle.com/usaf/world-war-ii
b'Consumer Price Index',b'Statistical measures of change in prices of consumer goods',"b'###Context:  \nThe Bureau of Labor Statistics defines the Consumer Price Index (CPI) as \xe2\x80\x9ca statistical measure of change, over time, of the prices of goods and services in major expenditure groups--such as food, housing, apparel, transportation, and medical care--typically purchased by urban consumers.  Essentially, it compares the cost of a sample of goods and services in a specific month relative to the cost of the same ""market basket"" in an earlier reference period. \n\n**Make sure to read the *cu.txt* for more descriptive summaries on each data file and how to use the unique identifiers.**\n\n###Content:\nThis dataset was collected June 27th, 2017 and may not be up-to-date.\n\nThe revised CPI introduced by the BLS in 1998 includes indexes for two populations; urban wage earners and clerical workers (CW), and all urban consumers (CU).  **This dataset covers all urban consumers (CU).**\n\nThe Consumer Price Index (CPI) is a statistical measure of change, over time, of the prices of goods and services in major expenditure groups--such as food, housing, apparel, transportation, and medical care--typically purchased by urban consumers.  Essentially, it compares the cost of a sample ""market basket"" of goods and services in a specific month relative to the cost of the same ""market basket"" in an earlier reference period.  This reference period is designated as the base period.\n\nAs a result of the 1998 revision, both the CW and the CU utilize updated expenditure weights based upon data tabulated from three years (1982, 1983, and 1984) of the Consumer Expenditure Survey and incorporate a number of technical improvements, including an updated and revised item structure.\n\nTo construct the two indexes, prices for about 100,000 items and data on about 8,300 housing units are collected in a sample of 91 urban places.  Comparison of indexes for individual CMSA\'s or cities show only the relative change over time in prices between locations.  These indexes cannot be used\nto measure interarea differences in price levels or living costs.\n\n**Summary Data Available:** U.S. average indexes for both populations are available for about 305 consumer items and groups of items.  In addition, over 100 of the indexes have been adjusted for seasonality.  The indexes are monthly with some beginning in 1913. Semi-annual indexes have been calculated for about 100 items for comparison with semi-annual areas mentioned below.  Semi-annual indexes are available from 1984 forward.\n\nArea indexes for both populations are available for 26 urban places.  For each area, indexes are published for about 42 items and groups.  The indexes are published monthly for three areas, bimonthly for eleven areas, and semi-annually for 12 urban areas.\n\nRegional indexes for both populations are available for four regions with  about 55 items and groups per region.  Beginning with January 1987, indexes are monthly, with some beginning as early as 1966.  Semi-annual indexes have been calculated for about 42 items for comparison with semi-annual areas mentioned above.  Semi-annual indexes have been calculated for about 42 items in the 27 urban places for comparison with semi-annual areas.\n\nCity-size indexes for both populations are available for three size classes with about 55 items and groups per class.  Beginning with January 1987, indexes are monthly and most begin in 1977.  Semi-annual indexes have been calculated for about 42 items for comparison with semi-annual areas mentioned below.\n\nRegion/city-size indexes for both populations are available cross classified by region and city-size class.  For each of 13 cross calculations, about 42 items and groups are available.  Beginning with January 1987, indexes are monthly and most begin in 1977.  Semi-annual indexes have been calculated for about 42 items in the 26 urban places for comparison with semi-annual areas.\n\n**Frequency of Observations:**  U.S. city average indexes, some area indexes, and regional indexes, city-size indexes, and region/city-size indexes for both populations are monthly.  Other area indexes for both populations are bimonthly or semi-annual.\n\n**Annual Averages:** Annual averages are available for all unadjusted series in the CW and CU.\n\n**Base Periods:** Most indexes have a base period of 1982-1984 = 100.  Other indexes, mainly those which have been added to the CPI program with the 1998 revision, are based more recently.  The base period value is 100.0, except for the ""Purchasing Power"" values (AAOR and SAOR) where the base period value is 1.000.\n\n**Data Characteristics:** Indexes are stored to one decimal place, except for the ""Purchasing Power"" values which are stored to three decimal places.\n\n*References:  BLS Handbook of Methods, Chapter 17, ""Consumer Price Index"",  BLS Bulletin 2285, April 1988.*\n\n\n###Acknowledgements: \nThis dataset was taken directly from the U.S. Bureau of Labor Statistics website at http://www.bls.gov/data/ and converted to CSV format.\n\n###Inspiration: \nThe Bureau of Labor Statistics has done a great job of providing this source of information for the public to explore. You can use this information to compare the cost of living in urban areas around the United States. What are the top 10 most expensive places to live? Which cities have the most expensive snacks or college textbooks? Coffee? Beer?'","b""['finance', 'business', 'medium', 'featured']""",https://www.kaggle.com/bls/consumer-price-index
b'Airlines Delay',b'Airline on-time statistics and delay causes',"b""The U.S. Department of Transportation's (DOT) Bureau of Transportation Statistics (BTS) tracks the on-time performance of domestic flights operated by large air carriers. Summary information on the number of on-time, delayed, canceled and diverted flights appears in DOT's monthly Air Travel Consumer Report, published about 30 days after the month's end, as well as in summary tables posted on this website. BTS began collecting details on the causes of flight delays in June 2003. Summary statistics and raw data are made available to the public at the time the Air Travel Consumer Report is released.\n\nThis version of the dataset was compiled from the Statistical Computing Statistical Graphics 2009 Data Expo and is also [available here][1].\n\n  [1]: http://stat-computing.org/dataexpo/2009/the-data.html""","b""['aviation', 'medium', 'featured']""",https://www.kaggle.com/giovamata/airlinedelaycauses
b'NYC Government Building Energy Usage',b'Energy usage for New York City owned office buildings',"b""### Context\n\nThis dataset contains energy usage information for every building owned and managed by NYC DCAS. DCAS, or the Department of Citywide Administrative Services, is the arm of the New York City municipal government which handles ownership and management of the city's office facilities and real estate inventory. The organization voluntarily publicly discloses self-measured information about the energy use of its buildings.\n\n### Content\n\nThis data contains information on the name, address, location, and 2015 financial cycle energy usage of every building managed at that time by DCAS.\n\n### Acknowledgements\n\nThis dataset is published as-is by of the City of New York ([here](https://data.cityofnewyork.us/City-Government/DCAS-Managed-Building-Energy-Usage/ubdi-jgw2)).\n\n### Inspiration\n\n* By combining this dataset with the [New York City Buildings Database](https://www.kaggle.com/new-york-city/nyc-buildings), what can you learn about the energy usage of buildings in New York City?\n* Can you use this data to model the energy consumption for city's office space at large?""","b""['government', 'energy', 'real estate', 'small', 'featured']""",https://www.kaggle.com/residentmario/nyc-building-energy-usage
b'Vader Lexicon',b'Lexicon use for the Vader Sentiment Algorithm',"b'### Context\n\nVADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.\n\nThe VADER lexicon is an empirically validated by multiple independent human judges, VADER incorporates a ""gold-standard"" sentiment lexicon that is especially attuned to microblog-like contexts. \n\nThe documentation of the lexicon and the algorithm can be found from the original implementation: https://github.com/cjhutto/vaderSentiment \n\nThe NLTK port has slight modification to integrate with the NLTK interfaces and it comes with better Python3 support: https://github.com/nltk/nltk/blob/develop/nltk/sentiment/vader.py\n\n### Citation\n\n    Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for\n    Sentiment Analysis of Social Media Text. Eighth International Conference on\n    Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n\n### Inspiration\n\nWe look forward to more sentiment analysis datasets, perhaps a JEDI (Joint Entropy Decay Iteration) algorithm someday?'","b""['linguistics', 'small', 'featured']""",https://www.kaggle.com/nltkdata/vader-lexicon
b'Snowball Data',b'Data for the Snowball Stemmer',"b'### Context\n\nThis dataset is a subset of the [Snowball data](https://github.com/snowballstem/snowball-data) that is used in NLTK version of the Snowball stemmer.\n\nNLTK Snowball stemmer supports the following languages: \n\n - Danish\n - Dutch\n - English \n - Finnish \n - French \n - German\n - Hungarian \n - Italian\n - Norwegian \n - Portuguese \n - Romanian\n - Russian\n - Spanish\n - Swedish \n - Turkish\n\nThe original Snowball stemmer is hosted on http://snowballstem.org/ \n\n### Acknowledgements\n\nLicense:\n\n\n    Copyright (c) 2001, Dr Martin Porter\n    Copyright (c) 2004,2005, Richard Boulton\n    All rights reserved.\n    \n    Redistribution and use in source and binary forms, with or without\n    modification, are permitted provided that the following conditions\n    are met:\n    \n      1. Redistributions of source code must retain the above copyright notice,\n         this list of conditions and the following disclaimer.\n      2. Redistributions in binary form must reproduce the above copyright notice,\n         this list of conditions and the following disclaimer in the documentation\n         and/or other materials provided with the distribution.\n      3. Neither the name of the Snowball project nor the names of its contributors\n         may be used to endorse or promote products derived from this software\n         without specific prior written permission.\n    \n    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND\n    ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n    WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n    DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\n    ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n    (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n    LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n    ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n    (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n    SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.'","b""['medium', 'featured']""",https://www.kaggle.com/nltkdata/snowball-data
b'DACA Recipients',b'Aggregate data as of Sept 4 2017',"b'### Context\n\nAggregate data from US Citizenship and Immigration Services on Deferred Action for Childhood Arrivals program as of Sept 4 2017\nhttps://www.uscis.gov/tools/reports-studies/immigration-forms-data/data-set-form-i-821d-deferred-action-childhood-arrivals\n\n### Content\n\n#### Country of birth: approximate active DACA recipients\n\nNotes:\n\n- This table refers to individuals who were granted Deferred Action for Childhood Arrivals (DACA) as of September 4, 2017.  The number of individuals who were ever granted DACA as of September 4, 2017 was approximately 800,000. This total excludes persons who applied for an initial grant of DACA and were not approved, as well as initial DACA requestors that were approved at first, but later had their initial request denied or terminated. Nearly 40,000 DACA recipients have adjusted to lawful permanent resident (LPR) status, leaving about 760,000 who are not LPRs.  About 70,000 individuals who were granted DACA either failed to renew at the end of their 2-year validity period or were denied on renewal, leaving approximately 690,000 active DACA recipients as of September 4, 2017.\n- Totals do not add due to rounding.\n- Countries  with fewer than 10 active DACA recipients are included in other.\n- Not available:  data are not available in electronic systems.\nSource:  U.S. Citizenship and Immigration Services,""\t\t\t\t\t\t\t\n\n#### State of Residence:\n\nNotes:\n\n- This table refers to individuals who were  granted Deferred Action for Childhood Arrivals (DACA) as of September 4, 2017.  The number of individuals who were ever granted DACA as of September 4, 2017 was approximately 800,000. This total excludes persons who applied for an initial grant of DACA and were not approved, as well as initial DACA requestors that were approved at first, but later had their initial request denied or terminated. Nearly 40,000 DACA recipients have adjusted to lawful permanent resident (LPR) status, leaving about 760,000 who are not LPRs.  About 70,000 individuals who were granted for DACA either failed to renew at the end of their 2-year validity period or were denied on renewal, leaving approximately 690,000 active DACA recipients as of September 4, 2017.\n- State of residence at the time of most recent application.\n- Totals do not add due to rounding.\n- Territories with less than 10 residents are included in other.\n- Not available:  data are not available in electronic systems.\nSource:  U.S. Citizenship and Immigration Services, CLAIMS3 and ELIS Systems.""\t\t\t\t\t\t\t\t\n\n#### Core-based Statistical Areas\n\nNotes:\n\n- This table refers to individuals who were granted Deferred Action for Childhood Arrivals (DACA) as of September 4, 2017.  The number of individuals who were ever granted DACA as of September 4, 2017 was approximately 800,000. This total excludes persons who applied for an initial grant of DACA and were not approved, as well as initial DACA requestors that were approved at first, but later had their initial request denied or terminated. Nearly 40,000 DACA recipients have adjusted to lawful permanent resident (LPR) status, leaving about 760,000 who are not LPRs.  About 70,000 individuals who were granted DACA either failed to renew at the end of their 2-year validity period or were denied on renewal, leaving approximately 690,000 active DACA recipients as of September 4, 2017.\n- Core Based Statistical Areas (CBSA) at the time of most recent application.  CBSAs are defined  by the Office of Management and Budget.\n- Totals may not add due to rounding.\n- CBSAs with fewer than 1,000 residents are included in other.\n- Not available:  data are not available in electronic systems.\nSource:  U.S. Citizenship and Immigration Services, CLAIMS3 and ELIS Systems.""\t\t\t\t\t\t\t\t\t\t\t\t\n\n#### Age and Sex\n\nNotes:\n\n- These tables refer to individuals who were  granted Deferred Action for Childhood Arrivals (DACA) as of September 4, 2017. The number of individuals who were ever granted DACA as of September 4, 2017 was approximately 800,000. This total excludes persons who applied for an initial grant of DACA and were not approved, as well as initial DACA requestors that were approved at first, but later had their initial request denied or terminated.  Nearly 40,000 DACA recipients have adjusted to lawful permanent resident (LPR) status, leaving about 760,000 who are not LPRs.  About 70,000 individuals who were granted DACA either failed to renew at the end of their 2-year validity period or were denied on renewal, leaving approximately 690,000 active DACA recipients as of September 4, 2017.\n- Age as of September 4, 2017 and marital status as of the time of most recent application.\n- Totals do not add due to rounding.\n- Interquartile range is the range between the 25th percentile and the 75th percentile.  About half of the active DACA recipients are 20 to 27 years old.\n- Not available:  data are not available in electronic systems.\nSource:  U.S. Citizenship and Immigration Services, CLAIMS3 and ELIS Systems.""\t\t\t\t\t\t\t\t\t\n\n#### Marital status\n\nNotes:\n\n- This table refers to individuals who were granted Deferred Action for Childhood Arrivals (DACA) as of September 4, 2017.  The number of individuals who were ever granted DACA as of September 4, 2017 was approximately\n800,000. This total excludes persons who applied for an initial grant of DACA and were not approved, as well as initial DACA requestors that were approved at first, but later had their initial request denied or terminated.  Nearly 40,000 DACA recipients have adjusted to lawful permanent resident (LPR) status, leaving about 760,000 who are not LPRs.  About 70,000 individuals who were granted DACA either failed to renew at the end of their 2-year validity period or were denied on renewal, leaving approximately 690,000 active DACA recipients as of September 4, 2017.\n- Marital status at time of most recent application.\n- Not available:  data are not available in electronic systems.\n\n### Inspiration\n\nI converted this data set from the published PDF so I could practice making choropleth maps. \n\n### Acknowledgements \n\nI got the CBSA topojson from here: https://discourse.looker.com/t/custom-topojson-for-2014-core-based-statistical-areas-cbsa/2028\n'","b""['demographics', 'politics', 'small', 'featured']""",https://www.kaggle.com/anupamakhan/daca-recipients-as-of-sept-4-2017
b'Names Corpus',b'5001 female names and 2943 male names',"b'### Context\n\nThis corpus contains 5001 female names and 2943 male names, sorted alphabetically, one per line created by Mark Kantrowitz and redistributed in NLTK. \n\nThe `names.zip` file includes \n \n  - README: The readme file.\n  - female.txt:  A line-delimited list of words.\n  - male.txt: A line-delimited list of words.\n\n### License/Usage\n\n    Names Corpus, Version 1.3 (1994-03-29)\n    Copyright (C) 1991 Mark Kantrowitz\n    Additions by Bill Ross\n    \n    This corpus contains 5001 female names and 2943 male names, sorted\n    alphabetically, one per line.\n    \n    You may use the lists of names for any purpose, so long as credit is\n    given in any published work. You may also redistribute the list if you\n    provide the recipients with a copy of this README file. The lists are\n    not in the public domain (I retain the copyright on the lists) but are\n    freely redistributable.  If you have any additions to the lists of\n    names, I would appreciate receiving them.\n    \n    Mark Kantrowitz <mkant+@cs.cmu.edu>\n    http://www-2.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/\n\n\n### Inspiration\n\nThis corpus is used for the [text classification chapter in the NLTK book](http://www.nltk.org/book/ch06.html).'","b""['linguistics', 'small', 'featured']""",https://www.kaggle.com/nltkdata/names
b'Stanford Open Policing Project - Bundle 1',b'Data on Traffic and Pedestrian Stops by Police in many states',"b""###Context: \n\nOn a typical day in the United States, police officers make more than 50,000 traffic stops. The Stanford Open Policing Project team is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public.\n\nIf you'd like to see data regarding other states, please go to https://www.kaggle.com/stanford-open-policing.\n\n### Content: \n\nThis dataset includes stop data from AZ, CO, CT, IA, MA, MD, MI and MO. Please see the data readme for the full details of the available fields.\n\n###Acknowledgements:\n\nThis dataset was kindly made available by the [Stanford Open Policing Project][1]. If you use it for a research publication, please cite their [working paper][2]:\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, V. Ramachandran, C. Phillips, S. Goel. (2017) \xe2\x80\x9cA large-scale analysis of racial disparities in police stops across the United States\xe2\x80\x9d.\n\n###Inspiration: \n\n - How predictable are the stop rates? Are there times and places that\n   reliably generate stops?\n - Concerns have been raised about jurisdictions using civil forfeiture\n   as a funding mechanism rather than to properly fight drug\n   trafficking. Can you identify any jurisdictions that may be\n   exhibiting this behavior?\n\n  [1]: https://openpolicing.stanford.edu/\n  [2]: https://5harad.com/papers/traffic-stops.pdf""","b""['crime', 'law', 'government agencies', 'large', 'featured']""",https://www.kaggle.com/stanford-open-policing/stanford-open-policing-project-bundle-1
b'Finding and Measuring Lungs in CT Data',"b'A collection of CT images, manually segmented lungs and measurements in 2/3D'","b'# Context\n\nCompetitions like LUNA (http://luna16.grand-challenge.org) and the Kaggle Data Science Bowl 2017 (https://www.kaggle.com/c/data-science-bowl-2017) involve processing and trying to find lesions in CT images of the lungs. In order to find disease in these images well, it is important to first find the lungs well. This dataset is a collection of 2D and 3D images with manually segmented lungs.\n\n# Challenge\n\nCome up with an algorithm for accurately segmenting lungs and measuring important clinical parameters (lung volume, PD, etc)\n\n## Percentile Density (PD)\n\nThe PD is the density (in Hounsfield units) the given percentile of pixels fall below in the image. The table includes 5 and 95% for reference. For smokers this value is often high indicating the build up of other things in the lungs.'","b""['image data', 'healthcare', 'medium', 'featured']""",https://www.kaggle.com/kmader/finding-lungs-in-ct-data
b'NYS Current Season Spring Trout Stocking',b'From New York State Open Data',"b""### Content  \n\nDEC stocks more than 2.3 million catchable-size brook, brown, and rainbow trout in over 309 lakes and ponds and roughly 2,900 miles of streams across the state each spring. This dataset represents the planned stocking numbers, species and time of spring for those waters for the current fishing season.  The current stocking data is updated annually in mid-March.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/iU25xH2wEDY) by [Milada Vigerova](https://unsplash.com/@mili_vigerova) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'lakes', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-current-season-spring-trout-stocking
b'Spotify Song Attributes',b'An attempt to build a classifier that can predict whether or not I like a song',"b'### Context\n\nA dataset of 2017 songs with attributes from Spotify\'s API. Each song is labeled ""1"" meaning I like it and ""0"" for songs I don\'t like. I used this to data to see if I could build a classifier that could predict whether or not I would like a song.\n\nI wrote an article about the project I used this data for. It includes code on how to grab this data from the Spotipy API wrapper and the methods behind my modeling.\nhttps://opendatascience.com/blog/a-machine-learning-deep-dive-into-my-spotify-data/\n\n\n### Content\n\nEach row represents a song.\n\nThere are 16 columns. 13 of which are song attributes, one column for song name, one for artist, and a column called ""target"" which is the label for the song.\n\nHere are the 13 track attributes: acousticness, danceability, duration_ms, energy, instrumentalness, key, liveness, loudness, mode, speechiness, tempo, time_signature, valence.\n\nInformation on what those traits mean can be found here: https://developer.spotify.com/web-api/get-audio-features/\n\n\n### Acknowledgements\nI would like to thank Spotify for providing this readily accessible data.\n\n\n### Inspiration\n\nI\'m a music lover who\'s curious about why I love the music that I love.'","b""['small', 'featured']""",https://www.kaggle.com/geomack/spotifyclassification
b'Chicago Primary Care Community Health Centers',b'From City of Chicago Open Data',"b""### Content  \n\nLocations and contact information for Chicago primary care community health clinics (including all federally qualified health centers and similar community health centers that provide primary care and are open to the general community).  Additional information can be found at: http://j.mp/QfZ7SP\n\nCDPH anticipates that this list will be used in the following ways: 1) by residents who are in need of \nassistance in finding a primary care physician and clinic near their homes; 2) by social service and \npublic sector service providers that want to link their consumers to primary care near their homes; 3) \nby health system and public health researchers who are interested in Chicago\xe2\x80\x99s primary care and \nsafety net provider landscape. \n \nClinics were excluded from this list if a) it is not specifically in their mission to care for underserved \npopulations or b) if clinic services are only available to a narrowly defined population. \n \nDisclaimers: This list is intended to be a working document of primary care clinics for underserved \npopulations in Chicago. If you believe an entry on this list to be outdated, misrepresented, or \notherwise in error, please contact healthychicago@cityofchicago.org.  \n\n### Context  \n\nThis is a dataset hosted by the City of Chicago. The city has an open data platform found [here](https://data.cityofchicago.org/) and they update their information according the amount of data that is brought in. Explore the City of Chicago using Kaggle and all of the data sources available through the City of Chicago [organization page](https://www.kaggle.com/chicago)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/_IkrjJCO3gs) by [dylan nolte](https://unsplash.com/@dylan_nolte) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'health', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-primary-care-community-health-centers
b'CT Medical Images',b'CT images from cancer imaging archive with contrast and patient age',"b'# Overview\n\nThe dataset is designed to allow for different methods to be tested for examining the trends in CT image data associated with using contrast and patient age. The basic idea is to identify image textures, statistical patterns and features correlating strongly with these traits and possibly build simple tools for automatically classifying these images when they have been misclassified (or finding outliers which could be suspicious cases, bad measurements, or poorly calibrated machines)\n\n# Data\nThe data are a tiny subset of images from the cancer imaging archive. They consist of the middle slice of all CT images taken where valid age, modality, and contrast tags could be found. This results in 475 series from 69 different patients.\n\nTCIA Archive Link - https://wiki.cancerimagingarchive.net/display/Public/TCGA-LUAD\n\n\n# License\n- http://creativecommons.org/licenses/by/3.0/\n- After the publication embargo period ends these collections are freely available to browse, download, and use for commercial, scientific and educational purposes as outlined in the Creative Commons Attribution 3.0 Unported License. Questions may be directed to help@cancerimagingarchive.net. Please be sure to acknowledge both this data set and TCIA in publications by including the following citations in your work:\n\n# Data Citation\n\n```\nAlbertina, B., Watson, M., Holback, C., Jarosz, R., Kirk, S., Lee, Y., \xe2\x80\xa6 Lemmerman, J. (2016). Radiology Data from The Cancer Genome Atlas Lung Adenocarcinoma [TCGA-LUAD] collection. The Cancer Imaging Archive. http://doi.org/10.7937/K9/TCIA.2016.JGNIHEP5\n```\n\n# TCIA Citation\n\n```\nClark K, Vendt B, Smith K, Freymann J, Kirby J, Koppel P, Moore S, Phillips S, Maffitt D, Pringle M, Tarbox L, Prior F. The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository, Journal of Digital Imaging, Volume 26, Number 6, December, 2013, pp 1045-1057. (paper)\n```'","b""['tutorial', 'image data', 'healthcare', 'medium', 'featured']""",https://www.kaggle.com/kmader/siim-medical-images
b'US Tariff Rates',b'Harmonized Tariff Rates as of July 2017',"b'This dataset includes the applicable tariff rates and statistical categories for all merchandise imported into the United States. It is based on the international Harmonized System, the global system of nomenclature that is used to describe most world trade in goods. \n\nAlthough the USITC publishes and maintains the HTSA in its various forms, Customs and Border Protection is the only agency that can provide legally binding advice or rulings on classification of imports. Contact your nearest Customs office with questions about how potential imports should be classified. For a binding ruling on classification, contact the Bureau of Customs and Border Protection.\n\n### Content\n\nThe csv is a somewhat condensed version of a series of pdf documents. The row by row contents are generally comprehensive, but the pdf chapters often contain general information that is not included here.\n\n### Acknowledgements\n\nThis dataset was made available by [the United States International Trade Commission][1]. You can find the original dataset, updated regularly, [here][2].\n\n\n\n  [1]: https://usitc.gov/\n  [2]: https://hts.usitc.gov/current'","b""['economics', 'small', 'featured']""",https://www.kaggle.com/sohier/us-tariff-rates
b'NYC Filming Permits',b'Information on ~40k Filming Locations',"b'### Context: \nDataset is a list of film and television permits received from the Mayor\'s Office of Media and Entertainment in response to a series of FOIL requests in 2015. The permits stretch from October 2011 through September 2015.\n\n### Content: \n\n\n* `ProjectTitle`: The title of the film/television project.\n* `EventName`: A shorthand name for the specific shoot/event being permitted, e.g. `SunsetPark-010815`.\n* `EventType`: One of the following: `Scouting Permit`, `Rigging Permit`, `Shooting Permit`, `Film Shoot / Production`, `DCAS Prep/Shoot/Wrap Permit`, `Grid Request`, or `Red Carpet Premiere`.  According to the MOME, `Shooting Permit` and `Film Shoot / Production` are interchangeable.\n* `EventStartDate` and `EventEndDate`: The start and end date and time of the permit.\n* `Location`: One or more locations covered by the permit.\n* `Boro`: What borough the listed locations are in.\n* `ProjectId`: An internal identifier.\n* `CategoryName`: `Film` or `Television`.\n* `SubCategoryName`: Includes values such as `Pilot`, `Student Film`, `Variety`, `Reality`, etc. This probably isn\'t a reliable classification for TV shows: it\'s chosen by the permit applicant on the online form and is not vetted by the Mayor\'s Office. It also includes overlapping subcategories. For example, a show could be both a `Morning Show` and a `Talk Show` but would have to choose one or the other.\n* `CompanyName`: The supplied production company name, which can be useful in connecting a working title to an actual film/show.\n\n* The project title is sometimes a variation on the actual title (e.g. `Mozart in the Jungle S1` or `The Wolf of Wall Street ReShoots`) or a working title (e.g. `Untitled Female Buddy Cop Movie` instead of `The Heat`, `St James Place` instead of `Bridge of Spies`).\n* In some cases, the locations listed actually span multiple boroughs, and the `Boro` field only represents the primary borough, or the borough of the first listed location.  In some cases, the `Boro` field is blank.\n* A given shooting permit can have any number of locations listed for a single day.  According to the guidelines, the locations are supposed to be listed in the order they\'re used on that day.  Most locations are either an address or a range of blocks in the format of `STREET 1 between STREET 2 and STREET 3`.\n* Permits are generally required when asserting the exclusive use of city property, like a sidewalk, a street, or a park. A shooting permit on a street doesn\'t necessarily mean there is exterior shooting on the street.  It may just mean, for example, that something is being shot indoors and the crew needs special parking privileges for trucks. See [""When a Permit is Required""](http://www1.nyc.gov/site/mome/permits/when-permit-required.page).\n* Shooting on Department of Citywide Administrative Services (DCAS) property, like in a city courthouse, involves an [additional permitting process](http://www.nyc.gov/html/dcas/html/business/film.shtml).\n* Shooting on MTA property or on state/federal property is subject to a different permitting process.\n* A shooting permit is typically, but not always, for a single day or a single overnight period.\n\n\n\n### Acknowledgements: \nData was FOIL\xe2\x80\x99d by [WNYC Data Journalism team](http://datanews.wnyc.org/) and hosted originally on GitHub [here](https://github.com/datanews/film-permits/blob/master/README.md). Check out these great related resources:\n\n* [General MOME Permit Info](http://www1.nyc.gov/site/mome/permits/permits.page)\n* [The Made in NY Location Library](http://www1.nyc.gov/site/mome/resources/location-library.page)\n* [DCAS Managed Public Buildings](http://www.nyc.gov/html/dcas/html/about/buildings.shtml)\n* [Metrocosm\'s NYC Film Permits Map](http://metrocosm.com/web/film-permits-map-nyc.html)\n* [2015 BCG Report on Media and Entertainment in NYC](http://www1.nyc.gov/assets/mome/pdf/bcg-report-10.15.pdf)\n\n\n### Inspiration: \n* Where do most films occur in the city?\n* When is the most common filming time?\n* Who films the most in the city?\n'","b""['government agencies', 'visual arts', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/nyc-filming-permits
b'Football Events',"b'More than 900,000 events from 9,074 football games across Europe'","b""Context\n-------------\nMost publicly available football (soccer) statistics are limited to aggregated data such as Goals, Shots, Fouls, Cards. When assessing performance or building predictive models, this simple aggregation, without any context, can be misleading. For example, a team that produced 10 shots on target from long range has a lower chance of scoring than a club that produced the same amount of shots from inside the box. However, metrics derived from this simple count of shots will similarly asses the two teams.\n\nA football game generates much more events and it is very important and interesting to take into account the context in which those events were generated. This dataset should keep sports analytics enthusiasts awake for long hours as the number of questions that can be asked is huge.\n\nContent\n-------\nThis dataset is a result of a very tiresome effort of webscraping and integrating different data sources. The central element is the text commentary. All the events were derived by reverse engineering the text commentary, using regex. Using this, I was able to derive 11 types of events, as well as the main player and secondary player involved in those events and many other statistics. In case I've missed extracting some useful information, you are gladly invited to do so and share your findings. The dataset provides a granular view of 9,074 games, totaling 941,009 events from the biggest 5 European football (soccer) leagues: England, Spain, Germany, Italy, France from 2011/2012 season to 2016/2017 season as of 25.01.2017.\nThere are games that have been played during these seasons for which I could not collect detailed data. Overall, over 90% of the played games during these seasons have event data.\n\n\nThe dataset is organized in 3 files:\n\n - **events.csv** contains event data about each game. Text commentary was scraped from: bbc.com, espn.com and onefootball.com\n -   **ginf.csv** - contains metadata and market odds about each game. odds were collected from oddsportal.com\n - **dictionary.txt** contains a dictionary with the textual description of each categorical variable coded with integers\n\n\nPast Research\n-------------\nI have used this data to:\n\n - create predictive models for football games in order to bet on football outcomes.\n - make visualizations about upcoming games\n - build expected goals models and compare players\n\nInspiration\n-----------\nThere are tons of interesting questions a sports enthusiast can answer with this dataset. For example:\n\n - What is the value of a shot? Or what is the probability of a shot being a goal given it's location, shooter, league, assist method, gamestate, number of players on the pitch, time - known as expected goals (xG) models\n - When are teams more likely to score?\n - Which teams are the best or sloppiest at holding the lead?\n - Which teams or players make the best use of set pieces?\n - In which leagues is the referee more likely to give a card?\n - How do players compare when they shoot with their week foot versus strong foot? Or which players are ambidextrous?\n - Identify different styles of plays (shooting from long range vs shooting from the box, crossing the ball vs passing the ball, use of headers)\n - Which teams have a bias for attacking on a particular flank?\n\nAnd many many more...""","b""['association football', 'medium', 'featured']""",https://www.kaggle.com/secareanualin/football-events
"b""Ben Hamner's Tweets""","b""A complete Twitter timeline from Kaggle's CTO""","b""### Context\n\nI was looking for something Ben Hamner, Kaggle's CTO, tweeted a while back and it turned out just using R's `TwitteR` package was easier than scrolling through his timeline. Since I collected all of his tweets, I figured I would share them here as well.\n\n### Content\n\n**What you get**: All of Ben Hamner's tweets current through today (12 December 2017).\n\n**What's inside**: The text from his tweets plus metadata like favorites, retweets, timestamps, etc. You can even see whether or not I've personally `favorited` or `retweeted` his tweets.\n\n### Acknowledgements\n\nThanks to Ben for his insightful tweets! Check out his tweets at [@benhamner on Twitter][1].\n\n\n  [1]: https://twitter.com/benhamner""","b""['internet', 'linguistics', 'twitter', 'small', 'featured']""",https://www.kaggle.com/mrisdal/ben-hamners-tweets
b'Hospital ratings',b'The official dataset used on Medicare.gov for hospital quality comparison',"b'### Context\n\nThis are the official datasets used on the Medicare.gov Hospital Compare Website provided by the Centers for Medicare & Medicaid Services. These data allow you to compare the quality of care at over 4,000 Medicare-certified hospitals across the country.\n\n### Content\n\nDataset fields:\n\n- Provider ID\n- Hospital Name\n- Address\n- City\n- State\n- ZIP Code\n- County Name\n- Phone Number\n- Hospital Type\n- Hospital Ownership\n- Emergency Services\n- Meets criteria for meaningful use of EHRs\n- Hospital overall rating\n- Hospital overall rating footnote\n- Mortality national comparison\n- Mortality national comparison footnote\n- Safety of care national comparison\n- Safety of care national comparison footnote\n- Readmission national comparison\n- Readmission national comparison footnote\n- Patient experience national comparison\n- Patient experience national comparison footnote\n- Effectiveness of care national comparison\n- Effectiveness of care national comparison footnote\n- Timeliness of care national comparison\n- Timeliness of care national comparison footnote\n- Efficient use of medical imaging national comparison\n- Efficient use of medical imaging national comparison\n\n### Acknowledgements\n\nDataset was downloaded from [https://data.medicare.gov/data/hospital-compare]\n\n\n### Inspiration\n\nIf you just broke your leg, you might need to use this dataset to find the best Hospital to get that fixed!'","b""['health', 'public health', 'hospitals', 'small', 'featured']""",https://www.kaggle.com/center-for-medicare-and-medicaid/hospital-ratings
b'NY Daily Report Of Single Adult And Family Intake',b'From New York City Open Data',"b""### Content  \n\nDaily report of how many Single Adults and Families are served  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/z9Z122x5hB8) by [Jelleke Vanooteghem](https://unsplash.com/@ilumire) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'family', 'small', 'featured']""",https://www.kaggle.com/new-york-city/ny-daily-report-of-single-adult-and-family-intake
b'LEGO Database',b'The LEGO Parts/Sets/Colors and Inventories of every official LEGO set',"b'### Context: \nLEGO is a popular brand of toy building bricks. They are often sold in sets with in order to build a specific object. Each set contains a number of parts in different shapes, sizes and colors. This database contains information on which parts are included in different LEGO sets. It was originally compiled to help people who owned some LEGO sets already figure out what other sets they could build with the pieces they had.\n\n### Content:\nThis dataset contains the LEGO Parts/Sets/Colors and Inventories of every official LEGO set in the Rebrickable database. These files are current as of July 2017. If you need it to be more recent data, you can use Rebrickable\xe2\x80\x99s [API][1] which provides up to date data, and additional features.\n\n### Acknowledgements: \nThis dataset was compiled by [Rebrickable][2], which is a website to help identify what  LEGO sets can be built given bricks and pieces from other LEGO sets. You can use these files for any purpose. \n\n### Inspiration:\nThis is a very rich dataset that offers lots of rooms for exploration, especially since the \xe2\x80\x9csets\xe2\x80\x9d file includes the year in which a set was first released. \n\n* How have the size of sets changed over time?\n* What colors are associated with witch themes? Could you predict which theme a set is from just by the bricks it contains?\n* What sets have the most-used pieces in them? What sets have the rarest pieces in them?\n* Have the colors of LEGOs included in sets changed over time?\n\n\n  [1]: https://rebrickable.com/api/\n  [2]: https://rebrickable.com/about/'","b""['games and toys', 'product', 'supply chain', 'medium', 'featured']""",https://www.kaggle.com/rtatman/lego-database
b'NYC ACRIS Codes',b'From New York City Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-acris-codes
b'World Factbook Country Profiles',b'Textual profiles describing every country in the world',"b'### Context\n\nThis dataset is a snapshot of all of the country profiles provided in the World Factbook as of early 2017. The World Factbook is a reference almanac published by the United States Central Intelligence Agency on a continual basis. It is often used as a reference text in other academic works.\n\n### Content\n\nThis dataset includes high-level textual information on the economy, politics, demography, culture, military, and society of every country in the world.\n\n### Acknowledgements\n\nThis data was scraped [here](https://github.com/opendatajson/factbook.json), then concatenated into a single entity before upload to Kaggle.\n\n### Inspiration\n\nThis dataset is an ideal basis of comparison for various world countries.\n\nAnalyzing international data? This dataset is a rich mix-in dataset for contextualizing such analyses.'","b""['economics', 'demographics', 'politics', 'military', 'small', 'featured']""",https://www.kaggle.com/usdod/world-factbook-country-profiles
b'Stanford Open Policing Project - Texas',b'Data on Traffic and Pedestrian Stops by Police in Texas',"b""###Context: \n\nOn a typical day in the United States, police officers make more than 50,000 traffic stops. The Stanford Open Policing Project team is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public.\n\nIf you'd like to see data regarding other states, please go to https://www.kaggle.com/stanford-open-policing.\n\n### Content: \n\nThis dataset includes over 2 gb of stop data from Texas, covering all of 2010 onwards. Please see the data readme for the full details of the available fields.\n\n###Acknowledgements:\n\nThis dataset was kindly made available by the [Stanford Open Policing Project][1]. If you use it for a research publication, please cite their [working paper][2]:\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, V. Ramachandran, C. Phillips, S. Goel. (2017) \xe2\x80\x9cA large-scale analysis of racial disparities in police stops across the United States\xe2\x80\x9d.\n\n###Inspiration: \n\n - How predictable are the stop rates? Are there times and places that\n   reliably generate stops?\n - Concerns have been raised about jurisdictions using civil forfeiture\n   as a funding mechanism rather than to properly fight drug\n   trafficking. Can you identify any jurisdictions that may be\n   exhibiting this behavior?\n\n  [1]: https://openpolicing.stanford.edu/\n  [2]: https://5harad.com/papers/traffic-stops.pdf""","b""['crime', 'law', 'government agencies', 'large', 'featured']""",https://www.kaggle.com/stanford-open-policing/stanford-open-policing-project-texas
"b'USA Income Tax Data by ZIP Code, 2014'",b'Distribution of income for 6 earning brackets',"b'The Statistics of Income (SOI) division bases its ZIP code data on administrative records of individual income tax returns (Forms 1040) from the Internal Revenue Service (IRS) Individual Master File (IMF) system. Included in these data are returns filed during the 12-month period, January 1, 2015 to December 31, 2015. While the bulk of returns filed during the 12-month period are primarily for Tax Year 2014, the IRS received a limited number of returns for tax years before 2014 and these have been included within the ZIP code data.\n\nThere is data for more years here:\n\nhttps://www.irs.gov/uac/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi\n\nSee documentation file attached. Crucially:\n\n  ZIPCODE - 5-digit Zip code\n\xc2\xa0\n \n  AGI_STUB - Size of adjusted gross income\n\n1 = $1 under $25,000\n2 = $25,000 under $50,000\n3 = $50,000 under $75,000\n4 = $75,000 under $100,000\n5 = $100,000 under $200,000\n6 = $200,000 or more'","b""['demographics', 'geography', 'income', 'medium', 'featured']""",https://www.kaggle.com/wpncrh/zip-code-income-tax-data-2014
b'NYS SNAP Caseloads and Expenditures',b'From New York State Open Data',"b""### Content  \n\nThese data are monthly listings of households, recipients and expenditures for the Supplemental Nutrition Assistance Program.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/vYMRkFYQq-M) by [Gabriel Ghnassia](https://unsplash.com/@gabrielghnassia) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-snap-caseloads-and-expenditures
b'New York City - Certificates of Occupancy',b'New and newly reconstructed buildings in New York City.',"b'### Context: \nThe City of New York issues Certificates of Occupancy to newly constructed (and newly reconstructed, e.g. \xe2\x80\x9cgut renovated\xe2\x80\x9d) buildings in New York City. These documents assert that the city has deemed the building habitable and safe to move into.\n\n### Content: \nThis dataset includes all temporary (expirable) and final (permanent) Certificates of Occupancies issues to newly habitable buildings in New York City, split between new (Job Type: NB) and reconstructed (Job Type: A1) buildings, issued between July 12, 2012 and August 29, 2017.\n\n### Acknowledgements: \nThis data is published as-is by the New York City Department of Buildings.\n\n### Inspiration: \n* In what areas of New York City are the newly constructed buildings concentrated?\n* What is the difference in distribution between buildings that are newly built and ones that are newly rebuilt?\n* In combination with the [New York City Buildings Database](https://www.kaggle.com/new-york-city/nyc-buildings/) dataset, what are notable differences in physical characteristics between recently constructed buildings and existing ones?'","b""['cities', 'civil engineering', 'medium', 'featured']""",https://www.kaggle.com/new-york-city/nyc-certificates-of-occupancy
b'Korean War Bombing Runs',b'Details on 12.8k Bombing Runs',"b""### Context: \nTHOR is a painstakingly cultivated database of historic aerial bombings from World War I through Vietnam. THOR has already proven useful in finding unexploded ordinance in Southeast Asia and improving Air Force combat tactics. Our goal is to see where public discourse and innovation takes this data.  Each theater of warfare has a separate data file, in addition to a [THOR Overview](http://www.data.mil/s/v2/data-stories-an-overview-of-thor/a100cd16-c2a7-453b-8ea6-45947c1bbc51/).\n\n\n### Content: \nBy June 1950, the U.S. Air Force had constructed a comprehensive historical program.  Over half the records in the Air Force Historical Archives consisted of World War II artifacts, including unit histories and combat reports compiled by field historians as they received a steady flow of documents from operational squadrons and wings.  The archives team developed experience pouring through intelligence reports, target folders, bomb damage assessments, and statistics to develop hard earned lessons on modern warfare. \nSo from the first day of combat, 25 June, historians embedded within operational commands in Korea knew recording events from the start would be important. In particular, Albert F. Simpson, the Archives' Director, picked up the phone and directly called the headquarters of the Far East Air Forces (FEAF) to request they begin collecting data on all sorties generated in theater.  Their statistical services agreed, and began regularly sending typed reports on 20 essential data items:\n\n* Group and Squadron designations\n* Operating base location\n* Type and model of aircraft\n* Aborted, airborne, and effective sorties\n* Number of aircraft lost or damaged to enemy ground, aircraft, or other action\n* Personnel Killed, Wounded, or Missing in Action\n* Number of enemy aircraft destroyed or damaged\n* Number of bombs, rockets, and bullets expended\n\nRead more [here](https://insight.livestories.com/s/v2/thor-korea/ff390af4-7ee7-4742-a404-2c3490f6ed96/) on the Exteter database and consult the data dictionary [here](https://www.dds.mil/data/thor_data_dictionary_2016.pdf).\n\n### Acknowledgements: \nTHOR is a dataset project initiated by  Lt Col Jenns Robertson and continued in partnership with Data.mil,  an experimental project, created by the [Defense Digital Service](https://www.dds.mil/) in collaboration with the [Deputy Chief Management Officer]( http://dcmo.defense.gov/) and data owners throughout the U.S. military. \n\n### Inspiration: \n* Which campaigns saw the heaviest bombings?\n* Which months saw the most runs?\n""","b""['war', 'military', 'small', 'featured']""",https://www.kaggle.com/usaf/korean-war-bombing-runs
b'Board Games Dataset',b'What makes a game a good game?',"b'# About\nA dataset containing the attributes and the ratings for around 94,000 among board games and expansions as get from [BoardGameGeek][1].\n\n# Resources\nThe same data and the scripts used to crawl it from BoardGameGeek are available in the form of [R package][2] on [Github][3].\n\n\n  [1]: https://www.boardgamegeek.com\n  [2]: https://github.com/9thcirclegames/bgg-analysis\n  [3]: https://github.com'","b""['board games', 'medium', 'featured']""",https://www.kaggle.com/gabrio/board-games-dataset
b'Melbourne Housing Market',b'Melbourne housing clearance data from Jan 2016',"b""##Update 06/08/2018 - Well it finally happened, Melbourne housing has cooled off. So here's your challenge; 1) when did it exactly happen? , 2) Could you see it slowing down? What were the variables that showed the slowing down (was it overall price, amount sold vs unsold, change in more rentals sold and less housing, changes in which CouncilArea or Region, more houses sold in distances further away from Melbourne CBD and less closer)? 3) Could you have predicted it (I'm not sure how you would do this, but I'm sure you magicians have a way that would make me think we should burn you for being a witch) 4) Should I hold off even longer in buying a two bedroom apartment in Northcote? &lt;-- This is the real reason for me in publishing this dataset :)\n\n####  Update 22/05/2018 - Will continue with a smaller subset of the data (not as many columns). The web scraping was taking some time and also may potentially cause problems. Will continue to post the data.\n\n\n#### Update 28/11/2017 - Last few weeks clearance levels starting to decrease (I may just be seeing a pattern I want to see.. maybe I'm just evil). Anyway, can any of you magicians make any sense of it?\n\n\nMelbourne is currently experiencing a housing bubble (some experts say it may burst soon). Maybe someone can find a trend or give a prediction? Which suburbs are the best to buy in? Which ones are value for money? Where's the expensive side of town? And more importantly where should I buy a 2 bedroom unit?\n\n## Content & Acknowledgements\n\nThis data was scraped from publicly available results posted every week from Domain.com.au, I've cleaned it as best I can, now it's up to you to make data analysis magic. The dataset includes Address, Type of Real estate, Suburb, Method of Selling, Rooms, Price, Real Estate Agent, Date of Sale and distance from C.B.D.\n\n....Now with extra data including including property size, land size and council area, you may need to change your code!\n\n## Some Key Details\n\n**Suburb**: Suburb\n\n**Address**: Address\n\n**Rooms**: Number of rooms\n\n**Price**: Price in Australian dollars\n\n**Method**: \n              S - property sold; \n              SP - property sold prior; \n              PI - property passed in; \n              PN - sold prior not disclosed; \n              SN - sold not disclosed; \n              NB - no bid; \n              VB - vendor bid; \n               W - withdrawn prior to auction; \n               SA - sold after auction; \n               SS - sold after auction price not disclosed. \n               N/A - price or highest bid not available. \n\n**Type**:\n        br - bedroom(s); \n        h - house,cottage,villa, semi,terrace; \n        u - unit, duplex;\n        t - townhouse; \n        dev site - development site; \n        o res - other residential.\n\n**SellerG**: Real Estate Agent\n\n**Date**: Date sold\n\n**Distance**: Distance from CBD in Kilometres\n\n**Regionname**: General Region (West, North West, North, North east ...etc) \n\n**Propertycount**: Number of properties that exist in the suburb.\n\n**Bedroom2** : Scraped # of Bedrooms (from different source)\n\n**Bathroom**: Number of Bathrooms\t\n\n**Car**: Number of carspots\t\n\n**Landsize**: Land Size in Metres\n\n**BuildingArea**: Building Size\tin Metres\n\n**YearBuilt**: Year the house was built\t\n\n**CouncilArea**: Governing council for the area\t\n\nLattitude: Self explanitory\t\n\nLongtitude: Self explanitory""","b""['demographics', 'housing', 'small', 'featured']""",https://www.kaggle.com/anthonypino/melbourne-housing-market
b'Congressional Voting Records',b'All roll call votes made by the United States Congress 1789-2017',"b""DW-Nominate scores of congressional voting behavior regularly appears in media such as the [New York Times][1], [Washington Post][2], and [538][3]. This dataset contains the voting records used to generate those scores and additional features related to the DW-NOMINATE calculations.\n\n### Content\n\nThis dataset contains descriptive data as well as ideological data for congressional rollcalls, individual member votes, members of congress, and parties. You can find information such the descriptions of rollcalls, what proportion of voting members were correctly classified by the ideological cutting line for that rollcall, the ideological position of members of congress, and more.\n\nBoth the rollcall data and the data on members are split into chambers and congresses. The data on parties is a dataset with some metadata about all of the different parties as well as their average ideological position and membership size broken down by congress and chamber.\n\nThe full details behind the DW-NOMINATE calculations may be helpful in interpreting some of this data. The technical details of the DW-NOMINATE model can be found in Poole's Spatial Models of Parliamentary Voting. Poole and Rosenthal's Ideology and Congress explores the nature of voting in Congress and the political history of the United States through the lens of the ideological dimensions recovered by DW-NOMINATE.\n\n### Acknowledgements\n\nThis dataset was prepared by the team at [VoteView][4]. Please visit their site if you require up-to-date records. You may also be interested in [their blog][5].\n\n### Inspiration\n-Using national scores as a training set, can you develop polarization scores for you own state legislature?\n-Can you find correlates that help explain changes in DW-NOMINATE scores?\n\n\n  [1]: https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=newssearch&cd=2&cad=rja&uact=8&ved=0ahUKEwiIrsTXv83VAhVM2mMKHZaPAGQQqQIIKigAMAE&url=https%3A%2F%2Fwww.nytimes.com%2Finteractive%2F2017%2F07%2F13%2Fus%2Fpolitics%2Fsenate-revised-health-care-whip-count.html&usg=AFQjCNHrJZefX1YKXBvV2qFvTmcoK2HOfg\n  [2]: https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=newssearch&cd=2&cad=rja&uact=8&ved=0ahUKEwj37J6SwM3VAhUD0mMKHbCNAt8QqQIIKygAMAE&url=https%3A%2F%2Fwww.washingtonpost.com%2Fgraphics%2Fpolitics%2Fendangered-seats%2F&usg=AFQjCNFl_hrXqN7RWbTcMVg1f-YWqyuV3A\n  [3]: https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=newssearch&cd=1&cad=rja&uact=8&ved=0ahUKEwiIrsTXv83VAhVM2mMKHZaPAGQQqQIIJygAMAA&url=https%3A%2F%2Ffivethirtyeight.com%2Ffeatures%2Frepublican-senators-arent-embracing-trumps-transgender-military-ban%2F&usg=AFQjCNGW9fpdRKl-EoND8a1qmLOoGp24BQ\n  [4]: https://voteview.com/data\n  [5]: https://voteviewblog.com/""","b""['politics', 'history', 'government', 'medium', 'featured']""",https://www.kaggle.com/voteview/congressional-voting-records
b'Poems from poetryfoundation.org',b'Modern and Renaissance poetry for classification exercises',b'### Context\nStudy for poem classification. Trying to classified poems with targets age and type. \nI use two Xgboost predictors to predict target and type separately.     \n\n\n### Content\n\nPlease refer to the website https://www.poetryfoundation.org/\nFor now I only crawl the data of \n\n - renaissance love\n - modern love \n - renaissance nature\n - modern nature\n - renaissance  mythology & folklore\n - modern  mythology & folklore\n\n\nSome have copyrights. I only use for studying :)\n### Acknowledgements\n\nhttps://www.poetryfoundation.org/ has the copyright \n\n### Inspiration\n\nclassification is fun!!',"b""['linguistics', 'poetry', 'small', 'featured']""",https://www.kaggle.com/ultrajack/modern-renaissance-poetry
b'New York City Census Data',"b'Demographic, Economic, and Location Data for Census Tracts in NYC'","b'### Context\n\nThere are a number of Kaggle datasets that provide spatial data around New York City. For many of these, it may be quite interesting to relate the data to the demographic and economic characteristics of nearby neighborhoods. I hope this data set will allow for making these comparisons without too much difficulty.\n\nExploring the data and making maps could be quite interesting as well.\n\n### Content\n\nThis dataset contains two CSV files:\n\n1. nyc_census_tracts.csv\n\n  This file contains a selection of census data taken from the ACS DP03 and DP05 tables. Things like total population, \n  racial/ethnic demographic information, employment and commuting characteristics, and more are contained here. There is a \n  great deal of additional data in the raw tables retrieved from the US Census Bureau website, so I could easily add more fields if \n  there is enough interest.\n\n  I obtained data for individual census tracts, which typically contain several thousand residents. \n\n2. census_block_loc.csv\n\n  For this file, I used an online FCC census block lookup tool to retrieve the census block code for a 200 x 200 grid containing \n  New York City and a bit of the surrounding area. This file contains the coordinates and associated census block codes along  \n  with the state and county names to make things a bit more readable to users.\n\n  Each census tract is split into a number of blocks, so one must extract the census tract code from the block code.\n\n### Acknowledgements\n\nThe data here was taken from the American Community Survey 2015 5-year estimates (https://factfinder.census.gov/faces/nav/jsf/pages/index.xhtml).\n\nThe census block coordinate data was taken from the FCC Census Block Conversions API (https://www.fcc.gov/general/census-block-conversions-api)\n\nAs public data from the US government, this is not subject to copyright within the US and should be considered public domain.'","b""['demographics', 'united states', 'small', 'featured']""",https://www.kaggle.com/muonneutrino/new-york-city-census-data
b'US Household Income Statistics',"b'+32,000 records, with grandularity on a neighborhood scale (mean, median, Stdev)'","b""### New Upload:\nAdded +32,000 more locations. For information on data calculations please refer to the methodology pdf document. Information on how to calculate the data your self is also provided as well as how to buy data for $1.29 dollars.\n\n### What you get:\nThe database contains 32,000 records on US Household Income Statistics & Geo Locations. The field description of the database is documented in the attached pdf file. **To access, all 348,893 records on a scale roughly equivalent to a neighborhood (census tract) see link below** and *make sure to up vote*. Up vote right now, please. *Enjoy*!\n\n\n###Household & Geographic Statistics:\n\n\n - Mean Household Income (double)\n - Median Household Income (double)\n - Standard Deviation of Household Income (double)\n - Number of Households (double) \n - Square area of land at location (double) \n - Square area of water at location (double) \n\n\n###Geographic Location:\n\n - Longitude (double)\n - Latitude (double)\n - State Name (character)\n - State abbreviated (character) \n - State_Code (character) \n - County Name (character)\n - City Name (character)\n - Name of city, town, village or CPD  (character)\n - Primary, Defines if the location is a track and block group.\n - Zip Code (character)\n - Area Code (character)                      \n\n\n### Abstract\nThe dataset originally developed for real estate and business investment research. Income is a vital element when determining both quality and socioeconomic features of a given geographic location. The following data was derived from over **+36,000 files** and covers 348,893 location records.\n\n### License\nOnly proper citing is required please see the documentation for details.\nHave Fun!!!\n\nGolden Oak Research Group, LLC. \xe2\x80\x9cU.S. Income Database Kaggle\xe2\x80\x9d. Publication: 5, August 2017. Accessed, day, month year.\n\n### Sources, don't have 2 dollars? Get the full information yourself!\n2011-2015 ACS 5-Year Documentation was provided by the U.S. Census Reports. Retrieved August 2, 2017, from https://www2.census.gov/programs-surveys/acs/summary_file/2015/data/5_year_by_state/\n\n###Found Errors?\nPlease tell us so we may provide you the most accurate data possible. You may reach us at:  research_development@goldenoakresearch.com \n\nfor any questions you can reach me on at 585-626-2965\n\n\n*please note: it is my personal number and email is preferred*\n\nCheck our data's accuracy:\n[Census Fact Checker][1]\n\n\n###Access all 348,893 location records and more:\n**Don't settle. Go big and win big.  Optimize your potential. Overcome limitation and outperform expectation**. *Access all household income records on a scale roughly equivalent to a neighborhood, see link below*:\n\n\n*Website*: [Golden Oak Research][2] *Kaggle Deals all databases $1.29 Limited time only*\n\n\nA small startup with big dreams, giving the every day, up and coming data scientist professional grade data at affordable prices It's what we do. \n\n  [1]: https://factfinder.census.gov/\n  [2]:https://www.goldenoakresearch.com/shop/""","b""['finance', 'demographics', 'geography', 'real estate', 'income', 'small', 'featured']""",https://www.kaggle.com/goldenoakresearch/us-household-income-stats-geo-locations
b'Diamonds',"b'Analyze diamonds by their cut, color, clarity, price, and other attributes'","b""### Context \n\nThis classic dataset contains the prices and other attributes of almost 54,000 diamonds. It's a great dataset for beginners learning to work with data analysis and visualization.\n\n### Content\n\n**price** price in US dollars (\\$326--\\$18,823)\n\n**carat** weight of the diamond (0.2--5.01)\n\n**cut** quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n\n**color** diamond colour, from J (worst) to D (best)\n\n**clarity** a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n\n**x** length in mm (0--10.74)\n\n**y** width in mm (0--58.9)\n\n**z** depth in mm (0--31.8)\n\n**depth** total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n\n**table** width of top of diamond relative to widest point (43--95)""","b""['finance', 'clothing', 'small', 'featured']""",https://www.kaggle.com/shivam2503/diamonds
b'New York City REACH Members',b'From New York City Open Data',"b""### Content  \n\nThe location and facility information for doctors who participate in NYC Regional Electronic Adoption Center for Health (REACH), which assists providers in adopting technology and methods for electronic health records.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated quarterly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/52p1K0d0euM) by [Austris Augusts](https://unsplash.com/@biosss91) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'health', 'small', 'featured']""",https://www.kaggle.com/new-york-city/new-york-city-reach-members
b'Open Flood Risk by Postcode',b'English postcodes with Environment Agency flood risk',"b""# Context \n\nThis dataset takes the Environment Agency's [Risk of Flooding from Rivers and Sea][1], and places English postcodes in their appropriate flood risk area, allowing you to look up flood risk from postcode.\n\n# Content\n\nRisk of Flooding from Rivers and Sea consists of geographical areas within England which are at risk of flooding from rivers and sea. Each area is assigned a flood risk within a banding:\n\n - High\n - Medium\n - Low\n - Very low\n - None\n\nOpen Flood Risk by Postcode takes postcodes as point locations (from [Open Postcode Geo][2]) and places the postcode in the appropriate flood risk area. It is important to note that actual properties within a specific postcode may have a slightly different point location and therefore be in a different flood risk area. Generally speaking the point location of a postcode is the point location of the central property in that postcode.\n\nFor a full field list and explanations of values see the [Open Flood Risk by Postcode documentation][3].\n\n# Acknowledgements\n\nOpen Flood Risk by Postcode is derived from two open datasets:\n\n - [Risk of Flooding from Rivers and Sea][4]\n - [Open Postcode Geo][5]\n\nBoth of these datasets are licensed under the [OGL][6].\n\nThe following attribution statements are required:\n\n - Contains OS data \xc2\xa9 Crown copyright and database right 2017\n - Contains Royal Mail data \xc2\xa9 Royal Mail copyright and database right 2017\n - Contains National Statistics data \xc2\xa9 Crown copyright and database right 2017\n - Contains Environment Agency data licensed under the Open Government Licence v3.0.\n\nThe dataset is maintained by [GetTheData][7].\n\nThe latest version and full documentation is available [here][8].\n\n# Inspiration\n\nExample application:\n\nLookup or drill down to individual English postcodes to see a map of that postcode and its flood risk, alongside surrounding postcodes and their flood risks:\n\n- Application: [Flood Map by Postcode][9]\n- Example postcode: [RG9 2LP][10]\n\n\n  [1]: https://data.gov.uk/dataset/risk-of-flooding-from-rivers-and-sea1\n  [2]: https://www.getthedata.com/open-postcode-geo\n  [3]: https://www.getthedata.com/open-flood-risk-by-postcode\n  [4]: https://data.gov.uk/dataset/risk-of-flooding-from-rivers-and-sea1\n  [5]: https://www.getthedata.com/open-postcode-geo\n  [6]: http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/\n  [7]: https://www.getthedata.com\n  [8]: https://www.getthedata.com/open-flood-risk-by-postcode\n  [9]: https://www.getthedata.com/flood-map-by-postcode\n  [10]: https://www.getthedata.com/flood-map/RG9-2LP""","b""['geography', 'medium', 'featured']""",https://www.kaggle.com/getthedata/open-flood-risk-by-postcode
"b'Consumer Price Index in Denver, CO'",b'104 years of monthly CPI data',"b'### Context: \nThe Consumer Price Indexes (CPI) program produces monthly data on changes in the prices paid by urban consumers for a representative basket of goods and services. It is a useful way to compare changes in the economy across time.\n\n### Content: \nThis data covers Jan 1913-May 2017, and is normalized to \xe2\x80\x9cCPI-U all items 1982-84=100, not seasonally adjusted\xe2\x80\x9d. Fields include time of measurement and CPI score.\n\n### Acknowledgements: \nThis dataset was compiled on behalf of the Bureau of Labor Statistics (BLS) via Colorado Department of Labor & Employment (CDLE) and hosted on [data.colorado.gov](https://data.colorado.gov/Business/Consumer-Price-Index-in-Denver/bynd-i2hj).\n\n\n### Inspiration: \n* What periods of time have seen the highest/lowest CPI? \n* When has inflation been the worse?\n* Can you predict present CPI?'","b""['economics', 'small', 'featured']""",https://www.kaggle.com/bls/denver-cpi
"b'US Unemployment Rate by County, 1990-2016'","b""Thanks to the US Department of Labor's Bureau of Labor Statistics""","b""# Context \n\nThis is a dataset that I built by scraping the United States Department of Labor's Bureau of Labor Statistics. I was looking for county-level unemployment data and realized that there was a data source for this, but the data set itself hadn't existed yet, so I decided to write a scraper and build it out myself.\n\n\n# Content\n\nThis data represents the Local Area Unemployment Statistics from 1990-2016, broken down by state and month. The data itself is pulled from this mapping site:\n\nhttps://data.bls.gov/map/MapToolServlet?survey=la&map=county&seasonal=u\n\nFurther, the ever-evolving and ever-improving codebase that pulled this data is available here:\n\nhttps://github.com/jayrav13/bls_local_area_unemployment\n\n\n# Acknowledgements\n\nOf course, a huge shoutout to bls.gov and their open and transparent data. I've certainly been inspired to dive into US-related data recently and having this data open further enables my curiosities.\n\n# Inspiration\n\nI was excited about building this data set out because I was pretty sure something similar didn't exist - curious to see what folks can do with it once they run with it! A curious question I had was surrounding Unemployment vs 2016 Presidential Election outcome down to the county level. A comparison can probably lead to interesting questions and discoveries such as trends in local elections that led to their most recent election outcome, etc.\n\n# Next Steps\n\nVersion 1 of this is as a massive JSON blob, normalized by year / month / state. I intend to transform this into a CSV in the future as well.""","b""['employment', 'medium', 'featured']""",https://www.kaggle.com/jayrav13/unemployment-by-county-us
b'Exoplanet Hunting in Deep Space',b'Kepler labelled time series data',"b""***The Search for New Earths***\n-------------------------\n\n[GitHub](https://github.com/winterdelta/keplersmachines)\n\nThe data describe the change in flux (light intensity) of several thousand stars. Each star has a binary label of `2` or `1`. 2 indicated that that the star is confirmed to have at least one exoplanet in orbit; some observations are in fact multi-planet systems.\n\nAs you can imagine, planets themselves do not emit light, but the stars that they orbit do. If said star is watched over several months or years, there may be a regular 'dimming' of the flux (the light intensity). This is evidence that there may be an orbiting body around the star; such a star could be considered to be a 'candidate' system. Further study of our candidate system, for example by a satellite that captures light at a different wavelength, could solidify the belief that the candidate can in fact be 'confirmed'.\n\n![Flux Diagram][1]\n\nIn the above diagram, a star is orbited by a blue planet. At t = 1, the starlight intensity drops because it is partially obscured by the planet, given our position. The starlight rises back to its original value at t = 2. The graph in each box shows the measured flux (light intensity) at each time interval.\n\n----------\n\n# Description \n\n\nTrainset:\n\n * 5087 rows or observations.\n * 3198 columns or features.\n * Column 1 is the label vector. Columns 2 - 3198 are the flux values over time.\n * **37** confirmed exoplanet-stars and 5050 non-exoplanet-stars.\n\nTestset:\n\n * 570 rows or observations.\n * 3198 columns or features.\n * Column 1 is the label vector. Columns 2 - 3198 are the flux values over time.\n * **5** confirmed exoplanet-stars and 565 non-exoplanet-stars.\n\n# Acknowledgements\n\nThe data presented here are cleaned and are derived from observations made by the NASA Kepler space telescope. The Mission is ongoing - for instance data from Campaign 12 was released on 8th March 2017. Over 99% of this dataset originates from **Campaign 3**. To boost the number of exoplanet-stars in the dataset, confirmed exoplanets from other campaigns were also included.\n\nTo be clear, all observations from Campaign 3 are included. And in addition to this, confirmed exoplanet-stars from other campaigns are also included.\n\nThe datasets were prepared late-summer 2016.\n\nCampaign 3 was used because 'it was felt' that this Campaign is unlikely to contain any undiscovered (i.e. wrongly labelled) exoplanets.\n\nNASA open-sources the original Kepler Mission data and it is hosted at the [Mikulski Archive][2]. After being beamed down to Earth, NASA applies de-noising algorithms to remove artefacts generated by the telescope. The data - in the `.fits` format - is stored online. And with the help of a seasoned astrophysicist, anyone with an internet connection can embark on a search to find and retrieve the datafiles from the Archive.\n\nThe cover image is copyright \xc2\xa9 2011 by [Dan Lessmann][3]\n\n\n  [1]: https://cdn.pbrd.co/images/5g0jyccQF.png\n  [2]: https://archive.stsci.edu/k2/\n  [3]: http://www.danlessmann.com/AstroPages/1astrogallery.htm""","b""['astronomy', 'space', 'medium', 'featured']""",https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data
b'Nineteenth Century Works On Nepal',b'For a quick viewing of how they portrayed the country in words and sentiments',"b'### Context\n\nThese 19th century works on Nepal were downloaded from Project Gutenberg for a quick viewing of how the line graphs of their page-by-page sentiment compared with one another in applying the the text mining, analysis and visualization capabilities of R, inspired by the work on janeaustenr or gutenbergr.    \n\n\n### Content\n\nThe books and collection of journals on Nepal of about 200 years ago are in text files. \n\n\n### Acknowledgements\n\nThese works have been available in machine readable format thanks to Project Gutenberg.\n\n\n### Inspiration\n\nAlthough the volumes of books and journals are growing in the online repositories of Project Gutenberg, only a few works in English are about Nepal. How are their portrayals of Nepal similar or different in word-clouds and sentiments? Which R packages can be useful to make these comparisons?'","b""['linguistics', 'languages', 'small', 'featured']""",https://www.kaggle.com/blogdish/nineteenth-century-works-on-nepal
b'What is a note?',b'A collection of notes played on a guitar',"b'**Overview**\n\nWe could take a music theory class to understand *what* a note is, but why don\'t we just find out for ourselves? In this data set we have the notes on a guitar on open strings, and on the 1st-8th frets on every string. The notes were recorded on a nice but low-end guitar called the Yamaha C-40.  The guitar is in standard tuning (from the top string to the bottom on we have E low, A, D, G, B, E high).\n\n**What to do with this dataset**\n\nI didn\'t label any notes (except the open ones - an open A string is an A). If you want a challenge you can cluster the notes and see if your clustering lumps all the same notes together. If you want labels so you can do some inspection of notes that are the same you can look on google for a guitar fretboard diagram. I have done both of these experiments and learned a bit about music which I \'m hoping to verify soon when I find a good music theory book.\n\nThis data set might be interesting to use to be able to write sheet music from an audio sample of some finger-picked music. Identifying chords is a difficult computational task, but finger-style guitar, with clear, individual notes, might be easier. If this is the case, a simple script could be written to write sheet music from an audio sample.\n\nOne draw back about the data set is that some non-plucked strings were vibrating when I played a note. I tried various techniques to muffle them, but there is still some noise in the background. I don\'t know if this is because of my technique or something that happens to all players on all guitars. In any event, this noise didn\'t hurt my analysis.\n\n**About the data**\n\nThey were recorded by me, Melvyn, using a program called audacity.\n\nThere is a directory with the name of the string. Inside the directory you will find .wav files named either open, 1, 2, ....8 for the fingering of the string. There is also a directory called ""scale"" I recorded some notes that make a ""do-re-mi..."" scale. You can use these for a number of things.\n\nI use the GuitarTuner app to tune the Guitar - I\'m just learning so I don\'t have an ear for notes yet. After some initial analysis it looks like the guitar might be a bit out of tune, so the resonant frequencies are a bit off from what they should be. Another thing that is interesting to think about it is how far a frequency must be from the proper on until it becomes distinguishable as a different note.'","b""['music', 'medium', 'featured']""",https://www.kaggle.com/juliancienfuegos/what-is-a-note
b'MEDLINE  and MeSH',b'Biomedical bibliometric data and paper classification',"b'### Content and Context\n\nThis dataset is a collection of  biomedicine and life science bibliometric data obtained from [MEDLINE](https://www.nlm.nih.gov/pubs/factsheets/medline.html).\n\nThe data covers 26,759,425 papers available thought MEDLINE from 1946 through 2016.\n\nThis dataset has been created by processing the  publicly available data dump at [nih.gov](ftp://ftp.ncbi.nlm.nih.gov/pub/).\nThe data dump consists of ca 23 Million `xml` articles. From these `xml` files I have extracted some meta data into more accessible `csv` files.\nThe processed `csv`s contain both very basic metadata (i.e. creation date, number of authors, and ids) and the ""Medical Subject Headings"" [MeSH](https://www.nlm.nih.gov/pubs/factsheets/mesh.html) classification.\n\nThe dataset is divided in two files, \n\n 1. `paper_details.csv`\n 2. `mesh.csv`\n\nThe `paper_details.csv` file contains the following columns:\n\n - pmid: this is the unique article identified within the dataset, it is also the official identifier used on PubMed\n - doi: digital object identifier, this id allows to uniquely identify a paper through the widely used [DOI scheme](https://www.doi.org/)\n - num_authors: number of authors on the paper\n - year: year the document has been created\n - month: month the document has been created\n - day:  day the document has been created\n - title: title of the document\n - issn: the ISSN number of the journal the document has been published in\n - issn_type: printed or electronic\n - volume: volume of the journal the document has been published in\n - issue: issue of the journal the document has been published in\n - journal_title: Name of Journal the document has been published in\n - journal_title_iso: ISO abbreviation of the journal title.\n\n5 GB, and 26,759,425 rows\n\nIn the `mesh.csv` file the following fields are available:\n\n  - pmid: this is the unique article identified within the dataset, it is also the official identifier used on PubMed\n  - descriptor_id: the id of the MeSH descriptor for the given document\n  - descriptor_name: name of the MeSH descriptor\n  - descriptor_major_topic: Y/N, indicate if the descriptor is a major topic in MeSH\n  - qualifiers: a list of MeSH qualifiers (aka subheadings). Subheadings are attached to MeSH headings to describe a specific aspect of a concept.\n\nNB: a document can and has more often then not more then one MeSH descriptor associated to it.\n\n11 GB, and 247,415,857 rows\n\n### Other Resources\n\nAn introduction to MeSH can be found [here](https://www.nlm.nih.gov/mesh/) and short tutorials from the U.S. National Library of Medicine on how to use MeSH can be found [here](https://www.nlm.nih.gov/bsd/disted/mesh.html).\n\nFactsheets describing MeSH and MEDLINE:\n  \n  - https://www.nlm.nih.gov/pubs/factsheets/mesh.html\n  - https://www.nlm.nih.gov/pubs/factsheets/medline.html\n\nFurther datasets, which might be useful to work with MeSH data:\n \n  - https://mbr.nlm.nih.gov/Downloads.shtml\n\n### Acknowledgements\n\nThe data is freely available for download from MEDLINE.\nSpecifically through their ftp service at ftp://ftp.ncbi.nlm.nih.gov/pub/.\n\nRead the disclaimer from the U.S. National Library of Medicine regarding public use and redistribution of the data [here](https://www.nlm.nih.gov/databases/download/terms_and_conditions.html)\n\nThe data extraction would not have been possible without access to the computing facilities of [IMT School for Advanced Studies Lucca](https://www.imtlucca.it/).\n\n### Inspiration\n\nQuestions which one might want to look into using this dataset could be:\n\n  - Prediction of Mesh Headings\n  - Descriptive statistics on the rise and fall of MeSH descriptors over time.\n  - Which Journals \xcb\x99have had the most meteoric rise?\n  - Compute the co-occurrence probability of a given MeSH descriptor pair over time\n\n### How to open the files:\n\nDue to the limit on Kaggle for files to be at most 500MB in size, the files have been split.\nMore specifically the two files have been compressed with zip and split. To recombine them do the following.\nIf you are on Linux/MacOS enter the following commands in the terminal\n\n    cat paper_details.csv.zip.part-* > papers_details.csv.zip\n    unzip papers_details.csv.zip\n\nFor Windows machines, [this](https://stackoverflow.com/questions/1120095/split-files-using-tar-gz-zip-or-bzip2) Stock Overflow Answer will help.\n\n### Image Credit\n\nThe beautiful cover image has been made by [olsztyn-poland](https://unsplash.com/search/olsztyn-poland) over at unsplash.com.\n\nLink: https://unsplash.com/collections/610433/medical?photo=nss2eRzQwgw'","b""['healthcare', 'research', 'pharmaceutical industry', 'large', 'featured']""",https://www.kaggle.com/alucaria/medline
b'Grasping Dataset',"b""A grasping dataset from simulation using Shadow Robot's Smart Grasping Sandbox""","b""### Context\n\nAt Shadow Robot, we are leaders in robotic grasping and manipulation. As part of our Smart Grasping System development, we're developing different algorithms using machine learning. \n\nThis first public dataset was created to investigate the use of machine learning to predict the stability of a grasp. Due to the limitations of the current simulation, it is a restricted dataset - only grasping a ball. The dataset is annotated with an objective grasp quality and contains the different data gathered from the joints (position, velocity, effort).\n\nYou can find all the explanations for this dataset [over on Medium][1].\n\n### Inspiration\n\nI'll be more than happy to discuss this dataset as well as which dataset you'd like to have to try your hands at solving real world robotic problems focused on grasping using machine learning. Let's connect on twitter (@ugocupcic)!\n\n  [1]: https://medium.freecodecamp.org/teaching-my-robot-to-think-my-grasp-sucks-5e3d5a908745""","b""['robotics', 'medium', 'featured']""",https://www.kaggle.com/ugocupcic/grasping-dataset
b'Federal Firearm Licences',b'Active firearm sales licenses in the United States',"b'### Context\n\nFirearms sold in the United States must be licensed by the US Department of Justice Bureau of Alcohol, Tobacco, Firearms and Explosives. This dataset is a record of every firearm license which was still current as of July 2017.\n\n### Content\n\nThis dataset contains the names, license types, expiration dates, and locations of all Federal Firearms License (FFL) holders in the United States. The possible license types are:\n\n* 01\tDealer in Firearms Other Than Destructive Devices (Includes Gunsmiths)\n* 02\tPawnbroker in Firearms Other Than Destructive Devices\n* 03\tCollector of Curios and Relics\n* 06\tManufacturer of Ammunition for Firearms\n* 07\tManufacturer of Firearms Other Than Destructive Devices\n* 08\tImporter of Firearms Other Than Destructive Devices\n* 09\tDealer in Destructive Devices\n* 10\tManufacturer of Destructive Devices\n* 11\tImporter of Destructive Devices\n\n### Acknowledgements\n\nThis data is [published online](https://www.atf.gov/firearms/listing-federal-firearms-licensees-ffls-2017) in a tab-separated format by the Department of Justice Bureau of Alcohol, Tobacco, Firearms, and Explosives. It has been lightly retouched into a `CSV` file before publication here.\n\n### Inspiration\n\n* Can you geocode this data to determine where licensed gun shops are distributed?\n* What is the distribution of gun licenses across different types?'","b""['government', 'medium', 'featured']""",https://www.kaggle.com/doj/federal-firearm-licensees
b'Punkt Sentence Tokenizer Models',b'Kiss and Strunk (2006) Unsupervised Multilingual Sentence Boundary Detection',"b'### Context\n\nThe `punkt.zip` file contains pre-trained Punkt sentence tokenizer (Kiss and Strunk, 2006) models that detect sentence boundaries. These models are used by `nltk.sent_tokenize` to split a string into a list of sentences. \n\nA brief tutorial on **sentence and word segmentation** (aka **tokenization**) can be found in [Chapter 3.8 of the NLTK book](http://www.nltk.org/book/ch03.html).\n\nThe `punkt.zip` file contents:\n             \n - **README**: contains the information of how and what the models are trained on. \n - **PY3/**: contains the below pickled files as above for Python3\n - **czech.pickle**        \n - **danish.pickle** \n - **dutch.pickle**\n - **english.pickle**  \n - **estonian.pickle**    \n - **finnish.pickle**\n - **french.pickle**   \n - **german.pickle**      \n - **greek.pickle** \n - **italian.pickle**     \n - **norwegian.pickle**   \n - **polish.pickle**\n - **portuguese.pickle**\n - **slovene.pickle**\n - **spanish.pickle**\n - **swedish.pickle**\n - **turkish.pickle** \n\n### Citations\n\n    Kiss, Tibor and Strunk, Jan (2006): Unsupervised Multilingual Sentence Boundary Detection.\n    Computational Linguistics 32: 485-525.'","b""['linguistics', 'medium', 'featured']""",https://www.kaggle.com/nltkdata/punkt
b'Industrial Security Clearance Adjurations',b'Over 20000 security clearance appeals made to the Department of Defense',"b'### Context\n\nIndustry contractors that work for or with the United States Department of Defense and comes into contact with secret or privileged information must submit to a background check by the government as a part of their contractual obligations. Any employee who fails to get the necessary clearance will be unable to work.\n\nEmployees may however appeal their decision; in this case the decision will be reviewed and finalized (or reversed) by the Department of Defense Office of Hearings and Appeals (DOHA). This dataset contains summaries of the deliberations and results of such hearings, and provides a window into getting security clearance to work as a defense contractor in the United States.\n\n### Content\n\nThis data contains dates, case numbers, decisions, and decisions summaries for over 20,000 cases submitted for review between late 1996 and early 2016.\n\n### Acknowledgements\n\nThis data was published in an HTML format by the US Department of Defense. It has been converted into a CSV format before upload to Kaggle.\n\n### Inspiration\n\n* What percentage of appeals were declined or upheld?\n* What were the dominant reasons decisions were made? Have the factors behind decisions changed over times?\n* What kinds of words appear in decision texts?'","b""['military', 'medium', 'featured']""",https://www.kaggle.com/usdod/dod-clearance-adjurations
b'MovieLens 20M Dataset',b'Over 20 Million Movie Ratings and Tagging Activities Since 1995',"b'## Context\n\nThe datasets describe ratings and free-text tagging activities from MovieLens, a movie recommendation service. It contains 20000263 ratings and 465564 tag applications across 27278 movies. These data were created by 138493 users between January 09, 1995 and March 31, 2015. This dataset was generated on October 17, 2016.\n\nUsers were selected at random for inclusion. All selected users had rated at least 20 movies. \n\n## Content\n\nNo demographic information is included. Each user is represented by an id, and no other information is provided.\n\nThe data are contained in six files.\n\n**tag.csv** that contains tags applied to movies by users:\n\n* **userId**\n\n* **movieId**\n\n* **tag**\n\n* **timestamp**\n\n**rating.csv** that contains ratings of movies by users:\n\n* **userId**\n\n* **movieId**\n\n* **rating**\n\n* **timestamp**\n\n**movie.csv** that contains movie information:\n\n* **movieId**\n\n* **title**\n\n* **genres**\n\n**link.csv** that contains identifiers that can be used to link to other sources:\n\n* **movieId**\n\n* **imdbId**\n\n* **tmbdId**\n\n**genome_scores.csv** that contains movie-tag relevance data:\n\n* **movieId**\n\n* **tagId**\n\n* **relevance**\n\n**genome_tags.csv** that contains tag descriptions:\n\n* **tagId**\n\n* **tag**\n\n## Acknowledgements\n\nThe original datasets can be found [here](http://grouplens.org/datasets/movielens/). To acknowledge use of the dataset in publications, please cite the following paper:\n\nF. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872\n\n## Inspiration\n\nSome ideas worth exploring:\n\n* Which genres receive the highest ratings? How does this change over time?\n\n* Determine the temporal trends in the genres/tagging activity of the movies released'","b""['film', 'medium', 'featured']""",https://www.kaggle.com/grouplens/movielens-20m-dataset
b'Pennsylvania Safe Schools Report',b'Self reporting statistics from Pennyslvania schools',"b'# Introduction\n\nEach year schools in Pennsylvania are required to report weapons violations, substance abuse, cyber harassment, and other crimes committed during school, at school events, or on a bus (or waiting at a bus stop) to and from school.\n\nThe raw data can be found at   [www.safeschools.state.pa.us][1]\n\n\n# Important:  (LEA Types)\n\nThe rows in this Dataset include several ""LEA Types"" (Legal Entity Types): ""School"", ""School District"", ""County""... etc. Please note that several Schools may fall under a single ""School District"", and there maybe several ""School Districts"" in a single county.  Hence, if you include both ""LEA Types"", the counts could be off.\n\n\n\n# Key Pennsylvania Safe Schools Legislation\n\nThe Safe Schools Act of 1995 (Act 26) was amended in 1997 (Act 30) to mandate annual reporting of all incidents of violence, weapons, alcohol, drugs and tobacco possession to the Department of Education. Local education agencies also are required to develop a Memorandum of Understanding with local law enforcement agencies and provide for other procedural safeguards to enhance school safety. Another amendment to Act 26 (Act 36 of 1999) empowers schools to acquire the tools and resources needed to develop and enhance safe learning environments.\n\n\n# How this data was collected for Kaggle.\n\nSee the following [gist][2].\n\n\n  [1]: https://www.safeschools.state.pa.us/\n  [2]: https://gist.github.com/mchirico/0292b37d6e806caca120467aba1aca7a'","b""['crime', 'education', 'small', 'featured']""",https://www.kaggle.com/mchirico/pennsylvania-safe-schools-report
b'Weekly Sales Transactions',b'Weekly purchase quantities of over 800 products over 52 weeks',"b'### Context\n\nContains weekly purchased quantities of 800 over products over 52 weeks. These data were used in the paper ""Time series clustering: A superior alternative for market basket analysis"" by Tan, Swee Chuan and San Lau, Jess Pei.\n\n\n### Content\n\n- Each row represents a different product\n- Each column represents a week of the year (52 total weeks). The last half of the columns are normalized for you.\n- Values represent quantity of the products sold during the week\n\n- 52 weeks: W0, W1, ..., W51\n- Normalised vlaues of weekly data: Normalised 0, Normalised 1, ..., Normalised 51 \n\n### Acknowledgements\n\nTan, Swee Chuan and San Lau, Jess Pei, Time series clustering: A superior alternative for market basket analysis.\n\nThis dataset was downloaded from the UCI Machine Learning Repository.  https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly'","b""['business', 'time series', 'product', 'timelines', 'small', 'featured']""",https://www.kaggle.com/crawford/weekly-sales-transactions
b'NYS Case-Specific Beneficial Use Determinations',b'From New York State Open Data',"b""### Content  \n\nAll case-specific beneficial use determinations (BUDs) granted by DEC\xe2\x80\x99s Division of Materials Management since 1988.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated annually.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/ruQHpukrN7c) by [Francesco Gallarotti](https://unsplash.com/@gallarotti) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-case-specific-beneficial-use-determinations
b'Prescription-based prediction',b'Predicting doctor attributes from prescription behavior',"b""This is the dataset used in the Roam blog post [Prescription-based prediction](http://roamanalytics.com/2016/09/13/prescription-based-prediction/). It is derived from a variety of US open health datasets, but the bulk of the data points come from the [Medicare Part D](https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Part-D-Prescriber.html) dataset and the [National Provider Identifier](https://npiregistry.cms.hhs.gov) dataset.\n\nThe prescription vector for each doctor tells a rich story about that doctor's attributes, including specialty, gender, age, and region. There are 239,930 doctors in the dataset.\n\nThe file is in JSONL format (one JSON record per line):\n\n<pre>\n{\n    'provider_variables': \n        {\n            'brand_name_rx_count': int,\n            'gender': 'M' or 'F',\n            'generic_rx_count': int,\n            'region': 'South' or 'MidWest' or 'Northeast' or 'West',\n            'settlement_type': 'non-urban' or 'urban'\n            'specialty': str\n            'years_practicing': int\n        },\n     'npi': str,\n     'cms_prescription_counts':\n        {\n            `drug_name`: int, \n            `drug_name`: int, \n            ...\n        }\n}\n</pre>\n\nThe brand/generic classifications behind `brand_name_rx_count` and `generic_rx_count` are defined heuristically.\nFor more details, see [the blog post](http://roamanalytics.com/2016/09/13/prescription-based-prediction/) or go directly to [the associated code](https://github.com/roaminsight/roamresearch/tree/master/BlogPosts/Prescription_based_prediction).""","b""['healthcare', 'artificial intelligence', 'medium', 'featured']""",https://www.kaggle.com/roamresearch/prescriptionbasedprediction
b'55000+ Song Lyrics',b'Lyrics for 55000+ songs in English from LyricsFreak',"b""# Context\n\nThese are the lyrics for 57650 songs. They can be used for Natural Language Processing purposes, such as clustering of the words with similar meanings or predicting artist by the song. The dataset can be expanded with some more features for more advanced research like sentiment analysis. The data is not modified, only slightly cleaned, which gives a lot of freedom to devise your own applications.\n\n# Mining\n\nI have mined this dataset as a corpus for my NLP studies. However, before performing any transformation to bag-of-words or bag-of-N-grams, I decided to share the data.\nThe data has been acquired from LyricsFreak through scraping. Then I did some very basic work on removing inconvenient data: non-English lyrics, extremely short and extremely long lyrics, lyrics with non-ASCII symbols. However, there's still work to be done in terms of data preparation.\n\n# Content\n\nThe dataset contains 4 columns:\n\n 1. **Artist**\n 2. **Song Name**\n 3. **Link** to a webpage with the song (for reference). This is to be concatenated with *http://www.lyricsfreak.com* to form a real URL.\n 4. **Lyrics** of the song, unmodified.\n\n# Acknowledgements\n\nI would like to acknowledge [LyricsFreak][1], which is the direct source of the data.\n\n\n  [1]: http://lyricsfreak.com/""","b""['linguistics', 'languages', 'music', 'medium', 'featured']""",https://www.kaggle.com/mousehead/songlyrics
b'SeedLing',b'A Seed Corpus for the Human Language Project',"b""### Context\n\nA broad-coverage corpus such as the [Human Language Project envisioned by Abney and Bird (2010)](http://www.anthology.aclweb.org/P/P10/P10-1010.pdf) would be a powerful resource for the study of endangered languages.\nSeedLing was created as a seed corpus for the Human Language Project to cover a broad range of languages (Guy et al. 2014).\n\nTAUS (Translation Automation User Society) also see the [importance of the Human Language Project in the context of keeping up with the demand for capacity and speed for translation](https://www.taus.net/think-tank/articles/translate-articles/the-call-for-the-human-language-project).  TAUS' definition of the Human Language Project can be found on https://www.taus.net/knowledgebase/index.php/Human_Language_Project\n\nA detailed explanation of how to use the corpus can be found on https://github.com/alvations/SeedLing\n\n### Content\n\nThe SeedLing corpus on this repository includes the data from:\n\n - **ODIN**: Online Database of Interlinear Text\n - **Omniglot**: Useful foreign phrases from www.omniglot.com\n - **UDHR**: Universal Declaration of Human Rights\n\n### Acknowledgements\n**Citation**:\n\nGuy Emerson, Liling Tan, Susanne Fertmann, Alexis Palmer and Michaela Regneri . 2014. SeedLing: Building and using a seed corpus for the Human Language Project. In Proceedings of The use of Computational methods in the study of Endangered Languages (ComputEL) Workshop. Baltimore, USA.\n\n    @InProceedings{seedling2014,\n      author    = {Guy Emerson, Liling Tan, Susanne Fertmann, Alexis Palmer and Michaela Regneri},\n      title     = {SeedLing: Building and using a seed corpus for the Human Language Project},\n      booktitle = {Proceedings of The use of Computational methods in the study of Endangered Languages (ComputEL) Workshop},\n      month     = {June},\n      year      = {2014},\n      address   = {Baltimore, USA},\n      publisher = {Association for Computational Linguistics},\n      pages     = {},\n      url       = {}\n    }\n\n**References**:\n\n    Steven Abney and Steven Bird. 2010. The Human Language \n    Project: Building a universal corpus of the world\xe2\x80\x99s languages. \n    In Proceedings of the 48th Annual Meeting of the Association \n    for Computational Linguistics, pages 88\xe2\x80\x9397.\n\n    Sime Ager. Omniglot - writing systems and languages \n    of the world. Retrieved from www.omniglot.com.\n    \n    William D Lewis and Fei Xia. 2010. Developing ODIN: A multilingual \n    repository of annotated language data for hundreds of the world\xe2\x80\x99s \n    languages. Literary and Linguistic Computing, 25(3):303\xe2\x80\x93319.\n    \n    UN General Assembly, Universal Declaration of Human Rights, \n    10 December 1948, 217 A (III), available at: \n    http://www.refworld.org/docid/3ae6b3712c.html \n    [accessed 26 April 2014]\n\n### Inspiration\n\nThis corpus was created in a span a semester in Saarland University by a linguist, a mathematician, a data geek and two amazing mentors from the [COLI department](http://www.coli.uni-saarland.de/). It wouldn't have been possible without the cross-disciplinary synergy and the common goal we had.\n\n - Expand/Explore the Human Language Project.\n - Go to the field and record/document their language. Make them computationally readable.\n - Grow the Seedling!""","b""['linguistics', 'languages', 'culture and humanities', 'small', 'featured']""",https://www.kaggle.com/alvations/seedling
b'City Lines',"b""Explore the transport systems of the world's cities""","b'### Context\n \nWhat did the expansion of the London Underground, the world\xe2\x80\x99s first underground railway which opened in 1863, look like? What about the transportation system in your home city? Citylines collects data on transportation lines across the world so you can answer questions like these and more.\n \n### Content\n \nThis dataset, originally shared and updated [here][1], includes transportation line data from a number of cities from around the world including London, Berlin, Mexico City, Barcelona, Washington D.C., and others covering many thousands of kilometers of lines. \n \n### Inspiration\n \nYou can explore geometries to generate maps and even see how lines have changed over time based on historical records. Want to include shapefiles with your analysis? Simply [publish a shapefile dataset here][2] and then [create a new kernel][3] (R or Python script/notebook), adding your shapefile as an additional datasource.\n \n\n\n  [1]: http://www.citylines.co/data\n  [2]: http://www.citylines.co/data\n  [3]: https://www.kaggle.com/citylines/city-lines/kernels?modal=true'","b""['cities', 'transport', 'small', 'featured']""",https://www.kaggle.com/citylines/city-lines
b'NYC DFTA Contracts',b'From New York City Open Data',"b""### Content  \n\nListing of all Senior Centers, Abuse Prevention Contracts, Home Care Contracts, Legal Services Contracts, NORC Contracts, Transportation Contracts, Case Mangement Contracts, Home Delivered Meal Contracts and  Caregiver Contracts in all five boroughs.</p>\r\nThe Department for the Aging (DFTA) provides a wide array of services specific to the elderly population of New York City.  To accomplish this, the department contracts out to organizations (mainly non-profit) to provide these services throughout the five boroughs.  The majority of the services provided are through our Neighborhood Senior Centers which provide free meals (mostly lunch, some breakfast and dinner meals) that meet nutritional standards defined by the FDA.  DFTA provides this data of our contracted agencies sorted by the contract servivce type.  The dataset contains the relevant information for the public to contact the agencies providing the services they may be seeking.  The data is limited in that the contract service type does not provide the full scope of services that are provided in detail.  \n\n### Context  \n\nThis is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  \n\n* Update Frequency: This dataset is updated weekly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/UxCS2kVhZTc) by [James Bold](https://unsplash.com/@jamesbold) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-city/nyc-dfta-contracts
"b""Corpus of bilingual children's speech""",b'Transcribed natural speech from 25 bilingual children',"b'###Project Description\nThe Paradis corpus consists of naturalistic language samples from 25 children learning English as a second language (English language learners or learners of English as an additional language). Transcription is in English orthography only; phonetic transcription was not included in this research. Any real names of people or places in the transcripts have been replaced with pseudonyms. The participants are identified with four letter codes.\n\n###Content\nThe data in this corpus was collected in 2002 in Edmonton, Canada. Children were video-\xc2\xad\xe2\x80\x90taped in conversation with a student research assistant in their homes for approximately 45 minutes. During this time, the research assistant had a list of \xe2\x80\x9cinterview\xe2\x80\x9d questions to ask. If the child introduced his or her own topics and the conversation moved forward, the questions were not asked. This dataset only includes data from the first stage of data collection, in 2002. The full longituinal corpus may be found on the CHILDES website, here: http://childes.talkbank.org/access/Biling/Paradis.html \n\nThese data are in .cha files, which are intended for use with the program CLAN (http://alpha.talkbank.org/clan/). However, you may also treat these files as raw text files, with one speech snippet per line. Lines starting with @ are metadata. \n\nFile format information: \n\n* *EXP: Experimenter speaking\n* *CHI: Child speaking\n* %[some text]: These lines contain non-linguistic information\n\n### Biographical data\nParticipants in this study were children from newcomer (immigrant and refugee) families to Canada. The children started to learn English as a second language (L2) after their first language (L1) had been established, at 4 years 11 months on average. In the table below, \xe2\x80\x9cAOA\xe2\x80\x9d refers to the \xe2\x80\x9cage of arrival\xe2\x80\x9d of the child when the family immigrated. The number \xe2\x80\x9c1\xe2\x80\x9d indicates children who were Canadian born. The column \xe2\x80\x9cAOE\xe2\x80\x9d refers to the age of onset of English acquisition. All ages are in months. Each child\xe2\x80\x99 s L1 and gender is also listed in the table below.\n\nFor more information about the participants and procedures in this research, see the following:\n\nParadis, J. (2005). Grammatical morphology in children learning English as a second language: Implications of similarities with Specific Language Impairment. Language, Speech and Hearing Services in the Schools, 36, 172-187.\nGolberg, H., Paradis, J. & Crago, M. (2008). Lexical acquisition over time in minority L1 children learning English as a L2. Applied Psycholinguistics, 29, 1-25.\n\n### Inspiration: \n\n* Does children\xe2\x80\x99s first language affect what English words they use? How many words?\n* Do some children pause (marked as (.) or (..)) more often than others?\n* Do children at different ages interrupt/overlap their speech more often? (Marked by <> around text.)\n* Does a children\xe2\x80\x99s age of first exposure to English affect how often then say \xe2\x80\x9cum\xe2\x80\x9d? (Transcribed as\xe2\x80\x9c&-um\xe2\x80\x9d.)\n\n### Related datasets:\n\n* [When do children learn words?](https://www.kaggle.com/rtatman/when-do-children-learn-words)\n* [Diagnosing specing language impairment in children](https://www.kaggle.com/dgokeeffe/specific-language-impairment)\n'","b""['linguistics', 'languages', 'children', 'small', 'featured']""",https://www.kaggle.com/rtatman/corpus-of-bilingual-childrens-speech
b'Crimes Committed in France',b'Monthly counts of crimes committed since 2000',"b""### Context\n\nThis dataset is an aggregated count of all crimes committed in France, broken down by month and category.\n\n### Content\n\nThis data was aggregated by the French national government and published online on the [French Open Data Portal](https://www.data.gouv.fr/fr/datasets/chiffres-departementaux-mensuels-relatifs-aux-crimes-et-delits-enregistres-par-les-services-de-police-et-de-gendarmerie-depuis-janvier-1996/). It is a combination of records kept by both local and national police forces. It's important to note that the name of the categories of crime are in French!\n\n### Acknowledgements\n\nThis data is a part of a larger group of Excel files published by the French Goverment on the [French Open Data Portal](https://www.data.gouv.fr/fr/datasets/chiffres-departementaux-mensuels-relatifs-aux-crimes-et-delits-enregistres-par-les-services-de-police-et-de-gendarmerie-depuis-janvier-1996/). It has been converted to a single CSV file before uploading here.\n\n### Inspiration\n\nThis is a simple time series dataset that can be probed for trends in the underlying types of crimes committed. Is petty theft more or less popular today than it was ten years ago? How much variation is there in the amount of robberies year-to-year? Can you normalize the growth in the number of crimes against the growth in the number of people? How do crimes committed here differ from those committed in, say, [Los Angeles](https://www.kaggle.com/cityofLA/crime-in-los-angeles/)?""","b""['crime', 'europe', 'small', 'featured']""",https://www.kaggle.com/government-of-france/crimes-in-france
"b'""Zwarte Piet"" Tweets'",b'All tweets from past months about this annually recurring party.',"b'""Zwarte Piet"" or ""Black Pete"" is originally part of an annually recurring party for children, called ""Sinterklaas"". Every single year they arrive by boat in the Netherlands, bringing toys and candy for all kind children. But since 2011 (if my research is correct) resistance started against ""Zwarte Piet"". An annually recurring discussion arose: is ""Black Pete"" just wrong or not and should it be forbidden, or not? \n\nAs far as my research is correct, it all started in 2011, and ever since people are demonstrating each year. So I thought this would be an interesting topic for a dataset. I collected all tweets with hastags ""sinterklaas"" or ""zwartepiet"" from 13-05-2017 till 23-11-2017. I tried to receive tweets from the whole year (23-11-2016 till 23-11-2017) but somehow I was just able to receive it from 13-05-2017 till 23-11-2017.\n\nPerhaps it\'s even more interesting to just collect all tweets of every year when the party ""lives"" around all people in the Netherlands (from around September till January), so we\'re even able to see changes over the past years. Maybe an idea for a next update.'","b""['internet', 'small', 'featured']""",https://www.kaggle.com/erikvdven/zwarte-piet-tweets
b'WNBA Player stats Season 2016-2017',"b'Points, Assists, Height, Weight and other personal details and stats'","b'### Context\n\nScraped and copied from http://www.wnba.com/stats/player-stats/#?Season=2017&SeasonType=Regular%20Season&PerMode=Totals + http://www.wnba.com/ in general for the bio data.\n\n\n### Content\nStats from all games of season 2016-2017\n\n - G = Games Played\n - MIN = Minutes Played\n - FGM = Field Goals Made\n - FGA = Field Goals Attempts\n - FG% = Field Goals %\n - 3PM = 3Points Made \n - 3PA = 3Points Attempts\n - 3P% = 3Points %\n - FTM = Free Throws made\n - FTA = Free Throws Attempts\n - FT% = Free Throws %\n - OREB = Offensive Rebounds\n - DREB = Defensive Rebounds\n - REB = Total Rebounds\n - AST = Assists\n - STL = Steals\n - BLK = Blocks\n - TO = Turnovers\n - PTS = Total points\n - DD2 = Double doubles\n - TD3 = Triple doubles\n\n### Inspiration\n\nCompare WNBA to NBA in best players, average heights, ...'","b""['sports', 'small', 'featured']""",https://www.kaggle.com/jinxbe/wnba-player-stats-2017
b'Amazon Reviews: Unlocked Mobile Phones',"b""More than 400,000 reviews from Amazon's unlocked mobile phone category""","b'# Context \n\n[PromptCloud][1] extracted 400 thousand reviews of unlocked mobile phones sold on Amazon.com to find out insights with respect to reviews, ratings, price and their relationships.\n\n# Content\n\nGiven below are the fields:\n\n - Product Title \n - Brand \n - Price \n - Rating \n - Review text \n - Number of people who found the review helpful\n\nData was acquired in December, 2016 by the crawlers build to deliver our data extraction services.\n\n# Initial Analysis\n\nIt can be accessed here: [http://www.kdnuggets.com/2017/01/data-mining-amazon-mobile-phone-reviews-interesting-insights.html][2]\n\n  [1]: https://promptcloud.com\n  [2]: http://www.kdnuggets.com/2017/01/data-mining-amazon-mobile-phone-reviews-interesting-insights.html'","b""['internet', 'business', 'telecommunications', 'medium', 'featured']""",https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones
b'Flight Route Database',"b'A database of 59,036 flight routes'","b'### Routes database\n\nAs of January 2012, the OpenFlights/Airline Route Mapper Route Database contains 59036 routes between 3209 airports on 531 airlines spanning the globe.\n\n### Content\n**The data is ISO 8859-1 (Latin-1) encoded.**\n\nEach entry contains the following information:\n\n- Airline\t2-letter (IATA) or 3-letter (ICAO) code of the airline.\n- Airline ID\tUnique OpenFlights identifier for airline (see Airline).\n- Source airport\t3-letter (IATA) or 4-letter (ICAO) code of the source airport.\n- Source airport ID\tUnique OpenFlights identifier for source airport (see Airport)\n- Destination airport\t3-letter (IATA) or 4-letter (ICAO) code of the destination airport.\n- Destination airport ID\tUnique OpenFlights identifier for destination airport (see Airport)\n- Codeshare\t""Y"" if this flight is a codeshare (that is, not operated by Airline, but another carrier), empty otherwise.\n- Stops\tNumber of stops on this flight (""0"" for direct)\n- Equipment\t3-letter codes for plane type(s) generally used on this flight, separated by spaces\n\nThe special value \\N is used for ""NULL"" to indicate that no value is available. \n\nNotes:\n\n- Routes are directional: if an airline operates services from A to B and from B to A, both A-B and B-A are listed separately.\n- Routes where one carrier operates both its own and codeshare flights are listed only once.\n\n### Acknowledgements\n\nThis dataset was downloaded from Openflights.org under the Open Database license. This is an excellent resource and there is a lot more on their website, so check them out!'","b""['small', 'featured']""",https://www.kaggle.com/open-flights/flight-route-database
b'The Metropolitan Museum of Art Open Access',"b'Explore information on more than 420,000 historic artworks'","b'**Dataset source:** [https://github.com/metmuseum/openaccess][1]\n\nThe Metropolitan Museum of Art presents over 5,000 years of art from around the world for everyone to experience and enjoy. The Museum lives in three iconic sites in New York City\xe2\x80\x94The Met Fifth Avenue, The Met Breuer, and The Met Cloisters. Millions of people also take part in The Met experience online.\n\nSince it was founded in 1870, The Met has always aspired to be more than a treasury of rare and beautiful objects. Every day, art comes alive in the Museum\'s galleries and through its exhibitions and events, revealing both new ideas and unexpected connections across time and across cultures.\n\nThe Metropolitan Museum of Art provides select datasets of information on more than 420,000 artworks in its Collection for unrestricted commercial and noncommercial use. To the extent possible under law, The Metropolitan Museum of Art has waived all copyright and related or neighboring rights to this dataset using Creative Commons Zero. This work is published from: The United States Of America. You can also find the text of the CC Zero deed in the file LICENSE in this repository. These select datasets are now available for use in any media without permission or fee; they also include identifying data for artworks under copyright. The datasets support the search, use, and interaction with the Museum\xe2\x80\x99s collection.\n\nAt this time, the datasets are available in CSV format, encoded in UTF-8. While UTF-8 is the standard for multilingual character encodings, it is not correctly interpreted by Excel on a Mac. Users of Excel on a Mac can convert the UTF-8 to UTF-16 so the file can be imported correctly.\n\nAdditional usage guidelines\n---------------------------\n\n**Images not included**\n\nImages are not included and are not part of the dataset. Companion artworks listed in the dataset covered by the policy are identified in the Collection section of the Museum\xe2\x80\x99s website with the Creative Commons Zero (CC0) icon.\n\nFor more details on how to use images of artworks in The Metropolitan Museum of Art\xe2\x80\x99s collection, please visit our Open Access page.\n\n**Documentation in progress**\n\nThis data is provided \xe2\x80\x9cas is\xe2\x80\x9d and you use this data at your own risk. The Metropolitan Museum of Art makes no representations or warranties of any kind. Documentation of the Museum\xe2\x80\x99s collection is an ongoing process and parts of the datasets are incomplete.\n\nWe plan to update the datasets with new and revised information on a regular basis. You are advised to regularly update your copy of the datasets to ensure you are using the best available information.\n\n**Pull requests**\n\nBecause these datasets are generated from our internal database, we do not accept pull requests. If you have identified errors or have extra information to share, please email us at openaccess@metmuseum.org and we will forward to the appropriate department for review.\n\n**Attribution**\n\nPlease consider attributing or citing The Metropolitan Museum of Art\'s CC0 select datasets, especially with respect to research or publication. Attribution supports efforts to release other datasets in the future. It also reduces the amount of ""orphaned data,"" helping to retain source links.\n\n**Do not misrepresent the dataset**\n\nDo not mislead others or misrepresent the datasets or their source. You must not use The Metropolitan Museum of Art\xe2\x80\x99s trademarks or otherwise claim or imply that the Museum or any other third party endorses you or your use of the dataset.\n\nWhenever you transform, translate or otherwise modify the dataset, you must make it clear that the resulting information has been modified. If you enrich or otherwise modify the dataset, consider publishing the derived dataset without reuse restrictions.\n\nThe writers of these guidelines thank the The Museum of Modern Art, Tate, Cooper-Hewitt, and Europeana.\n\n\n  [1]: https://github.com/metmuseum/openaccess'","b""['culture and humanities', 'museums', 'medium', 'featured']""",https://www.kaggle.com/metmuseum/the-metropolitan-museum-of-art-open-access
b'PTM Strava Data',b'GPX files from a GPS device',b'### Context\n\nSelected activities from Strava for use in Kaggle Kernels only.  GPX files from a GPS device.\n\n### Content\n\nLaramie_Enduro_2014.gpx\t\n\nLaramie_Enduro_2015.gpx\t\n\nLaramie_Enduro_2016.gpx\t\n\nWest_Laramie_Bike_Ride.gpx\t\n\nColorado_Belford_Oxford_and_Missouri_Mountains_Hike.gpx\t\n\nColorado_Longs_Peak_and_Chasm_Lake_Hike.gpx\t\n\nBerenthanti_Ghorepani_Ghandruk_Loop_Hike_Day_1_of_3_.gpx\t\n\nBerenthanti_Ghorepani_Ghandruk_Loop_Hike_Day_2_of_3_.gpx\t\n\nBerenthanti_Ghorepani_Ghandruk_Loop_Hike_Day_3_of_3_.gpx\t\n\n\n\n### Acknowledgements\n\nStrava\n\n### Inspiration\n\nStrava Labs',"b""['data visualization', 'geospatial analysis', 'small', 'featured']""",https://www.kaggle.com/paultimothymooney/ptm-strava-data
b'Inception V3 Model',b'Inception V3 Tensorflow Model',"b'[Inception-v3](https://arxiv.org/abs/1512.00567) is trained for the [ImageNet](http://image-net.org/) Large Visual Recognition Challenge using the data from 2012. This is a standard task in computer vision, where models try to classify entire images into [1000 classes](http://image-net.org/challenges/LSVRC/2014/browse-synsets), like ""Zebra"", ""Dalmatian"", and ""Dishwasher"".\n\nHere\'s [code on GitHub to train Inception-v3](https://github.com/tensorflow/models/tree/master/inception)'","b""['artificial intelligence', 'medium', 'featured']""",https://www.kaggle.com/google-brain/inception-v3
b'LADWP Water Supply in Acre Feet',b'From Los Angeles Open Data',"b""### Content  \n\nSources of LADWP Water Supply in Acre Feet. MWD - Metropolitan Water District, LA Aqueduct, Local Groundwater, and Recycled Water.  \n\n### Context  \n\nThis is a dataset hosted by the city of Los Angeles. The organization has an open data platform found [here](https://data.lacity.org) and they update their information according the amount of data that is brought in. Explore Los Angeles's Data using Kaggle and all of the data sources available through the city of Los Angeles [organization page](https://www.kaggle.com/cityofLA)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/iftBhUFfecE) by [Jeremy Bishop](https://unsplash.com/@tentides) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/cityofLA/ladwp-water-supply-in-acre-feet
b'1 million Sudoku games',b'1 million numpy array pairs of Sudoku games and solutions',"b'# Context \n\nSudoku is a popular number puzzle that requires you to fill blanks in a 9X9 grid with digits so that each column, each row, and each of the nine 3\xc3\x973 subgrids contains all of the digits from 1 to 9. Sudoku-solving has gained much attention from various fields. As a deep learning researcher, I was inclined to investigate the possibilities of neural networks solving Sudoku. This dataset was prepared for that.\n\n\n# Content\n\nThere are dozens of source codes to generate Sudoku games available. I picked one of them, and ran the code. It took approximately 6 hours to generate 1 million games ( + solutions).\n\nA Sudoku puzzle is represented as a 9x9 Python numpy array. The blanks were replaced with 0\'s. You can easily load and explore the data by running this.\n   \n    import numpy as np\n    quizzes = np.load(\'sudoku_quizzes.npy\') # shape = (1000000, 9, 9)\n    solutions = np.load(\'sudoku_solutions.npy\') # shape = (1000000, 9, 9)\n    for quiz, solution in zip(quizzes[:10], solutions[:10]):\n        print(quiz)\n        print(solution)\n\n** Updates for Version 3. **\n\nI converted NumPy arrays to csv so they are easily accessible, irrespective of language. In each line, a Sudoku quiz and its corresponding solution are separated by a comma. You can restore the csv file content to Numpy arrays if needed as follows:\n\n    import numpy as np\n    quizzes = np.zeros((1000000, 81), np.int32)\n    solutions = np.zeros((1000000, 81), np.int32)\n    for i, line in enumerate(open(\'sudoku.csv\', \'r\').read().splitlines()[1:]):\n        quiz, solution = line.split("","")\n        for j, q_s in enumerate(zip(quiz, solution)):\n            q, s = q_s\n            quizzes[i, j] = q\n            solutions[i, j] = s\n    quizzes = quizzes.reshape((-1, 9, 9))\n    solutions = solutions.reshape((-1, 9, 9))\n\n    \n\n# Acknowledgements\nI\'m grateful to Arel Cordero, who wrote and shared this great Sudoku generation code. https://www.ocf.berkeley.edu/~arel/sudoku/main.html.\n\n# Inspiration\n* Check  https://github.com/Kyubyong/sudoku to see if CNNs can crack Sudoku puzzles.\n* Also, reinforcement learning can be a promising alternative to this task.\n* Feel free to challenge Sudoku puzzles.'","b""['games and toys', 'medium', 'featured']""",https://www.kaggle.com/bryanpark/sudoku
b'Real Time Bidding',b'Predict clicks and handle imbalanced data',"b""# Context \n\nThis is *real* real-time bidding data that is used to predict if an advertiser should bid for a marketing slot e.g. a banner on a webpage. Explanatory variables are things like browser, operation system or time of the day the user is online, marketplace his identifiers were traded on earlier, etc. The column **'convert'** is 1, when the person clicked on the ad, and 0 if this is not the case. \n\n\n# Content\n\nUnfortunately, the data had to be anonymized, so you basically can't do a lot of feature engineering. I just applied PCA and kept 0.99 of the linear explanatory power. However, I think it's still really interesting data to just test your general algorithms on imbalanced data. ;)\n\n\n# Inspiration\n\nSince it's heavily imbalanced data, it doesn't make sense to train for accuracy, but rather try to get obtain a good AUC, F1Score, MCC or recall rate, by cross-validating your data. \nIt's interesting to compare different models (logistic regression, decision trees, svms, ...) over these metrics and see the impact that your split in train:test data has on the data. \n\nIt might be good strategy to follow these \n[Tactics to combat imbalanced classes](http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/).""","b""['business', 'artificial intelligence', 'medium', 'featured']""",https://www.kaggle.com/zurfer/rtb
b'Historical American Lynching',b'Information on 2806 lynchings in the United States',"b'### Context: \n\n""Lynching"" historically includes not only Southern lynching but frontier lynching and vigilantism nationwide and many labor-related incidents.  Persons of any race or ethnicity and either gender may have been either perpetrators or victims of lynching. The lynchings in this dataset follow an NAACP definition for including an incident in the inventory of lynchings:\n \n\n 1.  There must be evidence that someone was killed;\n 2. The killing must have occurred illegally;\n 3. Three or more persons must have taken part in the killing; and\n 4. The killers must have claimed to be serving justice or tradition.\n\n### Content: \n\nThe original data came from the NAACP Lynching Records at Tuskegee Institute, Tuskegee, Alabama.  Stewart Tolnay and E.M. Beck examined these records for name and event duplications and other errors with funding from a National Science Foundation Grant and made their findings available to Project HAL in 1998. Project HAL is inactive now, but it\xe2\x80\x99s original purpose was to build a data set for researchers to use and to add to. \n\nThe dataset contains the following information for each of the 2806 reported lynchings:\n\n* State: State where the lynching took place\n* Year: Year of the lynching\n* Mo: Month\n* Day: Day\n* Victim: Name of the victim\n* County: County where the lynching occurred (keep in mind that county names have changed & boundaries redrawn)\n* Race: Race of the victim\n* Sex: Sex of the victim\n* Mob: Information on the mob\n* Offense: Victim\xe2\x80\x99s alleged offense\n* Note: Note (if any)\n* 2nd Name: Name of the 2nd victim (if any)\n* 3rd Name: Name of the 3rd victim (if any)\n* Comments: Comments (if any)\n* Source: Source of the information (if any)\n\n### Acknowledgements: \n\nThis dataset was compiled by Dr. Elizabeth Hines and Dr. Eliza Steelwater. If you use this dataset in your work, please include the following citation: \n\nHines, E., & Steelwater, E. (2006). Project Hal: Historical American Lynching Data Collection Project. University of North Carolina, http://people.uncw.edu/hinese/HAL/HAL%20Web%20Page.htm\n\n### You may also like:\n\n* Bryan Stevenson\xe2\x80\x99s Equal Justice Initiative, EJI posts lynching information and stories and is currently quite active:  https://www.eji.org/\n* [First Person Narratives of the American South: Personal accounts of Southern life between 1860 and 1920](https://www.kaggle.com/docsouth-data/first-person-narratives-of-the-american-south)\n\n### Inspiration: \n\n* Can you use the county-level data in this dataset to create a map of lynchings in the US?\n* What demographic qualities were most associated with lynching victims?\n* How did patterns of lynching change over time?'","b""['crime', 'united states', 'violence', 'death', 'small', 'featured']""",https://www.kaggle.com/rtatman/historical-american-lynching
b'Diplomacy Betrayal Dataset',b'Can you predict a betrayal before it happens?',"b'This dataset contains a collection of interaction sequences between allies in online Diplomacy [1] games. A sequence consists of consecutive game seasons during which the two players exchange messages and help each other in the game. Half of the sequences end with betrayal, while the other half are part of lasting friendships.\n\n### Description\n\nDiplomacy [1] is a popular and engaging strategic board game that is often played online [2, 3].  It is based heavily on communication between the players.  Due to its military domination setting, Diplomacy is a well suited environment for studying naturally occurring betrayal and deception.\n\nFrom a collection of Diplomacy game logs, we identified and extracted *ongoing, established, and reciprocal* friendships: relationships that contain at least two consecutive and reciprocated acts of support that span at least three seasons in game time, with no more than five seasons passing between two acts of friendship.\n\nWe then identified 250 *betrayals*: the subset of friendships described above that are followed by at least two attacks.  To match each betrayal, we selected a friendship that is not followed by any offensive action, but is otherwise nearly identical (in terms of length and relative time within the game). The current dataset consists of these selected betrayals and friendships only.\n\nEach relationship contains a sequence of seasons.  Within each season, we provide features extracted from the messages sent by each player.\n\n### Acknowledgements: \n\nThis dataset is distributed under the [Open Data Commons Attribution (ODC-By 1.0)](http://opendatacommons.org/licenses/by/summary/) license.  It was collected by Vlad Niculae, Srijan Kumar, Jordan Boyd-Graber and Cristian Danescu-Niculescu-Mizil.\n\nIf you use this dataset, please cite this paper: \n\n> Niculae, V., Kumar, S., Boyd-Graber, J., & Danescu-Niculescu-Mizil, C. (2015). Linguistic harbingers of betrayal: A case study on an online strategy game. In Proceedings of the ACL.\n\n### Data format\n\nThe dataset is a UTF-8 encoded JSON file, which can be loaded into a Python kernel with the following code:\n\n    >>> import json\n    >>> from io import open\n    >>> with open(""diplomacy_data.json"", ""r"") as f:\n    ...     diplomacy = json.load(f)\n    ...\n\nIt is structured as a list of dictionaries, one for each of the 500 sequences.\n\n    >>> len(diplomacy)\n    500\n\nThis is an example of one such entry, with the fields explained:\n\n    >>> entry = diplomacy[0]\n    >>> entry\n    {\n        \'idx\': 0,           # unique identifier of the dataset entry\n        \'game\': 74,         # unique identifier of the game it comes from\n        \'betrayal\': True,   # whether the friendship ended in betrayal\n        \'people\': u\'AT\',    # the countries represented by the two players\n                            # (in this case, Austria and Turkey)\n        \'seasons\': ...\n    }\n\nThe \'seasons\' field is again a list of dictionaries, one for each game season in the friendship sequence.  In the example below, there are 8 seasons, each identified by the game year.  Decimal notation is used to denote the season in each year.  For example, 1906.0 is the spring of 1906 and 1906.5 is the fall of 1906.  Each season is also marked with what interaction the two players have at the end of the discussion:  whether the players supported one another (\'support\'), attacked one another (\'attack\'), or did not have explicit military interactions (null).\n\n    >>> seasons = entry[\'seasons\']\n    >>> len(seasons)\n    8\n    >>> seasons[0]\n    {\n        \'season\': 1906.5,           # fall of the year 1906 (game time)\n        \'interaction\': {\n            \'victim\': u\'support\',   # the victim supported the betrayer\n            \'betrayer\': u\'support\'  # the betrayer supported the victim\n        },\n        \'messages\': {\n            \'victim\': ...,\n            \'betrayer\': ...\n        }\n}\n\nThe [\'messages\'][\'victim\'] and [\'messages\'][\'betrayer\'] fields are lists of features of each message sent by the victim to the betrayer, and by the betrayer to the victim, respectively:\n\n    >>> msgs = seasons[0][\'messages\'][\'betrayer\']\n    >>> len(msgs)\n    6\n    >>> msgs[0]\n    {\n        ""n_words"": 146,             # number of words in the message\n        ""n_sentences"": 9,           # number of sentences in the message\n\n        ""n_requests"": 7,            # number of request sentences\n        ""politeness"": 0.8320,       # politeness of the requests (from 0 to 1)\n                                    # (using the Stanford Politeness\n                                    # Classifier available at [4])\n        ""sentiment"": {\n            ""positive"": 1,          # no. sentences with positive sentiment\n            ""neutral"": 3,           #      ""      ""      neutral sentiment\n            ""negative"": 5           #      ""      ""      negative sentiment\n        },                          # (using Stanford Sentiment Analysis [5])\n\n        ""lexicon_words"": {          # words and phrases matching several\n            ""disc_expansion"": [     # linguistic and psycholinguistic lexicons\n                ""until"",            # (see below for details)\n                ""yet"",\n                ""instead""\n            ],\n            ""premise"": [\n                ""for"",\n                ""for""\n            ],\n            ...\n        },\n        ""frequent_words"": [         # frequent words in the message\n            ""more"",                 # (occurring in at least 50 messages\n            ""let"",                  # and 5 friendships overall)\n            ""keep"",\n            ""...\n        ]\n    }\n\nThe words in each list are in random order. The order of messages within a season is also randomized.  This measure is in place to protect the privacy of the players and of their conversations.\n\nThe lexicons used to construct the ""lexicon_words"" field are:\n\n *  \'claim\', \'premise\':  Argumentation structure markers [6]\n *  \'allsubj\': Subjective markers [7]\n *  \'disc_*\':  Discourse markers from the Penn Discourse Treebank. [8]\n        Includes \'disc_comparison\', \'disc_expansion\', \'disc_contingency\',\n        \'disc_temporal_future\' and \'disc_temporal_rest\' (we manually split\n        \'temporal\' from PDT into \'temporal_future\' and \'temporal_rest\' to\n        capture planning).\n\n\n###  References\n\n[1] https://en.wikipedia.org/wiki/Diplomacy_%28game%29\n[2] http://www.floc.net/dpjudge/\n[3] http://usak.asciiking.com/\n[4] http://politeness.mpi-sws.org/\n[5] http://nlp.stanford.edu/sentiment/\n[6] C. Stab and I. Gurevych. Identifying Argumentative Discourse Structures in\n    Persuasive Essays. In: Proceedings of EMNLP, 2014.\n    https://www.ukp.tu-darmstadt.de/data/argumentation-mining/\n[7] E. Riloff and J. Wiebe. Learning extraction patterns for subjective\n    expressions. In: Proceedings of EMNLP, 2003.\n    http://www.anthology.aclweb.org/W/W03/W03-1014.pdf\n[8] https://www.seas.upenn.edu/~pdtb/'","b""['internet', 'linguistics', 'sociology', 'board games', 'medium', 'featured']""",https://www.kaggle.com/rtatman/diplomacy-betrayal-dataset
b'Dota 2 Matches',b'Explore player behavior and predict match outcomes.',"b'## Dataset update request for comments: ##\n\nIt would probably be good to update this dataset. Here are ideas I have for updating.\n\n* Get fresh data probably using opendota api,\n* Publish kernels with code to process whatever data new data is used. \n \nComments on the type of data to get would be helpful, without this I will not likely make an update, since I do not know much about what data is interesting to look at in dota 2.\n\nAdditionally if anyone is interested in spending the time to work on updating the dataset, then publish a kernel, with start on transformation of new data you collected. Otherwise I probably won\'t have an opportunity to work on this until august 2018, at earliest. \n\nhere is thread if you have comments. I will leave discussion open for as long as needed:)\n\nhttps://www.kaggle.com/devinanzelmo/dota-2-matches/discussion/52733 \n\n### Overview\n\nThis dataset contains 50000 ranked ladder matches from the Dota 2 data dump created by Opendota. It was inspired by \nthe [Dota 2 Matches](https://www.kaggle.com/jraramirez/dota-2-matches-dataset) data published here by Joe Ramir. This is an update and improved version of that dataset. I have kept the same image and a similar title.\n\n Dota 2 is a popular MOBA available as free to play, and can take up thousands of hours of your life.  The number of games in this dataset are played about every hour. If you like the data there are an additional 2-3 million matches easily available for download. \n\nThe aim of this dataset is to enable the exploration of player behavior, skill estimation, or anything you find interesting. The intent is to create an accessible, and easy to use resource, which can be expanded and modified if needed.  As such I am open to a wide variety of suggestions as to what additions or changes to make. \n\n### Help getting started\n\nIf there is some aspect of this data you would like to explore but seems difficult to get figure out how to work with please feel free to request some starter code in one of the following two Kernels discussion section. I usually check kaggle every day or so. If you post a request about the current data I will try to get something working. \n\nPython\nhttps://www.kaggle.com/devinanzelmo/d/devinanzelmo/dota-2-matches/misc-howtos-dota-requests-welcome/\n\nR\nhttps://www.kaggle.com/devinanzelmo/d/devinanzelmo/dota-2-matches/howtos-request-welcome/\n\n### Whats Currently Available\n\nSee https://github.com/odota/core/wiki/JSON-Data-Dump for documentaion on data. I have found a few undocumented areas in the data, including the `objectives` information. `player_slot` can be used to combine most of the data, and it is available in most of the tables. Additionally all tables include `match_id`, and some have `account_id` to make it easier to look at an individual players matches. `match_id`, and `account_id` have been reencoded to save a little space. I can upload tables to allow conversion if needed. \n\n - *matches*: contains top level information about each match. \nsee https://wiki.teamfortress.com/wiki/WebAPI/GetMatchDetails#Tower_Status%22tower_status_dire%22:%202047) for interpreting tower and barracks status. Cluster can link matches to geographic region. \n\n - *players*:  Individual players are identified by `account_id` but there is an option to play anonymously and roughly one third of the `account_id` are not available. Anonymous users have the value of `0` for `account_id`. Contains totals for kills, deaths, denies, etc.  Player action counts are available, and are indicated by variable names beginning with `unit_order_`.  Counts for reasons for acquiring or losing gold, and gaining experience, have prefixes `gold_`, and `xp_`. \n\n - *player\\_time*: Contains last hits, experience, and gold sampled at one minute interval for all players in all matches. The column names indicate the player_slot.  For instance `xp_t_1` indicates that this column has experience sums for the player in slot one.\n\n - *teamfights*:  Start and stop time of teamfights, as well as last death time.  Teamfights appear to be all battles  with three or more deaths. As such this does not include all battles for the entire match.\n\n - *teamfights\\_players* :  Additional information provided for each player in each teamfight. `player_slot` can be  used to link this back to `players.csv`\n\n - *objectives*:  Gives information on all the objectives completed, by which player and at what time.\n - *chat*:  All chat for the 50k matches. There is plenty of profanity, and good natured trolling. \n\n - *test\\_labels*: match_id and radiant_win(as integer 1 or 0) \n \n - *test\\_player*: full player and match table with hero_id, player_slot, match_id, and account_id \n\n\n**Nov 5th Update**\n\nAdded several additional tables. None of the previously uploaded data was altered. I plan to add several Kernels in the next week going over how to use the data, and performing some EDA. Many improvements to the player rating method I used are possible for those interested in MMR. \n\n - *player\\_ratings* contains match counts,  win counts, and TrueSkill rating, calculated on 900k matches which occurred prior to other uploaded data. trueskill ratings have two components, `mu`, which can be interpreted as the skill, with higher value being better, and `sigma` which is the uncertainty of the rating. \n - *match\\_outcomes* data for ~900k matches used to calculate player ratings. Use this to improve on the ratings I uploaded.\n - *purchase\\_log* item purchase times\n - *ability\\_upgrade* ability upgrade times and levels\n - *cluster\\_region* allows the mapping cluster found in `match.csv` to geographic region.\n - *patch\\_dates* release dates for various patches, use `start_time` from `match.csv` to determine which patch a match was played in. \n - *ability\\_ids* use with `ability_upgrades.csv` to get the names of upgraded abilities\n - *item\\_ids* use with `purchase_log.csv` to get the names of purchased items\n\n[Kernel showing how player skill was computed][1]: Contains several resources on trueskill rating system.\n\n### Past Research\n\nThere seem to be some efforts to establish indicators for skillfull play based on specific parts of gameplay. Opendota has many statistics, and some analysis for specific benchmarks at different times in the game. Dotabuff has a lot of information I have not explored it deeply. This is an area to gather more information.  \n\n### Some possible directions of investigation\n\nInsight from domain experts would also be useful to help clarify what problems are interesting to work on. Some initial task ideas\n\n - Predict match outcomes based on aggregates for individual players using only account_id as prior information\n - Add hero id to this and see if there is a differences in performance\n - Estimate player skill based on a sample of in game play(this might need an external mmr source or different definition skill)\n - Create improved indicators of skillful play based game actions to help players target areas for improvement\n\nAll of these areas have been worked on, but I am not aware of the most up to date research on dota2 gameplay.\n\nI plan on setting up several different predictive tasks in the upcoming weeks. A test set of an additional 50 to 100 thousand matches with just hero_id, and account_id included along with outcome of the match. \n\nThe current dataset seems pretty small for modeling individual players. I would prefer to have a wide range of features instead of a larger dataset for the moment.  \n\n*Dataset idea* for anyone interested in creating their own Dota 2 dataset. It would be useful to have a few full matches available to work on. They would need to be extracted from the .dem replay file to something easily parsed by R and Python as available in kernels. Given the size of a full match data only a few matches would be needed.  There are files available from opendota\' s website(check for replays).  Looking at fine grained match details would potentially allow for the creation of better high level parsed data. I think it would be a lot of work just to get a handle on working with full match data so a sample would be good to have. \n\n\n### Acknowledgements\n\n[Orginal kaggle dataset on dota2 matches by Joe Ramir](https://www.kaggle.com/jraramirez/dota-2-matches-dataset)\nI also borrowed the image and some of the content for these acknowledgements from the above, thanks!.\n\n[image source](http://media.steampowered.com/apps/dota2/images/blogfiles/keyart_ezalor.jpg)\n\n[Data download source](http://academictorrents.com/details/5c5deeb6cfe1c944044367d2e7465fd8bd2f4acf) created by yasp\n    \nDescription of original dataset creation: https://github.com/yasp-dota/yasp/issues/924\n\nyasp\'s license\n\n""License: CC BY-SA 4.0""\n\n""Terms: We ask that you attribute yasp.co if you create or publish anything related to our data. Also, please seed for as long as possible.""\n\nYasp is now known as opendota here are links to their website and github page\n\nhttps://www.opendota.com/ the data is used to for this site and its a easy way to get familier with it\n\nhttps://github.com/odota/core  check here for info especially [this wiki page](https://github.com/odota/core/wiki/JSON-Data-Dump) which gives details on the schema.\n\n\n  [1]: https://www.kaggle.com/devinanzelmo/d/devinanzelmo/dota-2-matches/dota-2-skill-rating-with-trueskill'","b""['video games', 'large', 'featured']""",https://www.kaggle.com/devinanzelmo/dota-2-matches
b'Tree Census in New York City',b'What tree species are thriving on the streets of each NYC borough?',"b""# Context \n\nNew York City\xe2\x80\x99s trees shade us in the summer, beautify our neighborhoods, help reduce noise, and support urban wildlife. Beyond these priceless benefits, our urban forest provides us a concrete return on the financial investment we put into it. This return includes stormwater interception, energy conservation, air pollutant removal, and carbon dioxide storage. Our publicly owned trees are as much of an asset to us as our streets, sewers, bridges, and public buildings.\n\n\n# Content\n\nThis dataset includes a record for every tree in New York City and includes the tree's location by borough and latitude/longitude, species by Latin name and common names, size, health, and issues with the tree's roots, trunk, and branches.\n\n\n# Acknowledgements\n\nThe 2015, 2005, and 1995 tree censuses were conducted by NYC Parks and Recreation staff, TreesCount! program staff, and hundreds of volunteers.""","b""['plants', 'forestry', 'medium', 'featured']""",https://www.kaggle.com/nycparks/tree-census
"b'The ""Trump Effect"" in Europe'",b'A post-election survey about populism in the US and the EU-28',"b'**Context** \n\nThe election of Donald Trump has taken the world by surprise and is fuelling populist movements in Europe, e.g. in Italy, Austria and France. Understanding populism and assessing the impact of the \xe2\x80\x9cTrump effect\xe2\x80\x9d on Europe is a tremendous challenge, and Dalia wants to help pool brainpower to find answers. \n\nThe goal is to find out where the next wave of populism could hit in Europe by comparing and contrasting US and EU voter profiles, opinions of Trump vs Clinton voters, Brexit vs. Bremain voters, and future expectations.\n\n**Content**\n\nExpanding Dalia\xe2\x80\x99s quarterly ""[EuroPulse][1]"" omnibus survey to the USA, Dalia has conducted a representative survey with n=11.283 respondents across all 28 EU member countries and n=1.052 respondents from the United States of America. To find out where the next wave of populism could hit Europe, Dalia\xe2\x80\x99s survey traces commonalities in social and political mindsets (like authoritarianism, prejudice, open-mindedness, xenophobia, etc.), voting behaviour and socio-demographic profiles on both sides of the Atlantic.\n\n**Inspiration**\n\nThe sources of our inspirations are many, but to name a few who influenced the way we asked questions: we were very inspired by the \'angry voter\' profile laid out by [Douglas Rivers][3], the influence of political and moral attitudes pointed out by [Jonathan Haidt][4] and the profile of ""America\'s forgotten working class"" by [J. D. Vance][5]. \n\n**Researchers should apply the necessary logic, caution and diligence when analysing and interpreting the results.** \n\n\n  [1]: https://daliaresearch.com/europulse/\n  [2]: https://daliaresearch.com/wp-content/uploads/2016/08/Methodology-PDF-1.pdf\n  [3]: http://www.americanacademy.de/home/person/douglas-rivers\n  [4]: https://www.ted.com/speakers/jonathan_haidt\n  [5]: https://www.ted.com/speakers/jd_vance\n  [6]: https://fivethirtyeight.com/'","b""['politics', 'international relations', 'medium', 'featured']""",https://www.kaggle.com/daliaresearch/trump-effect
b'ADS-16 Computational Advertising Dataset',b'A collection of 300 real ads voted by 120 unacquainted individuals',"b""# Context \n\nIn the last decade, new ways of shopping online have increased the possibility of buying products and services more easily and faster than ever. In this new context, personality is a key determinant in the decision making of the consumer when shopping. A person's buying choices are influenced by psychological factors like impulsiveness; indeed some consumers may be more susceptible to making impulse purchases than others. Since affective metadata are more closely related to the user's experience than generic parameters, accurate predictions reveal important aspects of user's attitudes, social life, including attitude of others and social identity. This work proposes a highly innovative research that uses a personality perspective to determine the unique associations among the consumer's buying tendency and advert recommendations. In fact, the lack of a publicly available benchmark for computational advertising do not allow both the exploration of this intriguing research direction and the evaluation of recent algorithms. We present the ADS Dataset, a publicly available benchmark consisting of 300 real advertisements (i.e., Rich Media Ads, Image Ads, Text Ads) rated by 120 unacquainted individuals, enriched with Big-Five users' personality factors and 1,200 personal users' pictures. \n\n\n# Content\n\nThe content of the zip files are folders.\nThe directory tree of this disk is as follows:\n\n20 Ads folder: \n              Ads belong to 20 product/service categories. all the ads are here.\n120  Users Folders:\n             Each folder contains data for one of the involved subjects.\n             300 real advertisements have been scored, Ratings according to the users\xe2\x80\x99 interests (1 star to 5 stars), ~1,200 personal pictures (labelled as positive/negative), Big-Five personality scores (O-C-E-A-N).\n\nData can be easily analysed in Matlab, or Python\n\n# Acknowledgements\nIf you use our dataset please cite:\n\n[1] Roffo, G., & Vinciarelli, A. (2016, August). Personality in computational advertising: A benchmark. In 4 th Workshop on Emotions and Personality in Personalized Systems (EMPIRE) 2016 (p. 18).\n \n\n\n# Inspiration\n\nWe collected and introduced a representative benchmark for computational advertising enriched with affective-like metadata such as personality factors. The benchmark allows to (i) explore the relationship between consumer characteristics, attitude toward online shopping and advert recommendation, (ii) identify the underlying dimensions of consumer shopping motivations and attitudes toward online in-store conversions, and (iii) have a reference benchmark for comparison of state-of-the-art advertisement recommender systems (ARSs). To the best of our knowledge, the ADS dataset is the first attempt at providing a set of advertisements scored by the users according to their interest into the content. \nWe hope that this work motivates researchers to take into account the use of personality factors as an integral part of their future work, since there is a high potential that incorporating these kind of users' characteristics into ARS could enhance recommendation quality and user experience.""","b""['marketing', 'medium', 'featured']""",https://www.kaggle.com/groffo/ads16-dataset
b'The Simpsons by the Data',"b'27 seasons of ""Simpsons did it.""'","b'This dataset contains the characters, locations, episode details, and script lines for approximately 600 Simpsons episodes, dating back to 1989.\n\nInspiration and credit for gathering the data goes to Todd Schneider:\n\nhttp://toddwschneider.com/posts/the-simpsons-by-the-data/  \nhttps://github.com/toddwschneider/flim-springfield'","b""['popular culture', 'medium', 'featured']""",https://www.kaggle.com/wcukierski/the-simpsons-by-the-data
b'Worldwide Economic Remittances',b'Money sent home to family by workers abroad',"b'### Context\n\nIn 2013 alone, international migrants sent $413 billion home to families and friends. This money is known as ""remittance money"", and the total is more than three times that afforded by total global foreign aid ($135 billion). Remittances are traditionally associated with poor migrants moving outside of their home country to find work, supporting their families back home on their foreign wages; as a result, they make up a significant part of the economic picture for many developing countries in the world.\n\nThis dataset, published by the World Bank, provides estimates of 2016 remittance movements between various countries. It also provides historical data on the flow of such money going back to 1970.\n\nFor a look at how remittances play into the global economy, watch ""[The hidden force in global economics: sending money home](https://www.ted.com/talks/dilip_ratha_the_hidden_force_in_global_economics_sending_money_home?language=en)"".\n\n### Content\n\nThis dataset contains three files:\n\n* `bilateral-remittance.csv` --- Estimated remittances between world countries in the year 2016.\n* `remittance-inflow.csv` --- Historical remittance money inflow into world countries since 1970. Typically high in developing nations.\n* `remittance-outflow.csv` --- Historical remittance money outflow from world countries since 1970. Typically high in more developed nations.\n\nAll monetary values are in terms of millions of US dollars.\n\nFor more information on how this data was generated and calculated, refer to the [World Bank Remittance Data FAQ](http://www.worldbank.org/en/topic/migrationremittancesdiasporaissues/overview).\n\n### Acknowledgements\n\nThis dataset is a republished version of three of the tables published by the World Bank which has been slightly cleaned up for use on Kaggle. For the original source, and other complimentary materials, check out the [dataset home page](http://www.worldbank.org/en/topic/migrationremittancesdiasporaissues/brief/migration-remittances-data).\n\n### Inspiration\n\n* What is the historical trend in remittance inflows and outflows for various countries? How does this relate to the developmental character of the countries in question?\n* What countries send to most money abroad? What countries receive the most money from abroad? Try combining this dataset with a demographics dataset to see what countries are most and least reliant on income from abroad.\n* How far do workers migrate for a job? Are they staying near home, or going half the world away? Are there any surprising facts about who send money to who?'","b""['economics', 'demographics', 'countries', 'international relations', 'globalization', 'small', 'featured']""",https://www.kaggle.com/theworldbank/worldwide-economic-remittances
b'US Mass Shootings ',b'Last 50 Years (1966-2017)',"b""### Context\n\nMass Shootings in the United States of America (1966-2017)\nThe US has witnessed 398 mass shootings in last 50 years that resulted in 1,996 deaths and 2,488 injured. The latest and the worst mass shooting of October 2, 2017 killed 58 and injured 515 so far. The number of people injured in this attack is more than the number of people injured in all mass shootings of 2015 and 2016 combined. \nThe average number of mass shootings per year is 7 for the last 50 years that would claim 39 lives and 48 injured per year. \n\n### Content\n\nGeography: United States of America\n\nTime period: 1966-2017\n\nUnit of analysis: Mass Shooting Attack\n\nDataset: The dataset contains detailed information of 398 mass shootings in the United States of America that killed 1996 and injured 2488 people.  \n\nVariables: The dataset contains Serial No, Title, Location, Date, Summary, Fatalities, Injured, Total Victims, Mental Health Issue, Race, Gender, and Lat-Long information.\n\n### Acknowledgements\n\nI\xe2\x80\x99ve consulted several public datasets and web pages to compile this data.  Some of the major data sources include [Wikipedia][1], [Mother Jones][2], [Stanford][3], [USA Today][4] and other web sources. \n\n### Inspiration\n\nWith a broken heart, I like to call the attention of my fellow Kagglers to use Machine Learning and Data Sciences to help me explore these ideas:\n\n\xe2\x80\xa2\tHow many people got killed and injured per year?\n\n\xe2\x80\xa2\tVisualize mass shootings on the U.S map\n\n\xe2\x80\xa2\tIs there any correlation between shooter and his/her race, gender\n\n\xe2\x80\xa2\tAny correlation with calendar dates? Do we have more deadly days, weeks or months on average\n\n\xe2\x80\xa2\tWhat cities and states are more prone to such attacks\n\n\xe2\x80\xa2\tCan you find and combine any other external datasets to enrich the analysis, for example, gun ownership by state\n\n\xe2\x80\xa2\tAny other pattern you see that can help in prediction, crowd safety or in-depth analysis of the event\n\n\xe2\x80\xa2\tHow many shooters have some kind of mental health problem? Can we compare that shooter with general population with same condition\n\n### Mass Shootings Dataset Ver 3\n\nThis is the new Version of Mass Shootings Dataset. I've added eight new variables:\n\n1.       Incident Area (where the incident took place), \n2.       Open/Close Location (Inside a building or open space) \n3.       Target (possible target audience or company), \n4.       Cause (Terrorism, Hate Crime, Fun (for no obvious reason etc.)\n5.       Policeman Killed (how many on duty officers got killed)\n6.       Age (age of the shooter)\n7.       Employed (Y/N) \n8.       Employed at  (Employer Name)\n\nAge, Employed and Employed at (3 variables) contain shooter details\n\n### Mass Shootings Dataset Ver 4\n\nQuite a few missing values have been added\n\n### Mass Shootings Dataset Ver 5\n\nThree more recent mass shootings have been added including the Texas Church shooting of November 5, 2017\n\n\nI hope it will help create more visualization and extract patterns. \n\nKeep Coding!\n\n\n  [1]: https://en.wikipedia.org/wiki/Category:Mass_shootings_in_the_United_States_by_year\n  [2]: http://www.motherjones.com/politics/2012/12/mass-shootings-mother-jones-full-data/\n  [3]: https://library.stanford.edu/projects/mass-shootings-america\n  [4]: http://www.gannett-cdn.com/GDContent/mass-killings/index.html#title""","b""['crime', 'united states', 'terrorism', 'violence', 'small', 'featured']""",https://www.kaggle.com/zusmani/us-mass-shootings-last-50-years
b'Worldnews on Reddit from 2008 to Today',b'Perfect for NLP or other tasks',"b""Reddit is a social network which divide topics into so called 'subreddits'.\n\nIn subreddit 'worldnews', news of the whole world are published. The dataset contains following columns:\ntime_created - a Unix timestamp of the submission creation date\ndate_created - creation time in %Y-%m-%d\nup_votes - how often the submission was upvoted\ndown_votes - how often the submission was downvoted\ntitle - the title of the submission\nover_18 - if the submission is for mature persons\nauthor - the reddit username of the author\nsubreddit - this is always 'worldnews'\n\nWith the dataset, you can estimate several things in contrast to world politics and special events.""","b""['internet', 'linguistics', 'news agencies', 'medium', 'featured']""",https://www.kaggle.com/rootuser/worldnews-on-reddit
b'Circadian Rhythm in the Brain',b'Fluorescence signal from the circadian regulation region of the brain',"b'# Overview\nThe data are a time-series of fluorescence images measured of  at OHSU Lab of Charles Allen (https://www.ohsu.edu/xd/research/centers-institutes/oregon-institute-occupational-health-sciences/research/allen/).\n\n## Introduction\n\nWe use a fluorescent protein as a reporter for the circadian clock gene Period1. We are able to follow the expression of this gene in many neurons for several days to understand how the neural network in the suprachiasmatic nucleus synchronizes the circadian clock of individual neurons to produce a precise circadian rhythm. We analyze each image to determine the fluorescence intensity of each neuron over multiple\ncircadian cycles. \n## FAQ\n\n### How where the images obtained: which animal and what staining?\n\nThe images were taken from a transgenic mouse in which expression of the fluorescent protein Venus is driven by the promoter for the circadian clock gene Period 1.\n\n### What is the anatomy of the images, and how are they oriented?\n\nThe bright line is the third ventricle, which resides on the midline of the brain. The two bright regions on either side of the ventricle are the two portions of the Suprachiasmatic nucleus (SCN). Below the ventricle and the SCN is a dark horizontal band that represents the optic chasm. \n\n### What is the bright vertical line in the top middle?\n\nThe bright line is the third ventricle. Pericytes that line the ventricle express the Venus at very high levels. We don\'t know the function of the circadian clock in these cells.  \n\n## Challenge\n\nCurrently we have to analyze each experiment by hand to follow an individual through a couple hundred images. This takes several days. This problem is going to get worse because we have just purchased a new automated microscope stage that will allow us to simultaneously image\nfrom four suprachiasmatic nuclei. \n\n# Preview\n\n<div style=""position:relative;height:0;padding-bottom:75.0%""><iframe src=""https://www.youtube.com/embed/2kx1LM_AU-0?ecver=2"" width=""480"" height=""360"" frameborder=""0"" style=""position:absolute;width:100%;height:100%;left:0"" allowfullscreen></iframe></div>\n\n[![Video of Measurements](https://img.youtube.com/vi/2kx1LM_AU-0/0.jpg)](https://www.youtube.com/watch?v=2kx1LM_AU-0)\n\n# Ideas for Analysis\n- Wavelets (pywavelets) following https://www.ncbi.nlm.nih.gov/pubmed/18931366 \n\n# Questions\n\n - Do the cells move during the experiment? \n - How regular is their signal?\n - Is the period 24 hours?\n - Do nearby cells oscillate together?\n - Do they form chunks or groups, over what range do they work?\n - Are there networks formed from time-precedence?'","b""['neuroscience', 'large', 'featured']""",https://www.kaggle.com/kmader/circadian-rhythm-in-the-brain
b'Eurfa Welsh Dictionary',"b'212,403 word dictionary of Welsh'","b'### Context: \n\nWelsh is a member of the Brittonic branch of the Celtic languages. It is spoken natively in Wales, by some in England, and in Y Wladfa (the Welsh colony in Chubut Province, Argentina). Historically, it has also been known in English as \xe2\x80\x98Cambrian\xe2\x80\x99, \xe2\x80\x98Cambric\xe2\x80\x99 and \xe2\x80\x98Cymric\xe2\x80\x99. The current number of Welsh speakers in Wales is over 562,000.\n\n### Content: \n\nEurfa is the largest Welsh dictionary under a free license, and it was the first dictionary of a Celtic language to list verbal inflections and mutated forms. It also includes in-context citations for most words from a number of corpora:\n\nBilingual (Welsh-English, Welsh-Spanish):\n\n* The 18m-word Kynulliad3 corpus (K3). This contains formal written Welsh (the majority of it translated from English).\n* The 450k-word Siarad corpus (S). These transcribed conversations contain ""Welsh as she is spoke"", including English codeswitches. For readability, the version here (download) removes much of the transcription marking.\n* The 200k-word Patagonia corpus (P). These transcribed conversations contain spoken Welsh from Patagonia. This has fewer codeswitches, and many of them are in Spanish rather than English. For readability, the version here (download) removes much of the transcription marking.\n* The 200k-word Korrect/Kywiro corpus (Ko). This contains Welsh translations of English text in free/open software programs.\n\nMonolingual (Welsh only)\n\n* A 220k-word subset of the 300k-word CIG1 child (18-30 months) language acquisition corpus (Kig1), containing non-child utterances only. The version here removes much of the transcription marking.\n* A 100k-word subset of the 560k-word CIG2 child (3-7 years) language acquisition corpus (Kig2), containing non-child utterances only. The version here removes much of the transcription marking.\n\n### Acknowledgements: \n\nThis dictionary was created by  Kevin Donnelly and is redistributed here under the GNU General Public License. For more information, see the attached LICENSE file.\n\n### You may also like:\n\n* [4 million word corpus of contemporary Welsh](https://www.kaggle.com/rtatman/kwici-welsh-wikipedia-corpus/)'","b""['linguistics', 'europe', 'languages', 'medium', 'featured']""",https://www.kaggle.com/rtatman/eurfa-welsh-dictionary
b'Patent Grant Full Text',b'Contains the full text of each patent grant issued weekly for 10/11/2016',"b'# [Grant Red Book (GRB)][1] Full Text\n\n## Context\n\nEvery Tuesday, the US Patent and Trademark Office (USPTO) issues approximately 6,000 patent grants (patents) and posts the full text of the patents online. These patent grant documents contain much of the supporting details for a given patent. From this data, we can track trends in innovation across industries.\n\n* **Frequency**: Weekly (Tuesdays)\n* **Period**: 10/11/2016\n\n## Content\n\nThe fields include patent number, series code and application number, type of patent, filing date, title, issue date, applicant information, inventor information, assignee(s) at time of issue, foreign priority information, related US patent documents, classification information (IPCR, CPC, US), US and foreign references, attorney, agent or firm/legal representative, examiner, citations, Patent Cooperation Treaty (PCT) information, abstract, specification, and claims.\n\n### Inspiration\n\nHow many times will you find \xe2\x80\x9csome assembly required\xe2\x80\x9d? What inventions are at the cutting edge of machine learning? To answer these questions and any others you may have about this catalog of knowledge, fork the kernel [Library of Inventions and Innovations][2] which demonstrates how to work with XML files in Python.\n\n![Library of inventions and innovations][3]\n\n## Acknowledgements\n\nThe USPTO owns the dataset. These files are a subset and concatenation of the Patent Grant Data/XML Version 4.5 ICE (Grant Red Book). Because of the concatenation of the individual XML documents, these files will not parse successfully or open/display by default in Internet Explorer. They also will not import into MS Excel. Each XML document within the file should have one start tag and one end tag. Concatenation creates a file that contains 6,000 plus start/end tag combinations. If you take one document out of the Patent Grant Full Text file and place it in a directory with the correct DTD and then double click that individual document, Internet Explorer will parse/open the document successfully. NOTE:  You may receive a warning about Active X controls. NOTE:  All Patent Grant Full Text files will open successfully in MS Word; NotePad; WordPad; and TextPad.\n\n## License\n\n[Creative Commons - Public Domain Mark 1.0][4]\n\n\n  [1]: https://www.uspto.gov/learning-and-resources/xml-resources\n  [2]: https://www.kaggle.com/the1owl/d/uspto/patent-grant-full-text/library-of-inventions-and-innovations\n  [3]: https://www.kaggle.io/svf/414669/d3dada6fe220c7cfe62881c49a433327/__results___files/__results___8_0.png\n  [4]: http://creativecommons.org/publicdomain/mark/1.0'","b""['law', 'medium', 'featured']""",https://www.kaggle.com/uspto/patent-grant-full-text
b'BLLIP Parser Model',b'Charniak-Johnson parser',"b'### Context\n\nNLTK provides an interface to the [BLLIP reranking parser](http://pypi.python.org/pypi/bllipparser/) (aka Charniak-Johnson parser, Charniak parser, Brown reranking parser). \n\nNLTK redistribute the pre-trained model trained on the WSJ section of the Penn Treebank without auxillary. \n\nThe full list of models can be found on https://github.com/BLLIP/bllip-parser/blob/master/MODELS.rst\n\n### Acknowledgements\n\nParser and reranker:\n\n    Eugene Charniak and Mark Johnson. 2005. ""Coarse-to-fine n-best \n    parsing and MaxEnt discriminative reranking."" In ACL.\n    \n    Eugene Charniak. 2000. ""A maximum-entropy-inspired parser."" In ACL.\n\nSelf-training:\n\n    David McClosky, Eugene Charniak, and Mark Johnson. 2006. \n    ""Effective Self-Training for Parsing."" In HLT-NAACL.\n\nSyntactic fusion:\n\n    Do Kook Choe, David McClosky, and Eugene Charniak. 2015. \n    ""Syntactic Parse Fusion."" In EMNLP.'","b""['medium', 'featured']""",https://www.kaggle.com/nltkdata/bllip
"b'Structural MRI Datasets (T1, T2, FLAIR etc.)'",b'Coursera NeuroHacking in R course datasets',"b'# Context \n\nData from the Coursera Course: ***Neurohacking In R*** taught by \nDr. Elizabeth Sweeney , Rice Academy Postdoctoral Fellow,  Ciprian M. Crainiceanu, Professor and John Muschelli III , Assistant Scientist\n\nPlease see https://www.coursera.org/learn/neurohacking for the lecture notes and example code from the instructors.\n\n\n# Content\nStructural MRI images for visualization and image processing\n\nFrom the instructors:\n\n*About this course: Neurohacking describes how to use the R programming language (https://cran.r-project.org/) and its associated packages to perform manipulation, processing, and analysis of neuroimaging data. We focus on publicly-available structural magnetic resonance imaging (MRI). We discuss concepts such as inhomogeneity correction, image registration, and image visualization. By the end of this course, you will be able to: Read/write images of the brain in the NIfTI (Neuroimaging Informatics Technology Initiative) format Visualize and explore these images, perform inhomogeneity correction, brain extraction, and image registration (within a subject and to a template).*\n\n\n\n\n# Acknowledgements\n\nDataset is public domain and was originally posted for the Coursera online course NeuroHacking in R.\n\n\n#Notes\nA. When you download the zip archive, double clicking might try to compress the file instead of extracting it. Unzipping on terminal (mac) correctly decompresses the archive.\n\nB.\nThe zip file contains a directory structure: \n      \n\n           BRAINIX\n                -----DICOM\n                    ----FLAIR\n                    ----ROI\n                    ----T1\n                    ----T2\n                -----NIFTI\n          kirby21\n                -----visit 1\n                    ----113\n                -----visit 2\n                    ----113\n          Template\n\nHowever, when it is unzipped here on Kaggle environment, somehow the directory structure is not maintained, therefore files with the same names are being overwritten. As a workaround, I added the directory names to the files\nie. BRAINIX_DICOM_T1_IM_0001_0011.dcm instead of just IM_0001_0011.dcm. \n\n\nCheck out script https://www.kaggle.com/ilknuricke/d/ilknuricke/neurohackinginrimages/structural-mri-visualization/code for example use.'","b""['healthcare', 'medium', 'featured']""",https://www.kaggle.com/ilknuricke/neurohackinginrimages
b'The Zurich Urban Micro Aerial Vehicle Dataset',"b'For appearance-based localization, visual odometry, and SLAM'","b""### Context \n\n*This dataset was originally published by the University of Zurich Robotics and Perception Group [here][1]. A sample of the data along with accompanying descriptions is provided here for research uses.*\n\nThis presents the world's first dataset recorded on-board a camera equipped Micro Aerial Vehicle (MAV) flying within urban streets at low altitudes (i.e., 5-15 meters above the ground). The 2 km dataset consists of time synchronized aerial high-resolution images, GPS and IMU sensor data, ground-level street view images, and ground truth data. The dataset is ideal to evaluate and benchmark appearance-based topological localization, monocular visual odometry, simultaneous localization and mapping (SLAM), and online 3D reconstruction algorithms for MAV in urban environments.\n\n### Content\n\nThe entire dataset is roughly 28 gigabyte. We also provide a sample subset less than 200 megabyte, representing the first part of the dataset. [You can download the entire dataset from this page][2].\n\nThe dataset contains time-synchronized high-resolution images (1920 x 1080 x 24 bits), GPS, IMU, and ground level Google-Street-View images. The high-resolution aerial images were captured with a rolling shutter GoPro Hero 4 camera that records each image frame line by line, from top to bottom with a readout time of 30 millisecond. A summary of the enclosed files is given below.\n\nThe data from the on-board barometric pressure sensor BarometricPressure.csv, accelerometer RawAccel.csv, gyroscope RawGyro.csv, GPS receiver OnbordGPS.csv, and pose estimation OnboardPose.csv is logged and timesynchronized using the clock of the PX4 autopilot board. The on-board sensor data was spatially and temporally aligned with the aerial images. The first column of every file contains the timestamp when the data was recorded expressed in microseconds. In the next columns the sensor readings are stored. The second column in OnbordGPS.csv encodes the identification number (ID) of every aerial image stored in the /MAV Images/ folder. The first column in GroundTruthAGL.csv is the ID of the aerial image, followed by the ground truth camera position of the MAV and the raw GPS data. The second column in GroundTruthAGM.csv is the ID of of the aerial image, followed by the ID of the first, second and third best match ground-level street view image in the /Street View Img/ folder.\n\n### Ground Truth\n\nTwo types of ground truth data are provided in order to evaluate and benchmark different vision-based localization algorithms. Firstly, appearance-based topological localization algorithms, that match aerial images to street level ones, can be evaluated in terms of precision rate and recall rate. Secondly, metric localization algorithms, that computed the ego-motion of the MAV using monocular visual SLAM tools, can be evaluated in terms of standard deviations from the ground truth path of the vehicle.\n\n[See more details here][3].\n\n### Past Research\n\nThe work listed below inspired the recording of this dataset. In these papers a much smaller dataset was used, that did not contain time synchronized GPS (except a small street segment ), IMU data and accurate metric ground truth.  If you used this dataset, please send your paper to majdik (at) ifi (dot) uzh (dot) ch. \n\nA.L. Majdik, D. Verda, Y. Albers-Schoenberg, D. Scaramuzza. Air-ground Matching: Appearance-based GPS-denied Urban Localization of Micro Aerial Vehicles Journal of Field Robotics, 2015.\n\nA. L. Majdik, D. Verda, Y. Albers-Schoenberg, D. Scaramuzza Micro Air Vehicle Localization and Position Tracking from Textured 3D Cadastral Models IEEE International Conference on Robotics and Automation (ICRA), Hong Kong, 2014.\n\nA. Majdik, Y. Albers-Schoenberg, D. Scaramuzza. MAV Urban Localization from Google Street View Data\nIEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Tokyo, 2013.\n\n### License\n\nThese datasets are released under the Creative Commons license (CC BY-NC-SA 3.0), which is free for non-commercial use (including research). \n\n### Acknowledgements\n\nThis dataset was recorded with the help of Karl Schwabe, Mathieu Noirot-Cosson, and Yves Albers-Schoenberg. To record the dataset we used a Fotokite MAV offered to our disposal by Perspective Robotics AG\xe2\x80\x94http://fotokite.com. \n\nThis work was supported by the National Centre of Competence in Research Robotics (NCCR) through the Swiss National Science Foundation and by the Hungarian Scientific Research Fund (No. OTKA/NKFIH 120499).\n\n\n  [1]: http://rpg.ifi.uzh.ch/zurichmavdataset.html\n  [2]: http://rpg.ifi.uzh.ch/zurichmavdataset.html\n  [3]: http://rpg.ifi.uzh.ch/zurichmavdataset.html""","b""['cities', 'vehicles', 'medium', 'featured']""",https://www.kaggle.com/mrisdal/zurich-urban-micro-aerial-vehicle
b'Darknet Market Cocaine Listings',b'How much does cocaine cost on the internet?',"b'The dataset is approximately 1,400 cleaned and standardized product listings from Dream Market\'s ""Cocaine"" category. It was collected with web-scraping and text extraction techniques in July 2017.\n\nExtracted features for each listing include:\n\n* product_title\n\n* ships_from_to\n\n* quantity in grams\n\n* quality\n\n* btc_price\n\n* vendor details\n\n* shipping dummy variables (true/false columns)\n\nFor further details on the creation of this dataset and what it contains, see the blog post here: https://medium.com/thought-skipper/dark-market-regression-calculating-the-price-distribution-of-cocaine-from-market-listings-10aeff1e89e0\n'","b""['internet', 'economics', 'crime', 'illegal drugs', 'small', 'featured']""",https://www.kaggle.com/everling/cocaine-listings
b'AI2 Science Questions',"b'2,707 multiple choice science questions from student assessments'","b'# Context \n\n[Project Aristo][1] at the [Allen Institute for Artificial Intelligence][2] (AI2) is focused on building a system that acquires and stores a vast amount of knowledge in computable form, then applies this knowledge to answer a variety of science questions from standardized exams for students in multiple grade levels. We are inviting the wider AI research community to work on this grand challenge with us by providing this dataset of student science assessment questions.\n\n# Content\n\nThese are English language questions that span several grade levels as indicated in the files. Each question is a 4-way multiple choice structure. Some of these questions include a diagram, either as part of the question text, as an answer option, or both. The diagrams are represented in the text with filenames that correspond to the diagram file itself in the companion folder. These questions come pre-split into Train, Development, and Test sets.\n\nThe data set includes the following fields:\n\n - **questionID**: a unique identifier for the question \n - **originalQuestionID**: the question number on the test\n - **totalPossiblePoints**: how many points the question is worth\n - **AnswerKey**: the correct answer option\n - **isMultipleChoiceQuestion**: 1 = multiple choice, 0 = other\n - **includesDiagram**: 1 = includes diagram, 0 = other\n - **examName**: the source of the exam\n - **schoolGrade**: grade level\n - **year**: year the source exam was published\n - **question**: the question itself\n - **subject**: Science\n - **category**: Test, Train, or Dev (data comes pre-split into these categories)\n\n# Evaluation\n\nAI2 has made available [Aristo mini][3], a light-weight question answering system that can quickly evaluate science questions with an evaluation web server and provided baseline solvers. You can extend the provided solvers with your own implementation to try out new approaches and compare results.\n\n# Acknowledgements\n\nThe Aristo project team at AI2 compiled this dataset and we use it actively in our research. For a description of the motivations and intention for this data, please see:\n\nClark, Peter. \xe2\x80\x9c[Elementary School Science and Math Tests as a Driver for AI: Take the Aristo Challenge!][4]\xe2\x80\x9d AAAI (2015).\n\n\n  [1]: http://allenai.org/aristo/\n  [2]: http://allenai.org/index.html\n  [3]: https://github.com/allenai/aristo-mini\n  [4]: https://www.semanticscholar.org/paper/Elementary-School-Science-and-Math-Tests-as-a-Clark/818b92bfad6e11d849bae552be60111579d91e91'","b""['linguistics', 'artificial intelligence', 'medium', 'featured']""",https://www.kaggle.com/allenai/ai2-science-questions
b'Foreign Direct Investment in India',b'Sector & Financial year wise time series data from 2000-2016.',b'**Connect/Follow me on [LinkedIn](http://link.rajanand.org/linkedin) for more updates on interesting dataset like this. Thanks.**\n\n### Context\n\nTo understand the Foreign direct investment in India for the last 17 years from 2000-01 to 2016-17.\n\n### Content\n\nThis dataset contains sector and financial year wise data of FDI in India.\n\n### Acknowledgements\n\n[Ministry of Commerce and Industry](http://commerce.gov.in/EIDB.aspx) has published Financial Year wise FDI Equity Inflows from 2000-01 to 2016-17 dataset in [Open Government Data Platform India](https://data.gov.in/catalog/foreign-direct-investment-fdi-equity-inflows) under [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).\n\n### Inspiration\n  \n  \n  - How much FDI has changed over the year?\n  - How much has varied since 2014 after Narendra Modi become PM of India?',"b""['finance', 'india', 'small', 'featured']""",https://www.kaggle.com/rajanand/fdi-in-india
b'Biodiversity in National Parks',b'Plant and animal species found in the American national park system',"b'# Context \n\nThe National Park Service&nbsp;publishes a database of animal and plant species identified in individual national parks and verified by evidence \xe2\x80\x94 observations, vouchers, or reports that document the presence of a species in a park. All park species records are available to the public on the National Park Species portal; exceptions are made for sensitive, threatened, or endangered species when widespread distribution of information could pose a risk to the species in the park.\n\n\n# Content\n\nNational Park species lists provide information on the presence and status of species in our national parks. These species lists are works in progress and the absence of a species from a list does not necessarily mean the species is absent from a park. The time and effort spent on species inventories varies from park to park, which may result in data gaps. Species taxonomy changes over time and reflects regional variations or preferences; therefore, records may be listed under a different species name.\n\nEach park species record includes a species ID, park name, taxonomic information, scientific name, one or more common names, record status, occurrence (verification of species presence in park), nativeness (species native or foreign to park), abundance (presence and visibility of species in park), seasonality (season and nature of presence in park), and conservation status (species classification according to US Fish & Wildlife Service). Taxonomic classes have been translated from Latin to English for species categorization; order, family, and scientific name (genus, species, subspecies) are in Latin.\n\n\n# Acknowledgements\n\nThe National Park Service species list database is managed and updated by staff at individual national parks and the systemwide Inventory and Monitoring department.\n\nSource: https://irma.nps.gov/NPSpecies\n\nUsers interested in getting this data via web services, please go to:  http://irmaservices.nps.gov'","b""['animals', 'plants', 'ecology', 'medium', 'featured']""",https://www.kaggle.com/nationalparkservice/park-biodiversity
b'Chicago - Citywide Payroll Data',b'Salaries paid to Chicago employees',"b'### Context\n\nThis dataset contains the name, job title, department, and salary of every employee that was on the City of Chicago payroll at the time of capture in mid-2017. It provides a transparent lens into who gets paid how much and for what.\n\n### Content\n\nThis dataset provides columns for employee name, the city department they work for, their job title, and various fields describing their compensation. Most employee salaries are covered by the `Annual Salary` field, but some employees paid hourly are covered by a combination of `Typical Hours` and `Hourly Rate` fields.\n\n### Acknowledgements\n\nThis dataset is published as-is by the City of Chicago ([here](https://data.cityofchicago.org/Administration-Finance/Current-Employee-Names-Salaries-and-Position-Title/xzkq-xp2w)).\n\n### Inspiration\n\n* How many people do the various city agencies employ, and how much does each department spend on salary in total?\n* What are the most numerous job titles in civic government employment?\n* How do Chicago employee salaries compare against [salaries of city employees in New York City](https://www.kaggle.com/new-york-city/nyc-citywide-payroll-data)? Is the difference more or less than the difference in cost of living between the two cities?'","b""['cities', 'money', 'small', 'featured']""",https://www.kaggle.com/chicago/chicago-citywide-payroll-data
b'U.S. Major League Soccer Salaries',b'Salaries from 2007 to 2017',"b""### Context\n\nThe Major League Soccer Union releases the salaries of every MLS player each year. This is a collection of salaries from 2007 to 2017.\n\n\n### Content\n\nEach file contains the following fields:\n\n- club: Team abbreviation\n- last_name: Player last name\n- first_name: Player first name\n- position: Position abbreviation\n- base_salary: Base salary\n- guaranteed_compensation: Guaranteed compensation\n\n### Acknowledgements\n\nJeremy Singer-Vine over at Data is Plural scraped the PDF's released by the MLS Union and put the data in a nice little package of CSV files for everyone.\n\nI downloaded this dataset from:\n[https://github.com/data-is-plural/mls-salaries][1]\n[MIT License][2]\n\n### Inspiration\n\nWho in the MLS makes the most money? Are they worth it? I make about $900 bazillion each year, can I afford a soccer team?\n\n\n  [1]: https://github.com/data-is-plural/mls-salaries\n  [2]: https://github.com/data-is-plural/mls-salaries/blob/master/LICENSE.txt""","b""['association football', 'income', 'small', 'featured']""",https://www.kaggle.com/crawford/us-major-league-soccer-salaries
b'Popular websites across the globe',b'General information on some of the most viewed sites country wise',"b""### Context \n\nThis dataset includes some of the basic information of the websites we daily use. \nWhile scrapping this info, I learned quite a lot in R programming, system speed, memory usage etc. and developed my niche in Web Scrapping. It took about 4-5 hrs for scrapping this data through my system (4GB RAM) and nearly about 4-5 days working out my idea through this project. \n\n### Content\nThe dataset contains Top 50 ranked sites from each 191 countries along with their traffic (global) rank. Here, country_rank represent the traffic rank of that site within the country, and traffic_rank represent the global traffic rank of that site. \n\nSince most of the columns meaning can be derived from their name itself, its pretty much straight forward to understand this dataset. However,  there are some instances of confusion which I would like to explain in here:\n\n1) most of the numeric values are in character format, hence, contain spaces which you might need to clean on.\n\n2) There are multiple instances of same website. for.e.g. Yahoo. com is present in 179 rows within this dataset. This is due to their different country rank in each country. \n\n3)The information provided in this dataset is for the top 50 websites in 191 countries as on 25th May 2017 and is subjected to change in future time due to the dynamic structure of ranking.\n\n4) The dataset inactual contains 9540 rows instead of 9550(50*191 rows). This was due to the unavailability of information for 10 websites. \n\nPS: in case if there are anymore queries, comment on this, I'll add an answer to that in above list.\n\n### Acknowledgements\n\nI wouldn't have done this without the help of others. I've scrapped this information from publicly available (open to all) websites namely: \n1) http://data.danetsoft.com/ \n2) http://www.alexa.com/topsites , \n**of which i'm highly grateful**. I truly appreciate and thanks the owner of these sites for providing us with the information that I included today in this dataset.\n\n### Inspiration\n\nI feel that there this a lot of scope for exploring & visualization this dataset to find out the trends in the attributes of these websites across countries. Also, one could try predicting the traffic(global) rank being a dependent factor on the other attributes of the website. In any case, this dataset will help you find out the popular sites in your area.""","b""['internet', 'world', 'small', 'featured']""",https://www.kaggle.com/bpali26/popular-websites-across-the-globe
"b'Vehicle Collisions in NYC, 2015-Present'",b'Where are the most pedestrians struck by vehicles in New York City?',"b'# Content\n\nThe motor vehicle collision database includes the date and time, location (as borough, street names, zip code and latitude and longitude coordinates), injuries and fatalities, vehicle number and types, and related factors for all 65,500 collisions in New York City during 2015 and 2016.\n\n\n# Acknowledgements\n\nThe vehicle collision data was collected by the NYPD and published by NYC OpenData.'","b""['road transport', 'walking', 'medium', 'featured']""",https://www.kaggle.com/nypd/vehicle-collisions
b'State Election Results 1971 - 2012',"b'Results for 72,000 elections'","b'### Context\n\nThis dataset contains results of general elections to the lower house of the state legislatures in the United States over the last fifty years, up to 2012. This dataset was created by [the Princeton Gerrymandering Project](gerrymander.princeton.edu) as part of their effort to analyze and combat partisan gerrymandering. The Supreme Court will be hearing [a very important case on this issue](http://www.scotusblog.com/2017/09/argument-preview-justices-tackle-partisan-gerrymandering/) on October 3rd 2017. Regardless of who wins, this dataset will be of interest to anyone hoping to defeat (or achieve!) a gerrymandering attempt.\n\n### Content\n\nEach row represents one election, from the perspective of the winner. For example, the first row of the data should be read as a victory for a Democrat who was not the incumbent.\n\n### Acknowledgements\n\nThis dataset was kindly made available by the Princeton Gerrymandering Project. You can find [their copy, detailed discussion of the data, and their code here][1].\n\n  [1]: https://github.com/PrincetonUniversity/historic_state_legislative_election_results'","b""['politics', 'political science', 'small', 'featured']""",https://www.kaggle.com/sohier/state-election-results-1971-2012
b'COMPAS Recidivism Racial Bias',b'Racial Bias in inmate COMPAS reoffense risk scores for Florida (ProPublica)',"b'### Context\nCOMPAS (Correctional Offender Management Profiling for Alternative Sanctions) is a popular commercial algorithm used by judges and parole officers for scoring criminal defendant\xe2\x80\x99s likelihood of reoffending (recidivism). It has been shown that the algorithm is biased in favor of white defendants, and against black inmates, based on a 2 year follow up study (i.e who actually committed  crimes or violent crimes after 2 years). The pattern of mistakes, as measured by precision/sensitivity is notable. \n\nQuoting from ProPublica:\n""\n> Black defendants were often predicted to be at a higher risk of recidivism than they actually were. Our analysis found that black defendants who did not recidivate over a two-year period were nearly twice as likely to be misclassified as higher risk compared to their white counterparts (45 percent vs. 23 percent).\nWhite defendants were often predicted to be less risky than they were. Our analysis found that white defendants who re-offended within the next two years were mistakenly labeled low risk almost twice as often as black re-offenders (48 percent vs. 28 percent).\nThe analysis also showed that even when controlling for prior crimes, future recidivism, age, and gender, black defendants were 45 percent more likely to be assigned higher risk scores than white defendants.\n\n - Black defendants were also twice as likely as white defendants to be misclassified as being a higher risk of violent recidivism. And white violent recidivists were 63 percent more likely to have been misclassified as a low risk of violent recidivism, compared with black violent recidivists.\n - The violent recidivism analysis also showed that even when controlling for prior crimes, future recidivism, age, and gender, black defendants were 77 percent more likely to be assigned higher risk scores than white defendants.\n""\n\n### Content\nData contains  variables used by the COMPAS algorithm in scoring defendants, along with their outcomes within 2 years of the decision, for over 10,000 criminal defendants in Broward County, Florida. \n3 subsets of the data are provided, including a subset of only violent recividism (as opposed to, e.g. being reincarcerated for non violent offenses such as vagrancy or Marijuana).\n\nIndepth analysis by ProPublica can be found in their [data methodology article][1].\n\n### Acknowledgements\n\nData & original analysis gathered by ProPublica. \nOriginal Data methodology article:\nhttps://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm\n\nOriginal Article:\nhttps://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\n\nOriginal data from ProPublica:\nhttps://github.com/propublica/compas-analysis\n\nAdditional ""simple"" subset provided by FairML, based on the proPublica data:\n\nhttp://blog.fastforwardlabs.com/2017/03/09/fairml-auditing-black-box-predictive-models.html\n\n### Inspiration\n\nIdeas:\n\n - Feature importance when predicting the COMPASS score itself, or recividism/crime risks.\n - Reweighting data to compensate for bias, e.g. subsetting for the violent offenders, or adjusting better for base risk. \n - Feature selection based on ""legal usage""/fairness (E.g. exclude race and see how well your model works. It worked for me).\n\n\n  [1]: https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm'","b""['demographics', 'crime', 'law', 'medium', 'featured']""",https://www.kaggle.com/danofer/compass
b'Rio de Janeiro Crime Records',b'Crime records from Rio de Janeiro State',"b""### Context\n\nRio de Janeiro is one of the most beautiful and famous city in the world. Unfortunately, it's also one of the most dangerous. For the last years, in a scenario of economical and political crisis in Brazil, the State of Rio de Janeiro was one of the most affected.\nSince 2006, the Instituto de Seguran\xc3\xa7a P\xc3\xbablica do Rio de Janeiro (Institue of Public Security of Rio de Janeiro State) publishes reports of each police station. \n\n\n### Content\nThree datasets are available:\nBaseDPEvolucaoMensalCisp - Monthly evolution of statistics by police station\nPopulacaoEvolucaoMensalCisp - Monthly evolution of population covered by police station\ndelegacias - Info about each police station\n\nMost of the data are in Brazilian Portuguese because it was extracted directly from government sites.\n\n### Acknowledgements\n\nThis dataset is provided by the [Instituto de Seguran\xc3\xa7a P\xc3\xbablica][1].\ndelegacias.csv was compiled by myself.\n\n### Inspiration\n>What is the most unsafe city in Rio de Janeiro State? And the safest?\n>Which events can be correlated with the numbers in dataset? (Elections, crisis...)\n>How crime correlates with population?\n\n  [1]: http://www.ispdados.rj.gov.br/""","b""['small', 'featured']""",https://www.kaggle.com/danielesteves/rio-police-records
b'3D MNIST',b'A 3D version of the MNIST database of handwritten digits',"b'# Context\nThe aim of this dataset is to provide a simple way to get started with 3D computer vision problems such as 3D shape recognition.\n\nAccurate [3D point clouds](https://en.wikipedia.org/wiki/Point_cloud) can (easily and cheaply) be adquired nowdays from different sources:\n\n- RGB-D devices: [Google Tango](http://get.google.com/tango/), [Microsoft Kinect](https://developer.microsoft.com/en-us/windows/kinect), etc.\n- [Lidar](https://en.wikipedia.org/wiki/Lidar).\n- [3D reconstruction from multiple images](https://en.wikipedia.org/wiki/3D_reconstruction_from_multiple_images).\n\nHowever there is a lack of large 3D datasets (you can find a [good one here](http://shapenet.cs.stanford.edu/) based on triangular meshes); it\'s especially hard  to find datasets based on point clouds (wich is the raw output from every 3D sensing device).\n\nThis dataset contains 3D point clouds generated from the original images of the MNIST dataset to bring a familiar introduction to 3D to people used to work with 2D datasets (images).\n\nIn the [3D_from_2D notebook](http://nbviewer.jupyter.org/github/daavoo/3DMNIST/blob/master/3D_from_2D.ipynb) you can find the code used to generate the dataset.\n\nYou can use the code in the notebook to generate a bigger 3D dataset from the original.\n\n# Content\n\n## full_dataset_vectors.h5\n\nThe entire dataset stored as 4096-D vectors obtained from the voxelization (x:16, y:16, z:16) of all the 3D point clouds.\n\nIn adition to the original point clouds, it contains randomly rotated copies with noise.\n\nThe full dataset is splitted into arrays:\n\n- X_train (10000, 4096)\n- y_train (10000)\n- X_test(2000, 4096)\n- y_test (2000)\n\nExample python code reading the full dataset:\n \n     with h5py.File(""../input/train_point_clouds.h5"", ""r"") as hf:    \n         X_train = hf[""X_train""][:]\n         y_train = hf[""y_train""][:]    \n         X_test = hf[""X_test""][:]  \n         y_test = hf[""y_test""][:]  \n\n## train_point_clouds.h5 &amp; test_point_clouds.h5\n\n5000 (train),  and 1000 (test) [3D point clouds](https://en.wikipedia.org/wiki/Point_cloud) stored in [HDF5 file format](https://support.hdfgroup.org/HDF5/whatishdf5.html). The point clouds have zero mean and a maximum dimension range of 1.\n\nEach file is divided into [HDF5 groups](https://support.hdfgroup.org/HDF5/Tutor/fileorg.html)\n\nEach group is named as its corresponding array index in the original mnist dataset and it contains:\n\n- ""points"" dataset: `x, y, z` coordinates of each 3D point in the point cloud.\n- ""normals"" dataset: `nx, ny, nz` components of the unit normal associate to each point.\n- ""img"" dataset: the original mnist image.\n- ""label"" attribute: the original mnist label.\n\nExample python code reading 2 digits and storing some of the group content in tuples:\n\n    with h5py.File(""../input/train_point_clouds.h5"", ""r"") as hf:    \n        a = hf[""0""]\n        b = hf[""1""]    \n        digit_a = (a[""img""][:], a[""points""][:], a.attrs[""label""]) \n        digit_b = (b[""img""][:], b[""points""][:], b.attrs[""label""]) \n \n## voxelgrid.py\nSimple Python class that generates a grid of voxels from the 3D point cloud. Check kernel for use.\n\n## plot3D.py\nModule with functions to plot point clouds and voxelgrid inside jupyter notebook.\nYou have to run this locally due to Kaggle\'s notebook lack of support to rendering Iframes. [See github issue here](https://github.com/Kaggle/docker-python/issues/36)\n\nFunctions included:\n\n- `array_to_color`\nConverts 1D array to rgb values use as kwarg `color` in plot_points()\n\n- `plot_points(xyz, colors=None, size=0.1, axis=False)`\n\n- `plot_voxelgrid(v_grid, cmap=""Oranges"", axis=False)`\n\n# Acknowledgements\n\n- Website of the [original MNIST dataset](http://yann.lecun.com/exdb/mnist/)\n- Website of the [3D MNIST dataset](https://github.com/daavoo/3DMNIST)\n\n\n# Have fun!\n\n\n'","b""['artificial intelligence', 'writing', 'medium', 'featured']""",https://www.kaggle.com/daavoo/3d-mnist
b'UK Human Trafficking Dataset',b'National Referral Mechanism Statistics',"b'### Context\n\nHuman trafficking is thought to be one of the fastest-growing activities of trans-national criminal organizations. It is defined as the trade of humans for the purpose of forced labour, sexual slavery, or commercial sexual exploitation for the trafficker or others. Human trafficking is condemned as a violation of human rights by international conventions. (Source: Wikipedia)\n\nThe National Referral Mechanism (NRM) is a framework for identifying victims of human trafficking and ensuring they receive the appropriate protection and support. The NRM is also the mechanism through which the UKHTC collects data about victims. This information contributes to building a clearer picture about the scope of human trafficking in the UK. \n\nThe NRM was introduced in 2009 to meet the UK\xe2\x80\x99s obligations under the Council of European Convention on Action against Trafficking in Human Beings. At the core of every country\xe2\x80\x99s NRM is the process of locating and identifying potential victims of trafficking. \n\n### Content\n\nFor years 2013 to 2016, the following tables are available:\n\n - YEAR_competent_authority.csv\n\n - YEAR_country_of_referral.csv\n\n - YEAR_exploitation_type.csv\n\n - YEAR_referrals_adult.csv\n\n - YEAR_referrals_all.csv\n\n - YEAR_referrals_minor.csv\n\n - YEAR_referring_agency.csv\n\nFor 2015 to 2016, there is an additional table:\n\n - YEAR_decision_data.csv\n\n### Acknowledgements\n\nData obtained from UK National Crime Agency, [National Referral Mechanism Statistics][1] end of year summary reports (2013 - 2016). Human Trafficking data reports are provided under Publications section of the UK National Crime Agency website. Data tables were extracted from pdf reports with [Tabula][2].\n\nLicensed under [Open Government License][3]\n\nPhoto by Pedro Gabriel Miziara on Unsplash\n\n\n  [1]: http://www.nationalcrimeagency.gov.uk/publications/national-referral-mechanism-statistics\n  [2]: http://tabula.technology/\n  [3]: http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/'","b""['crime', 'society', 'rights', 'small', 'featured']""",https://www.kaggle.com/algosforgood/uk-human-trafficking-data
b'UK Human Trafficking Dataset',b'National Referral Mechanism Statistics',"b'### Context\n\nHuman trafficking is thought to be one of the fastest-growing activities of trans-national criminal organizations. It is defined as the trade of humans for the purpose of forced labour, sexual slavery, or commercial sexual exploitation for the trafficker or others. Human trafficking is condemned as a violation of human rights by international conventions. (Source: Wikipedia)\n\nThe National Referral Mechanism (NRM) is a framework for identifying victims of human trafficking and ensuring they receive the appropriate protection and support. The NRM is also the mechanism through which the UKHTC collects data about victims. This information contributes to building a clearer picture about the scope of human trafficking in the UK. \n\nThe NRM was introduced in 2009 to meet the UK\xe2\x80\x99s obligations under the Council of European Convention on Action against Trafficking in Human Beings. At the core of every country\xe2\x80\x99s NRM is the process of locating and identifying potential victims of trafficking. \n\n### Content\n\nFor years 2013 to 2016, the following tables are available:\n\n - YEAR_competent_authority.csv\n\n - YEAR_country_of_referral.csv\n\n - YEAR_exploitation_type.csv\n\n - YEAR_referrals_adult.csv\n\n - YEAR_referrals_all.csv\n\n - YEAR_referrals_minor.csv\n\n - YEAR_referring_agency.csv\n\nFor 2015 to 2016, there is an additional table:\n\n - YEAR_decision_data.csv\n\n### Acknowledgements\n\nData obtained from UK National Crime Agency, [National Referral Mechanism Statistics][1] end of year summary reports (2013 - 2016). Human Trafficking data reports are provided under Publications section of the UK National Crime Agency website. Data tables were extracted from pdf reports with [Tabula][2].\n\nLicensed under [Open Government License][3]\n\nPhoto by Pedro Gabriel Miziara on Unsplash\n\n\n  [1]: http://www.nationalcrimeagency.gov.uk/publications/national-referral-mechanism-statistics\n  [2]: http://tabula.technology/\n  [3]: http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/'","b""['crime', 'society', 'rights', 'small', 'featured']""",https://www.kaggle.com/'charmap' codec can't encode character '\u012b' in position 32: character maps to <undefined>
b'Used cars database',"b'Over 370,000 used cars scraped from Ebay Kleinanzeigen'","b'  [machine learning + open data = business value] [1]\n\n\n\n\n  [1]: https://machine-learning1.sharetribe.com/en/listings/665346-predict-nyc-tlc-driver-licence-status?utm_source=kaggle_usedcars\n\nOver 370000 used cars scraped with Scrapy from Ebay-Kleinanzeigen. The content of the data is in german, so one has to translate it first if one can not speak german. Those fields are included:\n**autos.csv:**\n\n- dateCrawled : when this ad was first crawled, all field-values are taken from this date\n- name : ""name"" of the car\n- seller : private or dealer\n- offerType\n- price : the price on the ad to sell the car\n- abtest\n- vehicleType\n- yearOfRegistration : at which year the car was first registered\n- gearbox\n- powerPS : power of the car in PS\n- model\n- kilometer : how many kilometers the car has driven\n- monthOfRegistration : at which month the car was first registered\n- fuelType\n- brand\n- notRepairedDamage : if the car has a damage which is not repaired yet\n- dateCreated : the date for which the ad at ebay was created\n- nrOfPictures : number of pictures in the ad (unfortunately this field contains everywhere a 0 and is thus useless (bug in crawler!) )\n- postalCode \n- lastSeenOnline : when the crawler saw this ad last online\n\nThe fields lastSeen and dateCreated could be used to estimate how long a car will be at least online before it is sold.\n\nbrought to you by [Orges Leka][4]\n\n[Regression on average Price per Year based on this dataset][2]\n\n\n[Table of value loss of an average used car per year][3]\n\nThe second file is produced in MySQL from the first one through the query:\n\n\n    select \n     count(*) as count, \n     kilometer, \n     yearOfRegistration, \n    20*round(powerPS/20) as powerPS, \n    min(price) as minprice, \n    max(price) as maxPrice, \n    avg(price) as avgPreis, \n    sqrt(variance(price)) as sdPreis from items where \n         yearOfRegistration &gt; 1990 and yearOfRegistration &lt; 2016 \n        and price &gt; 100 and price &lt; 100000 \n        and powerPS &lt; 600 and powerPS &gt; 0 \n     group by yearOfRegistration, round(powerPS/20),kilometer \n    having count &gt; 10 \n    into outfile \'/tmp/cnt_km_year_powerPS_minPrice_maxPrice_avgPrice_sdPrice.csv\' \n    fields terminated by \',\' lines terminated by \'\\n\';\n\nHappy Coding!\n\n\n  [2]: https://orgesleka.blogspot.de/2016/10/gebrauchtwagenpreise-auf-ebay.html\n  [3]: http://orgesleka.blogspot.de/2016/11/tabelle-zum-wertverlust-pro-jahr-bei.html\n  [4]: http://www.orges-leka.de'","b""['automobiles', 'medium', 'featured']""",https://www.kaggle.com/orgesleka/used-cars-database
b'Space walking',b'A record of Russian and U.S. extra-vehicular actvity',"b'### Context\n\nExtra-vehicular activities are activities done by an astronaut or cosmonaut outside a spacecraft beyond the Earth\'s appreciable atmosphere. I like to just call it space walking :)  It\'s unclear if this is a complete record of spacewalks. So keep that in mind.\n\n\n### Content\n\n- EVA #\n- Country\n- Crew: Crew members, separated with |\n- Vehicle: Space craft, space ship, space station, etc. If multiple vehicles, they are separated with |\n- Date\n- Duration\n- Purpose: Description of the EVA. Some of these have internal commas and are enclosed with double quotes ("")\n\n### Acknowledgements\n\nThese data were collected from [here][1]\n\nThe original CSV was modified slightly to remove extra spaces \n\n\n  [1]: https://data.nasa.gov/Raw-Data/Extra-vehicular-Activity-EVA-US-and-Russia/9kcy-zwvn'","b""['space', 'spaceflight', 'astronauts', 'aerospace engineering', 'small', 'featured']""",https://www.kaggle.com/nasa/space-walking-russian-and-us-evas
b'Segmenting Soft Tissue Sarcomas',b'A challenge to automate tumor segmentation',"b""# Summary\nThe data is a preprocessed subset of the TCIA Study named Soft Tissue Sarcoma. The data have been converted from DICOM folders of varying resolution and data types to 3D HDF5 arrays with isotropic voxel size. This should make it easier to get started and test out various approaches (NN, RF, CRF, etc) to improve segmentations.\n\n# TCIA Summary\nThis collection contains FDG-PET/CT and anatomical MR (T1-weighted, T2-weighted with fat-suppression) imaging data from 51 patients with histologically proven soft-tissue sarcomas (STSs) of the extremities. All patients had pre-treatment FDG-PET/CT and MRI scans between November 2004 and November 2011. (Note: date in the TCIA images have been changed in the interest of de-identification; the same change was applied across all images, preserving the time intervals between serial scans). During the follow-up period, 19 patients developed lung metastases. Imaging data and lung metastases development status were used in the following study:\n\nValli\xc3\xa8res, M. et al. (2015). A radiomics model from joint FDG-PET and MRI texture features for the prediction of lung metastases in soft-tissue sarcomas of the extremities. Physics in Medicine and Biology, 60(14), 5471-5496. doi:10.1088/0031-9155/60/14/5471.\n\nImaging data, tumor contours (RTstruct DICOM objects), clinical data and source code is available for this study. See the DOI below for more details and links to access the whole dataset. Please contact Martin Valli\xc3\xa8res (mart.vallieres@gmail.com) of the Medical Physics Unit of McGill University for any scientific inquiries about this dataset.\n\n# Acknowledgements\n\nWe would like to acknowledge the individuals and institutions that have provided data for this collection:\nMcGill University, Montreal, Canada - Special thanks to Martin Valli\xc3\xa8res of the Medical Physics Unit\n\n# License\nThis collection is freely available to browse, download, and use for commercial, scientific and educational purposes as outlined in the Creative Commons Attribution 3.0 Unported License.  See TCIA's Data Usage Policies and Restrictions for additional details. Questions may be directed to help@cancerimagingarchive.net.\n\n# Citation\n## Data Citation\nValli\xc3\xa8res, Martin, Freeman, Carolyn R., Skamene, Sonia R., & El Naqa, Issam. (2015). A radiomics model from joint FDG-PET and MRI texture features for the prediction of lung metastases in soft-tissue sarcomas of the extremities. The Cancer Imaging Archive. http://doi.org/10.7937/K9/TCIA.2015.7GO2GSKS\n\n## Publication Citation\nValli\xc3\xa8res, M., Freeman, C. R., Skamene, S. R., & Naqa, I. El. (2015, June 29). A radiomics model from joint FDG-PET and MRI texture features for the prediction of lung metastases in soft-tissue sarcomas of the extremities. Physics in Medicine and Biology. IOP Publishing. http://doi.org/10.1088/0031-9155/60/14/5471\n\n## TCIA Citation\nClark K, Vendt B, Smith K, Freymann J, Kirby J, Koppel P, Moore S, Phillips S, Maffitt D, Pringle M, Tarbox L, Prior F. The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository, Journal of Digital Imaging, Volume 26, Number 6, December, 2013, pp 1045-1057. (paper)""","b""['healthcare', 'medium', 'featured']""",https://www.kaggle.com/4quant/soft-tissue-sarcoma
b'United States Droughts by County',b'Weekly data on extent and severity of drought in each US county (2000-present)',"b'The [United States Drought Monitor](http://droughtmonitor.unl.edu/Home.aspx) collects weekly data on drought conditions around the U.S.\n\n## Acknowledgements\n\nAll data was downloaded from the [United States Drought Monitor webpage](http://droughtmonitor.unl.edu/Home.aspx).\n\nThe U.S. Drought Monitor is jointly produced by the National Drought Mitigation Center at the University of Nebraska-Lincoln, the United States Department of Agriculture, and the National Oceanic and Atmospheric Administration. Map courtesy of NDMC-UNL.\n\n## The Data\n\nThe data contains weekly observations about the extent and severity of drought in each county of the United States. The dataset contains the following fields:\n\n- **releaseDate**: when this data was released on the USDM website\n- **FIPS**: the FIPS code for this county\n- **county**: the county name\n- **state**: the state the county is in\n- **NONE**: percentage of the county that is *not in drought*\n- **D0**: percentage of the county that is in *abnormally dry conditions*\n- **D1**: percentage of the county that is in *moderate drought*\n- **D2**: percentage of the county that is in *severe drought*\n- **D3**: percentage of the county that is in *extreme drought*\n- **D4**: percentage of the county that is in *exceptional drought*\n- **validStart**: the starting date of the week that these observations represent\n- **validEnd**: the ending date of the week that these observations represent\n- **domStatisticFormatID**: seems to always be 1\n\n**Note:** the drought categories are cumulative: if an area is in D3, then it is also in D2, D1, and D0. This means that, for every observation, D4 <= D3 <= D2 <= D1 <= D0.\n\n### County Info\n\nTo make some analyses slightly easier, I\'ve also included *county_info_2016.csv*, which contains physical size information about each county. This file contains the following fields:\n\n- **USPS**: \tUnited States Postal Service State Abbreviation\n- **GEOID**: \tFIPS code\n- **ANSICODE**: \tAmerican National Standards Institute code\n- **NAME**: \tName\n- **ALAND**: \tLand Area (square meters) - Created for statistical purposes only\n- **AWATER**: \tWater Area (square meters) - Created for statistical purposes only\n- **ALAND_SQMI**: \tLand Area (square miles) - Created for statistical purposes only\n- **AWATER_SQMI**: \tWater Area (square miles) - Created for statistical purposes only\n- **INTPTLAT**: \tLatitude (decimal degrees) First character is blank or ""-"" denoting North or South latitude respectively\n- **INTPTLONG**: \tLongitude (decimal degrees) First character is blank or ""-"" denoting East or West longitude respectively'","b""['climate', 'geography', 'medium', 'featured']""",https://www.kaggle.com/us-drought-monitor/united-states-droughts-by-county
b'Deaths related to the Northern Ireland conflict',b'Patterns of politically associated violence in Northern Ireland',"b'### Context\n\nA dataset of information on deaths related to the Northern Ireland conflict (1969-2005).\n\n\n### Content\n\n - Fatalities: A list of deaths related to the Northern Ireland conflict (Fact table)\n - Location: A list of locations where the fatalities took place [including GPS coordinates] (Links to fact table via the ""Location"" field)\n - Agency: This refers to groups responsible for fatal incidents [including agency groups] (Links to fact table via the ""Agency"" field)\n - Status: This refers to the role of fatality victims [including status groups] (Links to fact table via the ""Status"" field)\n\nDimension Remarks\n\n - Name: Spellings might vary from other sources\n - Year: Relates to year of death rather than fatal incident\n - Religion: Only that of Northern Ireland residents is listed\n - Agency: This refers to groups responsible for fatal incidents\n - Status: This refers to the role of fatality victims\n - Location: Westminster electoral areas are employed for Northern Ireland fatalities\n - Rationale: This refers to the inferred purpose underlying the fatal act\n - Causality: This probes the degree of inferred purposiveness of a fatal event\n - Context: This distinguishes between incidents such as gun fire, explosions, beatings\n - New Incident: This offers a count of discrete fatal incidents\n - 1st Fatality: This distinguishes multiple fatality incidents \n\n\n### Acknowledgements\n\nThe information was compiled by Michael McKeown and was contributed by him to the CAIN Web site. Michael McKeown has taken the decision (June 2009) to make the dataset freely available via the CAIN site. While users are free to download the dataset for research purposes, the database remains copyright \xc2\xa9 of Michael McKeown.\n\n\n### Inspiration\n\n""The following study represents both the revisiting and continuation of a task which had occupied me for over twenty years. The concluded work highlights complexities and ambiguities in the patterns of the violence in Northern Ireland over the past three decades which are often obscured by the polar interpretations offered by partizan commentaries. For that reason I believe it should be inserted into the public arena for further consideration and possibly as a methodological model for further enquiry.""\nMichael McKeown (2001).'","b""['crime', 'politics', 'small', 'featured']""",https://www.kaggle.com/cclayford/deaths-related-to-the-northern-ireland-conflict
b'NYS Capital District Transport Authority (CDTA)',b'From New York State Open Data',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset hosted by the State of New York. The state has an open data platform found [here](https://data.ny.gov/) and they update their information according the amount of data that is brought in. Explore New York State using Kaggle and all of the data sources available through the State of New York [organization page](https://www.kaggle.com/new-york-state)!  \n\n* Update Frequency: This dataset is updated monthly.\n\n### Acknowledgements\n\nThis dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  \n\n[Cover photo](https://unsplash.com/photos/IisDI6liZEM) by [Matthew Henry](https://unsplash.com/@matthewhenry) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._  \n\nThis dataset is distributed under the following licenses: Public Domain""","b""['socrata', 'small', 'featured']""",https://www.kaggle.com/new-york-state/nys-capital-district-transport-authority-cdta
b'Top Trending How Tos on Google',"b'The top trending ""how to"" related searches on Google in the past 5 years'","b'These are the top trending ""How to"" searches on Google, ranked by their spike value. Trending searches are searches with the biggest increase in search interest since the previous time period. Data covers the past 5 years. \n\n'","b""['small', 'featured']""",https://www.kaggle.com/GoogleNewsLab/top-trending-how-tos-on-google
b'Swiss Rail Plan',"b'The locations, timetables, and fare information for the SBB/CFF/FFS Rail Network'",b'# Introduction\nThe basic inspiration was the inability to search through lots of alternative routes while traveling over Easter weekend and having to manually to point-to-point searches. The hope is by using a bit of R/Python the search for the best routes can be made a lot easier.\n\n# Data Structure\nThe data is organized in a format called GTFS which is explained in detail [here](https://opentransportdata.swiss/de/cookbook/gtfs/) but only available in German. Kernels should make it clear how to work with most of the data\n\n# Source / Attribution\nThe data all comes from opentransportdata.swiss and can be downloaded in the original format by following this [link](https://opentransportdata.swiss/de/dataset/timetable-2016-gtfs)',"b""['rail transport', 'medium', 'featured']""",https://www.kaggle.com/kmader/swiss-rail-plan
b'The Interview Attendance Problem',b'Predict which candidates will attend the intervew',"b""### Context\n\nThe data pertains to the recruitment industry in India for the years 2014-2016 and deals with candidate interview attendance for various clients. The details are largely self explanatory. \n\n### Content\n\nThe data have been collected by me and my fellow researchers over a period of over 2 years between September 2014 and January 2017. \n\nThere are a set of questions that are asked by a recruiter while scheduling the candidate. The answers to these determine whether expected attendance is yes, no or uncertain.\n \nFor details on individual feeds, see the [Data](https://www.kaggle.com/vishnusraghavan/the-interview-attendance-problem/data) tab.\n\n### Acknowledgements\n\nA great measure of thanks goes to my colleaues in research and work. \n\n 1. Dr Rajendra Desai: Associate Professor, St Joseph's College of Management, Bangalore\n 2. Marcia Akshaya Leo: HR recruiter, Chennai\n 3. Dr Rashmi Nakra, Professor, St Josephs College of Management, Bangalore\n 4. Prima: Student, St Josephs College of Management, Bangalore\n 5. Trupthi: Student, St Josephs College of Management, Bangalore\n \n\n### Inspiration\n\nA few pointers:\n\n* We have already attempted Naive Bayes with decent results.\n* We would like to know if we can predict whether a candidate will attend interviews or not with other algorithms\n* Also, whether any of the present set of variables can be modified to yield better results\n* Whether we can find additional variables from the internet and whether we can derive variables from the existing set of variables.""","b""['business', 'strategy', 'management', 'small', 'featured']""",https://www.kaggle.com/vishnusraghavan/the-interview-attendance-problem
"b""Students' Academic Performance Dataset""",b'xAPI-Educational Mining Dataset',"b""Students' Academic Performance Dataset (xAPI-Edu-Data)\n=======================================\n\nData Set Characteristics: Multivariate\n\nNumber of Instances: 480\n\nArea: E-learning, Education, Predictive models, Educational Data Mining\n\nAttribute Characteristics: Integer/Categorical \n\nNumber of Attributes: 16\n\nDate: 2016-11-8\n\nAssociated Tasks: Classification\n\nMissing Values? No\n\nFile formats: xAPI-Edu-Data.csv\n\nSource:\n=======\nElaf Abu Amrieh, Thair Hamtini, and Ibrahim Aljarah, The University of Jordan, Amman, Jordan, http://www.Ibrahimaljarah.com\nwww.ju.edu.jo\n\nDataset Information:\n=====================\nThis is an educational data set which is collected from learning management system (LMS) called Kalboard 360. Kalboard 360 is a multi-agent LMS, which has been designed to facilitate learning through the use of leading-edge technology. Such system provides users with a synchronous access to educational resources from any device with Internet connection. \n\nThe data is collected using a learner activity tracker tool, which called experience API (xAPI). The xAPI is a component of the training and learning architecture (TLA) that enables to monitor learning progress and learner\xe2\x80\x99s actions like reading an article or watching a training video. The experience API helps the learning activity providers to determine the learner, activity and objects that describe a learning experience.\nThe dataset consists of 480 student records and 16 features. The features are classified into three major categories: (1) Demographic features such as gender and nationality. (2) Academic background features such as educational stage, grade Level and section. (3) Behavioral features such as raised hand on class, opening resources, answering survey by parents, and school satisfaction.\n\nThe dataset consists of 305 males and 175 females. The students come from different origins such as 179 students are from Kuwait, 172 students are from Jordan, 28 students from Palestine, 22 students are from Iraq, 17 students from Lebanon, 12 students from Tunis, 11 students from Saudi Arabia, 9 students from Egypt, 7 students from Syria, 6 students from USA, Iran and Libya, 4 students from Morocco and one student from Venezuela.\n\nThe dataset is collected through two educational semesters: 245 student records are collected during the first semester and 235 student records are collected during the second semester. \n\nThe data set includes also the school attendance feature such as the students are classified into two categories based on their absence days: 191 students exceed 7 absence days and 289 students their absence days under 7.\n\nThis dataset includes also a new category of features; this feature is parent parturition in the educational process. Parent participation feature have two sub features: Parent Answering Survey and Parent School Satisfaction. There are 270 of the parents answered survey and 210 are not, 292 of the parents are satisfied from the school and 188 are not. \n\n(See the related papers for more details).\n\nAttributes\n============\n1 Gender - student's gender (nominal: 'Male' or 'Female\xe2\x80\x99) \n\n2 Nationality- student's nationality (nominal:\xe2\x80\x99 Kuwait\xe2\x80\x99,\xe2\x80\x99 Lebanon\xe2\x80\x99,\xe2\x80\x99 Egypt\xe2\x80\x99,\xe2\x80\x99 SaudiArabia\xe2\x80\x99,\xe2\x80\x99 USA\xe2\x80\x99,\xe2\x80\x99 Jordan\xe2\x80\x99,\xe2\x80\x99 \nVenezuela\xe2\x80\x99,\xe2\x80\x99 Iran\xe2\x80\x99,\xe2\x80\x99 Tunis\xe2\x80\x99,\xe2\x80\x99 Morocco\xe2\x80\x99,\xe2\x80\x99 Syria\xe2\x80\x99,\xe2\x80\x99 Palestine\xe2\x80\x99,\xe2\x80\x99 Iraq\xe2\x80\x99,\xe2\x80\x99 Lybia\xe2\x80\x99)\n\n3 Place of birth- student's Place of birth (nominal:\xe2\x80\x99 Kuwait\xe2\x80\x99,\xe2\x80\x99 Lebanon\xe2\x80\x99,\xe2\x80\x99 Egypt\xe2\x80\x99,\xe2\x80\x99 SaudiArabia\xe2\x80\x99,\xe2\x80\x99 USA\xe2\x80\x99,\xe2\x80\x99 Jordan\xe2\x80\x99,\xe2\x80\x99 \nVenezuela\xe2\x80\x99,\xe2\x80\x99 Iran\xe2\x80\x99,\xe2\x80\x99 Tunis\xe2\x80\x99,\xe2\x80\x99 Morocco\xe2\x80\x99,\xe2\x80\x99 Syria\xe2\x80\x99,\xe2\x80\x99 Palestine\xe2\x80\x99,\xe2\x80\x99 Iraq\xe2\x80\x99,\xe2\x80\x99 Lybia\xe2\x80\x99)\n\n4 Educational Stages- educational level student belongs (nominal: \xe2\x80\x98lowerlevel\xe2\x80\x99,\xe2\x80\x99MiddleSchool\xe2\x80\x99,\xe2\x80\x99HighSchool\xe2\x80\x99) \n\n5 Grade Levels- grade student belongs (nominal: \xe2\x80\x98G-01\xe2\x80\x99, \xe2\x80\x98G-02\xe2\x80\x99, \xe2\x80\x98G-03\xe2\x80\x99, \xe2\x80\x98G-04\xe2\x80\x99, \xe2\x80\x98G-05\xe2\x80\x99, \xe2\x80\x98G-06\xe2\x80\x99, \xe2\x80\x98G-07\xe2\x80\x99, \xe2\x80\x98G-08\xe2\x80\x99, \xe2\x80\x98G-09\xe2\x80\x99, \xe2\x80\x98G-10\xe2\x80\x99, \xe2\x80\x98G-11\xe2\x80\x99, \xe2\x80\x98G-12 \xe2\x80\x98) \n\n6 Section ID- classroom student belongs (nominal:\xe2\x80\x99A\xe2\x80\x99,\xe2\x80\x99B\xe2\x80\x99,\xe2\x80\x99C\xe2\x80\x99)\n\n7 Topic- course topic (nominal:\xe2\x80\x99 English\xe2\x80\x99,\xe2\x80\x99 Spanish\xe2\x80\x99, \xe2\x80\x98French\xe2\x80\x99,\xe2\x80\x99 Arabic\xe2\x80\x99,\xe2\x80\x99 IT\xe2\x80\x99,\xe2\x80\x99 Math\xe2\x80\x99,\xe2\x80\x99 Chemistry\xe2\x80\x99, \xe2\x80\x98Biology\xe2\x80\x99, \xe2\x80\x98Science\xe2\x80\x99,\xe2\x80\x99 History\xe2\x80\x99,\xe2\x80\x99 Quran\xe2\x80\x99,\xe2\x80\x99 Geology\xe2\x80\x99)\n\n8 Semester- school year semester (nominal:\xe2\x80\x99 First\xe2\x80\x99,\xe2\x80\x99 Second\xe2\x80\x99)\n\n9 Parent responsible for student (nominal:\xe2\x80\x99mom\xe2\x80\x99,\xe2\x80\x99father\xe2\x80\x99)\n\n10 Raised hand- how many times the student raises his/her hand on classroom (numeric:0-100)\n\n11- Visited resources- how many times the student visits a course content(numeric:0-100)\n\n12 Viewing announcements-how many times the student checks the new announcements(numeric:0-100)\n\n13 Discussion groups- how many times the student participate on discussion groups (numeric:0-100)\n\n14 Parent Answering Survey- parent answered the surveys which are provided from school or not \n(nominal:\xe2\x80\x99Yes\xe2\x80\x99,\xe2\x80\x99No\xe2\x80\x99)\n\n15 Parent School Satisfaction- the Degree of parent satisfaction from school(nominal:\xe2\x80\x99Yes\xe2\x80\x99,\xe2\x80\x99No\xe2\x80\x99)\n\n16 Student Absence Days-the number of absence days for each student (nominal: above-7, under-7)\n\n# The students are classified into three numerical intervals based on their total grade/mark:\n\nLow-Level: interval includes values from 0 to 69, \n\nMiddle-Level: interval includes values from 70 to 89, \n\nHigh-Level: interval includes values from 90-100.\n\nRelevant Papers:\n================\n- Amrieh, E. A., Hamtini, T., & Aljarah, I. (2016). Mining Educational Data to Predict Student\xe2\x80\x99s academic Performance using Ensemble Methods. International Journal of Database Theory and Application, 9(8), 119-136.\n\n- Amrieh, E. A., Hamtini, T., & Aljarah, I. (2015, November). Preprocessing and analyzing educational data set using X-API for improving student's performance. In Applied Electrical Engineering and Computing Technologies (AEECT), 2015 IEEE Jordan Conference on (pp. 1-5). IEEE.\n\nCitation Request:\n=================\nPlease include these citations if you plan to use this dataset:\n\n- Amrieh, E. A., Hamtini, T., & Aljarah, I. (2016). Mining Educational Data to Predict Student\xe2\x80\x99s academic Performance using Ensemble Methods. International Journal of Database Theory and Application, 9(8), 119-136.\n\n- Amrieh, E. A., Hamtini, T., & Aljarah, I. (2015, November). Preprocessing and analyzing educational data set using X-API for improving student's performance. In Applied Electrical Engineering and Computing Technologies (AEECT), 2015 IEEE Jordan Conference on (pp. 1-5). IEEE.""","b""['education', 'small', 'featured']""",https://www.kaggle.com/aljarah/xAPI-Edu-Data
b'Epicurious - Recipes with Rating and Nutrition',"b'Recipes from Epicurious by rating, nutritional content, and categories'","b""# Context \nI created this dataset to explore different factors affecting people's enjoyment of food and/or cooking!\n\n\n# Content\n\nOver 20k recipes listed by recipe rating, nutritional information and assigned category (sparse). I may later upload a version binned by recipe creation date and also including recipe ingredients.\n\nUse the 'full_format_recipes.json' file to interact with all recipe data, 'epi_r.csv' drops ingredients and directions in favour of sparse category dummies. \n\n\n# Acknowledgements\nRecipe information lifted from: http://www.epicurious.com/recipes-menus""","b""['food and drink', 'nutrition', 'medium', 'featured']""",https://www.kaggle.com/hugodarwood/epirecipes
b'1000 Cameras Dataset',b'Data describing 1000 cameras in 13 properties',"b'### Context\n\nSome camera enthusiast went and described 1,000 cameras based on 13 properties! \n\n### Content\n\nRow one describes the datatype for each column and can probably be removed.\n\nThe 13 properties of each camera:\n\n- Model\n- Release date\n- Max resolution\n- Low resolution\n- Effective pixels\n- Zoom wide (W)\n- Zoom tele (T)\n- Normal focus range\n- Macro focus range\n- Storage included\n- Weight (inc. batteries)\n- Dimensions\n- Price\n\n\n\n### Acknowledgements\nThese datasets have been gathered and cleaned up by Petra Isenberg, Pierre Dragicevic and Yvonne Jansen.  The original source can be found [here][1].\n\nThis dataset has been converted to CSV.\n\n\n\n  [1]: https://perso.telecom-paristech.fr/eagan/class/igr204/datasets'","b""['electronics', 'small', 'featured']""",https://www.kaggle.com/crawford/1000-cameras-dataset
b'Cuneiform Digital Library Initiative',b'Explore thousands of ancient tablet transliterations',"b'What is CDLI?\n--------------------\nThe Cuneiform Digital Library Initiative (CDLI) is an international digital library project aimed at putting text and images of an estimated 500,000 recovered cuneiform tablets created from between roughly 3350 BC and the end of the pre-Christian era online. The initiative is a joint project of the University of California, Los Angeles, the University of Oxford, and the Max Planck Institute for the History of Science, Berlin. \n\nThis dataset includes the full CDLI catalogue (metadata), transliterations of tablets in the catalogue, and word/sign lists from old akkadian and Ur III. This data was downloaded on the 9th of May 2017.\n\nTransliterations are in .atf format, find out more about this format here: [http://oracc.museum.upenn.edu/doc/help/editinginatf/cdliatf/index.html][1]\n\nFind more about CDLI here: [http://cdli.ucla.edu/][2]\n\nWhat is Cuneiform?\n--------------------\nCuneiform script, one of the earliest systems of writing, was invented by the Sumerians. It is distinguished by its wedge-shaped marks on clay tablets, made by means of a blunt reed for a stylus. The name cuneiform itself simply means ""wedge shaped"".\n\nCuneiform is not a language, nor is it an alphabet. Cuneiform uses between 600-1000 characters to write words or syllables. It has been used by many different cultural groups to represent many different languages, but it was primarily used to write Sumerian and Akkadian. Deciphering cuneiform is very difficult to this day, though the difficulty varies depending on the language.\n\n[https://en.wikipedia.org/wiki/Cuneiform_script][3]\n\nWhat is Assyriology?\n--------------------\nAssyriology is the study of the languages, history, and culture of the people who used the ancient writing system called cuneiform. Cuneiform was used primarily in an area called the Near East, centred on Mesopotamia (modern Iraq and eastern Syria) where cuneiform was invented, but including the Northern Levant (Western Syria and Lebanon), parts of Anatolia, and western Iran. The sources for Assyriology are all archaeological, and include both inscribed and uninscribed objects. Most Assyriologists focus on the rich textual record from the ancient Near East, and specialise in either the study of language, literature, or history of the ancient Near East.\n\nAssyriology began as an academic discipline with the recovery of the monuments of ancient Assyria, and the decipherment of cuneiform, in the middle of the 19th century. Large numbers of archaeological objects, including texts, were brought to museums in Europe and later the US, following the early excavations of Nineveh, Kalhu, Babylon, Girsu, Assur and so forth. Today Assyriology is studied in universities across the globe, both as an undergraduate and a graduate subject, and knowledge from the ancient Near East informs students of numerous other disciplines such as the History of Science, Archaeology, Classics, Biblical studies and more.\n\n\n  [1]: http://oracc.museum.upenn.edu/doc/help/editinginatf/cdliatf/index.html\n  [2]: http://cdli.ucla.edu/\n  [3]: https://en.wikipedia.org/wiki/Cuneiform_script'","b""['linguistics', 'languages', 'history', 'medium', 'featured']""",https://www.kaggle.com/mylesoneill/cuneiform-digital-library-initiative
b'Advance Retail Sales Time Series Collection',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/2iV9nqP4Y6A) by [Cristiane Teston](https://unsplash.com/@cristiane) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/advance-retail-sales-time-series-collection
b'Hate Crime Classification',"b""Let's stop hate crimes with the power of data science!""","b""### Context\n\nWe should definitely stop hate crimes. Let's use data science to stop them. This is mainly classification but any other approach is welcome. Example; prediction for next possible hate crime.\n\n### Content\n\n3700 rows of CSV from Google Trend. Headline, date, location, URL.\n\n### Acknowledgements\n\nSpecial thanks to ; http://googletrends.github.io/data/\n\n### Inspiration\nMedia data is mainly NLP CSV. We have to come up with other ways to add the value from it.""","b""['small', 'featured']""",https://www.kaggle.com/team-ai/classification-of-hate-crime-in-the-us
b'1 M+ Real Time stock market data [NSE/BSE]',b'Real time price volume data for select Nifty 50 stocks from both NSE/BSE',"b""### Context\n\nStarting something in FinTech is the most difficult thing. You have no open data. These days I'm trying to do some algo-trading. Maybe not in true sense, because it's not high frequency scalping. But anyway that's that.\n\n\n### What?\n\nThe data gives almost-Realtime data for half of the Nifty 50 stocks for last week of May and first 2 Weeks of July.\n\n\n----------\n\n\nNow here is the obvious question. The dataset does not have timestamp. That's because it is collected via Web-Socket streaming as it happens. Sometimes once in a couple of seconds, sometimes 10-15 times in the same span. So there is no point to timestamp IMHO. Anyway it'll be client-side timestamp, so not a true timestamp. \n### Description\n - tick_data.csv contains only the price-volume data.\n- volume: total volumes traded for the day </br>\n- last_price: denotes the quote price for latest trade\n - List item instrument_list.csv contains description of the underlying instrument.\n\nP.S:\n\n**All the data points are not tick-by-tick update. Rather it is mostly an update after 600 ms, provided a trade happened **""","b""['finance', 'medium', 'featured']""",https://www.kaggle.com/deeiip/1m-real-time-stock-market-data-nse
b'Gone With The Wind',b'Text Mining with Novels',"b'### Context\n\nI am fond of reading romances, so I find practice text mining with novels extremely amusing. I also think this is a good way to approach literary works in quantitative light and gain some new insights.\n\n\n### Content\n\nThe dataset includes a Plain Text file and a Microsoft Word file of the book *Gone With The Wind*  by Margaret Mitchell. There are some problems with UTF-8 so more cleaning is needed.\n\n\n### Acknowledgements\n\nI converted this dataset from full PDF file of the book created by Don Lainson dlainson@sympatico.ca, sponsored by Project Gutenberg of Australia eBooks. http://campbellmgold.com/archive_ebooks/gone_with_the_wind_mitchell.pdf\n\n### Inspiration\n\nI have started on some sentiment analysis based on chapter number, and based on characters. What is the general air of this classic? Which chapter is the most depressing? Which words are most associated with Scarlett? Rhett Butler? What are the sentiments regarding the War? And the Abolition?\n\n'","b""['linguistics', 'small', 'featured']""",https://www.kaggle.com/mykhe1097/text-mining-gone-with-the-wind
b'Eye Gaze',b'Simulated and real datasets of eyes looking in different directions',"b'# Context\nThe main reason for making this dataset is the publication of the paper: [Learning from Simulated and Unsupervised Images through Adversarial Training](https://arxiv.org/pdf/1612.07828v1.pdf) and the idea of the SimGAN. The dataset and kernels should make it easier to get started making SimGAN networks and testing them out and comparing them to other approaches like KNN, GAN, InfoGAN and the like. \n\n# Content\n\ngaze.csv: A full table of values produced by the UnityEyes tool for every image in the gaze.h5 file\n\ngaze.json: A json version of the CSV table (easier to read in pandas)\n\ngaze.h5: The synthetic gazes from the UnityEyes tool\n\nreal_gaze.h5: The gaze images from MPII packed into a single hdf5\n\n\n# Acknowledgements\n\nThe synthetic images were generated with the windows version of UnityEyes http://www.cl.cam.ac.uk/research/rainbow/projects/unityeyes/tutorial.html\n\nThe real images were taken from https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/gaze-based-human-computer-interaction/appearance-based-gaze-estimation-in-the-wild-mpiigaze/, which can be cited like this: Appearance-based Gaze Estimation in the Wild, X. Zhang, Y. Sugano, M. Fritz and A. Bulling, Proc. of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR), June, p.4511-4520, (2015).\n\n# Inspiration\n\nEnhancement:\n\n - One of the challenges (as covered in the paper) is enhancing the\n   simulated images by using the real images. One possible approach is\n   using the SimGAN which is implemented for reference in one of the\n   notebooks. There are a number of other approaches (pix2pix, CycleGAN)\n   which could have interesting results.\n\nGaze Detection:\n\n - The synthetic dataset has the gaze information since it was generated\n   by UnityEyes with a predefined look-vector. The overview notebook\n   covers what this vector means and how each component can be\n   interpreted. It would be very useful to have a simple, quick network\n   for automatically generating this look vector from an image'","b""['image data', 'psychometrics', 'large', 'featured']""",https://www.kaggle.com/4quant/eye-gaze
b'Eurovision YouTube Comments',b'YouTube comments on entries from the 2003-2008 Eurovision Song Contests',"b'### Context: \nThe Eurovision Song Contest, which originated in 1956, is present on YouTube through uploads of songs performed in the Contest. Any user can freely comment on these songs. This dataset is made of up a collection of comments made on four YouTube videos of Eurovision entries by Belgium. The comments are in a number of languages.\n\n### Content: \nThe YouTube online forums associated with the Eurovision Song Contest have a large number of users from varied linguistic backgrounds who, because of their interests in song performance, are particularly attentive to language-related issues, such as the accent of the performers and the choice of language of the songs. Commentaries are made by forum participants from disparate locations on a variety of topics, one of the most prominent being language, including language features and perceptions of language use.\n\n### Acknowledgements: \nThis dataset was collected by Dejan Ivkovi\xc4\x87 for the purpose of linguistic research. If you made use of this data, please cite the following article:\n\n[Ivkovi\xc4\x87, D. (2013). The Eurovision Song Contest on YouTube: A corpus-based analysis of language attitudes. Language@Internet, 10, article 1. (urn:nbn:de:0009-7-35977)][1]\n\n### Inspiration: \n\n* This dataset contains multiple languages. Can you identify and the language of each comment?\n* Can you automatically find positive and negative comments about different country\xe2\x80\x99s songs?\n* Are some commenters more positive or more negative than others?\n\n[1]: http://www.languageatinternet.org/articles/2013/Ivkovic/?searchterm=eurovision'","b""['internet', 'linguistics', 'languages', 'music', 'small', 'featured']""",https://www.kaggle.com/rtatman/eurovision-youtube-comments
b'CDC 500 Cities',b'Dozens of Public Health Datapoints Reported by Residents of 500 US Cities',"b""### Context: \nPublic health is a large and expensive problem for policymakers to understand in order to provide health services and prevent future epidemics. Self-reported data can be tricky due to many sampling issues, but it can paint an interesting picture of how healthy a given area\xe2\x80\x99s population might be.\n\n### Content: \nData includes small area samples of residents from 500 US cities. Recorded is the percent of residents who answered a public health-related question affirmatively (see [here](https://nccd.cdc.gov/500_Cities/rdPage.aspx?rdReport=DPH_500_Cities.ComparisonReport)). In addition to crude data, additional data is provided with age adjustment applied. 95% Confidence Intervals also provided for both datapoints.\n\n### Acknowledgements: \nThis data was collected by Centers for Disease Control and Prevention, National Center for Chronic Disease Prevention and Health Promotion, Division of Population Health. 500 Cities Project Data [online]. 2016 [accessed Aug 10, 2017]. URL: https://www.cdc.gov/500cities.\n\n### Inspiration: \n* Are there any regional health trends?\n* Any unusual hotspots of declining health? Higher levels of wellness?\n* Can you split the data by geography and predict neighboring cities health?\n* Who's healthier, larger or smaller cities?""","b""['small', 'featured']""",https://www.kaggle.com/cdc/500-cities
b'CDC 500 Cities',b'Dozens of Public Health Datapoints Reported by Residents of 500 US Cities',"b""### Context: \nPublic health is a large and expensive problem for policymakers to understand in order to provide health services and prevent future epidemics. Self-reported data can be tricky due to many sampling issues, but it can paint an interesting picture of how healthy a given area\xe2\x80\x99s population might be.\n\n### Content: \nData includes small area samples of residents from 500 US cities. Recorded is the percent of residents who answered a public health-related question affirmatively (see [here](https://nccd.cdc.gov/500_Cities/rdPage.aspx?rdReport=DPH_500_Cities.ComparisonReport)). In addition to crude data, additional data is provided with age adjustment applied. 95% Confidence Intervals also provided for both datapoints.\n\n### Acknowledgements: \nThis data was collected by Centers for Disease Control and Prevention, National Center for Chronic Disease Prevention and Health Promotion, Division of Population Health. 500 Cities Project Data [online]. 2016 [accessed Aug 10, 2017]. URL: https://www.cdc.gov/500cities.\n\n### Inspiration: \n* Are there any regional health trends?\n* Any unusual hotspots of declining health? Higher levels of wellness?\n* Can you split the data by geography and predict neighboring cities health?\n* Who's healthier, larger or smaller cities?""","b""['small', 'featured']""",https://www.kaggle.com/cjroth/chronist
"b""Elon Musk's Tweets""",b'Tweets by @elonmusk from 2012 to 2017',"b""### Context\n\n[Elon Musk](https://en.wikipedia.org/wiki/Elon_Musk) is an American business magnate. He was one of the founders of PayPal in the past, and the founder and/or cofounder and/or CEO of SpaceX, Tesla, SolarCity, OpenAI, Neuralink, and The Boring Company in the present. He is known as much for his extremely forward-thinking ideas and huge media presence as he is for his extremely business savvy.\n\nMusk is famously active on Twitter. This dataset contains all tweets made by [@elonmusk](https://twitter.com/elonmusk), his official Twitter handle, between November 16, 2012 and September 29, 2017.\n\n### Content\n\nThis dataset includes the body of the tweet and the time it was made, as well as who it was re-tweeted from (if it is a retweet).\n\n### Inspiration\n\n* Can you figure out Elon Musk's opinions on various things by studying his Twitter statements?\n* How Elon Musk's post rate increased, decreased, or stayed about the same over time? ""","b""['small', 'featured']""",https://www.kaggle.com/kulgen/elon-musks-tweets
b'City Payroll Data',b'Payroll information for all Los Angeles city departments since 2013',"b'# Context\n\nThe Los Angeles City Controller Office releases payroll information for all city employees on a quarterly basis since 2013.\n\n# Content\n\nData includes department titles, job titles, projected annual salaries (with breakdowns of quarterly pay), bonuses, and benefits information. \n\n# Inspiration\n\n* How do benefits and salaries differ for employees across departments and titles? Are there any unusually large differences between lowest and highest employee salaries?\n* How have salaries changed over the past three years?\n* Have the costs of benefits changed dramatically since the passing of the Affordable Care Act?\n* What is the most common government role in Los Angeles?'","b""['cities', 'income', 'medium', 'featured']""",https://www.kaggle.com/cityofLA/city-payroll-data
b'Pokemon with stats',b'721 Pokemon with stats and types',"b""This data set includes 721 Pokemon, including their number, name, first and second type, and basic stats: HP, Attack, Defense, Special Attack, Special Defense, and Speed. It has been of great use when teaching statistics to kids. With certain types you can also give a geeky introduction to machine learning.\n\nThis are the raw attributes that are used for calculating how much damage an attack will do in the games. This dataset is about the pokemon games (*NOT* pokemon cards or Pokemon Go).\n\nThe data as described by [Myles O'Neill](https://www.kaggle.com/mylesoneill) is:\n\n- **#**: ID for each pokemon\n- **Name**: Name of each pokemon\n- **Type 1**: Each pokemon has a type, this determines weakness/resistance to attacks\n- **Type 2**: Some pokemon are dual type and have 2\n- **Total**: sum of all stats that come after this, a general guide to how strong a pokemon is\n- **HP**: hit points, or health, defines how much damage a pokemon can withstand before fainting\n- **Attack**: the base modifier for normal attacks (eg. Scratch, Punch)\n- **Defense**: the base damage resistance against normal attacks\n- **SP Atk**: special attack, the base modifier for special attacks (e.g. fire blast, bubble beam)\n- **SP Def**: the base damage resistance against special attacks\n- **Speed**: determines which pokemon attacks first each round\n\nThe data for this table has been acquired from several different sites, including: \n\n - [pokemon.com](http://www.pokemon.com/us/pokedex/)\n - [pokemondb](http://pokemondb.net/pokedex)\n - [bulbapedia](http://bulbapedia.bulbagarden.net/wiki/List_of_Pok%C3%A9mon_by_National_Pok%C3%A9dex_number)\n\nOne question has been answered with this database: The type of a pokemon cannot be inferred only by it's Attack and Deffence. It would be worthy to find which two variables can define the type of a pokemon, if any. Two variables can be plotted in a 2D space, and used as an example for machine learning. This could mean the creation of a visual example any geeky Machine Learning class would love.""","b""['video games', 'popular culture', 'games and toys', 'small', 'featured']""",https://www.kaggle.com/abcsds/pokemon
b'TechCrunch Posts Compilation',b'40k compiled posts with a rich set of features will boost your visualizations',"b""# Inspiration \nI'm a big fan of [TechCrunch](https://techcrunch.com/) for a while now. Kind of because I get to know about new startups that's coming up or maybe just because I find Tito Hamze videos fun. But TechCrunch got plenty of good content. And where we find good content we produce great exploratory analysis.\n\nThis dataset is a great opportunity for you to boost your skills as an EDA expert! It provides several features that make you able to create different analyses such as time series, clustering, predictive, segmenting, classification and tons of others. Let's not forget about word2vec for that. It would be awesome to see that in action here!\n\nI've made the scraper available on github, if you want to check it out, here is the link: [techcrunch scraper repo](https://github.com/thibalbo/techcrunch-posts-scraper)\n\n\n# Content\nThis dataset comes with a rich set of features. You will have:\n\n1. **authors**: `authors of the post - can be one or multiple authors`\n2. **category**: `post category`\n3. **content**: `post content - each paragraph can be extracted by splitting on the \\n`\n4. **date**: `post date`\n5. **id**: `post id - the same id used on techcrunch website`\n6. **img_src**: `post main image url`\n7. **section**: `post section - each section is one of the options on the main page dropdown menu`\n8. **tags**: `post tags - can be zero or multiple tags`\n9. **title**: `post title`\n10. **topics**: `post topics`\n11. **url**: `post url`\n\n#Acknowledgements\nAll posts were scraped from the [TechCrunch](https://techcrunch.com/) website on mid oct-16. Each line contains information about one post and each post appear in no more than one line.""","b""['internet', 'linguistics', 'medium', 'featured']""",https://www.kaggle.com/thibalbo/techcrunch-posts-compilation
b'Allen-Unger Global Commodity Prices',b'Price Time Series Between 965 and 1983',"b'### Context\n\nAre you tired of hearing your elders talk about how much cheaper things were back in their day? Would you like to one-up them by talking about how much cheaper goods were a thousand years before they were born? Of course you would!\n\nYou might also have an interest in an unusually comprehensive set of historic prices that cover long time spans. English port wine prices, for example, stretch from 1209 through 1869.\n\n### Content\nEach commodity contains prices in the local currency and standardized silver units that allow for broader comparisons.\n\nPlease note that this dataset has been consolidated into a single file from the original thousand or so csvs, so the format is slightly different.\n\n### Acknowledgements\n\nThis dataset was kindly made available by Robert Allen and Richard Unger. You can find [the original dataset here][1].\n\n### Inspiration\n\n- Can you identify goods or locations that remained largely unaffected by the industrial revolution?\n\n### If you like\n\nIf you enjoyed this dataset, you might also like the [millennium of macroeconomic data](https://www.kaggle.com/bank-of-england/a-millennium-of-macroeconomic-data) dataset.\n\n\n  [1]: http://www.iisg.nl/hpw/allen-unger-commodities.php'","b""['economics', 'history', 'medium', 'featured']""",https://www.kaggle.com/sohier/allenunger-global-commodity-prices
b'Austin Crime Statistics',"b'159k Crime Reports, 2014-2016'","b'### Context: \nCrime in growing cities such as Austin changes with the population. This data covers individual crimes reported in Austin, primarily 2014-2015.\n\n### Content: \n159k rows of data on type of crime reported, location by various attributes (lat/lon, council district, census tract) and time are included. Clearance status by Austin PD is also recorded where available.\n\n### Acknowledgements: \nData was prepared from a txt file accessed via [Google Cloud BigQuery Public Datasets]( https://cloud.google.com/bigquery/public-data/ ). Image by [Tobias Zils](https://unsplash.com/@herrzett).\n\n### Inspiration: \nAre there any clear seasonal or hourly trends in certain crimes? Which crimes are most often cleared by Austin PD, and which remain open? How long do clearances take?'","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/jboysen/austin-crime
b'Corporate Prosecution Registry',b'Details of federal cases in the United States against corporations since 2001',"b'### Context\n\nThe goal of this Corporate Prosecutions Registry is to provide comprehensive and up-to-date information on federal organizational prosecutions in the United States, so that we can better understand how corporate prosecutions are brought and resolved. It includes detailed information about every federal organizational prosecution since 2001, as well as deferred and non-prosecution agreements with organizations since 1990.\n\n### Dataset Description\n\nThese data on deferred prosecution and non-prosecution agreements were collected by identifying agreements through news searches, press releases by the Department of Justice and U.S. Attorney\xe2\x80\x99s Office, and also when practitioners brought agreements to our attention. The Government Accountability Office conducted a study of federal deferred prosecution and non-prosecution agreements with organizations, and in August 2010, the GAO provided a list of those agreements in response to an information request. Finally, searches of the Bloomberg dockets database located additional prosecution agreements with companies that had not previously been located. Jon Ashley has contacted U.S. Attorney\xe2\x80\x99s Offices to request agreements. An effort by the First Amendment Clinic at the University of Virginia School of Law to litigate Freedom of Information Act requests resulted in locating a group of missing agreements which are now available on the Registry.\n\nThis Registry only includes information about federal organizational prosecutions, and not cases brought solely in state courts. Nor does this Registry include leniency agreements entered through the Antitrust Division\xe2\x80\x99s leniency program, which are kept confidential. The Registry also does not include convictions overturned on appeal, or cases in which the indictment was dismissed or the company was acquitted at a trial.\n\nThe U.S. Sentencing Commission reports sentencing data concerning organizational prosecutions each year. That data does not include cases resolved without a formal sentencing, such as deferred and non-prosecution agreements.\n\n### Acknowledgements\n\nThe Corporate Prosecutions Registry is a project of the University of Virginia School of Law. It was created by Professor Brandon Garrett (bgarrett@virginia.edu) and Jon Ashley (jaa6c@virginia.edu). Please cite this dataset as: \n\xe2\x80\x9cBrandon L. Garrett and Jon Ashley, Corporate Prosecutions Registry, University of Virginia School of Law, at http://lib.law.virginia.edu/Garrett/corporate-prosecution-registry/index.html\xe2\x80\x9d\n\n### Inspiration\n\n - Which industries face the most prosecutions?\n - Which government organizations have been the most successful at pursuing cases against corporations?\n - Not a single case in the dataset led to a trial conviction. Can you link these corporate cases to criminal cases against the individuals involved? How many of them were convicted instead?'","b""['crime', 'business', 'small', 'featured']""",https://www.kaggle.com/university-of-virginia/corporate-prosecution-registry
b'Interest Rate Records',b'Historic H15 Release Data from the Federal Reserve',"b'The [H15 Release][1] from the federal reserve provides daily interest rate information for a variety of core interest rates, such as T bills and the federal funds rate. For some rates, this dataset extends all the way back to 1954.\n\nThe rates included are:\n\n- time_period\n- federal_funds\n- 1_month_nonfinancial_commercial_paper\n- 2_month_nonfinancial_commercial_paper\n- 3_month_nonfinancial_commercial_paper\n- 1_month_financial_commercial_paper\n- 2_month_financial_commercial_paper\n- 3_month_financial_commercial_paper\n- prime_rate\n- discount_rate\n- 4_week_treasury_bill\n- 3_month_treasury_bill\n- 6_month_treasury_bill\n- 1_year_treasury_bill\n- 1_month_treasury_constant_maturity\n- 3_month_treasury_constant_maturity\n- 6_month_treasury_constant_maturity\n- 1_year_treasury_constant_maturity\n- 2_year_treasury_constant_maturity\n- 3_year_treasury_constant_maturity\n- 5_year_treasury_constant_maturity\n- 7_year_treasury_constant_maturity\n- 10_year_treasury_constant_maturity\n- 20_year_treasury_constant_maturity\n- 30_year_treasury_constant_maturity\n- 5_year_inflation_indexed_treasury_constant_maturity\n- 7_year_inflation_indexed_treasury_constant_maturity\n- 10_year_inflation_indexed_treasury_constant_maturity\n- 20_year_inflation_indexed_treasury_constant_maturity\n- 30_year_inflation_indexed_treasury_constant_maturity\n- inflation_indexed_long_term_average\n\nPlease see https://www.federalreserve.gov/releases/h15/ for notices, caveats, and newly released data.\n\n  [1]: https://www.federalreserve.gov/releases/h15/'","b""['finance', 'government', 'banking', 'small', 'featured']""",https://www.kaggle.com/sohier/interest-rate-records
b'Chat messages',b'Urban night city chat messages',"b""# Context \n\nCollection of chat messages in night urban city between boys and girls.\n\n\n# Content\n\nData set of messages (more than 1 million of rows) in Russian language from teenager population taken in period from 2012 to 2016 inclusive\n\n# Acknowledgements\n\nAll personal info in the message' body were taken from public web source, and, though, are free of use. \n\n# Inspiration\n\nThis dataset can be used to classify chat messages as male / female.\n\n# Key objectives\n\n1. Extract phone numbers from messages. All phone numbers are located in Ukraine and belongs to one from next operators\n\n- +380 50\n- +380 95\n- +380 66\n- +380 99\n- +380 63\n- +380 73\n- +380 93\n- +380 68\n- +380 67\n- +380 96\n- +380 97\n- +380 98\n\n2. Classify chat messages by gender (male/female)""","b""['linguistics', 'cities', 'telecommunications', 'medium', 'featured']""",https://www.kaggle.com/onidzelskyi/chat-messages
b'The General Social Survey (GSS)',"b'Longitudinal study of popular beliefs, attitudes, morality & behaviors in the US'","b'\xe2\x80\x8b\xe2\x80\x8bThe GSS gathers data on contemporary American society in order to monitor and explain trends and constants in attitudes, behaviors, and attributes.  Hundreds of trends have been tracked since 1972. In addition, since the GSS adopted questions from earlier surveys, trends can be followed for up to 70 years.\n\nThe GSS contains a standard core of demographic, behavioral, and attitudinal questions, plus topics of special interest. Among the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.\n\nAltogether the GSS is the single best source for sociological and attitudinal trend data covering the United States. It allows researchers to examine the structure and functioning of society in general as well as the role played by relevant subgroups and to compare the United States to other nations. ([Source][1])\n\nThis dataset is a csv version of the [Cumulative Data File][2], a cross-sectional sample of the GSS from 1972-current.\n\n  [1]: http://gss.norc.org/About-The-GSS\n  [2]: http://gss.norc.org/get-the-data/spss'","b""['ethics', 'political science', 'large', 'featured']""",https://www.kaggle.com/norc/general-social-survey
b'Fantasy Premier League - 2016/2017',"b'Dataset regarding users, fixtures, points of Fantasy English Premier League'","b'# Context \n\n[Fantasy Premier League][1] is the online global competition for Football Enthusiasts to try their luck at picking up their ""Dream Team"" and collect points. It involves a deep understanding of the Sport, Clubs, Players and the Fixtures apart from many other things. All this makes for a compelling Data Science (read Machine Learning Problem).\n\nEnglish Premier League (EPL) - one of the famous leagues in the sport of football. Most viewed and followed across the globe. FPL provides an opportunity for enthusiasts to try their hand at decision making. To predict the best set of players who perform every game. Points are given based on various parameters.\n\n## Goal - To get the maximum Team Score every week\n\n# Content\n\nTime Period - Year 2016-17 Season\n\nDataset consists of\n\n 1. FPL users data (basic information)\n 2. Fixtures (Week-wise)\n 3. Points earned by every user (Gameweek-wise)\n\n# Data Extraction\n\nDetailed Information about the Code\nGithub repo - https://github.com/ChaiBapchya/fantasypremierleague-datascience\n\n# Acknowledgements\n\nThanks to Fantasy Premier League, without which this data would not have been available.\n\n# Inspiration\n\n+ Diego Costa scores a goal every 15 minutes of the match he plays. \n+ Harry Kane is the youngest player to have scored 100 Premier League goals. \n\nSuch statistics (if true) are a compelling read.\n\nBut, to know - \n\n - Nathaniel Chalobah has 70% probability of scoring against Stoke City\n   this weekend. \n - Alexis Sanchez will score around 2 goals this month.\n - Cesc Fabregas is going to assist this weekend. \n - There\'s 70% David De Gea is going to have a clean-sheet.\n\nSuch statistics and much more lend so much credibility to decision making. It would enable Fantasy Premier League team owners to decide :-\n\na. When to choose which player?\n\nb. When is the right time to use the WildCard?\n\nc. If it is time to be patient with a signing?\n\nd. Who to watch out for?\n\nIn order to do this, one needs data to back your predictions. Hence, I was keen on retrieving all this data. \n\n# Future Scope - \n- Predict the best team for the upcoming week.\n- Predict the best player (Highest value for money) (Goalkeeper, Defender, MId-fielder, Attacker)\n- Suggest possible changes in formation if need be.\n\n  [1]: https://fantasy.premierleague.com/ ""Fantasy Premie League""'","b""['association football', 'medium', 'featured']""",https://www.kaggle.com/chaibapat/fantasy-premier-league
b'Barcelona Unemployment',b'Barcelona registered unemployment percentages by hood and month',"b'### Context\n\nThis dataset represents the % of registered unemployment in the city of Barcelona (Spain) from year 2012 till 2016.\n\nRegistered unemployment corresponds to the job demands pending cover by the last day of each month, excluding employees who want to change jobs, the ones that do not have readily available or incompatible situation, the ones that are asking for a specific occupation and the temporary agricultural beneficiaries special unemployment benefit. \n\n\n### Content\n\nAll files in this dataset have the same format. Every row represents a hood from the city.\n\n 1. District number\n 2. Hood name\n 3. Number of citizens from this hood with ages between 16 and 64 (legal ages for having a job)\n 4. 12 columns (one per month), % of unemployment\n\nIn Barcelona we have hoods and districts. Every hood belongs to a district. A district is formed by several hoods.\n\n\n### Acknowledgements\n\nThis data can be found in ""[Open Data BCN - Barcelona\'s City Hall Open Data Service][1]"", which is the owner of the CSV files.\n\n\n### Inspiration\n\nA few weeks ago I needed this datasets for testing purposes.\n\nI have uploaded this information here, because, in my honest opinion, ""data"" and ""research"" should be shared with everybody. Enjoy!\n\n\n  [1]: http://opendata-ajuntament.barcelona.cat/en/'","b""['finance', 'business', 'small', 'featured']""",https://www.kaggle.com/marcvelmer/barcelona-unemployment
b'Case Data from San Francisco 311',b'SF311 cases created since 7/1/2008 with location data',"b""# Context \n\nThis San Francisco 311 dataset contains all 311 cases created since 7/1/2008 (~2M).  SF311 is a way for citizens to obtain information, report problems, or submit service requests to the City and County of San Francisco.  \n\nPotential question(s) to get started with!\n\n - What are some effective visualizations for conveying 311 incidences and trends?\n - How do 311 requests vary by neighborhood? or source? Over time or seasonally?\n - What attributes have the greatest effect on how long it takes a case to close?\n - Is there a way to identify duplicative reports (when multiple people create a 311 report for the same incidence)?\n\n\n\n# Fields\n\nPlease see DataSF's 311 Case Data FAQ [here][1]\n\n - CaseID - (Numeric) - The unique ID of the service request created.\n - Opened - (Timestamp) - The date and time when the service request was made\n - Closed - (Timestamp) - The date and time when the service request was closed\n - Updated - (Timestamp) - The date and time when the service request was last modified. For requests with status=closed, this will be the date the request was closed\n - Status - (Text) - The current status of the service request.\n - Status Notes - (Text) - Explanation of why status was changed to current state or more details on current status than conveyed with status alone\n - Responsible Agency - (Text) - The agency responsible for fulfilling or otherwise addressing the service request.\n - Category - (Text) - The Human readable name of the specific service request type\n - Request Type - (Text) - More specific description of the problem related to the Category\n - Request Details - (Text) - More specific description of the problem related to the Request Type\n - Address - (Text) - Human readable address or description of location\n - Supervisor District - (Numeric) - Supervisor District\n - Neighborhood - (Text) - Neighborhood\n - Point - (Geometry: Point) - latitude and longitude using the (WGS84) projection.\n - Source - (Text) - How the service request was made\n - Media URL - (Text) - Url to media\n\nWe have included the following commonly used geographic shapefile(s):\n\n - [Supervisor Districts as of April 2012][2]\n - Neighborhoods\n\n# Acknowledgements\n\nData provided by [SF311][3] via the San Francisco Open Data Portal at https://data.sfgov.org/d/vw6y-z8j6\n\nPDDL 1.0 ODC Public Domain Dedication and Licence ([PDDL][4])\n\nPhoto via Flickr [Jeremy Brooks][5] [(CC BY-NC 2.0)][6]\n\n\n  [1]: http://support.datasf.org/customer/en/portal/articles/2429403-311-case-data---faq\n  [2]: https://data.sfgov.org/Geographic-Locations-and-Boundaries/Supervisor-Districts-as-of-April-2012/xz9b-wyfc\n  [3]: https://sf311.org/\n  [4]: http://opendatacommons.org/licenses/pddl/1.0/\n  [5]: https://www.flickr.com/photos/jeremybrooks/\n  [6]: https://creativecommons.org/licenses/by-nc/2.0/""","b""['crime', 'medium', 'featured']""",https://www.kaggle.com/datasf/case-data-from-san-francisco-311
b'News Aggregator Dataset',b'Headlines and categories of 400k news stories from 2014',"b""This dataset contains headlines, URLs, and categories for 422,937 news stories collected by a web aggregator between March 10th, 2014 and August 10th, 2014.\n\nNews categories included in this dataset include business; science and technology; entertainment; and health. Different news articles that refer to the same news item (e.g., several articles about recently released employment statistics) are also categorized together.\n\n## Content\nThe columns included in this dataset are:\n\n- **ID** : the numeric ID of the article\n- **TITLE** : the headline of the article\n- **URL** : the URL of the article\n- **PUBLISHER** : the publisher of the article\n- **CATEGORY** : the category of the news item; one of:\n-- *b* : business\n-- *t* : science and technology\n-- *e* : entertainment\n-- *m* : health\n- **STORY** : alphanumeric ID of the news story that the article discusses\n- **HOSTNAME** : hostname where the article was posted\n- **TIMESTAMP** : approximate timestamp of the article's publication, given in Unix time (seconds since midnight on Jan 1, 1970)\n\n## Acknowledgments\nThis dataset comes from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Any publications that use this data should cite the repository as follows:\n\nLichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n\nThis specific dataset can be found in the UCI ML Repository at [this URL](http://archive.ics.uci.edu/ml/datasets/News+Aggregator)\n\n## Inspiration\nWhat kinds of questions can we explore using this dataset? Here are a few possibilities:\n\n- can we predict the category (business, entertainment, etc.) of a news article given only its headline?\n- can we predict the specific story that a news article refers to, given only its headline?""","b""['linguistics', 'news agencies', 'medium', 'featured']""",https://www.kaggle.com/uciml/news-aggregator-dataset
b'Ironic Corpus',b'1950 sentences labeled for ironic content',"b'### Context: \n\nIrony in language is when a statement is produced with one meaning but the intended meaning is exactly the opposite. For instance, someone who has burned toast might serve it and say ironically \xe2\x80\x9cit\xe2\x80\x99s a little underdone\xe2\x80\x9d.  Automatically detecting when language is ironic is an especially difficult task in Natural Language Processing.\n\n### Content: \nThis dataset contains 1950 comments, which have been labeled as ironic (1) or not ironic (-1) by human annotators. The text was taken from Reddit comments.\n\n### Acknowledgements: \n\nThis dataset and analysis of it is presented in the following paper.\n\nWallace, B. C., Do Kook Choe, L. K., Kertz, L., & Charniak, E. (2014, April). Humans Require Context to Infer Ironic Intent (so Computers Probably do, too). In ACL (2) (pp. 512-516). Url: http://www.byronwallace.com/static/articles/wallace-irony-acl-2014.pdf\n\nMade possible by support from the Army Research Office (ARO), grant 64481-MA / W9111F-13-1-0406\n""Sociolinguistically Informed Natural Language Processing: Automating Irony Detection""\n\n### Inspiration: \n\n* Is irony more likely when discussing certain topics?\n* Does ironic text tend to have more positive or more negative sentiment?\n* What novel features can you develop to help detect irony?'","b""['linguistics', 'languages', 'small', 'featured']""",https://www.kaggle.com/rtatman/ironic-corpus
b'Wage Estimates',b'Modeled wage estimates of average hourly wages',"b'###Context: \nThe Occupational Employment Statistics (OES) and National Compensation Survey (NCS) programs have produced estimates by borrowing from the strength and breadth of each survey to provide more details on occupational wages than either program provides individually. Modeled wage estimates provide annual estimates of average hourly wages for occupations by selected job characteristics and within \ngeographical location. The job characteristics include bargaining status (union and nonunion), part- and full-time work status, incentive- and time-based pay, and work levels by occupation.\n\nDirect estimates are based on survey responses only from the particular geographic area to which the estimate refers. In contrast, modeled wage estimates use survey responses from larger areas to fill in information for smaller areas where the sample size is not sufficient to produce direct estimates. Modeled wage estimates require the assumption that the patterns to responses in the larger area hold in the smaller area.\n\nThe sample size for the NCS is not large enough to produce direct estimates by area, occupation, and job characteristic for all of the areas for which the OES publishes estimates by area and occupation. The NCS sample consists of 6 private industry panels with approximately 3,300 establishments sampled per panel, and 1,600 sampled state and local government units. The OES full six-panel sample consists of nearly 1.2 million establishments. \n\nThe sample establishments are classified in industry categories based on the North American Industry Classification System (NAICS). Within an establishment, specific job categories are selected to represent broader occupational definitions. Jobs are classified according to the Standard Occupational Classification (SOC) system.\n\n###Content:\n**Summary**: Average hourly wage estimates for civilian workers in occupations by job characteristic and work levels. These data are available at the national, state, metropolitan, and nonmetropolitan area levels.\n\n**Frequency of Observations**: Data are available on an annual basis, typically in May. \n\n**Data Characteristics**: All hourly wages are published to the nearest cent.\n\n###Acknowledgements: \nThis dataset was taken directly from the Bureau of Labor Statistics and converted to CSV format. \n\n###Inspiration: \nThis dataset contains the estimated wages of civilian workers in the United States. Wage changes in certain industries may be indicators for growth or decline. Which industries have had the greatest increases in wages? Combine this dataset with the Bureau of Labor Statistics Consumer Price Index dataset and find out what kinds of jobs you would need to afford your snacks and instant coffee!'","b""['income', 'medium', 'featured']""",https://www.kaggle.com/bls/wage-estimates
b'Ubudehe Livestock 1',b'Ubudehe Livestock 1 from Rwanda NISR',"b'Overview\nIdentification\nCOUNTRY\nRwanda\nTITLE\nIntegrated Household Living Conditions Survey 2010-2011\n\nTRANSLATED TITLE\nEnqu\xc3\xaate Int\xc3\xa9grale sur les conditions de vie des m\xc3\xa9nages 2010-2011\n\nSTUDY TYPE\nIncome/Expenditure/Household Survey\nSERIES INFORMATION\nThis is the third in a series of periodic standardized income and expenditure surveys. The Rwanda EICV is conducted with a periodicity of 5 years. The surveys in the series are as follows:\n\nEICV1 2000-2001\n\nEICV2 2005-2006\n\nEICV3 2010-2011\n\nID NUMBER\nRWA-NISR-EICV3-02\nVersion\nVERSION DESCRIPTION\nVersion 2.0: Final public-use dataset\n\nPRODUCTION DATE\n2012-10-19\nNOTES\nVersion 2.0\n\nThe date of this version corresponds to the date of NISR approval of the final public-use datasets.\n\nOverview\nABSTRACT\nThe 2010/11 Integrated Household Living Conditions Survey or EICV3 (Enqu\xc3\xaate Int\xc3\xa9grale sur les Conditions de Vie des M\xc3\xa9nages) is the third in the series of surveys which started in 2000/01 and is designed to monitor poverty and living conditions in Rwanda. The survey methodology has changed little over its 10 years, making it ideal for monitoring changes in the country. In 2010/11, for the first time the achieved sample size of 14,308 households in the EICV3 was sufficient to provide estimates which are reliable at the level of the district.\n\nKIND OF DATA\nSample survey data [ssd]\n\nUNITS OF ANALYSIS\nFor the purposes of this study, the following units of analysis are considered:\n\n-communities\n\n-households\n\n-persons\n\nScope\nNOTES\nThe scope of survey is defined by the need to evaluate poverty determinants and effects of poverty in various domains. This includes gathering data in specific sectors and examning summary statistics and computed indicators by consumption indicator, gender etc. The survey primarily seeks to compute household consumption aggregates and correlate consumption to the following areas are within the scope and integrated into the survey:\n\n- Education (education expenditures): general education, curriculum, vocational training and, higher learning, school-leaving, literacy and apprenticeship.\n\n- Health (health expenditures): disability and health problems, general health and preventative vaccination over the past 12 months.\n\n- Migration (travel expenditures): rural-urban migration, internal and external migration.\n\n- Housing (expenditures on utilities, rent etc.): status of the housing occupancy, services and installations, physical characteristics of the dwelling, access and satisfaction towards basic services.\n\n- Economic activity (revenue): unemployment, underemployment and job search, occupation, wage or salaried employment characteristics, VUP Activities, all other activities, domestic work.\n\n- Non-agricultural activities (revenue): activity status, formal and informal sector activity.\n\n- Agriculture (income and expenditure) : livestock, land and agricultural equipment, details of holding parcels/blocs and agricultural policy changes, crop harvests and use on a large and small scale crop production, harvests and use, transformation (processing) of agricultural products.\n\nIn addition to the specific sector information, consumption and/or wealth holding information was collected:\n\n- Consumption: Expenditure on non food items, food expenditure, subsistence farming (own consumption) with different recall periods.\n\n- Other cash flows : transfers out by household, transfers received by the household, income support programs & other revenues (excluding all incomes accrued from saving), VUP, UBUDEHE & RSSP schemes, other expenditure (excluding expenditures related to any form of saving).\n\n- Stock items: credit, durable assets and savings (household assets and liabilities)\n\nTOPICS\nTopic\tVocabulary\tURI\nconsumption/consumer behaviour [1.1]\tCESSDA\thttp://www.nesstar.org/rdf/common\neconomic conditions and indicators [1.2]\tCESSDA\thttp://www.nesstar.org/rdf/common\nEDUCATION [6]\tCESSDA\thttp://www.nesstar.org/rdf/common\ngeneral health [8.4]\tCESSDA\thttp://www.nesstar.org/rdf/common\nemployment [3.1]\tCESSDA\thttp://www.nesstar.org/rdf/common\nunemployment [3.5]\tCESSDA\thttp://www.nesstar.org/rdf/common\nhousing [10.1]\tCESSDA\thttp://www.nesstar.org/rdf/common\ntime use [13.9]\tCESSDA\thttp://www.nesstar.org/rdf/common\nmigration [14.3]\tCESSDA\thttp://www.nesstar.org/rdf/common\ninformation technology [16.2]\tCESSDA\thttp://www.nesstar.org/rdf/common\nCoverage\nGEOGRAPHIC COVERAGE\nThis is a national survey with representivity at the (5) provicial and (30) district level and includes urban and rural households.\n\nGEOGRAPHIC UNIT\nThe cluster\n\nUNIVERSE\nAll household members.\n\nProducers and Sponsors\nPRIMARY INVESTIGATOR(S)\nName\tAffiliation\nNational Institute of Statistics of Rwanda (NISR)\tMinistry of finance and economics planning (MINECOFIN)\nOTHER PRODUCER(S)\nName\tAffiliation\tRole\nOxford Policy Management\tDFID\tPermanante assistance\nGeoffrey Greenwell\tUNDP\tDesigner of data system\nDavid Megill\tUNDP\tStatistician\nMetadata Production\nMETADATA PRODUCED BY\nName\tAbbreviation\tAffiliation\tRole\nJuste NITIEMA\t\tOxford Policy Management (OPM)\tDeveloped the document\nGeoffrey Greenwell\t\tUNDP\tReviewed and edited document\nRuben Muhayiteto\t\tNISR\tRevision of metadata\nDATE OF METADATA PRODUCTION\n2011-06-02\nDDI DOCUMENT VERSION\nVersion 1.0 (Oct. 19,2012) \n\nThis version of the document represents the first draft of the public-use dataset of the EICV 3 study.\n\nVersion 1.1 (June 28th ,2016): Changed the title from French into English\n\nDDI DOCUMENT ID\nRWA-NISR-DDI-EICV3-02'","b""['economics', 'small', 'featured']""",https://www.kaggle.com/jprukundo/ubudehelivestock1
b'NASA Facilities',b'A dataset of NASA facility names and locations',"b'### Context\n\nNASA has something like 400 different facilities across the United States! This dataset is a collection of those facilities and their locations.\n\n### Content\n\n- Center: Name of the ""Center"", a collection facilities\n- Center Search Status: Public or...?\n- Facility: Name of the facility\n- FacilityURL\n- Occupied\n- Status\n- URL Link\n- Record Date\n- Last Update\n- Country\n- Location\n- City\n- State\n- Zipcode\n\n\n### Acknowledgements\n\nThis dataset was downloaded from [https://data.nasa.gov/Management-Operations/NASA-Facilities/gvk9-iz74][1]. The original file was modified to remove contact information for each facility.\n\n\n  [1]: https://data.nasa.gov/Management-Operations/NASA-Facilities/gvk9-iz74'","b""['space', 'spaceflight', 'organizations', 'small', 'featured']""",https://www.kaggle.com/nasa/nasa-facilities
b'Pima Indians Diabetes Database',b'Predict the onset of diabetes based on diagnostic measures',"b'## Context\n\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\n## Content\n\nThe datasets consists of several medical predictor variables and one target variable, `Outcome`. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n\n## Acknowledgements\n\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). [Using the ADAP learning algorithm to forecast the onset of diabetes mellitus][1]. *In Proceedings of the Symposium on Computer Applications and Medical Care* (pp. 261--265). IEEE Computer Society Press.\n\n## Inspiration\n\nCan you build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?\n\n  [1]: http://rexa.info/paper/04587c10a7c92baa01948f71f2513d5928fe8e81'","b""['healthcare', 'india', 'health sciences', 'small', 'featured']""",https://www.kaggle.com/uciml/pima-indians-diabetes-database
"b'ATP Matches, 1968 to 2017'",b'Details of the ATP matches since 1968',"b'The data set contains the details about all the ATP matches played since 1968. The data set has a lot of missing values, especially for the period between 1968 - 1991. \n\nThanks to Xiaming Chen for making the data available to the online community. \n\nPrimarily, I would like to understand how tennis matches/players have evolved over time and any other insights.'","b""['sports', 'tennis', 'medium', 'featured']""",https://www.kaggle.com/sijovm/atpdata
"b'ACLED Asian Conflicts, 2015-2017'",b'35k Conflicts Across Developing Asian Countries',"b'### Context: \nThe [Armed Conflict Location and Event Data Project](https://www.acleddata.com/about-acled/) is designed for disaggregated conflict analysis and crisis mapping. This dataset codes the dates and locations of all reported political violence and protest events in developing Asian countries in. Political violence and protest includes events that occur within civil wars and periods of instability, public protest and regime breakdown. The project covers 2015 to the present.\n\n### Content: \nThese data contain information on:\n\n* Dates and locations of conflict events;\n* Specific types of events including battles, civilian killings, riots, protests and recruitment activities;\n* Events by a range of actors, including rebels, governments, militias, armed groups, protesters and civilians;\n* Changes in territorial control; and\n* Reported fatalities.\n\nEvent data are derived from a variety of sources including reports from developing countries and local media, humanitarian agencies, and research publications. Please review the [codebook](http://www.acleddata.com/wp-content/uploads/2017/01/ACLED_Codebook_2017.pdf) and [user guide](http://www.acleddata.com/wp-content/uploads/2017/01/ACLED_User-Guide_2017.pdf) for additional information: the codebook is for coders and users of ACLED, whereas the brief guide for users reviews important information for downloading, reviewing and using ACLED data. A specific [user guide for development and humanitarian practitioners](http://www.acleddata.com/wp-content/uploads/2017/01/ACLED_User-Guide-for-Humanitarians_2017.pdf) is also available, as is a guide to our sourcing materials.\n\n\n### Acknowledgements: \nACLED is directed by Prof. Clionadh Raleigh (University of Sussex). It is operated by senior research manager Andrea Carboni (University of Sussex) for Africa and Hillary Tanoff for South and South-East Asia. The data collection involves several research analysts, including Charles Vannice, James Moody, Daniel Wigmore-Shepherd, Andrea Carboni, Matt Batten-Carew, Margaux Pinaud, Roudabeh Kishi, Helen Morris, Braden Fuller, Daniel Moody and others. Please cite:\n\nRaleigh, Clionadh, Andrew Linke, H\xc3\xa5vard Hegre and Joakim Karlsen. 2010. Introducing ACLED-Armed Conflict Location and Event Data. Journal of Peace Research 47(5) 651-660.\n\n### Inspiration: \nDo conflicts in one region predict future flare-ups? How do the individual actors interact across time?'","b""['war', 'medium', 'featured']""",https://www.kaggle.com/jboysen/asian-conflicts
b'Atlas of Pidgin and Creole Language Structures',b'Information on 76 Creole and Pidgin Languages',"b'### Context: \nWhen groups of people who don\xe2\x80\x99t share a spoken language come together, they will often create a new language which combines elements of their first languages. These languages are known as \xe2\x80\x9cpidgins\xe2\x80\x9d. If they are then learned by children as their first language they become fully-fledged languages known as \xe2\x80\x9ccreoles\xe2\x80\x9d. This dataset contains information on both creoles and pidgins spoken around the world.\n\n### Content: \nThis dataset includes information on the grammatical and lexical structures of 76 pidgin and creole languages. The language set contains not only the most widely studied Atlantic and Indian Ocean creoles, but also less well known pidgins and creoles from Africa, South Asia, Southeast Asia, Melanesia and Australia, including some extinct varieties, and several mixed languages.\n\nThis dataset is made up of several tables, each of which contains different pieces of information:\n\n* language: A table of language names & the unique id\xe2\x80\x99s associated with them.\n* language_data: A table of data on the different languages, including the name speakers\xe2\x80\x99 call their language (Autoglossonym), other names the language is called, how many speakers it has, the language which contributed the most words to the language (Major lexifier), other languages which contribute to that language, where it is spoken, and where it is an official language fro. The column language_id has the id linked to the language table.\n* language_source: The sources referenced on each language (referencing the language and source tables).\n* langauge_table: Information on the geographic location of each language.\n* source: Information on the scholarly sources referenced for information on language.\n\n### Acknowledgements: \nThis dataset contains information from the online portion of the [Atlas of Pidgin and Creole Language Structures (APiCS)](http://apics-online.info/). It is distributed under a [Creative Commons Attribution 3.0 Unported License](https://creativecommons.org/licenses/by/3.0/) . If you use this dataset in your work, please use this citation:\n\nSalikoko S. Mufwene. 2013. Kikongo-Kituba structure dataset. \nIn: Michaelis, Susanne Maria & Maurer, Philippe & Haspelmath, Martin & Huber, Magnus (eds.) \nAtlas of Pidgin and Creole Language Structures Online. \nLeipzig: Max Planck Institute for Evolutionary Anthropology. \n(Available online at http://apics-online.info/contributions/58, Accessed on 2017-07-28.)\n\n### Inspiration: \n\n* Which areas of the world have the most creoles/pidgins?\n* Which language has contributed to the most creoles/pidgins? Why might this be?\n* Can you map the areas of influence of the various lexicalized Major Lexifier languages? \n\n### You may also be interested in:\n\n* [World Language Family Map](https://www.kaggle.com/rtatman/world-language-family-map)\n* [The Sign Language Analyses (SLAY) Database](https://www.kaggle.com/rtatman/sign-language-analyses)\n* [World Atlas of Language Structures: Information on the linguistic structures in 2,679 languages](https://www.kaggle.com/rtatman/world-atlas-of-language-structures)'","b""['linguistics', 'languages', 'small', 'featured']""",https://www.kaggle.com/rtatman/atlas-of-pidgin-and-creole-language-structures
b'Jester Collaborative Filtering Dataset',"b""70,000+ users' rating of 100 witty jokes""","b'### Context\n\nThe funniness of joke is very subjective. Having more than 70,000 users rate jokes, can an algorithm be written to identify the universally funny joke?\n\n### Content\n\n- The data file are in **.csv** format.\n- The complete dataset is 100 rows and 73422 columns.\n- The complete dataset is split into 3 **.csv** files.\n- **JokeText.csv** contains the Id of the joke and the complete joke string.\n- **UserRatings1.csv** contains the ratings provided by the first 36710 users.\n- **UserRatings2.csv** contains the ratings provided by the last 36711 users.\n- The dataset is arranged such that the initial users have rated higher number of jokes than the later users.\n- The rating is a real value between **-10.0** and **+10.0**.\n- The **empty values** indicate that the user has not provided any rating for that particular joke.\n\n### Acknowledgements\n\nThe dataset is associated with the below research paper.\n\n[Eigentaste: A Constant Time Collaborative Filtering Algorithm.](http://www.ieor.berkeley.edu/~goldberg/pubs/eigentaste.pdf) Ken Goldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins. Information Retrieval, 4(2), 133-151. July 2001.\n\nMore information and datasets can be found at [http://eigentaste.berkeley.edu/dataset/](http://eigentaste.berkeley.edu/dataset/)\n\n### Inspiration\n\nSince funniness is a very subjective matter, it will be very interesting to see if data science can bring out the details on what makes something funny.'","b""['humor', 'medium', 'featured']""",https://www.kaggle.com/aakaashjois/jester-collaborative-filtering-dataset
b'SqueezeNet 1.1',b'SqueezeNet 1.1 Pre-trained Model for PyTorch',"b'# SqueezeNet 1.0\n\n---\n\n## SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size<br>\nRecent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). \n<br>\n\n**Authors: Forrest N. Iandola, Song Han, Matthew W. Moskewicz, Khalid Ashraf, William J. Dally, Kurt Keutzer**<br>\n**https://arxiv.org/abs/1602.07360**\n\n---\n\n#SqueezeNet Architectures<br>\n![SqueezeNet Architecture][1]\n\n\n---\n\n### What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset. \n\n### Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it. \n\n\n  [1]: https://imgur.com/WV7Ru4Q.jpg'","b""['machine learning', 'pre-trained model', 'small', 'featured']""",https://www.kaggle.com/pytorch/squeezenet11
b'General Election Results',"b'November 8, 2016 General Election for the State of Arizona'","b'### Context\n\nThe 2016 Statewide General Election results for Arizona.\n\nArizona\'s 15 counties are required by statute to publish tabulated General Election results by precinct. This file represents a standardized and aggregated version of all 15 files. Please note that while the file is mostly standardized, many of the attributes are relatable accross counties via a fuzzy match (the keyword ""Congress"" etc...).\n\n\n### Content\n\n 1. County: Abbreviation of Arizona\'s 15 counties\n  - AP: Apache\n  - CH: Cochise\n  - CN: Coconino\n  - GI: Gila\n  - GM: Graham\n  - GN: Greenlee\n  - LP: La Paz\n  - MC: Maricopa\n  - MO: Mohave\n  - NA: Navajo\n  - PM: Pima\n  - PN: Pinal\n  - SC: Santa Cruz\n  - YA: Yavapai\n  - YU: Yuma\n\n 2. PrecinctID: Precinct identification number designated by the counties. County shorthand has been added.\n 3. PrecinctName: Precinct Name designated by the counties. This is directly passed from the tabulation files. \n 4. ContestID: Contest Identification number designated by the counties. This is directly passed from the tabulation files and may not be standardized across counties.\n 5. ContestTitle: Title of race as designated by counties. This is directly passed from the tabulation files and may not be standardized across counties.\n 6. CandidateID: Candidate identification number designated by the counties. This is directly passed form the tabulation files and may not be standardized across counties.\n 7. CandidateName: Name of Candidate as desingated by the counties. This is directly passed form the tabulation files and may not be standardized across counties.\n 8. TotalVotes: Vote Total aggregated from the attributes ""PollVotes, EarlyVotes, Provisionals, LatePoll, LateEarly"". \n 9. PollVotes: Total votes tabulated at a designated precinct location on election day.\n 10. EarlyVotes: Total votes tabulated by the counties during the 29 day early voting period.\n 11. Provisionals: Total votes tabulated at a designated precinct location that were deemed acceptable provisional ballots.\n 12: LateEarly: Total votes tabulated by the counties of early votes that were dropped off at designated polling locations rather than received in the mail. (Note: only a few counties separated this number from EarlyVote in their tabulation files).\n 13. Registered: The number of registered voters at the time of the election in each designated precinct.\n 14. Undervote: The number of ballots that did note cast the allowed number of votes for any given race. (Example: voters are allowed to ""vote for 2"" in the Arizona House of Representatives race, in this case these ballots were either left blank or only voted for 1)\n 15. ContestTotal: Total votes cast in a given contest.\n 16. CandidateParty: Party of candidate in a given contest.\n    - REP: Republican\n    - DEM: Democrat\n    - NP: No Party\n    - GRN: Green\n    - LBT: Libertarian\n 17. TotalTurnout: Total turnout for a designated precinct.\n 18. EDTurnout: Total turnout for a designated precinct on election day.\n 19. EarlyTurnout: Total turnout for a designated precinct during the 29 day early voting period. (Note, this number will include early ballots dropped off at the designated polling location.)\n\n\nFinal Note: There are certain records in the file that are not part of any contest. They are normally designated by a contest ID that begins with a ""999"" These are records that the tabulators append to every file to provide background on each of the designated precincts.\n\n \n\n\n'","b""['politics', 'medium', 'featured']""",https://www.kaggle.com/arizonaSecofState/2016-statewide-general-election-results
b'Sensor readings from a wall-following robot',b'Data collected from a robot while navigating around a room',"b'### Context\n\n- The data were collected as the SCITOS G5 navigated through the room following the wall in a clockwise  direction, for 4 \n rounds. To navigate, the robot uses 24 ultrasound sensors arranged circularly around its ""waist"".  The numbering of the ultrasound sensors starts at the front of the robot and increases in clockwise direction.\n\n- The provided files comprise three diferent data sets. \n\n  - The first one contains the raw values of the measurements  of all 24 ultrasound sensors and the corresponding class label (Moving forward, turning left, etc). Sensor readings are sampled at a rate of 9 samples per second.\n\n  - The second one contains four sensor readings named \'simplified distances\' and the corresponding class label l (Moving forward, turning left, etc). These simplified distances are referred to as the \'front distance\', \'left distance\', \'right distance\' and \'back distance\'.  They consist, respectively, of the minimum sensor readings among those within 60 degree arcs located at the front, left,  right and back parts of the robot.\n\n  - The third one contains only the front and left simplified distances and the corresponding class labell (Moving forward, turning left, etc). \n\t\n- It is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same  time step, so each file has the same number of rows (one for each sampling time step).                                                           \n\n- The wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions. \n\n- If some kind of short-term memory mechanism is provided to the neural classifiers, their performances are improved in general.  For example, if past inputs are provided together with current sensor readings, even the Perceptron becomes able to learn the task and command the robot successfully. If a recurrent neural network, such as the Elman network, is used to learn the task, the resulting dynamical classifier is able to learn the task using less hidden neurons than the MLP network.\n\n- Files with different number of sensor readings were built in order to evaluate the performance of the classifiers with respect to the number of inputs.\n\n\n### Content\n\nFile sensor_readings_24.csv:\n\n  - US1: ultrasound sensor at the front of the robot (reference angle: 180\xc2\xb0) - (numeric: real)\n  - US2: ultrasound reading (reference angle: -165\xc2\xb0) - (numeric: real)\n  - US3: ultrasound reading (reference angle: -150\xc2\xb0) - (numeric: real)\n  - US4: ultrasound reading (reference angle: -135\xc2\xb0) - (numeric: real)\n  - US5: ultrasound reading (reference angle: -120\xc2\xb0) - (numeric: real)\n  - US6: ultrasound reading (reference angle: -105\xc2\xb0) - (numeric: real)\n  - US7: ultrasound reading (reference angle: -90\xc2\xb0) - (numeric: real)\n  - US8: ultrasound reading (reference angle: -75\xc2\xb0) - (numeric: real)\n  - US9: ultrasound reading (reference angle: -60\xc2\xb0) - (numeric: real)\n  - US10: ultrasound reading (reference angle: -45\xc2\xb0) - (numeric: real)\n  - US11: ultrasound reading (reference angle: -30\xc2\xb0) - (numeric: real)\n  - US12: ultrasound reading (reference angle: -15\xc2\xb0) - (numeric: real)\n  - US13: reading of ultrasound sensor situated at the back of the robot (reference angle: 0\xc2\xb0) - (numeric: real)\n  - US14: ultrasound reading (reference angle: 15\xc2\xb0) - (numeric: real)\n  - US15: ultrasound reading (reference angle: 30\xc2\xb0) - (numeric: real)\n  - US16: ultrasound reading (reference angle: 45\xc2\xb0) - (numeric: real)\n  - US17: ultrasound reading (reference angle: 60\xc2\xb0) - (numeric: real)\n  - US18: ultrasound reading (reference angle: 75\xc2\xb0) - (numeric: real)\n  - US19: ultrasound reading (reference angle: 90\xc2\xb0) - (numeric: real)\n  - US20: ultrasound reading (reference angle: 105\xc2\xb0) - (numeric: real)\n  - US21: ultrasound reading (reference angle: 120\xc2\xb0) - (numeric: real)\n  - US22: ultrasound reading (reference angle: 135\xc2\xb0) - (numeric: real)\n  - US23: ultrasound reading (reference angle: 150\xc2\xb0) - (numeric: real)\n  - US24: ultrasound reading (reference angle: 165\xc2\xb0) - (numeric: real)\n  - Classes:  Move-Forward, Slight-Right-Turn, Sharp-Right-Turn, Slight-Left-Turn\n\nFile: sensor_readings_4.csv:\n\n  - SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real)\n  - SD_left:  minimum sensor reading within a 60 degree arc located at the left of the robot  - (numeric: real)\n  - SD_right: minimum sensor reading within a 60 degree arc located at the right of the robot - (numeric: real)\n  - SD_back:  minimum sensor reading within a 60 degree arc located at the back of the robot - (numeric: real)\n  - Classes:  Move-Forward, Slight-Right-Turn, Sharp-Right-Turn, Slight-Left-Turn\n\nFile: sensor_readings_2.csv:\n\n  - SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real)\n  - SD_left:  minimum sensor reading within a 60 degree arc located at the left of the robot - (numeric: real)\n  - Classes:  Move-Forward, Slight-Right-Turn, Sharp-Right-Turn, Slight-Left-Turn\n\n\n### Acknowledgements\n\nThese datasets were downlaoded from the UCI Machine Learning Repository\n\nLichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n\n### Inspiration\n\nUse these ultrasound readings to predict the class, i.e. given these readings, is the robot moving straight? turning left?\n'","b""['robotics', 'small', 'featured']""",https://www.kaggle.com/uciml/wall-following-robot
b'Magic The Gathering Cards',b'Analyze cards from this classic trading card game',"b'Magic The Gathering (MTG, or just Magic) is a trading card game first published in 1993 by Wizards of the Coast. This game has seen immense popularity and new cards are still released every few months. The strength of different cards in the game can vary wildly and as a result some cards now sell on secondary markets for as high as thousands of dollars.\n\n[MTG JSON][1] has an excellent collection of every single Magic Card - stored in JSON data. Version 3.6 (collected September 21, 2016) of their database is provided here.\n\nFull documentation for the data is provided here:\nhttp://mtgjson.com/documentation.html\n\nAlso, if you want to include images of the cards in your writeups, you can grab them from the official Wizards of the Coast website using the following URL:\n\nhttp://gatherer.wizards.com/Handlers/Image.ashx?multiverseid=180607&type=card\n\nJust replace the multiverse ID with the one provided in the mtgjson file.\n\n\n  [1]: http://mtgjson.com'","b""['games and toys', 'card games', 'medium', 'featured']""",https://www.kaggle.com/mylesoneill/magic-the-gathering-cards
b'Top 100 Chess Players Historical',b'The Top 100 ranked players in Chess between July 2000 and June 2017',"b'### Context\n\nRankings are a constant phenomenon in society, with a  persistent interest in the stratification of items in a set across various disciplines. In sports, rankings are a direct representation of the performance of a team or player over a certain period.  Given the straightforward nature of rankings in sports (points based system) there is the opportunity to statistically explore rankings of sports disciplines. \n\n\n### Content\n\nThe dataset comprises monthly rankings data of the Top 100 Chess players between July 2000 and June 2017 . The data is housed in a single csv file. \n\n### Acknowledgements\n\nData was sourced from the official site of the World Chess Federation: fide.com\n\n### Inspiration\n\nThis dataset could be of use to anyone interested in the distribution of rankings in competitive events.'","b""['board games', 'small', 'featured']""",https://www.kaggle.com/odartey/top-chess-players
b'Election News Headlines',"b""A day's harvest of election headlines from Nepal's news homepages ""","b""### Context\nThe headlines, with links in most cases, were harvested for a quick viewing of the kinds of election talk the online news media were carrying as the campaign picked up steam ahead of Nepal's first federal and provincial elections less than a month away. \n\n\n### Content\n\nThe headlines, with links preceding them, were scraped from 24 news websites of Nepal on 11/14/2017. They comprise 510 lines of Nepali texts in UTF-8, after removing the links in English.\n\n\n### Acknowledgements\n\nThe dataset is part of a personal hobby of the author to take stock of the election talk going on in Nepali media at the moment. This was possible thanks to the Python libraries, requests and bs4, available with the Jupyter notebooks on Anaconda.   \n\n\n### Inspiration\n\nMedia headlines tend to be a succinct gist of the election talk going on in the campaign period, with their potential to throw light on the kind of rhetoric and quality of arguments used for election gains. What can a text analysis of the headlines show?    ""","b""['internet', 'linguistics', 'politics', 'small', 'featured']""",https://www.kaggle.com/blogdish/election-news-headlines
b'League of Legends',"b'Competitive matches, 2015 to 2018'","b'League of Legends competitive matches between 2015-2017. The matches include the NALCS, EULCS, LCK, LMS, and CBLoL leagues as well as the World Championship and Mid-Season Invitational tournaments.'","b""['video games', 'medium', 'featured']""",https://www.kaggle.com/chuckephron/leagueoflegends
b'US Stocks Fundamentals (XBRL)',"b'Fundamental data for 12,129 companies based on XBRL'","b'This dataset contains US stocks fundamental data, such as income statement, balance sheet and cash flows.\n\n - 12,129 companies\n -  8,526 unique indicators\n -  ~20 indicators comparable across most companies\n -  Five years of data, yearly\n\nThe data is provided by http://usfundamentals.com.'","b""['finance', 'medium', 'featured']""",https://www.kaggle.com/usfundamentals/us-stocks-fundamentals
b'World Gender Statistics',"b'Sex-disaggregated and gender-specific data on demographics, education, etc.'","b""The Gender Statistics database is a comprehensive source for the latest sex-disaggregated data and gender statistics covering demography, education, health, access to economic opportunities, public life and decision-making, and agency.\n\n## The Data\n\nThe data is split into several files, with the main one being Data.csv. The Data.csv contains all the variables of interest in this dataset, while the others are lists of references and general nation-by-nation information.\n\nData.csv contains the following fields:\n\n### Data.csv\n\n- **Country.Name**: the name of the country\n- **Country.Code**: the country's code\n- **Indicator.Name**: the name of the variable that this row represents\n- **Indicator.Code**: a unique id for the variable\n- **1960 - 2016**: one column EACH for the value of the variable in each year it was available\n\n### The other files\n\nI couldn't find any metadata for these, and I'm not qualified to guess at what each of the variables mean. I'll list the variables for each file, and if anyone has any suggestions (or, even better, actual knowledge/citations) as to what they mean, please leave a note in the comments and I'll add your info to the data description.\n\n**Country-Series.csv**\n\n- **CountryCode**\n- **SeriesCode**\n- **DESCRIPTION**\n\n**Country.csv**\n\n- **Country.Code**\n- **Short.Name**\n- **Table.Name**\n- **Long.Name**\n- **2-alpha.code**\n- **Currency.Unit**\n- **Special.Notes**\n- **Region**\n- **Income.Group**\n- **WB-2.code**\n- **National.accounts.base.year**\n- **National.accounts.reference.year**\n- **SNA.price.valuation**\n- **Lending.category**\n- **Other.groups**\n- **System.of.National.Accounts**\n- **Alternative.conversion.factor**\n- **PPP.survey.year**\n- **Balance.of.Payments.Manual.in.use**\n- **External.debt.Reporting.status**\n- **System.of.trade**\n- **Government.Accounting.concept**\n- **IMF.data.dissemination.standard**\n- **Latest.population.census**\n- **Latest.household.survey**\n- **Source.of.most.recent.Income.and.expenditure.data**\n- **Vital.registration.complete**\n- **Latest.agricultural.census**\n- **Latest.industrial.data**\n- **Latest.trade.data**\n- **Latest.water.withdrawal.data**\n\n**FootNote.csv**\n\n- **CountryCode**\n- **SeriesCode**\n- **Year**\n- **DESCRIPTION**\n\n**Series-Time.csv**\n\n- **SeriesCode**\n- **Year**\n- **DESCRIPTION**\n\n**Series.csv**\n\n- **Series.Code**\n- **Topic**\n- **Indicator.Name**\n- **Short.definition**\n- **Long.definition**\n- **Unit.of.measure**\n- **Periodicity**\n- **Base.Period**\n- **Other.notes**\n- **Aggregation.method**\n- **Limitations.and.exceptions**\n- **Notes.from.original.source**\n- **General.comments**\n- **Source**\n- **Statistical.concept.and.methodology**\n- **Development.relevance**\n- **Related.source.links**\n- **Other.web.links**\n- **Related.indicators**\n- **License.Type**\n\n\n## Acknowledgements\n\nThis dataset was downloaded from [The World Bank's Open Data project](http://data.worldbank.org/). The summary of the Terms of Use of this data is as follows:\n\n- You are free to copy, distribute, adapt, display or include the data in other products for commercial and noncommercial purposes at no cost subject to certain limitations summarized below.\n\n- You must include attribution for the data you use in the manner indicated in the metadata included with the data.\n\n- You must not claim or imply that The World Bank endorses your use of the data by or use The World Bank\xe2\x80\x99s logo(s) or trademark(s) in conjunction with such use.\n\n- Other parties may have ownership interests in some of the materials contained on The World Bank Web site. For example, we maintain a list of some specific data within the Datasets that you may not redistribute or reuse without first contacting the original content provider, as well as information regarding how to contact the original content provider. Before incorporating any data in other products, please check the list: [Terms of use: Restricted Data.](http://data.worldbank.org/restricted-data)\n\n-- [ed. note: this last is not applicable to the Gender Statistics database]\n\n- The World Bank makes no warranties with respect to the data and you agree The World Bank shall not be liable to you in connection with your use of the data.\n\n- This is only a summary of the Terms of Use for Datasets Listed in The World Bank Data Catalogue. Please read the actual agreement that controls your use of the Datasets, which is available here: Terms of use for datasets. Also see World Bank Terms and Conditions.""","b""['demographics', 'education', 'utility', 'gender', 'medium', 'featured']""",https://www.kaggle.com/theworldbank/world-gender-statistics
b'Car Sale Advertisements',b'Data collected from private car sale advertisements in Ukraine',"b'#Context\n\nThis dataset was collected by me from car sale advertisements for study/practice purposes in 2016. Though there is couple well known car features datasets they seems quite simple and outdated. Car topic is really interesting. But I wanted to practice with real raw data which has all inconvenient moments (as NA\xe2\x80\x99s for example).\n\nThis dataset contains data for more than 9.5K cars sale in Ukraine. Most of them are used cars so it opens the possibility to analyze features related to car operation. At the end of the day I look at this data as a subset from all Ukrainian car fleet.\n\n# Content\n\nDataset contains 9576 rows and 10 variables with essential meanings:\n\n - car: manufacturer brand \n - price: seller\xe2\x80\x99s price in advertisement (in USD)\n - body: car body type \n - mileage: as mentioned in advertisement (\xe2\x80\x98000 Km)\n - engV: rounded engine volume (\xe2\x80\x98000 cubic cm)\n - engType: type of fuel (\xe2\x80\x9cOther\xe2\x80\x9d in this case should be treated as NA) \n - registration: whether car registered in Ukraine or not \n - year: year of production \n - model: specific model name \n - drive: drive type\n\nData has gaps, so be careful and check for NA\xe2\x80\x99s.\nI tried to check and drop repeated offers, but theoretically duplications are possible.\n\n#Inspiration\n\nData will be handy to study and practice different models and approaches. \nAs a further step you can compare patters in Ukrainian market to your own domestic car market characteristics.'","b""['automobiles', 'small', 'featured']""",https://www.kaggle.com/antfarol/car-sale-advertisements
b'Human Resources Data Set',b'Dataset used for learning data visualization and basic regression',"b'### Context\nHR data can be hard to come by, and HR professionals generally lag behind with respect to analytics and data visualization competency. Thus, Dr. Carla Patalano and I set out to create our own HR-related dataset, which is used in one of our graduate MSHRM courses called HR Metrics and Analytics, at New England College of Business. We created this data set ourselves.\n\n### Content\n\nThere are multiple worksheets within the Excel workbook. These include\n\n- Core data set\n- Production staff\n- Sales analysis\n- Salaries\n- Recruiting sources\n\nThe Excel workbook revolves around a fictitious company, called Dental Magic, and the core data set contains names, DOBs, age, gender, marital status, date of hire, reasons for termination, department, whether they are active or terminated, position title, pay rate, manager name, and performance score.\n\n### Acknowledgements\n\nDr. Carla Patalano provided many suggestions for creating this synthetic data set, which has been used now by over 30 Human Resource Management students at the college. Students in the course learn data visualization techniques with Tableau Desktop and use this data set to complete a series of assignments.\n\n### Inspiration\n\n- Is there any relationship between who a person works for and their performance score?\n- What is the overall diversity profile of the organization?\n- What are our best recruiting sources if we want to ensure a diverse organization?\n\nThere are so many other interesting questions that could be addressed through this interesting data set. Dr. Patalano and I look forward to seeing what we can come up with.'","b""['business', 'employment', 'small', 'featured']""",https://www.kaggle.com/rhuebner/human-resources-data-set
b'Independent Political Ad Spending (2004-2016)',b'Spending on political ads by independent (non-candidate) groups',"b'## What is an Independent Expenditure?\n\nIndependent expenditures are what some refer to as ""hard money"" in politics -- spending on ads that specifically mention a candidate (either supporting or opposing). The money for these ads must come from PACs that are independent of the candidate and campaign, and the PACs cannot coordinate with the candidate.\n\nThe Federal Election Commission (FEC) collects information on independent expenditures to ensure payers\' independence from candidates.\n\n## What can we look at?\n\nI\'m super interested to see how much spending has increased over the years. The FEC data only goes back to 2004, and it may be the case that the older data is spotty, but I don\'t doubt that political spending has gone up in the past few years (the 2016 Presidential campaign reportedly involved the most political money since the 1970s).\n\n## What does the data look like?\n\nThis dataset includes a ton of information from the independent expenditure reports:\n\n- **committee_id** : unique id of the PAC that made the payment\n- **committee_name** : name of the PAC that made the payment\n- **report_year** : the year the report was file\n- **report_type** : one of 24 or 48; whether this is a 24-hour report or a 48-hour report\n- **image_number** : unique id of the scanned image of the report\n- **line_number** : line number in the report\n- **file_number** : unique id of the report\n- **payee_name** : who got paid\n- **payee_first_name** : if an individual payee, their first name\n- **payee_middle_name** : if an individual payee, their middle name\n- **payee_last_name** : if an individual payee, their last name\n- **payee_street_1** : payee street address (1 of 2)\n- **payee_street_2** : payee street address (2 of 2)\n- **payee_city** : payee city\n- **payee_state** : payee state\n- **payee_zip** : payee ZIP code\n- **expenditure_description** : a string describing the expenditure\n- **expenditure_date** : when was this expenditure made?\n- **dissemination_date** : when was the advertisement disseminated?\n- **expenditure_amount** : how much was spent?\n- **office_total_ytd** : how much has this PAC spent on this office, year-to-date?\n- **category_code** : category of the expenditure (*need to find categories!*)\n- **category_code_full** : category of the expenditure (*need to find categories!*)\n- **support_oppose_indicator** : one of S or O; whether the ad is in support of or opposition to the candidate\n- **memo_code** :\n- **memo_code_full** :\n- **candidate_id** : unique id of the candidate\n- **candidate_name** : name of the candidate\n- **candidate_prefix** : title or prefix of the candidate\n- **candidate_first_name** : first name of the candidate\n- **candidate_middle_name** : middle name of the candidate\n- **candidate_last_name** : last name of the candidate\n- **candidate_suffix** : suffix of the candidate\'s name\n- **candidate_office** : office that the candidate is running for -- one of P (President), S (Senate), or H (House)\n- **cand_office_state** : if House or Senate race, in what state?\n- **cand_office_district** : if House or Senate race, in what district?\n- **conduit_committee_id** :\n- **conduit_committee_name** :\n- **conduit_committee_street1** :\n- **conduit_committee_street2** :\n- **conduit_committee_city** :\n- **conduit_committee_state** :\n- **conduit_committee_zip** :\n- **election_type** : one of P (primary) or G (general)\n- **election_type_full** : an id comprising the election type and the year, with no delimiter\n- **independent_sign_name** :\n- **independent_sign_date** :\n- **notary_sign_name** :\n- **notary_sign_date** :\n- **notary_commission_expiration_date** :\n- **back_reference_transaction_id** :\n- **back_reference_schedule_name** :\n- **filer_first_name** : \n- **filer_middle_name** :\n- **filer_last_name** :\n- **transaction_id** : unique id identifying the transaction\n- **original_sub_id** :\n- **action_code** :\n- **action_code_full** :\n- **schedule_type_full** :\n- **filing_form** :\n- **link_id** :\n- **sub_id** :\n- **payee_prefix** :\n- **payee_suffix** :\n- **is_notice** :\n- **memo_text** :\n- **filer_prefix** :\n- **filer_suffix** :\n- **schedule_type** :\n- **pdf_url** : link to the scanned form'","b""['finance', 'politics', 'medium', 'featured']""",https://www.kaggle.com/fec/independent-political-ad-spending
b'Firearms Provisions in US States',"b'Presence of 133 Provisions in US States, 1991-2017'","b'### Context: \nThe State Firearm Laws project aims to provide researchers with the data necessary to evaluate the effectiveness of various firearm laws. By carefully monitoring how gun legislation impacts firearm-related violence, we can provide policymakers with the evidence they need to make gun ownership safer for everyone.\n\nAmmunition regulations establish rules for anyone in the business of buying or selling firearm ammunition. Federal regulation of firearm ammunition usually accompanies the regulation of firearms, rather than existing independently. For example, the federal age requirements for ammunition purchase, by type of firearm and type of dealer, are the same as those for the purchase of firearms, and the populations that are prohibited from possessing firearms are also prohibited from possessing firearm ammunition.\n\n### Content: \nData covers all 50 US States, 1991-2017 and includes:\n\n* Vendor license required to sell ammunition.\n* Records of ammunition sales must be retained by the dealer.\n* Permit required to purchase ammunition.\n* Background checks required for ammunition purchases.\n* Sale of ammunition is restricted to the same categories of those who are legally allowed to purchase firearms.\n* Purchase of any type of ammunition restricted to those ages 18 and older.\n* Purchase of handgun ammunition restricted to those ages 21 and older.\n\n\n### Acknowledgements: \nOne-hundred of the 133 provisions were coded by Michael Siegel, MD, MPH, Boston University School of Public Health, with funding from the Robert Wood Johnson Foundation, Evidence for Action: Investigator-Initiated Research to Build a Culture of Health program (grant #73337), using data derived from the Thomson Reuters Westlaw legislative database. The other 33 provisions were coded using a database created by Everytown for Gun Safety and Legal Science, LLC. Shared in accordance with the Creative Commons Attribution-4.0 International License, which is incorporated herein by this reference. No changes were made to the original coding, but the data were adapted for use in this database. See the [codebook](https://www.statefirearmlaws.org/download-codebook.html) for a list of which provisions were coded by which source. Additional materials include an associated [report](https://www.statefirearmlaws.org/report/SFL-Report-2016.pdf) and [related publications](https://www.statefirearmlaws.org/publications.html). \n\n### Inspiration: \n* Which states have seen the most increase in regulation? Any decrease?\n* Can you correlate gun laws and homicides from [this dataset](https://www.kaggle.com/murderaccountability/homicide-reports)?'","b""['government', 'government agencies', 'small', 'featured']""",https://www.kaggle.com/jboysen/state-firearms
"b'Rocket alerts in Israel made by ""Tzeva Adom""'",b'List of rocket alerts in Israel published by the Israeli Home Front Command',"b'### Context\n\nSince 2001, Palestinian militants have launched thousands of rocket and mortar attacks on Israel from the Gaza Strip as part of the continuing Arab\xe2\x80\x93Israeli conflict. From 2004 to 2014, these attacks have killed 27 Israeli civilians, 5 foreign nationals, 5 IDF soldiers, and at least 11 Palestinians and injured more than 1900 people, but their main effect is their creation of widespread psychological trauma and disruption of daily life among the Israeli population.\n\nsource:\n\nWikipedia[https://en.wikipedia.org/wiki/Palestinian_rocket_attacks_on_Israel]\n\n### Content\n\nThis dataset contains the latest rocket alerts released by the Israeli ""Home Front Security"". The data was aggregated in the http://tzeva-adom.com site.\n\nThe column contains date in dd/mm/yy format, time mm:hh format and the name of the area in Hebrew (And sometimes messages like:\n\n\xd7\x94\xd7\x95\xd7\xa4\xd7\xa2\xd7\x9c\xd7\x94 \xd7\x91\xd7\x99\xd7\xa9\xd7\x95\xd7\x91 \xd7\x91\xd7\xa2\xd7\x95\xd7\x98\xd7\xa3 \xd7\xa2\xd7\x96\xd7\x94- \xd7\x9b\xd7\x9b\xd7\x94\'\'\xd7\xa0 \xd7\x90\xd7\x99\xd7\x9b\xd7\x95\xd7\x9f \xd7\xa9\xd7\x95\xd7\x95\xd7\x90 which means that it\'s a false alarm. Those messages can be easily distinguished by the length of them.\n\nArea sizes may differ and does not report exact coordinates.\n\nA list of all the possible areas and messages is in a separate file.\n\nData is reported from 2013-2014.\n\n\n### Acknowledgements\n\nContext was taken from the Wikipedia page: Palestinian rocket attacks on Israel.\nData generated by the Israeli Home Front Command and was made easily accessible to developers(Many apps were created based on it. Reporting the alarm during the last conflict).\n\nThe data was aggregated at the site http://tzeva-adom.com.\n\n### Inspiration\n\nIsrael has a system called ""Iron Dome"" which intercepts rockets(But only from certain distance).  The challenge for Israel is where those systems should be deployed and at what times. Furthermore, it will be interesting to find patterns in the times rockets were being launched, trying to see if different places were targeted in different times of day.\nAlso, areas that were targeted at the same time find if it\'s possible to cluster the places into different groups of areas.\n\nOperation ""Protective Edge"" took place from 8 July until 26 August 2014. After it ended,  The rocket attack ended (more or less) until today(June 2017). It will be interesting to check out how the operation effects the alerts, the launching patterns, targeted areas, etc.\n\nThough the names in this dataset are in Hebrew, no Hebrew knowledge is needed for working with this dataset. I tried to find an appropriate automatic transliteration service to English, but non of them proved useful. If anyone knows how to get them in English, even using some list from the internet of the cities names in English and their corresponding Hebrew names,  I\'ll appreciate your contribution to the dataset\'s GitHub repository:\n\nhttps://github.com/tomersa/tzeva_adom_dataset.git\n\nAlso, you may contact me and I\'ll add the changes.'","b""['international relations', 'war', 'small', 'featured']""",https://www.kaggle.com/sab30226/rocket-alerts-in-israel-made-by-tzeva-adom
b'Trump Administration Financial Disclosures',b'Financial data submitted by Trump federal appointees',"b'### Context\n\nBefore joining the federal executive administration, new government appointees must submit, amongst other things, detailed information regarding their finances and previous job history. Such disclosure rules are in place in order to prevent conflicts of interest, and are a fundamental part of the work done by government ethics commissions. This dataset is a condensed collection of information recovered from these forms for a selection of top Trump administration appointees.\n\n### Content\n\nThis dataset is split into five separate `CSV` files: \n\n * `names_and_job_titles.csv` -- The names and job titles of appointees. Not all appointees are included in this dataset.\n * `jobs_before_joining_admin.csv` -- Positions held by administration members immediately prior to their joining the federal government.\n * `clients_before_joining_admin.csv` -- Former appointee clients before joining the federal government.\n * `income_sources_and_assets.csv` -- All acknowledged and disclosed income sources and assets. The most important file.\n * `debts.csv` -- Known appointee debt obligations. This record is incomplete.\n * `employee_agreements.csv` -- Agreements that the appointee made as part of the conditions of their entering employment with the federal government.\n\n### Acknowledgements\n\nProPublica, The New York Times, the Associated Press, and others [pooled their resources](https://www.propublica.org/article/white-house-wouldnt-post-trump-staffers-financial-disclosures) to collect and condense disclosure forms for many prominent members of the Trump administration. These were in turn collected into a [public spreadsheet](https://docs.google.com/spreadsheets/d/1R5AOpTBa6kro2qbSRa7kUD-Gg2FKD7v6vc2EJS7Dooo/). This dataset is a further condensation of this work.\n\n### Inspiration\n\nWhat can you discover about the finances and potential conflicts of interest of members of the Trump administration by looking at the raw government record?'","b""['politics', 'united states', 'government', 'money', 'small', 'featured']""",https://www.kaggle.com/residentmario/trump-financial-disclosures
b'Vehicle Fuel Economy',b'Mileage and more for 1948-2018',"b""Fuel economy data are the result of vehicle testing done at the Environmental Protection Agency's National Vehicle and Fuel Emissions Laboratory in Ann Arbor, Michigan, and by vehicle manufacturers with oversight by EPA.\n\n### Content\n\nPlease see the csvs labeled with 'fields' for descriptions of the data fields; there are too many to list here.\n\n### Acknowledgements\n\nThis dataset was kindly provided by the US EPA. You can find the original dataset, which is updated regularly, [here][1].\n\n### Inspiration\n\n- How has the rate of change of fuel economy changed over time?\n- Do simple clustering techniques on vehicles lead to the same groupings that are typically associated with manufacturers, such as putting Porsche and BMW together in a luxury car group?\n\n\n  [1]: https://www.fueleconomy.gov/feg/download.shtml""","b""['government agencies', 'vehicles', 'medium', 'featured']""",https://www.kaggle.com/epa/vehicle-fuel-economy
b'World Development Indicators',b'Explore country development indicators from around the world',"b""The World Development Indicators from the World Bank contain over a thousand annual indicators of economic development from hundreds of countries around the world.\r\n\r\nHere's a [list of the available indicators](https://www.kaggle.com/benhamner/d/worldbank/world-development-indicators/indicators-in-data) along with a [list of the available countries](https://www.kaggle.com/benhamner/d/worldbank/world-development-indicators/countries-in-the-wdi-data).\r\n\r\nFor example, this data includes the life expectancy at birth from many countries around the world:\r\n\r\n[![Life expactancy at birth map](https://www.kaggle.io/svf/148550/984799c02510d42a0ef29b5770284d00/map.png)](https://www.kaggle.com/benhamner/d/worldbank/world-development-indicators/r-rworldmap-visualization-example)\r\n\r\nThe dataset hosted here is a slightly transformed verion of the raw files [available here](http://data.worldbank.org/data-catalog/world-development-indicators) to facilitate analytics.""","b""['economics', 'international relations', 'large', 'featured']""",https://www.kaggle.com/worldbank/world-development-indicators
b'Character Encoding Examples',b' Example text files for five popular text encodings',"b'### Context:\n\nCharacter encodings are sets of mappings from raw bits (0\xe2\x80\x99s and 1\xe2\x80\x99s) to text characters. When a text encoded with a specific encoder is decoded with a different encoder, it changes the output text. Sometimes this results in completely unreadable text.\n\nThis dataset is intended to provide a list of example texts in different character encodings to help you diagnose which file encoding your source file actually in. \n\n### Content\n\nThis dataset is made up of six text files that represent five different character encodings and six different languages. The character encodings represented in this dataset are ISO-8859-1 (also known as Latin 1), \n\nASCII, Windows 1251, UTF-16 that has been successfully converted into the UTF-8 and BIG-5. More information on the files is available in the file_guide.csv file.\n\nEach  text file contains a header and footer. The body text is delimited by this text:\n\n*** START OF THE PROJECT GUTENBERG EBOOK [TITLE OF BOOK GOES HERE] ***\n\n*** END OF THE PROJECT GUTENBERG EBOOK [TITLE OF BOOK GOES HERE]***\n\n### Acknowledgements: \n\nThe texts in this dataset were prepared by Project Gutenberg volunteers. These texts are in the public domain. \n\n### Inspiration: \n\n* Can you build an tool to automatically detect when a file in the wrong encoding is read in?\n* You can use this dataset to explore what happens when you read in text using different encoders.'","b""['linguistics', 'languages', 'computer science', 'programming languages', 'writing', 'small', 'featured']""",https://www.kaggle.com/rtatman/character-encoding-examples
b' Bestseller books on Paytm',b' 1500 bestseller books on Paytm',"b""###Context\n\nThis is a pre-crawled dataset, taken as subset of a bigger [dataset (more than 16,000 books)][1] that was created by extracting data from paytm.com, a leading eCommerce store in India.\n\n### Content\n\nThis dataset has following fields:\n\n- amtsave\n- brand\n- breadcrumbs\n- country\n- desc\n- discount\n- domain\n- gallery\n- image\n- insertedon\n- list_price\n- model\n- name\n- other_sellers\n- payment_methods_supported\n- productcode\n- selling_price\n- specifications\n- type\n- uniq_id\n- url\n- weight\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud's in-house web-crawling service.\n\n### Inspiration\nAnalyses of pricing, discount, specifications and authors can be performed.\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=pt-kaggle&utm_medium=referral""","b""['internet', 'books', 'small', 'featured']""",https://www.kaggle.com/PromptCloudHQ/bestseller-books-on-paytm
b'Workers Browser Activity in CrowdFlower Tasks',b'In-page behaviour of crowdworkers performing tasks on CrowdFlower',"b'### Context\n\nData Scientists often use crowdsourcing platforms, such as Amazon Mechanical Turk or CrowdFlower to collect labels for their data. Controlling high quality and timeless execution of tasks is an important part of such collection process. It is not possible (or not efficient) to manually check every worker assignment. There is an intuition that there quality could be predicted based on workers task browser behaviour (e.g. key presses, scrolling, mouse clicks, tab switching). In this dataset there are assignment results for 3 different crowdsourcing tasks launched on CrowdFlower, along with associated workers behaviour.\n\n\n### Content\n\nWe collected data running 3 tasks: \n\n - Image labelling,  \n - Receipt Transcription,  \n - Business Search.\n\n![Task User Interface][1]\n\nTasks are described in tasks.csv.\nResults for corresponding tasks are given in files: results_{task_id}.csv. Workers\'s activity could be found in the following files:\n\n * activity_keyboard.csv - timestamps of keyboard keys pressed\n * activity_mouse.csv - timestamps of mouse clicks with associated HTML elements\n * activity_tab.csv - timestamps of event task browser tab changes (opened, active, hidden, closed)\n * activity_page.csv - a summary of events happened in the task page every 2 seconds (boolean keyboard activity, boolean mouse movement activity, boolean scrolling activity, the position of the screen, boolean if text was selected)\n\nResult files have a similar structure to the original one given by CrowdFlower:\n\n * _unit_id: A unique ID number created by the system for each row\n * _created_at: The time the contributor submitted the judgement \n * _golden: This will be ""true"" if this is a test question, otherwise it is ""false""\n * _id: A unique ID number generated for this specific judgment\n * _missed: This will be ""true"" if the row is an incorrect judgment on a test question.\n * _started_at: The time at which the contributor started working on the judgement\n * _tainted: This will be ""true"" if the contributor has been flagged for falling below the required accuracy. This judgment will not be used in the aggregation.\n * _channel: The work channel that the contributor accessed the job through\n * _trust: The contributor\'s accuracy. Learn more about trust here\n * _worker_id: A unique ID number assigned to the contributor (in the current dataset MD5 value is given)\n * _country: The country the contributor is from\n * _region: A region code for the area the contributor is from\n * _city: The city the contributor is from\n * _ip: The IP address for the contributor (in the current dataset MD5 value is given)\n * {{field}}: There will be a column for each field in the job, with a header equal to the field\'s name.\n * {{field}}_gold: The correct answer for the test question\n\n### Acknowledgements\n\nWe thank crowd workers who accomplished our not always exciting tasks on CrowdFlower. \n\n\n  [1]: http://bit.ly/2wWtuDe'","b""['web sites', 'medium', 'featured']""",https://www.kaggle.com/humancomp/worker-activity-crowdflower
b'Vegetarian and Vegan Restaurants',"b'A list of over 18,000 restaurants that serve vegetarian or vegan food in the US.'","b""# About This Data\nThis is a list of over 18,000 restaurants in the US that serve vegetarian or vegan food provided by [Datafiniti's Business Database][1]. The dataset includes address, city, state, business name, business categories, menu data, phone numbers, and more.\n\n*Note that this is a sample of a large data set. The full data set is available through Datafiniti.*\n\n# What You Can Do With This Data\nYou can use this data to determine the [most vegetarian and vegan-friendly cities in the US][2]. E.g.:\n\n - How many restaurants in each metro area offers vegetarian options?\n - Which metros among the 25 most popular metro areas have the most and least vegetarian restaurants per 100,000 residents?\n - Which metros with at least 10 vegetarian restaurants have the most vegetarian restaurants per 100,000 residents?\n - How many restaurants in each metro area offers vegan options?\n - Which metros among the 25 most popular metro areas have the most and least vegan restaurants per 100,000 residents?\n - Which metros with at least 10 vegan restaurants have the most vegan restaurants per 100,000 residents?\n - Which cuisines are served the most at vegetarian restaurants?\n\n# Data Schema\nA full schema for the data is available in our [support documentation][3].\n\n# About Datafiniti\nDatafiniti provides instant access to web data. We compile data from thousands of websites to create standardized databases of business, product, and property information. [Learn more][4].\n\n# Want More?\nYou can get more data like this by [joining Datafiniti][5] or [requesting a demo][6].\n\n  [1]: https://datafiniti.co/products/business-data/\n  [2]: https://datafiniti.co/city-best-for-vegetarians/\n  [3]: https://datafiniti-api.readme.io/docs/business-data-schema\n  [4]: https://datafiniti.co\n  [5]: https://portal.datafiniti.co/login\n  [6]: https://datafiniti.co/request-a-demo/""","b""['food and drink', 'business', 'databases', 'small', 'featured']""",https://www.kaggle.com/datafiniti/vegetarian-vegan-restaurants
b'Solar Radiation Prediction',b'Task from NASA Hackathon',"b'# Context \n\nSpace Apps Moscow was held on April 29th & 30th. Thank you to the 175 people who joined the International Space Apps Challenge at this location!\n\n\n\n# Content\n\nThe dataset contains such columns as: ""wind direction"", ""wind speed"", ""humidity"" and temperature. The response parameter that is to be predicted is: ""Solar_radiation"". It contains measurements for the past 4 months and you have to predict the level of solar radiation.\nJust imagine that you\'ve got solar energy batteries and you want to know will it  be reasonable to use them in future?\n\n\n# Acknowledgements\n\nThanks NASA for the dataset.\n\n# Inspiration\n\nPredict the level of solar radiation.\nHere are some intersecting dependences that i have figured out:\n1. Humidity & Solar_radiation.\n2.Temeperature & Solar_radiation.\n\nThe best result of accuracy  I could get using cross-validation was only 55%.'","b""['energy', 'space', 'small', 'featured']""",https://www.kaggle.com/dronio/SolarEnergy
b'Election Day Tweets',"b'Tweets scraped from Twitter on November 8, 2016'","b'Tweets scraped by [Chris Albon](https://github.com/chrisalbon) on the day of the 2016 United States elections.\n\nChris Albon\'s site only posted tweet IDs, rather than full tweets. We\'re in the process of scraping the full information, but due to API limiting this is taking a very long time. Version 1 of this dataset contains just under 400k tweets, about 6% of the 6.5 million originally posted.\n\nThis dataset will be updated as more tweets become available.\n\n## Acknowledgements\n\n[The original data](https://github.com/chrisalbon/election_day_2016_twitter) was scraped by [Chris Albon](https://github.com/chrisalbon), and tweet IDs were posted to his Github page.\n\n## The Data\n\nSince I (Ed King) used my own Twitter API key to scrape these tweets, this dataset contains a couple of fields with information on whether I have personally interacted with particular users or tweets. Since Kaggle encouraged me to not remove any data from a dataset, I\'m leaving it in; feel free to build a classifier of the types of users I follow.\n\nThe dataset consists of the following fields:\n\n- **text**: text of the tweet\n- **created_at**: date and time of the tweet\n- **geo**: a JSON object containing coordinates [latitude, longitude] and a `type\'\n- **lang**: Twitter\'s guess as to the language of the tweet\n- **place**: a Place object from the Twitter API\n- **coordinates**: a JSON object containing coordinates [longitude, latitude] and a `type\'; **note** that coordinates are reversed from the **geo** field\n- **user.favourites_count**: number of tweets the user has favorited\n- **user.statuses_count**: number of statuses the user has posted\n- **user.description**: the text of the user\'s profile description\n- **user.location**: text of the user\'s profile location\n- **user.id**: unique id for the user\n- **user.created_at**: when the user created their account\n- **user.verified**: bool; is user verified?\n- **user.following**: bool; am I (Ed King) following this user?\n- **user.url**: the URL that the user listed in their profile (not necessarily a link to their Twitter profile)\n- **user.listed_count**: number of lists this user is on (?)\n- **user.followers_count**: number of accounts that follow this user\n- **user.default_profile_image**: bool; does the user use the default profile pic?\n- **user.utc_offset**: positive or negative distance from UTC, in seconds\n- **user.friends_count**: number of accounts this user follows\n- **user.default_profile**: bool; does the user use the default profile?\n- **user.name**: user\'s profile name\n- **user.lang**: user\'s default language\n- **user.screen_name**: user\'s account name\n- **user.geo_enabled**: bool; does user have geo enabled?\n- **user.profile_background_color**: user\'s profile background color, as hex in format ""RRGGBB"" (no \'#\')\n- **user.profile_image_url**: a link to the user\'s profile pic\n- **user.time_zone**: full name of the user\'s time zone\n- **id**: unique tweet ID\n- **favorite_count**: number of times the tweet has been favorited\n- **retweeted**: is this a retweet?\n- **source**: if a link, where is it from (e.g., ""Instagram"")\n- **favorited**: have I (Ed King) favorited this tweet?\n- **retweet_count**: number of times this tweet has been retweeted\n\n\nI\'ve also included a file called ```bad_tweets.csv``` , which includes all of the tweet IDs that could not be scraped, along with the error message I received while trying to scrape them. This typically happens because the tweet has been deleted, the user has deleted their account (or been banned), or the user has made their tweets private. The fields in this file are **id** and **exception.response**.'","b""['internet', 'politics', 'medium', 'featured']""",https://www.kaggle.com/kinguistics/election-day-tweets
b'Classic Literature in ASCII',b'Explore some of the most influential english language works',"b""On the internet of the 1980's everything was stored in ASCII text files. During these early days, many literary works were manually typed up and shared widely. [TEXTFILES.COM][1] is a website by Jason Scott dedicated to collecting and preserving text files from this internet of the past. This dataset is a small subset of his total collection - focussing exclusively on english literary works. \n\nEach book is stored in its own ASCII text file and all are in English. How similar are the writing styles of so-called classic authors? Can you train a model to determine if a work is fictional or not? What words or phrases are the most popular in these books?\n\n\n  [1]: http://textfiles.com""","b""['internet', 'literature', 'medium', 'featured']""",https://www.kaggle.com/mylesoneill/classic-literature-in-ascii
"b'Airports, Train Stations, and Ferry Terminals'","b""Openflight.org's database of the worlds transportation hubs""","b'### Context\n\nThis is a database of airports, train stations, and ferry terminals around the world. Some of the data come from public sources and some of it comes from OpenFlights.org user contributions.\n\n### Content\n\n- Airport ID\tUnique OpenFlights identifier for this airport.\n- Name\tName of airport. May or may not contain the City name.\n- City\tMain city served by airport. May be spelled differently from Name.\n- Country\tCountry or territory where airport is located. See countries.dat to cross-reference to ISO 3166-1 codes.\n- IATA\t3-letter IATA code. Null if not assigned/unknown.\n- ICAO\t4-letter ICAO code.\n- Null if not assigned.\n- Latitude\tDecimal degrees, usually to six significant digits. Negative is South, positive is North.\n- Longitude\tDecimal degrees, usually to six significant digits. Negative is West, positive is East.\n- Altitude\tIn feet.\n- Timezone\tHours offset from UTC. Fractional hours are expressed as decimals, eg. India is 5.5.\n- DST\tDaylight savings time. One of E (Europe), A (US/Canada), S (South America), O (Australia), Z (New Zealand), N (None) or U (Unknown). See also: Help: Time\n- Tz database time zone\tTimezone in ""tz"" (Olson) format, eg. ""America/Los_Angeles"".\n- Type\tType of the airport. Value ""airport"" for air terminals, ""station"" for train stations, ""port"" for ferry terminals and ""unknown"" if not known.\n- Source\tSource of this data. ""OurAirports"" for data sourced from OurAirports, ""Legacy"" for old data not matched to OurAirports (mostly DAFIF), ""User"" for unverified user contributions. In airports.csv, only source=OurAirports is included.\n\n\n### Acknowledgements\n\nThis dataset was downloaded from [Openflights.org][1] under the Open Database license. This is an excellent resource and there is a lot more on their website, so check them out! \n\n  [1]: https://openflights.org/data.html'","b""['vehicles', 'transport', 'aviation', 'public transport', 'rail transport', 'small', 'featured']""",https://www.kaggle.com/open-flights/airports-train-stations-and-ferry-terminals
b'Restaurants on Yellowpages.com',"b'6,000 Restaurants on Yellowpages.com'","b'###Context\n\nThis is a pre-crawled dataset, taken as subset of a bigger [dataset (more than 85,000 restaurants)][1] that was created by extracting data from yellowpages.com.\n\n<a href=""https://upload.wikimedia.org/wikipedia/en/thumb/7/7f/Yellow_Pages_logo.svg/1024px-Yellow_Pages_logo.svg.png"" style=""width:250px""/>\n\n### Content\n\nThis dataset has following fields:\n\n - `Url`\n - `Name`\n - `Street`\n - `Zip Code`\n - `City`\n - `State`\n - `Phone`\n - `Email`\n - `Website`\n - `Categories` - A comma-delimited (`,`) list of categories the listing in question falls under. Most listings are placed in multiple categories.\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud\'s in-house web-crawling service.\n\n### Inspiration\nAnalyses of city and categories can be performed.\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=yp-kaggle&utm_medium=referral'","b""['internet', 'hotels', 'small', 'featured']""",https://www.kaggle.com/PromptCloudHQ/restaurants-on-yellowpagescom
b'Aviation Accident Database & Synopses',b'The NTSB aviation accident dataset',"b'# Content\n\nThe NTSB aviation accident database contains information from 1962 and later about civil aviation accidents and selected incidents within the United States, its territories and possessions, and in international waters.\n\n\n# Acknowledgements\n\nGenerally, a preliminary report is available online within a few days of an accident. Factual information is added when available, and when the investigation is completed, the preliminary report is replaced with a final description of the accident and its probable cause. Full narrative descriptions may not be available for dates before 1993, cases under revision, or where NTSB did not have primary investigative responsibility.\n\n# Inspiration\nHope it will teach us how to improve the quality and safety of traveling by Airplane.'","b""['aviation', 'small', 'featured']""",https://www.kaggle.com/khsamaha/aviation-accident-database-synopses
b'SF Historic Secured Property Tax Rolls',b'SF secured property tax roll spanning from 2007 to 2015',"b'# Context \n\nThis data set includes the Office of the Assessor-Recorder\xe2\x80\x99s secured property tax roll spanning from 2007 to 2015 (~1.6M). It includes all legally disclosable information, including location of property, value of property, the unique property identifier, and specific property characteristics. The data is used to accurately and fairly appraise all taxable property in the City and County of San Francisco. The Office of the Assessor-Recorder makes no representation or warranty that the information provided is accurate and/or has no errors or omissions. \n\nPotential question(s) to get started with!\n\n - Can the effects of [Prop 13][1] been seen in the historic property tax rolls?\n\n\n# Fields\n\nThere are 48 fields in this dataset.  \n\nA full data dictionary can be found [here][2].\n\nWe have included the following commonly used geographic shapefiles:\n\n - [Analysis Neighborhoods][3]\n - [Supervisor Districts as of April 2012][4]\n\n\n\n# Acknowledgements\n\nData provided by the [San Francisco Office of the Assessor-Recorder][6] via the San Francisco Open Data Portal at https://data.sfgov.org/d/wv5m-vpq2\nPDDL 1.0 ODC Public Domain Dedication and Licence ([PDDL][7]) \n\nPhoto from Flickr via [Rebecca Morgan][8] [(CC BY-NC-SA 2.0)][9]\n\n\n  [1]: https://ballotpedia.org/California_Proposition_13_(1978)\n  [2]: https://data.sfgov.org/api/views/wv5m-vpq2/files/3360189c-38b9-48bd-ac1c-1b39a8353662?download=true&filename=ASR-0001_DataDictionary_historic-secured-property-rolls.xlsx\n  [3]: https://data.sfgov.org/Geographic-Locations-and-Boundaries/Analysis-Neighborhoods/p5b7-5n3h\n  [4]: https://data.sfgov.org/Geographic-Locations-and-Boundaries/Supervisor-Districts-as-of-April-2012/xz9b-wyfc\n  [5]: http://\n  [6]: http://www.sfassessor.org\n  [7]: http://opendatacommons.org/licenses/pddl/1.0/\n  [8]: https://www.flickr.com/photos/iheartvanillapesto/2493740462/in/photostream/\n  [9]: https://creativecommons.org/licenses/by-nc-sa/2.0/'","b""['finance', 'politics', 'cities', 'medium', 'featured']""",https://www.kaggle.com/datasf/sf-historic-secured-property-tax-rolls
b'Pesticide Use in Agriculture',b'Which compounds are used most frequently in the United States?',"b'# Content\n\nThis dataset includes annual county-level pesticide use estimates for 423 pesticides (active ingredients) applied to agricultural crops grown in the contiguous United States. Two different methods were used to estimate a range of pesticide use for all states except California. Both low and high estimate methods incorporated proprietary surveyed rates for United States Department of Agriculture Crop Reporting Districts, but the estimates differed in how they treated situations when a district was surveyed and pesticide use was not reported. Low estimates assumed zero use in the district for that pesticide; however, high estimates treated the unreported use of pesticides as missing data and estimated the pesticide usage from neighboring locations within the same region.\n\n\n# Acknowledgements\n\nData for the state of California was provided by the 2014 Department of Pesticide Regulation Pesticide Use Report. The 2015 report is not yet available.'","b""['agriculture', 'medium', 'featured']""",https://www.kaggle.com/usgs/pesticide-use
b'USDA PLANTS Checklist',b'Names of plants that grow in North America.',"b'### Context\n\nThis dataset is a checklist of plants known to grow in North America. The list is maintained by the United States Department of Agriculture.\n\n### Content\n\nThis data includes scientific names and common names of all plants in the United States.\n\n### Acknowledgements\n\nThis dataset is published as-is by the United States Department of Agriculture.\n\n### Inspiration\n\nWhat words are commonly used in plant names? Can you detect any trends in, say, adjectives commonly used in plant names that are less commonly used in the English language?'","b""['agriculture', 'plants', 'small', 'featured']""",https://www.kaggle.com/usdeptofag/usda-plants-checklist
b'Averaged Perceptron Tagger',b'The model that nltk.pos_tag loads',"b'### Context\n\nThe `averaged_perceptron_tagger.zip` contains the pre-trained English [Part-of-Speech (POS]](https://en.wikipedia.org/wiki/Part_of_speech) tagger in NLTK.  \n\nThe `nltk.tag.AveragedPerceptronTagger` is the default tagger as of NLTK version 3.1. The model was trained on on Sections 00-18 of the Wall Street Journal sections of [OntoNotes 5](https://catalog.ldc.upenn.edu/ldc2013t19)\n\nThe original implementation comes from [Matthew Honnibal](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python), it outperforms the [predecessor maximum entropy POS model](https://stackoverflow.com/questions/31386224/what-created-maxent-treebank-pos-tagger-english-pickle) in NLTK. \n\nThe version from [Textblob](https://github.com/sloria/textblob-aptagger) was ported over to NLTK in [pull-request #122](https://github.com/nltk/nltk/issues/1122).\n\n### Acknowledgements\n\n - Credit goes to [Matthew Honnibal](https://twitter.com/honnibal). \n - The reimplementation in Textblob by [Steven Loria](https://github.com/sloria/textblob-aptagger)\n - Re-reimplementation in NLTK by [Long Duong](https://sites.google.com/site/longduongunimelb/)'","b""['small', 'featured']""",https://www.kaggle.com/nltkdata/averaged-perceptron-tagger
b'Steven Wilson detector',"b""Finding songs that match Steven Wilson's style""","b""### Context\n\nI'm going straight to the point: I'm obsessed with Steven Wilson. I can't help it, I love his music. And I *need* more music with similar (almost identical) style. So, what I'm trying to solve here is, **how to find songs that match SW's style with almost zero error?**\n\n![][1]\n\nI'm aware that Spotify gives you recommendations, like similar artists and such. But that's not enough -- Spotify always gives you varied music. Progressive rock is a very broad genre, and I just want those songs that sound very, **very** similar to Steven Wilson or Porcupine Tree.\n  \nBTW, Porcupine Tree was Steven Wilson's band, and they both sound practically the same. [I made an analysis](https://www.kaggle.com/danielgrijalvas/comparing-steven-wilson-and-porcupine-tree) where I checked their musical similarities.\n\n### Content\n\nI'm using the Spotify web API to get the data. They have an amazingly rich amount of information, especially the [audio features](https://developer.spotify.com/web-api/get-audio-features/).  \n  \nThis repository has **5** datasets: \n\n - `StevenWilson.csv`: contains Steven Wilson discography (65 songs)\n - `PorcupineTree.csv`:  65 Porcupine Tree songs\n - `Complete Steven Wilson.csv`: a merge between the past two datasets (Steven Wilson + Porcupine Tree)\n - `Train.csv`: 200 songs used to train KNN. 100 are Steven Wilson songs and the rest are totally different songs\n - `Test.csv`: 100 songs that may or may not be like Steven Wilson's. I picked this songs from various prog rock playlists and my Discover Weekly from Spotify.  \n  \nAlso, so far I've made two kernels: \n\n - [Comparing Steven Wilson and Porcupine Tree](https://www.kaggle.com/danielgrijalvas/comparing-steven-wilson-and-porcupine-tree) \n - [Finding songs that match SW's style using K-Nearest Neighbors](https://www.kaggle.com/danielgrijalvas/finding-songs-that-match-sw-s-style-using-knn)\n\n### Data\nThere are **21** columns in the datasets. \n\n**Numerical**: this columns were scraped using [get_audio_features](https://developer.spotify.com/web-api/get-audio-features/) from the Spotify API. \n\n - `acousticness`: a confidence measure from 0.0 to 1.0 of whether the track is acoustic; 1.0 represents high confidence the track is acoustic\n - `danceability`: it describes how suitable a track is for dancing; a value of 0.0 is least danceable and 1.0 is most danceable\n - `duration_ms`: the duration of the track in milliseconds\n - `energy`: a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity\n - `instrumentalness`: predicts whether a track contains no vocals; values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0\n - `liveness`: detects the presence of an audience in the recording; 1.0 represents high confidence that the track was performed live\n - `loudness`: the overall loudness of a track in decibels (dB)\n - `speechiness`: detects the presence of spoken words in a track; the more exclusively speech-like the recording (e.g. talk show), the closer to 1.0 the attribute value\n - `tempo`: the overall estimated tempo of a track in beats per minute (BPM)\n - `valence`: a measure from 0.0 to 1.0 describing the musical positiveness; tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry)  \n\n**Categorical**: these features are categories represented as numbers. \n\n - `key`: the musical key the track is in. e.g. 0 = C, 1 = C\xe2\x99\xaf/D\xe2\x99\xad, 2 = D, and so on\n - `mode`: mode indicates the modality (major or minor); major is represented by 1 and minor is 0\n - `time_signature`: an estimated overall [time signature](https://en.wikipedia.org/wiki/Time_signature) of a track; it is a notational convention to specify how many beats are in each bar (or measure). e.g. 4/4, 4/3, 3/4, 8/4 etc.\n\n**Strings**: these fields are mostly useless (except for name, album, artist and lyrics) \n \n - `id`: the Spotify ID of the song\n - `name`: name of the song\n - `album`: album of the song\n - `artist`: artist of the song\n - `uri`: the Spotify URI of the song\n - `type`: the type of the Spotify object\n - `track_href`: the Spotify API link of the song\n - `analysis_url`: the URL used for getting the audio features\n - `lyrics`: lyrics of the song in lower case\n\n### Future\nEver been obsessed with a song? an album? an artist? I'm planning on building a web app that solves this. It will help you find music extremely similar to other. \n\n\n  [1]: https://38.media.tumblr.com/b358910974f6582d49fc526c2e774c2e/tumblr_msq6s8LEij1s75866o1_500.gif""","b""['music', 'small', 'featured']""",https://www.kaggle.com/danielgrijalvas/steven-wilson-analysis
b'Education Statistics',b'From World Bank Open Data',"b""### Content  \n\n<p>The World Bank EdStats All Indicator Query holds over 4,000 internationally comparable indicators that describe education access, progression, completion, literacy, teachers, population, and expenditures. The indicators cover the education cycle from pre-primary to vocational and tertiary education.</p>\n<p>The query also holds learning outcome data from international and regional learning assessments (e.g. PISA, TIMSS, PIRLS), equity data from household surveys, and projection/attainment data to 2050. For further information, please visit the EdStats website.</p>  \n\n### Context  \n\nThis is a dataset hosted by the World Bank. The organization has an open data platform found [here](https://databank.worldbank.org/) and they update their information according the amount of data that is brought in. Explore the World Bank using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  \n\n* Update Frequency: This dataset is updated daily.\n\n### Acknowledgements\n\nThis dataset is maintained using the World Bank's [APIs](data.worldbank.org/developers) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/6tXwyNEsnCI) by [Melvin Thambi](https://unsplash.com/@melvinthambi) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['world', 'education', 'utility', 'countries', 'medium', 'featured']""",https://www.kaggle.com/theworldbank/education-statistics
"b'Hurricanes and Typhoons, 1851-2014'","b'Location, wind, and pressure of tropical cyclones in Atlantic and Pacific Oceans'","b""# Context \n\nThe National Hurricane Center (NHC) conducts a post-storm analysis of each tropical cyclone in the Atlantic\nbasin (i.e., North Atlantic Ocean, Gulf of Mexico, and Caribbean Sea) and and the North Pacific Ocean to determine the official assessment of the cyclone's history. This analysis makes use of all available observations, including those that may not have been available in real time. In addition, NHC conducts ongoing reviews of any retrospective tropical cyclone analyses brought to its attention and on a regular basis updates the historical record to reflect\nchanges introduced.\n\n\n# Content\n\nThe NHC publishes the tropical cyclone historical database in a format known as HURDAT, short for HURricane DATabase. These databases (Atlantic HURDAT2 and NE/NC Pacific HURDAT2) contain six-hourly information on the location, maximum winds, central pressure, and (starting in 2004) size of all known tropical cyclones and subtropical cyclones.""","b""['weather', 'small', 'featured']""",https://www.kaggle.com/noaa/hurricane-database
b'Australian Marriage Law Postal Survey',b'Should the law be changed to allow same-sex couples to marry?',"b""### Introduction\n\nOn 9 August 2017, the Treasurer, under the Census and Statistics Act 1905, directed the Australian Statistician to collect and publish statistical information from all eligible Australians on the Commonwealth Electoral Roll, about their views on whether or not the law should be changed to allow same-sex couples to marry.\n\nThe voluntary survey asked one question: should the law be changed to allow same-sex couples to marry?  Respondents were asked to mark one box \xe2\x80\x93 Yes or No \xe2\x80\x93 on the survey form.\n\nSurvey materials were mailed to eligible Australians on the Commonwealth Electoral Roll as at 24 August 2017.\n\nA range of strategies were implemented to assist all eligible Australians who wished to complete the survey to do so. A survey response was received from 12,727,920 (79.5%) eligible Australians.\n\nThe ABS implemented robust systems and controls for the processing, coding and publication of statistical data. Detailed information on the systems used as well as the accuracy and integrity of the data is available in the Survey Process and the Quality and Integrity Statement.\n\nThe official statistics include a count of responses (Yes, No and Response Not Clear) by Federal Electoral Division (FED), State/Territory and National. This also includes a count of eligible Australians who have not participated in the survey.\n\nInformation from the Commonwealth Electoral Roll has been used to independently produce a participation rate by age and gender for each FED, State/Territory and National.  This rate has been published by gender, for each of the following age groups: 18-19 years, 20-24 years, 25-29 years, 30-34 years, 35-39 years, 40-44 years, 45-49 years, 50-54 years, 55-59 years, 60-64 years, 65-69 years, 70-74 years, 75-79 years, 80-84 years, and 85+ years.\n\n### National results\n\n*Should the law be changed to allow same-sex couples to marry?*\n\nOf the eligible Australians who expressed a view on this question, the majority indicated that the law should be changed to allow same-sex couples to marry, with 7,817,247 (61.6%) responding Yes and 4,873,987 (38.4%) responding No. Nearly 8 out of 10 eligible Australians (79.5%) expressed their view.\n\nAll states and territories recorded a majority Yes response. 133 of the 150 Federal Electoral Divisions recorded a majority Yes response, and 17 of the 150 Federal Electoral Divisions recorded a majority No response.\n\n### Data Source\n\nAll data presented here comes from the official ABS website: https://marriagesurvey.abs.gov.au/\n\nThis data was cleaned by Myles O'Neill and Richard Dear to make it easier to work with.""","b""['government', 'lgbt', 'love', 'small', 'featured']""",https://www.kaggle.com/australian-bureau-of-statistics/australian-marriage-law-postal-survey
b'UFO Sightings',b'Reports of unidentified flying object reports in the last century',"b'# Context\n\nThis dataset contains over 80,000 reports of UFO sightings over the last century. \n\n# Content\n\nThere are two versions of this dataset: scrubbed and complete. The complete data includes entries where the location of the sighting was not found or blank (0.8146%) or have an erroneous or blank time (8.0237%). Since the reports date back to the 20th century, some older data might be obscured. Data contains city, state, time, description, and duration of each sighting.\n\n# Inspiration\n\n* What areas of the country are most likely to have UFO sightings?\n* Are there any trends in UFO sightings over time? Do they tend to be clustered or seasonal?\n* Do clusters of UFO sightings correlate with landmarks, such as airports or government research centers?\n* What are the most common UFO descriptions? \n\n# Acknowledgement\n\nThis dataset was scraped, geolocated, and time standardized from NUFORC data by Sigmond Axel [here](https://github.com/planetsig/ufo-reports).'","b""['space', 'medium', 'featured']""",https://www.kaggle.com/NUFORC/ufo-sightings
b'Suicides in India',b'Sucides in each state is classified according to various parameters from 2001-12',"b""**Connect/Follow me on [LinkedIn](http://link.rajanand.org/linkedin) for more updates on interesting dataset like this. Thanks.**\n\n###Context###\n\nThis data set contains yearly suicide detail of all the states/u.t of India by various parameters from 2001 to 2012.\n\n###Content###\n\nTime Period: 2001 - 2012 \nGranularity: Yearly\nLocation: States and U.T's of India \n\nParameters:\n\na) Suicide causes\nb) Education status\nc) By means adopted\nd) Professional profile\ne) Social status\n\n###Acknowledgements###\n\nNational Crime Records Bureau (NCRB), Govt of India has shared this [dataset](https://data.gov.in/dataset-group-name/accidental-deaths-and-suicides) under [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).\nNCRB has also shared the historical data on their [website](http://ncrb.nic.in/StatPublications/ADSI/PrevPublications.htm)""","b""['india', 'health', 'death', 'mental health', 'medium', 'featured']""",https://www.kaggle.com/rajanand/suicides-in-india
b'(LoL) League of Legends Ranked Games',"b'Details from over 50,000 ranked games of LoL'","b""General Info\n----------------\n\nThis is a collection of over 50,000 ranked EUW games from the game League of Legends, as well as json files containing a way to convert between champion and summoner spell IDs and their names. For each game, there are fields for:\n\n - Game ID\n - Creation Time (in Epoch format)\n - Game Duration (in seconds)\n - Season ID\n - Winner (1 = team1,   2 = team2)\n - First Baron, dragon, tower, blood, inhibitor and Rift Herald (1 = team1,   2 = team2, 0 = none)\n - Champions and summoner spells for each team (Stored as Riot's champion and summoner spell IDs)\n - The number of tower, inhibitor, Baron, dragon and Rift Herald kills each team has\n - The 5 bans of each team (Again, champion IDs are used)\n\nThis dataset was collected using the Riot Games API, which makes it easy to lookup and collect information on a users ranked history and collect their games. However finding a list of usernames is the hard part, in this case I am using a list of usernames scraped from 3rd party LoL sites.\n\nPossible Uses\n-------------\n\nThere is a vast amount of data in just a single LoL game. This dataset takes the most relevant information and makes it available easily for use in things such as attempting to predict the outcome of a LoL game, analysing which in-game events are most likely to lead to victory, understanding how big of an effect bans of a specific champion have, and more.""","b""['internet', 'video games', 'small', 'featured']""",https://www.kaggle.com/datasnaek/league-of-legends
b'StackSample: 10% of Stack Overflow Q&A',b'Text from 10% of Stack Overflow questions and answers on programming topics',"b'Dataset with the text of 10% of questions and answers from the Stack Overflow programming Q&A website.\n\nThis is organized as three tables:\n\n* **Questions** contains the title, body, creation date, closed date (if applicable), score, and owner ID for all non-deleted Stack Overflow questions whose Id is a multiple of 10.\n* **Answers** contains the body, creation date, score, and owner ID for each of the answers to these questions. The ParentId column links back to the Questions table.\n* **Tags** contains the tags on each of these questions\n\nDatasets of [all R questions](https://www.kaggle.com/stackoverflow/rquestions) and [all Python questions](https://www.kaggle.com/stackoverflow/pythonquestions) are also available on Kaggle, but this dataset is especially useful for analyses that span many languages.\n\nExample projects include:\n\n* Identifying tags from question text\n* Predicting whether questions will be upvoted, downvoted, or closed based on their text\n* Predicting how long questions will take to answer\n\n### License\n\nAll Stack Overflow user contributions are licensed under [CC-BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/) with [attribution required](http://blog.stackoverflow.com/2009/06/attribution-required/).'","b""['internet', 'programming languages', 'large', 'featured']""",https://www.kaggle.com/stackoverflow/stacksample
b'EURUSD - 15m - 2010-2016',"b'FOREX currency rates data for EURUSD, 15 minute candles, BID, years 2010-2016'","b""# Context \n\nI've always wanted to have a proper sample Forex currency rates dataset for testing purposes, so I've created one.\n\n\n# Content\n\nThe data contains Forex EURUSD currency rates in 15-minute slices (OHLC - Open High Low Close, and Volume). BID price only. Spread is *not provided*, so be careful. \n\n(Quick reminder: Bid price + Spread = Ask price)\n\nThe dates are in the yyyy-mm-dd hh:mm format, GMT. Volume is in Units.\n\n# Acknowledgements\n\nDukascopy Bank SA\nhttps://www.dukascopy.com/swiss/english/marketwatch/historical/\n\n# Inspiration\n\nJust would like to see if there is still an way to beat the current Forex market conditions, with the prop traders' advanced automatic algorithms running in the wild.""","b""['finance', 'money', 'medium', 'featured']""",https://www.kaggle.com/meehau/EURUSD
b'The Correlates of State Policy Project',b'One-stop shop for anyone studying state policies and politics',"b'### Context\n\nThe Correlates of State Policy Project aims to compile, disseminate, and encourage the use of data relevant to U.S. state policy research, tracking policy differences across and change over time in the 50 states. We have gathered more than nine-hundred variables from various sources and assembled them into one large, useful dataset. We hope this Project will become a \xe2\x80\x9cone-stop shop\xe2\x80\x9d for academics, policy analysts, students, and researchers looking for variables germane to the study of state policies and politics. \n\n### Content\n\nThe Correlates of State Policy Project includes more than nine-hundred variables, with observations across the U.S. 50 states and time (1900 \xe2\x80\x93 2016). These variables represent policy outputs or political, social, or economic factors that may influence policy differences across the states. The codebook includes the variable name, a short description of the variable, the variable time frame, a longer description of the variable, and the variable source(s) and notes.\n\nTake a look at the codebook PDF to get more information about each column\n\n\n### Acknowledgements\n\nThis aggregated data set is only possible because many scholars and students have spent tireless hours creating, collecting, cleaning, and making data publicly available. Thus if you use the dataset, please cite the original data sources. \n\nJordan, Marty P. and Matt Grossmann. 2016. The Correlates of State Policy Project v.1.10. East Lansing, MI: Institute for Public Policy and Social Research (IPPSR). \n\nThis dataset was originally downloaded from \n\nhttp://ippsr.msu.edu/public-policy/correlates-state-policy'","b""['medium', 'featured']""",https://www.kaggle.com/ippsr/correlates-state-policy
b'Boston Airbnb Open Data',"b'A sneak peek into the Airbnb activity in Boston, MA, USA'","b'# Context\n\nSince 2008, guests and hosts have used Airbnb to travel in a more unique, personalized way. As part of the Airbnb Inside initiative, this dataset describes the listing activity of homestays in Boston, MA. \n\n# Content\n\nThe following Airbnb activity is included in this Boston dataset:\n* Listings, including full descriptions and average review score\n* Reviews, including unique id for each reviewer and detailed comments\n* Calendar, including listing id and the price and availability for that day\n\n# Inspiration\n\n* Can you describe the vibe of each Boston neighborhood using listing descriptions?\n* What are the busiest times of the year to visit Boston? By how much do prices spike?\n* Is there a general upward trend of both new Airbnb listings and total Airbnb visitors to Boston?\n\nFor more ideas, visualizations of all Boston datasets can be found [here](http://insideairbnb.com/boston/).\n\n# Acknowledgement\n\nThis dataset is part of Airbnb Inside, and the original source can be found [here](http://insideairbnb.com/get-the-data.html).'","b""['united states', 'hotels', 'home', 'medium', 'featured']""",https://www.kaggle.com/airbnb/boston
b'Estimate of Median Household Income Group Series',b'Explore Time Series from the U.S. Census Bureau',"b""### Content  \n\nMore details about each file are in the individual file descriptions.  \n\n### Context  \n\nThis is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  \n\n* Update Frequency: This dataset is updated daily.\n\n\n\n### Acknowledgements\n\nThis dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  \n\n[Cover photo](https://unsplash.com/photos/UvgzVZimyWU) by [Quincy Alivio](https://unsplash.com/@kwncy) on [Unsplash](https://unsplash.com/)  \n_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._""","b""['economics', 'small', 'featured']""",https://www.kaggle.com/census/estimate-of-median-household-income-group-series
b'Weather data in New York City - 2016',"b'Added for the ""New York City Taxi Trip Duration"" challenge'","b'### Context\nAs a former transportation student I know how the weather can influence traffic. Both the increase of traffic, as well as the decrease of road conditions increases the travel time.\n\n### Content\nWeather data collected from the National Weather Service. It contains the first six months of 2016, for a weather station in central park. It contains for each day the minimum temperature, maximum temperature, average temperature, precipitation, new snow fall, and current snow depth. The temperature is measured in Fahrenheit and the depth is measured in inches. T means that there is a trace of precipitation.\n\n### Acknowledgements\nThe data was retrieved on 20th of July, 2017 on the website http://w2.weather.gov/climate/xmacis.php?wfo=okx.'","b""['weather', 'utility', 'small', 'featured']""",https://www.kaggle.com/mathijs/weather-data-in-new-york-city-2016
b'Import and Export by India from 2014 to 2017',b'Commodity & country wise annual import and export data.',"b""**Connect/Follow me on [LinkedIn](http://link.rajanand.org/linkedin) for more updates on interesting dataset like this. Thanks.**\n\n### Context\n\nTo better understand the imports and exports by India and how it changed in 3 years.\n\n\n### Content\n\nImport and export data available by principle commodity and country wise for 3 years from Apr'2014 to Mar'2017.\n\n### Column Descriptions\n\n1. pc_code: Integer, Principal Commodity Code\n2. pc: String, Principal Commodity Name\n3. unit: String, measurement of quantity\n4. country_code:  Integer, country code\n5. country_name: String, country name\n6. quantity: Integer, quantify of export or import\n7. value: Integer, monetary valeu of the quantity (in million USD)\n\n### Acknowledgements\n\n[Ministry of Commerce and Industry](http://commerce.gov.in), Govt of India has published [these](https://data.gov.in/catalog/principal-commodity-wise-export) [datasets](https://data.gov.in/catalog/principal-commodity-wise-import) in Open Govt Data Platform India portal under [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).\n\n### Inspiration\n\nSome of questions I would like to be answered are\n\n 1. Top countries by growth percentage.\n 2. Top commodity by quantity or value.\n 3. YoY growth of export and import.\n\n\n""","b""['business', 'india', 'industry', 'small', 'featured']""",https://www.kaggle.com/rajanand/import-and-export-by-india
b'IMDB data from 2006 to 2016',"b'A data set of 1,000 popular movies on IMDB in the last 10 years'","b""Here's a data set of 1,000 most popular movies on IMDB in the last 10 years. The data points included are:\n\nTitle, Genre, Description, Director,  Actors, Year, Runtime, Rating, Votes, Revenue, Metascrore\n\nFeel free to tinker with it and derive interesting insights.""","b""['film', 'small', 'featured']""",https://www.kaggle.com/PromptCloudHQ/imdb-data
b'FAA Laser Incident Reports',b'A report of laser incidents from 2010 to 2014',"b'### Context\n\nOn February 14, 2012, the President signed Public Law 112-95 , the ""FAA Modernization and Reform Act of 2012."" Section 311 amended Title 18 of the United States Code (U.S.C.) Chapter 2, \xc2\xa7 39, by adding \xc2\xa7 39A, which makes it a federal crime to aim a laser pointer at an aircraft. As a result of this law, the FAA has compiled a report of laser incidents\n\n\n### Content\n\nThere is a datafile for each year and the column headers changed a little from year to year so keep that in mind when you\'re loading the data.\n\n* DATE - Date of report\n* TIME (UTC) - Time of laser incident\n* ACID - Aircraft ID (AC/ID, Aircraft ID, etc)\n* No. A/C - Number of aircraft\n* TYPE A/C - Type of aircraft\n* ALT - Altitude\n* MAJOR CITY - Nearest major city abbreviation\n* COLOR - Color of laser\n* Injury Reported - Were there injuries?\n* CITY - Nearest city\n* STATE - State\n\n### Acknowledments\nOriginal file was converted into separate CSV files for each year. Original dataset can be found here: https://www.faa.gov/about/initiatives/lasers/laws/\n\n\n\n![Laser incident][1]\n  [1]: http://i.imgur.com/uMOC0qN.gif'","b""['aviation', 'small', 'featured']""",https://www.kaggle.com/crawford/laser-incident-report
b'Seattle Police Reports',b'Seattle Police Reports',b'All recorded police reports as taken from https://data.seattle.gov/Public-Safety/Seattle-Police-Department-Police-Report-Incident/7ais-f98f',"b""['crime', 'cities', 'medium', 'featured']""",https://www.kaggle.com/sam/seattle-crime
b'5-Day Data Challenge Sign-Up Survey Responses',b'What are folks\xe2\x80\x99 backgrounds? And do they prefer cats or dogs?',"b""### Context: \n\nThis dataset contains survey responses to a survey that people could complete when they signed up for the [5-Day Data Challenge](https://www.kaggle.com/getting-started/41174).\n\nOn December 12, 2017 survey responses for the second 5-Day Data Challenge were added. For this version of the challenge, participants could sign up for either an intro version or a more in-depth regression challenge.\n\n### Content: \n\nThe optional survey included four multiple-choice questions: \n\n1. Have you ever taken a course in statistics?\n\n* Yep  \n* Yes, but I've forgotten everything  \n* Nope\n\n2. Do you have any previous experience with programming?  \n\n* Nope  \n* I have a little bit of experience  \n* I have quite a bit of experience  \n* I have a whole lot of experience\n\n3. What's your interest in data science?  \n\n* Just curious  \n* It will help me in my current job  \n* I want to get a job where I use data science   \n* Other\n \n4. Just for fun, do you prefer dogs or cat?  \n\n* Dogs \xf0\x9f\x90\xb6  \n* Cats \xf0\x9f\x90\xb1  \n* Both \xf0\x9f\x90\xb1\xf0\x9f\x90\xb6  \n* Neither \xf0\x9f\x99\x85\n\nIn order to protect privacy, the data has been shuffled (so there\xe2\x80\x99s no temporal order to the responses) and a random 2% of the data has been removed (so even if you know that someone completed the survey, you cannot be sure that their responses are included in this dataset). In addition, all incomplete responses have been removed, and any text entered in the \xe2\x80\x9cother\xe2\x80\x9d free response field has been replaced with the text \xe2\x80\x9cother\xe2\x80\x9d.\n\n### Acknowledgements: \n\nThanks to everyone who completed the survey! :) \n\n### Inspiration: \n\n* Is there a relationship between how much programming experience someone has and why they\xe2\x80\x99re interested in data science?\n* Are more experienced programmers more likely to have taken statistics?\n* Do people tend to prefer dogs, cats, both or neither? Is there a relationship between what people prefer and why they\xe2\x80\x99re interested in data science?""","b""['categorical data', 'small', 'featured']""",https://www.kaggle.com/rtatman/5day-data-challenge-signup-survey-responses
b'Jester Online Joke Recommender',"b'Over 11 million ratings of 150 jokes from 79,681 users'","b'### Context\n\nJester is a joke recommender system developed at UC Berkeley to study social information filtering. Users of the system are presented a joke and then they rate them. This dataset is a collection of those ratings.\n\n[http://eigentaste.berkeley.edu/][2]\n\n*Eigentaste: A Constant Time Collaborative Filtering Algorithm. Ken\nGoldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins. Information\nRetrieval, 4(2), 133-151. July 2001.*\n\n\n### Content\n\nNotes from the source:\n\n- Each row is a user (Row 1 = User #1)\n\n- Each column is a joke (Column 1 = Joke #1)\n\n- Ratings are given as real values from -10.00 to +10.00\n\n- 99 corresponds to a null rating\n\n- As of May 2009, the jokes 7, 8, 13, 15, 16, 17, 18, 19 are the ""gauge set"" (as discussed in the [Eigentaste paper][1]) \n\n\n\n### Acknowledgements\n\nThanks go to Dr. Ken Golberg\'s group for putting this super cool data together and for permission to share it with the Kaggle community! \n\n*Eigentaste: A Constant Time Collaborative Filtering Algorithm. Ken\nGoldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins. Information\nRetrieval, 4(2), 133-151. July 2001.*\n\n- The original data file was converted to a CSV format before uploading. \n\n- The original list of jokes was converted from DAT to TSV.\n\n- Original files can be found here: [http://eigentaste.berkeley.edu/dataset/][2]\n\n\n\n### Inspiration\n\nTake a look at the [Eigentaste paper][1] to learn more about how the data was used. See if you can recreate the study or glean some new insight!\n\n\n  [1]: http://www.ieor.berkeley.edu/~goldberg/pubs/eigentaste.pdf\n  [2]: http://eigentaste.berkeley.edu/dataset/'","b""['humor', 'medium', 'featured']""",https://www.kaggle.com/crawford/jester-online-joke-recommender
b'San Francisco Library Usage',"b'Anonymized library usage data by over 420,000 patrons'","b""### Context \n\nSan Francisco's Integrated Library System (ILS) is composed of bibliographic records including inventoried items, patron records, and circulation data. The data is used in the daily operation of the library, including circulation, online public catalog, cataloging, acquisitions, collection development, processing, and serials control. This dataset represents the usage of inventoried items by patrons (~420K records).\n\n### Content\n\nThe dataset includes approximately 420,000 records, with each record representing an anonymized library patron. Individual columns include statistics on the type code and age of the patron, the year the patron registered (only since 2003), and how heavily the patron has been utilizing the library system (in terms of number of checkouts) since first registering.\n\nFor more information on specific columns refer to the [official data dictionary][1] and the information in the Column Metadata on the `/Data` tab.\n\n### Acknowledgements\n\nThe data is provided by [SF Public Library][3] via the [San Francisco Open Data Portal](https://data.sfgov.org/d/qzz6-2jup), under the PDDL 1.0 ODC Public Domain Dedication and Licence ([PDDL][4]).\n\nPhoto via Flickr [Kolya Miller][5] [(CC BY-NC-SA 2.0)][6].\n\n### Inspiration\n\n* What attributes are most associated with library activity (# of checkouts, # of renewals)?\n* Can you group the data into type of patrons?  What classifiers would you use to predict patron type?\n\n  [1]: https://data.sfgov.org/api/views/qzz6-2jup/files/72c2070f-7b56-4d14-840a-d1a70f5d0f19?download=true&amp;filename=LIB-0003_DataDictionary_library-usage.xlsx\n  [2]: https://data.sfgov.org/Geographic-Locations-and-Boundaries/Supervisor-Districts-as-of-April-2012/xz9b-wyfc\n  [3]: http://sfpl.org/\n  [4]: http://opendatacommons.org/licenses/pddl/1.0/\n  [5]: https://www.flickr.com/photos/kolya/71123986/\n  [6]: https://creativecommons.org/licenses/by-nc-sa/2.0/""","b""['libraries', 'medium', 'featured']""",https://www.kaggle.com/datasf/sf-library-usage-data
b'Leading Causes of Death in the USA',b'Age-adjusted death rates for the top 10 leading causes of death in the US',"b'# Content\n\nAge-adjusted Death Rates for Selected Major Causes of Death: United States, 1900-2013\n\n# Age adjusting rates \nis a way to make fairer comparisons between groups with different age distributions. For example, a county having a higher percentage of elderly people may have a higher rate of death or hospitalization than a county with a younger population, merely because the elderly are more likely to die or be hospitalized. (The same distortion can happen when comparing races, genders, or time periods.) Age adjustment can make the different groups more comparable.\nA ""standard"" population distribution is used to adjust death and hospitalization rates. The age-adjusted rates are rates that would have existed if the population under study had the same age distribution as the ""standard"" population. Therefore, they are summary measures adjusted for differences in age distributions.\n\n# Acknowledgements\n\nScrap data from data.gov'","b""['demographics', 'utility', 'death', 'small', 'featured']""",https://www.kaggle.com/kingburrito666/leading-causes-of-death-usa
b'Restaurant Data with Consumer Ratings',b'Data from a restaurant recommender prototype',"b'### Context\n\nThis dataset was used for a study where the task was to generate a top-n list of restaurants according to the consumer preferences and finding the significant features. Two approaches were tested: a collaborative filter technique and a contextual approach: (i) The collaborative filter technique used only one file i.e., rating_final.csv that comprises the user, item and rating attributes.  (ii) The contextual approach generated the recommendations using the remaining eight data files.\n\n\n\n### Content\n\nThere are 9 data files and a README,  and are grouped like this:\n\nRestaurants\n\n- 1 chefmozaccepts.csv\n- 2 chefmozcuisine.csv\n- 3 chefmozhours4.csv\n- 4 chefmozparking.csv\n- 5 geoplaces2.csv\n\nConsumers\n\n- 6 usercuisine.csv\n- 7 userpayment.csv\n- 8 userprofile.csv\n\nUser-Item-Rating\n\n- 9 rating_final.csv\n\n\n\nMore detailed file descriptions can also be found in the README:\n\n- 1 chefmozaccepts.csv\n  - Instances: 1314\n  - Attributes: 2\n  - placeID: Nominal\n  - Rpayment: Nominal, 12\n\n\n- 2 chefmozcuisine.csv\n  - Instances: 916\n  - Attributes: 2\n  - placeID: Nominal\n  - Rcuisine: Nominal, 59\n\n- 3 chefmozhours4.csv\n  - Instances: 2339\n  - Attributes: 3\n  - placeID: Nominal\n  - hours: Nominal, Range:00:00-23:30\n  - days: Nominal, 7 \n\n- 4 chefmozparking.csv\n  - Instances: 702\n  - Attributes: 2\n  - placeID: Nominal\n  - parking_lot: Nominal, 7\n\n- 5 geoplaces2.csv\n  - Instances: 130\n  - Attributes: 21\n  - placeID: Nominal\n  - latitude: Numeric\n  - longitude: Numeric\n  - the_geom_meter: Nominal (Geospatial)\n  - name: Nominal\n  - address: Nominal,Missing: 27\n  - city: Nominal, Missing: 18\n  - state: Nominal, Missing: 18\n  - country: Nominal, Missing: 28\n  - fax: Numeric, Missing: 130\n  - zip: Nominal,Missing: 74\n  - alcohol: Nominal, Values: 3 \n  - smoking_area: Nominal, 5 \n  - dress_code:\tNominal, 3 \n  - accessibility: Nominal, 3 \n  - price: Nominal, 3 \n  - url: Nominal, Missing: 116\n  - Rambience: Nominal, 2\n  - franchise: Nominal, 2 \n  - area: Nominal, 2\n  - other_services:\tNominal, 3\n\n- 6 rating_final.csv\n  - Instances: 1161\n  - Attributes: 5\n  - userID: Nominal\n  - placeID: Nominal\n  - rating: Numeric, 3\n  - food_rating: Numeric, 3 \n  - service_rating:\tNumeric, 3\n\n- 7 usercuisine.csv\n  - Instances: 330\n  - Attributes: 2\n  - userID: Nominal\n  - Rcuisine: Nominal, 103 \n\n- 8 userpayment.csv\n  - Instances: 177\n  - Attributes: 2\n  - userID: Nominal\n  - Upayment: Nominal, 5 \n\n- 9 userprofile\n  - Instances: 138\n  - Attributes: 19\n  - userID: Nominal\n  - latitude: Numeric\n  - longitude: Numeric\n  - the_geom_meter: Nominal (Geospatial)\n  - smoker: Nominal\n  - drink_level: Nominal, 3\n  - dress_preference:Nominal, 4\n  - ambience: Nominal, 3\n  - transport: Nominal, 3\n  - marital_status:\tNominal, 3\n  - hijos: Nominal, 3\n  - birth_year:\tNominal\n  - interest: Nominal, 5\n  - personality: Nominal, 4\n  - religion: Nominal, 5 \n  - activity: Nominal, 4\n  - color: Nominal, 8 \n  - weight: Numeric\n  - budget: Nominal, 3\n  - height: Numeric\n\n\n### Acknowledgements\n\nThis dataset was originally downloaded from the UCI ML Repository:\n[UCI ML][1]\n\nCreators: \nRafael Ponce Medell\xc3\xadn and Juan Gabriel Gonz\xc3\xa1lez Serna\nrafaponce@cenidet.edu.mx, gabriel@cenidet.edu.mx\nDepartment of Computer Science.\nNational Center for Research and Technological Development CENIDET, M\xc3\xa9xico\n\n\nDonors of database:\nBlanca Vargas-Govea and Juan Gabriel Gonz\xc3\xa1lez Serna\nblanca.vargas@cenidet.edu.mx/blanca.vg@gmail.com, gabriel@cenidet.edu.mx\nDepartment of Computer Science.\nNational Center for Research and Technological Development CENIDET, M\xc3\xa9xico\n\n### Inspiration\n\nUse this data to create a restaurant recommender or determine which restaurants a person is most likely to visit.\n\n\n  [1]: https://archive.ics.uci.edu/ml/datasets/Restaurant+%26+consumer+data'","b""['business', 'small', 'featured']""",https://www.kaggle.com/uciml/restaurant-data-with-consumer-ratings
b'Deep Learning A-Z - ANN dataset',"b'Kirill Eremenko ""Deep Learning A-Z\xe2\x84\xa2: Hands-On Artificial Neural Networks"" course'","b'# Context \n\nThis is the dataset used in the section ""ANN (Artificial Neural Networks)"" of the Udemy course from Kirill Eremenko (Data Scientist & Forex Systems Expert) and Hadelin de Ponteves (Data Scientist), called **Deep Learning A-Z\xe2\x84\xa2: Hands-On Artificial Neural Networks**. The dataset is **very useful for beginners** of Machine Learning, and a simple playground where to compare several techniques/skills.\n\nIt can be freely downloaded here: https://www.superdatascience.com/deep-learning/\n\n\n----------\n\n\nThe story:\nA bank is investigating a very high rate of customer leaving the bank. Here is a 10.000 records dataset to investigate and predict which of the customers are more likely to leave the bank soon.\n\nThe story of the story:\nI\'d like to compare several techniques (better if not alone, and with the experience of several Kaggle users) to improve my basic knowledge on Machine Learning.\n\n\n# Content\n\nI will write more later, but the columns names are very self-explaining.\n\n\n# Acknowledgements\n\nUdemy instructors Kirill Eremenko (Data Scientist & Forex Systems Expert) and Hadelin de Ponteves (Data Scientist), and their efforts to provide this dataset to their students.\n\n\n# Inspiration\n\nWhich methods score best with this dataset? Which are fastest (or, executable in a decent time)? Which are the basic steps with such a simple dataset, very useful to beginners?'","b""['artificial intelligence', 'small', 'featured']""",https://www.kaggle.com/filippoo/deep-learning-az-ann
b'Electron Microscopy 3D Segmentation',b'A copy of the EPFL  CVLab dataset',"b""# Context \n\nThe dataset available for download on this webpage represents a 5x5x5\xc2\xb5m section taken from the CA1 hippocampus region of the brain, corresponding to a 1065x2048x1536 volume. The resolution of each voxel is approximately 5x5x5nm. \n\n\n# Content\n\nTwo image datasets in 3D of Electron Microscopy data with accompanying labels. The data is provided as multipage TIF files that can be loaded in Fiji, R, KNIME, or Python\n\n\n# Acknowledgements\n\nThe dataset was copied from http://cvlab.epfl.ch/data/em directly and only placed here to utilize the Kaggle's kernel and forum capabilities.  Please acknowledge the CV group dataset for publication or any other uses\n\n## Data Citations\n\n - A. Lucchi Y. Li and P. Fua, Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets, Conference on Computer Vision and Pattern Recognition, 2013.\t\n - A. Lucchi, K.Smith, R. Achanta, G. Knott, P. Fua, Supervoxel-Based\n   Segmentation of Mitochondria in EM Image Stacks with Learned Shape\n   Features, IEEE Transactions on Medical Imaging, Vol. 30, Nr. 11,\n   October 2011.\n\n# Challenges\n- How accurately can the segmentation be performed with neural networks?\n- Is 3D more accurate than 2D for segmentation?\n- How can mistakes critical to structure or connectivity be penalized more heavily, how would a standard ROC penalize them?""","b""['neuroscience', 'microtechnology', 'medium', 'featured']""",https://www.kaggle.com/kmader/electron-microscopy-3d-segmentation
"b'Azerbaijan Voter List, 2016'",b'Three files containing the list of voters scraped from site in 2016',"b'# Context \n**Azerbaijan Voter List** in three files (as scraped from the Central Election Commission [website][1] in 2006)\n\n# Content\nIncludes the sequence column (meaningless), the district code (Dair\xc9\x99nin kodu), the polling station code (M\xc9\x99nt\xc9\x99q\xc9\x99nin kodu), voters names (Se\xc3\xa7icinin soyad\xc4\xb1, ad\xc4\xb1, atas\xc4\xb1n\xc4\xb1n ad\xc4\xb1), Permanent residence address (street, house and apartment number) (Daimi ya\xc5\x9fay\xc4\xb1\xc5\x9f yerinin \xc3\xbcnvan\xc4\xb1 (k\xc3\xbc\xc3\xa7\xc9\x99, ev v\xc9\x99 m\xc9\x99nzilin n\xc3\xb6mr\xc9\x99si), and year of birth (T\xc9\x99v\xc9\x99ll\xc3\xbcd). \nHere is an example page with the table: https://www.infocenter.gov.az/page/voters/?s=1\n\nIn total: 125 districts; 5,415 polling stations; 5,139,414 voter records \n\n# Inspiration\n\nWorking on getting another earlier voter list for comparison. For now, just some summary statistics and duplicate counts. \n\n\n  [1]: https://www.infocenter.gov.az/page/voters/'","b""['politics', 'medium', 'featured']""",https://www.kaggle.com/msbrown/azerbaijanvoterlist
b'Elevation Data meets SF Fire Department Calls',b'Do the fires climb? Do fire fighters only fight fire?',"b'### Context \nThis dataset is generated via merging ""San Francisco Fire Department Calls"" and ""San Francisco Elevation Data"". Fire Calls-For-Service includes all fire units responses to calls. Each record includes the call number, neighborhood, location, unit type, call type, and all relevant time intervals are also included. \n\n### Content\n\n - Call Type:  Type of call the incident falls into.\n - Call Final Disposition: Disposition of the call (Code). For example TH2: Transport to Hospital - Code 2, FIR: Resolved by Fire Department\n - Unit Type: Unit type\n - Received DtTm: Date and time of call is received at the 911 Dispatch Center.\n - Response DtTm: Date and time this unit acknowledges the dispatch and records that the unit is en route to the location of the call.\n - On Scene DtTm: Date and time the unit records arriving to the location of the incident\n - Call Type Group: Call types are divided into four main groups: Fire, Alarm, Potential Life Threatening and Non Life Threatening.\n - Neighborhood  District: Neighborhood District associated with this address, boundaries available [here](https://data.sfgov.org/d/p5b7-5n3h)\n - Location: Latitude and longitude of address obfuscated either to the midblock, intersection or call box\n - Elevation:Elevation in meters\n\n### Acknowledgements\n\nSan Francisco Fire Department calls are downloaded from [SFOpen webpage](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3).\n\nSan Francisco DEM (Digital elevation models) file is obtained from [National Centers for Environmental Information web page](http://www.ngdc.noaa.gov/dem/squareCellGrid/download/741)*\n \n*Carignan, K.S., L.A. Taylor, B.W. Eakins, R.J. Caldwell, D.Z. Friday, P.R. Grothe, and E. Lim, 2011. Digital Elevation Models of Central California and San Francisco Bay: Procedures, Data Sources and Analysis, NOAA Technical Memorandum NESDIS NGDC-52, U.S. Dept. of Commerce, Boulder, CO, 49 pp.\n\n### Inspiration\n\n- Do fire fighters only fight fire?  There is a wide range of calls directed to FD, what is the leading cause?\n\n- How often do firefighters actually fight a fire on a given day/week?\n\n- How fast do they respond to calls? Does the elevation lag the response? \n\n- Are there special times/months where they receive more or less calls?  \n\n- Is there a relationship between the elevation and the rate or type of calls?'","b""['firefighting', 'medium', 'featured']""",https://www.kaggle.com/bengin/SanFranciscoFireDepartmentCalls
b'Properties on StayZilla',"b'6,000 Properties on StayZilla'","b""###Context\n\nThis is a pre-crawled dataset, taken as subset of a bigger [dataset (more than 61,000 properties)][1] that was created by extracting data from StayZilla.com, an Indian AirBnB-like startup founded in 2005 that closed its operations in 2017.\n\n![](http://bsmedia.business-standard.com/_media/bs/img/article/2015-09/09/full/1441804837-4815.jpg)\n\n### Content\n\nThis dataset has following fields:\n\n- `additional_info` - Special considerations regarding this property.\n- `amenities` - Pipe (`|`) delimited list of amenities offered at the property.\n- `check_in_date`\n- `check_out_date`\n- `city`\n- `country`\n- `crawl_date`\n- `description` - Textual description of the property, as entered into the site by the lister.\n- `highlight_value` - Property highlights, as entered into the site by the lister.\n- `hotel_star_rating` - In case the property is a hotel, its out-of-five star rating. Not all hotels have ratings.\n- `image_count` - Number of images posted to the site by the lister.\n- `image_urls`\n- `internet` - Does this property have Internet access yes/no.\n- `landmark`\n- `latitude`\n- `longitude`\n- `occupancy` - How many adults and children may book the listing.\n- `pageurl`\n- `property_address`\n- `property_id`\n- `property_name`\n- `property_type` - Home? Hotel? Resort? Etc.\n- `qts` - Crawler timestamp.\n- `query_time_stamp` - Copy of `qts`.\n- `room_price`\n- `room_types` - Number of beds and baths for the room.\n- `search_term`\n- `service_value` - Whether or not the property is verified with StayZilla (plus some junk entries).\n- `similar_hotel` - Some similar listings by name.\n- `sitename`\n- `things_to_do` - Nearby activities as entered by the lister.\n- `things_to_note` - Special notes entered by the lister.\n\n### Acknowledgements\n\nThis dataset was created by PromptCloud's in-house web-crawling service.\n\n### Inspiration\n* What is the shape of the Indian property-sharing market, and how does it differ from that of, say, the United States? (try comparing this dataset to, say, the [Boston AirBnB](https://www.kaggle.com/airbnb/boston) dataset).\n* What are the contents of textual descriptions for properties?\n* Where are StayZilla properties located geographically?\n\n  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=sz-kaggle&utm_medium=referral""","b""['internet', 'hotels', 'small', 'featured']""",https://www.kaggle.com/PromptCloudHQ/properties-on-stayzilla
b'SNAP Memetracker',b'Tracking high-frequency phrases across internet news',"b""This database contains a subset of the [Memetracker](http://snap.stanford.edu/data/memetracker9.html) dataset collected by [SNAP](http://snap.stanford.edu/index.html). \n\nThe full Memetracker dataset has observations broken into months. Because of size considerations, however, this version consists of one-half of a month: the first 15 days of Memetracker observations from November 2008.\n\n## About\n\nMemetracker tracks the quotes and phrases that appear most frequently over time across the entire online news spectrum. This makes it possible to see how different stories compete for news and blog coverage each day, and how certain stories persist while others fade quickly.\n\nOverall Memetracker tracks more than 17 million different phrases and about 54% of the total phrase/quote mentions appear on blogs and 46% in news media.\n\n## Acknowledgments\n\nThis dataset was collected by the Stanford Network Analysis Project. Detailed information about the data and its analysis can be found at the website [here](http://snap.stanford.edu/data/memetracker9.html).\n\nAn analysis of this dataset was published here:    \nJ. Leskovec, L. Backstrom, J. Kleinberg. [Meme-tracking and the Dynamics of the News Cycle](http://cs.stanford.edu/people/jure/pubs/quotes-kdd09.pdf). ACM SIGKDD Intl. Conf. on Knowledge Discovery and Data Mining, 2009.\n\n\n## The Data\n\nThe SQLite database contains three tables:\n\n```articles```: 4,542,920 records, with the following fields:\n\n- **article_id**: a unique id for the article (int)\n- **url**: the URL of the article (text)\n- **date**: the date of the article (text), in the strptime format '%Y-%m-%d %H:%M:%S'\n\n```quotes```: 7,956,125 records, with the following fields:\n\n- **article_id**: unique id for the article that this quote was found in (int)\n- **phrase**: the high-frequency phrase found in the article (text)\n\n```links```: 16,727,125 records, with the following fields:\n\n- **article_id**: unique id for the article that this link was found in (int)\n- **link_out**: the URL of the link out (text)\n- **link_out_id**: unique id for the target article (int), if it exists; else NULL""","b""['internet', 'linguistics', 'large', 'featured']""",https://www.kaggle.com/snap/snap-memetracker
b'The National Summary of Meats',"b""USDA's data on beef and mutton production since the 1930s""","b""Beef. Lamb. Veal. We might not all eat them, but they are the meats whose grades the US Department of Agriculture has seen fit to publish. This dataset contains records on meat production and quality as far back as 1930. \n\nAfter meat and poultry are inspected for wholesomeness, producers and processors may request that they have products graded for quality by a licensed Federal grader. The USDA's Agricultural Marketing Service (http://www.ams.usda.gov) is the agency responsible for grading meat and poultry. Those who request grading must pay for the service. Grading for quality means the evaluation of traits related to tenderness, juiciness, and flavor of meat; and, for poultry, a normal shape that is fully fleshed and meaty and free of defects.\n\nUSDA grades are based on nationally uniform Federal standards of quality. No matter where or when a consumer purchases graded meat or poultry, it must have met the same grade criteria. The grade is stamped on the carcass or side of beef and is usually not visible on retail cuts. However, retail packages of beef, as well as poultry, will show the U.S. grade mark if they have been officially graded.\n\nTo better understand the available fields:\n - All fields labeled 'pounds' are really in units of indicate millions\n   of pounds.\n - You can find a helpful explanation of what the different grades mean\n   [here][1].\n\n### Acknowledgements\n\nThis data was kindly released by the US Department of Agriculture. You can find [their most recent meat updates here][2].\n\n### Inspiration\n\n - This is a good dataset for anyone looking to do basic data cleanup. I've converted it into a properly formed CSV, but there are still numerous missing values, footnoted fields, and exceptions.\n - This is a good candidate for regression analysis, especially in conjunction with other datasets. Can you identify correlates for the amount of beef produced? Validate how well cattle futures predict annual yields?\n - 2015 was a banner year for beef production. What happened?\n\n  [1]: https://www.fsis.usda.gov/wps/portal/fsis/topics/food-safety-education/get-answers/food-safety-fact-sheets/production-and-inspection/inspection-and-grading-of-meat-and-poultry-what-are-the-differences_/inspection-and-grading-differences/!ut/p/a1/jZFRT4MwEMc_DY9di8yF-UZIzIYOXBYd42Xp4FpIoCVtkcxPb8EHnRm69qV39_tf2__hDKc4E_S94tRUUtB6iLPFkWzJwl2GJEqW7iNZx2_b5CkMib-7t8DhDyD2btRPrID8p49uuOBObcINx1lLTYkqwSROORhEhe5BaZwyKQukKQNzRozmBukSwNhCq2TR5YMVFi6sVLcwhjj9Po8lrmhRCY4kQw1QM-Za2dVGnVFfDgkFyJSAiooxUCBy0MfJLj8gvMfZ5ReJa_c69nbzVRR7JJn_Bq7M4AuYNtm6yGt5Ggd-CMTJ861dCoZHqFmnbLo0ptUPDnFI3_czLiWvYZbLxiHXJKXUBqeXJG6b1_TjOViR6qXZ-zr4BEpuht4!/#4a\n  [2]: http://usda.gov/content/usda-open-data-catalog""","b""['government', 'agriculture', 'small', 'featured']""",https://www.kaggle.com/usda/the-national-summary-of-meats
b'Retrosheet events 1970 - 2015',b'A granular history of baseball',"b'This data set comprises events for major league baseball, provided by <http://retrosheet.org>.\n\n\n     The information used here was obtained free of\n     charge from and is copyrighted by Retrosheet.  Interested\n     parties may contact Retrosheet at ""www.retrosheet.org"".\n\nRoughly speaking an event is an outcome in a baseball game. This includes the end result of a plate appearance (strikeout, out in the field, hit, base on balls), events that occur within a plate appearance (stolen bases, caught stealing), and rare other occurrences. The retrosheet event data prior to 1955 are not complete. The data subsequent to 1988 include pitch counts while the data prior do not. The data here cover the years 1970-2015, in three divisions (1970-1992, 1993-2004, 2005-2015) that correspond, roughly, to distinct eras with different run-scoring environments. These data have specifically been obtained with a mix of the data dumps available at <a href=""http://www.baseballheatmaps.com/"">baseball heatmaps</a> and with the `py-retrosheet` Python package, available on <a href=""https://github.com/wellsoliver/py-retrosheet"">github</a>.\n\nI have augmented the data provided by retrosheet with some additional fields. Most substantively the rows include the <a href=""http://www.fangraphs.com/library/offense/woba/"">wOBA</a> value of the event, in the field `woba_pts`, and an estimated time stamp, in units of seconds since Jan. 1, 1900 (`time_since_1900`).\n\nThe conversion from retrosheet files to sql and csv is done by the `chadwick` software. A detailed description of all of the fields is available on the documentation for `chadwick`, <http://chadwick.sourceforge.net/doc/cwevent.html>. In order to keep the file sizes down, I have limited the fields in this data set to a subset of the fields described in the `chadwick` documentation.\n\nThe master.csv file is a subset of the Baseball Databank data and is released under a Creative Commons Attribution-ShareAlike 3.0 Unported License.<a href=""https://creativecommons.org/licenses/by-sa/3.0/"">https://creativecommons.org/licenses/by-sa/3.0/</a>. More details are available on the Baseball Databank github <a href=""https://github.com/chadwickbureau/baseballdatabank"">https://github.com/chadwickbureau/baseballdatabank</a>'","b""['history', 'baseball', 'medium', 'featured']""",https://www.kaggle.com/bdilday/retrosheet-events-1970-2015
b'Localization Data for Posture Reconstruction',b'Recordings of five people while wearing localization tags',"b""### Context\n\nThese datums  represent a multi-agent system for the care of elderly people living at home on their own, with the aim to prolong their independence. The system was designed to provide a reliable, robust and flexible monitoring by sensing the user in the environment, reconstructing the position and posture to create the physical awareness of the user in the environment, reacting to critical situations, calling for help in the case of an emergency, and issuing warnings if unusual behavior was detected. \n\n### Content\n\n**Columns descriptions**\n\n- Sequence Name: A01, A02, A03, A04, A05, B01, B02, B03, B04, B05, ...,E05\n  - A-E represent a person (5 total)\n  - 01, 02, 03, 04, 05 = Tag Numbers\n\n- Tag identifiers\n  - ANKLE_LEFT = 010-000-024-033\n  - ANKLE_RIGHT = 010-000-030-096\n  - CHEST = 020-000-033-111\n  - BELT = 020-000-032-221\n\n- Time stamp\n- Date\n  - Format = dd.MM.yyyy HH:mm:ss:SSS\n- x coordinate of the tag \n- y coordinate of the tag \n- z coordinate of the tag \n- activity\n  - walking, falling, 'lying down', lying, 'sitting down', sitting, 'standing up from lying', 'on all fours', 'sitting on the ground', 'standing up from sitting', 'standing up from sitting on the ground\n\n\n### Acknowledgements\n\nB. Kaluza, V. Mirchevska, E. Dovgan, M. Lustrek, M. Gams, An Agent-based Approach to Care in Independent Living, International Joint Conference on Ambient Intelligence (AmI-10), Malaga, Spain, In press\n\n### Inspiration\n\nGiven these data, can you classify the persons activity from the tags they wore?""","b""['healthcare', 'programming', 'biotechnology', 'medium', 'featured']""",https://www.kaggle.com/uciml/posture-reconstruction
b'Shakespeare plays',"b'All of shakespeares plays, characters, lines, and acts in one CSV'","b""# Context \n\nThis is **all of Shakespeare's plays**. \n\n# Content\n\nThis is a dataset comprised of all of Shakespeare's plays. It includes the following:\n\n - The first column is the Data-Line, it just keeps track of all the\n   rows there are.\n - The second column is the play that the lines are from.\n - The third column is the actual line being spoken at any given time.\n - The fourth column is the Act-Scene-Line from which any given line is\n   from.\n - The fifth column is the player who is saying any given line.\n - The sixth column is the line being spoken.\n\n# Inspiration\n\nI've been doing Shakespeare for a while and I wanted to make a Shakespearean chatbot.""","b""['languages', 'literature', 'writing', 'medium', 'featured']""",https://www.kaggle.com/kingburrito666/shakespeare-plays
b'Six Degrees of Francis Bacon',b'An early modern social network',"b'### Overview\n\nSix Degrees of Francis Bacon is a digital reconstruction of the early modern social network (EMSN). Historians and literary critics have long studied the way that early modern people associated with each other and participated in various kinds of formal and informal groups. By data-mining existing scholarship that describes relationships between early modern persons, documents, and institutions, we have created a unified, systematized representation of the way people in early modern England were connected.\n\n### Contents\n\nThis dataset contains information on 171419 relationships between 15824 early modern figures (including, of course, the titular Francis Bacon). The individuals have been separated into 109 distinct labelled groups and the relationships fall under one of 64 labelled categories.\n\nThis dataset contains the following files:\n\n* SDFB_groups.csv: a list of the groups of individuals in the dataset\n* SDFB_people.csv: a list of all individuals in the dataset\n* SDFB_relationships_100000000_100020000.csv: This and the following \xe2\x80\x9crelationships\xe2\x80\x9d files contain information on relationships between specific individuals\n* SDFB_relationships_100020001_100040000.csv\n* SDFB_relationships_100040001_100060000.csv\n* SDFB_relationships_100060001_100080000.csv\n* SDFB_relationships_100080001_100100000.csv\n* SDFB_relationships_100100001_100120000.csv\n* SDFB_relationships_100120001_100140000.csv\n* SDFB_relationships_100140001_100160000.csv\n* SDFB_relationships_100160001_100180000.csv\n* SDFB_relationships_greater_than_100180000.csv\n* SDFB_RelationshipTypes.csv: the types of relationships found in the database\n* table-of-contents.csv: a table of contents for the files\n\n### Acknowledgements\n\nPlease cite Six Degrees of Francis Bacon as follows:\n\nSDFB Team, Six Degrees of Francis Bacon: Reassembling the Early Modern Social Network. www.sixdegreesoffrancisbacon.com (August 29, 2017).\n\n### Inspiration\n\nThis dataset is an excellent place to explore network analysis and visualization. Each individual is a node, and each relationship an edge. \n\n* Can you visualize this social network? \n* Who is the most central figure in this social network? \n* Do different groups have different degrees of connectivity? Plexity?'","b""['europe', 'history', 'sociology', 'networks', 'north america', 'medium', 'featured']""",https://www.kaggle.com/rtatman/six-degrees-of-francis-bacon
b'Insect Light Trap',b'The University of Copenhagen\xe2\x80\x99s Zoological Museum zapped insects for 18 years',"b""### Context\n\nThe University of Copenhagen\xe2\x80\x99s Zoological Museum placed a light trap on their roof and for 18 years they documented the types of insects being caught.  The data was collected as part of a study to determine insect responses to recent climate change.\n\n### Content\n\nThis file contains the raw data from the light trapping study ordered by: Order (Lepidoptera/Coleoptera), family, name (species), year, date1 (start), date2 (end) and number of individuals\n\n### Acknowledgements\n\nOriginal publication:\n*Thomsen PF, J\xc3\xb8rgensen PS, Bruun HH, Pedersen J, Riis-Nielsen T, Jonko K, S\xc5\x82owi\xc5\x84ska I, Rahbek C, Karsholt O* (2016) Resource specialists lead local insect community turnover associated with temperature \xe2\x80\x93 analysis of an 18-year full-seasonal record of moths and beetles. Journal of Animal Ecology 85(1): 251\xe2\x80\x93261. http://dx.doi.org/10.1111/1365-2656.12452\n\nThe original dataset can be found at [http://datadryad.org/resource/doi:10.5061/dryad.s4945/1][1]\n\n\n### Inspiration\n\nClimate change is on everyone's mind for one reason or another and insects are susceptible to climate change just like humans. Using these data, can you determine which species have become more or less prevalent over the 18 years of collection?\n\n\n  [1]: http://datadryad.org/resource/doi:10.5061/dryad.s4945/1""","b""['biology', 'environment', 'small', 'featured']""",https://www.kaggle.com/University-of-Copenhagen/insect-light-trap
b'Linux Kernel Git Revision History',b'Anonymized git commit log with detailed file information',"b""This dataset contains commits with detailed information about changed files from about **12 years** of the [linux kernel][1] master branch. It contains about 600.000 (filtered) commits and this breaks down to about 1.4 million file change records.\n\nEach row represents a changed file in a specific commit, with annotated deletions and additions to that file, as well as the filename and the subject of the commit. I also included anonymized information about the author of each changed file aswell as the time of commit and the timezone of the author.\n\nThe columns in detail:\n\n* author_timestamp: UNIX timestamp of when the commit happened\n* commit_hash: SHA-1 hash of the commit\n* commit_utc_offset_hours: Extraced UTC offset in hours from commit time\n* filename: The filename that was changed in the commit\n* n_additions: Number of added lines\n* n_deletions: Number of deleted lines\n* subject: Subject of commit\n* author_id: Anonymized author ID.\n\nI'm sure with this dataset nice visualizations can be created, let's see what we can come up with!\n\nFor everybody interested how the dataset was created, I've setup a github repo that contains all the required steps to reproduce it [here][2].\n\nIf you have any questions, feel free to contact me via PM or discussions here.\n\n  [1]: https://www.kernel.org/\n  [2]: https://github.com/tdhd/kaggle-linux-git""","b""['programming', 'computing and society', 'medium', 'featured']""",https://www.kaggle.com/philschmidt/linux-kernel-git-revision-history
"b'Subreddit Interactions for 25,000 Users'",b'Modeling Reddit users from their metadata',"b""# Context \n\nThe dataset is a csv file compiled using a python scrapper developed using Reddit's PRAW API. The raw data is a list of 3-tuples of [username,subreddit,utc timestamp]. Each row represents a single comment made by the user, representing about 5 days worth of Reddit data. Note that the actual comment text is not included, only the user, subreddit and comment timestamp of the users comment. The goal of the dataset is to provide a lens in discovering user patterns from reddit meta-data alone. The original use case was to compile a dataset suitable for training a neural network in developing a subreddit recommender system. That final system can be found [here][1]\n\nA very unpolished EDA for the dataset can be found [here][2]. Note the published dataset is only half of the one used in the EDA and recommender system, to meet kaggle's 500MB size limitation.\n\n# Content\n\nuser - The username of the person submitting the comment  \nsubreddit - The title of the subreddit the user made the comment in  \nutc_stamp - the utc timestamp of when the user made the comment  \n\n# Acknowledgements\n\nThe dataset was compiled as part of a school project. The final project report, with my collaborators, can be found [here][3]\n\n\n# Inspiration\n\nWe were able to build a pretty cool subreddit recommender with the dataset. A blog post for it can be found [here][4], and the stand alone jupyter notebook for it [here][5]. Our final model is very undertuned, so there's definitely improvements to be made there, but I think there are many other cool data projects and visualizations that could be built from this dataset. One example would be to analyze the spread of users through the Reddit ecosystem, whether the average user clusters in close communities, or traverses wide and far to different corners. If you do end up building something on this, please share! And have fun!\n\nReleased under [Reddit's API licence][6]\n\n\n  [1]: http://ponderinghydrogen.pythonanywhere.com/\n  [2]: https://github.com/cole-maclean/MAI-CI/blob/master/SubRecommender/EDA%20Notebook.ipynb\n  [3]: http://cole-maclean.github.io/blog/files/subreddit-recommender.pdf\n  [4]: http://cole-maclean.github.io/blog/RNN-Based-Subreddit-Recommender-System/\n  [5]: https://github.com/cole-maclean/MAI-CI/blob/master/notebooks/blog%20post.ipynb\n  [6]: https://www.reddit.com/r/%20reddit.com/wiki/api-terms""","b""['internet', 'sociology', 'medium', 'featured']""",https://www.kaggle.com/colemaclean/subreddit-interactions
b'Academic Scores for NCAA Athletic Programs',"b""Survey of team's program eligibility and retention by year and institution""","b""# Context \n\nCollege presidents across the nation recognized a need to track how student-athletes are doing academically prior to graduation. Starting in 2003, colleges and universities in NCAA Division I \xe2\x80\x94 the largest and highest profile athletics programs \xe2\x80\x94 implemented a comprehensive academic reform package designed to improve the academic success and graduation of all student-athletes. The centerpiece of the academic reform package was the development of a real-time academic measurement for sports teams, known as the Academic Progress Rate (APR).\n\nThe APR includes student-athlete eligibility, retention and graduation as factors in a formula that yields a single number, providing a much clearer picture of the current academic culture on each Division I sports team in the country. Since its inception, the APR has become an important measure of student-athlete academic success. For high APR scores, the NCAA recognizes member institutions for ensuring that student-athletes succeed in the classroom. If, however, low APR scores are earned consistently, member institutions can be subjected to penalties including scholarship reductions and the loss of eligibility to compete in championships.\n\n\n# Content\n\nThis study was created, by the National Collegiate Athletic Association (NCAA), to provide public access to team-level APR scores, eligibility rates, retention rates, and athlete counts on Division I athletic programs starting with the 2003-2004 season through the 2013-2014 season\n\n\n# Inspiration\n\nWhich sport or school has the highest academic score? Which schools' scores have increased or decreased significantly in the past decade? Are men's or women's team academic performance better? What about public and private colleges?""","b""['sports', 'education', 'small', 'featured']""",https://www.kaggle.com/ncaa/academic-scores
b'Fantasy Premier League - 2017/18',b'Data for the 2017/18 season of the Fantasy Premier League',"b""### Context\n\nThe Fantasy Premier League has become more popular every year. In the FPL, people pick fantasy teams of real-life players, and every week, receive points based on their picks' real-life performance.\n\nWithin this dataset, we have some historical data for the player performance in previous seasons, as well as future match fixtures.\n\n### Content\n\nThe three main components currently in this dataset are:\n\n 1. The individual players' current performance stats.\n 2. The individual players' past performance stats (how much historical data depends on the player).\n 3. A list of future match fixtures.\n\nAll the data was taken from the [Official Fantasy Premier League][1] website.\n\nN.B. A lot of the data was cobbled together from the output of publicly accessible JSON endpoints, therefore there are a lot of duplications (as fixture data was initially from the perspective of the individual players). Also, since a lot of this data is used to drive the UI of a Web Application, there are a lot of redundancies, all of which could do with being cleaned up.\n\n\n### Inspiration\n\nA lot of my friends are massively into all aspects of the Premier League (fantasy or otherwise), so my main motivation in putting this dataset together was to see was it possible to gain a competitive advantage over my very domain knowledgeable friends, with little to no domain knowledge myself.\n\nThe obvious questions that could be answered with this data correspond to predicting the future performance of players based on historical metrics.\n\n\n  [1]: https://fantasy.premierleague.com/a/statistics/total_points""","b""['association football', 'small', 'featured']""",https://www.kaggle.com/thomasd9/fantasy-premier-league-201718
"b'Zillow Rent Index, 2010-Present'",b'Which city has the highest median price or price per square foot?',"b""# Context\n\nZillow operates an industry-leading economics and analytics bureau led by Zillow\xe2\x80\x99s Chief Economist, Dr. Stan Humphries. At Zillow, Dr. Humphries and his team of economists and data analysts produce extensive housing data and analysis covering more than 500 markets nationwide. Zillow Research produces various real estate, rental and mortgage-related metrics and publishes unique analyses on current topics and trends affecting the housing market.\n\nAt Zillow\xe2\x80\x99s core is our living database of more than 100 million U.S. homes, featuring both public and user-generated information including number of bedrooms and bathrooms, tax assessments, home sales and listing data of homes for sale and for rent. This data allows us to calculate, among other indicators, the Zestimate, a highly accurate, automated, estimated value of almost every home in the country as well as the Zillow Home Value Index and Zillow Rent Index, leading measures of median home values and rents. \n\n\n# Content\n\nThe Zillow Rent Index is the median estimated monthly rental price for a given area, and covers multifamily, single family, condominium, and cooperative homes in Zillow\xe2\x80\x99s database, regardless of whether they are currently listed for rent. It is expressed in dollars and is seasonally adjusted. The Zillow Rent Index is published at the national, state, metro, county, city, neighborhood, and zip code levels.\n\nZillow produces rent estimates (Rent Zestimates) based on proprietary statistical and machine learning models. Within each county or state, the models observe recent rental listings and learn the relative contribution of various home attributes in predicting prevailing rents. These home attributes include physical facts about the home, prior sale transactions, tax assessment information and geographic location as well as the estimated market value of the home (Zestimate). Based on the patterns learned, these models estimate rental prices on all homes, including those not presently for rent. Because of the availability of Zillow rental listing data used to train the models, Rent Zestimates are only available back to November 2010; therefore, each ZRI time series starts on the same date.\n\n\n# Acknowledgements\n\nThe rent index data was calculated from Zillow's proprietary Rent Zestimates and published on its website.\n\n\n# Inspiration\n\nWhat city has the highest and lowest rental prices in the country? Which metropolitan area is the most expensive to live in? Where have rental prices increased in the past five years and where have they remained the same? What city or state has the lowest cost per square foot?""","b""['cities', 'real estate', 'home', 'medium', 'featured']""",https://www.kaggle.com/zillow/rent-index
b'Brazilian congress',b'Patterns in the Brazilian congress voting behavior',"b'## Patterns in the Brazilian congress voting behavior ##\n\nThe Brazilian Government House of Representatives maintains a public database, that contains legislative information since 1970. One type of information that is available are the records of bills. For each bill, the database gives a list of votes choices, state and party of each deputy, and a list of details about the bill itself like type, year, text of proposal, benches orientations and situation (a bill can be voted more than one time, in this work we will treat each votation as a single one). We retrieved more than 100000 bills (propList), where less than 1% was voted (propVotList) until November 2016. \n\n\n----------\n\nOur objective is detect regularity patterns of legislative behavior, institutional arrangements, and legislative outcome.\n\nRaw data from: http://www2.camara.leg.br/transparencia/dados-abertos/dados-abertos-legislativo/webservices/proposicoes-1/proposicoes'","b""['crime', 'politics', 'medium', 'featured']""",https://www.kaggle.com/felipeleiteantunes/braziliancongress
"b'Armors, Exoskeletons & Mecchas'","b'300 heroes listed, 80 fully detailed'","b'### Context\n\nThe file presents a listing of characters wearing powered armor / mini or giant meccha in movies, comics, animation etc. \n\nThe purpose was to analyse our imaginaries in a specific field (i.e armors in this case) in order to see what are the macro elements, see how they evolve around time and if they are close to what is used in real life.\n\n\n### Content\n\nEach armor is analyzed according to 13 characteristics (uses an AI or not, what kind or power, where is the weapon, its capacities (does is fly, gives enhanced strength etc.). Being a social science professor and not a data analysts, I went on marvel wikia, DC wikia etc. to compile it. Something like 80 heroes are fully presented, and a list of almost 300 been found. \n\n### Inspiration\n\nComing from social science I compiled that data during my free time, but I understand that it is highly limiting and that there must be a way to aggregate much more data, & faster. Also, I am sure that it does not meet some of the standards for such work. Being a newbie here, please tell me how to improve this & I will.\n\nThe question after is to know if we can ""predict"" what future armors will look like : is there a trend showing that AI is used more and more ? That they all fly ? Once this done, it would allow to ""delineate"" the ideal characteristics of a super hero and hence, where we could innovate if we do not want to reproduce things that already done while imagining them ?\n\nThe last questions correlate to social trends : do some characteristics appear during a certain period ? If yes, is it correlated to some specific social context ? (new type of wars impacting how we imagine our heroes ?).'","b""['small', 'featured']""",https://www.kaggle.com/nicolasmin/armors-exoskeletons-mecchas
b'Glass Classification',b'Can you correctly identify glass type?',"b'# Context \n\nThis is a Glass Identification Data Set from UCI. It contains 10 attributes including id. The response is glass type(discrete 7 values)\n\n\n# Content\n\nAttribute Information:\n\n1. Id number: 1 to 214 (removed from CSV file)\n2. RI: refractive index \n3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10) \n4. Mg: Magnesium \n5. Al: Aluminum \n6. Si: Silicon \n7. K: Potassium \n8. Ca: Calcium \n9. Ba: Barium \n10. Fe: Iron \n11. Type of glass: (class attribute) \n-- 1 building_windows_float_processed \n-- 2 building_windows_non_float_processed \n-- 3 vehicle_windows_float_processed \n-- 4 vehicle_windows_non_float_processed (none in this database) \n-- 5 containers \n-- 6 tableware \n-- 7 headlamps\n\n\n# Acknowledgements\n\nhttps://archive.ics.uci.edu/ml/datasets/Glass+Identification\nSource:\n\nCreator: \nB. German \nCentral Research Establishment \nHome Office Forensic Science Service \nAldermaston, Reading, Berkshire RG7 4PN \n\nDonor: \nVina Spiehler, Ph.D., DABFT \nDiagnostic Products Corporation \n(213) 776-0180 (ext 3014)\n\n# Inspiration\n\nData exploration of this dataset reveals two important characteristics :\n1) The variables are highly **corelated** with each other including the response variables:\nSo which kind of ML algorithm is most suitable for this dataset Random Forest , KNN or other? Also since dataset is too small is there any chance of applying PCA or it should be completely avoided?\n\n2) Highly **Skewed** Data:\nIs scaling sufficient or are there any other techniques which should be applied to normalize data? Like BOX-COX Power transformation?'","b""['artificial intelligence', 'chemistry', 'small', 'featured']""",https://www.kaggle.com/uciml/glass
b'Glass Classification',b'Can you correctly identify glass type?',"b'# Context \n\nThis is a Glass Identification Data Set from UCI. It contains 10 attributes including id. The response is glass type(discrete 7 values)\n\n\n# Content\n\nAttribute Information:\n\n1. Id number: 1 to 214 (removed from CSV file)\n2. RI: refractive index \n3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10) \n4. Mg: Magnesium \n5. Al: Aluminum \n6. Si: Silicon \n7. K: Potassium \n8. Ca: Calcium \n9. Ba: Barium \n10. Fe: Iron \n11. Type of glass: (class attribute) \n-- 1 building_windows_float_processed \n-- 2 building_windows_non_float_processed \n-- 3 vehicle_windows_float_processed \n-- 4 vehicle_windows_non_float_processed (none in this database) \n-- 5 containers \n-- 6 tableware \n-- 7 headlamps\n\n\n# Acknowledgements\n\nhttps://archive.ics.uci.edu/ml/datasets/Glass+Identification\nSource:\n\nCreator: \nB. German \nCentral Research Establishment \nHome Office Forensic Science Service \nAldermaston, Reading, Berkshire RG7 4PN \n\nDonor: \nVina Spiehler, Ph.D., DABFT \nDiagnostic Products Corporation \n(213) 776-0180 (ext 3014)\n\n# Inspiration\n\nData exploration of this dataset reveals two important characteristics :\n1) The variables are highly **corelated** with each other including the response variables:\nSo which kind of ML algorithm is most suitable for this dataset Random Forest , KNN or other? Also since dataset is too small is there any chance of applying PCA or it should be completely avoided?\n\n2) Highly **Skewed** Data:\nIs scaling sufficient or are there any other techniques which should be applied to normalize data? Like BOX-COX Power transformation?'","b""['artificial intelligence', 'chemistry', 'small', 'featured']""",https://www.kaggle.com/gmadevs/atp-matches-dataset
b'Glass Classification',b'Can you correctly identify glass type?',"b'# Context \n\nThis is a Glass Identification Data Set from UCI. It contains 10 attributes including id. The response is glass type(discrete 7 values)\n\n\n# Content\n\nAttribute Information:\n\n1. Id number: 1 to 214 (removed from CSV file)\n2. RI: refractive index \n3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10) \n4. Mg: Magnesium \n5. Al: Aluminum \n6. Si: Silicon \n7. K: Potassium \n8. Ca: Calcium \n9. Ba: Barium \n10. Fe: Iron \n11. Type of glass: (class attribute) \n-- 1 building_windows_float_processed \n-- 2 building_windows_non_float_processed \n-- 3 vehicle_windows_float_processed \n-- 4 vehicle_windows_non_float_processed (none in this database) \n-- 5 containers \n-- 6 tableware \n-- 7 headlamps\n\n\n# Acknowledgements\n\nhttps://archive.ics.uci.edu/ml/datasets/Glass+Identification\nSource:\n\nCreator: \nB. German \nCentral Research Establishment \nHome Office Forensic Science Service \nAldermaston, Reading, Berkshire RG7 4PN \n\nDonor: \nVina Spiehler, Ph.D., DABFT \nDiagnostic Products Corporation \n(213) 776-0180 (ext 3014)\n\n# Inspiration\n\nData exploration of this dataset reveals two important characteristics :\n1) The variables are highly **corelated** with each other including the response variables:\nSo which kind of ML algorithm is most suitable for this dataset Random Forest , KNN or other? Also since dataset is too small is there any chance of applying PCA or it should be completely avoided?\n\n2) Highly **Skewed** Data:\nIs scaling sufficient or are there any other techniques which should be applied to normalize data? Like BOX-COX Power transformation?'","b""['artificial intelligence', 'chemistry', 'small', 'featured']""",https://www.kaggle.com/federalreserve/commercial-paper-rates
b'Glass Classification',b'Can you correctly identify glass type?',"b'# Context \n\nThis is a Glass Identification Data Set from UCI. It contains 10 attributes including id. The response is glass type(discrete 7 values)\n\n\n# Content\n\nAttribute Information:\n\n1. Id number: 1 to 214 (removed from CSV file)\n2. RI: refractive index \n3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10) \n4. Mg: Magnesium \n5. Al: Aluminum \n6. Si: Silicon \n7. K: Potassium \n8. Ca: Calcium \n9. Ba: Barium \n10. Fe: Iron \n11. Type of glass: (class attribute) \n-- 1 building_windows_float_processed \n-- 2 building_windows_non_float_processed \n-- 3 vehicle_windows_float_processed \n-- 4 vehicle_windows_non_float_processed (none in this database) \n-- 5 containers \n-- 6 tableware \n-- 7 headlamps\n\n\n# Acknowledgements\n\nhttps://archive.ics.uci.edu/ml/datasets/Glass+Identification\nSource:\n\nCreator: \nB. German \nCentral Research Establishment \nHome Office Forensic Science Service \nAldermaston, Reading, Berkshire RG7 4PN \n\nDonor: \nVina Spiehler, Ph.D., DABFT \nDiagnostic Products Corporation \n(213) 776-0180 (ext 3014)\n\n# Inspiration\n\nData exploration of this dataset reveals two important characteristics :\n1) The variables are highly **corelated** with each other including the response variables:\nSo which kind of ML algorithm is most suitable for this dataset Random Forest , KNN or other? Also since dataset is too small is there any chance of applying PCA or it should be completely avoided?\n\n2) Highly **Skewed** Data:\nIs scaling sufficient or are there any other techniques which should be applied to normalize data? Like BOX-COX Power transformation?'","b""['artificial intelligence', 'chemistry', 'small', 'featured']""",https://www.kaggle.com/fivethirtyeight/world-cup
